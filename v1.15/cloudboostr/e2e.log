I0325 08:52:32.410392      16 test_context.go:406] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-563117487
I0325 08:52:32.410725      16 e2e.go:243] Starting e2e run "f49af86e-17ad-4574-9850-f11a88690abd" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1585126350 - Will randomize all specs
Will run 215 of 4412 specs

Mar 25 08:52:32.760: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
Mar 25 08:52:32.762: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Mar 25 08:52:32.775: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Mar 25 08:52:32.826: INFO: 8 / 8 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Mar 25 08:52:32.827: INFO: expected 5 pod replicas in namespace 'kube-system', 5 are Running and Ready.
Mar 25 08:52:32.827: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Mar 25 08:52:32.833: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'filebeat' (0 seconds elapsed)
Mar 25 08:52:32.835: INFO: e2e test version: v1.15.7
Mar 25 08:52:32.836: INFO: kube-apiserver version: v1.15.7
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 08:52:32.838: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename emptydir
Mar 25 08:52:32.875: INFO: Found PodSecurityPolicies; assuming PodSecurityPolicy is enabled.
Mar 25 08:52:32.891: INFO: Found ClusterRoles; assuming RBAC is enabled.
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-226
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0666 on tmpfs
Mar 25 08:52:33.013: INFO: Waiting up to 5m0s for pod "pod-c0a5345c-b65b-41e5-adcc-e2c5df8484c5" in namespace "emptydir-226" to be "success or failure"
Mar 25 08:52:33.022: INFO: Pod "pod-c0a5345c-b65b-41e5-adcc-e2c5df8484c5": Phase="Pending", Reason="", readiness=false. Elapsed: 9.038264ms
Mar 25 08:52:35.025: INFO: Pod "pod-c0a5345c-b65b-41e5-adcc-e2c5df8484c5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011978894s
Mar 25 08:52:37.028: INFO: Pod "pod-c0a5345c-b65b-41e5-adcc-e2c5df8484c5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01496629s
STEP: Saw pod success
Mar 25 08:52:37.028: INFO: Pod "pod-c0a5345c-b65b-41e5-adcc-e2c5df8484c5" satisfied condition "success or failure"
Mar 25 08:52:37.030: INFO: Trying to get logs from node ip-10-90-32-23.eu-west-2.compute.internal pod pod-c0a5345c-b65b-41e5-adcc-e2c5df8484c5 container test-container: <nil>
STEP: delete the pod
Mar 25 08:52:37.065: INFO: Waiting for pod pod-c0a5345c-b65b-41e5-adcc-e2c5df8484c5 to disappear
Mar 25 08:52:37.067: INFO: Pod pod-c0a5345c-b65b-41e5-adcc-e2c5df8484c5 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 08:52:37.067: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-226" for this suite.
Mar 25 08:52:43.080: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 08:52:43.146: INFO: namespace emptydir-226 deletion completed in 6.07586769s

• [SLOW TEST:10.308 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 08:52:43.146: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2589
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-map-ba20d90b-e106-4571-9a08-ae45b5fb67f8
STEP: Creating a pod to test consume configMaps
Mar 25 08:52:43.343: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-9796401b-bd10-46db-99fe-756cd1e047f7" in namespace "projected-2589" to be "success or failure"
Mar 25 08:52:43.352: INFO: Pod "pod-projected-configmaps-9796401b-bd10-46db-99fe-756cd1e047f7": Phase="Pending", Reason="", readiness=false. Elapsed: 8.752292ms
Mar 25 08:52:45.355: INFO: Pod "pod-projected-configmaps-9796401b-bd10-46db-99fe-756cd1e047f7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011980612s
Mar 25 08:52:47.358: INFO: Pod "pod-projected-configmaps-9796401b-bd10-46db-99fe-756cd1e047f7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014935045s
STEP: Saw pod success
Mar 25 08:52:47.358: INFO: Pod "pod-projected-configmaps-9796401b-bd10-46db-99fe-756cd1e047f7" satisfied condition "success or failure"
Mar 25 08:52:47.360: INFO: Trying to get logs from node ip-10-90-32-23.eu-west-2.compute.internal pod pod-projected-configmaps-9796401b-bd10-46db-99fe-756cd1e047f7 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Mar 25 08:52:47.375: INFO: Waiting for pod pod-projected-configmaps-9796401b-bd10-46db-99fe-756cd1e047f7 to disappear
Mar 25 08:52:47.377: INFO: Pod pod-projected-configmaps-9796401b-bd10-46db-99fe-756cd1e047f7 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 08:52:47.377: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2589" for this suite.
Mar 25 08:52:53.388: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 08:52:53.462: INFO: namespace projected-2589 deletion completed in 6.082733885s

• [SLOW TEST:10.317 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 08:52:53.463: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-7379
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod busybox-bda2c519-46c9-4816-b6db-eda58950184a in namespace container-probe-7379
Mar 25 08:52:57.620: INFO: Started pod busybox-bda2c519-46c9-4816-b6db-eda58950184a in namespace container-probe-7379
STEP: checking the pod's current state and verifying that restartCount is present
Mar 25 08:52:57.622: INFO: Initial restart count of pod busybox-bda2c519-46c9-4816-b6db-eda58950184a is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 08:56:58.013: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-7379" for this suite.
Mar 25 08:57:04.028: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 08:57:04.104: INFO: namespace container-probe-7379 deletion completed in 6.085792978s

• [SLOW TEST:250.641 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 08:57:04.104: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-5937
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name s-test-opt-del-5f3d3b96-4578-4ba0-92a7-3d240d91d2ff
STEP: Creating secret with name s-test-opt-upd-d7399f64-92c5-4421-aad8-2b6755ae456b
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-5f3d3b96-4578-4ba0-92a7-3d240d91d2ff
STEP: Updating secret s-test-opt-upd-d7399f64-92c5-4421-aad8-2b6755ae456b
STEP: Creating secret with name s-test-opt-create-dbc2fe52-f2d7-40ed-b982-5932e9290851
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 08:57:08.319: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5937" for this suite.
Mar 25 08:57:30.330: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 08:57:30.399: INFO: namespace secrets-5937 deletion completed in 22.076809042s

• [SLOW TEST:26.294 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 08:57:30.404: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-625
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Mar 25 08:57:30.663: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"ea3c189c-1185-4ab7-8028-dc68f64d4af1", Controller:(*bool)(0xc00177b952), BlockOwnerDeletion:(*bool)(0xc00177b953)}}
Mar 25 08:57:30.677: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"485cc602-cbd6-466d-9bc5-e2032a1d4734", Controller:(*bool)(0xc00177bb36), BlockOwnerDeletion:(*bool)(0xc00177bb37)}}
Mar 25 08:57:30.690: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"433eb700-734b-4c3b-a9d5-58921f909311", Controller:(*bool)(0xc0028fdd56), BlockOwnerDeletion:(*bool)(0xc0028fdd57)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 08:57:35.698: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-625" for this suite.
Mar 25 08:57:41.709: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 08:57:41.776: INFO: namespace gc-625 deletion completed in 6.075304998s

• [SLOW TEST:11.372 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 08:57:41.776: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-4217
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Mar 25 08:57:41.915: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f23c08a5-f2c7-4372-9241-6e17e32a6f6f" in namespace "projected-4217" to be "success or failure"
Mar 25 08:57:41.919: INFO: Pod "downwardapi-volume-f23c08a5-f2c7-4372-9241-6e17e32a6f6f": Phase="Pending", Reason="", readiness=false. Elapsed: 3.942223ms
Mar 25 08:57:43.922: INFO: Pod "downwardapi-volume-f23c08a5-f2c7-4372-9241-6e17e32a6f6f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006796548s
STEP: Saw pod success
Mar 25 08:57:43.922: INFO: Pod "downwardapi-volume-f23c08a5-f2c7-4372-9241-6e17e32a6f6f" satisfied condition "success or failure"
Mar 25 08:57:43.924: INFO: Trying to get logs from node ip-10-90-32-23.eu-west-2.compute.internal pod downwardapi-volume-f23c08a5-f2c7-4372-9241-6e17e32a6f6f container client-container: <nil>
STEP: delete the pod
Mar 25 08:57:43.940: INFO: Waiting for pod downwardapi-volume-f23c08a5-f2c7-4372-9241-6e17e32a6f6f to disappear
Mar 25 08:57:43.942: INFO: Pod downwardapi-volume-f23c08a5-f2c7-4372-9241-6e17e32a6f6f no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 08:57:43.943: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4217" for this suite.
Mar 25 08:57:49.959: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 08:57:50.116: INFO: namespace projected-4217 deletion completed in 6.170844748s

• [SLOW TEST:8.340 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 08:57:50.117: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6949
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name s-test-opt-del-0ec38bc6-37b9-4e96-a15c-94f73c74d326
STEP: Creating secret with name s-test-opt-upd-5f679355-e064-4773-80b1-1285858f1c28
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-0ec38bc6-37b9-4e96-a15c-94f73c74d326
STEP: Updating secret s-test-opt-upd-5f679355-e064-4773-80b1-1285858f1c28
STEP: Creating secret with name s-test-opt-create-b01cc7c0-e0a7-4ff8-8152-1a85475c8e6e
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 08:59:02.631: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6949" for this suite.
Mar 25 08:59:24.645: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 08:59:24.739: INFO: namespace projected-6949 deletion completed in 22.105686s

• [SLOW TEST:94.622 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 08:59:24.739: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svcaccounts-6546
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: getting the auto-created API token
STEP: reading a file in the container
Mar 25 08:59:27.396: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-6546 pod-service-account-890932ce-769f-4113-a635-af87e61a1f1a -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
STEP: reading a file in the container
Mar 25 08:59:27.719: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-6546 pod-service-account-890932ce-769f-4113-a635-af87e61a1f1a -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
STEP: reading a file in the container
Mar 25 08:59:27.879: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-6546 pod-service-account-890932ce-769f-4113-a635-af87e61a1f1a -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 08:59:28.059: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-6546" for this suite.
Mar 25 08:59:34.072: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 08:59:34.148: INFO: namespace svcaccounts-6546 deletion completed in 6.085887549s

• [SLOW TEST:9.409 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:23
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 08:59:34.148: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-7008
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating service endpoint-test2 in namespace services-7008
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-7008 to expose endpoints map[]
Mar 25 08:59:34.294: INFO: successfully validated that service endpoint-test2 in namespace services-7008 exposes endpoints map[] (6.269265ms elapsed)
STEP: Creating pod pod1 in namespace services-7008
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-7008 to expose endpoints map[pod1:[80]]
Mar 25 08:59:37.319: INFO: successfully validated that service endpoint-test2 in namespace services-7008 exposes endpoints map[pod1:[80]] (3.019130062s elapsed)
STEP: Creating pod pod2 in namespace services-7008
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-7008 to expose endpoints map[pod1:[80] pod2:[80]]
Mar 25 08:59:40.356: INFO: successfully validated that service endpoint-test2 in namespace services-7008 exposes endpoints map[pod1:[80] pod2:[80]] (3.031767349s elapsed)
STEP: Deleting pod pod1 in namespace services-7008
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-7008 to expose endpoints map[pod2:[80]]
Mar 25 08:59:40.371: INFO: successfully validated that service endpoint-test2 in namespace services-7008 exposes endpoints map[pod2:[80]] (10.024714ms elapsed)
STEP: Deleting pod pod2 in namespace services-7008
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-7008 to expose endpoints map[]
Mar 25 08:59:40.381: INFO: successfully validated that service endpoint-test2 in namespace services-7008 exposes endpoints map[] (2.794643ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 08:59:40.395: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-7008" for this suite.
Mar 25 09:00:02.405: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 09:00:02.715: INFO: namespace services-7008 deletion completed in 22.31731732s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:92

• [SLOW TEST:28.566 seconds]
[sig-network] Services
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 09:00:02.715: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-6194
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test use defaults
Mar 25 09:00:02.926: INFO: Waiting up to 5m0s for pod "client-containers-0f0f9336-755f-45e8-9f31-eb4ae7da1704" in namespace "containers-6194" to be "success or failure"
Mar 25 09:00:02.950: INFO: Pod "client-containers-0f0f9336-755f-45e8-9f31-eb4ae7da1704": Phase="Pending", Reason="", readiness=false. Elapsed: 24.272067ms
Mar 25 09:00:04.953: INFO: Pod "client-containers-0f0f9336-755f-45e8-9f31-eb4ae7da1704": Phase="Pending", Reason="", readiness=false. Elapsed: 2.027056356s
Mar 25 09:00:06.956: INFO: Pod "client-containers-0f0f9336-755f-45e8-9f31-eb4ae7da1704": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02995657s
STEP: Saw pod success
Mar 25 09:00:06.956: INFO: Pod "client-containers-0f0f9336-755f-45e8-9f31-eb4ae7da1704" satisfied condition "success or failure"
Mar 25 09:00:06.958: INFO: Trying to get logs from node ip-10-90-32-23.eu-west-2.compute.internal pod client-containers-0f0f9336-755f-45e8-9f31-eb4ae7da1704 container test-container: <nil>
STEP: delete the pod
Mar 25 09:00:06.974: INFO: Waiting for pod client-containers-0f0f9336-755f-45e8-9f31-eb4ae7da1704 to disappear
Mar 25 09:00:06.976: INFO: Pod client-containers-0f0f9336-755f-45e8-9f31-eb4ae7da1704 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 09:00:06.976: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-6194" for this suite.
Mar 25 09:00:12.987: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 09:00:13.056: INFO: namespace containers-6194 deletion completed in 6.077276168s

• [SLOW TEST:10.341 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 09:00:13.056: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-1005
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Mar 25 09:00:13.194: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c099b7d7-dab5-4dc4-be72-d0b528437a9e" in namespace "downward-api-1005" to be "success or failure"
Mar 25 09:00:13.201: INFO: Pod "downwardapi-volume-c099b7d7-dab5-4dc4-be72-d0b528437a9e": Phase="Pending", Reason="", readiness=false. Elapsed: 7.021524ms
Mar 25 09:00:15.204: INFO: Pod "downwardapi-volume-c099b7d7-dab5-4dc4-be72-d0b528437a9e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009969674s
STEP: Saw pod success
Mar 25 09:00:15.204: INFO: Pod "downwardapi-volume-c099b7d7-dab5-4dc4-be72-d0b528437a9e" satisfied condition "success or failure"
Mar 25 09:00:15.206: INFO: Trying to get logs from node ip-10-90-32-23.eu-west-2.compute.internal pod downwardapi-volume-c099b7d7-dab5-4dc4-be72-d0b528437a9e container client-container: <nil>
STEP: delete the pod
Mar 25 09:00:15.224: INFO: Waiting for pod downwardapi-volume-c099b7d7-dab5-4dc4-be72-d0b528437a9e to disappear
Mar 25 09:00:15.226: INFO: Pod downwardapi-volume-c099b7d7-dab5-4dc4-be72-d0b528437a9e no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 09:00:15.226: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1005" for this suite.
Mar 25 09:00:21.236: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 09:00:21.306: INFO: namespace downward-api-1005 deletion completed in 6.077701646s

• [SLOW TEST:8.250 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 09:00:21.306: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-4493
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
Mar 25 09:00:21.442: INFO: PodSpec: initContainers in spec.initContainers
Mar 25 09:01:02.570: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-acfa93a0-3666-4c70-ab87-a46c5a40116a", GenerateName:"", Namespace:"init-container-4493", SelfLink:"/api/v1/namespaces/init-container-4493/pods/pod-init-acfa93a0-3666-4c70-ab87-a46c5a40116a", UID:"e9601d1d-eea5-44c7-a7ec-4eb43947e391", ResourceVersion:"329801", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63720723621, loc:(*time.Location)(0x7ed0a00)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"442644833"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-2rpwn", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc001c08180), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-2rpwn", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-2rpwn", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-2rpwn", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc001872298), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"ip-10-90-32-23.eu-west-2.compute.internal", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc001830060), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc001872310)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc001872330)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc001872338), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc00187233c), PreemptionPolicy:(*v1.PreemptionPolicy)(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720723621, loc:(*time.Location)(0x7ed0a00)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720723621, loc:(*time.Location)(0x7ed0a00)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720723621, loc:(*time.Location)(0x7ed0a00)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720723621, loc:(*time.Location)(0x7ed0a00)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.90.32.23", PodIP:"10.200.96.20", StartTime:(*v1.Time)(0xc002ea2120), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc002b141c0)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc002b14230)}, Ready:false, RestartCount:3, Image:"busybox:1.29", ImageID:"docker-pullable://busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"docker://3714a8be70bdfd520f1263016d647c1d4e8e7bcfd98c25478275576cdb80d70f"}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc002ea2160), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:""}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc002ea2140), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:""}}, QOSClass:"Guaranteed"}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 09:01:02.571: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-4493" for this suite.
Mar 25 09:01:24.583: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 09:01:24.666: INFO: namespace init-container-4493 deletion completed in 22.092958833s

• [SLOW TEST:63.360 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 09:01:24.666: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-283
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-017a1da0-46df-458a-9b63-237efb6ff00e
STEP: Creating a pod to test consume secrets
Mar 25 09:01:24.813: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-f2a8c817-4752-4c98-9902-6dccbfc38f37" in namespace "projected-283" to be "success or failure"
Mar 25 09:01:24.820: INFO: Pod "pod-projected-secrets-f2a8c817-4752-4c98-9902-6dccbfc38f37": Phase="Pending", Reason="", readiness=false. Elapsed: 7.320591ms
Mar 25 09:01:26.823: INFO: Pod "pod-projected-secrets-f2a8c817-4752-4c98-9902-6dccbfc38f37": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01051491s
STEP: Saw pod success
Mar 25 09:01:26.823: INFO: Pod "pod-projected-secrets-f2a8c817-4752-4c98-9902-6dccbfc38f37" satisfied condition "success or failure"
Mar 25 09:01:26.825: INFO: Trying to get logs from node ip-10-90-32-23.eu-west-2.compute.internal pod pod-projected-secrets-f2a8c817-4752-4c98-9902-6dccbfc38f37 container projected-secret-volume-test: <nil>
STEP: delete the pod
Mar 25 09:01:26.844: INFO: Waiting for pod pod-projected-secrets-f2a8c817-4752-4c98-9902-6dccbfc38f37 to disappear
Mar 25 09:01:26.846: INFO: Pod pod-projected-secrets-f2a8c817-4752-4c98-9902-6dccbfc38f37 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 09:01:26.846: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-283" for this suite.
Mar 25 09:01:32.864: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 09:01:32.938: INFO: namespace projected-283 deletion completed in 6.089137505s

• [SLOW TEST:8.272 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 09:01:32.938: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename svc-latency
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svc-latency-1548
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating replication controller svc-latency-rc in namespace svc-latency-1548
I0325 09:01:33.086742      16 runners.go:180] Created replication controller with name: svc-latency-rc, namespace: svc-latency-1548, replica count: 1
I0325 09:01:34.137413      16 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0325 09:01:35.137658      16 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Mar 25 09:01:35.245: INFO: Created: latency-svc-5458c
Mar 25 09:01:35.251: INFO: Got endpoints: latency-svc-5458c [13.167789ms]
Mar 25 09:01:35.264: INFO: Created: latency-svc-b76jl
Mar 25 09:01:35.270: INFO: Created: latency-svc-plqwh
Mar 25 09:01:35.273: INFO: Got endpoints: latency-svc-b76jl [21.962986ms]
Mar 25 09:01:35.278: INFO: Got endpoints: latency-svc-plqwh [26.875596ms]
Mar 25 09:01:35.281: INFO: Created: latency-svc-ftdzv
Mar 25 09:01:35.286: INFO: Got endpoints: latency-svc-ftdzv [34.4386ms]
Mar 25 09:01:35.290: INFO: Created: latency-svc-gvjth
Mar 25 09:01:35.295: INFO: Got endpoints: latency-svc-gvjth [22.072236ms]
Mar 25 09:01:35.298: INFO: Created: latency-svc-kr8pc
Mar 25 09:01:35.303: INFO: Got endpoints: latency-svc-kr8pc [50.845334ms]
Mar 25 09:01:35.307: INFO: Created: latency-svc-s792p
Mar 25 09:01:35.311: INFO: Got endpoints: latency-svc-s792p [59.89443ms]
Mar 25 09:01:35.315: INFO: Created: latency-svc-5x7wj
Mar 25 09:01:35.320: INFO: Got endpoints: latency-svc-5x7wj [68.107011ms]
Mar 25 09:01:35.324: INFO: Created: latency-svc-nb4fj
Mar 25 09:01:35.328: INFO: Got endpoints: latency-svc-nb4fj [76.682868ms]
Mar 25 09:01:35.332: INFO: Created: latency-svc-btmxs
Mar 25 09:01:35.336: INFO: Got endpoints: latency-svc-btmxs [84.201088ms]
Mar 25 09:01:35.340: INFO: Created: latency-svc-x4crm
Mar 25 09:01:35.345: INFO: Got endpoints: latency-svc-x4crm [93.514938ms]
Mar 25 09:01:35.349: INFO: Created: latency-svc-66x8l
Mar 25 09:01:35.355: INFO: Created: latency-svc-qgf4q
Mar 25 09:01:35.357: INFO: Got endpoints: latency-svc-66x8l [104.492852ms]
Mar 25 09:01:35.362: INFO: Created: latency-svc-st8qr
Mar 25 09:01:35.364: INFO: Got endpoints: latency-svc-qgf4q [112.174376ms]
Mar 25 09:01:35.369: INFO: Got endpoints: latency-svc-st8qr [116.785793ms]
Mar 25 09:01:35.373: INFO: Created: latency-svc-gtj6c
Mar 25 09:01:35.378: INFO: Got endpoints: latency-svc-gtj6c [125.796402ms]
Mar 25 09:01:35.381: INFO: Created: latency-svc-ns9tj
Mar 25 09:01:35.387: INFO: Got endpoints: latency-svc-ns9tj [134.959702ms]
Mar 25 09:01:35.391: INFO: Created: latency-svc-c9r5s
Mar 25 09:01:35.396: INFO: Created: latency-svc-wxcfp
Mar 25 09:01:35.398: INFO: Got endpoints: latency-svc-c9r5s [145.914024ms]
Mar 25 09:01:35.405: INFO: Got endpoints: latency-svc-wxcfp [126.91555ms]
Mar 25 09:01:35.407: INFO: Created: latency-svc-n49lc
Mar 25 09:01:35.413: INFO: Created: latency-svc-mssqg
Mar 25 09:01:35.415: INFO: Got endpoints: latency-svc-n49lc [129.279576ms]
Mar 25 09:01:35.418: INFO: Got endpoints: latency-svc-mssqg [123.231193ms]
Mar 25 09:01:35.425: INFO: Created: latency-svc-khbx5
Mar 25 09:01:35.430: INFO: Created: latency-svc-6flhl
Mar 25 09:01:35.433: INFO: Got endpoints: latency-svc-khbx5 [129.336715ms]
Mar 25 09:01:35.437: INFO: Got endpoints: latency-svc-6flhl [125.910784ms]
Mar 25 09:01:35.441: INFO: Created: latency-svc-kmj7k
Mar 25 09:01:35.446: INFO: Got endpoints: latency-svc-kmj7k [125.928971ms]
Mar 25 09:01:35.450: INFO: Created: latency-svc-r48p7
Mar 25 09:01:35.455: INFO: Created: latency-svc-phqwr
Mar 25 09:01:35.458: INFO: Got endpoints: latency-svc-r48p7 [129.959057ms]
Mar 25 09:01:35.464: INFO: Got endpoints: latency-svc-phqwr [127.661064ms]
Mar 25 09:01:35.467: INFO: Created: latency-svc-bdjxt
Mar 25 09:01:35.473: INFO: Created: latency-svc-dhxvf
Mar 25 09:01:35.475: INFO: Got endpoints: latency-svc-bdjxt [129.893393ms]
Mar 25 09:01:35.480: INFO: Created: latency-svc-w4tzb
Mar 25 09:01:35.482: INFO: Got endpoints: latency-svc-dhxvf [125.715189ms]
Mar 25 09:01:35.487: INFO: Got endpoints: latency-svc-w4tzb [122.949358ms]
Mar 25 09:01:35.490: INFO: Created: latency-svc-zpng6
Mar 25 09:01:35.495: INFO: Got endpoints: latency-svc-zpng6 [125.727227ms]
Mar 25 09:01:35.499: INFO: Created: latency-svc-hg579
Mar 25 09:01:35.503: INFO: Got endpoints: latency-svc-hg579 [125.055633ms]
Mar 25 09:01:35.506: INFO: Created: latency-svc-sxzl8
Mar 25 09:01:35.511: INFO: Got endpoints: latency-svc-sxzl8 [124.044585ms]
Mar 25 09:01:35.514: INFO: Created: latency-svc-ntr4k
Mar 25 09:01:35.524: INFO: Got endpoints: latency-svc-ntr4k [125.385658ms]
Mar 25 09:01:35.528: INFO: Created: latency-svc-hmbds
Mar 25 09:01:35.556: INFO: Got endpoints: latency-svc-hmbds [150.682364ms]
Mar 25 09:01:35.557: INFO: Created: latency-svc-mbjmx
Mar 25 09:01:35.560: INFO: Got endpoints: latency-svc-mbjmx [145.361159ms]
Mar 25 09:01:35.569: INFO: Created: latency-svc-5mcgp
Mar 25 09:01:35.576: INFO: Got endpoints: latency-svc-5mcgp [157.493572ms]
Mar 25 09:01:35.579: INFO: Created: latency-svc-crfbv
Mar 25 09:01:35.585: INFO: Got endpoints: latency-svc-crfbv [152.377153ms]
Mar 25 09:01:35.589: INFO: Created: latency-svc-rc6qf
Mar 25 09:01:35.595: INFO: Created: latency-svc-5xkrl
Mar 25 09:01:35.601: INFO: Created: latency-svc-w8cvx
Mar 25 09:01:35.602: INFO: Got endpoints: latency-svc-rc6qf [165.155345ms]
Mar 25 09:01:35.610: INFO: Created: latency-svc-bfvrg
Mar 25 09:01:35.613: INFO: Created: latency-svc-7bc7s
Mar 25 09:01:35.621: INFO: Created: latency-svc-lcmkc
Mar 25 09:01:35.626: INFO: Created: latency-svc-gd82w
Mar 25 09:01:35.630: INFO: Created: latency-svc-czvlz
Mar 25 09:01:35.635: INFO: Created: latency-svc-59vt7
Mar 25 09:01:35.643: INFO: Created: latency-svc-l66pm
Mar 25 09:01:35.646: INFO: Created: latency-svc-l6wls
Mar 25 09:01:35.651: INFO: Got endpoints: latency-svc-5xkrl [205.457212ms]
Mar 25 09:01:35.655: INFO: Created: latency-svc-dd82w
Mar 25 09:01:35.660: INFO: Created: latency-svc-qcpjq
Mar 25 09:01:35.664: INFO: Created: latency-svc-ltlg4
Mar 25 09:01:35.669: INFO: Created: latency-svc-k84mn
Mar 25 09:01:35.674: INFO: Created: latency-svc-2lbjz
Mar 25 09:01:35.677: INFO: Created: latency-svc-6nd95
Mar 25 09:01:35.698: INFO: Got endpoints: latency-svc-w8cvx [239.873453ms]
Mar 25 09:01:35.706: INFO: Created: latency-svc-q9szm
Mar 25 09:01:35.749: INFO: Got endpoints: latency-svc-bfvrg [285.084452ms]
Mar 25 09:01:35.755: INFO: Created: latency-svc-h7kzg
Mar 25 09:01:35.798: INFO: Got endpoints: latency-svc-7bc7s [322.894228ms]
Mar 25 09:01:35.806: INFO: Created: latency-svc-652zb
Mar 25 09:01:35.848: INFO: Got endpoints: latency-svc-lcmkc [366.057647ms]
Mar 25 09:01:35.855: INFO: Created: latency-svc-xrzv7
Mar 25 09:01:35.898: INFO: Got endpoints: latency-svc-gd82w [411.025758ms]
Mar 25 09:01:35.905: INFO: Created: latency-svc-m7ngb
Mar 25 09:01:35.948: INFO: Got endpoints: latency-svc-czvlz [453.415266ms]
Mar 25 09:01:35.955: INFO: Created: latency-svc-l9tns
Mar 25 09:01:35.998: INFO: Got endpoints: latency-svc-59vt7 [495.210826ms]
Mar 25 09:01:36.006: INFO: Created: latency-svc-6xbm6
Mar 25 09:01:36.049: INFO: Got endpoints: latency-svc-l66pm [537.598607ms]
Mar 25 09:01:36.055: INFO: Created: latency-svc-gw5kl
Mar 25 09:01:36.098: INFO: Got endpoints: latency-svc-l6wls [574.475557ms]
Mar 25 09:01:36.105: INFO: Created: latency-svc-b8p9h
Mar 25 09:01:36.149: INFO: Got endpoints: latency-svc-dd82w [593.105358ms]
Mar 25 09:01:36.164: INFO: Created: latency-svc-hsqtl
Mar 25 09:01:36.200: INFO: Got endpoints: latency-svc-qcpjq [639.105209ms]
Mar 25 09:01:36.206: INFO: Created: latency-svc-v7vz4
Mar 25 09:01:36.249: INFO: Got endpoints: latency-svc-ltlg4 [672.947223ms]
Mar 25 09:01:36.256: INFO: Created: latency-svc-5pwls
Mar 25 09:01:36.298: INFO: Got endpoints: latency-svc-k84mn [712.892958ms]
Mar 25 09:01:36.305: INFO: Created: latency-svc-d8lst
Mar 25 09:01:36.348: INFO: Got endpoints: latency-svc-2lbjz [745.659394ms]
Mar 25 09:01:36.356: INFO: Created: latency-svc-9tbdn
Mar 25 09:01:36.399: INFO: Got endpoints: latency-svc-6nd95 [747.82791ms]
Mar 25 09:01:36.405: INFO: Created: latency-svc-5zlfn
Mar 25 09:01:36.449: INFO: Got endpoints: latency-svc-q9szm [750.981796ms]
Mar 25 09:01:36.457: INFO: Created: latency-svc-hpxs7
Mar 25 09:01:36.499: INFO: Got endpoints: latency-svc-h7kzg [750.134882ms]
Mar 25 09:01:36.505: INFO: Created: latency-svc-4n4zq
Mar 25 09:01:36.552: INFO: Got endpoints: latency-svc-652zb [754.232439ms]
Mar 25 09:01:36.559: INFO: Created: latency-svc-7qqxj
Mar 25 09:01:36.599: INFO: Got endpoints: latency-svc-xrzv7 [750.217464ms]
Mar 25 09:01:36.605: INFO: Created: latency-svc-k62bg
Mar 25 09:01:36.648: INFO: Got endpoints: latency-svc-m7ngb [749.892342ms]
Mar 25 09:01:36.656: INFO: Created: latency-svc-xrrbq
Mar 25 09:01:36.698: INFO: Got endpoints: latency-svc-l9tns [750.126294ms]
Mar 25 09:01:36.705: INFO: Created: latency-svc-4swzb
Mar 25 09:01:36.748: INFO: Got endpoints: latency-svc-6xbm6 [749.677755ms]
Mar 25 09:01:36.755: INFO: Created: latency-svc-trkxs
Mar 25 09:01:36.799: INFO: Got endpoints: latency-svc-gw5kl [750.274235ms]
Mar 25 09:01:36.806: INFO: Created: latency-svc-wtbfn
Mar 25 09:01:36.849: INFO: Got endpoints: latency-svc-b8p9h [750.630431ms]
Mar 25 09:01:36.855: INFO: Created: latency-svc-87x8r
Mar 25 09:01:36.899: INFO: Got endpoints: latency-svc-hsqtl [749.657314ms]
Mar 25 09:01:36.906: INFO: Created: latency-svc-glcc4
Mar 25 09:01:36.949: INFO: Got endpoints: latency-svc-v7vz4 [749.072917ms]
Mar 25 09:01:36.956: INFO: Created: latency-svc-7jn48
Mar 25 09:01:36.999: INFO: Got endpoints: latency-svc-5pwls [749.846701ms]
Mar 25 09:01:37.006: INFO: Created: latency-svc-hsqhf
Mar 25 09:01:37.049: INFO: Got endpoints: latency-svc-d8lst [750.580107ms]
Mar 25 09:01:37.055: INFO: Created: latency-svc-lhk64
Mar 25 09:01:37.099: INFO: Got endpoints: latency-svc-9tbdn [750.141552ms]
Mar 25 09:01:37.106: INFO: Created: latency-svc-g8nmc
Mar 25 09:01:37.149: INFO: Got endpoints: latency-svc-5zlfn [749.933091ms]
Mar 25 09:01:37.158: INFO: Created: latency-svc-8htpn
Mar 25 09:01:37.198: INFO: Got endpoints: latency-svc-hpxs7 [748.796338ms]
Mar 25 09:01:37.205: INFO: Created: latency-svc-mw9gn
Mar 25 09:01:37.248: INFO: Got endpoints: latency-svc-4n4zq [748.981971ms]
Mar 25 09:01:37.256: INFO: Created: latency-svc-pgg8h
Mar 25 09:01:37.299: INFO: Got endpoints: latency-svc-7qqxj [746.168905ms]
Mar 25 09:01:37.307: INFO: Created: latency-svc-shprm
Mar 25 09:01:37.349: INFO: Got endpoints: latency-svc-k62bg [750.59884ms]
Mar 25 09:01:37.356: INFO: Created: latency-svc-d8vdq
Mar 25 09:01:37.398: INFO: Got endpoints: latency-svc-xrrbq [750.16792ms]
Mar 25 09:01:37.405: INFO: Created: latency-svc-9f7md
Mar 25 09:01:37.449: INFO: Got endpoints: latency-svc-4swzb [750.786222ms]
Mar 25 09:01:37.456: INFO: Created: latency-svc-zsqg8
Mar 25 09:01:37.498: INFO: Got endpoints: latency-svc-trkxs [749.83026ms]
Mar 25 09:01:37.505: INFO: Created: latency-svc-5lvfz
Mar 25 09:01:37.547: INFO: Got endpoints: latency-svc-wtbfn [748.039983ms]
Mar 25 09:01:37.555: INFO: Created: latency-svc-mrxzp
Mar 25 09:01:37.598: INFO: Got endpoints: latency-svc-87x8r [749.468208ms]
Mar 25 09:01:37.605: INFO: Created: latency-svc-rrp9d
Mar 25 09:01:37.649: INFO: Got endpoints: latency-svc-glcc4 [749.970535ms]
Mar 25 09:01:37.657: INFO: Created: latency-svc-464h4
Mar 25 09:01:37.699: INFO: Got endpoints: latency-svc-7jn48 [749.85279ms]
Mar 25 09:01:37.705: INFO: Created: latency-svc-q8c4j
Mar 25 09:01:37.749: INFO: Got endpoints: latency-svc-hsqhf [750.175676ms]
Mar 25 09:01:37.756: INFO: Created: latency-svc-94x6f
Mar 25 09:01:37.799: INFO: Got endpoints: latency-svc-lhk64 [749.658897ms]
Mar 25 09:01:37.805: INFO: Created: latency-svc-p95zk
Mar 25 09:01:37.849: INFO: Got endpoints: latency-svc-g8nmc [750.362403ms]
Mar 25 09:01:37.856: INFO: Created: latency-svc-6mv7c
Mar 25 09:01:37.899: INFO: Got endpoints: latency-svc-8htpn [750.018355ms]
Mar 25 09:01:37.906: INFO: Created: latency-svc-lhv7d
Mar 25 09:01:37.948: INFO: Got endpoints: latency-svc-mw9gn [749.822743ms]
Mar 25 09:01:37.955: INFO: Created: latency-svc-zvxml
Mar 25 09:01:37.998: INFO: Got endpoints: latency-svc-pgg8h [749.899718ms]
Mar 25 09:01:38.006: INFO: Created: latency-svc-vl4pq
Mar 25 09:01:38.049: INFO: Got endpoints: latency-svc-shprm [750.020463ms]
Mar 25 09:01:38.056: INFO: Created: latency-svc-pk4fb
Mar 25 09:01:38.098: INFO: Got endpoints: latency-svc-d8vdq [748.559319ms]
Mar 25 09:01:38.106: INFO: Created: latency-svc-tm6pd
Mar 25 09:01:38.149: INFO: Got endpoints: latency-svc-9f7md [750.145277ms]
Mar 25 09:01:38.160: INFO: Created: latency-svc-q2tc4
Mar 25 09:01:38.198: INFO: Got endpoints: latency-svc-zsqg8 [749.078511ms]
Mar 25 09:01:38.205: INFO: Created: latency-svc-cpcsz
Mar 25 09:01:38.248: INFO: Got endpoints: latency-svc-5lvfz [750.089859ms]
Mar 25 09:01:38.255: INFO: Created: latency-svc-4rpqr
Mar 25 09:01:38.299: INFO: Got endpoints: latency-svc-mrxzp [751.326605ms]
Mar 25 09:01:38.306: INFO: Created: latency-svc-z5nsq
Mar 25 09:01:38.348: INFO: Got endpoints: latency-svc-rrp9d [749.65976ms]
Mar 25 09:01:38.355: INFO: Created: latency-svc-hq4bz
Mar 25 09:01:38.399: INFO: Got endpoints: latency-svc-464h4 [750.613102ms]
Mar 25 09:01:38.406: INFO: Created: latency-svc-l44mb
Mar 25 09:01:38.449: INFO: Got endpoints: latency-svc-q8c4j [749.917905ms]
Mar 25 09:01:38.456: INFO: Created: latency-svc-rx5xv
Mar 25 09:01:38.499: INFO: Got endpoints: latency-svc-94x6f [750.023906ms]
Mar 25 09:01:38.506: INFO: Created: latency-svc-qdkpx
Mar 25 09:01:38.549: INFO: Got endpoints: latency-svc-p95zk [750.309598ms]
Mar 25 09:01:38.557: INFO: Created: latency-svc-rh5g7
Mar 25 09:01:38.599: INFO: Got endpoints: latency-svc-6mv7c [749.612329ms]
Mar 25 09:01:38.606: INFO: Created: latency-svc-qktth
Mar 25 09:01:38.648: INFO: Got endpoints: latency-svc-lhv7d [749.141507ms]
Mar 25 09:01:38.655: INFO: Created: latency-svc-chc9j
Mar 25 09:01:38.699: INFO: Got endpoints: latency-svc-zvxml [750.594872ms]
Mar 25 09:01:38.706: INFO: Created: latency-svc-pk8zf
Mar 25 09:01:38.749: INFO: Got endpoints: latency-svc-vl4pq [750.972468ms]
Mar 25 09:01:38.756: INFO: Created: latency-svc-488wp
Mar 25 09:01:38.798: INFO: Got endpoints: latency-svc-pk4fb [749.58152ms]
Mar 25 09:01:38.810: INFO: Created: latency-svc-f688g
Mar 25 09:01:38.849: INFO: Got endpoints: latency-svc-tm6pd [750.952818ms]
Mar 25 09:01:38.856: INFO: Created: latency-svc-fqxzd
Mar 25 09:01:38.899: INFO: Got endpoints: latency-svc-q2tc4 [750.509281ms]
Mar 25 09:01:38.906: INFO: Created: latency-svc-4nvzc
Mar 25 09:01:38.948: INFO: Got endpoints: latency-svc-cpcsz [750.156388ms]
Mar 25 09:01:38.956: INFO: Created: latency-svc-f5bdh
Mar 25 09:01:38.999: INFO: Got endpoints: latency-svc-4rpqr [750.868226ms]
Mar 25 09:01:39.006: INFO: Created: latency-svc-cwhsz
Mar 25 09:01:39.049: INFO: Got endpoints: latency-svc-z5nsq [749.927861ms]
Mar 25 09:01:39.056: INFO: Created: latency-svc-xdkfb
Mar 25 09:01:39.099: INFO: Got endpoints: latency-svc-hq4bz [750.533256ms]
Mar 25 09:01:39.106: INFO: Created: latency-svc-ccwjn
Mar 25 09:01:39.148: INFO: Got endpoints: latency-svc-l44mb [749.230193ms]
Mar 25 09:01:39.159: INFO: Created: latency-svc-hfkz7
Mar 25 09:01:39.202: INFO: Got endpoints: latency-svc-rx5xv [753.354431ms]
Mar 25 09:01:39.209: INFO: Created: latency-svc-nxgtd
Mar 25 09:01:39.249: INFO: Got endpoints: latency-svc-qdkpx [750.211481ms]
Mar 25 09:01:39.256: INFO: Created: latency-svc-tb5pr
Mar 25 09:01:39.299: INFO: Got endpoints: latency-svc-rh5g7 [749.758606ms]
Mar 25 09:01:39.306: INFO: Created: latency-svc-2fwkj
Mar 25 09:01:39.349: INFO: Got endpoints: latency-svc-qktth [750.022298ms]
Mar 25 09:01:39.356: INFO: Created: latency-svc-5q2bl
Mar 25 09:01:39.398: INFO: Got endpoints: latency-svc-chc9j [750.14029ms]
Mar 25 09:01:39.405: INFO: Created: latency-svc-flcw6
Mar 25 09:01:39.448: INFO: Got endpoints: latency-svc-pk8zf [749.619196ms]
Mar 25 09:01:39.455: INFO: Created: latency-svc-zqmhb
Mar 25 09:01:39.498: INFO: Got endpoints: latency-svc-488wp [749.205472ms]
Mar 25 09:01:39.505: INFO: Created: latency-svc-cx4lk
Mar 25 09:01:39.549: INFO: Got endpoints: latency-svc-f688g [750.12431ms]
Mar 25 09:01:39.555: INFO: Created: latency-svc-m9qvq
Mar 25 09:01:39.598: INFO: Got endpoints: latency-svc-fqxzd [749.525158ms]
Mar 25 09:01:39.605: INFO: Created: latency-svc-v2qxl
Mar 25 09:01:39.649: INFO: Got endpoints: latency-svc-4nvzc [749.122498ms]
Mar 25 09:01:39.656: INFO: Created: latency-svc-6h7q5
Mar 25 09:01:39.699: INFO: Got endpoints: latency-svc-f5bdh [750.001772ms]
Mar 25 09:01:39.706: INFO: Created: latency-svc-mshr7
Mar 25 09:01:39.749: INFO: Got endpoints: latency-svc-cwhsz [750.028487ms]
Mar 25 09:01:39.756: INFO: Created: latency-svc-vpf69
Mar 25 09:01:39.799: INFO: Got endpoints: latency-svc-xdkfb [750.148179ms]
Mar 25 09:01:39.806: INFO: Created: latency-svc-54499
Mar 25 09:01:39.848: INFO: Got endpoints: latency-svc-ccwjn [749.259697ms]
Mar 25 09:01:39.855: INFO: Created: latency-svc-zgjr6
Mar 25 09:01:39.899: INFO: Got endpoints: latency-svc-hfkz7 [750.284057ms]
Mar 25 09:01:39.906: INFO: Created: latency-svc-kb7bq
Mar 25 09:01:39.949: INFO: Got endpoints: latency-svc-nxgtd [746.598013ms]
Mar 25 09:01:39.955: INFO: Created: latency-svc-k5kst
Mar 25 09:01:40.000: INFO: Got endpoints: latency-svc-tb5pr [749.373642ms]
Mar 25 09:01:40.007: INFO: Created: latency-svc-jbmqq
Mar 25 09:01:40.049: INFO: Got endpoints: latency-svc-2fwkj [749.748371ms]
Mar 25 09:01:40.056: INFO: Created: latency-svc-rs2l9
Mar 25 09:01:40.098: INFO: Got endpoints: latency-svc-5q2bl [749.618574ms]
Mar 25 09:01:40.105: INFO: Created: latency-svc-jn5w2
Mar 25 09:01:40.149: INFO: Got endpoints: latency-svc-flcw6 [750.465811ms]
Mar 25 09:01:40.158: INFO: Created: latency-svc-vnwxg
Mar 25 09:01:40.199: INFO: Got endpoints: latency-svc-zqmhb [750.366835ms]
Mar 25 09:01:40.206: INFO: Created: latency-svc-xgr92
Mar 25 09:01:40.249: INFO: Got endpoints: latency-svc-cx4lk [750.541015ms]
Mar 25 09:01:40.255: INFO: Created: latency-svc-wrjpv
Mar 25 09:01:40.298: INFO: Got endpoints: latency-svc-m9qvq [749.760412ms]
Mar 25 09:01:40.307: INFO: Created: latency-svc-2q4ff
Mar 25 09:01:40.349: INFO: Got endpoints: latency-svc-v2qxl [750.78901ms]
Mar 25 09:01:40.356: INFO: Created: latency-svc-4sldj
Mar 25 09:01:40.399: INFO: Got endpoints: latency-svc-6h7q5 [750.357227ms]
Mar 25 09:01:40.406: INFO: Created: latency-svc-d48k8
Mar 25 09:01:40.449: INFO: Got endpoints: latency-svc-mshr7 [750.302703ms]
Mar 25 09:01:40.455: INFO: Created: latency-svc-9jhgd
Mar 25 09:01:40.498: INFO: Got endpoints: latency-svc-vpf69 [748.939337ms]
Mar 25 09:01:40.506: INFO: Created: latency-svc-8rst5
Mar 25 09:01:40.548: INFO: Got endpoints: latency-svc-54499 [749.297043ms]
Mar 25 09:01:40.555: INFO: Created: latency-svc-r977p
Mar 25 09:01:40.598: INFO: Got endpoints: latency-svc-zgjr6 [750.339563ms]
Mar 25 09:01:40.605: INFO: Created: latency-svc-s2n6v
Mar 25 09:01:40.648: INFO: Got endpoints: latency-svc-kb7bq [749.413691ms]
Mar 25 09:01:40.655: INFO: Created: latency-svc-mhpxh
Mar 25 09:01:40.698: INFO: Got endpoints: latency-svc-k5kst [749.120969ms]
Mar 25 09:01:40.706: INFO: Created: latency-svc-8zfl8
Mar 25 09:01:40.749: INFO: Got endpoints: latency-svc-jbmqq [749.023524ms]
Mar 25 09:01:40.757: INFO: Created: latency-svc-56kf4
Mar 25 09:01:40.799: INFO: Got endpoints: latency-svc-rs2l9 [750.162619ms]
Mar 25 09:01:40.805: INFO: Created: latency-svc-52dj7
Mar 25 09:01:40.848: INFO: Got endpoints: latency-svc-jn5w2 [749.875286ms]
Mar 25 09:01:40.855: INFO: Created: latency-svc-nc4tx
Mar 25 09:01:40.898: INFO: Got endpoints: latency-svc-vnwxg [749.050833ms]
Mar 25 09:01:40.905: INFO: Created: latency-svc-jgmd9
Mar 25 09:01:40.948: INFO: Got endpoints: latency-svc-xgr92 [749.516717ms]
Mar 25 09:01:40.955: INFO: Created: latency-svc-w4kqh
Mar 25 09:01:40.999: INFO: Got endpoints: latency-svc-wrjpv [750.147203ms]
Mar 25 09:01:41.005: INFO: Created: latency-svc-zsc94
Mar 25 09:01:41.048: INFO: Got endpoints: latency-svc-2q4ff [749.63687ms]
Mar 25 09:01:41.055: INFO: Created: latency-svc-ft2mp
Mar 25 09:01:41.099: INFO: Got endpoints: latency-svc-4sldj [749.275152ms]
Mar 25 09:01:41.105: INFO: Created: latency-svc-kcwgk
Mar 25 09:01:41.148: INFO: Got endpoints: latency-svc-d48k8 [749.432173ms]
Mar 25 09:01:41.159: INFO: Created: latency-svc-d8wmj
Mar 25 09:01:41.198: INFO: Got endpoints: latency-svc-9jhgd [749.450062ms]
Mar 25 09:01:41.206: INFO: Created: latency-svc-ppws2
Mar 25 09:01:41.249: INFO: Got endpoints: latency-svc-8rst5 [750.492987ms]
Mar 25 09:01:41.256: INFO: Created: latency-svc-4j9sv
Mar 25 09:01:41.300: INFO: Got endpoints: latency-svc-r977p [751.272531ms]
Mar 25 09:01:41.306: INFO: Created: latency-svc-wjf4z
Mar 25 09:01:41.348: INFO: Got endpoints: latency-svc-s2n6v [749.945906ms]
Mar 25 09:01:41.356: INFO: Created: latency-svc-2k78w
Mar 25 09:01:41.398: INFO: Got endpoints: latency-svc-mhpxh [749.969912ms]
Mar 25 09:01:41.406: INFO: Created: latency-svc-tnxf2
Mar 25 09:01:41.449: INFO: Got endpoints: latency-svc-8zfl8 [750.896287ms]
Mar 25 09:01:41.456: INFO: Created: latency-svc-b52hv
Mar 25 09:01:41.499: INFO: Got endpoints: latency-svc-56kf4 [749.96912ms]
Mar 25 09:01:41.505: INFO: Created: latency-svc-ptv4k
Mar 25 09:01:41.549: INFO: Got endpoints: latency-svc-52dj7 [750.054325ms]
Mar 25 09:01:41.556: INFO: Created: latency-svc-bcqt9
Mar 25 09:01:41.598: INFO: Got endpoints: latency-svc-nc4tx [749.14063ms]
Mar 25 09:01:41.604: INFO: Created: latency-svc-jbqgg
Mar 25 09:01:41.648: INFO: Got endpoints: latency-svc-jgmd9 [750.143684ms]
Mar 25 09:01:41.656: INFO: Created: latency-svc-2nn9j
Mar 25 09:01:41.698: INFO: Got endpoints: latency-svc-w4kqh [749.936859ms]
Mar 25 09:01:41.705: INFO: Created: latency-svc-qbcgf
Mar 25 09:01:41.749: INFO: Got endpoints: latency-svc-zsc94 [749.983481ms]
Mar 25 09:01:41.759: INFO: Created: latency-svc-8p6d9
Mar 25 09:01:41.799: INFO: Got endpoints: latency-svc-ft2mp [750.350122ms]
Mar 25 09:01:41.805: INFO: Created: latency-svc-6g7kf
Mar 25 09:01:41.849: INFO: Got endpoints: latency-svc-kcwgk [750.421987ms]
Mar 25 09:01:41.856: INFO: Created: latency-svc-jsklr
Mar 25 09:01:41.899: INFO: Got endpoints: latency-svc-d8wmj [750.08922ms]
Mar 25 09:01:41.906: INFO: Created: latency-svc-mhwmh
Mar 25 09:01:41.948: INFO: Got endpoints: latency-svc-ppws2 [749.940645ms]
Mar 25 09:01:41.956: INFO: Created: latency-svc-gqxkt
Mar 25 09:01:41.999: INFO: Got endpoints: latency-svc-4j9sv [750.017382ms]
Mar 25 09:01:42.006: INFO: Created: latency-svc-dc42f
Mar 25 09:01:42.049: INFO: Got endpoints: latency-svc-wjf4z [749.223295ms]
Mar 25 09:01:42.056: INFO: Created: latency-svc-ft26f
Mar 25 09:01:42.099: INFO: Got endpoints: latency-svc-2k78w [750.327206ms]
Mar 25 09:01:42.105: INFO: Created: latency-svc-8zcdd
Mar 25 09:01:42.149: INFO: Got endpoints: latency-svc-tnxf2 [750.630448ms]
Mar 25 09:01:42.158: INFO: Created: latency-svc-lgng6
Mar 25 09:01:42.199: INFO: Got endpoints: latency-svc-b52hv [750.187809ms]
Mar 25 09:01:42.206: INFO: Created: latency-svc-2h9pd
Mar 25 09:01:42.248: INFO: Got endpoints: latency-svc-ptv4k [749.538069ms]
Mar 25 09:01:42.255: INFO: Created: latency-svc-bdp9w
Mar 25 09:01:42.299: INFO: Got endpoints: latency-svc-bcqt9 [749.543417ms]
Mar 25 09:01:42.305: INFO: Created: latency-svc-55pg6
Mar 25 09:01:42.348: INFO: Got endpoints: latency-svc-jbqgg [750.791667ms]
Mar 25 09:01:42.355: INFO: Created: latency-svc-7x5f8
Mar 25 09:01:42.399: INFO: Got endpoints: latency-svc-2nn9j [750.329431ms]
Mar 25 09:01:42.405: INFO: Created: latency-svc-qf5n8
Mar 25 09:01:42.449: INFO: Got endpoints: latency-svc-qbcgf [750.340863ms]
Mar 25 09:01:42.456: INFO: Created: latency-svc-pf56f
Mar 25 09:01:42.499: INFO: Got endpoints: latency-svc-8p6d9 [749.932808ms]
Mar 25 09:01:42.511: INFO: Created: latency-svc-tgvd9
Mar 25 09:01:42.549: INFO: Got endpoints: latency-svc-6g7kf [750.493507ms]
Mar 25 09:01:42.560: INFO: Created: latency-svc-rx9tt
Mar 25 09:01:42.599: INFO: Got endpoints: latency-svc-jsklr [750.041964ms]
Mar 25 09:01:42.606: INFO: Created: latency-svc-ctg2k
Mar 25 09:01:42.649: INFO: Got endpoints: latency-svc-mhwmh [750.26279ms]
Mar 25 09:01:42.661: INFO: Created: latency-svc-wxzq5
Mar 25 09:01:42.698: INFO: Got endpoints: latency-svc-gqxkt [749.510336ms]
Mar 25 09:01:42.705: INFO: Created: latency-svc-q2n8q
Mar 25 09:01:42.748: INFO: Got endpoints: latency-svc-dc42f [749.434942ms]
Mar 25 09:01:42.755: INFO: Created: latency-svc-kl6f9
Mar 25 09:01:42.798: INFO: Got endpoints: latency-svc-ft26f [749.507897ms]
Mar 25 09:01:42.806: INFO: Created: latency-svc-b9vm9
Mar 25 09:01:42.849: INFO: Got endpoints: latency-svc-8zcdd [749.815463ms]
Mar 25 09:01:42.856: INFO: Created: latency-svc-ghpcm
Mar 25 09:01:42.899: INFO: Got endpoints: latency-svc-lgng6 [749.859873ms]
Mar 25 09:01:42.906: INFO: Created: latency-svc-n2f46
Mar 25 09:01:42.950: INFO: Got endpoints: latency-svc-2h9pd [750.474121ms]
Mar 25 09:01:42.956: INFO: Created: latency-svc-sqpwj
Mar 25 09:01:42.998: INFO: Got endpoints: latency-svc-bdp9w [749.972797ms]
Mar 25 09:01:43.006: INFO: Created: latency-svc-s2745
Mar 25 09:01:43.049: INFO: Got endpoints: latency-svc-55pg6 [750.330203ms]
Mar 25 09:01:43.056: INFO: Created: latency-svc-cggpk
Mar 25 09:01:43.098: INFO: Got endpoints: latency-svc-7x5f8 [749.928496ms]
Mar 25 09:01:43.149: INFO: Got endpoints: latency-svc-qf5n8 [749.880699ms]
Mar 25 09:01:43.199: INFO: Got endpoints: latency-svc-pf56f [749.927836ms]
Mar 25 09:01:43.248: INFO: Got endpoints: latency-svc-tgvd9 [748.781959ms]
Mar 25 09:01:43.299: INFO: Got endpoints: latency-svc-rx9tt [749.963198ms]
Mar 25 09:01:43.348: INFO: Got endpoints: latency-svc-ctg2k [748.961493ms]
Mar 25 09:01:43.398: INFO: Got endpoints: latency-svc-wxzq5 [749.149957ms]
Mar 25 09:01:43.449: INFO: Got endpoints: latency-svc-q2n8q [750.764314ms]
Mar 25 09:01:43.499: INFO: Got endpoints: latency-svc-kl6f9 [750.834604ms]
Mar 25 09:01:43.549: INFO: Got endpoints: latency-svc-b9vm9 [750.509646ms]
Mar 25 09:01:43.600: INFO: Got endpoints: latency-svc-ghpcm [750.774854ms]
Mar 25 09:01:43.649: INFO: Got endpoints: latency-svc-n2f46 [750.253853ms]
Mar 25 09:01:43.699: INFO: Got endpoints: latency-svc-sqpwj [749.115023ms]
Mar 25 09:01:43.748: INFO: Got endpoints: latency-svc-s2745 [749.442254ms]
Mar 25 09:01:43.798: INFO: Got endpoints: latency-svc-cggpk [748.818522ms]
Mar 25 09:01:43.798: INFO: Latencies: [21.962986ms 22.072236ms 26.875596ms 34.4386ms 50.845334ms 59.89443ms 68.107011ms 76.682868ms 84.201088ms 93.514938ms 104.492852ms 112.174376ms 116.785793ms 122.949358ms 123.231193ms 124.044585ms 125.055633ms 125.385658ms 125.715189ms 125.727227ms 125.796402ms 125.910784ms 125.928971ms 126.91555ms 127.661064ms 129.279576ms 129.336715ms 129.893393ms 129.959057ms 134.959702ms 145.361159ms 145.914024ms 150.682364ms 152.377153ms 157.493572ms 165.155345ms 205.457212ms 239.873453ms 285.084452ms 322.894228ms 366.057647ms 411.025758ms 453.415266ms 495.210826ms 537.598607ms 574.475557ms 593.105358ms 639.105209ms 672.947223ms 712.892958ms 745.659394ms 746.168905ms 746.598013ms 747.82791ms 748.039983ms 748.559319ms 748.781959ms 748.796338ms 748.818522ms 748.939337ms 748.961493ms 748.981971ms 749.023524ms 749.050833ms 749.072917ms 749.078511ms 749.115023ms 749.120969ms 749.122498ms 749.14063ms 749.141507ms 749.149957ms 749.205472ms 749.223295ms 749.230193ms 749.259697ms 749.275152ms 749.297043ms 749.373642ms 749.413691ms 749.432173ms 749.434942ms 749.442254ms 749.450062ms 749.468208ms 749.507897ms 749.510336ms 749.516717ms 749.525158ms 749.538069ms 749.543417ms 749.58152ms 749.612329ms 749.618574ms 749.619196ms 749.63687ms 749.657314ms 749.658897ms 749.65976ms 749.677755ms 749.748371ms 749.758606ms 749.760412ms 749.815463ms 749.822743ms 749.83026ms 749.846701ms 749.85279ms 749.859873ms 749.875286ms 749.880699ms 749.892342ms 749.899718ms 749.917905ms 749.927836ms 749.927861ms 749.928496ms 749.932808ms 749.933091ms 749.936859ms 749.940645ms 749.945906ms 749.963198ms 749.96912ms 749.969912ms 749.970535ms 749.972797ms 749.983481ms 750.001772ms 750.017382ms 750.018355ms 750.020463ms 750.022298ms 750.023906ms 750.028487ms 750.041964ms 750.054325ms 750.08922ms 750.089859ms 750.12431ms 750.126294ms 750.134882ms 750.14029ms 750.141552ms 750.143684ms 750.145277ms 750.147203ms 750.148179ms 750.156388ms 750.162619ms 750.16792ms 750.175676ms 750.187809ms 750.211481ms 750.217464ms 750.253853ms 750.26279ms 750.274235ms 750.284057ms 750.302703ms 750.309598ms 750.327206ms 750.329431ms 750.330203ms 750.339563ms 750.340863ms 750.350122ms 750.357227ms 750.362403ms 750.366835ms 750.421987ms 750.465811ms 750.474121ms 750.492987ms 750.493507ms 750.509281ms 750.509646ms 750.533256ms 750.541015ms 750.580107ms 750.594872ms 750.59884ms 750.613102ms 750.630431ms 750.630448ms 750.764314ms 750.774854ms 750.786222ms 750.78901ms 750.791667ms 750.834604ms 750.868226ms 750.896287ms 750.952818ms 750.972468ms 750.981796ms 751.272531ms 751.326605ms 753.354431ms 754.232439ms]
Mar 25 09:01:43.798: INFO: 50 %ile: 749.748371ms
Mar 25 09:01:43.798: INFO: 90 %ile: 750.594872ms
Mar 25 09:01:43.798: INFO: 99 %ile: 753.354431ms
Mar 25 09:01:43.798: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 09:01:43.798: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svc-latency-1548" for this suite.
Mar 25 09:01:53.810: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 09:01:53.881: INFO: namespace svc-latency-1548 deletion completed in 10.079459127s

• [SLOW TEST:20.943 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should not be very high  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 09:01:53.883: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-8090
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod busybox-9a1eca8a-9cca-4faf-85b0-82027ecd0165 in namespace container-probe-8090
Mar 25 09:01:58.029: INFO: Started pod busybox-9a1eca8a-9cca-4faf-85b0-82027ecd0165 in namespace container-probe-8090
STEP: checking the pod's current state and verifying that restartCount is present
Mar 25 09:01:58.033: INFO: Initial restart count of pod busybox-9a1eca8a-9cca-4faf-85b0-82027ecd0165 is 0
Mar 25 09:02:46.113: INFO: Restart count of pod container-probe-8090/busybox-9a1eca8a-9cca-4faf-85b0-82027ecd0165 is now 1 (48.079717028s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 09:02:46.122: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-8090" for this suite.
Mar 25 09:02:52.138: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 09:02:52.236: INFO: namespace container-probe-8090 deletion completed in 6.110681261s

• [SLOW TEST:58.353 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 09:02:52.236: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-531
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-531
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating stateful set ss in namespace statefulset-531
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-531
Mar 25 09:02:52.443: INFO: Found 0 stateful pods, waiting for 1
Mar 25 09:03:02.446: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Mar 25 09:03:02.448: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 exec --namespace=statefulset-531 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar 25 09:03:02.619: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Mar 25 09:03:02.619: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar 25 09:03:02.619: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Mar 25 09:03:02.622: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Mar 25 09:03:12.625: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Mar 25 09:03:12.625: INFO: Waiting for statefulset status.replicas updated to 0
Mar 25 09:03:12.640: INFO: POD   NODE                                       PHASE    GRACE  CONDITIONS
Mar 25 09:03:12.640: INFO: ss-0  ip-10-90-32-23.eu-west-2.compute.internal  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-25 09:02:52 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-03-25 09:03:02 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-03-25 09:03:02 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-25 09:02:52 +0000 UTC  }]
Mar 25 09:03:12.640: INFO: ss-1                                             Pending         []
Mar 25 09:03:12.640: INFO: 
Mar 25 09:03:12.640: INFO: StatefulSet ss has not reached scale 3, at 2
Mar 25 09:03:13.644: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.994864387s
Mar 25 09:03:14.647: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.991519569s
Mar 25 09:03:15.650: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.987959451s
Mar 25 09:03:16.654: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.984506206s
Mar 25 09:03:17.657: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.981070661s
Mar 25 09:03:18.661: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.977521327s
Mar 25 09:03:19.665: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.973785034s
Mar 25 09:03:20.669: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.970217294s
Mar 25 09:03:21.672: INFO: Verifying statefulset ss doesn't scale past 3 for another 966.505907ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-531
Mar 25 09:03:22.675: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 exec --namespace=statefulset-531 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 25 09:03:22.845: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Mar 25 09:03:22.845: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Mar 25 09:03:22.845: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Mar 25 09:03:22.845: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 exec --namespace=statefulset-531 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 25 09:03:23.018: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Mar 25 09:03:23.018: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Mar 25 09:03:23.018: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Mar 25 09:03:23.018: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 exec --namespace=statefulset-531 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 25 09:03:23.198: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Mar 25 09:03:23.198: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Mar 25 09:03:23.198: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Mar 25 09:03:23.201: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Mar 25 09:03:23.201: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Mar 25 09:03:23.201: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Mar 25 09:03:23.204: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 exec --namespace=statefulset-531 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar 25 09:03:23.382: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Mar 25 09:03:23.382: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar 25 09:03:23.382: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Mar 25 09:03:23.382: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 exec --namespace=statefulset-531 ss-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar 25 09:03:23.554: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Mar 25 09:03:23.554: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar 25 09:03:23.554: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Mar 25 09:03:23.554: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 exec --namespace=statefulset-531 ss-2 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar 25 09:03:23.744: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Mar 25 09:03:23.744: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar 25 09:03:23.744: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Mar 25 09:03:23.744: INFO: Waiting for statefulset status.replicas updated to 0
Mar 25 09:03:23.746: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
Mar 25 09:03:33.751: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Mar 25 09:03:33.751: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Mar 25 09:03:33.751: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Mar 25 09:03:33.763: INFO: POD   NODE                                       PHASE    GRACE  CONDITIONS
Mar 25 09:03:33.763: INFO: ss-0  ip-10-90-32-23.eu-west-2.compute.internal  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-25 09:02:52 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-03-25 09:03:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-03-25 09:03:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-25 09:02:52 +0000 UTC  }]
Mar 25 09:03:33.763: INFO: ss-1  ip-10-90-32-24.eu-west-2.compute.internal  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-25 09:03:12 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-03-25 09:03:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-03-25 09:03:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-25 09:03:12 +0000 UTC  }]
Mar 25 09:03:33.764: INFO: ss-2  ip-10-90-32-22.eu-west-2.compute.internal  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-25 09:03:12 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-03-25 09:03:24 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-03-25 09:03:24 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-25 09:03:12 +0000 UTC  }]
Mar 25 09:03:33.764: INFO: 
Mar 25 09:03:33.764: INFO: StatefulSet ss has not reached scale 0, at 3
Mar 25 09:03:34.767: INFO: POD   NODE                                       PHASE    GRACE  CONDITIONS
Mar 25 09:03:34.767: INFO: ss-0  ip-10-90-32-23.eu-west-2.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-25 09:02:52 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-03-25 09:03:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-03-25 09:03:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-25 09:02:52 +0000 UTC  }]
Mar 25 09:03:34.767: INFO: ss-1  ip-10-90-32-24.eu-west-2.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-25 09:03:12 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-03-25 09:03:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-03-25 09:03:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-25 09:03:12 +0000 UTC  }]
Mar 25 09:03:34.767: INFO: ss-2  ip-10-90-32-22.eu-west-2.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-25 09:03:12 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-03-25 09:03:24 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-03-25 09:03:24 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-25 09:03:12 +0000 UTC  }]
Mar 25 09:03:34.767: INFO: 
Mar 25 09:03:34.767: INFO: StatefulSet ss has not reached scale 0, at 3
Mar 25 09:03:35.771: INFO: POD   NODE                                       PHASE    GRACE  CONDITIONS
Mar 25 09:03:35.771: INFO: ss-0  ip-10-90-32-23.eu-west-2.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-25 09:02:52 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-03-25 09:03:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-03-25 09:03:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-25 09:02:52 +0000 UTC  }]
Mar 25 09:03:35.771: INFO: ss-1  ip-10-90-32-24.eu-west-2.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-25 09:03:12 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-03-25 09:03:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-03-25 09:03:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-25 09:03:12 +0000 UTC  }]
Mar 25 09:03:35.771: INFO: 
Mar 25 09:03:35.771: INFO: StatefulSet ss has not reached scale 0, at 2
Mar 25 09:03:36.774: INFO: POD   NODE                                       PHASE    GRACE  CONDITIONS
Mar 25 09:03:36.774: INFO: ss-0  ip-10-90-32-23.eu-west-2.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-25 09:02:52 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-03-25 09:03:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-03-25 09:03:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-25 09:02:52 +0000 UTC  }]
Mar 25 09:03:36.774: INFO: 
Mar 25 09:03:36.774: INFO: StatefulSet ss has not reached scale 0, at 1
Mar 25 09:03:37.777: INFO: POD   NODE                                       PHASE    GRACE  CONDITIONS
Mar 25 09:03:37.777: INFO: ss-0  ip-10-90-32-23.eu-west-2.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-25 09:02:52 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-03-25 09:03:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-03-25 09:03:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-25 09:02:52 +0000 UTC  }]
Mar 25 09:03:37.778: INFO: 
Mar 25 09:03:37.778: INFO: StatefulSet ss has not reached scale 0, at 1
Mar 25 09:03:38.781: INFO: POD   NODE                                       PHASE    GRACE  CONDITIONS
Mar 25 09:03:38.781: INFO: ss-0  ip-10-90-32-23.eu-west-2.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-25 09:02:52 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-03-25 09:03:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-03-25 09:03:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-25 09:02:52 +0000 UTC  }]
Mar 25 09:03:38.781: INFO: 
Mar 25 09:03:38.781: INFO: StatefulSet ss has not reached scale 0, at 1
Mar 25 09:03:39.784: INFO: POD   NODE                                       PHASE    GRACE  CONDITIONS
Mar 25 09:03:39.784: INFO: ss-0  ip-10-90-32-23.eu-west-2.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-25 09:02:52 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-03-25 09:03:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-03-25 09:03:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-25 09:02:52 +0000 UTC  }]
Mar 25 09:03:39.785: INFO: 
Mar 25 09:03:39.785: INFO: StatefulSet ss has not reached scale 0, at 1
Mar 25 09:03:40.788: INFO: POD   NODE                                       PHASE    GRACE  CONDITIONS
Mar 25 09:03:40.788: INFO: ss-0  ip-10-90-32-23.eu-west-2.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-25 09:02:52 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-03-25 09:03:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-03-25 09:03:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-25 09:02:52 +0000 UTC  }]
Mar 25 09:03:40.788: INFO: 
Mar 25 09:03:40.788: INFO: StatefulSet ss has not reached scale 0, at 1
Mar 25 09:03:41.791: INFO: POD   NODE                                       PHASE    GRACE  CONDITIONS
Mar 25 09:03:41.791: INFO: ss-0  ip-10-90-32-23.eu-west-2.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-25 09:02:52 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-03-25 09:03:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-03-25 09:03:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-25 09:02:52 +0000 UTC  }]
Mar 25 09:03:41.791: INFO: 
Mar 25 09:03:41.791: INFO: StatefulSet ss has not reached scale 0, at 1
Mar 25 09:03:42.795: INFO: POD   NODE                                       PHASE    GRACE  CONDITIONS
Mar 25 09:03:42.795: INFO: ss-0  ip-10-90-32-23.eu-west-2.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-25 09:02:52 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-03-25 09:03:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-03-25 09:03:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-25 09:02:52 +0000 UTC  }]
Mar 25 09:03:42.795: INFO: 
Mar 25 09:03:42.795: INFO: StatefulSet ss has not reached scale 0, at 1
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-531
Mar 25 09:03:43.798: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 exec --namespace=statefulset-531 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 25 09:03:43.894: INFO: rc: 1
Mar 25 09:03:43.894: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-563117487 exec --namespace=statefulset-531 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  error: unable to upgrade connection: container not found ("nginx")
 [] <nil> 0xc001a04630 exit status 1 <nil> <nil> true [0xc0028f4158 0xc0028f4170 0xc0028f4188] [0xc0028f4158 0xc0028f4170 0xc0028f4188] [0xc0028f4168 0xc0028f4180] [0xba6c10 0xba6c10] 0xc003326d80 <nil>}:
Command stdout:

stderr:
error: unable to upgrade connection: container not found ("nginx")

error:
exit status 1
Mar 25 09:03:53.895: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 exec --namespace=statefulset-531 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 25 09:03:53.963: INFO: rc: 1
Mar 25 09:03:53.963: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-563117487 exec --namespace=statefulset-531 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc001a04990 exit status 1 <nil> <nil> true [0xc0028f4190 0xc0028f41a8 0xc0028f41c0] [0xc0028f4190 0xc0028f41a8 0xc0028f41c0] [0xc0028f41a0 0xc0028f41b8] [0xba6c10 0xba6c10] 0xc0033270e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Mar 25 09:04:03.963: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 exec --namespace=statefulset-531 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 25 09:04:04.030: INFO: rc: 1
Mar 25 09:04:04.030: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-563117487 exec --namespace=statefulset-531 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc001ba99e0 exit status 1 <nil> <nil> true [0xc0033b4240 0xc0033b4280 0xc0033b42a8] [0xc0033b4240 0xc0033b4280 0xc0033b42a8] [0xc0033b4260 0xc0033b42a0] [0xba6c10 0xba6c10] 0xc00293b5c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Mar 25 09:04:14.031: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 exec --namespace=statefulset-531 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 25 09:04:14.104: INFO: rc: 1
Mar 25 09:04:14.104: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-563117487 exec --namespace=statefulset-531 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc001ba9d40 exit status 1 <nil> <nil> true [0xc0033b42b0 0xc0033b42c8 0xc0033b42e0] [0xc0033b42b0 0xc0033b42c8 0xc0033b42e0] [0xc0033b42c0 0xc0033b42d8] [0xba6c10 0xba6c10] 0xc00293b980 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Mar 25 09:04:24.104: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 exec --namespace=statefulset-531 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 25 09:04:24.185: INFO: rc: 1
Mar 25 09:04:24.185: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-563117487 exec --namespace=statefulset-531 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc001a04cf0 exit status 1 <nil> <nil> true [0xc0028f41c8 0xc0028f41e0 0xc0028f41f8] [0xc0028f41c8 0xc0028f41e0 0xc0028f41f8] [0xc0028f41d8 0xc0028f41f0] [0xba6c10 0xba6c10] 0xc003327440 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Mar 25 09:04:34.186: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 exec --namespace=statefulset-531 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 25 09:04:34.255: INFO: rc: 1
Mar 25 09:04:34.255: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-563117487 exec --namespace=statefulset-531 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc001a05260 exit status 1 <nil> <nil> true [0xc0028f4200 0xc0028f4218 0xc0028f4238] [0xc0028f4200 0xc0028f4218 0xc0028f4238] [0xc0028f4210 0xc0028f4230] [0xba6c10 0xba6c10] 0xc0033277a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Mar 25 09:04:44.255: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 exec --namespace=statefulset-531 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 25 09:04:44.326: INFO: rc: 1
Mar 25 09:04:44.326: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-563117487 exec --namespace=statefulset-531 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002436300 exit status 1 <nil> <nil> true [0xc000e64148 0xc000e647e0 0xc000e64d78] [0xc000e64148 0xc000e647e0 0xc000e64d78] [0xc000e64298 0xc000e64d18] [0xba6c10 0xba6c10] 0xc003b18300 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Mar 25 09:04:54.326: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 exec --namespace=statefulset-531 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 25 09:04:54.393: INFO: rc: 1
Mar 25 09:04:54.393: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-563117487 exec --namespace=statefulset-531 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc00175a300 exit status 1 <nil> <nil> true [0xc002372018 0xc002372070 0xc0023720a8] [0xc002372018 0xc002372070 0xc0023720a8] [0xc002372060 0xc002372098] [0xba6c10 0xba6c10] 0xc003c7c540 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Mar 25 09:05:04.394: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 exec --namespace=statefulset-531 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 25 09:05:04.464: INFO: rc: 1
Mar 25 09:05:04.464: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-563117487 exec --namespace=statefulset-531 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002436660 exit status 1 <nil> <nil> true [0xc000e64db0 0xc000e650f8 0xc000e65280] [0xc000e64db0 0xc000e650f8 0xc000e65280] [0xc000e64f20 0xc000e65270] [0xba6c10 0xba6c10] 0xc003b18780 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Mar 25 09:05:14.465: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 exec --namespace=statefulset-531 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 25 09:05:14.532: INFO: rc: 1
Mar 25 09:05:14.532: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-563117487 exec --namespace=statefulset-531 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc00175a6f0 exit status 1 <nil> <nil> true [0xc0023720b0 0xc002372128 0xc002372190] [0xc0023720b0 0xc002372128 0xc002372190] [0xc002372100 0xc002372180] [0xba6c10 0xba6c10] 0xc003c7cc00 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Mar 25 09:05:24.532: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 exec --namespace=statefulset-531 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 25 09:05:24.598: INFO: rc: 1
Mar 25 09:05:24.598: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-563117487 exec --namespace=statefulset-531 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc00175aa50 exit status 1 <nil> <nil> true [0xc002372198 0xc002372218 0xc0023722b0] [0xc002372198 0xc002372218 0xc0023722b0] [0xc0023721c8 0xc002372260] [0xba6c10 0xba6c10] 0xc003c7d1a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Mar 25 09:05:34.598: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 exec --namespace=statefulset-531 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 25 09:05:34.666: INFO: rc: 1
Mar 25 09:05:34.666: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-563117487 exec --namespace=statefulset-531 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc00175adb0 exit status 1 <nil> <nil> true [0xc0023722d0 0xc002372350 0xc0023723b0] [0xc0023722d0 0xc002372350 0xc0023723b0] [0xc0023722f0 0xc0023723a0] [0xba6c10 0xba6c10] 0xc003c7d5c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Mar 25 09:05:44.667: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 exec --namespace=statefulset-531 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 25 09:05:44.733: INFO: rc: 1
Mar 25 09:05:44.733: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-563117487 exec --namespace=statefulset-531 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0024369c0 exit status 1 <nil> <nil> true [0xc000e652f0 0xc000e653b0 0xc000e65490] [0xc000e652f0 0xc000e653b0 0xc000e65490] [0xc000e65398 0xc000e65428] [0xba6c10 0xba6c10] 0xc003b18ae0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Mar 25 09:05:54.733: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 exec --namespace=statefulset-531 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 25 09:05:54.803: INFO: rc: 1
Mar 25 09:05:54.803: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-563117487 exec --namespace=statefulset-531 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002436d50 exit status 1 <nil> <nil> true [0xc000e654b8 0xc000e65560 0xc000e65700] [0xc000e654b8 0xc000e65560 0xc000e65700] [0xc000e65510 0xc000e656d8] [0xba6c10 0xba6c10] 0xc003b18f60 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Mar 25 09:06:04.803: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 exec --namespace=statefulset-531 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 25 09:06:04.874: INFO: rc: 1
Mar 25 09:06:04.874: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-563117487 exec --namespace=statefulset-531 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0024370b0 exit status 1 <nil> <nil> true [0xc000e65738 0xc000e657c0 0xc000e65830] [0xc000e65738 0xc000e657c0 0xc000e65830] [0xc000e657a0 0xc000e65820] [0xba6c10 0xba6c10] 0xc003b19320 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Mar 25 09:06:14.874: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 exec --namespace=statefulset-531 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 25 09:06:14.941: INFO: rc: 1
Mar 25 09:06:14.941: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-563117487 exec --namespace=statefulset-531 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002437410 exit status 1 <nil> <nil> true [0xc000e65848 0xc000e65930 0xc000e659c8] [0xc000e65848 0xc000e65930 0xc000e659c8] [0xc000e65918 0xc000e65980] [0xba6c10 0xba6c10] 0xc003b19680 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Mar 25 09:06:24.942: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 exec --namespace=statefulset-531 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 25 09:06:25.011: INFO: rc: 1
Mar 25 09:06:25.011: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-563117487 exec --namespace=statefulset-531 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0024377a0 exit status 1 <nil> <nil> true [0xc000e65a28 0xc000e65a70 0xc000e65aa0] [0xc000e65a28 0xc000e65a70 0xc000e65aa0] [0xc000e65a60 0xc000e65a90] [0xba6c10 0xba6c10] 0xc003b19aa0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Mar 25 09:06:35.012: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 exec --namespace=statefulset-531 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 25 09:06:35.081: INFO: rc: 1
Mar 25 09:06:35.081: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-563117487 exec --namespace=statefulset-531 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc00175b1a0 exit status 1 <nil> <nil> true [0xc0023723e0 0xc002372450 0xc0023724c8] [0xc0023723e0 0xc002372450 0xc0023724c8] [0xc002372430 0xc002372498] [0xba6c10 0xba6c10] 0xc003c7daa0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Mar 25 09:06:45.082: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 exec --namespace=statefulset-531 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 25 09:06:45.149: INFO: rc: 1
Mar 25 09:06:45.149: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-563117487 exec --namespace=statefulset-531 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc00175a330 exit status 1 <nil> <nil> true [0xc002372030 0xc002372088 0xc0023720b0] [0xc002372030 0xc002372088 0xc0023720b0] [0xc002372070 0xc0023720a8] [0xba6c10 0xba6c10] 0xc003c7c540 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Mar 25 09:06:55.149: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 exec --namespace=statefulset-531 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 25 09:06:55.222: INFO: rc: 1
Mar 25 09:06:55.222: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-563117487 exec --namespace=statefulset-531 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc00175a720 exit status 1 <nil> <nil> true [0xc0023720e0 0xc002372150 0xc002372198] [0xc0023720e0 0xc002372150 0xc002372198] [0xc002372128 0xc002372190] [0xba6c10 0xba6c10] 0xc003c7cc00 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Mar 25 09:07:05.222: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 exec --namespace=statefulset-531 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 25 09:07:05.288: INFO: rc: 1
Mar 25 09:07:05.289: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-563117487 exec --namespace=statefulset-531 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc00175aab0 exit status 1 <nil> <nil> true [0xc0023721a8 0xc002372238 0xc0023722d0] [0xc0023721a8 0xc002372238 0xc0023722d0] [0xc002372218 0xc0023722b0] [0xba6c10 0xba6c10] 0xc003c7d1a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Mar 25 09:07:15.289: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 exec --namespace=statefulset-531 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 25 09:07:15.355: INFO: rc: 1
Mar 25 09:07:15.355: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-563117487 exec --namespace=statefulset-531 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002436330 exit status 1 <nil> <nil> true [0xc000e64058 0xc000e64298 0xc000e64d18] [0xc000e64058 0xc000e64298 0xc000e64d18] [0xc000e64228 0xc000e64a58] [0xba6c10 0xba6c10] 0xc003b18300 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Mar 25 09:07:25.356: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 exec --namespace=statefulset-531 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 25 09:07:25.424: INFO: rc: 1
Mar 25 09:07:25.424: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-563117487 exec --namespace=statefulset-531 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0024366c0 exit status 1 <nil> <nil> true [0xc000e64d78 0xc000e64f20 0xc000e65270] [0xc000e64d78 0xc000e64f20 0xc000e65270] [0xc000e64e38 0xc000e65168] [0xba6c10 0xba6c10] 0xc003b18780 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Mar 25 09:07:35.424: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 exec --namespace=statefulset-531 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 25 09:07:35.490: INFO: rc: 1
Mar 25 09:07:35.490: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-563117487 exec --namespace=statefulset-531 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc00175ae40 exit status 1 <nil> <nil> true [0xc0023722e0 0xc002372380 0xc0023723e0] [0xc0023722e0 0xc002372380 0xc0023723e0] [0xc002372350 0xc0023723b0] [0xba6c10 0xba6c10] 0xc003c7d5c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Mar 25 09:07:45.490: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 exec --namespace=statefulset-531 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 25 09:07:45.561: INFO: rc: 1
Mar 25 09:07:45.561: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-563117487 exec --namespace=statefulset-531 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002436ab0 exit status 1 <nil> <nil> true [0xc000e65280 0xc000e65398 0xc000e65428] [0xc000e65280 0xc000e65398 0xc000e65428] [0xc000e65360 0xc000e653b8] [0xba6c10 0xba6c10] 0xc003b18ae0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Mar 25 09:07:55.561: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 exec --namespace=statefulset-531 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 25 09:07:55.627: INFO: rc: 1
Mar 25 09:07:55.627: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-563117487 exec --namespace=statefulset-531 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002436e70 exit status 1 <nil> <nil> true [0xc000e65490 0xc000e65510 0xc000e656d8] [0xc000e65490 0xc000e65510 0xc000e656d8] [0xc000e654e8 0xc000e655a8] [0xba6c10 0xba6c10] 0xc003b18f60 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Mar 25 09:08:05.627: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 exec --namespace=statefulset-531 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 25 09:08:05.693: INFO: rc: 1
Mar 25 09:08:05.694: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-563117487 exec --namespace=statefulset-531 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc00175b200 exit status 1 <nil> <nil> true [0xc002372410 0xc002372478 0xc0023724d8] [0xc002372410 0xc002372478 0xc0023724d8] [0xc002372450 0xc0023724c8] [0xba6c10 0xba6c10] 0xc003c7daa0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Mar 25 09:08:15.694: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 exec --namespace=statefulset-531 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 25 09:08:15.759: INFO: rc: 1
Mar 25 09:08:15.759: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-563117487 exec --namespace=statefulset-531 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc00175b740 exit status 1 <nil> <nil> true [0xc0023724e0 0xc002372530 0xc002372578] [0xc0023724e0 0xc002372530 0xc002372578] [0xc0023724f8 0xc002372550] [0xba6c10 0xba6c10] 0xc002dce000 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Mar 25 09:08:25.759: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 exec --namespace=statefulset-531 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 25 09:08:25.826: INFO: rc: 1
Mar 25 09:08:25.826: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-563117487 exec --namespace=statefulset-531 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0024371d0 exit status 1 <nil> <nil> true [0xc000e65700 0xc000e657a0 0xc000e65820] [0xc000e65700 0xc000e657a0 0xc000e65820] [0xc000e65770 0xc000e657e0] [0xba6c10 0xba6c10] 0xc003b19320 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Mar 25 09:08:35.826: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 exec --namespace=statefulset-531 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 25 09:08:35.893: INFO: rc: 1
Mar 25 09:08:35.893: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-563117487 exec --namespace=statefulset-531 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002437590 exit status 1 <nil> <nil> true [0xc000e65830 0xc000e65918 0xc000e65980] [0xc000e65830 0xc000e65918 0xc000e65980] [0xc000e658c8 0xc000e65940] [0xba6c10 0xba6c10] 0xc003b19680 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Mar 25 09:08:45.893: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 exec --namespace=statefulset-531 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 25 09:08:45.970: INFO: rc: 1
Mar 25 09:08:45.971: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: 
Mar 25 09:08:45.971: INFO: Scaling statefulset ss to 0
Mar 25 09:08:45.977: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Mar 25 09:08:45.979: INFO: Deleting all statefulset in ns statefulset-531
Mar 25 09:08:45.981: INFO: Scaling statefulset ss to 0
Mar 25 09:08:45.987: INFO: Waiting for statefulset status.replicas updated to 0
Mar 25 09:08:45.988: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 09:08:46.001: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-531" for this suite.
Mar 25 09:08:52.018: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 09:08:52.132: INFO: namespace statefulset-531 deletion completed in 6.12667414s

• [SLOW TEST:359.896 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 09:08:52.133: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-6100
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
Mar 25 09:09:02.284: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W0325 09:09:02.284914      16 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 09:09:02.285: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-6100" for this suite.
Mar 25 09:09:08.295: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 09:09:08.364: INFO: namespace gc-6100 deletion completed in 6.076963003s

• [SLOW TEST:16.231 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 09:09:08.365: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-5834
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name cm-test-opt-del-f00893d3-fcf5-4404-9e56-c9a780b83225
STEP: Creating configMap with name cm-test-opt-upd-ea2cd363-ec79-416e-a64c-b30db84318a2
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-f00893d3-fcf5-4404-9e56-c9a780b83225
STEP: Updating configmap cm-test-opt-upd-ea2cd363-ec79-416e-a64c-b30db84318a2
STEP: Creating configMap with name cm-test-opt-create-70a0e946-87a6-4acb-9b99-b565e1814be5
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 09:09:12.576: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5834" for this suite.
Mar 25 09:09:34.587: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 09:09:34.656: INFO: namespace configmap-5834 deletion completed in 22.077924914s

• [SLOW TEST:26.291 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 09:09:34.657: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-8647
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1292
STEP: creating an rc
Mar 25 09:09:34.793: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 create -f - --namespace=kubectl-8647'
Mar 25 09:09:35.158: INFO: stderr: ""
Mar 25 09:09:35.158: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Waiting for Redis master to start.
Mar 25 09:09:36.162: INFO: Selector matched 1 pods for map[app:redis]
Mar 25 09:09:36.162: INFO: Found 0 / 1
Mar 25 09:09:37.161: INFO: Selector matched 1 pods for map[app:redis]
Mar 25 09:09:37.161: INFO: Found 0 / 1
Mar 25 09:09:38.162: INFO: Selector matched 1 pods for map[app:redis]
Mar 25 09:09:38.162: INFO: Found 0 / 1
Mar 25 09:09:39.161: INFO: Selector matched 1 pods for map[app:redis]
Mar 25 09:09:39.161: INFO: Found 1 / 1
Mar 25 09:09:39.161: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Mar 25 09:09:39.163: INFO: Selector matched 1 pods for map[app:redis]
Mar 25 09:09:39.163: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
STEP: checking for a matching strings
Mar 25 09:09:39.163: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 logs redis-master-sj8l5 redis-master --namespace=kubectl-8647'
Mar 25 09:09:39.241: INFO: stderr: ""
Mar 25 09:09:39.241: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 25 Mar 09:09:37.663 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 25 Mar 09:09:37.664 # Server started, Redis version 3.2.12\n1:M 25 Mar 09:09:37.664 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 25 Mar 09:09:37.664 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log lines
Mar 25 09:09:39.242: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 logs redis-master-sj8l5 redis-master --namespace=kubectl-8647 --tail=1'
Mar 25 09:09:39.315: INFO: stderr: ""
Mar 25 09:09:39.315: INFO: stdout: "1:M 25 Mar 09:09:37.664 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log bytes
Mar 25 09:09:39.315: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 logs redis-master-sj8l5 redis-master --namespace=kubectl-8647 --limit-bytes=1'
Mar 25 09:09:39.388: INFO: stderr: ""
Mar 25 09:09:39.388: INFO: stdout: " "
STEP: exposing timestamps
Mar 25 09:09:39.388: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 logs redis-master-sj8l5 redis-master --namespace=kubectl-8647 --tail=1 --timestamps'
Mar 25 09:09:39.463: INFO: stderr: ""
Mar 25 09:09:39.463: INFO: stdout: "2020-03-25T09:09:37.664460086Z 1:M 25 Mar 09:09:37.664 * The server is now ready to accept connections on port 6379\n"
STEP: restricting to a time range
Mar 25 09:09:41.963: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 logs redis-master-sj8l5 redis-master --namespace=kubectl-8647 --since=1s'
Mar 25 09:09:42.041: INFO: stderr: ""
Mar 25 09:09:42.041: INFO: stdout: ""
Mar 25 09:09:42.041: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 logs redis-master-sj8l5 redis-master --namespace=kubectl-8647 --since=24h'
Mar 25 09:09:42.117: INFO: stderr: ""
Mar 25 09:09:42.117: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 25 Mar 09:09:37.663 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 25 Mar 09:09:37.664 # Server started, Redis version 3.2.12\n1:M 25 Mar 09:09:37.664 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 25 Mar 09:09:37.664 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1298
STEP: using delete to clean up resources
Mar 25 09:09:42.117: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 delete --grace-period=0 --force -f - --namespace=kubectl-8647'
Mar 25 09:09:42.189: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar 25 09:09:42.189: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
Mar 25 09:09:42.189: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 get rc,svc -l name=nginx --no-headers --namespace=kubectl-8647'
Mar 25 09:09:42.264: INFO: stderr: "No resources found.\n"
Mar 25 09:09:42.264: INFO: stdout: ""
Mar 25 09:09:42.264: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 get pods -l name=nginx --namespace=kubectl-8647 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Mar 25 09:09:42.333: INFO: stderr: ""
Mar 25 09:09:42.333: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 09:09:42.333: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8647" for this suite.
Mar 25 09:09:48.344: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 09:09:48.413: INFO: namespace kubectl-8647 deletion completed in 6.076972531s

• [SLOW TEST:13.756 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl logs
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 09:09:48.413: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-5268
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test override all
Mar 25 09:09:48.556: INFO: Waiting up to 5m0s for pod "client-containers-7fcfc721-9661-4724-b016-f468e11b0225" in namespace "containers-5268" to be "success or failure"
Mar 25 09:09:48.561: INFO: Pod "client-containers-7fcfc721-9661-4724-b016-f468e11b0225": Phase="Pending", Reason="", readiness=false. Elapsed: 5.396822ms
Mar 25 09:09:50.564: INFO: Pod "client-containers-7fcfc721-9661-4724-b016-f468e11b0225": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008492716s
Mar 25 09:09:52.568: INFO: Pod "client-containers-7fcfc721-9661-4724-b016-f468e11b0225": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011741672s
STEP: Saw pod success
Mar 25 09:09:52.568: INFO: Pod "client-containers-7fcfc721-9661-4724-b016-f468e11b0225" satisfied condition "success or failure"
Mar 25 09:09:52.570: INFO: Trying to get logs from node ip-10-90-32-23.eu-west-2.compute.internal pod client-containers-7fcfc721-9661-4724-b016-f468e11b0225 container test-container: <nil>
STEP: delete the pod
Mar 25 09:09:52.595: INFO: Waiting for pod client-containers-7fcfc721-9661-4724-b016-f468e11b0225 to disappear
Mar 25 09:09:52.597: INFO: Pod client-containers-7fcfc721-9661-4724-b016-f468e11b0225 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 09:09:52.597: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-5268" for this suite.
Mar 25 09:09:58.619: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 09:09:58.686: INFO: namespace containers-5268 deletion completed in 6.08521176s

• [SLOW TEST:10.272 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 09:09:58.686: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-368
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Mar 25 09:10:01.398: INFO: Successfully updated pod "pod-update-df43035b-1488-4a3d-9f3c-9cc8a8cc21e0"
STEP: verifying the updated pod is in kubernetes
Mar 25 09:10:01.407: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 09:10:01.407: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-368" for this suite.
Mar 25 09:10:23.426: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 09:10:23.493: INFO: namespace pods-368 deletion completed in 22.083137383s

• [SLOW TEST:24.808 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 09:10:23.495: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-474
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-474
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace statefulset-474
STEP: Creating statefulset with conflicting port in namespace statefulset-474
STEP: Waiting until pod test-pod will start running in namespace statefulset-474
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-474
Mar 25 09:10:25.659: INFO: Observed stateful pod in namespace: statefulset-474, name: ss-0, uid: 75f92f39-e6d5-40d9-8cdd-178502930c12, status phase: Pending. Waiting for statefulset controller to delete.
Mar 25 09:10:26.049: INFO: Observed stateful pod in namespace: statefulset-474, name: ss-0, uid: 75f92f39-e6d5-40d9-8cdd-178502930c12, status phase: Failed. Waiting for statefulset controller to delete.
Mar 25 09:10:26.057: INFO: Observed stateful pod in namespace: statefulset-474, name: ss-0, uid: 75f92f39-e6d5-40d9-8cdd-178502930c12, status phase: Failed. Waiting for statefulset controller to delete.
Mar 25 09:10:26.062: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-474
STEP: Removing pod with conflicting port in namespace statefulset-474
STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-474 and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Mar 25 09:10:30.095: INFO: Deleting all statefulset in ns statefulset-474
Mar 25 09:10:30.099: INFO: Scaling statefulset ss to 0
Mar 25 09:10:40.119: INFO: Waiting for statefulset status.replicas updated to 0
Mar 25 09:10:40.121: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 09:10:40.133: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-474" for this suite.
Mar 25 09:10:46.148: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 09:10:46.215: INFO: namespace statefulset-474 deletion completed in 6.078329422s

• [SLOW TEST:22.721 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 09:10:46.216: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-6904
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
W0325 09:11:16.387765      16 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Mar 25 09:11:16.387: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 09:11:16.387: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-6904" for this suite.
Mar 25 09:11:22.398: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 09:11:22.468: INFO: namespace gc-6904 deletion completed in 6.077886223s

• [SLOW TEST:36.252 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 09:11:22.468: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-1262
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0644 on tmpfs
Mar 25 09:11:22.611: INFO: Waiting up to 5m0s for pod "pod-ce479a1b-280d-449a-98d4-9e8a591c54f4" in namespace "emptydir-1262" to be "success or failure"
Mar 25 09:11:22.615: INFO: Pod "pod-ce479a1b-280d-449a-98d4-9e8a591c54f4": Phase="Pending", Reason="", readiness=false. Elapsed: 3.65741ms
Mar 25 09:11:24.617: INFO: Pod "pod-ce479a1b-280d-449a-98d4-9e8a591c54f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005931979s
STEP: Saw pod success
Mar 25 09:11:24.617: INFO: Pod "pod-ce479a1b-280d-449a-98d4-9e8a591c54f4" satisfied condition "success or failure"
Mar 25 09:11:24.619: INFO: Trying to get logs from node ip-10-90-32-23.eu-west-2.compute.internal pod pod-ce479a1b-280d-449a-98d4-9e8a591c54f4 container test-container: <nil>
STEP: delete the pod
Mar 25 09:11:24.637: INFO: Waiting for pod pod-ce479a1b-280d-449a-98d4-9e8a591c54f4 to disappear
Mar 25 09:11:24.642: INFO: Pod pod-ce479a1b-280d-449a-98d4-9e8a591c54f4 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 09:11:24.642: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1262" for this suite.
Mar 25 09:11:30.663: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 09:11:30.733: INFO: namespace emptydir-1262 deletion completed in 6.084956427s

• [SLOW TEST:8.265 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 09:11:30.733: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-1842
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 09:12:30.924: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-1842" for this suite.
Mar 25 09:12:52.935: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 09:12:53.009: INFO: namespace container-probe-1842 deletion completed in 22.082351839s

• [SLOW TEST:82.276 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Delete Grace Period 
  should be submitted and removed [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 09:12:53.011: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-5219
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Delete Grace Period
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:47
[It] should be submitted and removed [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: setting up selector
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
Mar 25 09:12:55.170: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-563117487 proxy -p 0'
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
Mar 25 09:13:10.247: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 09:13:10.251: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-5219" for this suite.
Mar 25 09:13:16.268: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 09:13:16.342: INFO: namespace pods-5219 deletion completed in 6.08734283s

• [SLOW TEST:23.331 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  [k8s.io] Delete Grace Period
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should be submitted and removed [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 09:13:16.342: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-6964
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Mar 25 09:13:16.481: INFO: Pod name pod-release: Found 0 pods out of 1
Mar 25 09:13:21.484: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 09:13:21.501: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-6964" for this suite.
Mar 25 09:13:27.539: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 09:13:27.608: INFO: namespace replication-controller-6964 deletion completed in 6.100179982s

• [SLOW TEST:11.266 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 09:13:27.609: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5032
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with configMap that has name projected-configmap-test-upd-22577a46-e0ba-47e9-a756-322c245faffc
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-22577a46-e0ba-47e9-a756-322c245faffc
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 09:13:31.782: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5032" for this suite.
Mar 25 09:13:51.793: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 09:13:51.864: INFO: namespace projected-5032 deletion completed in 20.079361464s

• [SLOW TEST:24.256 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 09:13:51.864: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8297
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating the pod
Mar 25 09:13:54.544: INFO: Successfully updated pod "annotationupdated42774e9-4354-46f7-bbce-71c789db3ccc"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 09:13:56.557: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8297" for this suite.
Mar 25 09:14:18.568: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 09:14:18.636: INFO: namespace projected-8297 deletion completed in 22.075540241s

• [SLOW TEST:26.771 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 09:14:18.637: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-3158
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the container
STEP: wait for the container to reach Failed
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Mar 25 09:14:20.785: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 09:14:20.796: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-3158" for this suite.
Mar 25 09:14:26.807: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 09:14:26.874: INFO: namespace container-runtime-3158 deletion completed in 6.075482283s

• [SLOW TEST:8.237 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  blackbox test
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
    on terminated container
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:129
      should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 09:14:26.875: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replicaset-5561
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Mar 25 09:14:27.006: INFO: Creating ReplicaSet my-hostname-basic-0babb3f2-c5a7-4519-8ea2-f324d5afff4f
Mar 25 09:14:27.015: INFO: Pod name my-hostname-basic-0babb3f2-c5a7-4519-8ea2-f324d5afff4f: Found 0 pods out of 1
Mar 25 09:14:32.018: INFO: Pod name my-hostname-basic-0babb3f2-c5a7-4519-8ea2-f324d5afff4f: Found 1 pods out of 1
Mar 25 09:14:32.018: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-0babb3f2-c5a7-4519-8ea2-f324d5afff4f" is running
Mar 25 09:14:32.020: INFO: Pod "my-hostname-basic-0babb3f2-c5a7-4519-8ea2-f324d5afff4f-8x9jg" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-03-25 09:14:27 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-03-25 09:14:30 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-03-25 09:14:30 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-03-25 09:14:27 +0000 UTC Reason: Message:}])
Mar 25 09:14:32.020: INFO: Trying to dial the pod
Mar 25 09:14:37.030: INFO: Controller my-hostname-basic-0babb3f2-c5a7-4519-8ea2-f324d5afff4f: Got expected result from replica 1 [my-hostname-basic-0babb3f2-c5a7-4519-8ea2-f324d5afff4f-8x9jg]: "my-hostname-basic-0babb3f2-c5a7-4519-8ea2-f324d5afff4f-8x9jg", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 09:14:37.030: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-5561" for this suite.
Mar 25 09:14:43.040: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 09:14:43.134: INFO: namespace replicaset-5561 deletion completed in 6.101962517s

• [SLOW TEST:16.260 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 09:14:43.135: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-4649
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0777 on node default medium
Mar 25 09:14:43.276: INFO: Waiting up to 5m0s for pod "pod-6b892305-fd5c-40ea-a919-97e48877d33d" in namespace "emptydir-4649" to be "success or failure"
Mar 25 09:14:43.283: INFO: Pod "pod-6b892305-fd5c-40ea-a919-97e48877d33d": Phase="Pending", Reason="", readiness=false. Elapsed: 6.85978ms
Mar 25 09:14:45.285: INFO: Pod "pod-6b892305-fd5c-40ea-a919-97e48877d33d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009769497s
Mar 25 09:14:47.288: INFO: Pod "pod-6b892305-fd5c-40ea-a919-97e48877d33d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011881132s
STEP: Saw pod success
Mar 25 09:14:47.288: INFO: Pod "pod-6b892305-fd5c-40ea-a919-97e48877d33d" satisfied condition "success or failure"
Mar 25 09:14:47.289: INFO: Trying to get logs from node ip-10-90-32-23.eu-west-2.compute.internal pod pod-6b892305-fd5c-40ea-a919-97e48877d33d container test-container: <nil>
STEP: delete the pod
Mar 25 09:14:47.305: INFO: Waiting for pod pod-6b892305-fd5c-40ea-a919-97e48877d33d to disappear
Mar 25 09:14:47.308: INFO: Pod pod-6b892305-fd5c-40ea-a919-97e48877d33d no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 09:14:47.308: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4649" for this suite.
Mar 25 09:14:53.319: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 09:14:53.395: INFO: namespace emptydir-4649 deletion completed in 6.08467071s

• [SLOW TEST:10.260 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-node] ConfigMap 
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 09:14:53.396: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-2136
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap that has name configmap-test-emptyKey-5bbefe75-66c6-4ed5-ac9c-7b3990bbf72a
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 09:14:53.531: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2136" for this suite.
Mar 25 09:14:59.542: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 09:14:59.619: INFO: namespace configmap-2136 deletion completed in 6.08494569s

• [SLOW TEST:6.223 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 09:14:59.619: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-8911
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Mar 25 09:15:01.779: INFO: Expected: &{OK} to match Container's Termination Message: OK --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 09:15:01.811: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-8911" for this suite.
Mar 25 09:15:07.861: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 09:15:07.930: INFO: namespace container-runtime-8911 deletion completed in 6.097705928s

• [SLOW TEST:8.311 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  blackbox test
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
    on terminated container
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:129
      should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 09:15:07.931: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-7435
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0644 on tmpfs
Mar 25 09:15:08.071: INFO: Waiting up to 5m0s for pod "pod-ec920194-9d3b-4bfd-9f48-75fe4e5aeb50" in namespace "emptydir-7435" to be "success or failure"
Mar 25 09:15:08.075: INFO: Pod "pod-ec920194-9d3b-4bfd-9f48-75fe4e5aeb50": Phase="Pending", Reason="", readiness=false. Elapsed: 4.089317ms
Mar 25 09:15:10.078: INFO: Pod "pod-ec920194-9d3b-4bfd-9f48-75fe4e5aeb50": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007043236s
STEP: Saw pod success
Mar 25 09:15:10.078: INFO: Pod "pod-ec920194-9d3b-4bfd-9f48-75fe4e5aeb50" satisfied condition "success or failure"
Mar 25 09:15:10.081: INFO: Trying to get logs from node ip-10-90-32-23.eu-west-2.compute.internal pod pod-ec920194-9d3b-4bfd-9f48-75fe4e5aeb50 container test-container: <nil>
STEP: delete the pod
Mar 25 09:15:10.096: INFO: Waiting for pod pod-ec920194-9d3b-4bfd-9f48-75fe4e5aeb50 to disappear
Mar 25 09:15:10.098: INFO: Pod pod-ec920194-9d3b-4bfd-9f48-75fe4e5aeb50 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 09:15:10.098: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7435" for this suite.
Mar 25 09:15:16.111: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 09:15:16.179: INFO: namespace emptydir-7435 deletion completed in 6.078353693s

• [SLOW TEST:8.249 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 09:15:16.179: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-8297
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Mar 25 09:15:16.311: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 09:15:18.402: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-8297" for this suite.
Mar 25 09:15:56.413: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 09:15:56.487: INFO: namespace pods-8297 deletion completed in 38.081433209s

• [SLOW TEST:40.307 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 09:15:56.487: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-8885
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Mar 25 09:16:22.646: INFO: Container started at 2020-03-25 09:15:57 +0000 UTC, pod became ready at 2020-03-25 09:16:20 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 09:16:22.646: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-8885" for this suite.
Mar 25 09:16:44.658: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 09:16:44.729: INFO: namespace container-probe-8885 deletion completed in 22.079681931s

• [SLOW TEST:48.242 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 09:16:44.730: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-8509
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Performing setup for networking test in namespace pod-network-test-8509
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Mar 25 09:16:44.860: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Mar 25 09:17:10.941: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.200.33.18:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-8509 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 25 09:17:10.941: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
Mar 25 09:17:11.035: INFO: Found all expected endpoints: [netserver-0]
Mar 25 09:17:11.038: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.200.96.44:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-8509 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 25 09:17:11.038: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
Mar 25 09:17:11.141: INFO: Found all expected endpoints: [netserver-1]
Mar 25 09:17:11.144: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.200.90.12:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-8509 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 25 09:17:11.144: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
Mar 25 09:17:11.242: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 09:17:11.242: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-8509" for this suite.
Mar 25 09:17:33.255: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 09:17:33.322: INFO: namespace pod-network-test-8509 deletion completed in 22.077045014s

• [SLOW TEST:48.592 seconds]
[sig-network] Networking
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 09:17:33.322: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-9850
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test env composition
Mar 25 09:17:33.459: INFO: Waiting up to 5m0s for pod "var-expansion-42004806-7a4e-4862-a884-af943e0a2d49" in namespace "var-expansion-9850" to be "success or failure"
Mar 25 09:17:33.463: INFO: Pod "var-expansion-42004806-7a4e-4862-a884-af943e0a2d49": Phase="Pending", Reason="", readiness=false. Elapsed: 4.085532ms
Mar 25 09:17:35.466: INFO: Pod "var-expansion-42004806-7a4e-4862-a884-af943e0a2d49": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007001042s
STEP: Saw pod success
Mar 25 09:17:35.466: INFO: Pod "var-expansion-42004806-7a4e-4862-a884-af943e0a2d49" satisfied condition "success or failure"
Mar 25 09:17:35.468: INFO: Trying to get logs from node ip-10-90-32-23.eu-west-2.compute.internal pod var-expansion-42004806-7a4e-4862-a884-af943e0a2d49 container dapi-container: <nil>
STEP: delete the pod
Mar 25 09:17:35.492: INFO: Waiting for pod var-expansion-42004806-7a4e-4862-a884-af943e0a2d49 to disappear
Mar 25 09:17:35.494: INFO: Pod var-expansion-42004806-7a4e-4862-a884-af943e0a2d49 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 09:17:35.494: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-9850" for this suite.
Mar 25 09:17:41.507: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 09:17:41.570: INFO: namespace var-expansion-9850 deletion completed in 6.073363724s

• [SLOW TEST:8.248 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 09:17:41.570: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-6543
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1516
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Mar 25 09:17:41.701: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=kubectl-6543'
Mar 25 09:17:41.773: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Mar 25 09:17:41.773: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
Mar 25 09:17:41.790: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 1 spec.replicas 1 status.replicas 0
STEP: rolling-update to same image controller
Mar 25 09:17:41.794: INFO: scanned /root for discovery docs: <nil>
Mar 25 09:17:41.794: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 rolling-update e2e-test-nginx-rc --update-period=1s --image=docker.io/library/nginx:1.14-alpine --image-pull-policy=IfNotPresent --namespace=kubectl-6543'
Mar 25 09:17:57.571: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Mar 25 09:17:57.571: INFO: stdout: "Created e2e-test-nginx-rc-e4433abd20ac28bd6445fca06fb70dc1\nScaling up e2e-test-nginx-rc-e4433abd20ac28bd6445fca06fb70dc1 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-e4433abd20ac28bd6445fca06fb70dc1 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-e4433abd20ac28bd6445fca06fb70dc1 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
Mar 25 09:17:57.571: INFO: stdout: "Created e2e-test-nginx-rc-e4433abd20ac28bd6445fca06fb70dc1\nScaling up e2e-test-nginx-rc-e4433abd20ac28bd6445fca06fb70dc1 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-e4433abd20ac28bd6445fca06fb70dc1 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-e4433abd20ac28bd6445fca06fb70dc1 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
Mar 25 09:17:57.571: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=kubectl-6543'
Mar 25 09:17:57.638: INFO: stderr: ""
Mar 25 09:17:57.638: INFO: stdout: "e2e-test-nginx-rc-e4433abd20ac28bd6445fca06fb70dc1-zvzfv "
Mar 25 09:17:57.638: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 get pods e2e-test-nginx-rc-e4433abd20ac28bd6445fca06fb70dc1-zvzfv -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6543'
Mar 25 09:17:57.704: INFO: stderr: ""
Mar 25 09:17:57.704: INFO: stdout: "true"
Mar 25 09:17:57.704: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 get pods e2e-test-nginx-rc-e4433abd20ac28bd6445fca06fb70dc1-zvzfv -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-6543'
Mar 25 09:17:57.772: INFO: stderr: ""
Mar 25 09:17:57.772: INFO: stdout: "docker.io/library/nginx:1.14-alpine"
Mar 25 09:17:57.772: INFO: e2e-test-nginx-rc-e4433abd20ac28bd6445fca06fb70dc1-zvzfv is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1522
Mar 25 09:17:57.772: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 delete rc e2e-test-nginx-rc --namespace=kubectl-6543'
Mar 25 09:17:57.844: INFO: stderr: ""
Mar 25 09:17:57.844: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 09:17:57.844: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6543" for this suite.
Mar 25 09:18:19.864: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 09:18:19.930: INFO: namespace kubectl-6543 deletion completed in 22.079620819s

• [SLOW TEST:38.360 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 09:18:19.930: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-4050
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name secret-emptykey-test-4a2e4320-8ff8-437c-8e1d-59deab15d200
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 09:18:20.113: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-4050" for this suite.
Mar 25 09:18:26.125: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 09:18:26.195: INFO: namespace secrets-4050 deletion completed in 6.07900002s

• [SLOW TEST:6.265 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 09:18:26.195: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-3186
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Mar 25 09:18:28.360: INFO: Waiting up to 5m0s for pod "client-envvars-1f04b047-8156-4077-b94b-632e4a93551d" in namespace "pods-3186" to be "success or failure"
Mar 25 09:18:28.363: INFO: Pod "client-envvars-1f04b047-8156-4077-b94b-632e4a93551d": Phase="Pending", Reason="", readiness=false. Elapsed: 3.685082ms
Mar 25 09:18:30.367: INFO: Pod "client-envvars-1f04b047-8156-4077-b94b-632e4a93551d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006811061s
STEP: Saw pod success
Mar 25 09:18:30.367: INFO: Pod "client-envvars-1f04b047-8156-4077-b94b-632e4a93551d" satisfied condition "success or failure"
Mar 25 09:18:30.368: INFO: Trying to get logs from node ip-10-90-32-23.eu-west-2.compute.internal pod client-envvars-1f04b047-8156-4077-b94b-632e4a93551d container env3cont: <nil>
STEP: delete the pod
Mar 25 09:18:30.383: INFO: Waiting for pod client-envvars-1f04b047-8156-4077-b94b-632e4a93551d to disappear
Mar 25 09:18:30.385: INFO: Pod client-envvars-1f04b047-8156-4077-b94b-632e4a93551d no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 09:18:30.385: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-3186" for this suite.
Mar 25 09:19:08.397: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 09:19:08.470: INFO: namespace pods-3186 deletion completed in 38.081982111s

• [SLOW TEST:42.275 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 09:19:08.473: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-9201
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-projected-nww6
STEP: Creating a pod to test atomic-volume-subpath
Mar 25 09:19:08.619: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-nww6" in namespace "subpath-9201" to be "success or failure"
Mar 25 09:19:08.622: INFO: Pod "pod-subpath-test-projected-nww6": Phase="Pending", Reason="", readiness=false. Elapsed: 3.61479ms
Mar 25 09:19:10.625: INFO: Pod "pod-subpath-test-projected-nww6": Phase="Running", Reason="", readiness=true. Elapsed: 2.006591951s
Mar 25 09:19:12.628: INFO: Pod "pod-subpath-test-projected-nww6": Phase="Running", Reason="", readiness=true. Elapsed: 4.009633642s
Mar 25 09:19:14.631: INFO: Pod "pod-subpath-test-projected-nww6": Phase="Running", Reason="", readiness=true. Elapsed: 6.012738834s
Mar 25 09:19:16.635: INFO: Pod "pod-subpath-test-projected-nww6": Phase="Running", Reason="", readiness=true. Elapsed: 8.016151747s
Mar 25 09:19:18.638: INFO: Pod "pod-subpath-test-projected-nww6": Phase="Running", Reason="", readiness=true. Elapsed: 10.018961813s
Mar 25 09:19:20.641: INFO: Pod "pod-subpath-test-projected-nww6": Phase="Running", Reason="", readiness=true. Elapsed: 12.022003214s
Mar 25 09:19:22.644: INFO: Pod "pod-subpath-test-projected-nww6": Phase="Running", Reason="", readiness=true. Elapsed: 14.025074894s
Mar 25 09:19:24.647: INFO: Pod "pod-subpath-test-projected-nww6": Phase="Running", Reason="", readiness=true. Elapsed: 16.027979432s
Mar 25 09:19:26.650: INFO: Pod "pod-subpath-test-projected-nww6": Phase="Running", Reason="", readiness=true. Elapsed: 18.030975068s
Mar 25 09:19:28.653: INFO: Pod "pod-subpath-test-projected-nww6": Phase="Running", Reason="", readiness=true. Elapsed: 20.033948787s
Mar 25 09:19:30.656: INFO: Pod "pod-subpath-test-projected-nww6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.036956439s
STEP: Saw pod success
Mar 25 09:19:30.656: INFO: Pod "pod-subpath-test-projected-nww6" satisfied condition "success or failure"
Mar 25 09:19:30.657: INFO: Trying to get logs from node ip-10-90-32-23.eu-west-2.compute.internal pod pod-subpath-test-projected-nww6 container test-container-subpath-projected-nww6: <nil>
STEP: delete the pod
Mar 25 09:19:30.674: INFO: Waiting for pod pod-subpath-test-projected-nww6 to disappear
Mar 25 09:19:30.676: INFO: Pod pod-subpath-test-projected-nww6 no longer exists
STEP: Deleting pod pod-subpath-test-projected-nww6
Mar 25 09:19:30.676: INFO: Deleting pod "pod-subpath-test-projected-nww6" in namespace "subpath-9201"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 09:19:30.678: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-9201" for this suite.
Mar 25 09:19:36.691: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 09:19:36.757: INFO: namespace subpath-9201 deletion completed in 6.074079636s

• [SLOW TEST:28.284 seconds]
[sig-storage] Subpath
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with projected pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 09:19:36.757: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7010
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-eab2e0eb-0048-4745-9312-838815cea56e
STEP: Creating a pod to test consume configMaps
Mar 25 09:19:36.896: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-53dd57f2-f570-447c-ac57-719191b1056f" in namespace "projected-7010" to be "success or failure"
Mar 25 09:19:36.903: INFO: Pod "pod-projected-configmaps-53dd57f2-f570-447c-ac57-719191b1056f": Phase="Pending", Reason="", readiness=false. Elapsed: 6.965026ms
Mar 25 09:19:38.906: INFO: Pod "pod-projected-configmaps-53dd57f2-f570-447c-ac57-719191b1056f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00995515s
STEP: Saw pod success
Mar 25 09:19:38.907: INFO: Pod "pod-projected-configmaps-53dd57f2-f570-447c-ac57-719191b1056f" satisfied condition "success or failure"
Mar 25 09:19:38.908: INFO: Trying to get logs from node ip-10-90-32-23.eu-west-2.compute.internal pod pod-projected-configmaps-53dd57f2-f570-447c-ac57-719191b1056f container projected-configmap-volume-test: <nil>
STEP: delete the pod
Mar 25 09:19:38.924: INFO: Waiting for pod pod-projected-configmaps-53dd57f2-f570-447c-ac57-719191b1056f to disappear
Mar 25 09:19:38.925: INFO: Pod pod-projected-configmaps-53dd57f2-f570-447c-ac57-719191b1056f no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 09:19:38.925: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7010" for this suite.
Mar 25 09:19:44.939: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 09:19:45.005: INFO: namespace projected-7010 deletion completed in 6.077458824s

• [SLOW TEST:8.249 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 09:19:45.006: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-1253
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating Redis RC
Mar 25 09:19:45.139: INFO: namespace kubectl-1253
Mar 25 09:19:45.139: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 create -f - --namespace=kubectl-1253'
Mar 25 09:19:45.449: INFO: stderr: ""
Mar 25 09:19:45.449: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Mar 25 09:19:46.452: INFO: Selector matched 1 pods for map[app:redis]
Mar 25 09:19:46.453: INFO: Found 0 / 1
Mar 25 09:19:47.452: INFO: Selector matched 1 pods for map[app:redis]
Mar 25 09:19:47.452: INFO: Found 1 / 1
Mar 25 09:19:47.452: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Mar 25 09:19:47.455: INFO: Selector matched 1 pods for map[app:redis]
Mar 25 09:19:47.455: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Mar 25 09:19:47.455: INFO: wait on redis-master startup in kubectl-1253 
Mar 25 09:19:47.455: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 logs redis-master-qfrfz redis-master --namespace=kubectl-1253'
Mar 25 09:19:47.555: INFO: stderr: ""
Mar 25 09:19:47.555: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 25 Mar 09:19:46.513 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 25 Mar 09:19:46.513 # Server started, Redis version 3.2.12\n1:M 25 Mar 09:19:46.513 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 25 Mar 09:19:46.513 * The server is now ready to accept connections on port 6379\n"
STEP: exposing RC
Mar 25 09:19:47.555: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=kubectl-1253'
Mar 25 09:19:47.637: INFO: stderr: ""
Mar 25 09:19:47.637: INFO: stdout: "service/rm2 exposed\n"
Mar 25 09:19:47.641: INFO: Service rm2 in namespace kubectl-1253 found.
STEP: exposing service
Mar 25 09:19:49.660: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=kubectl-1253'
Mar 25 09:19:49.743: INFO: stderr: ""
Mar 25 09:19:49.743: INFO: stdout: "service/rm3 exposed\n"
Mar 25 09:19:49.752: INFO: Service rm3 in namespace kubectl-1253 found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 09:19:51.757: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1253" for this suite.
Mar 25 09:20:13.783: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 09:20:13.854: INFO: namespace kubectl-1253 deletion completed in 22.090372044s

• [SLOW TEST:28.848 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl expose
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create services for rc  [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 09:20:13.854: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-6374
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap configmap-6374/configmap-test-0b5718b4-e673-42db-ae8b-675d1a825393
STEP: Creating a pod to test consume configMaps
Mar 25 09:20:13.995: INFO: Waiting up to 5m0s for pod "pod-configmaps-c2220e11-5895-4b0c-b9e2-fac235095331" in namespace "configmap-6374" to be "success or failure"
Mar 25 09:20:14.001: INFO: Pod "pod-configmaps-c2220e11-5895-4b0c-b9e2-fac235095331": Phase="Pending", Reason="", readiness=false. Elapsed: 6.506571ms
Mar 25 09:20:16.004: INFO: Pod "pod-configmaps-c2220e11-5895-4b0c-b9e2-fac235095331": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009447145s
Mar 25 09:20:18.007: INFO: Pod "pod-configmaps-c2220e11-5895-4b0c-b9e2-fac235095331": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012436006s
STEP: Saw pod success
Mar 25 09:20:18.007: INFO: Pod "pod-configmaps-c2220e11-5895-4b0c-b9e2-fac235095331" satisfied condition "success or failure"
Mar 25 09:20:18.009: INFO: Trying to get logs from node ip-10-90-32-23.eu-west-2.compute.internal pod pod-configmaps-c2220e11-5895-4b0c-b9e2-fac235095331 container env-test: <nil>
STEP: delete the pod
Mar 25 09:20:18.025: INFO: Waiting for pod pod-configmaps-c2220e11-5895-4b0c-b9e2-fac235095331 to disappear
Mar 25 09:20:18.028: INFO: Pod pod-configmaps-c2220e11-5895-4b0c-b9e2-fac235095331 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 09:20:18.028: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6374" for this suite.
Mar 25 09:20:24.062: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 09:20:24.133: INFO: namespace configmap-6374 deletion completed in 6.094355151s

• [SLOW TEST:10.279 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 09:20:24.133: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2347
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name cm-test-opt-del-9687670c-2194-41ee-ba8d-f4f48e643874
STEP: Creating configMap with name cm-test-opt-upd-42862c6a-460b-4580-b981-ad4c29579852
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-9687670c-2194-41ee-ba8d-f4f48e643874
STEP: Updating configmap cm-test-opt-upd-42862c6a-460b-4580-b981-ad4c29579852
STEP: Creating configMap with name cm-test-opt-create-f34adf96-402d-44c3-a9ac-b7cac0cc075e
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 09:20:28.356: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2347" for this suite.
Mar 25 09:20:50.367: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 09:20:50.434: INFO: namespace projected-2347 deletion completed in 22.075597895s

• [SLOW TEST:26.301 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 09:20:50.435: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-4468
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-upd-4df1512a-3932-4402-a4ab-39f960b1742d
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-4df1512a-3932-4402-a4ab-39f960b1742d
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 09:20:54.632: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4468" for this suite.
Mar 25 09:21:16.643: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 09:21:16.712: INFO: namespace configmap-4468 deletion completed in 22.077244442s

• [SLOW TEST:26.277 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 09:21:16.713: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-6212
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
Mar 25 09:21:16.844: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 09:21:19.688: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-6212" for this suite.
Mar 25 09:21:25.705: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 09:21:25.769: INFO: namespace init-container-6212 deletion completed in 6.076422462s

• [SLOW TEST:9.056 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 09:21:25.769: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-8164
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Performing setup for networking test in namespace pod-network-test-8164
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Mar 25 09:21:25.898: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Mar 25 09:21:49.977: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.200.96.58:8080/dial?request=hostName&protocol=http&host=10.200.33.19&port=8080&tries=1'] Namespace:pod-network-test-8164 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 25 09:21:49.977: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
Mar 25 09:21:50.080: INFO: Waiting for endpoints: map[]
Mar 25 09:21:50.082: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.200.96.58:8080/dial?request=hostName&protocol=http&host=10.200.90.14&port=8080&tries=1'] Namespace:pod-network-test-8164 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 25 09:21:50.082: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
Mar 25 09:21:50.181: INFO: Waiting for endpoints: map[]
Mar 25 09:21:50.183: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.200.96.58:8080/dial?request=hostName&protocol=http&host=10.200.96.57&port=8080&tries=1'] Namespace:pod-network-test-8164 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 25 09:21:50.183: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
Mar 25 09:21:50.286: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 09:21:50.287: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-8164" for this suite.
Mar 25 09:22:12.298: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 09:22:12.364: INFO: namespace pod-network-test-8164 deletion completed in 22.074503234s

• [SLOW TEST:46.595 seconds]
[sig-network] Networking
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 09:22:12.365: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-9572
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Mar 25 09:22:12.501: INFO: Waiting up to 5m0s for pod "downwardapi-volume-049e451a-57ca-4e12-b2ef-51daca01680c" in namespace "downward-api-9572" to be "success or failure"
Mar 25 09:22:12.508: INFO: Pod "downwardapi-volume-049e451a-57ca-4e12-b2ef-51daca01680c": Phase="Pending", Reason="", readiness=false. Elapsed: 6.639516ms
Mar 25 09:22:14.511: INFO: Pod "downwardapi-volume-049e451a-57ca-4e12-b2ef-51daca01680c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009287634s
STEP: Saw pod success
Mar 25 09:22:14.511: INFO: Pod "downwardapi-volume-049e451a-57ca-4e12-b2ef-51daca01680c" satisfied condition "success or failure"
Mar 25 09:22:14.513: INFO: Trying to get logs from node ip-10-90-32-23.eu-west-2.compute.internal pod downwardapi-volume-049e451a-57ca-4e12-b2ef-51daca01680c container client-container: <nil>
STEP: delete the pod
Mar 25 09:22:14.528: INFO: Waiting for pod downwardapi-volume-049e451a-57ca-4e12-b2ef-51daca01680c to disappear
Mar 25 09:22:14.530: INFO: Pod downwardapi-volume-049e451a-57ca-4e12-b2ef-51daca01680c no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 09:22:14.530: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9572" for this suite.
Mar 25 09:22:20.541: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 09:22:20.610: INFO: namespace downward-api-9572 deletion completed in 6.076840386s

• [SLOW TEST:8.245 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 09:22:20.610: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename hostpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in hostpath-9271
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test hostPath mode
Mar 25 09:22:20.748: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "hostpath-9271" to be "success or failure"
Mar 25 09:22:20.752: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 4.006441ms
Mar 25 09:22:22.755: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006990879s
Mar 25 09:22:24.761: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013104474s
STEP: Saw pod success
Mar 25 09:22:24.761: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Mar 25 09:22:24.763: INFO: Trying to get logs from node ip-10-90-32-22.eu-west-2.compute.internal pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Mar 25 09:22:24.785: INFO: Waiting for pod pod-host-path-test to disappear
Mar 25 09:22:24.787: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 09:22:24.787: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "hostpath-9271" for this suite.
Mar 25 09:22:30.799: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 09:22:30.868: INFO: namespace hostpath-9271 deletion completed in 6.077988568s

• [SLOW TEST:10.257 seconds]
[sig-storage] HostPath
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 09:22:30.868: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-5606
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
Mar 25 09:22:41.059: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W0325 09:22:41.058991      16 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 09:22:41.059: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-5606" for this suite.
Mar 25 09:22:47.070: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 09:22:47.138: INFO: namespace gc-5606 deletion completed in 6.076326961s

• [SLOW TEST:16.270 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 09:22:47.138: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-8051
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Mar 25 09:22:47.285: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Mar 25 09:22:47.300: INFO: Number of nodes with available pods: 0
Mar 25 09:22:47.300: INFO: Node ip-10-90-32-22.eu-west-2.compute.internal is running more than one daemon pod
Mar 25 09:22:48.323: INFO: Number of nodes with available pods: 0
Mar 25 09:22:48.324: INFO: Node ip-10-90-32-22.eu-west-2.compute.internal is running more than one daemon pod
Mar 25 09:22:49.313: INFO: Number of nodes with available pods: 3
Mar 25 09:22:49.313: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Mar 25 09:22:49.364: INFO: Wrong image for pod: daemon-set-2h68r. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Mar 25 09:22:49.364: INFO: Wrong image for pod: daemon-set-7mscx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Mar 25 09:22:49.364: INFO: Wrong image for pod: daemon-set-8m86m. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Mar 25 09:22:50.373: INFO: Wrong image for pod: daemon-set-2h68r. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Mar 25 09:22:50.373: INFO: Wrong image for pod: daemon-set-7mscx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Mar 25 09:22:50.373: INFO: Wrong image for pod: daemon-set-8m86m. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Mar 25 09:22:51.373: INFO: Wrong image for pod: daemon-set-2h68r. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Mar 25 09:22:51.373: INFO: Wrong image for pod: daemon-set-7mscx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Mar 25 09:22:51.373: INFO: Wrong image for pod: daemon-set-8m86m. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Mar 25 09:22:52.376: INFO: Wrong image for pod: daemon-set-2h68r. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Mar 25 09:22:52.376: INFO: Wrong image for pod: daemon-set-7mscx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Mar 25 09:22:52.376: INFO: Wrong image for pod: daemon-set-8m86m. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Mar 25 09:22:52.376: INFO: Pod daemon-set-8m86m is not available
Mar 25 09:22:53.373: INFO: Wrong image for pod: daemon-set-2h68r. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Mar 25 09:22:53.373: INFO: Wrong image for pod: daemon-set-7mscx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Mar 25 09:22:53.373: INFO: Wrong image for pod: daemon-set-8m86m. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Mar 25 09:22:53.373: INFO: Pod daemon-set-8m86m is not available
Mar 25 09:22:54.373: INFO: Wrong image for pod: daemon-set-2h68r. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Mar 25 09:22:54.373: INFO: Wrong image for pod: daemon-set-7mscx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Mar 25 09:22:54.373: INFO: Wrong image for pod: daemon-set-8m86m. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Mar 25 09:22:54.373: INFO: Pod daemon-set-8m86m is not available
Mar 25 09:22:55.375: INFO: Wrong image for pod: daemon-set-2h68r. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Mar 25 09:22:55.375: INFO: Wrong image for pod: daemon-set-7mscx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Mar 25 09:22:55.375: INFO: Wrong image for pod: daemon-set-8m86m. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Mar 25 09:22:55.375: INFO: Pod daemon-set-8m86m is not available
Mar 25 09:22:56.373: INFO: Wrong image for pod: daemon-set-2h68r. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Mar 25 09:22:56.373: INFO: Wrong image for pod: daemon-set-7mscx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Mar 25 09:22:56.373: INFO: Wrong image for pod: daemon-set-8m86m. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Mar 25 09:22:56.373: INFO: Pod daemon-set-8m86m is not available
Mar 25 09:22:57.372: INFO: Wrong image for pod: daemon-set-2h68r. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Mar 25 09:22:57.372: INFO: Wrong image for pod: daemon-set-7mscx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Mar 25 09:22:57.372: INFO: Wrong image for pod: daemon-set-8m86m. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Mar 25 09:22:57.372: INFO: Pod daemon-set-8m86m is not available
Mar 25 09:22:58.373: INFO: Wrong image for pod: daemon-set-2h68r. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Mar 25 09:22:58.373: INFO: Wrong image for pod: daemon-set-7mscx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Mar 25 09:22:58.373: INFO: Wrong image for pod: daemon-set-8m86m. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Mar 25 09:22:58.373: INFO: Pod daemon-set-8m86m is not available
Mar 25 09:22:59.373: INFO: Wrong image for pod: daemon-set-2h68r. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Mar 25 09:22:59.373: INFO: Wrong image for pod: daemon-set-7mscx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Mar 25 09:22:59.373: INFO: Wrong image for pod: daemon-set-8m86m. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Mar 25 09:22:59.373: INFO: Pod daemon-set-8m86m is not available
Mar 25 09:23:00.373: INFO: Wrong image for pod: daemon-set-2h68r. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Mar 25 09:23:00.373: INFO: Wrong image for pod: daemon-set-7mscx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Mar 25 09:23:00.373: INFO: Pod daemon-set-z5vzk is not available
Mar 25 09:23:01.373: INFO: Wrong image for pod: daemon-set-2h68r. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Mar 25 09:23:01.373: INFO: Wrong image for pod: daemon-set-7mscx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Mar 25 09:23:01.373: INFO: Pod daemon-set-z5vzk is not available
Mar 25 09:23:02.373: INFO: Wrong image for pod: daemon-set-2h68r. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Mar 25 09:23:02.373: INFO: Wrong image for pod: daemon-set-7mscx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Mar 25 09:23:03.373: INFO: Wrong image for pod: daemon-set-2h68r. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Mar 25 09:23:03.373: INFO: Pod daemon-set-2h68r is not available
Mar 25 09:23:03.373: INFO: Wrong image for pod: daemon-set-7mscx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Mar 25 09:23:04.373: INFO: Wrong image for pod: daemon-set-7mscx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Mar 25 09:23:04.373: INFO: Pod daemon-set-k5c6b is not available
Mar 25 09:23:05.373: INFO: Wrong image for pod: daemon-set-7mscx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Mar 25 09:23:05.373: INFO: Pod daemon-set-k5c6b is not available
Mar 25 09:23:06.373: INFO: Wrong image for pod: daemon-set-7mscx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Mar 25 09:23:06.373: INFO: Pod daemon-set-k5c6b is not available
Mar 25 09:23:07.372: INFO: Wrong image for pod: daemon-set-7mscx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Mar 25 09:23:07.372: INFO: Pod daemon-set-7mscx is not available
Mar 25 09:23:08.373: INFO: Wrong image for pod: daemon-set-7mscx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Mar 25 09:23:08.373: INFO: Pod daemon-set-7mscx is not available
Mar 25 09:23:09.373: INFO: Wrong image for pod: daemon-set-7mscx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Mar 25 09:23:09.373: INFO: Pod daemon-set-7mscx is not available
Mar 25 09:23:10.373: INFO: Wrong image for pod: daemon-set-7mscx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Mar 25 09:23:10.373: INFO: Pod daemon-set-7mscx is not available
Mar 25 09:23:11.373: INFO: Wrong image for pod: daemon-set-7mscx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Mar 25 09:23:11.373: INFO: Pod daemon-set-7mscx is not available
Mar 25 09:23:12.373: INFO: Wrong image for pod: daemon-set-7mscx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Mar 25 09:23:12.373: INFO: Pod daemon-set-7mscx is not available
Mar 25 09:23:13.373: INFO: Wrong image for pod: daemon-set-7mscx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Mar 25 09:23:13.373: INFO: Pod daemon-set-7mscx is not available
Mar 25 09:23:14.374: INFO: Wrong image for pod: daemon-set-7mscx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Mar 25 09:23:14.374: INFO: Pod daemon-set-7mscx is not available
Mar 25 09:23:15.373: INFO: Wrong image for pod: daemon-set-7mscx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Mar 25 09:23:15.373: INFO: Pod daemon-set-7mscx is not available
Mar 25 09:23:16.373: INFO: Wrong image for pod: daemon-set-7mscx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Mar 25 09:23:16.373: INFO: Pod daemon-set-7mscx is not available
Mar 25 09:23:17.373: INFO: Pod daemon-set-cvlfj is not available
STEP: Check that daemon pods are still running on every node of the cluster.
Mar 25 09:23:17.382: INFO: Number of nodes with available pods: 2
Mar 25 09:23:17.382: INFO: Node ip-10-90-32-23.eu-west-2.compute.internal is running more than one daemon pod
Mar 25 09:23:18.388: INFO: Number of nodes with available pods: 2
Mar 25 09:23:18.388: INFO: Node ip-10-90-32-23.eu-west-2.compute.internal is running more than one daemon pod
Mar 25 09:23:19.399: INFO: Number of nodes with available pods: 3
Mar 25 09:23:19.399: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-8051, will wait for the garbage collector to delete the pods
Mar 25 09:23:19.499: INFO: Deleting DaemonSet.extensions daemon-set took: 17.890645ms
Mar 25 09:23:19.799: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.222561ms
Mar 25 09:23:26.802: INFO: Number of nodes with available pods: 0
Mar 25 09:23:26.802: INFO: Number of running nodes: 0, number of available pods: 0
Mar 25 09:23:26.803: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-8051/daemonsets","resourceVersion":"335041"},"items":null}

Mar 25 09:23:26.805: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-8051/pods","resourceVersion":"335041"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 09:23:26.813: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-8051" for this suite.
Mar 25 09:23:32.825: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 09:23:32.892: INFO: namespace daemonsets-8051 deletion completed in 6.076347383s

• [SLOW TEST:45.754 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 09:23:32.892: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in namespaces-1160
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-3023
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-997
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 09:23:51.308: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-1160" for this suite.
Mar 25 09:23:57.319: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 09:23:57.391: INFO: namespace namespaces-1160 deletion completed in 6.08054373s
STEP: Destroying namespace "nsdeletetest-3023" for this suite.
Mar 25 09:23:57.393: INFO: Namespace nsdeletetest-3023 was already deleted
STEP: Destroying namespace "nsdeletetest-997" for this suite.
Mar 25 09:24:03.402: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 09:24:03.477: INFO: namespace nsdeletetest-997 deletion completed in 6.083729672s

• [SLOW TEST:30.584 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 09:24:03.477: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-7395
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 09:24:03.617: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-7395" for this suite.
Mar 25 09:24:09.630: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 09:24:09.705: INFO: namespace services-7395 deletion completed in 6.085090537s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:92

• [SLOW TEST:6.229 seconds]
[sig-network] Services
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide secure master service  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 09:24:09.706: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-5228
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:81
Mar 25 09:24:09.838: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Mar 25 09:24:09.844: INFO: Waiting for terminating namespaces to be deleted...
Mar 25 09:24:09.846: INFO: 
Logging pods the kubelet thinks is on node ip-10-90-32-22.eu-west-2.compute.internal before test
Mar 25 09:24:09.850: INFO: traefik-ingress-controller-d8npl from traefik-ingress started at 2020-03-23 09:01:47 +0000 UTC (1 container statuses recorded)
Mar 25 09:24:09.850: INFO: 	Container traefik-ingress-lb ready: true, restart count 0
Mar 25 09:24:09.850: INFO: kubernetes-dashboard-84ffbc8546-bph6j from kube-system started at 2020-03-23 08:46:30 +0000 UTC (1 container statuses recorded)
Mar 25 09:24:09.850: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Mar 25 09:24:09.850: INFO: sonobuoy-systemd-logs-daemon-set-881e638473c24530-zhx7s from heptio-sonobuoy started at 2020-03-25 08:52:11 +0000 UTC (2 container statuses recorded)
Mar 25 09:24:09.850: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar 25 09:24:09.850: INFO: 	Container systemd-logs ready: true, restart count 0
Mar 25 09:24:09.850: INFO: filebeat-rfcxf from kube-system started at 2020-03-23 08:46:09 +0000 UTC (1 container statuses recorded)
Mar 25 09:24:09.850: INFO: 	Container filebeat ready: true, restart count 0
Mar 25 09:24:09.850: INFO: sonobuoy from heptio-sonobuoy started at 2020-03-25 08:52:05 +0000 UTC (1 container statuses recorded)
Mar 25 09:24:09.850: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Mar 25 09:24:09.850: INFO: coredns-84c98f9bb6-jtxmm from kube-system started at 2020-03-23 08:59:43 +0000 UTC (1 container statuses recorded)
Mar 25 09:24:09.850: INFO: 	Container coredns ready: true, restart count 0
Mar 25 09:24:09.850: INFO: 
Logging pods the kubelet thinks is on node ip-10-90-32-23.eu-west-2.compute.internal before test
Mar 25 09:24:09.855: INFO: filebeat-4w76v from kube-system started at 2020-03-23 08:49:56 +0000 UTC (1 container statuses recorded)
Mar 25 09:24:09.856: INFO: 	Container filebeat ready: true, restart count 0
Mar 25 09:24:09.856: INFO: traefik-ingress-controller-nwxk9 from traefik-ingress started at 2020-03-23 09:01:51 +0000 UTC (1 container statuses recorded)
Mar 25 09:24:09.856: INFO: 	Container traefik-ingress-lb ready: true, restart count 0
Mar 25 09:24:09.856: INFO: coredns-84c98f9bb6-jw9th from kube-system started at 2020-03-23 08:59:41 +0000 UTC (1 container statuses recorded)
Mar 25 09:24:09.856: INFO: 	Container coredns ready: true, restart count 0
Mar 25 09:24:09.856: INFO: sonobuoy-systemd-logs-daemon-set-881e638473c24530-4r6qn from heptio-sonobuoy started at 2020-03-25 08:52:11 +0000 UTC (2 container statuses recorded)
Mar 25 09:24:09.856: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar 25 09:24:09.856: INFO: 	Container systemd-logs ready: true, restart count 0
Mar 25 09:24:09.856: INFO: nginx-7db9fccd9b-w4mt2 from miro started at 2020-03-23 08:50:25 +0000 UTC (1 container statuses recorded)
Mar 25 09:24:09.856: INFO: 	Container nginx ready: true, restart count 0
Mar 25 09:24:09.856: INFO: 
Logging pods the kubelet thinks is on node ip-10-90-32-24.eu-west-2.compute.internal before test
Mar 25 09:24:09.869: INFO: traefik-ingress-controller-8wz6n from traefik-ingress started at 2020-03-23 09:01:43 +0000 UTC (1 container statuses recorded)
Mar 25 09:24:09.869: INFO: 	Container traefik-ingress-lb ready: true, restart count 0
Mar 25 09:24:09.869: INFO: metrics-server-5998746b76-qchjq from kube-system started at 2020-03-23 08:59:45 +0000 UTC (1 container statuses recorded)
Mar 25 09:24:09.869: INFO: 	Container metrics-server ready: true, restart count 0
Mar 25 09:24:09.869: INFO: sonobuoy-e2e-job-da73411fd655405d from heptio-sonobuoy started at 2020-03-25 08:52:11 +0000 UTC (2 container statuses recorded)
Mar 25 09:24:09.869: INFO: 	Container e2e ready: true, restart count 0
Mar 25 09:24:09.869: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar 25 09:24:09.869: INFO: sonobuoy-systemd-logs-daemon-set-881e638473c24530-r7mb9 from heptio-sonobuoy started at 2020-03-25 08:52:11 +0000 UTC (2 container statuses recorded)
Mar 25 09:24:09.869: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar 25 09:24:09.869: INFO: 	Container systemd-logs ready: true, restart count 0
Mar 25 09:24:09.869: INFO: filebeat-b24zt from kube-system started at 2020-03-23 08:53:59 +0000 UTC (1 container statuses recorded)
Mar 25 09:24:09.869: INFO: 	Container filebeat ready: true, restart count 0
Mar 25 09:24:09.869: INFO: coredns-84c98f9bb6-hdmp4 from kube-system started at 2020-03-23 08:59:41 +0000 UTC (1 container statuses recorded)
Mar 25 09:24:09.869: INFO: 	Container coredns ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-b2a8ab42-d15a-48c0-9b1a-f570584723e1 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-b2a8ab42-d15a-48c0-9b1a-f570584723e1 off the node ip-10-90-32-23.eu-west-2.compute.internal
STEP: verifying the node doesn't have the label kubernetes.io/e2e-b2a8ab42-d15a-48c0-9b1a-f570584723e1
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 09:24:13.930: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-5228" for this suite.
Mar 25 09:24:21.940: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 09:24:22.011: INFO: namespace sched-pred-5228 deletion completed in 8.078397717s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:72

• [SLOW TEST:12.305 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 09:24:22.011: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-7253
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-ae4b5154-9492-4b42-8bc5-4a318d90fd0a
STEP: Creating a pod to test consume configMaps
Mar 25 09:24:22.159: INFO: Waiting up to 5m0s for pod "pod-configmaps-08e7cf76-2ce8-4ea2-b663-235b63140e01" in namespace "configmap-7253" to be "success or failure"
Mar 25 09:24:22.166: INFO: Pod "pod-configmaps-08e7cf76-2ce8-4ea2-b663-235b63140e01": Phase="Pending", Reason="", readiness=false. Elapsed: 6.614704ms
Mar 25 09:24:24.169: INFO: Pod "pod-configmaps-08e7cf76-2ce8-4ea2-b663-235b63140e01": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00974996s
STEP: Saw pod success
Mar 25 09:24:24.169: INFO: Pod "pod-configmaps-08e7cf76-2ce8-4ea2-b663-235b63140e01" satisfied condition "success or failure"
Mar 25 09:24:24.171: INFO: Trying to get logs from node ip-10-90-32-23.eu-west-2.compute.internal pod pod-configmaps-08e7cf76-2ce8-4ea2-b663-235b63140e01 container configmap-volume-test: <nil>
STEP: delete the pod
Mar 25 09:24:24.190: INFO: Waiting for pod pod-configmaps-08e7cf76-2ce8-4ea2-b663-235b63140e01 to disappear
Mar 25 09:24:24.191: INFO: Pod pod-configmaps-08e7cf76-2ce8-4ea2-b663-235b63140e01 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 09:24:24.192: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7253" for this suite.
Mar 25 09:24:30.203: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 09:24:30.271: INFO: namespace configmap-7253 deletion completed in 6.076655028s

• [SLOW TEST:8.260 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 09:24:30.272: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-5222
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Starting the proxy
Mar 25 09:24:30.404: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-563117487 proxy --unix-socket=/tmp/kubectl-proxy-unix745209666/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 09:24:30.452: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5222" for this suite.
Mar 25 09:24:36.464: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 09:24:36.557: INFO: namespace kubectl-5222 deletion completed in 6.101596005s

• [SLOW TEST:6.285 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Proxy server
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 09:24:36.557: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-1023
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating pod
Mar 25 09:24:38.750: INFO: Pod pod-hostip-9dc0ee5c-e3f1-4c92-a8ff-6e3d75357151 has hostIP: 10.90.32.23
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 09:24:38.750: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-1023" for this suite.
Mar 25 09:25:00.761: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 09:25:00.828: INFO: namespace pods-1023 deletion completed in 22.0751991s

• [SLOW TEST:24.271 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 09:25:00.828: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-6116
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-map-612ede96-0a49-41d5-bd75-8dc62c723bab
STEP: Creating a pod to test consume secrets
Mar 25 09:25:00.967: INFO: Waiting up to 5m0s for pod "pod-secrets-454ee9d6-4979-43cb-86ca-74538e73faaf" in namespace "secrets-6116" to be "success or failure"
Mar 25 09:25:00.974: INFO: Pod "pod-secrets-454ee9d6-4979-43cb-86ca-74538e73faaf": Phase="Pending", Reason="", readiness=false. Elapsed: 6.660794ms
Mar 25 09:25:02.977: INFO: Pod "pod-secrets-454ee9d6-4979-43cb-86ca-74538e73faaf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009509082s
STEP: Saw pod success
Mar 25 09:25:02.977: INFO: Pod "pod-secrets-454ee9d6-4979-43cb-86ca-74538e73faaf" satisfied condition "success or failure"
Mar 25 09:25:02.979: INFO: Trying to get logs from node ip-10-90-32-23.eu-west-2.compute.internal pod pod-secrets-454ee9d6-4979-43cb-86ca-74538e73faaf container secret-volume-test: <nil>
STEP: delete the pod
Mar 25 09:25:02.997: INFO: Waiting for pod pod-secrets-454ee9d6-4979-43cb-86ca-74538e73faaf to disappear
Mar 25 09:25:02.999: INFO: Pod pod-secrets-454ee9d6-4979-43cb-86ca-74538e73faaf no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 09:25:02.999: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6116" for this suite.
Mar 25 09:25:09.011: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 09:25:09.079: INFO: namespace secrets-6116 deletion completed in 6.077370815s

• [SLOW TEST:8.251 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 09:25:09.080: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replicaset-1298
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Mar 25 09:25:12.240: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 09:25:12.255: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-1298" for this suite.
Mar 25 09:25:34.294: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 09:25:34.362: INFO: namespace replicaset-1298 deletion completed in 22.099859436s

• [SLOW TEST:25.282 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 09:25:34.362: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-2681
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Performing setup for networking test in namespace pod-network-test-2681
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Mar 25 09:25:34.494: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Mar 25 09:25:56.593: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.200.96.74 8081 | grep -v '^\s*$'] Namespace:pod-network-test-2681 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 25 09:25:56.593: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
Mar 25 09:25:57.679: INFO: Found all expected endpoints: [netserver-0]
Mar 25 09:25:57.681: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.200.90.21 8081 | grep -v '^\s*$'] Namespace:pod-network-test-2681 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 25 09:25:57.681: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
Mar 25 09:25:58.772: INFO: Found all expected endpoints: [netserver-1]
Mar 25 09:25:58.774: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.200.33.26 8081 | grep -v '^\s*$'] Namespace:pod-network-test-2681 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 25 09:25:58.774: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
Mar 25 09:25:59.874: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 09:25:59.874: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-2681" for this suite.
Mar 25 09:26:21.895: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 09:26:21.963: INFO: namespace pod-network-test-2681 deletion completed in 22.08047899s

• [SLOW TEST:47.600 seconds]
[sig-network] Networking
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 09:26:21.963: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-3746
STEP: Waiting for a default service account to be provisioned in namespace
[It] should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: starting a background goroutine to produce watch events
STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 09:26:27.674: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-3746" for this suite.
Mar 25 09:26:33.820: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 09:26:33.887: INFO: namespace watch-3746 deletion completed in 6.161605662s

• [SLOW TEST:11.923 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 09:26:33.890: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-1032
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:63
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Mar 25 09:26:38.058: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar 25 09:26:38.060: INFO: Pod pod-with-prestop-exec-hook still exists
Mar 25 09:26:40.060: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar 25 09:26:40.063: INFO: Pod pod-with-prestop-exec-hook still exists
Mar 25 09:26:42.060: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar 25 09:26:42.063: INFO: Pod pod-with-prestop-exec-hook still exists
Mar 25 09:26:44.061: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar 25 09:26:44.063: INFO: Pod pod-with-prestop-exec-hook still exists
Mar 25 09:26:46.060: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar 25 09:26:46.063: INFO: Pod pod-with-prestop-exec-hook still exists
Mar 25 09:26:48.060: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar 25 09:26:48.063: INFO: Pod pod-with-prestop-exec-hook still exists
Mar 25 09:26:50.060: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar 25 09:26:50.071: INFO: Pod pod-with-prestop-exec-hook still exists
Mar 25 09:26:52.060: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar 25 09:26:52.063: INFO: Pod pod-with-prestop-exec-hook still exists
Mar 25 09:26:54.060: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar 25 09:26:54.065: INFO: Pod pod-with-prestop-exec-hook still exists
Mar 25 09:26:56.060: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar 25 09:26:56.064: INFO: Pod pod-with-prestop-exec-hook still exists
Mar 25 09:26:58.060: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar 25 09:26:58.063: INFO: Pod pod-with-prestop-exec-hook still exists
Mar 25 09:27:00.060: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar 25 09:27:00.063: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 09:27:00.069: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-1032" for this suite.
Mar 25 09:27:22.081: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 09:27:22.149: INFO: namespace container-lifecycle-hook-1032 deletion completed in 22.076404788s

• [SLOW TEST:48.259 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when create a pod with lifecycle hook
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 09:27:22.149: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-9988
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Mar 25 09:27:22.284: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 09:27:24.310: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-9988" for this suite.
Mar 25 09:28:02.322: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 09:28:02.395: INFO: namespace pods-9988 deletion completed in 38.0807463s

• [SLOW TEST:40.245 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 09:28:02.395: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-9600
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Mar 25 09:28:02.527: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 09:28:03.684: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-9600" for this suite.
Mar 25 09:28:09.696: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 09:28:09.766: INFO: namespace custom-resource-definition-9600 deletion completed in 6.079073488s

• [SLOW TEST:7.371 seconds]
[sig-api-machinery] CustomResourceDefinition resources
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:35
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 09:28:09.767: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-7397
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
W0325 09:28:49.931326      16 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Mar 25 09:28:49.931: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 09:28:49.931: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-7397" for this suite.
Mar 25 09:28:55.948: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 09:28:56.019: INFO: namespace gc-7397 deletion completed in 6.084127323s

• [SLOW TEST:46.252 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 09:28:56.020: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6911
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-70b22513-042f-4328-9177-8b98a776ab37
STEP: Creating a pod to test consume configMaps
Mar 25 09:28:56.210: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-30c8c9a5-725a-4866-83ca-808cd5ca48fe" in namespace "projected-6911" to be "success or failure"
Mar 25 09:28:56.217: INFO: Pod "pod-projected-configmaps-30c8c9a5-725a-4866-83ca-808cd5ca48fe": Phase="Pending", Reason="", readiness=false. Elapsed: 7.030873ms
Mar 25 09:28:58.220: INFO: Pod "pod-projected-configmaps-30c8c9a5-725a-4866-83ca-808cd5ca48fe": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010181976s
STEP: Saw pod success
Mar 25 09:28:58.221: INFO: Pod "pod-projected-configmaps-30c8c9a5-725a-4866-83ca-808cd5ca48fe" satisfied condition "success or failure"
Mar 25 09:28:58.222: INFO: Trying to get logs from node ip-10-90-32-23.eu-west-2.compute.internal pod pod-projected-configmaps-30c8c9a5-725a-4866-83ca-808cd5ca48fe container projected-configmap-volume-test: <nil>
STEP: delete the pod
Mar 25 09:28:58.238: INFO: Waiting for pod pod-projected-configmaps-30c8c9a5-725a-4866-83ca-808cd5ca48fe to disappear
Mar 25 09:28:58.240: INFO: Pod pod-projected-configmaps-30c8c9a5-725a-4866-83ca-808cd5ca48fe no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 09:28:58.240: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6911" for this suite.
Mar 25 09:29:04.252: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 09:29:04.320: INFO: namespace projected-6911 deletion completed in 6.077424546s

• [SLOW TEST:8.300 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 09:29:04.321: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-4606
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-ed629b55-daa4-4505-9ccf-2f76cc1c9693
STEP: Creating a pod to test consume secrets
Mar 25 09:29:04.462: INFO: Waiting up to 5m0s for pod "pod-secrets-91afc753-423b-495a-b44f-8978ee790d39" in namespace "secrets-4606" to be "success or failure"
Mar 25 09:29:04.469: INFO: Pod "pod-secrets-91afc753-423b-495a-b44f-8978ee790d39": Phase="Pending", Reason="", readiness=false. Elapsed: 6.736002ms
Mar 25 09:29:06.472: INFO: Pod "pod-secrets-91afc753-423b-495a-b44f-8978ee790d39": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009817241s
STEP: Saw pod success
Mar 25 09:29:06.472: INFO: Pod "pod-secrets-91afc753-423b-495a-b44f-8978ee790d39" satisfied condition "success or failure"
Mar 25 09:29:06.474: INFO: Trying to get logs from node ip-10-90-32-23.eu-west-2.compute.internal pod pod-secrets-91afc753-423b-495a-b44f-8978ee790d39 container secret-volume-test: <nil>
STEP: delete the pod
Mar 25 09:29:06.491: INFO: Waiting for pod pod-secrets-91afc753-423b-495a-b44f-8978ee790d39 to disappear
Mar 25 09:29:06.493: INFO: Pod pod-secrets-91afc753-423b-495a-b44f-8978ee790d39 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 09:29:06.493: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-4606" for this suite.
Mar 25 09:29:12.504: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 09:29:12.583: INFO: namespace secrets-4606 deletion completed in 6.088106692s

• [SLOW TEST:8.263 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 09:29:12.584: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-1180
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0325 09:29:18.791855      16 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Mar 25 09:29:18.791: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 09:29:18.792: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-1180" for this suite.
Mar 25 09:29:24.803: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 09:29:24.873: INFO: namespace gc-1180 deletion completed in 6.079045115s

• [SLOW TEST:12.289 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 09:29:24.873: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-6775
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-d3248545-2245-4605-a79d-4adf1d9cb88c
STEP: Creating a pod to test consume secrets
Mar 25 09:29:25.016: INFO: Waiting up to 5m0s for pod "pod-secrets-4c085c7a-747d-4bda-87c9-5dbf3d756fa7" in namespace "secrets-6775" to be "success or failure"
Mar 25 09:29:25.024: INFO: Pod "pod-secrets-4c085c7a-747d-4bda-87c9-5dbf3d756fa7": Phase="Pending", Reason="", readiness=false. Elapsed: 8.409934ms
Mar 25 09:29:27.027: INFO: Pod "pod-secrets-4c085c7a-747d-4bda-87c9-5dbf3d756fa7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011377239s
STEP: Saw pod success
Mar 25 09:29:27.027: INFO: Pod "pod-secrets-4c085c7a-747d-4bda-87c9-5dbf3d756fa7" satisfied condition "success or failure"
Mar 25 09:29:27.029: INFO: Trying to get logs from node ip-10-90-32-23.eu-west-2.compute.internal pod pod-secrets-4c085c7a-747d-4bda-87c9-5dbf3d756fa7 container secret-env-test: <nil>
STEP: delete the pod
Mar 25 09:29:27.043: INFO: Waiting for pod pod-secrets-4c085c7a-747d-4bda-87c9-5dbf3d756fa7 to disappear
Mar 25 09:29:27.046: INFO: Pod pod-secrets-4c085c7a-747d-4bda-87c9-5dbf3d756fa7 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 09:29:27.046: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6775" for this suite.
Mar 25 09:29:33.056: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 09:29:33.123: INFO: namespace secrets-6775 deletion completed in 6.074569652s

• [SLOW TEST:8.250 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 09:29:33.123: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-6877
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 09:29:37.337: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-6877" for this suite.
Mar 25 09:29:43.347: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 09:29:43.417: INFO: namespace kubelet-test-6877 deletion completed in 6.07761414s

• [SLOW TEST:10.294 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should have an terminated reason [NodeConformance] [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 09:29:43.418: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-4447
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0777 on node default medium
Mar 25 09:29:43.556: INFO: Waiting up to 5m0s for pod "pod-13d30bea-408b-449c-9315-cdbfe5bce6b7" in namespace "emptydir-4447" to be "success or failure"
Mar 25 09:29:43.560: INFO: Pod "pod-13d30bea-408b-449c-9315-cdbfe5bce6b7": Phase="Pending", Reason="", readiness=false. Elapsed: 3.579911ms
Mar 25 09:29:45.563: INFO: Pod "pod-13d30bea-408b-449c-9315-cdbfe5bce6b7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006520452s
STEP: Saw pod success
Mar 25 09:29:45.563: INFO: Pod "pod-13d30bea-408b-449c-9315-cdbfe5bce6b7" satisfied condition "success or failure"
Mar 25 09:29:45.564: INFO: Trying to get logs from node ip-10-90-32-23.eu-west-2.compute.internal pod pod-13d30bea-408b-449c-9315-cdbfe5bce6b7 container test-container: <nil>
STEP: delete the pod
Mar 25 09:29:45.580: INFO: Waiting for pod pod-13d30bea-408b-449c-9315-cdbfe5bce6b7 to disappear
Mar 25 09:29:45.581: INFO: Pod pod-13d30bea-408b-449c-9315-cdbfe5bce6b7 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 09:29:45.582: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4447" for this suite.
Mar 25 09:29:51.592: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 09:29:51.685: INFO: namespace emptydir-4447 deletion completed in 6.100856504s

• [SLOW TEST:8.267 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 09:29:51.685: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-6980
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir volume type on tmpfs
Mar 25 09:29:51.823: INFO: Waiting up to 5m0s for pod "pod-848f0e9a-4d46-4fd9-bd66-3c55077a78be" in namespace "emptydir-6980" to be "success or failure"
Mar 25 09:29:51.826: INFO: Pod "pod-848f0e9a-4d46-4fd9-bd66-3c55077a78be": Phase="Pending", Reason="", readiness=false. Elapsed: 3.520888ms
Mar 25 09:29:53.829: INFO: Pod "pod-848f0e9a-4d46-4fd9-bd66-3c55077a78be": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006337744s
STEP: Saw pod success
Mar 25 09:29:53.829: INFO: Pod "pod-848f0e9a-4d46-4fd9-bd66-3c55077a78be" satisfied condition "success or failure"
Mar 25 09:29:53.831: INFO: Trying to get logs from node ip-10-90-32-23.eu-west-2.compute.internal pod pod-848f0e9a-4d46-4fd9-bd66-3c55077a78be container test-container: <nil>
STEP: delete the pod
Mar 25 09:29:53.845: INFO: Waiting for pod pod-848f0e9a-4d46-4fd9-bd66-3c55077a78be to disappear
Mar 25 09:29:53.847: INFO: Pod pod-848f0e9a-4d46-4fd9-bd66-3c55077a78be no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 09:29:53.847: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6980" for this suite.
Mar 25 09:29:59.859: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 09:29:59.928: INFO: namespace emptydir-6980 deletion completed in 6.077841324s

• [SLOW TEST:8.242 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 09:29:59.928: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-488
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-map-3fbe2368-9918-4df0-b6ce-f7bc54addda8
STEP: Creating a pod to test consume configMaps
Mar 25 09:30:00.073: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-72c05248-e49e-4bc6-adb7-e14723b42a13" in namespace "projected-488" to be "success or failure"
Mar 25 09:30:00.085: INFO: Pod "pod-projected-configmaps-72c05248-e49e-4bc6-adb7-e14723b42a13": Phase="Pending", Reason="", readiness=false. Elapsed: 11.332401ms
Mar 25 09:30:02.088: INFO: Pod "pod-projected-configmaps-72c05248-e49e-4bc6-adb7-e14723b42a13": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01436608s
STEP: Saw pod success
Mar 25 09:30:02.088: INFO: Pod "pod-projected-configmaps-72c05248-e49e-4bc6-adb7-e14723b42a13" satisfied condition "success or failure"
Mar 25 09:30:02.094: INFO: Trying to get logs from node ip-10-90-32-23.eu-west-2.compute.internal pod pod-projected-configmaps-72c05248-e49e-4bc6-adb7-e14723b42a13 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Mar 25 09:30:02.148: INFO: Waiting for pod pod-projected-configmaps-72c05248-e49e-4bc6-adb7-e14723b42a13 to disappear
Mar 25 09:30:02.151: INFO: Pod pod-projected-configmaps-72c05248-e49e-4bc6-adb7-e14723b42a13 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 09:30:02.151: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-488" for this suite.
Mar 25 09:30:08.178: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 09:30:08.245: INFO: namespace projected-488 deletion completed in 6.086789s

• [SLOW TEST:8.317 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 09:30:08.246: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-438
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:63
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Mar 25 09:30:12.413: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Mar 25 09:30:12.415: INFO: Pod pod-with-prestop-http-hook still exists
Mar 25 09:30:14.415: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Mar 25 09:30:14.418: INFO: Pod pod-with-prestop-http-hook still exists
Mar 25 09:30:16.415: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Mar 25 09:30:16.418: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 09:30:16.427: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-438" for this suite.
Mar 25 09:30:38.438: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 09:30:38.501: INFO: namespace container-lifecycle-hook-438 deletion completed in 22.071606108s

• [SLOW TEST:30.255 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when create a pod with lifecycle hook
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 09:30:38.501: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-9136
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Mar 25 09:30:40.657: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 09:30:40.668: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-9136" for this suite.
Mar 25 09:30:46.682: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 09:30:46.749: INFO: namespace container-runtime-9136 deletion completed in 6.075655979s

• [SLOW TEST:8.248 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  blackbox test
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
    on terminated container
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:129
      should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
      /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 09:30:46.750: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9689
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-map-46898b9e-fe1d-470f-b24a-1b8126fe1688
STEP: Creating a pod to test consume secrets
Mar 25 09:30:46.940: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-29847e0f-9436-4369-b4c8-9b7a9b0df453" in namespace "projected-9689" to be "success or failure"
Mar 25 09:30:46.947: INFO: Pod "pod-projected-secrets-29847e0f-9436-4369-b4c8-9b7a9b0df453": Phase="Pending", Reason="", readiness=false. Elapsed: 6.58045ms
Mar 25 09:30:48.950: INFO: Pod "pod-projected-secrets-29847e0f-9436-4369-b4c8-9b7a9b0df453": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009574668s
STEP: Saw pod success
Mar 25 09:30:48.950: INFO: Pod "pod-projected-secrets-29847e0f-9436-4369-b4c8-9b7a9b0df453" satisfied condition "success or failure"
Mar 25 09:30:48.952: INFO: Trying to get logs from node ip-10-90-32-23.eu-west-2.compute.internal pod pod-projected-secrets-29847e0f-9436-4369-b4c8-9b7a9b0df453 container projected-secret-volume-test: <nil>
STEP: delete the pod
Mar 25 09:30:48.967: INFO: Waiting for pod pod-projected-secrets-29847e0f-9436-4369-b4c8-9b7a9b0df453 to disappear
Mar 25 09:30:48.969: INFO: Pod pod-projected-secrets-29847e0f-9436-4369-b4c8-9b7a9b0df453 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 09:30:48.969: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9689" for this suite.
Mar 25 09:30:54.979: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 09:30:55.047: INFO: namespace projected-9689 deletion completed in 6.075460488s

• [SLOW TEST:8.296 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 09:30:55.047: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-4023
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Mar 25 09:30:55.206: INFO: Number of nodes with available pods: 0
Mar 25 09:30:55.206: INFO: Node ip-10-90-32-22.eu-west-2.compute.internal is running more than one daemon pod
Mar 25 09:30:56.212: INFO: Number of nodes with available pods: 0
Mar 25 09:30:56.212: INFO: Node ip-10-90-32-22.eu-west-2.compute.internal is running more than one daemon pod
Mar 25 09:30:57.212: INFO: Number of nodes with available pods: 3
Mar 25 09:30:57.212: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Stop a daemon pod, check that the daemon pod is revived.
Mar 25 09:30:57.228: INFO: Number of nodes with available pods: 2
Mar 25 09:30:57.228: INFO: Node ip-10-90-32-22.eu-west-2.compute.internal is running more than one daemon pod
Mar 25 09:30:58.233: INFO: Number of nodes with available pods: 2
Mar 25 09:30:58.233: INFO: Node ip-10-90-32-22.eu-west-2.compute.internal is running more than one daemon pod
Mar 25 09:30:59.236: INFO: Number of nodes with available pods: 2
Mar 25 09:30:59.237: INFO: Node ip-10-90-32-22.eu-west-2.compute.internal is running more than one daemon pod
Mar 25 09:31:00.234: INFO: Number of nodes with available pods: 2
Mar 25 09:31:00.234: INFO: Node ip-10-90-32-22.eu-west-2.compute.internal is running more than one daemon pod
Mar 25 09:31:01.234: INFO: Number of nodes with available pods: 2
Mar 25 09:31:01.234: INFO: Node ip-10-90-32-22.eu-west-2.compute.internal is running more than one daemon pod
Mar 25 09:31:02.234: INFO: Number of nodes with available pods: 2
Mar 25 09:31:02.234: INFO: Node ip-10-90-32-22.eu-west-2.compute.internal is running more than one daemon pod
Mar 25 09:31:03.234: INFO: Number of nodes with available pods: 2
Mar 25 09:31:03.234: INFO: Node ip-10-90-32-22.eu-west-2.compute.internal is running more than one daemon pod
Mar 25 09:31:04.233: INFO: Number of nodes with available pods: 2
Mar 25 09:31:04.233: INFO: Node ip-10-90-32-22.eu-west-2.compute.internal is running more than one daemon pod
Mar 25 09:31:05.234: INFO: Number of nodes with available pods: 2
Mar 25 09:31:05.234: INFO: Node ip-10-90-32-22.eu-west-2.compute.internal is running more than one daemon pod
Mar 25 09:31:06.233: INFO: Number of nodes with available pods: 2
Mar 25 09:31:06.233: INFO: Node ip-10-90-32-22.eu-west-2.compute.internal is running more than one daemon pod
Mar 25 09:31:07.234: INFO: Number of nodes with available pods: 2
Mar 25 09:31:07.234: INFO: Node ip-10-90-32-22.eu-west-2.compute.internal is running more than one daemon pod
Mar 25 09:31:08.233: INFO: Number of nodes with available pods: 2
Mar 25 09:31:08.233: INFO: Node ip-10-90-32-22.eu-west-2.compute.internal is running more than one daemon pod
Mar 25 09:31:09.234: INFO: Number of nodes with available pods: 2
Mar 25 09:31:09.234: INFO: Node ip-10-90-32-22.eu-west-2.compute.internal is running more than one daemon pod
Mar 25 09:31:10.234: INFO: Number of nodes with available pods: 2
Mar 25 09:31:10.234: INFO: Node ip-10-90-32-22.eu-west-2.compute.internal is running more than one daemon pod
Mar 25 09:31:11.233: INFO: Number of nodes with available pods: 2
Mar 25 09:31:11.233: INFO: Node ip-10-90-32-22.eu-west-2.compute.internal is running more than one daemon pod
Mar 25 09:31:12.234: INFO: Number of nodes with available pods: 3
Mar 25 09:31:12.234: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-4023, will wait for the garbage collector to delete the pods
Mar 25 09:31:12.295: INFO: Deleting DaemonSet.extensions daemon-set took: 6.701196ms
Mar 25 09:31:14.395: INFO: Terminating DaemonSet.extensions daemon-set pods took: 2.100306485s
Mar 25 09:31:26.797: INFO: Number of nodes with available pods: 0
Mar 25 09:31:26.798: INFO: Number of running nodes: 0, number of available pods: 0
Mar 25 09:31:26.799: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-4023/daemonsets","resourceVersion":"337089"},"items":null}

Mar 25 09:31:26.801: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-4023/pods","resourceVersion":"337089"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 09:31:26.809: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-4023" for this suite.
Mar 25 09:31:32.820: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 09:31:32.887: INFO: namespace daemonsets-4023 deletion completed in 6.075592923s

• [SLOW TEST:37.841 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 09:31:32.888: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-7033
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 09:31:36.045: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-7033" for this suite.
Mar 25 09:31:58.057: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 09:31:58.124: INFO: namespace replication-controller-7033 deletion completed in 22.0763895s

• [SLOW TEST:25.236 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 09:31:58.124: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-7595
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 09:32:00.277: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-7595" for this suite.
Mar 25 09:32:50.288: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 09:32:50.360: INFO: namespace kubelet-test-7595 deletion completed in 50.080232274s

• [SLOW TEST:52.236 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when scheduling a busybox Pod with hostAliases
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:136
    should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 09:32:50.360: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-1646
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-map-cb15b78c-5f78-4ad4-bb8b-60eeb4558acd
STEP: Creating a pod to test consume configMaps
Mar 25 09:32:50.501: INFO: Waiting up to 5m0s for pod "pod-configmaps-4020d3b2-163a-4293-a616-aac0ed46074a" in namespace "configmap-1646" to be "success or failure"
Mar 25 09:32:50.508: INFO: Pod "pod-configmaps-4020d3b2-163a-4293-a616-aac0ed46074a": Phase="Pending", Reason="", readiness=false. Elapsed: 6.630126ms
Mar 25 09:32:52.513: INFO: Pod "pod-configmaps-4020d3b2-163a-4293-a616-aac0ed46074a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011664366s
STEP: Saw pod success
Mar 25 09:32:52.513: INFO: Pod "pod-configmaps-4020d3b2-163a-4293-a616-aac0ed46074a" satisfied condition "success or failure"
Mar 25 09:32:52.516: INFO: Trying to get logs from node ip-10-90-32-23.eu-west-2.compute.internal pod pod-configmaps-4020d3b2-163a-4293-a616-aac0ed46074a container configmap-volume-test: <nil>
STEP: delete the pod
Mar 25 09:32:52.531: INFO: Waiting for pod pod-configmaps-4020d3b2-163a-4293-a616-aac0ed46074a to disappear
Mar 25 09:32:52.532: INFO: Pod pod-configmaps-4020d3b2-163a-4293-a616-aac0ed46074a no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 09:32:52.533: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1646" for this suite.
Mar 25 09:32:58.544: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 09:32:58.615: INFO: namespace configmap-1646 deletion completed in 6.080109828s

• [SLOW TEST:8.255 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 09:32:58.615: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-6146
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1557
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Mar 25 09:32:58.755: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --generator=deployment/apps.v1 --namespace=kubectl-6146'
Mar 25 09:32:58.984: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Mar 25 09:32:58.984: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the deployment e2e-test-nginx-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1562
Mar 25 09:33:01.010: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 delete deployment e2e-test-nginx-deployment --namespace=kubectl-6146'
Mar 25 09:33:01.084: INFO: stderr: ""
Mar 25 09:33:01.084: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 09:33:01.084: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6146" for this suite.
Mar 25 09:33:07.100: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 09:33:07.174: INFO: namespace kubectl-6146 deletion completed in 6.085374851s

• [SLOW TEST:8.559 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run deployment
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 09:33:07.174: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-3385
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-e409bc5d-e4b5-4496-b279-3d8db9df06e7
STEP: Creating a pod to test consume configMaps
Mar 25 09:33:07.318: INFO: Waiting up to 5m0s for pod "pod-configmaps-6ebcce7d-ad07-488e-9c99-1bce4e5b5873" in namespace "configmap-3385" to be "success or failure"
Mar 25 09:33:07.326: INFO: Pod "pod-configmaps-6ebcce7d-ad07-488e-9c99-1bce4e5b5873": Phase="Pending", Reason="", readiness=false. Elapsed: 7.237783ms
Mar 25 09:33:09.329: INFO: Pod "pod-configmaps-6ebcce7d-ad07-488e-9c99-1bce4e5b5873": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010422071s
STEP: Saw pod success
Mar 25 09:33:09.329: INFO: Pod "pod-configmaps-6ebcce7d-ad07-488e-9c99-1bce4e5b5873" satisfied condition "success or failure"
Mar 25 09:33:09.331: INFO: Trying to get logs from node ip-10-90-32-23.eu-west-2.compute.internal pod pod-configmaps-6ebcce7d-ad07-488e-9c99-1bce4e5b5873 container configmap-volume-test: <nil>
STEP: delete the pod
Mar 25 09:33:09.345: INFO: Waiting for pod pod-configmaps-6ebcce7d-ad07-488e-9c99-1bce4e5b5873 to disappear
Mar 25 09:33:09.347: INFO: Pod pod-configmaps-6ebcce7d-ad07-488e-9c99-1bce4e5b5873 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 09:33:09.347: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3385" for this suite.
Mar 25 09:33:15.358: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 09:33:15.420: INFO: namespace configmap-3385 deletion completed in 6.070550165s

• [SLOW TEST:8.246 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 09:33:15.421: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-9116
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1612
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Mar 25 09:33:15.552: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-9116'
Mar 25 09:33:15.638: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Mar 25 09:33:15.638: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
STEP: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1617
Mar 25 09:33:15.649: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 delete jobs e2e-test-nginx-job --namespace=kubectl-9116'
Mar 25 09:33:15.719: INFO: stderr: ""
Mar 25 09:33:15.719: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 09:33:15.719: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9116" for this suite.
Mar 25 09:33:37.733: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 09:33:37.879: INFO: namespace kubectl-9116 deletion completed in 22.155683054s

• [SLOW TEST:22.458 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run job
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 09:33:37.879: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-9710
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl label
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1210
STEP: creating the pod
Mar 25 09:33:38.012: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 create -f - --namespace=kubectl-9710'
Mar 25 09:33:38.178: INFO: stderr: ""
Mar 25 09:33:38.178: INFO: stdout: "pod/pause created\n"
Mar 25 09:33:38.178: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Mar 25 09:33:38.178: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-9710" to be "running and ready"
Mar 25 09:33:38.182: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 4.304122ms
Mar 25 09:33:40.195: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.016743507s
Mar 25 09:33:40.195: INFO: Pod "pause" satisfied condition "running and ready"
Mar 25 09:33:40.195: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: adding the label testing-label with value testing-label-value to a pod
Mar 25 09:33:40.195: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 label pods pause testing-label=testing-label-value --namespace=kubectl-9710'
Mar 25 09:33:40.266: INFO: stderr: ""
Mar 25 09:33:40.266: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Mar 25 09:33:40.266: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 get pod pause -L testing-label --namespace=kubectl-9710'
Mar 25 09:33:40.331: INFO: stderr: ""
Mar 25 09:33:40.331: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Mar 25 09:33:40.331: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 label pods pause testing-label- --namespace=kubectl-9710'
Mar 25 09:33:40.400: INFO: stderr: ""
Mar 25 09:33:40.400: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Mar 25 09:33:40.401: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 get pod pause -L testing-label --namespace=kubectl-9710'
Mar 25 09:33:40.465: INFO: stderr: ""
Mar 25 09:33:40.465: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    \n"
[AfterEach] [k8s.io] Kubectl label
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1217
STEP: using delete to clean up resources
Mar 25 09:33:40.465: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 delete --grace-period=0 --force -f - --namespace=kubectl-9710'
Mar 25 09:33:40.536: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar 25 09:33:40.536: INFO: stdout: "pod \"pause\" force deleted\n"
Mar 25 09:33:40.536: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 get rc,svc -l name=pause --no-headers --namespace=kubectl-9710'
Mar 25 09:33:40.607: INFO: stderr: "No resources found.\n"
Mar 25 09:33:40.607: INFO: stdout: ""
Mar 25 09:33:40.607: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 get pods -l name=pause --namespace=kubectl-9710 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Mar 25 09:33:40.673: INFO: stderr: ""
Mar 25 09:33:40.673: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 09:33:40.673: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9710" for this suite.
Mar 25 09:33:46.684: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 09:33:46.752: INFO: namespace kubectl-9710 deletion completed in 6.075977676s

• [SLOW TEST:8.873 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl label
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 09:33:46.753: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-6074
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
Mar 25 09:33:46.934: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 09:33:50.140: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-6074" for this suite.
Mar 25 09:33:56.151: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 09:33:56.222: INFO: namespace init-container-6074 deletion completed in 6.078950576s

• [SLOW TEST:9.469 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 09:33:56.222: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-5467
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1721
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Mar 25 09:33:56.378: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 run e2e-test-nginx-pod --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --labels=run=e2e-test-nginx-pod --namespace=kubectl-5467'
Mar 25 09:33:56.453: INFO: stderr: ""
Mar 25 09:33:56.453: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod is running
STEP: verifying the pod e2e-test-nginx-pod was created
Mar 25 09:34:01.503: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 get pod e2e-test-nginx-pod --namespace=kubectl-5467 -o json'
Mar 25 09:34:01.585: INFO: stderr: ""
Mar 25 09:34:01.585: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"creationTimestamp\": \"2020-03-25T09:33:56Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"kubectl-5467\",\n        \"resourceVersion\": \"337594\",\n        \"selfLink\": \"/api/v1/namespaces/kubectl-5467/pods/e2e-test-nginx-pod\",\n        \"uid\": \"198d34be-570c-4fff-acd7-a6778c90cb35\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-cft89\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"ip-10-90-32-23.eu-west-2.compute.internal\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-cft89\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-cft89\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-03-25T09:33:56Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-03-25T09:33:58Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-03-25T09:33:58Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-03-25T09:33:56Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://09fed1fdefefab3001561c52d8c1d67f940c6eda54f56dc0219d2337122d6dde\",\n                \"image\": \"nginx:1.14-alpine\",\n                \"imageID\": \"docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2020-03-25T09:33:57Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.90.32.23\",\n        \"phase\": \"Running\",\n        \"podIP\": \"10.200.96.102\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2020-03-25T09:33:56Z\"\n    }\n}\n"
STEP: replace the image in the pod
Mar 25 09:34:01.585: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 replace -f - --namespace=kubectl-5467'
Mar 25 09:34:01.737: INFO: stderr: ""
Mar 25 09:34:01.737: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
STEP: verifying the pod e2e-test-nginx-pod has the right image docker.io/library/busybox:1.29
[AfterEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1726
Mar 25 09:34:01.740: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 delete pods e2e-test-nginx-pod --namespace=kubectl-5467'
Mar 25 09:34:03.321: INFO: stderr: ""
Mar 25 09:34:03.321: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 09:34:03.321: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5467" for this suite.
Mar 25 09:34:09.333: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 09:34:09.401: INFO: namespace kubectl-5467 deletion completed in 6.076591243s

• [SLOW TEST:13.179 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl replace
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 09:34:09.402: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3917
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Mar 25 09:34:09.541: INFO: Waiting up to 5m0s for pod "downwardapi-volume-4d6a35ad-8823-4529-86db-fc431e29fb09" in namespace "projected-3917" to be "success or failure"
Mar 25 09:34:09.547: INFO: Pod "downwardapi-volume-4d6a35ad-8823-4529-86db-fc431e29fb09": Phase="Pending", Reason="", readiness=false. Elapsed: 6.812443ms
Mar 25 09:34:11.551: INFO: Pod "downwardapi-volume-4d6a35ad-8823-4529-86db-fc431e29fb09": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009905532s
STEP: Saw pod success
Mar 25 09:34:11.551: INFO: Pod "downwardapi-volume-4d6a35ad-8823-4529-86db-fc431e29fb09" satisfied condition "success or failure"
Mar 25 09:34:11.553: INFO: Trying to get logs from node ip-10-90-32-23.eu-west-2.compute.internal pod downwardapi-volume-4d6a35ad-8823-4529-86db-fc431e29fb09 container client-container: <nil>
STEP: delete the pod
Mar 25 09:34:11.567: INFO: Waiting for pod downwardapi-volume-4d6a35ad-8823-4529-86db-fc431e29fb09 to disappear
Mar 25 09:34:11.570: INFO: Pod downwardapi-volume-4d6a35ad-8823-4529-86db-fc431e29fb09 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 09:34:11.570: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3917" for this suite.
Mar 25 09:34:17.580: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 09:34:17.659: INFO: namespace projected-3917 deletion completed in 6.087001937s

• [SLOW TEST:8.258 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 09:34:17.660: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-3257
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-3257.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-3257.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Mar 25 09:34:31.835: INFO: DNS probes using dns-3257/dns-test-577b2e4c-3e13-41d8-a3f0-a428ad9d8f1a succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 09:34:31.846: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-3257" for this suite.
Mar 25 09:34:37.858: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 09:34:37.933: INFO: namespace dns-3257 deletion completed in 6.084438889s

• [SLOW TEST:20.273 seconds]
[sig-network] DNS
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 09:34:37.933: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-kubelet-etc-hosts-7756
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Mar 25 09:34:42.098: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-7756 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 25 09:34:42.098: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
Mar 25 09:34:42.186: INFO: Exec stderr: ""
Mar 25 09:34:42.186: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-7756 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 25 09:34:42.186: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
Mar 25 09:34:42.298: INFO: Exec stderr: ""
Mar 25 09:34:42.298: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-7756 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 25 09:34:42.298: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
Mar 25 09:34:42.385: INFO: Exec stderr: ""
Mar 25 09:34:42.385: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-7756 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 25 09:34:42.385: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
Mar 25 09:34:42.504: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Mar 25 09:34:42.505: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-7756 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 25 09:34:42.505: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
Mar 25 09:34:42.587: INFO: Exec stderr: ""
Mar 25 09:34:42.587: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-7756 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 25 09:34:42.587: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
Mar 25 09:34:42.689: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Mar 25 09:34:42.689: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-7756 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 25 09:34:42.690: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
Mar 25 09:34:42.796: INFO: Exec stderr: ""
Mar 25 09:34:42.797: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-7756 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 25 09:34:42.797: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
Mar 25 09:34:42.896: INFO: Exec stderr: ""
Mar 25 09:34:42.896: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-7756 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 25 09:34:42.896: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
Mar 25 09:34:43.011: INFO: Exec stderr: ""
Mar 25 09:34:43.011: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-7756 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 25 09:34:43.011: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
Mar 25 09:34:43.113: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 09:34:43.113: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-kubelet-etc-hosts-7756" for this suite.
Mar 25 09:35:29.125: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 09:35:29.192: INFO: namespace e2e-kubelet-etc-hosts-7756 deletion completed in 46.07641963s

• [SLOW TEST:51.259 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 09:35:29.192: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-2390
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Mar 25 09:35:29.331: INFO: Waiting up to 5m0s for pod "downward-api-a68cfe37-a5d6-495e-afe7-02503447a559" in namespace "downward-api-2390" to be "success or failure"
Mar 25 09:35:29.335: INFO: Pod "downward-api-a68cfe37-a5d6-495e-afe7-02503447a559": Phase="Pending", Reason="", readiness=false. Elapsed: 3.558225ms
Mar 25 09:35:31.338: INFO: Pod "downward-api-a68cfe37-a5d6-495e-afe7-02503447a559": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007038733s
Mar 25 09:35:33.341: INFO: Pod "downward-api-a68cfe37-a5d6-495e-afe7-02503447a559": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01013648s
STEP: Saw pod success
Mar 25 09:35:33.341: INFO: Pod "downward-api-a68cfe37-a5d6-495e-afe7-02503447a559" satisfied condition "success or failure"
Mar 25 09:35:33.343: INFO: Trying to get logs from node ip-10-90-32-23.eu-west-2.compute.internal pod downward-api-a68cfe37-a5d6-495e-afe7-02503447a559 container dapi-container: <nil>
STEP: delete the pod
Mar 25 09:35:33.359: INFO: Waiting for pod downward-api-a68cfe37-a5d6-495e-afe7-02503447a559 to disappear
Mar 25 09:35:33.362: INFO: Pod downward-api-a68cfe37-a5d6-495e-afe7-02503447a559 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 09:35:33.362: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2390" for this suite.
Mar 25 09:35:39.374: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 09:35:39.438: INFO: namespace downward-api-2390 deletion completed in 6.073217625s

• [SLOW TEST:10.246 seconds]
[sig-node] Downward API
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 09:35:39.438: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename events
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in events-2458
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Mar 25 09:35:41.584: INFO: &Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-367857dd-1d25-4eb3-8ac5-83a0c93d8cdb,GenerateName:,Namespace:events-2458,SelfLink:/api/v1/namespaces/events-2458/pods/send-events-367857dd-1d25-4eb3-8ac5-83a0c93d8cdb,UID:999a5240-c8b5-498b-b667-8c3a236ce56c,ResourceVersion:337926,Generation:0,CreationTimestamp:2020-03-25 09:35:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 568718697,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-s9d7d {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-s9d7d,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-s9d7d true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-90-32-23.eu-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00223fe50} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00223fe70}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-25 09:35:39 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2020-03-25 09:35:41 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2020-03-25 09:35:41 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-25 09:35:39 +0000 UTC  }],Message:,Reason:,HostIP:10.90.32.23,PodIP:10.200.96.107,StartTime:2020-03-25 09:35:39 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2020-03-25 09:35:40 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 docker-pullable://gcr.io/kubernetes-e2e-test-images/serve-hostname@sha256:bab70473a6d8ef65a22625dc9a1b0f0452e811530fdbe77e4408523460177ff1 docker://9b7a30ff095968812920d23be5b3a2b571686245af916f9a070de5c55725d8dc}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}

STEP: checking for scheduler event about the pod
Mar 25 09:35:43.588: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Mar 25 09:35:45.591: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 09:35:45.597: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-2458" for this suite.
Mar 25 09:36:27.613: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 09:36:27.693: INFO: namespace events-2458 deletion completed in 42.093124006s

• [SLOW TEST:48.255 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 09:36:27.693: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-76
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-76.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-76.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-76.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-76.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-76.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-76.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-76.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-76.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-76.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-76.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-76.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-76.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-76.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 80.200.100.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.100.200.80_udp@PTR;check="$$(dig +tcp +noall +answer +search 80.200.100.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.100.200.80_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-76.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-76.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-76.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-76.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-76.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-76.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-76.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-76.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-76.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-76.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-76.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-76.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-76.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 80.200.100.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.100.200.80_udp@PTR;check="$$(dig +tcp +noall +answer +search 80.200.100.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.100.200.80_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Mar 25 09:36:31.878: INFO: Unable to read wheezy_tcp@dns-test-service.dns-76.svc.cluster.local from pod dns-76/dns-test-374b9ec8-dc32-42c5-be40-900fbf3cee34: the server could not find the requested resource (get pods dns-test-374b9ec8-dc32-42c5-be40-900fbf3cee34)
Mar 25 09:36:31.883: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-76.svc.cluster.local from pod dns-76/dns-test-374b9ec8-dc32-42c5-be40-900fbf3cee34: the server could not find the requested resource (get pods dns-test-374b9ec8-dc32-42c5-be40-900fbf3cee34)
Mar 25 09:36:31.904: INFO: Unable to read jessie_tcp@dns-test-service.dns-76.svc.cluster.local from pod dns-76/dns-test-374b9ec8-dc32-42c5-be40-900fbf3cee34: the server could not find the requested resource (get pods dns-test-374b9ec8-dc32-42c5-be40-900fbf3cee34)
Mar 25 09:36:31.910: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-76.svc.cluster.local from pod dns-76/dns-test-374b9ec8-dc32-42c5-be40-900fbf3cee34: the server could not find the requested resource (get pods dns-test-374b9ec8-dc32-42c5-be40-900fbf3cee34)
Mar 25 09:36:31.929: INFO: Lookups using dns-76/dns-test-374b9ec8-dc32-42c5-be40-900fbf3cee34 failed for: [wheezy_tcp@dns-test-service.dns-76.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-76.svc.cluster.local jessie_tcp@dns-test-service.dns-76.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-76.svc.cluster.local]

Mar 25 09:36:36.992: INFO: DNS probes using dns-76/dns-test-374b9ec8-dc32-42c5-be40-900fbf3cee34 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 09:36:37.057: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-76" for this suite.
Mar 25 09:36:43.070: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 09:36:43.141: INFO: namespace dns-76 deletion completed in 6.080977193s

• [SLOW TEST:15.448 seconds]
[sig-network] DNS
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 09:36:43.141: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-2057
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
Mar 25 09:36:43.273: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 09:36:47.136: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-2057" for this suite.
Mar 25 09:37:09.147: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 09:37:09.218: INFO: namespace init-container-2057 deletion completed in 22.079687715s

• [SLOW TEST:26.077 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 09:37:09.218: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-9446
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: starting the proxy server
Mar 25 09:37:09.349: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-563117487 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 09:37:09.407: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9446" for this suite.
Mar 25 09:37:15.418: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 09:37:15.499: INFO: namespace kubectl-9446 deletion completed in 6.088691758s

• [SLOW TEST:6.280 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Proxy server
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 09:37:15.499: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-3079
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Mar 25 09:37:15.699: INFO: Waiting up to 5m0s for pod "downwardapi-volume-811a30c8-e8b2-4734-a3ac-74f64c2664c4" in namespace "downward-api-3079" to be "success or failure"
Mar 25 09:37:15.708: INFO: Pod "downwardapi-volume-811a30c8-e8b2-4734-a3ac-74f64c2664c4": Phase="Pending", Reason="", readiness=false. Elapsed: 8.428624ms
Mar 25 09:37:17.711: INFO: Pod "downwardapi-volume-811a30c8-e8b2-4734-a3ac-74f64c2664c4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01173951s
STEP: Saw pod success
Mar 25 09:37:17.711: INFO: Pod "downwardapi-volume-811a30c8-e8b2-4734-a3ac-74f64c2664c4" satisfied condition "success or failure"
Mar 25 09:37:17.713: INFO: Trying to get logs from node ip-10-90-32-23.eu-west-2.compute.internal pod downwardapi-volume-811a30c8-e8b2-4734-a3ac-74f64c2664c4 container client-container: <nil>
STEP: delete the pod
Mar 25 09:37:17.728: INFO: Waiting for pod downwardapi-volume-811a30c8-e8b2-4734-a3ac-74f64c2664c4 to disappear
Mar 25 09:37:17.730: INFO: Pod downwardapi-volume-811a30c8-e8b2-4734-a3ac-74f64c2664c4 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 09:37:17.730: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3079" for this suite.
Mar 25 09:37:23.745: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 09:37:23.810: INFO: namespace downward-api-3079 deletion completed in 6.078314122s

• [SLOW TEST:8.312 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 09:37:23.811: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-6232
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Mar 25 09:37:23.948: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6d8ddf42-57a2-4aa8-9db6-0efee38acebb" in namespace "downward-api-6232" to be "success or failure"
Mar 25 09:37:23.952: INFO: Pod "downwardapi-volume-6d8ddf42-57a2-4aa8-9db6-0efee38acebb": Phase="Pending", Reason="", readiness=false. Elapsed: 3.700309ms
Mar 25 09:37:25.955: INFO: Pod "downwardapi-volume-6d8ddf42-57a2-4aa8-9db6-0efee38acebb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006537618s
STEP: Saw pod success
Mar 25 09:37:25.955: INFO: Pod "downwardapi-volume-6d8ddf42-57a2-4aa8-9db6-0efee38acebb" satisfied condition "success or failure"
Mar 25 09:37:25.957: INFO: Trying to get logs from node ip-10-90-32-22.eu-west-2.compute.internal pod downwardapi-volume-6d8ddf42-57a2-4aa8-9db6-0efee38acebb container client-container: <nil>
STEP: delete the pod
Mar 25 09:37:25.973: INFO: Waiting for pod downwardapi-volume-6d8ddf42-57a2-4aa8-9db6-0efee38acebb to disappear
Mar 25 09:37:25.976: INFO: Pod downwardapi-volume-6d8ddf42-57a2-4aa8-9db6-0efee38acebb no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 09:37:25.976: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6232" for this suite.
Mar 25 09:37:31.987: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 09:37:32.055: INFO: namespace downward-api-6232 deletion completed in 6.075968568s

• [SLOW TEST:8.244 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 09:37:32.055: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-1681
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating Redis RC
Mar 25 09:37:32.187: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 create -f - --namespace=kubectl-1681'
Mar 25 09:37:32.337: INFO: stderr: ""
Mar 25 09:37:32.337: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Mar 25 09:37:33.340: INFO: Selector matched 1 pods for map[app:redis]
Mar 25 09:37:33.340: INFO: Found 0 / 1
Mar 25 09:37:34.340: INFO: Selector matched 1 pods for map[app:redis]
Mar 25 09:37:34.340: INFO: Found 1 / 1
Mar 25 09:37:34.340: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Mar 25 09:37:34.343: INFO: Selector matched 1 pods for map[app:redis]
Mar 25 09:37:34.343: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Mar 25 09:37:34.343: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 patch pod redis-master-5qffd --namespace=kubectl-1681 -p {"metadata":{"annotations":{"x":"y"}}}'
Mar 25 09:37:34.419: INFO: stderr: ""
Mar 25 09:37:34.419: INFO: stdout: "pod/redis-master-5qffd patched\n"
STEP: checking annotations
Mar 25 09:37:34.422: INFO: Selector matched 1 pods for map[app:redis]
Mar 25 09:37:34.422: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 09:37:34.422: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1681" for this suite.
Mar 25 09:37:56.432: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 09:37:56.500: INFO: namespace kubectl-1681 deletion completed in 22.075206733s

• [SLOW TEST:24.445 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl patch
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 09:37:56.500: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-5876
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0666 on node default medium
Mar 25 09:37:56.636: INFO: Waiting up to 5m0s for pod "pod-e01d58f1-15e6-4cf9-a735-293a9c90ce20" in namespace "emptydir-5876" to be "success or failure"
Mar 25 09:37:56.643: INFO: Pod "pod-e01d58f1-15e6-4cf9-a735-293a9c90ce20": Phase="Pending", Reason="", readiness=false. Elapsed: 6.682665ms
Mar 25 09:37:58.646: INFO: Pod "pod-e01d58f1-15e6-4cf9-a735-293a9c90ce20": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009656398s
STEP: Saw pod success
Mar 25 09:37:58.646: INFO: Pod "pod-e01d58f1-15e6-4cf9-a735-293a9c90ce20" satisfied condition "success or failure"
Mar 25 09:37:58.648: INFO: Trying to get logs from node ip-10-90-32-23.eu-west-2.compute.internal pod pod-e01d58f1-15e6-4cf9-a735-293a9c90ce20 container test-container: <nil>
STEP: delete the pod
Mar 25 09:37:58.662: INFO: Waiting for pod pod-e01d58f1-15e6-4cf9-a735-293a9c90ce20 to disappear
Mar 25 09:37:58.664: INFO: Pod pod-e01d58f1-15e6-4cf9-a735-293a9c90ce20 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 09:37:58.664: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5876" for this suite.
Mar 25 09:38:04.675: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 09:38:04.748: INFO: namespace emptydir-5876 deletion completed in 6.08164215s

• [SLOW TEST:8.248 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 09:38:04.749: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-3906
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Mar 25 09:38:04.880: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 version'
Mar 25 09:38:04.941: INFO: stderr: ""
Mar 25 09:38:04.941: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"15\", GitVersion:\"v1.15.7\", GitCommit:\"6c143d35bb11d74970e7bc0b6c45b6bfdffc0bd4\", GitTreeState:\"clean\", BuildDate:\"2019-12-11T12:42:56Z\", GoVersion:\"go1.12.12\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"15\", GitVersion:\"v1.15.7\", GitCommit:\"6c143d35bb11d74970e7bc0b6c45b6bfdffc0bd4\", GitTreeState:\"clean\", BuildDate:\"2019-12-11T12:34:17Z\", GoVersion:\"go1.12.12\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 09:38:04.941: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3906" for this suite.
Mar 25 09:38:10.961: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 09:38:11.034: INFO: namespace kubectl-3906 deletion completed in 6.089316179s

• [SLOW TEST:6.286 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl version
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 09:38:11.035: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-7234
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1420
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Mar 25 09:38:11.168: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-7234'
Mar 25 09:38:11.245: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Mar 25 09:38:11.245: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1426
Mar 25 09:38:13.257: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 delete deployment e2e-test-nginx-deployment --namespace=kubectl-7234'
Mar 25 09:38:13.330: INFO: stderr: ""
Mar 25 09:38:13.330: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 09:38:13.330: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7234" for this suite.
Mar 25 09:38:19.346: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 09:38:19.411: INFO: namespace kubectl-7234 deletion completed in 6.076701407s

• [SLOW TEST:8.376 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run default
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 09:38:19.411: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-7752
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:179
[It] should be submitted and removed  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 09:38:19.552: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-7752" for this suite.
Mar 25 09:38:41.570: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 09:38:41.634: INFO: namespace pods-7752 deletion completed in 22.074915822s

• [SLOW TEST:22.223 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should be submitted and removed  [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 09:38:41.634: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in namespaces-9685
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-2946
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-8244
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 09:38:48.043: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-9685" for this suite.
Mar 25 09:38:54.056: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 09:38:54.123: INFO: namespace namespaces-9685 deletion completed in 6.077392375s
STEP: Destroying namespace "nsdeletetest-2946" for this suite.
Mar 25 09:38:54.125: INFO: Namespace nsdeletetest-2946 was already deleted
STEP: Destroying namespace "nsdeletetest-8244" for this suite.
Mar 25 09:39:00.133: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 09:39:00.204: INFO: namespace nsdeletetest-8244 deletion completed in 6.079324404s

• [SLOW TEST:18.570 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 09:39:00.205: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-7787
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
Mar 25 09:39:00.340: INFO: observed the pod list
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
Mar 25 09:39:07.380: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 09:39:07.382: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-7787" for this suite.
Mar 25 09:39:13.392: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 09:39:13.456: INFO: namespace pods-7787 deletion completed in 6.071571448s

• [SLOW TEST:13.251 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 09:39:13.456: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-5681
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Mar 25 09:39:13.592: INFO: Waiting up to 5m0s for pod "downwardapi-volume-129b101b-621c-48ed-a91e-49b697483967" in namespace "downward-api-5681" to be "success or failure"
Mar 25 09:39:13.600: INFO: Pod "downwardapi-volume-129b101b-621c-48ed-a91e-49b697483967": Phase="Pending", Reason="", readiness=false. Elapsed: 7.390845ms
Mar 25 09:39:15.603: INFO: Pod "downwardapi-volume-129b101b-621c-48ed-a91e-49b697483967": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010407207s
STEP: Saw pod success
Mar 25 09:39:15.603: INFO: Pod "downwardapi-volume-129b101b-621c-48ed-a91e-49b697483967" satisfied condition "success or failure"
Mar 25 09:39:15.605: INFO: Trying to get logs from node ip-10-90-32-23.eu-west-2.compute.internal pod downwardapi-volume-129b101b-621c-48ed-a91e-49b697483967 container client-container: <nil>
STEP: delete the pod
Mar 25 09:39:15.620: INFO: Waiting for pod downwardapi-volume-129b101b-621c-48ed-a91e-49b697483967 to disappear
Mar 25 09:39:15.622: INFO: Pod downwardapi-volume-129b101b-621c-48ed-a91e-49b697483967 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 09:39:15.622: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5681" for this suite.
Mar 25 09:39:21.633: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 09:39:21.705: INFO: namespace downward-api-5681 deletion completed in 6.080233165s

• [SLOW TEST:8.249 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 09:39:21.705: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-3505
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Performing setup for networking test in namespace pod-network-test-3505
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Mar 25 09:39:21.842: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Mar 25 09:39:43.931: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.200.96.118:8080/dial?request=hostName&protocol=udp&host=10.200.33.39&port=8081&tries=1'] Namespace:pod-network-test-3505 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 25 09:39:43.931: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
Mar 25 09:39:44.028: INFO: Waiting for endpoints: map[]
Mar 25 09:39:44.030: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.200.96.118:8080/dial?request=hostName&protocol=udp&host=10.200.90.31&port=8081&tries=1'] Namespace:pod-network-test-3505 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 25 09:39:44.030: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
Mar 25 09:39:44.125: INFO: Waiting for endpoints: map[]
Mar 25 09:39:44.127: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.200.96.118:8080/dial?request=hostName&protocol=udp&host=10.200.96.117&port=8081&tries=1'] Namespace:pod-network-test-3505 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 25 09:39:44.127: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
Mar 25 09:39:44.224: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 09:39:44.224: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-3505" for this suite.
Mar 25 09:40:06.237: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 09:40:06.305: INFO: namespace pod-network-test-3505 deletion completed in 22.0768046s

• [SLOW TEST:44.600 seconds]
[sig-network] Networking
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job 
  should delete a job [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 09:40:06.305: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename job
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in job-8017
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete a job [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: delete a job
STEP: deleting Job.batch foo in namespace job-8017, will wait for the garbage collector to delete the pods
Mar 25 09:40:10.502: INFO: Deleting Job.batch foo took: 5.753966ms
Mar 25 09:40:10.802: INFO: Terminating Job.batch foo pods took: 300.25317ms
STEP: Ensuring job was deleted
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 09:40:43.105: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-8017" for this suite.
Mar 25 09:40:49.117: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 09:40:49.183: INFO: namespace job-8017 deletion completed in 6.075082251s

• [SLOW TEST:42.878 seconds]
[sig-apps] Job
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should delete a job [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 09:40:49.184: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-9027
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Mar 25 09:40:49.322: INFO: Waiting up to 5m0s for pod "downward-api-9cd17c7b-fec4-477d-93aa-d38a1e8827b4" in namespace "downward-api-9027" to be "success or failure"
Mar 25 09:40:49.326: INFO: Pod "downward-api-9cd17c7b-fec4-477d-93aa-d38a1e8827b4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.05802ms
Mar 25 09:40:51.329: INFO: Pod "downward-api-9cd17c7b-fec4-477d-93aa-d38a1e8827b4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007065398s
Mar 25 09:40:53.332: INFO: Pod "downward-api-9cd17c7b-fec4-477d-93aa-d38a1e8827b4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010270855s
STEP: Saw pod success
Mar 25 09:40:53.332: INFO: Pod "downward-api-9cd17c7b-fec4-477d-93aa-d38a1e8827b4" satisfied condition "success or failure"
Mar 25 09:40:53.334: INFO: Trying to get logs from node ip-10-90-32-24.eu-west-2.compute.internal pod downward-api-9cd17c7b-fec4-477d-93aa-d38a1e8827b4 container dapi-container: <nil>
STEP: delete the pod
Mar 25 09:40:53.351: INFO: Waiting for pod downward-api-9cd17c7b-fec4-477d-93aa-d38a1e8827b4 to disappear
Mar 25 09:40:53.353: INFO: Pod downward-api-9cd17c7b-fec4-477d-93aa-d38a1e8827b4 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 09:40:53.353: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9027" for this suite.
Mar 25 09:40:59.365: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 09:40:59.436: INFO: namespace downward-api-9027 deletion completed in 6.080071092s

• [SLOW TEST:10.252 seconds]
[sig-node] Downward API
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 09:40:59.436: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-6919
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating the pod
Mar 25 09:41:02.109: INFO: Successfully updated pod "annotationupdate61e08358-6a05-441c-bf29-ebd3f26548a0"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 09:41:04.122: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6919" for this suite.
Mar 25 09:41:26.133: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 09:41:26.199: INFO: namespace downward-api-6919 deletion completed in 22.074849439s

• [SLOW TEST:26.763 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 09:41:26.200: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-2672
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:273
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a replication controller
Mar 25 09:41:26.331: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 create -f - --namespace=kubectl-2672'
Mar 25 09:41:26.483: INFO: stderr: ""
Mar 25 09:41:26.483: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Mar 25 09:41:26.483: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-2672'
Mar 25 09:41:26.551: INFO: stderr: ""
Mar 25 09:41:26.551: INFO: stdout: "update-demo-nautilus-2pzcs update-demo-nautilus-kl425 "
Mar 25 09:41:26.551: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 get pods update-demo-nautilus-2pzcs -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2672'
Mar 25 09:41:26.620: INFO: stderr: ""
Mar 25 09:41:26.620: INFO: stdout: ""
Mar 25 09:41:26.620: INFO: update-demo-nautilus-2pzcs is created but not running
Mar 25 09:41:31.620: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-2672'
Mar 25 09:41:31.690: INFO: stderr: ""
Mar 25 09:41:31.690: INFO: stdout: "update-demo-nautilus-2pzcs update-demo-nautilus-kl425 "
Mar 25 09:41:31.690: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 get pods update-demo-nautilus-2pzcs -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2672'
Mar 25 09:41:31.754: INFO: stderr: ""
Mar 25 09:41:31.754: INFO: stdout: "true"
Mar 25 09:41:31.754: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 get pods update-demo-nautilus-2pzcs -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-2672'
Mar 25 09:41:31.817: INFO: stderr: ""
Mar 25 09:41:31.817: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar 25 09:41:31.817: INFO: validating pod update-demo-nautilus-2pzcs
Mar 25 09:41:31.821: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar 25 09:41:31.821: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar 25 09:41:31.821: INFO: update-demo-nautilus-2pzcs is verified up and running
Mar 25 09:41:31.821: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 get pods update-demo-nautilus-kl425 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2672'
Mar 25 09:41:31.883: INFO: stderr: ""
Mar 25 09:41:31.883: INFO: stdout: "true"
Mar 25 09:41:31.883: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 get pods update-demo-nautilus-kl425 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-2672'
Mar 25 09:41:31.946: INFO: stderr: ""
Mar 25 09:41:31.946: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar 25 09:41:31.946: INFO: validating pod update-demo-nautilus-kl425
Mar 25 09:41:31.950: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar 25 09:41:31.950: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar 25 09:41:31.950: INFO: update-demo-nautilus-kl425 is verified up and running
STEP: scaling down the replication controller
Mar 25 09:41:31.951: INFO: scanned /root for discovery docs: <nil>
Mar 25 09:41:31.951: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=kubectl-2672'
Mar 25 09:41:33.045: INFO: stderr: ""
Mar 25 09:41:33.045: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Mar 25 09:41:33.045: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-2672'
Mar 25 09:41:33.112: INFO: stderr: ""
Mar 25 09:41:33.112: INFO: stdout: "update-demo-nautilus-2pzcs update-demo-nautilus-kl425 "
STEP: Replicas for name=update-demo: expected=1 actual=2
Mar 25 09:41:38.112: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-2672'
Mar 25 09:41:38.178: INFO: stderr: ""
Mar 25 09:41:38.178: INFO: stdout: "update-demo-nautilus-kl425 "
Mar 25 09:41:38.178: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 get pods update-demo-nautilus-kl425 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2672'
Mar 25 09:41:38.247: INFO: stderr: ""
Mar 25 09:41:38.247: INFO: stdout: "true"
Mar 25 09:41:38.247: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 get pods update-demo-nautilus-kl425 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-2672'
Mar 25 09:41:38.316: INFO: stderr: ""
Mar 25 09:41:38.316: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar 25 09:41:38.316: INFO: validating pod update-demo-nautilus-kl425
Mar 25 09:41:38.319: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar 25 09:41:38.319: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar 25 09:41:38.319: INFO: update-demo-nautilus-kl425 is verified up and running
STEP: scaling up the replication controller
Mar 25 09:41:38.320: INFO: scanned /root for discovery docs: <nil>
Mar 25 09:41:38.320: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=kubectl-2672'
Mar 25 09:41:39.416: INFO: stderr: ""
Mar 25 09:41:39.416: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Mar 25 09:41:39.416: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-2672'
Mar 25 09:41:39.485: INFO: stderr: ""
Mar 25 09:41:39.485: INFO: stdout: "update-demo-nautilus-6ntlr update-demo-nautilus-kl425 "
Mar 25 09:41:39.485: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 get pods update-demo-nautilus-6ntlr -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2672'
Mar 25 09:41:39.562: INFO: stderr: ""
Mar 25 09:41:39.562: INFO: stdout: ""
Mar 25 09:41:39.562: INFO: update-demo-nautilus-6ntlr is created but not running
Mar 25 09:41:44.562: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-2672'
Mar 25 09:41:44.633: INFO: stderr: ""
Mar 25 09:41:44.633: INFO: stdout: "update-demo-nautilus-6ntlr update-demo-nautilus-kl425 "
Mar 25 09:41:44.633: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 get pods update-demo-nautilus-6ntlr -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2672'
Mar 25 09:41:44.705: INFO: stderr: ""
Mar 25 09:41:44.705: INFO: stdout: "true"
Mar 25 09:41:44.705: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 get pods update-demo-nautilus-6ntlr -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-2672'
Mar 25 09:41:44.769: INFO: stderr: ""
Mar 25 09:41:44.769: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar 25 09:41:44.769: INFO: validating pod update-demo-nautilus-6ntlr
Mar 25 09:41:44.773: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar 25 09:41:44.773: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar 25 09:41:44.773: INFO: update-demo-nautilus-6ntlr is verified up and running
Mar 25 09:41:44.773: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 get pods update-demo-nautilus-kl425 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2672'
Mar 25 09:41:44.843: INFO: stderr: ""
Mar 25 09:41:44.843: INFO: stdout: "true"
Mar 25 09:41:44.843: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 get pods update-demo-nautilus-kl425 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-2672'
Mar 25 09:41:44.906: INFO: stderr: ""
Mar 25 09:41:44.906: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar 25 09:41:44.906: INFO: validating pod update-demo-nautilus-kl425
Mar 25 09:41:44.909: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar 25 09:41:44.909: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar 25 09:41:44.909: INFO: update-demo-nautilus-kl425 is verified up and running
STEP: using delete to clean up resources
Mar 25 09:41:44.909: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 delete --grace-period=0 --force -f - --namespace=kubectl-2672'
Mar 25 09:41:44.977: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar 25 09:41:44.977: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Mar 25 09:41:44.977: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-2672'
Mar 25 09:41:45.045: INFO: stderr: "No resources found.\n"
Mar 25 09:41:45.045: INFO: stdout: ""
Mar 25 09:41:45.045: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 get pods -l name=update-demo --namespace=kubectl-2672 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Mar 25 09:41:45.117: INFO: stderr: ""
Mar 25 09:41:45.118: INFO: stdout: "update-demo-nautilus-6ntlr\nupdate-demo-nautilus-kl425\n"
Mar 25 09:41:45.618: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-2672'
Mar 25 09:41:45.687: INFO: stderr: "No resources found.\n"
Mar 25 09:41:45.687: INFO: stdout: ""
Mar 25 09:41:45.687: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 get pods -l name=update-demo --namespace=kubectl-2672 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Mar 25 09:41:45.758: INFO: stderr: ""
Mar 25 09:41:45.758: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 09:41:45.758: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2672" for this suite.
Mar 25 09:41:51.770: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 09:41:51.841: INFO: namespace kubectl-2672 deletion completed in 6.079646143s

• [SLOW TEST:25.641 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 09:41:51.841: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-726
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-projected-all-test-volume-a1fd6128-d1a5-4d47-9804-55695723c865
STEP: Creating secret with name secret-projected-all-test-volume-b2a21963-61de-45ee-ad99-5e95a42967fb
STEP: Creating a pod to test Check all projections for projected volume plugin
Mar 25 09:41:51.986: INFO: Waiting up to 5m0s for pod "projected-volume-2a7f7dd8-2472-46ab-a2a0-f2c74ba24ccf" in namespace "projected-726" to be "success or failure"
Mar 25 09:41:51.990: INFO: Pod "projected-volume-2a7f7dd8-2472-46ab-a2a0-f2c74ba24ccf": Phase="Pending", Reason="", readiness=false. Elapsed: 3.60978ms
Mar 25 09:41:53.993: INFO: Pod "projected-volume-2a7f7dd8-2472-46ab-a2a0-f2c74ba24ccf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006444823s
STEP: Saw pod success
Mar 25 09:41:53.993: INFO: Pod "projected-volume-2a7f7dd8-2472-46ab-a2a0-f2c74ba24ccf" satisfied condition "success or failure"
Mar 25 09:41:53.995: INFO: Trying to get logs from node ip-10-90-32-23.eu-west-2.compute.internal pod projected-volume-2a7f7dd8-2472-46ab-a2a0-f2c74ba24ccf container projected-all-volume-test: <nil>
STEP: delete the pod
Mar 25 09:41:54.010: INFO: Waiting for pod projected-volume-2a7f7dd8-2472-46ab-a2a0-f2c74ba24ccf to disappear
Mar 25 09:41:54.012: INFO: Pod projected-volume-2a7f7dd8-2472-46ab-a2a0-f2c74ba24ccf no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 09:41:54.012: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-726" for this suite.
Mar 25 09:42:00.024: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 09:42:00.103: INFO: namespace projected-726 deletion completed in 6.089296082s

• [SLOW TEST:8.262 seconds]
[sig-storage] Projected combined
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_combined.go:31
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 09:42:00.104: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename prestop
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in prestop-6469
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pre_stop.go:167
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating server pod server in namespace prestop-6469
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace prestop-6469
STEP: Deleting pre-stop pod
Mar 25 09:42:13.270: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 09:42:13.275: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "prestop-6469" for this suite.
Mar 25 09:42:51.291: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 09:42:51.356: INFO: namespace prestop-6469 deletion completed in 38.07600121s

• [SLOW TEST:51.252 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 09:42:51.356: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1596
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-map-4769ecc0-7ece-493c-bc34-97011d38a2d9
STEP: Creating a pod to test consume configMaps
Mar 25 09:42:51.495: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-05b223f5-2e24-46ea-8ad3-b3686f7128b5" in namespace "projected-1596" to be "success or failure"
Mar 25 09:42:51.499: INFO: Pod "pod-projected-configmaps-05b223f5-2e24-46ea-8ad3-b3686f7128b5": Phase="Pending", Reason="", readiness=false. Elapsed: 3.769026ms
Mar 25 09:42:53.502: INFO: Pod "pod-projected-configmaps-05b223f5-2e24-46ea-8ad3-b3686f7128b5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006778006s
STEP: Saw pod success
Mar 25 09:42:53.502: INFO: Pod "pod-projected-configmaps-05b223f5-2e24-46ea-8ad3-b3686f7128b5" satisfied condition "success or failure"
Mar 25 09:42:53.504: INFO: Trying to get logs from node ip-10-90-32-23.eu-west-2.compute.internal pod pod-projected-configmaps-05b223f5-2e24-46ea-8ad3-b3686f7128b5 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Mar 25 09:42:53.520: INFO: Waiting for pod pod-projected-configmaps-05b223f5-2e24-46ea-8ad3-b3686f7128b5 to disappear
Mar 25 09:42:53.523: INFO: Pod pod-projected-configmaps-05b223f5-2e24-46ea-8ad3-b3686f7128b5 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 09:42:53.524: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1596" for this suite.
Mar 25 09:42:59.534: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 09:42:59.601: INFO: namespace projected-1596 deletion completed in 6.075176783s

• [SLOW TEST:8.245 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 09:42:59.602: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-5277
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0666 on tmpfs
Mar 25 09:42:59.742: INFO: Waiting up to 5m0s for pod "pod-b77c3438-8994-4106-a05f-c5f0f587855b" in namespace "emptydir-5277" to be "success or failure"
Mar 25 09:42:59.757: INFO: Pod "pod-b77c3438-8994-4106-a05f-c5f0f587855b": Phase="Pending", Reason="", readiness=false. Elapsed: 14.850724ms
Mar 25 09:43:01.760: INFO: Pod "pod-b77c3438-8994-4106-a05f-c5f0f587855b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.017666444s
STEP: Saw pod success
Mar 25 09:43:01.760: INFO: Pod "pod-b77c3438-8994-4106-a05f-c5f0f587855b" satisfied condition "success or failure"
Mar 25 09:43:01.762: INFO: Trying to get logs from node ip-10-90-32-23.eu-west-2.compute.internal pod pod-b77c3438-8994-4106-a05f-c5f0f587855b container test-container: <nil>
STEP: delete the pod
Mar 25 09:43:01.776: INFO: Waiting for pod pod-b77c3438-8994-4106-a05f-c5f0f587855b to disappear
Mar 25 09:43:01.779: INFO: Pod pod-b77c3438-8994-4106-a05f-c5f0f587855b no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 09:43:01.779: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5277" for this suite.
Mar 25 09:43:07.790: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 09:43:07.858: INFO: namespace emptydir-5277 deletion completed in 6.076186069s

• [SLOW TEST:8.256 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 09:43:07.858: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-3292
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test override command
Mar 25 09:43:08.046: INFO: Waiting up to 5m0s for pod "client-containers-3dc2acd8-9ef1-466f-b248-3335a15cefd3" in namespace "containers-3292" to be "success or failure"
Mar 25 09:43:08.050: INFO: Pod "client-containers-3dc2acd8-9ef1-466f-b248-3335a15cefd3": Phase="Pending", Reason="", readiness=false. Elapsed: 3.506913ms
Mar 25 09:43:10.053: INFO: Pod "client-containers-3dc2acd8-9ef1-466f-b248-3335a15cefd3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006391428s
STEP: Saw pod success
Mar 25 09:43:10.053: INFO: Pod "client-containers-3dc2acd8-9ef1-466f-b248-3335a15cefd3" satisfied condition "success or failure"
Mar 25 09:43:10.055: INFO: Trying to get logs from node ip-10-90-32-23.eu-west-2.compute.internal pod client-containers-3dc2acd8-9ef1-466f-b248-3335a15cefd3 container test-container: <nil>
STEP: delete the pod
Mar 25 09:43:10.069: INFO: Waiting for pod client-containers-3dc2acd8-9ef1-466f-b248-3335a15cefd3 to disappear
Mar 25 09:43:10.071: INFO: Pod client-containers-3dc2acd8-9ef1-466f-b248-3335a15cefd3 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 09:43:10.071: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-3292" for this suite.
Mar 25 09:43:16.082: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 09:43:16.150: INFO: namespace containers-3292 deletion completed in 6.075975233s

• [SLOW TEST:8.292 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 09:43:16.150: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-6032
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-86339838-8416-4d44-bd21-e13469f79a99
STEP: Creating a pod to test consume configMaps
Mar 25 09:43:16.292: INFO: Waiting up to 5m0s for pod "pod-configmaps-04ac08b5-d54e-4dc9-8bf3-014c4fd59810" in namespace "configmap-6032" to be "success or failure"
Mar 25 09:43:16.296: INFO: Pod "pod-configmaps-04ac08b5-d54e-4dc9-8bf3-014c4fd59810": Phase="Pending", Reason="", readiness=false. Elapsed: 3.454797ms
Mar 25 09:43:18.298: INFO: Pod "pod-configmaps-04ac08b5-d54e-4dc9-8bf3-014c4fd59810": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006265322s
STEP: Saw pod success
Mar 25 09:43:18.299: INFO: Pod "pod-configmaps-04ac08b5-d54e-4dc9-8bf3-014c4fd59810" satisfied condition "success or failure"
Mar 25 09:43:18.300: INFO: Trying to get logs from node ip-10-90-32-23.eu-west-2.compute.internal pod pod-configmaps-04ac08b5-d54e-4dc9-8bf3-014c4fd59810 container configmap-volume-test: <nil>
STEP: delete the pod
Mar 25 09:43:18.315: INFO: Waiting for pod pod-configmaps-04ac08b5-d54e-4dc9-8bf3-014c4fd59810 to disappear
Mar 25 09:43:18.317: INFO: Pod pod-configmaps-04ac08b5-d54e-4dc9-8bf3-014c4fd59810 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 09:43:18.317: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6032" for this suite.
Mar 25 09:43:24.328: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 09:43:24.398: INFO: namespace configmap-6032 deletion completed in 6.078502058s

• [SLOW TEST:8.248 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 09:43:24.399: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-1465
STEP: Waiting for a default service account to be provisioned in namespace
[It] pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating Pod
STEP: Waiting for the pod running
STEP: Geting the pod
STEP: Reading file content from the nginx-container
Mar 25 09:43:26.553: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 exec pod-sharedvolume-9ba40132-e87d-497e-94b0-7d2e6d62405b -c busybox-main-container --namespace=emptydir-1465 -- cat /usr/share/volumeshare/shareddata.txt'
Mar 25 09:43:26.863: INFO: stderr: ""
Mar 25 09:43:26.863: INFO: stdout: "Hello from the busy-box sub-container\n"
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 09:43:26.863: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1465" for this suite.
Mar 25 09:43:32.875: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 09:43:32.944: INFO: namespace emptydir-1465 deletion completed in 6.077751229s

• [SLOW TEST:8.545 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 09:43:32.944: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7659
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-01af40c1-09b9-4848-9ff0-7cf97bc2514d
STEP: Creating a pod to test consume secrets
Mar 25 09:43:33.086: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-230ff523-520e-4b88-b41c-b67915b9fd2c" in namespace "projected-7659" to be "success or failure"
Mar 25 09:43:33.091: INFO: Pod "pod-projected-secrets-230ff523-520e-4b88-b41c-b67915b9fd2c": Phase="Pending", Reason="", readiness=false. Elapsed: 5.368396ms
Mar 25 09:43:35.094: INFO: Pod "pod-projected-secrets-230ff523-520e-4b88-b41c-b67915b9fd2c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008494934s
STEP: Saw pod success
Mar 25 09:43:35.094: INFO: Pod "pod-projected-secrets-230ff523-520e-4b88-b41c-b67915b9fd2c" satisfied condition "success or failure"
Mar 25 09:43:35.096: INFO: Trying to get logs from node ip-10-90-32-23.eu-west-2.compute.internal pod pod-projected-secrets-230ff523-520e-4b88-b41c-b67915b9fd2c container projected-secret-volume-test: <nil>
STEP: delete the pod
Mar 25 09:43:35.115: INFO: Waiting for pod pod-projected-secrets-230ff523-520e-4b88-b41c-b67915b9fd2c to disappear
Mar 25 09:43:35.119: INFO: Pod pod-projected-secrets-230ff523-520e-4b88-b41c-b67915b9fd2c no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 09:43:35.119: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7659" for this suite.
Mar 25 09:43:41.130: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 09:43:41.199: INFO: namespace projected-7659 deletion completed in 6.076684681s

• [SLOW TEST:8.255 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 09:43:41.200: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6978
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Mar 25 09:43:41.339: INFO: Waiting up to 5m0s for pod "downwardapi-volume-46cd06ba-a8e2-4df6-b16d-a388d7502976" in namespace "projected-6978" to be "success or failure"
Mar 25 09:43:41.342: INFO: Pod "downwardapi-volume-46cd06ba-a8e2-4df6-b16d-a388d7502976": Phase="Pending", Reason="", readiness=false. Elapsed: 3.547934ms
Mar 25 09:43:43.345: INFO: Pod "downwardapi-volume-46cd06ba-a8e2-4df6-b16d-a388d7502976": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006568322s
STEP: Saw pod success
Mar 25 09:43:43.345: INFO: Pod "downwardapi-volume-46cd06ba-a8e2-4df6-b16d-a388d7502976" satisfied condition "success or failure"
Mar 25 09:43:43.347: INFO: Trying to get logs from node ip-10-90-32-23.eu-west-2.compute.internal pod downwardapi-volume-46cd06ba-a8e2-4df6-b16d-a388d7502976 container client-container: <nil>
STEP: delete the pod
Mar 25 09:43:43.363: INFO: Waiting for pod downwardapi-volume-46cd06ba-a8e2-4df6-b16d-a388d7502976 to disappear
Mar 25 09:43:43.365: INFO: Pod downwardapi-volume-46cd06ba-a8e2-4df6-b16d-a388d7502976 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 09:43:43.365: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6978" for this suite.
Mar 25 09:43:49.376: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 09:43:49.445: INFO: namespace projected-6978 deletion completed in 6.077442266s

• [SLOW TEST:8.246 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 09:43:49.446: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-8125
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-configmap-5cjr
STEP: Creating a pod to test atomic-volume-subpath
Mar 25 09:43:49.590: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-5cjr" in namespace "subpath-8125" to be "success or failure"
Mar 25 09:43:49.593: INFO: Pod "pod-subpath-test-configmap-5cjr": Phase="Pending", Reason="", readiness=false. Elapsed: 3.409636ms
Mar 25 09:43:51.596: INFO: Pod "pod-subpath-test-configmap-5cjr": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006333446s
Mar 25 09:43:53.599: INFO: Pod "pod-subpath-test-configmap-5cjr": Phase="Running", Reason="", readiness=true. Elapsed: 4.00950115s
Mar 25 09:43:55.602: INFO: Pod "pod-subpath-test-configmap-5cjr": Phase="Running", Reason="", readiness=true. Elapsed: 6.01281495s
Mar 25 09:43:57.606: INFO: Pod "pod-subpath-test-configmap-5cjr": Phase="Running", Reason="", readiness=true. Elapsed: 8.015891874s
Mar 25 09:43:59.609: INFO: Pod "pod-subpath-test-configmap-5cjr": Phase="Running", Reason="", readiness=true. Elapsed: 10.019095507s
Mar 25 09:44:01.612: INFO: Pod "pod-subpath-test-configmap-5cjr": Phase="Running", Reason="", readiness=true. Elapsed: 12.021931613s
Mar 25 09:44:03.615: INFO: Pod "pod-subpath-test-configmap-5cjr": Phase="Running", Reason="", readiness=true. Elapsed: 14.025070394s
Mar 25 09:44:05.618: INFO: Pod "pod-subpath-test-configmap-5cjr": Phase="Running", Reason="", readiness=true. Elapsed: 16.028042076s
Mar 25 09:44:07.621: INFO: Pod "pod-subpath-test-configmap-5cjr": Phase="Running", Reason="", readiness=true. Elapsed: 18.031123469s
Mar 25 09:44:09.624: INFO: Pod "pod-subpath-test-configmap-5cjr": Phase="Running", Reason="", readiness=true. Elapsed: 20.034181163s
Mar 25 09:44:11.627: INFO: Pod "pod-subpath-test-configmap-5cjr": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.037125784s
STEP: Saw pod success
Mar 25 09:44:11.627: INFO: Pod "pod-subpath-test-configmap-5cjr" satisfied condition "success or failure"
Mar 25 09:44:11.629: INFO: Trying to get logs from node ip-10-90-32-23.eu-west-2.compute.internal pod pod-subpath-test-configmap-5cjr container test-container-subpath-configmap-5cjr: <nil>
STEP: delete the pod
Mar 25 09:44:11.644: INFO: Waiting for pod pod-subpath-test-configmap-5cjr to disappear
Mar 25 09:44:11.647: INFO: Pod pod-subpath-test-configmap-5cjr no longer exists
STEP: Deleting pod pod-subpath-test-configmap-5cjr
Mar 25 09:44:11.647: INFO: Deleting pod "pod-subpath-test-configmap-5cjr" in namespace "subpath-8125"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 09:44:11.648: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-8125" for this suite.
Mar 25 09:44:17.659: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 09:44:17.725: INFO: namespace subpath-8125 deletion completed in 6.073595346s

• [SLOW TEST:28.279 seconds]
[sig-storage] Subpath
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 09:44:17.725: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-5520
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-secret-gz5j
STEP: Creating a pod to test atomic-volume-subpath
Mar 25 09:44:17.868: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-gz5j" in namespace "subpath-5520" to be "success or failure"
Mar 25 09:44:17.872: INFO: Pod "pod-subpath-test-secret-gz5j": Phase="Pending", Reason="", readiness=false. Elapsed: 3.622033ms
Mar 25 09:44:19.875: INFO: Pod "pod-subpath-test-secret-gz5j": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006542156s
Mar 25 09:44:21.878: INFO: Pod "pod-subpath-test-secret-gz5j": Phase="Running", Reason="", readiness=true. Elapsed: 4.009357042s
Mar 25 09:44:23.881: INFO: Pod "pod-subpath-test-secret-gz5j": Phase="Running", Reason="", readiness=true. Elapsed: 6.012448248s
Mar 25 09:44:25.884: INFO: Pod "pod-subpath-test-secret-gz5j": Phase="Running", Reason="", readiness=true. Elapsed: 8.015288233s
Mar 25 09:44:27.887: INFO: Pod "pod-subpath-test-secret-gz5j": Phase="Running", Reason="", readiness=true. Elapsed: 10.018146138s
Mar 25 09:44:29.890: INFO: Pod "pod-subpath-test-secret-gz5j": Phase="Running", Reason="", readiness=true. Elapsed: 12.021144825s
Mar 25 09:44:31.893: INFO: Pod "pod-subpath-test-secret-gz5j": Phase="Running", Reason="", readiness=true. Elapsed: 14.024036498s
Mar 25 09:44:33.896: INFO: Pod "pod-subpath-test-secret-gz5j": Phase="Running", Reason="", readiness=true. Elapsed: 16.027073212s
Mar 25 09:44:35.898: INFO: Pod "pod-subpath-test-secret-gz5j": Phase="Running", Reason="", readiness=true. Elapsed: 18.030013139s
Mar 25 09:44:37.902: INFO: Pod "pod-subpath-test-secret-gz5j": Phase="Running", Reason="", readiness=true. Elapsed: 20.033068649s
Mar 25 09:44:39.904: INFO: Pod "pod-subpath-test-secret-gz5j": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.035928284s
STEP: Saw pod success
Mar 25 09:44:39.904: INFO: Pod "pod-subpath-test-secret-gz5j" satisfied condition "success or failure"
Mar 25 09:44:39.906: INFO: Trying to get logs from node ip-10-90-32-23.eu-west-2.compute.internal pod pod-subpath-test-secret-gz5j container test-container-subpath-secret-gz5j: <nil>
STEP: delete the pod
Mar 25 09:44:39.923: INFO: Waiting for pod pod-subpath-test-secret-gz5j to disappear
Mar 25 09:44:39.926: INFO: Pod pod-subpath-test-secret-gz5j no longer exists
STEP: Deleting pod pod-subpath-test-secret-gz5j
Mar 25 09:44:39.926: INFO: Deleting pod "pod-subpath-test-secret-gz5j" in namespace "subpath-5520"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 09:44:39.928: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-5520" for this suite.
Mar 25 09:44:45.941: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 09:44:46.009: INFO: namespace subpath-5520 deletion completed in 6.078682515s

• [SLOW TEST:28.284 seconds]
[sig-storage] Subpath
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with secret pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 09:44:46.010: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-8466
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0666 on node default medium
Mar 25 09:44:46.147: INFO: Waiting up to 5m0s for pod "pod-fd99bf09-b83e-4800-b76d-b6e24327ec42" in namespace "emptydir-8466" to be "success or failure"
Mar 25 09:44:46.150: INFO: Pod "pod-fd99bf09-b83e-4800-b76d-b6e24327ec42": Phase="Pending", Reason="", readiness=false. Elapsed: 3.597798ms
Mar 25 09:44:48.153: INFO: Pod "pod-fd99bf09-b83e-4800-b76d-b6e24327ec42": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006643703s
Mar 25 09:44:50.157: INFO: Pod "pod-fd99bf09-b83e-4800-b76d-b6e24327ec42": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009799477s
STEP: Saw pod success
Mar 25 09:44:50.157: INFO: Pod "pod-fd99bf09-b83e-4800-b76d-b6e24327ec42" satisfied condition "success or failure"
Mar 25 09:44:50.159: INFO: Trying to get logs from node ip-10-90-32-23.eu-west-2.compute.internal pod pod-fd99bf09-b83e-4800-b76d-b6e24327ec42 container test-container: <nil>
STEP: delete the pod
Mar 25 09:44:50.173: INFO: Waiting for pod pod-fd99bf09-b83e-4800-b76d-b6e24327ec42 to disappear
Mar 25 09:44:50.175: INFO: Pod pod-fd99bf09-b83e-4800-b76d-b6e24327ec42 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 09:44:50.175: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8466" for this suite.
Mar 25 09:44:56.186: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 09:44:56.255: INFO: namespace emptydir-8466 deletion completed in 6.076790999s

• [SLOW TEST:10.245 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 09:44:56.255: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2012
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Mar 25 09:44:56.393: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c51a7424-6460-4e90-acb2-904eb455696f" in namespace "projected-2012" to be "success or failure"
Mar 25 09:44:56.401: INFO: Pod "downwardapi-volume-c51a7424-6460-4e90-acb2-904eb455696f": Phase="Pending", Reason="", readiness=false. Elapsed: 7.825827ms
Mar 25 09:44:58.404: INFO: Pod "downwardapi-volume-c51a7424-6460-4e90-acb2-904eb455696f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010739595s
STEP: Saw pod success
Mar 25 09:44:58.404: INFO: Pod "downwardapi-volume-c51a7424-6460-4e90-acb2-904eb455696f" satisfied condition "success or failure"
Mar 25 09:44:58.406: INFO: Trying to get logs from node ip-10-90-32-23.eu-west-2.compute.internal pod downwardapi-volume-c51a7424-6460-4e90-acb2-904eb455696f container client-container: <nil>
STEP: delete the pod
Mar 25 09:44:58.420: INFO: Waiting for pod downwardapi-volume-c51a7424-6460-4e90-acb2-904eb455696f to disappear
Mar 25 09:44:58.423: INFO: Pod downwardapi-volume-c51a7424-6460-4e90-acb2-904eb455696f no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 09:44:58.423: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2012" for this suite.
Mar 25 09:45:04.434: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 09:45:04.507: INFO: namespace projected-2012 deletion completed in 6.081480121s

• [SLOW TEST:8.252 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 09:45:04.507: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-9547
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-9547.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-9547.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-9547.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-9547.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-9547.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-9547.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe /etc/hosts
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Mar 25 09:45:06.681: INFO: DNS probes using dns-9547/dns-test-c9266cbc-f5e2-4125-afe9-e35cf8403d0f succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 09:45:06.691: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-9547" for this suite.
Mar 25 09:45:12.703: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 09:45:12.766: INFO: namespace dns-9547 deletion completed in 6.072514232s

• [SLOW TEST:8.259 seconds]
[sig-network] DNS
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 09:45:12.767: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-2677
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod test-webserver-c841bc86-d847-4da2-84a4-f9dd8db272a1 in namespace container-probe-2677
Mar 25 09:45:14.920: INFO: Started pod test-webserver-c841bc86-d847-4da2-84a4-f9dd8db272a1 in namespace container-probe-2677
STEP: checking the pod's current state and verifying that restartCount is present
Mar 25 09:45:14.922: INFO: Initial restart count of pod test-webserver-c841bc86-d847-4da2-84a4-f9dd8db272a1 is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 09:49:15.305: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-2677" for this suite.
Mar 25 09:49:21.319: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 09:49:21.384: INFO: namespace container-probe-2677 deletion completed in 6.075351987s

• [SLOW TEST:248.617 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 09:49:21.385: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-574
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-1508ee34-7986-42a3-9385-a8405269995f
STEP: Creating a pod to test consume secrets
Mar 25 09:49:21.530: INFO: Waiting up to 5m0s for pod "pod-secrets-6cb77b49-0c03-40dc-8f5e-d9f5a859cfc1" in namespace "secrets-574" to be "success or failure"
Mar 25 09:49:21.532: INFO: Pod "pod-secrets-6cb77b49-0c03-40dc-8f5e-d9f5a859cfc1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.336937ms
Mar 25 09:49:23.535: INFO: Pod "pod-secrets-6cb77b49-0c03-40dc-8f5e-d9f5a859cfc1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005415499s
STEP: Saw pod success
Mar 25 09:49:23.535: INFO: Pod "pod-secrets-6cb77b49-0c03-40dc-8f5e-d9f5a859cfc1" satisfied condition "success or failure"
Mar 25 09:49:23.537: INFO: Trying to get logs from node ip-10-90-32-23.eu-west-2.compute.internal pod pod-secrets-6cb77b49-0c03-40dc-8f5e-d9f5a859cfc1 container secret-volume-test: <nil>
STEP: delete the pod
Mar 25 09:49:23.553: INFO: Waiting for pod pod-secrets-6cb77b49-0c03-40dc-8f5e-d9f5a859cfc1 to disappear
Mar 25 09:49:23.555: INFO: Pod pod-secrets-6cb77b49-0c03-40dc-8f5e-d9f5a859cfc1 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 09:49:23.555: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-574" for this suite.
Mar 25 09:49:29.565: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 09:49:29.644: INFO: namespace secrets-574 deletion completed in 6.086757535s

• [SLOW TEST:8.259 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 09:49:29.644: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-3340
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1456
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Mar 25 09:49:29.775: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=kubectl-3340'
Mar 25 09:49:29.852: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Mar 25 09:49:29.852: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: verifying the pod controlled by rc e2e-test-nginx-rc was created
STEP: confirm that you can get logs from an rc
Mar 25 09:49:29.871: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-lwfkf]
Mar 25 09:49:29.871: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-lwfkf" in namespace "kubectl-3340" to be "running and ready"
Mar 25 09:49:29.874: INFO: Pod "e2e-test-nginx-rc-lwfkf": Phase="Pending", Reason="", readiness=false. Elapsed: 3.290416ms
Mar 25 09:49:31.877: INFO: Pod "e2e-test-nginx-rc-lwfkf": Phase="Running", Reason="", readiness=true. Elapsed: 2.0062006s
Mar 25 09:49:31.877: INFO: Pod "e2e-test-nginx-rc-lwfkf" satisfied condition "running and ready"
Mar 25 09:49:31.877: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-lwfkf]
Mar 25 09:49:31.877: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 logs rc/e2e-test-nginx-rc --namespace=kubectl-3340'
Mar 25 09:49:31.971: INFO: stderr: ""
Mar 25 09:49:31.971: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1461
Mar 25 09:49:31.971: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 delete rc e2e-test-nginx-rc --namespace=kubectl-3340'
Mar 25 09:49:32.042: INFO: stderr: ""
Mar 25 09:49:32.042: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 09:49:32.042: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3340" for this suite.
Mar 25 09:49:54.058: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 09:49:54.133: INFO: namespace kubectl-3340 deletion completed in 22.086882197s

• [SLOW TEST:24.489 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run rc
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 09:49:54.134: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7912
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Mar 25 09:49:54.273: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f084e52d-b348-42ad-b803-94c019a1ccff" in namespace "projected-7912" to be "success or failure"
Mar 25 09:49:54.279: INFO: Pod "downwardapi-volume-f084e52d-b348-42ad-b803-94c019a1ccff": Phase="Pending", Reason="", readiness=false. Elapsed: 5.826444ms
Mar 25 09:49:56.282: INFO: Pod "downwardapi-volume-f084e52d-b348-42ad-b803-94c019a1ccff": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009201559s
STEP: Saw pod success
Mar 25 09:49:56.282: INFO: Pod "downwardapi-volume-f084e52d-b348-42ad-b803-94c019a1ccff" satisfied condition "success or failure"
Mar 25 09:49:56.284: INFO: Trying to get logs from node ip-10-90-32-23.eu-west-2.compute.internal pod downwardapi-volume-f084e52d-b348-42ad-b803-94c019a1ccff container client-container: <nil>
STEP: delete the pod
Mar 25 09:49:56.301: INFO: Waiting for pod downwardapi-volume-f084e52d-b348-42ad-b803-94c019a1ccff to disappear
Mar 25 09:49:56.303: INFO: Pod downwardapi-volume-f084e52d-b348-42ad-b803-94c019a1ccff no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 09:49:56.303: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7912" for this suite.
Mar 25 09:50:02.314: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 09:50:02.388: INFO: namespace projected-7912 deletion completed in 6.082852827s

• [SLOW TEST:8.255 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 09:50:02.389: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-wrapper-256
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 09:50:04.562: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-256" for this suite.
Mar 25 09:50:10.574: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 09:50:10.643: INFO: namespace emptydir-wrapper-256 deletion completed in 6.077104939s

• [SLOW TEST:8.254 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not conflict [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 09:50:10.643: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-8582
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating secret secrets-8582/secret-test-5f68c4b4-7254-4328-9a7f-c88b6103211c
STEP: Creating a pod to test consume secrets
Mar 25 09:50:10.784: INFO: Waiting up to 5m0s for pod "pod-configmaps-759e355b-e578-45e5-a3dd-2ba9b3f82a32" in namespace "secrets-8582" to be "success or failure"
Mar 25 09:50:10.786: INFO: Pod "pod-configmaps-759e355b-e578-45e5-a3dd-2ba9b3f82a32": Phase="Pending", Reason="", readiness=false. Elapsed: 2.375521ms
Mar 25 09:50:12.789: INFO: Pod "pod-configmaps-759e355b-e578-45e5-a3dd-2ba9b3f82a32": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005075668s
STEP: Saw pod success
Mar 25 09:50:12.789: INFO: Pod "pod-configmaps-759e355b-e578-45e5-a3dd-2ba9b3f82a32" satisfied condition "success or failure"
Mar 25 09:50:12.791: INFO: Trying to get logs from node ip-10-90-32-23.eu-west-2.compute.internal pod pod-configmaps-759e355b-e578-45e5-a3dd-2ba9b3f82a32 container env-test: <nil>
STEP: delete the pod
Mar 25 09:50:12.812: INFO: Waiting for pod pod-configmaps-759e355b-e578-45e5-a3dd-2ba9b3f82a32 to disappear
Mar 25 09:50:12.814: INFO: Pod pod-configmaps-759e355b-e578-45e5-a3dd-2ba9b3f82a32 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 09:50:12.814: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8582" for this suite.
Mar 25 09:50:18.825: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 09:50:18.899: INFO: namespace secrets-8582 deletion completed in 6.082563274s

• [SLOW TEST:8.256 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 09:50:18.900: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-749
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-map-e0b08d08-9d61-49f0-97c7-6d43f4fdec1d
STEP: Creating a pod to test consume configMaps
Mar 25 09:50:19.041: INFO: Waiting up to 5m0s for pod "pod-configmaps-5677ed4a-b22e-4d4a-8217-650ee7f22d88" in namespace "configmap-749" to be "success or failure"
Mar 25 09:50:19.048: INFO: Pod "pod-configmaps-5677ed4a-b22e-4d4a-8217-650ee7f22d88": Phase="Pending", Reason="", readiness=false. Elapsed: 6.74139ms
Mar 25 09:50:21.051: INFO: Pod "pod-configmaps-5677ed4a-b22e-4d4a-8217-650ee7f22d88": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009827299s
STEP: Saw pod success
Mar 25 09:50:21.051: INFO: Pod "pod-configmaps-5677ed4a-b22e-4d4a-8217-650ee7f22d88" satisfied condition "success or failure"
Mar 25 09:50:21.053: INFO: Trying to get logs from node ip-10-90-32-23.eu-west-2.compute.internal pod pod-configmaps-5677ed4a-b22e-4d4a-8217-650ee7f22d88 container configmap-volume-test: <nil>
STEP: delete the pod
Mar 25 09:50:21.072: INFO: Waiting for pod pod-configmaps-5677ed4a-b22e-4d4a-8217-650ee7f22d88 to disappear
Mar 25 09:50:21.074: INFO: Pod pod-configmaps-5677ed4a-b22e-4d4a-8217-650ee7f22d88 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 09:50:21.074: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-749" for this suite.
Mar 25 09:50:27.085: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 09:50:27.154: INFO: namespace configmap-749 deletion completed in 6.077026598s

• [SLOW TEST:8.254 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 09:50:27.154: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-4718
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating replication controller my-hostname-basic-1199fb68-72cb-4f35-9616-494fb234690a
Mar 25 09:50:27.294: INFO: Pod name my-hostname-basic-1199fb68-72cb-4f35-9616-494fb234690a: Found 0 pods out of 1
Mar 25 09:50:32.297: INFO: Pod name my-hostname-basic-1199fb68-72cb-4f35-9616-494fb234690a: Found 1 pods out of 1
Mar 25 09:50:32.297: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-1199fb68-72cb-4f35-9616-494fb234690a" are running
Mar 25 09:50:32.299: INFO: Pod "my-hostname-basic-1199fb68-72cb-4f35-9616-494fb234690a-zk2lh" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-03-25 09:50:27 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-03-25 09:50:29 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-03-25 09:50:29 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-03-25 09:50:27 +0000 UTC Reason: Message:}])
Mar 25 09:50:32.299: INFO: Trying to dial the pod
Mar 25 09:50:37.308: INFO: Controller my-hostname-basic-1199fb68-72cb-4f35-9616-494fb234690a: Got expected result from replica 1 [my-hostname-basic-1199fb68-72cb-4f35-9616-494fb234690a-zk2lh]: "my-hostname-basic-1199fb68-72cb-4f35-9616-494fb234690a-zk2lh", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 09:50:37.308: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-4718" for this suite.
Mar 25 09:50:43.320: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 09:50:43.391: INFO: namespace replication-controller-4718 deletion completed in 6.079905415s

• [SLOW TEST:16.236 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 09:50:43.391: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-428
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Mar 25 09:50:43.523: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 create -f - --namespace=kubectl-428'
Mar 25 09:50:43.672: INFO: stderr: ""
Mar 25 09:50:43.672: INFO: stdout: "replicationcontroller/redis-master created\n"
Mar 25 09:50:43.673: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 create -f - --namespace=kubectl-428'
Mar 25 09:50:43.828: INFO: stderr: ""
Mar 25 09:50:43.828: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Mar 25 09:50:44.831: INFO: Selector matched 1 pods for map[app:redis]
Mar 25 09:50:44.831: INFO: Found 0 / 1
Mar 25 09:50:45.831: INFO: Selector matched 1 pods for map[app:redis]
Mar 25 09:50:45.831: INFO: Found 1 / 1
Mar 25 09:50:45.831: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Mar 25 09:50:45.833: INFO: Selector matched 1 pods for map[app:redis]
Mar 25 09:50:45.833: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Mar 25 09:50:45.833: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 describe pod redis-master-2vxms --namespace=kubectl-428'
Mar 25 09:50:45.912: INFO: stderr: ""
Mar 25 09:50:45.912: INFO: stdout: "Name:           redis-master-2vxms\nNamespace:      kubectl-428\nPriority:       0\nNode:           ip-10-90-32-23.eu-west-2.compute.internal/10.90.32.23\nStart Time:     Wed, 25 Mar 2020 09:50:43 +0000\nLabels:         app=redis\n                role=master\nAnnotations:    <none>\nStatus:         Running\nIP:             10.200.96.145\nControlled By:  ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   docker://c06b81424b33bae211fba9ca715c00fbe87e4999e38db8904353e03e96e0f484\n    Image:          gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Image ID:       docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Wed, 25 Mar 2020 09:50:44 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-jkrx2 (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-jkrx2:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-jkrx2\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age   From                                                Message\n  ----    ------     ----  ----                                                -------\n  Normal  Scheduled  2s    default-scheduler                                   Successfully assigned kubectl-428/redis-master-2vxms to ip-10-90-32-23.eu-west-2.compute.internal\n  Normal  Pulled     1s    kubelet, ip-10-90-32-23.eu-west-2.compute.internal  Container image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\" already present on machine\n  Normal  Created    1s    kubelet, ip-10-90-32-23.eu-west-2.compute.internal  Created container redis-master\n  Normal  Started    1s    kubelet, ip-10-90-32-23.eu-west-2.compute.internal  Started container redis-master\n"
Mar 25 09:50:45.912: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 describe rc redis-master --namespace=kubectl-428'
Mar 25 09:50:45.992: INFO: stderr: ""
Mar 25 09:50:45.992: INFO: stdout: "Name:         redis-master\nNamespace:    kubectl-428\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  2s    replication-controller  Created pod: redis-master-2vxms\n"
Mar 25 09:50:45.992: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 describe service redis-master --namespace=kubectl-428'
Mar 25 09:50:46.065: INFO: stderr: ""
Mar 25 09:50:46.065: INFO: stdout: "Name:              redis-master\nNamespace:         kubectl-428\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                10.100.200.186\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         10.200.96.145:6379\nSession Affinity:  None\nEvents:            <none>\n"
Mar 25 09:50:46.068: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 describe node ip-10-90-32-22.eu-west-2.compute.internal'
Mar 25 09:50:46.155: INFO: stderr: ""
Mar 25 09:50:46.155: INFO: stdout: "Name:               ip-10-90-32-22.eu-west-2.compute.internal\nRoles:              <none>\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/instance-type=t2.large\n                    beta.kubernetes.io/os=linux\n                    bosh.id=4335990c-e929-424a-a665-735f10bd931b\n                    bosh.zone=z1\n                    failure-domain.beta.kubernetes.io/region=eu-west-2\n                    failure-domain.beta.kubernetes.io/zone=eu-west-2b\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=10.90.32.22\n                    kubernetes.io/os=linux\n                    spec.ip=10.90.32.22\nAnnotations:        node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Mon, 23 Mar 2020 08:46:09 +0000\nTaints:             <none>\nUnschedulable:      false\nConditions:\n  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----             ------  -----------------                 ------------------                ------                       -------\n  MemoryPressure   False   Wed, 25 Mar 2020 09:50:35 +0000   Mon, 23 Mar 2020 08:46:09 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure     False   Wed, 25 Mar 2020 09:50:35 +0000   Mon, 23 Mar 2020 08:46:09 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure      False   Wed, 25 Mar 2020 09:50:35 +0000   Mon, 23 Mar 2020 08:46:09 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready            True    Wed, 25 Mar 2020 09:50:35 +0000   Mon, 23 Mar 2020 08:46:09 +0000   KubeletReady                 kubelet is posting ready status. AppArmor enabled\nAddresses:\n  InternalIP:   10.90.32.22\n  Hostname:     10.90.32.22\n  InternalDNS:  ip-10-90-32-22\nCapacity:\n attachable-volumes-aws-ebs:  39\n cpu:                         2\n ephemeral-storage:           95041356Ki\n hugepages-2Mi:               0\n memory:                      8166336Ki\n pods:                        110\nAllocatable:\n attachable-volumes-aws-ebs:  39\n cpu:                         2\n ephemeral-storage:           87590113545\n hugepages-2Mi:               0\n memory:                      8063936Ki\n pods:                        110\nSystem Info:\n Machine ID:                 07247e0ac52118695e75f7c25c7b4c89\n System UUID:                EC2C7581-9CE6-36BD-1423-1828A914E054\n Boot ID:                    82ee264f-857a-4fc9-8fbc-0963da28d0db\n Kernel Version:             4.15.0-88-generic\n OS Image:                   Ubuntu 16.04.6 LTS\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  docker://18.9.9\n Kubelet Version:            v1.15.7\n Kube-Proxy Version:         v1.15.7\nProviderID:                  aws:///eu-west-2b/i-0ef9e2ef6da12e993\nNon-terminated Pods:         (6 in total)\n  Namespace                  Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                  ----                                                       ------------  ----------  ---------------  -------------  ---\n  heptio-sonobuoy            sonobuoy                                                   0 (0%)        0 (0%)      0 (0%)           0 (0%)         58m\n  heptio-sonobuoy            sonobuoy-systemd-logs-daemon-set-881e638473c24530-zhx7s    0 (0%)        0 (0%)      0 (0%)           0 (0%)         58m\n  kube-system                coredns-84c98f9bb6-jtxmm                                   100m (5%)     0 (0%)      70Mi (0%)        170Mi (2%)     2d\n  kube-system                filebeat-rfcxf                                             200m (10%)    0 (0%)      200Mi (2%)       400Mi (5%)     2d1h\n  kube-system                kubernetes-dashboard-84ffbc8546-bph6j                      50m (2%)      100m (5%)   100Mi (1%)       300Mi (3%)     2d1h\n  traefik-ingress            traefik-ingress-controller-d8npl                           0 (0%)        0 (0%)      0 (0%)           0 (0%)         2d\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource                    Requests    Limits\n  --------                    --------    ------\n  cpu                         350m (17%)  100m (5%)\n  memory                      370Mi (4%)  870Mi (11%)\n  ephemeral-storage           0 (0%)      0 (0%)\n  attachable-volumes-aws-ebs  0           0\nEvents:                       <none>\n"
Mar 25 09:50:46.155: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 describe namespace kubectl-428'
Mar 25 09:50:46.227: INFO: stderr: ""
Mar 25 09:50:46.227: INFO: stdout: "Name:         kubectl-428\nLabels:       e2e-framework=kubectl\n              e2e-run=f49af86e-17ad-4574-9850-f11a88690abd\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 09:50:46.227: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-428" for this suite.
Mar 25 09:51:08.238: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 09:51:08.307: INFO: namespace kubectl-428 deletion completed in 22.076663924s

• [SLOW TEST:24.916 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl describe
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 09:51:08.307: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-805
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-3b238bb8-abf9-4679-9c58-906855a79477
STEP: Creating a pod to test consume secrets
Mar 25 09:51:08.449: INFO: Waiting up to 5m0s for pod "pod-secrets-1ecbe696-e2a8-493c-9587-322dc0084cc4" in namespace "secrets-805" to be "success or failure"
Mar 25 09:51:08.460: INFO: Pod "pod-secrets-1ecbe696-e2a8-493c-9587-322dc0084cc4": Phase="Pending", Reason="", readiness=false. Elapsed: 10.947683ms
Mar 25 09:51:10.463: INFO: Pod "pod-secrets-1ecbe696-e2a8-493c-9587-322dc0084cc4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013960792s
STEP: Saw pod success
Mar 25 09:51:10.463: INFO: Pod "pod-secrets-1ecbe696-e2a8-493c-9587-322dc0084cc4" satisfied condition "success or failure"
Mar 25 09:51:10.465: INFO: Trying to get logs from node ip-10-90-32-23.eu-west-2.compute.internal pod pod-secrets-1ecbe696-e2a8-493c-9587-322dc0084cc4 container secret-volume-test: <nil>
STEP: delete the pod
Mar 25 09:51:10.480: INFO: Waiting for pod pod-secrets-1ecbe696-e2a8-493c-9587-322dc0084cc4 to disappear
Mar 25 09:51:10.482: INFO: Pod pod-secrets-1ecbe696-e2a8-493c-9587-322dc0084cc4 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 09:51:10.482: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-805" for this suite.
Mar 25 09:51:16.493: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 09:51:16.564: INFO: namespace secrets-805 deletion completed in 6.079377684s

• [SLOW TEST:8.257 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-network] DNS 
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 09:51:16.564: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-6554
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a test externalName service
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-6554.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-6554.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-6554.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-6554.svc.cluster.local; sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Mar 25 09:51:20.724: INFO: DNS probes using dns-test-6a0fcf06-6feb-4e03-b234-ce9e32baf06e succeeded

STEP: deleting the pod
STEP: changing the externalName to bar.example.com
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-6554.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-6554.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-6554.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-6554.svc.cluster.local; sleep 1; done

STEP: creating a second pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Mar 25 09:51:24.770: INFO: DNS probes using dns-test-ca89afb6-224f-46c4-952c-1a13728a285a succeeded

STEP: deleting the pod
STEP: changing the service to type=ClusterIP
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-6554.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-6554.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-6554.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-6554.svc.cluster.local; sleep 1; done

STEP: creating a third pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Mar 25 09:51:28.816: INFO: DNS probes using dns-test-4c1b5f1a-e1e2-4c32-ba1e-3727bfe788e6 succeeded

STEP: deleting the pod
STEP: deleting the test externalName service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 09:51:28.844: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-6554" for this suite.
Mar 25 09:51:34.855: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 09:51:34.931: INFO: namespace dns-6554 deletion completed in 6.083946788s

• [SLOW TEST:18.366 seconds]
[sig-network] DNS
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 09:51:34.931: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-6773
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-upd-125ee8ee-e726-4963-86ff-a32c7e190899
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 09:51:39.101: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6773" for this suite.
Mar 25 09:52:01.112: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 09:52:01.178: INFO: namespace configmap-6773 deletion completed in 22.074614993s

• [SLOW TEST:26.247 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] version v1
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 09:52:01.178: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-4885
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-b6gjp in namespace proxy-4885
I0325 09:52:01.335712      16 runners.go:180] Created replication controller with name: proxy-service-b6gjp, namespace: proxy-4885, replica count: 1
I0325 09:52:02.386371      16 runners.go:180] proxy-service-b6gjp Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0325 09:52:03.386721      16 runners.go:180] proxy-service-b6gjp Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0325 09:52:04.387019      16 runners.go:180] proxy-service-b6gjp Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0325 09:52:05.387299      16 runners.go:180] proxy-service-b6gjp Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0325 09:52:06.387595      16 runners.go:180] proxy-service-b6gjp Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0325 09:52:07.387859      16 runners.go:180] proxy-service-b6gjp Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0325 09:52:08.388100      16 runners.go:180] proxy-service-b6gjp Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0325 09:52:09.388382      16 runners.go:180] proxy-service-b6gjp Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Mar 25 09:52:09.391: INFO: setup took 8.071615114s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Mar 25 09:52:09.417: INFO: (0) /api/v1/namespaces/proxy-4885/pods/proxy-service-b6gjp-x86nh:1080/proxy/: <a href="/api/v1/namespaces/proxy-4885/pods/proxy-service-b6gjp-x86nh:1080/proxy/rewriteme">test<... (200; 25.811477ms)
Mar 25 09:52:09.417: INFO: (0) /api/v1/namespaces/proxy-4885/pods/proxy-service-b6gjp-x86nh/proxy/: <a href="/api/v1/namespaces/proxy-4885/pods/proxy-service-b6gjp-x86nh/proxy/rewriteme">test</a> (200; 25.649627ms)
Mar 25 09:52:09.417: INFO: (0) /api/v1/namespaces/proxy-4885/pods/proxy-service-b6gjp-x86nh:160/proxy/: foo (200; 25.659756ms)
Mar 25 09:52:09.420: INFO: (0) /api/v1/namespaces/proxy-4885/pods/http:proxy-service-b6gjp-x86nh:160/proxy/: foo (200; 28.870413ms)
Mar 25 09:52:09.420: INFO: (0) /api/v1/namespaces/proxy-4885/services/http:proxy-service-b6gjp:portname2/proxy/: bar (200; 29.107367ms)
Mar 25 09:52:09.420: INFO: (0) /api/v1/namespaces/proxy-4885/services/http:proxy-service-b6gjp:portname1/proxy/: foo (200; 28.936126ms)
Mar 25 09:52:09.420: INFO: (0) /api/v1/namespaces/proxy-4885/services/proxy-service-b6gjp:portname2/proxy/: bar (200; 28.56963ms)
Mar 25 09:52:09.420: INFO: (0) /api/v1/namespaces/proxy-4885/pods/http:proxy-service-b6gjp-x86nh:1080/proxy/: <a href="/api/v1/namespaces/proxy-4885/pods/http:proxy-service-b6gjp-x86nh:1080/proxy/rewriteme">... (200; 28.903789ms)
Mar 25 09:52:09.420: INFO: (0) /api/v1/namespaces/proxy-4885/pods/proxy-service-b6gjp-x86nh:162/proxy/: bar (200; 29.168748ms)
Mar 25 09:52:09.420: INFO: (0) /api/v1/namespaces/proxy-4885/pods/http:proxy-service-b6gjp-x86nh:162/proxy/: bar (200; 29.036505ms)
Mar 25 09:52:09.424: INFO: (0) /api/v1/namespaces/proxy-4885/pods/https:proxy-service-b6gjp-x86nh:462/proxy/: tls qux (200; 32.985652ms)
Mar 25 09:52:09.424: INFO: (0) /api/v1/namespaces/proxy-4885/services/proxy-service-b6gjp:portname1/proxy/: foo (200; 33.272276ms)
Mar 25 09:52:09.424: INFO: (0) /api/v1/namespaces/proxy-4885/services/https:proxy-service-b6gjp:tlsportname1/proxy/: tls baz (200; 33.706038ms)
Mar 25 09:52:09.424: INFO: (0) /api/v1/namespaces/proxy-4885/pods/https:proxy-service-b6gjp-x86nh:460/proxy/: tls baz (200; 33.498551ms)
Mar 25 09:52:09.425: INFO: (0) /api/v1/namespaces/proxy-4885/services/https:proxy-service-b6gjp:tlsportname2/proxy/: tls qux (200; 34.117353ms)
Mar 25 09:52:09.426: INFO: (0) /api/v1/namespaces/proxy-4885/pods/https:proxy-service-b6gjp-x86nh:443/proxy/: <a href="/api/v1/namespaces/proxy-4885/pods/https:proxy-service-b6gjp-x86nh:443/proxy/tlsrewritem... (200; 34.853324ms)
Mar 25 09:52:09.434: INFO: (1) /api/v1/namespaces/proxy-4885/pods/http:proxy-service-b6gjp-x86nh:1080/proxy/: <a href="/api/v1/namespaces/proxy-4885/pods/http:proxy-service-b6gjp-x86nh:1080/proxy/rewriteme">... (200; 8.143455ms)
Mar 25 09:52:09.440: INFO: (1) /api/v1/namespaces/proxy-4885/pods/proxy-service-b6gjp-x86nh:160/proxy/: foo (200; 13.798241ms)
Mar 25 09:52:09.440: INFO: (1) /api/v1/namespaces/proxy-4885/pods/http:proxy-service-b6gjp-x86nh:162/proxy/: bar (200; 13.870964ms)
Mar 25 09:52:09.440: INFO: (1) /api/v1/namespaces/proxy-4885/pods/http:proxy-service-b6gjp-x86nh:160/proxy/: foo (200; 13.915128ms)
Mar 25 09:52:09.440: INFO: (1) /api/v1/namespaces/proxy-4885/pods/https:proxy-service-b6gjp-x86nh:443/proxy/: <a href="/api/v1/namespaces/proxy-4885/pods/https:proxy-service-b6gjp-x86nh:443/proxy/tlsrewritem... (200; 14.249305ms)
Mar 25 09:52:09.440: INFO: (1) /api/v1/namespaces/proxy-4885/pods/proxy-service-b6gjp-x86nh:162/proxy/: bar (200; 14.087062ms)
Mar 25 09:52:09.444: INFO: (1) /api/v1/namespaces/proxy-4885/pods/proxy-service-b6gjp-x86nh:1080/proxy/: <a href="/api/v1/namespaces/proxy-4885/pods/proxy-service-b6gjp-x86nh:1080/proxy/rewriteme">test<... (200; 17.451854ms)
Mar 25 09:52:09.444: INFO: (1) /api/v1/namespaces/proxy-4885/pods/https:proxy-service-b6gjp-x86nh:460/proxy/: tls baz (200; 17.546861ms)
Mar 25 09:52:09.445: INFO: (1) /api/v1/namespaces/proxy-4885/pods/proxy-service-b6gjp-x86nh/proxy/: <a href="/api/v1/namespaces/proxy-4885/pods/proxy-service-b6gjp-x86nh/proxy/rewriteme">test</a> (200; 18.840418ms)
Mar 25 09:52:09.445: INFO: (1) /api/v1/namespaces/proxy-4885/pods/https:proxy-service-b6gjp-x86nh:462/proxy/: tls qux (200; 19.027174ms)
Mar 25 09:52:09.446: INFO: (1) /api/v1/namespaces/proxy-4885/services/https:proxy-service-b6gjp:tlsportname2/proxy/: tls qux (200; 19.248283ms)
Mar 25 09:52:09.447: INFO: (1) /api/v1/namespaces/proxy-4885/services/http:proxy-service-b6gjp:portname2/proxy/: bar (200; 20.413811ms)
Mar 25 09:52:09.447: INFO: (1) /api/v1/namespaces/proxy-4885/services/https:proxy-service-b6gjp:tlsportname1/proxy/: tls baz (200; 20.673026ms)
Mar 25 09:52:09.447: INFO: (1) /api/v1/namespaces/proxy-4885/services/http:proxy-service-b6gjp:portname1/proxy/: foo (200; 20.644461ms)
Mar 25 09:52:09.447: INFO: (1) /api/v1/namespaces/proxy-4885/services/proxy-service-b6gjp:portname2/proxy/: bar (200; 20.467839ms)
Mar 25 09:52:09.447: INFO: (1) /api/v1/namespaces/proxy-4885/services/proxy-service-b6gjp:portname1/proxy/: foo (200; 20.921782ms)
Mar 25 09:52:09.463: INFO: (2) /api/v1/namespaces/proxy-4885/pods/proxy-service-b6gjp-x86nh/proxy/: <a href="/api/v1/namespaces/proxy-4885/pods/proxy-service-b6gjp-x86nh/proxy/rewriteme">test</a> (200; 15.884563ms)
Mar 25 09:52:09.468: INFO: (2) /api/v1/namespaces/proxy-4885/pods/http:proxy-service-b6gjp-x86nh:1080/proxy/: <a href="/api/v1/namespaces/proxy-4885/pods/http:proxy-service-b6gjp-x86nh:1080/proxy/rewriteme">... (200; 20.302328ms)
Mar 25 09:52:09.469: INFO: (2) /api/v1/namespaces/proxy-4885/pods/http:proxy-service-b6gjp-x86nh:160/proxy/: foo (200; 21.522287ms)
Mar 25 09:52:09.469: INFO: (2) /api/v1/namespaces/proxy-4885/pods/proxy-service-b6gjp-x86nh:1080/proxy/: <a href="/api/v1/namespaces/proxy-4885/pods/proxy-service-b6gjp-x86nh:1080/proxy/rewriteme">test<... (200; 21.432989ms)
Mar 25 09:52:09.469: INFO: (2) /api/v1/namespaces/proxy-4885/pods/proxy-service-b6gjp-x86nh:160/proxy/: foo (200; 21.221331ms)
Mar 25 09:52:09.469: INFO: (2) /api/v1/namespaces/proxy-4885/pods/http:proxy-service-b6gjp-x86nh:162/proxy/: bar (200; 21.37929ms)
Mar 25 09:52:09.473: INFO: (2) /api/v1/namespaces/proxy-4885/pods/https:proxy-service-b6gjp-x86nh:462/proxy/: tls qux (200; 25.514592ms)
Mar 25 09:52:09.473: INFO: (2) /api/v1/namespaces/proxy-4885/pods/https:proxy-service-b6gjp-x86nh:443/proxy/: <a href="/api/v1/namespaces/proxy-4885/pods/https:proxy-service-b6gjp-x86nh:443/proxy/tlsrewritem... (200; 25.710132ms)
Mar 25 09:52:09.473: INFO: (2) /api/v1/namespaces/proxy-4885/services/https:proxy-service-b6gjp:tlsportname1/proxy/: tls baz (200; 25.86346ms)
Mar 25 09:52:09.473: INFO: (2) /api/v1/namespaces/proxy-4885/pods/https:proxy-service-b6gjp-x86nh:460/proxy/: tls baz (200; 25.710359ms)
Mar 25 09:52:09.473: INFO: (2) /api/v1/namespaces/proxy-4885/services/http:proxy-service-b6gjp:portname2/proxy/: bar (200; 25.748705ms)
Mar 25 09:52:09.473: INFO: (2) /api/v1/namespaces/proxy-4885/pods/proxy-service-b6gjp-x86nh:162/proxy/: bar (200; 25.789051ms)
Mar 25 09:52:09.474: INFO: (2) /api/v1/namespaces/proxy-4885/services/proxy-service-b6gjp:portname1/proxy/: foo (200; 26.854752ms)
Mar 25 09:52:09.475: INFO: (2) /api/v1/namespaces/proxy-4885/services/proxy-service-b6gjp:portname2/proxy/: bar (200; 27.105907ms)
Mar 25 09:52:09.475: INFO: (2) /api/v1/namespaces/proxy-4885/services/https:proxy-service-b6gjp:tlsportname2/proxy/: tls qux (200; 27.075432ms)
Mar 25 09:52:09.475: INFO: (2) /api/v1/namespaces/proxy-4885/services/http:proxy-service-b6gjp:portname1/proxy/: foo (200; 27.537768ms)
Mar 25 09:52:09.485: INFO: (3) /api/v1/namespaces/proxy-4885/pods/http:proxy-service-b6gjp-x86nh:160/proxy/: foo (200; 10.376642ms)
Mar 25 09:52:09.495: INFO: (3) /api/v1/namespaces/proxy-4885/pods/https:proxy-service-b6gjp-x86nh:462/proxy/: tls qux (200; 19.874557ms)
Mar 25 09:52:09.495: INFO: (3) /api/v1/namespaces/proxy-4885/pods/http:proxy-service-b6gjp-x86nh:1080/proxy/: <a href="/api/v1/namespaces/proxy-4885/pods/http:proxy-service-b6gjp-x86nh:1080/proxy/rewriteme">... (200; 20.121954ms)
Mar 25 09:52:09.495: INFO: (3) /api/v1/namespaces/proxy-4885/pods/proxy-service-b6gjp-x86nh:160/proxy/: foo (200; 20.16313ms)
Mar 25 09:52:09.496: INFO: (3) /api/v1/namespaces/proxy-4885/pods/https:proxy-service-b6gjp-x86nh:443/proxy/: <a href="/api/v1/namespaces/proxy-4885/pods/https:proxy-service-b6gjp-x86nh:443/proxy/tlsrewritem... (200; 20.138072ms)
Mar 25 09:52:09.496: INFO: (3) /api/v1/namespaces/proxy-4885/pods/proxy-service-b6gjp-x86nh:1080/proxy/: <a href="/api/v1/namespaces/proxy-4885/pods/proxy-service-b6gjp-x86nh:1080/proxy/rewriteme">test<... (200; 20.552769ms)
Mar 25 09:52:09.496: INFO: (3) /api/v1/namespaces/proxy-4885/pods/proxy-service-b6gjp-x86nh/proxy/: <a href="/api/v1/namespaces/proxy-4885/pods/proxy-service-b6gjp-x86nh/proxy/rewriteme">test</a> (200; 20.450616ms)
Mar 25 09:52:09.496: INFO: (3) /api/v1/namespaces/proxy-4885/pods/http:proxy-service-b6gjp-x86nh:162/proxy/: bar (200; 20.767773ms)
Mar 25 09:52:09.496: INFO: (3) /api/v1/namespaces/proxy-4885/pods/https:proxy-service-b6gjp-x86nh:460/proxy/: tls baz (200; 20.32268ms)
Mar 25 09:52:09.496: INFO: (3) /api/v1/namespaces/proxy-4885/pods/proxy-service-b6gjp-x86nh:162/proxy/: bar (200; 20.899767ms)
Mar 25 09:52:09.497: INFO: (3) /api/v1/namespaces/proxy-4885/services/http:proxy-service-b6gjp:portname1/proxy/: foo (200; 22.088685ms)
Mar 25 09:52:09.497: INFO: (3) /api/v1/namespaces/proxy-4885/services/https:proxy-service-b6gjp:tlsportname2/proxy/: tls qux (200; 22.176713ms)
Mar 25 09:52:09.497: INFO: (3) /api/v1/namespaces/proxy-4885/services/http:proxy-service-b6gjp:portname2/proxy/: bar (200; 22.061508ms)
Mar 25 09:52:09.497: INFO: (3) /api/v1/namespaces/proxy-4885/services/proxy-service-b6gjp:portname1/proxy/: foo (200; 22.0628ms)
Mar 25 09:52:09.498: INFO: (3) /api/v1/namespaces/proxy-4885/services/https:proxy-service-b6gjp:tlsportname1/proxy/: tls baz (200; 22.19759ms)
Mar 25 09:52:09.498: INFO: (3) /api/v1/namespaces/proxy-4885/services/proxy-service-b6gjp:portname2/proxy/: bar (200; 22.55376ms)
Mar 25 09:52:09.508: INFO: (4) /api/v1/namespaces/proxy-4885/pods/https:proxy-service-b6gjp-x86nh:443/proxy/: <a href="/api/v1/namespaces/proxy-4885/pods/https:proxy-service-b6gjp-x86nh:443/proxy/tlsrewritem... (200; 9.831171ms)
Mar 25 09:52:09.516: INFO: (4) /api/v1/namespaces/proxy-4885/pods/http:proxy-service-b6gjp-x86nh:1080/proxy/: <a href="/api/v1/namespaces/proxy-4885/pods/http:proxy-service-b6gjp-x86nh:1080/proxy/rewriteme">... (200; 17.02378ms)
Mar 25 09:52:09.516: INFO: (4) /api/v1/namespaces/proxy-4885/pods/http:proxy-service-b6gjp-x86nh:160/proxy/: foo (200; 16.698176ms)
Mar 25 09:52:09.516: INFO: (4) /api/v1/namespaces/proxy-4885/pods/https:proxy-service-b6gjp-x86nh:460/proxy/: tls baz (200; 17.506565ms)
Mar 25 09:52:09.516: INFO: (4) /api/v1/namespaces/proxy-4885/pods/proxy-service-b6gjp-x86nh/proxy/: <a href="/api/v1/namespaces/proxy-4885/pods/proxy-service-b6gjp-x86nh/proxy/rewriteme">test</a> (200; 17.235801ms)
Mar 25 09:52:09.516: INFO: (4) /api/v1/namespaces/proxy-4885/pods/proxy-service-b6gjp-x86nh:1080/proxy/: <a href="/api/v1/namespaces/proxy-4885/pods/proxy-service-b6gjp-x86nh:1080/proxy/rewriteme">test<... (200; 16.672437ms)
Mar 25 09:52:09.516: INFO: (4) /api/v1/namespaces/proxy-4885/pods/https:proxy-service-b6gjp-x86nh:462/proxy/: tls qux (200; 17.388128ms)
Mar 25 09:52:09.525: INFO: (4) /api/v1/namespaces/proxy-4885/services/proxy-service-b6gjp:portname1/proxy/: foo (200; 26.60254ms)
Mar 25 09:52:09.525: INFO: (4) /api/v1/namespaces/proxy-4885/services/proxy-service-b6gjp:portname2/proxy/: bar (200; 26.287854ms)
Mar 25 09:52:09.525: INFO: (4) /api/v1/namespaces/proxy-4885/pods/http:proxy-service-b6gjp-x86nh:162/proxy/: bar (200; 25.887818ms)
Mar 25 09:52:09.525: INFO: (4) /api/v1/namespaces/proxy-4885/services/http:proxy-service-b6gjp:portname1/proxy/: foo (200; 25.668274ms)
Mar 25 09:52:09.525: INFO: (4) /api/v1/namespaces/proxy-4885/services/https:proxy-service-b6gjp:tlsportname1/proxy/: tls baz (200; 25.860576ms)
Mar 25 09:52:09.525: INFO: (4) /api/v1/namespaces/proxy-4885/services/https:proxy-service-b6gjp:tlsportname2/proxy/: tls qux (200; 26.311821ms)
Mar 25 09:52:09.525: INFO: (4) /api/v1/namespaces/proxy-4885/services/http:proxy-service-b6gjp:portname2/proxy/: bar (200; 26.635151ms)
Mar 25 09:52:09.525: INFO: (4) /api/v1/namespaces/proxy-4885/pods/proxy-service-b6gjp-x86nh:162/proxy/: bar (200; 26.073299ms)
Mar 25 09:52:09.525: INFO: (4) /api/v1/namespaces/proxy-4885/pods/proxy-service-b6gjp-x86nh:160/proxy/: foo (200; 26.141927ms)
Mar 25 09:52:09.540: INFO: (5) /api/v1/namespaces/proxy-4885/pods/https:proxy-service-b6gjp-x86nh:443/proxy/: <a href="/api/v1/namespaces/proxy-4885/pods/https:proxy-service-b6gjp-x86nh:443/proxy/tlsrewritem... (200; 14.683793ms)
Mar 25 09:52:09.543: INFO: (5) /api/v1/namespaces/proxy-4885/pods/http:proxy-service-b6gjp-x86nh:160/proxy/: foo (200; 17.566074ms)
Mar 25 09:52:09.543: INFO: (5) /api/v1/namespaces/proxy-4885/pods/proxy-service-b6gjp-x86nh:1080/proxy/: <a href="/api/v1/namespaces/proxy-4885/pods/proxy-service-b6gjp-x86nh:1080/proxy/rewriteme">test<... (200; 17.42873ms)
Mar 25 09:52:09.543: INFO: (5) /api/v1/namespaces/proxy-4885/pods/proxy-service-b6gjp-x86nh/proxy/: <a href="/api/v1/namespaces/proxy-4885/pods/proxy-service-b6gjp-x86nh/proxy/rewriteme">test</a> (200; 17.873288ms)
Mar 25 09:52:09.543: INFO: (5) /api/v1/namespaces/proxy-4885/pods/http:proxy-service-b6gjp-x86nh:1080/proxy/: <a href="/api/v1/namespaces/proxy-4885/pods/http:proxy-service-b6gjp-x86nh:1080/proxy/rewriteme">... (200; 17.816238ms)
Mar 25 09:52:09.543: INFO: (5) /api/v1/namespaces/proxy-4885/pods/proxy-service-b6gjp-x86nh:160/proxy/: foo (200; 17.936416ms)
Mar 25 09:52:09.543: INFO: (5) /api/v1/namespaces/proxy-4885/pods/proxy-service-b6gjp-x86nh:162/proxy/: bar (200; 18.460321ms)
Mar 25 09:52:09.543: INFO: (5) /api/v1/namespaces/proxy-4885/services/https:proxy-service-b6gjp:tlsportname1/proxy/: tls baz (200; 18.611164ms)
Mar 25 09:52:09.544: INFO: (5) /api/v1/namespaces/proxy-4885/pods/http:proxy-service-b6gjp-x86nh:162/proxy/: bar (200; 18.470521ms)
Mar 25 09:52:09.547: INFO: (5) /api/v1/namespaces/proxy-4885/pods/https:proxy-service-b6gjp-x86nh:460/proxy/: tls baz (200; 20.816378ms)
Mar 25 09:52:09.547: INFO: (5) /api/v1/namespaces/proxy-4885/services/http:proxy-service-b6gjp:portname1/proxy/: foo (200; 21.512836ms)
Mar 25 09:52:09.547: INFO: (5) /api/v1/namespaces/proxy-4885/services/proxy-service-b6gjp:portname2/proxy/: bar (200; 22.021006ms)
Mar 25 09:52:09.547: INFO: (5) /api/v1/namespaces/proxy-4885/services/https:proxy-service-b6gjp:tlsportname2/proxy/: tls qux (200; 22.241061ms)
Mar 25 09:52:09.548: INFO: (5) /api/v1/namespaces/proxy-4885/pods/https:proxy-service-b6gjp-x86nh:462/proxy/: tls qux (200; 22.880187ms)
Mar 25 09:52:09.548: INFO: (5) /api/v1/namespaces/proxy-4885/services/proxy-service-b6gjp:portname1/proxy/: foo (200; 22.35335ms)
Mar 25 09:52:09.548: INFO: (5) /api/v1/namespaces/proxy-4885/services/http:proxy-service-b6gjp:portname2/proxy/: bar (200; 22.330771ms)
Mar 25 09:52:09.562: INFO: (6) /api/v1/namespaces/proxy-4885/pods/http:proxy-service-b6gjp-x86nh:1080/proxy/: <a href="/api/v1/namespaces/proxy-4885/pods/http:proxy-service-b6gjp-x86nh:1080/proxy/rewriteme">... (200; 12.996318ms)
Mar 25 09:52:09.565: INFO: (6) /api/v1/namespaces/proxy-4885/pods/proxy-service-b6gjp-x86nh/proxy/: <a href="/api/v1/namespaces/proxy-4885/pods/proxy-service-b6gjp-x86nh/proxy/rewriteme">test</a> (200; 16.291176ms)
Mar 25 09:52:09.566: INFO: (6) /api/v1/namespaces/proxy-4885/pods/https:proxy-service-b6gjp-x86nh:443/proxy/: <a href="/api/v1/namespaces/proxy-4885/pods/https:proxy-service-b6gjp-x86nh:443/proxy/tlsrewritem... (200; 17.099694ms)
Mar 25 09:52:09.566: INFO: (6) /api/v1/namespaces/proxy-4885/pods/https:proxy-service-b6gjp-x86nh:460/proxy/: tls baz (200; 16.828204ms)
Mar 25 09:52:09.566: INFO: (6) /api/v1/namespaces/proxy-4885/pods/proxy-service-b6gjp-x86nh:160/proxy/: foo (200; 16.730258ms)
Mar 25 09:52:09.570: INFO: (6) /api/v1/namespaces/proxy-4885/services/proxy-service-b6gjp:portname1/proxy/: foo (200; 20.935287ms)
Mar 25 09:52:09.570: INFO: (6) /api/v1/namespaces/proxy-4885/pods/proxy-service-b6gjp-x86nh:162/proxy/: bar (200; 20.56286ms)
Mar 25 09:52:09.570: INFO: (6) /api/v1/namespaces/proxy-4885/pods/http:proxy-service-b6gjp-x86nh:160/proxy/: foo (200; 20.335368ms)
Mar 25 09:52:09.570: INFO: (6) /api/v1/namespaces/proxy-4885/pods/http:proxy-service-b6gjp-x86nh:162/proxy/: bar (200; 20.518893ms)
Mar 25 09:52:09.570: INFO: (6) /api/v1/namespaces/proxy-4885/pods/proxy-service-b6gjp-x86nh:1080/proxy/: <a href="/api/v1/namespaces/proxy-4885/pods/proxy-service-b6gjp-x86nh:1080/proxy/rewriteme">test<... (200; 20.335548ms)
Mar 25 09:52:09.570: INFO: (6) /api/v1/namespaces/proxy-4885/services/https:proxy-service-b6gjp:tlsportname2/proxy/: tls qux (200; 21.335338ms)
Mar 25 09:52:09.571: INFO: (6) /api/v1/namespaces/proxy-4885/pods/https:proxy-service-b6gjp-x86nh:462/proxy/: tls qux (200; 21.645116ms)
Mar 25 09:52:09.572: INFO: (6) /api/v1/namespaces/proxy-4885/services/http:proxy-service-b6gjp:portname1/proxy/: foo (200; 22.261744ms)
Mar 25 09:52:09.572: INFO: (6) /api/v1/namespaces/proxy-4885/services/http:proxy-service-b6gjp:portname2/proxy/: bar (200; 23.087711ms)
Mar 25 09:52:09.572: INFO: (6) /api/v1/namespaces/proxy-4885/services/https:proxy-service-b6gjp:tlsportname1/proxy/: tls baz (200; 22.668154ms)
Mar 25 09:52:09.572: INFO: (6) /api/v1/namespaces/proxy-4885/services/proxy-service-b6gjp:portname2/proxy/: bar (200; 22.779354ms)
Mar 25 09:52:09.583: INFO: (7) /api/v1/namespaces/proxy-4885/pods/https:proxy-service-b6gjp-x86nh:443/proxy/: <a href="/api/v1/namespaces/proxy-4885/pods/https:proxy-service-b6gjp-x86nh:443/proxy/tlsrewritem... (200; 10.907094ms)
Mar 25 09:52:09.587: INFO: (7) /api/v1/namespaces/proxy-4885/pods/proxy-service-b6gjp-x86nh:162/proxy/: bar (200; 14.359126ms)
Mar 25 09:52:09.589: INFO: (7) /api/v1/namespaces/proxy-4885/pods/https:proxy-service-b6gjp-x86nh:462/proxy/: tls qux (200; 16.748324ms)
Mar 25 09:52:09.589: INFO: (7) /api/v1/namespaces/proxy-4885/pods/http:proxy-service-b6gjp-x86nh:160/proxy/: foo (200; 16.138675ms)
Mar 25 09:52:09.589: INFO: (7) /api/v1/namespaces/proxy-4885/pods/proxy-service-b6gjp-x86nh/proxy/: <a href="/api/v1/namespaces/proxy-4885/pods/proxy-service-b6gjp-x86nh/proxy/rewriteme">test</a> (200; 16.673336ms)
Mar 25 09:52:09.589: INFO: (7) /api/v1/namespaces/proxy-4885/pods/http:proxy-service-b6gjp-x86nh:162/proxy/: bar (200; 16.913972ms)
Mar 25 09:52:09.589: INFO: (7) /api/v1/namespaces/proxy-4885/pods/proxy-service-b6gjp-x86nh:1080/proxy/: <a href="/api/v1/namespaces/proxy-4885/pods/proxy-service-b6gjp-x86nh:1080/proxy/rewriteme">test<... (200; 16.313518ms)
Mar 25 09:52:09.589: INFO: (7) /api/v1/namespaces/proxy-4885/pods/https:proxy-service-b6gjp-x86nh:460/proxy/: tls baz (200; 17.138216ms)
Mar 25 09:52:09.592: INFO: (7) /api/v1/namespaces/proxy-4885/pods/http:proxy-service-b6gjp-x86nh:1080/proxy/: <a href="/api/v1/namespaces/proxy-4885/pods/http:proxy-service-b6gjp-x86nh:1080/proxy/rewriteme">... (200; 19.358233ms)
Mar 25 09:52:09.592: INFO: (7) /api/v1/namespaces/proxy-4885/pods/proxy-service-b6gjp-x86nh:160/proxy/: foo (200; 19.438289ms)
Mar 25 09:52:09.594: INFO: (7) /api/v1/namespaces/proxy-4885/services/http:proxy-service-b6gjp:portname2/proxy/: bar (200; 21.34636ms)
Mar 25 09:52:09.594: INFO: (7) /api/v1/namespaces/proxy-4885/services/proxy-service-b6gjp:portname1/proxy/: foo (200; 21.697498ms)
Mar 25 09:52:09.594: INFO: (7) /api/v1/namespaces/proxy-4885/services/https:proxy-service-b6gjp:tlsportname2/proxy/: tls qux (200; 21.307464ms)
Mar 25 09:52:09.594: INFO: (7) /api/v1/namespaces/proxy-4885/services/https:proxy-service-b6gjp:tlsportname1/proxy/: tls baz (200; 21.054236ms)
Mar 25 09:52:09.594: INFO: (7) /api/v1/namespaces/proxy-4885/services/proxy-service-b6gjp:portname2/proxy/: bar (200; 21.533288ms)
Mar 25 09:52:09.594: INFO: (7) /api/v1/namespaces/proxy-4885/services/http:proxy-service-b6gjp:portname1/proxy/: foo (200; 21.211374ms)
Mar 25 09:52:09.610: INFO: (8) /api/v1/namespaces/proxy-4885/pods/http:proxy-service-b6gjp-x86nh:160/proxy/: foo (200; 15.460295ms)
Mar 25 09:52:09.610: INFO: (8) /api/v1/namespaces/proxy-4885/pods/http:proxy-service-b6gjp-x86nh:1080/proxy/: <a href="/api/v1/namespaces/proxy-4885/pods/http:proxy-service-b6gjp-x86nh:1080/proxy/rewriteme">... (200; 15.321354ms)
Mar 25 09:52:09.614: INFO: (8) /api/v1/namespaces/proxy-4885/pods/proxy-service-b6gjp-x86nh:162/proxy/: bar (200; 19.3141ms)
Mar 25 09:52:09.614: INFO: (8) /api/v1/namespaces/proxy-4885/pods/http:proxy-service-b6gjp-x86nh:162/proxy/: bar (200; 19.334559ms)
Mar 25 09:52:09.614: INFO: (8) /api/v1/namespaces/proxy-4885/pods/https:proxy-service-b6gjp-x86nh:462/proxy/: tls qux (200; 19.69653ms)
Mar 25 09:52:09.614: INFO: (8) /api/v1/namespaces/proxy-4885/pods/proxy-service-b6gjp-x86nh/proxy/: <a href="/api/v1/namespaces/proxy-4885/pods/proxy-service-b6gjp-x86nh/proxy/rewriteme">test</a> (200; 19.199208ms)
Mar 25 09:52:09.614: INFO: (8) /api/v1/namespaces/proxy-4885/pods/https:proxy-service-b6gjp-x86nh:443/proxy/: <a href="/api/v1/namespaces/proxy-4885/pods/https:proxy-service-b6gjp-x86nh:443/proxy/tlsrewritem... (200; 19.923869ms)
Mar 25 09:52:09.615: INFO: (8) /api/v1/namespaces/proxy-4885/pods/proxy-service-b6gjp-x86nh:160/proxy/: foo (200; 19.810833ms)
Mar 25 09:52:09.615: INFO: (8) /api/v1/namespaces/proxy-4885/pods/https:proxy-service-b6gjp-x86nh:460/proxy/: tls baz (200; 19.872534ms)
Mar 25 09:52:09.615: INFO: (8) /api/v1/namespaces/proxy-4885/pods/proxy-service-b6gjp-x86nh:1080/proxy/: <a href="/api/v1/namespaces/proxy-4885/pods/proxy-service-b6gjp-x86nh:1080/proxy/rewriteme">test<... (200; 20.170645ms)
Mar 25 09:52:09.616: INFO: (8) /api/v1/namespaces/proxy-4885/services/proxy-service-b6gjp:portname1/proxy/: foo (200; 21.560264ms)
Mar 25 09:52:09.616: INFO: (8) /api/v1/namespaces/proxy-4885/services/http:proxy-service-b6gjp:portname2/proxy/: bar (200; 21.557271ms)
Mar 25 09:52:09.616: INFO: (8) /api/v1/namespaces/proxy-4885/services/http:proxy-service-b6gjp:portname1/proxy/: foo (200; 21.886062ms)
Mar 25 09:52:09.616: INFO: (8) /api/v1/namespaces/proxy-4885/services/https:proxy-service-b6gjp:tlsportname2/proxy/: tls qux (200; 21.58339ms)
Mar 25 09:52:09.616: INFO: (8) /api/v1/namespaces/proxy-4885/services/https:proxy-service-b6gjp:tlsportname1/proxy/: tls baz (200; 21.416476ms)
Mar 25 09:52:09.617: INFO: (8) /api/v1/namespaces/proxy-4885/services/proxy-service-b6gjp:portname2/proxy/: bar (200; 21.594772ms)
Mar 25 09:52:09.625: INFO: (9) /api/v1/namespaces/proxy-4885/pods/proxy-service-b6gjp-x86nh:1080/proxy/: <a href="/api/v1/namespaces/proxy-4885/pods/proxy-service-b6gjp-x86nh:1080/proxy/rewriteme">test<... (200; 8.335837ms)
Mar 25 09:52:09.628: INFO: (9) /api/v1/namespaces/proxy-4885/pods/http:proxy-service-b6gjp-x86nh:162/proxy/: bar (200; 10.25996ms)
Mar 25 09:52:09.631: INFO: (9) /api/v1/namespaces/proxy-4885/pods/https:proxy-service-b6gjp-x86nh:462/proxy/: tls qux (200; 14.630238ms)
Mar 25 09:52:09.631: INFO: (9) /api/v1/namespaces/proxy-4885/pods/http:proxy-service-b6gjp-x86nh:160/proxy/: foo (200; 13.760102ms)
Mar 25 09:52:09.632: INFO: (9) /api/v1/namespaces/proxy-4885/pods/http:proxy-service-b6gjp-x86nh:1080/proxy/: <a href="/api/v1/namespaces/proxy-4885/pods/http:proxy-service-b6gjp-x86nh:1080/proxy/rewriteme">... (200; 14.486772ms)
Mar 25 09:52:09.632: INFO: (9) /api/v1/namespaces/proxy-4885/pods/https:proxy-service-b6gjp-x86nh:443/proxy/: <a href="/api/v1/namespaces/proxy-4885/pods/https:proxy-service-b6gjp-x86nh:443/proxy/tlsrewritem... (200; 13.890935ms)
Mar 25 09:52:09.632: INFO: (9) /api/v1/namespaces/proxy-4885/pods/proxy-service-b6gjp-x86nh/proxy/: <a href="/api/v1/namespaces/proxy-4885/pods/proxy-service-b6gjp-x86nh/proxy/rewriteme">test</a> (200; 14.696428ms)
Mar 25 09:52:09.632: INFO: (9) /api/v1/namespaces/proxy-4885/pods/https:proxy-service-b6gjp-x86nh:460/proxy/: tls baz (200; 14.96213ms)
Mar 25 09:52:09.635: INFO: (9) /api/v1/namespaces/proxy-4885/pods/proxy-service-b6gjp-x86nh:160/proxy/: foo (200; 17.557613ms)
Mar 25 09:52:09.635: INFO: (9) /api/v1/namespaces/proxy-4885/pods/proxy-service-b6gjp-x86nh:162/proxy/: bar (200; 17.478579ms)
Mar 25 09:52:09.638: INFO: (9) /api/v1/namespaces/proxy-4885/services/proxy-service-b6gjp:portname1/proxy/: foo (200; 21.603235ms)
Mar 25 09:52:09.638: INFO: (9) /api/v1/namespaces/proxy-4885/services/http:proxy-service-b6gjp:portname1/proxy/: foo (200; 20.622082ms)
Mar 25 09:52:09.639: INFO: (9) /api/v1/namespaces/proxy-4885/services/https:proxy-service-b6gjp:tlsportname2/proxy/: tls qux (200; 21.167122ms)
Mar 25 09:52:09.639: INFO: (9) /api/v1/namespaces/proxy-4885/services/https:proxy-service-b6gjp:tlsportname1/proxy/: tls baz (200; 21.159242ms)
Mar 25 09:52:09.639: INFO: (9) /api/v1/namespaces/proxy-4885/services/proxy-service-b6gjp:portname2/proxy/: bar (200; 21.356118ms)
Mar 25 09:52:09.639: INFO: (9) /api/v1/namespaces/proxy-4885/services/http:proxy-service-b6gjp:portname2/proxy/: bar (200; 22.000754ms)
Mar 25 09:52:09.656: INFO: (10) /api/v1/namespaces/proxy-4885/pods/proxy-service-b6gjp-x86nh:162/proxy/: bar (200; 16.025748ms)
Mar 25 09:52:09.656: INFO: (10) /api/v1/namespaces/proxy-4885/pods/https:proxy-service-b6gjp-x86nh:460/proxy/: tls baz (200; 17.051213ms)
Mar 25 09:52:09.656: INFO: (10) /api/v1/namespaces/proxy-4885/pods/http:proxy-service-b6gjp-x86nh:162/proxy/: bar (200; 16.410592ms)
Mar 25 09:52:09.656: INFO: (10) /api/v1/namespaces/proxy-4885/pods/proxy-service-b6gjp-x86nh:1080/proxy/: <a href="/api/v1/namespaces/proxy-4885/pods/proxy-service-b6gjp-x86nh:1080/proxy/rewriteme">test<... (200; 16.274129ms)
Mar 25 09:52:09.656: INFO: (10) /api/v1/namespaces/proxy-4885/pods/proxy-service-b6gjp-x86nh/proxy/: <a href="/api/v1/namespaces/proxy-4885/pods/proxy-service-b6gjp-x86nh/proxy/rewriteme">test</a> (200; 16.891975ms)
Mar 25 09:52:09.657: INFO: (10) /api/v1/namespaces/proxy-4885/pods/https:proxy-service-b6gjp-x86nh:462/proxy/: tls qux (200; 17.231293ms)
Mar 25 09:52:09.657: INFO: (10) /api/v1/namespaces/proxy-4885/services/http:proxy-service-b6gjp:portname1/proxy/: foo (200; 17.586292ms)
Mar 25 09:52:09.657: INFO: (10) /api/v1/namespaces/proxy-4885/pods/proxy-service-b6gjp-x86nh:160/proxy/: foo (200; 17.495655ms)
Mar 25 09:52:09.657: INFO: (10) /api/v1/namespaces/proxy-4885/pods/https:proxy-service-b6gjp-x86nh:443/proxy/: <a href="/api/v1/namespaces/proxy-4885/pods/https:proxy-service-b6gjp-x86nh:443/proxy/tlsrewritem... (200; 16.515567ms)
Mar 25 09:52:09.661: INFO: (10) /api/v1/namespaces/proxy-4885/pods/http:proxy-service-b6gjp-x86nh:1080/proxy/: <a href="/api/v1/namespaces/proxy-4885/pods/http:proxy-service-b6gjp-x86nh:1080/proxy/rewriteme">... (200; 21.802567ms)
Mar 25 09:52:09.662: INFO: (10) /api/v1/namespaces/proxy-4885/pods/http:proxy-service-b6gjp-x86nh:160/proxy/: foo (200; 21.782523ms)
Mar 25 09:52:09.663: INFO: (10) /api/v1/namespaces/proxy-4885/services/https:proxy-service-b6gjp:tlsportname2/proxy/: tls qux (200; 23.240004ms)
Mar 25 09:52:09.663: INFO: (10) /api/v1/namespaces/proxy-4885/services/https:proxy-service-b6gjp:tlsportname1/proxy/: tls baz (200; 22.625611ms)
Mar 25 09:52:09.663: INFO: (10) /api/v1/namespaces/proxy-4885/services/proxy-service-b6gjp:portname1/proxy/: foo (200; 23.591199ms)
Mar 25 09:52:09.663: INFO: (10) /api/v1/namespaces/proxy-4885/services/proxy-service-b6gjp:portname2/proxy/: bar (200; 23.11953ms)
Mar 25 09:52:09.663: INFO: (10) /api/v1/namespaces/proxy-4885/services/http:proxy-service-b6gjp:portname2/proxy/: bar (200; 22.962387ms)
Mar 25 09:52:09.680: INFO: (11) /api/v1/namespaces/proxy-4885/pods/https:proxy-service-b6gjp-x86nh:462/proxy/: tls qux (200; 16.705706ms)
Mar 25 09:52:09.680: INFO: (11) /api/v1/namespaces/proxy-4885/pods/http:proxy-service-b6gjp-x86nh:160/proxy/: foo (200; 16.857075ms)
Mar 25 09:52:09.683: INFO: (11) /api/v1/namespaces/proxy-4885/pods/http:proxy-service-b6gjp-x86nh:1080/proxy/: <a href="/api/v1/namespaces/proxy-4885/pods/http:proxy-service-b6gjp-x86nh:1080/proxy/rewriteme">... (200; 19.130044ms)
Mar 25 09:52:09.683: INFO: (11) /api/v1/namespaces/proxy-4885/services/proxy-service-b6gjp:portname2/proxy/: bar (200; 19.965969ms)
Mar 25 09:52:09.683: INFO: (11) /api/v1/namespaces/proxy-4885/pods/https:proxy-service-b6gjp-x86nh:460/proxy/: tls baz (200; 19.629023ms)
Mar 25 09:52:09.684: INFO: (11) /api/v1/namespaces/proxy-4885/pods/proxy-service-b6gjp-x86nh:162/proxy/: bar (200; 19.891358ms)
Mar 25 09:52:09.684: INFO: (11) /api/v1/namespaces/proxy-4885/services/https:proxy-service-b6gjp:tlsportname1/proxy/: tls baz (200; 20.316365ms)
Mar 25 09:52:09.686: INFO: (11) /api/v1/namespaces/proxy-4885/pods/https:proxy-service-b6gjp-x86nh:443/proxy/: <a href="/api/v1/namespaces/proxy-4885/pods/https:proxy-service-b6gjp-x86nh:443/proxy/tlsrewritem... (200; 22.202239ms)
Mar 25 09:52:09.686: INFO: (11) /api/v1/namespaces/proxy-4885/pods/proxy-service-b6gjp-x86nh:160/proxy/: foo (200; 22.105741ms)
Mar 25 09:52:09.686: INFO: (11) /api/v1/namespaces/proxy-4885/pods/proxy-service-b6gjp-x86nh:1080/proxy/: <a href="/api/v1/namespaces/proxy-4885/pods/proxy-service-b6gjp-x86nh:1080/proxy/rewriteme">test<... (200; 22.394349ms)
Mar 25 09:52:09.686: INFO: (11) /api/v1/namespaces/proxy-4885/pods/proxy-service-b6gjp-x86nh/proxy/: <a href="/api/v1/namespaces/proxy-4885/pods/proxy-service-b6gjp-x86nh/proxy/rewriteme">test</a> (200; 22.243341ms)
Mar 25 09:52:09.686: INFO: (11) /api/v1/namespaces/proxy-4885/services/https:proxy-service-b6gjp:tlsportname2/proxy/: tls qux (200; 22.64277ms)
Mar 25 09:52:09.686: INFO: (11) /api/v1/namespaces/proxy-4885/services/http:proxy-service-b6gjp:portname2/proxy/: bar (200; 22.416217ms)
Mar 25 09:52:09.686: INFO: (11) /api/v1/namespaces/proxy-4885/services/proxy-service-b6gjp:portname1/proxy/: foo (200; 22.502935ms)
Mar 25 09:52:09.686: INFO: (11) /api/v1/namespaces/proxy-4885/pods/http:proxy-service-b6gjp-x86nh:162/proxy/: bar (200; 22.446807ms)
Mar 25 09:52:09.687: INFO: (11) /api/v1/namespaces/proxy-4885/services/http:proxy-service-b6gjp:portname1/proxy/: foo (200; 23.11767ms)
Mar 25 09:52:09.695: INFO: (12) /api/v1/namespaces/proxy-4885/pods/http:proxy-service-b6gjp-x86nh:160/proxy/: foo (200; 8.179639ms)
Mar 25 09:52:09.702: INFO: (12) /api/v1/namespaces/proxy-4885/pods/http:proxy-service-b6gjp-x86nh:162/proxy/: bar (200; 15.161485ms)
Mar 25 09:52:09.702: INFO: (12) /api/v1/namespaces/proxy-4885/pods/https:proxy-service-b6gjp-x86nh:460/proxy/: tls baz (200; 14.893645ms)
Mar 25 09:52:09.702: INFO: (12) /api/v1/namespaces/proxy-4885/pods/https:proxy-service-b6gjp-x86nh:462/proxy/: tls qux (200; 14.964408ms)
Mar 25 09:52:09.702: INFO: (12) /api/v1/namespaces/proxy-4885/pods/proxy-service-b6gjp-x86nh:162/proxy/: bar (200; 15.404954ms)
Mar 25 09:52:09.703: INFO: (12) /api/v1/namespaces/proxy-4885/pods/proxy-service-b6gjp-x86nh:160/proxy/: foo (200; 15.772818ms)
Mar 25 09:52:09.703: INFO: (12) /api/v1/namespaces/proxy-4885/pods/proxy-service-b6gjp-x86nh/proxy/: <a href="/api/v1/namespaces/proxy-4885/pods/proxy-service-b6gjp-x86nh/proxy/rewriteme">test</a> (200; 15.502367ms)
Mar 25 09:52:09.703: INFO: (12) /api/v1/namespaces/proxy-4885/pods/http:proxy-service-b6gjp-x86nh:1080/proxy/: <a href="/api/v1/namespaces/proxy-4885/pods/http:proxy-service-b6gjp-x86nh:1080/proxy/rewriteme">... (200; 15.498983ms)
Mar 25 09:52:09.703: INFO: (12) /api/v1/namespaces/proxy-4885/pods/proxy-service-b6gjp-x86nh:1080/proxy/: <a href="/api/v1/namespaces/proxy-4885/pods/proxy-service-b6gjp-x86nh:1080/proxy/rewriteme">test<... (200; 15.729089ms)
Mar 25 09:52:09.707: INFO: (12) /api/v1/namespaces/proxy-4885/pods/https:proxy-service-b6gjp-x86nh:443/proxy/: <a href="/api/v1/namespaces/proxy-4885/pods/https:proxy-service-b6gjp-x86nh:443/proxy/tlsrewritem... (200; 19.740185ms)
Mar 25 09:52:09.708: INFO: (12) /api/v1/namespaces/proxy-4885/services/http:proxy-service-b6gjp:portname1/proxy/: foo (200; 21.086744ms)
Mar 25 09:52:09.708: INFO: (12) /api/v1/namespaces/proxy-4885/services/http:proxy-service-b6gjp:portname2/proxy/: bar (200; 20.806776ms)
Mar 25 09:52:09.708: INFO: (12) /api/v1/namespaces/proxy-4885/services/proxy-service-b6gjp:portname2/proxy/: bar (200; 21.075484ms)
Mar 25 09:52:09.708: INFO: (12) /api/v1/namespaces/proxy-4885/services/https:proxy-service-b6gjp:tlsportname2/proxy/: tls qux (200; 21.056587ms)
Mar 25 09:52:09.708: INFO: (12) /api/v1/namespaces/proxy-4885/services/https:proxy-service-b6gjp:tlsportname1/proxy/: tls baz (200; 20.986617ms)
Mar 25 09:52:09.709: INFO: (12) /api/v1/namespaces/proxy-4885/services/proxy-service-b6gjp:portname1/proxy/: foo (200; 21.394629ms)
Mar 25 09:52:09.722: INFO: (13) /api/v1/namespaces/proxy-4885/pods/https:proxy-service-b6gjp-x86nh:462/proxy/: tls qux (200; 13.392294ms)
Mar 25 09:52:09.723: INFO: (13) /api/v1/namespaces/proxy-4885/pods/http:proxy-service-b6gjp-x86nh:162/proxy/: bar (200; 13.869604ms)
Mar 25 09:52:09.723: INFO: (13) /api/v1/namespaces/proxy-4885/pods/https:proxy-service-b6gjp-x86nh:443/proxy/: <a href="/api/v1/namespaces/proxy-4885/pods/https:proxy-service-b6gjp-x86nh:443/proxy/tlsrewritem... (200; 14.266319ms)
Mar 25 09:52:09.727: INFO: (13) /api/v1/namespaces/proxy-4885/pods/proxy-service-b6gjp-x86nh:160/proxy/: foo (200; 18.286901ms)
Mar 25 09:52:09.727: INFO: (13) /api/v1/namespaces/proxy-4885/pods/proxy-service-b6gjp-x86nh:1080/proxy/: <a href="/api/v1/namespaces/proxy-4885/pods/proxy-service-b6gjp-x86nh:1080/proxy/rewriteme">test<... (200; 18.083177ms)
Mar 25 09:52:09.727: INFO: (13) /api/v1/namespaces/proxy-4885/pods/http:proxy-service-b6gjp-x86nh:160/proxy/: foo (200; 18.224171ms)
Mar 25 09:52:09.727: INFO: (13) /api/v1/namespaces/proxy-4885/pods/proxy-service-b6gjp-x86nh/proxy/: <a href="/api/v1/namespaces/proxy-4885/pods/proxy-service-b6gjp-x86nh/proxy/rewriteme">test</a> (200; 18.53512ms)
Mar 25 09:52:09.727: INFO: (13) /api/v1/namespaces/proxy-4885/pods/proxy-service-b6gjp-x86nh:162/proxy/: bar (200; 18.441633ms)
Mar 25 09:52:09.727: INFO: (13) /api/v1/namespaces/proxy-4885/pods/http:proxy-service-b6gjp-x86nh:1080/proxy/: <a href="/api/v1/namespaces/proxy-4885/pods/http:proxy-service-b6gjp-x86nh:1080/proxy/rewriteme">... (200; 18.535282ms)
Mar 25 09:52:09.728: INFO: (13) /api/v1/namespaces/proxy-4885/pods/https:proxy-service-b6gjp-x86nh:460/proxy/: tls baz (200; 18.466511ms)
Mar 25 09:52:09.728: INFO: (13) /api/v1/namespaces/proxy-4885/services/https:proxy-service-b6gjp:tlsportname1/proxy/: tls baz (200; 19.015181ms)
Mar 25 09:52:09.730: INFO: (13) /api/v1/namespaces/proxy-4885/services/http:proxy-service-b6gjp:portname1/proxy/: foo (200; 21.296498ms)
Mar 25 09:52:09.730: INFO: (13) /api/v1/namespaces/proxy-4885/services/proxy-service-b6gjp:portname1/proxy/: foo (200; 21.20587ms)
Mar 25 09:52:09.730: INFO: (13) /api/v1/namespaces/proxy-4885/services/http:proxy-service-b6gjp:portname2/proxy/: bar (200; 21.194589ms)
Mar 25 09:52:09.730: INFO: (13) /api/v1/namespaces/proxy-4885/services/proxy-service-b6gjp:portname2/proxy/: bar (200; 21.705286ms)
Mar 25 09:52:09.731: INFO: (13) /api/v1/namespaces/proxy-4885/services/https:proxy-service-b6gjp:tlsportname2/proxy/: tls qux (200; 22.039109ms)
Mar 25 09:52:09.745: INFO: (14) /api/v1/namespaces/proxy-4885/pods/https:proxy-service-b6gjp-x86nh:460/proxy/: tls baz (200; 13.088415ms)
Mar 25 09:52:09.745: INFO: (14) /api/v1/namespaces/proxy-4885/pods/proxy-service-b6gjp-x86nh:160/proxy/: foo (200; 13.77801ms)
Mar 25 09:52:09.745: INFO: (14) /api/v1/namespaces/proxy-4885/services/https:proxy-service-b6gjp:tlsportname1/proxy/: tls baz (200; 14.38363ms)
Mar 25 09:52:09.750: INFO: (14) /api/v1/namespaces/proxy-4885/pods/https:proxy-service-b6gjp-x86nh:443/proxy/: <a href="/api/v1/namespaces/proxy-4885/pods/https:proxy-service-b6gjp-x86nh:443/proxy/tlsrewritem... (200; 18.172482ms)
Mar 25 09:52:09.750: INFO: (14) /api/v1/namespaces/proxy-4885/pods/proxy-service-b6gjp-x86nh:162/proxy/: bar (200; 18.289059ms)
Mar 25 09:52:09.751: INFO: (14) /api/v1/namespaces/proxy-4885/pods/https:proxy-service-b6gjp-x86nh:462/proxy/: tls qux (200; 18.824284ms)
Mar 25 09:52:09.751: INFO: (14) /api/v1/namespaces/proxy-4885/pods/http:proxy-service-b6gjp-x86nh:160/proxy/: foo (200; 19.332714ms)
Mar 25 09:52:09.751: INFO: (14) /api/v1/namespaces/proxy-4885/pods/proxy-service-b6gjp-x86nh:1080/proxy/: <a href="/api/v1/namespaces/proxy-4885/pods/proxy-service-b6gjp-x86nh:1080/proxy/rewriteme">test<... (200; 19.242729ms)
Mar 25 09:52:09.751: INFO: (14) /api/v1/namespaces/proxy-4885/pods/proxy-service-b6gjp-x86nh/proxy/: <a href="/api/v1/namespaces/proxy-4885/pods/proxy-service-b6gjp-x86nh/proxy/rewriteme">test</a> (200; 19.842577ms)
Mar 25 09:52:09.751: INFO: (14) /api/v1/namespaces/proxy-4885/pods/http:proxy-service-b6gjp-x86nh:1080/proxy/: <a href="/api/v1/namespaces/proxy-4885/pods/http:proxy-service-b6gjp-x86nh:1080/proxy/rewriteme">... (200; 19.780193ms)
Mar 25 09:52:09.751: INFO: (14) /api/v1/namespaces/proxy-4885/pods/http:proxy-service-b6gjp-x86nh:162/proxy/: bar (200; 20.141096ms)
Mar 25 09:52:09.753: INFO: (14) /api/v1/namespaces/proxy-4885/services/proxy-service-b6gjp:portname2/proxy/: bar (200; 21.946711ms)
Mar 25 09:52:09.753: INFO: (14) /api/v1/namespaces/proxy-4885/services/proxy-service-b6gjp:portname1/proxy/: foo (200; 21.156765ms)
Mar 25 09:52:09.753: INFO: (14) /api/v1/namespaces/proxy-4885/services/http:proxy-service-b6gjp:portname1/proxy/: foo (200; 21.552731ms)
Mar 25 09:52:09.753: INFO: (14) /api/v1/namespaces/proxy-4885/services/https:proxy-service-b6gjp:tlsportname2/proxy/: tls qux (200; 22.164885ms)
Mar 25 09:52:09.753: INFO: (14) /api/v1/namespaces/proxy-4885/services/http:proxy-service-b6gjp:portname2/proxy/: bar (200; 21.40654ms)
Mar 25 09:52:09.764: INFO: (15) /api/v1/namespaces/proxy-4885/pods/https:proxy-service-b6gjp-x86nh:462/proxy/: tls qux (200; 10.707319ms)
Mar 25 09:52:09.768: INFO: (15) /api/v1/namespaces/proxy-4885/pods/proxy-service-b6gjp-x86nh/proxy/: <a href="/api/v1/namespaces/proxy-4885/pods/proxy-service-b6gjp-x86nh/proxy/rewriteme">test</a> (200; 14.393308ms)
Mar 25 09:52:09.772: INFO: (15) /api/v1/namespaces/proxy-4885/pods/proxy-service-b6gjp-x86nh:162/proxy/: bar (200; 17.613899ms)
Mar 25 09:52:09.772: INFO: (15) /api/v1/namespaces/proxy-4885/pods/proxy-service-b6gjp-x86nh:1080/proxy/: <a href="/api/v1/namespaces/proxy-4885/pods/proxy-service-b6gjp-x86nh:1080/proxy/rewriteme">test<... (200; 17.929776ms)
Mar 25 09:52:09.772: INFO: (15) /api/v1/namespaces/proxy-4885/pods/proxy-service-b6gjp-x86nh:160/proxy/: foo (200; 17.646349ms)
Mar 25 09:52:09.773: INFO: (15) /api/v1/namespaces/proxy-4885/pods/http:proxy-service-b6gjp-x86nh:160/proxy/: foo (200; 19.577367ms)
Mar 25 09:52:09.773: INFO: (15) /api/v1/namespaces/proxy-4885/pods/https:proxy-service-b6gjp-x86nh:443/proxy/: <a href="/api/v1/namespaces/proxy-4885/pods/https:proxy-service-b6gjp-x86nh:443/proxy/tlsrewritem... (200; 19.476189ms)
Mar 25 09:52:09.774: INFO: (15) /api/v1/namespaces/proxy-4885/pods/https:proxy-service-b6gjp-x86nh:460/proxy/: tls baz (200; 19.895636ms)
Mar 25 09:52:09.774: INFO: (15) /api/v1/namespaces/proxy-4885/pods/http:proxy-service-b6gjp-x86nh:162/proxy/: bar (200; 19.714684ms)
Mar 25 09:52:09.775: INFO: (15) /api/v1/namespaces/proxy-4885/services/http:proxy-service-b6gjp:portname2/proxy/: bar (200; 21.389314ms)
Mar 25 09:52:09.775: INFO: (15) /api/v1/namespaces/proxy-4885/services/proxy-service-b6gjp:portname2/proxy/: bar (200; 21.329633ms)
Mar 25 09:52:09.775: INFO: (15) /api/v1/namespaces/proxy-4885/services/proxy-service-b6gjp:portname1/proxy/: foo (200; 21.485973ms)
Mar 25 09:52:09.775: INFO: (15) /api/v1/namespaces/proxy-4885/pods/http:proxy-service-b6gjp-x86nh:1080/proxy/: <a href="/api/v1/namespaces/proxy-4885/pods/http:proxy-service-b6gjp-x86nh:1080/proxy/rewriteme">... (200; 21.485789ms)
Mar 25 09:52:09.778: INFO: (15) /api/v1/namespaces/proxy-4885/services/https:proxy-service-b6gjp:tlsportname2/proxy/: tls qux (200; 23.772373ms)
Mar 25 09:52:09.778: INFO: (15) /api/v1/namespaces/proxy-4885/services/http:proxy-service-b6gjp:portname1/proxy/: foo (200; 24.041023ms)
Mar 25 09:52:09.778: INFO: (15) /api/v1/namespaces/proxy-4885/services/https:proxy-service-b6gjp:tlsportname1/proxy/: tls baz (200; 24.324983ms)
Mar 25 09:52:09.798: INFO: (16) /api/v1/namespaces/proxy-4885/pods/proxy-service-b6gjp-x86nh:1080/proxy/: <a href="/api/v1/namespaces/proxy-4885/pods/proxy-service-b6gjp-x86nh:1080/proxy/rewriteme">test<... (200; 19.603522ms)
Mar 25 09:52:09.798: INFO: (16) /api/v1/namespaces/proxy-4885/pods/https:proxy-service-b6gjp-x86nh:460/proxy/: tls baz (200; 19.358976ms)
Mar 25 09:52:09.798: INFO: (16) /api/v1/namespaces/proxy-4885/pods/https:proxy-service-b6gjp-x86nh:443/proxy/: <a href="/api/v1/namespaces/proxy-4885/pods/https:proxy-service-b6gjp-x86nh:443/proxy/tlsrewritem... (200; 19.77648ms)
Mar 25 09:52:09.798: INFO: (16) /api/v1/namespaces/proxy-4885/pods/https:proxy-service-b6gjp-x86nh:462/proxy/: tls qux (200; 19.464341ms)
Mar 25 09:52:09.799: INFO: (16) /api/v1/namespaces/proxy-4885/services/http:proxy-service-b6gjp:portname2/proxy/: bar (200; 20.895671ms)
Mar 25 09:52:09.802: INFO: (16) /api/v1/namespaces/proxy-4885/pods/proxy-service-b6gjp-x86nh/proxy/: <a href="/api/v1/namespaces/proxy-4885/pods/proxy-service-b6gjp-x86nh/proxy/rewriteme">test</a> (200; 23.294065ms)
Mar 25 09:52:09.802: INFO: (16) /api/v1/namespaces/proxy-4885/services/https:proxy-service-b6gjp:tlsportname2/proxy/: tls qux (200; 24.380214ms)
Mar 25 09:52:09.802: INFO: (16) /api/v1/namespaces/proxy-4885/pods/http:proxy-service-b6gjp-x86nh:1080/proxy/: <a href="/api/v1/namespaces/proxy-4885/pods/http:proxy-service-b6gjp-x86nh:1080/proxy/rewriteme">... (200; 23.328548ms)
Mar 25 09:52:09.802: INFO: (16) /api/v1/namespaces/proxy-4885/services/http:proxy-service-b6gjp:portname1/proxy/: foo (200; 24.096392ms)
Mar 25 09:52:09.802: INFO: (16) /api/v1/namespaces/proxy-4885/pods/http:proxy-service-b6gjp-x86nh:162/proxy/: bar (200; 22.955967ms)
Mar 25 09:52:09.803: INFO: (16) /api/v1/namespaces/proxy-4885/pods/http:proxy-service-b6gjp-x86nh:160/proxy/: foo (200; 23.414958ms)
Mar 25 09:52:09.803: INFO: (16) /api/v1/namespaces/proxy-4885/pods/proxy-service-b6gjp-x86nh:160/proxy/: foo (200; 23.806019ms)
Mar 25 09:52:09.804: INFO: (16) /api/v1/namespaces/proxy-4885/services/https:proxy-service-b6gjp:tlsportname1/proxy/: tls baz (200; 25.658811ms)
Mar 25 09:52:09.804: INFO: (16) /api/v1/namespaces/proxy-4885/services/proxy-service-b6gjp:portname2/proxy/: bar (200; 24.550556ms)
Mar 25 09:52:09.804: INFO: (16) /api/v1/namespaces/proxy-4885/pods/proxy-service-b6gjp-x86nh:162/proxy/: bar (200; 25.148648ms)
Mar 25 09:52:09.804: INFO: (16) /api/v1/namespaces/proxy-4885/services/proxy-service-b6gjp:portname1/proxy/: foo (200; 25.591218ms)
Mar 25 09:52:09.815: INFO: (17) /api/v1/namespaces/proxy-4885/pods/proxy-service-b6gjp-x86nh/proxy/: <a href="/api/v1/namespaces/proxy-4885/pods/proxy-service-b6gjp-x86nh/proxy/rewriteme">test</a> (200; 11.217602ms)
Mar 25 09:52:09.822: INFO: (17) /api/v1/namespaces/proxy-4885/services/https:proxy-service-b6gjp:tlsportname2/proxy/: tls qux (200; 17.576507ms)
Mar 25 09:52:09.822: INFO: (17) /api/v1/namespaces/proxy-4885/pods/https:proxy-service-b6gjp-x86nh:462/proxy/: tls qux (200; 17.479717ms)
Mar 25 09:52:09.824: INFO: (17) /api/v1/namespaces/proxy-4885/pods/http:proxy-service-b6gjp-x86nh:1080/proxy/: <a href="/api/v1/namespaces/proxy-4885/pods/http:proxy-service-b6gjp-x86nh:1080/proxy/rewriteme">... (200; 19.349437ms)
Mar 25 09:52:09.824: INFO: (17) /api/v1/namespaces/proxy-4885/pods/proxy-service-b6gjp-x86nh:162/proxy/: bar (200; 19.53511ms)
Mar 25 09:52:09.824: INFO: (17) /api/v1/namespaces/proxy-4885/services/https:proxy-service-b6gjp:tlsportname1/proxy/: tls baz (200; 19.647587ms)
Mar 25 09:52:09.824: INFO: (17) /api/v1/namespaces/proxy-4885/pods/proxy-service-b6gjp-x86nh:160/proxy/: foo (200; 19.883839ms)
Mar 25 09:52:09.824: INFO: (17) /api/v1/namespaces/proxy-4885/pods/https:proxy-service-b6gjp-x86nh:460/proxy/: tls baz (200; 20.119856ms)
Mar 25 09:52:09.825: INFO: (17) /api/v1/namespaces/proxy-4885/pods/http:proxy-service-b6gjp-x86nh:162/proxy/: bar (200; 19.969371ms)
Mar 25 09:52:09.825: INFO: (17) /api/v1/namespaces/proxy-4885/services/http:proxy-service-b6gjp:portname2/proxy/: bar (200; 20.443909ms)
Mar 25 09:52:09.826: INFO: (17) /api/v1/namespaces/proxy-4885/pods/proxy-service-b6gjp-x86nh:1080/proxy/: <a href="/api/v1/namespaces/proxy-4885/pods/proxy-service-b6gjp-x86nh:1080/proxy/rewriteme">test<... (200; 21.396623ms)
Mar 25 09:52:09.826: INFO: (17) /api/v1/namespaces/proxy-4885/pods/http:proxy-service-b6gjp-x86nh:160/proxy/: foo (200; 21.372224ms)
Mar 25 09:52:09.826: INFO: (17) /api/v1/namespaces/proxy-4885/pods/https:proxy-service-b6gjp-x86nh:443/proxy/: <a href="/api/v1/namespaces/proxy-4885/pods/https:proxy-service-b6gjp-x86nh:443/proxy/tlsrewritem... (200; 21.454533ms)
Mar 25 09:52:09.826: INFO: (17) /api/v1/namespaces/proxy-4885/services/proxy-service-b6gjp:portname2/proxy/: bar (200; 21.919847ms)
Mar 25 09:52:09.827: INFO: (17) /api/v1/namespaces/proxy-4885/services/http:proxy-service-b6gjp:portname1/proxy/: foo (200; 22.061739ms)
Mar 25 09:52:09.827: INFO: (17) /api/v1/namespaces/proxy-4885/services/proxy-service-b6gjp:portname1/proxy/: foo (200; 22.346379ms)
Mar 25 09:52:09.839: INFO: (18) /api/v1/namespaces/proxy-4885/pods/https:proxy-service-b6gjp-x86nh:443/proxy/: <a href="/api/v1/namespaces/proxy-4885/pods/https:proxy-service-b6gjp-x86nh:443/proxy/tlsrewritem... (200; 11.833634ms)
Mar 25 09:52:09.843: INFO: (18) /api/v1/namespaces/proxy-4885/pods/proxy-service-b6gjp-x86nh:162/proxy/: bar (200; 14.954883ms)
Mar 25 09:52:09.843: INFO: (18) /api/v1/namespaces/proxy-4885/pods/http:proxy-service-b6gjp-x86nh:160/proxy/: foo (200; 15.04823ms)
Mar 25 09:52:09.843: INFO: (18) /api/v1/namespaces/proxy-4885/pods/proxy-service-b6gjp-x86nh:1080/proxy/: <a href="/api/v1/namespaces/proxy-4885/pods/proxy-service-b6gjp-x86nh:1080/proxy/rewriteme">test<... (200; 15.289103ms)
Mar 25 09:52:09.843: INFO: (18) /api/v1/namespaces/proxy-4885/pods/proxy-service-b6gjp-x86nh:160/proxy/: foo (200; 15.700806ms)
Mar 25 09:52:09.843: INFO: (18) /api/v1/namespaces/proxy-4885/pods/https:proxy-service-b6gjp-x86nh:460/proxy/: tls baz (200; 15.962013ms)
Mar 25 09:52:09.844: INFO: (18) /api/v1/namespaces/proxy-4885/pods/http:proxy-service-b6gjp-x86nh:162/proxy/: bar (200; 15.998514ms)
Mar 25 09:52:09.844: INFO: (18) /api/v1/namespaces/proxy-4885/pods/http:proxy-service-b6gjp-x86nh:1080/proxy/: <a href="/api/v1/namespaces/proxy-4885/pods/http:proxy-service-b6gjp-x86nh:1080/proxy/rewriteme">... (200; 15.891172ms)
Mar 25 09:52:09.844: INFO: (18) /api/v1/namespaces/proxy-4885/pods/proxy-service-b6gjp-x86nh/proxy/: <a href="/api/v1/namespaces/proxy-4885/pods/proxy-service-b6gjp-x86nh/proxy/rewriteme">test</a> (200; 16.275129ms)
Mar 25 09:52:09.844: INFO: (18) /api/v1/namespaces/proxy-4885/pods/https:proxy-service-b6gjp-x86nh:462/proxy/: tls qux (200; 16.122579ms)
Mar 25 09:52:09.848: INFO: (18) /api/v1/namespaces/proxy-4885/services/proxy-service-b6gjp:portname2/proxy/: bar (200; 20.748541ms)
Mar 25 09:52:09.849: INFO: (18) /api/v1/namespaces/proxy-4885/services/http:proxy-service-b6gjp:portname2/proxy/: bar (200; 21.066009ms)
Mar 25 09:52:09.849: INFO: (18) /api/v1/namespaces/proxy-4885/services/http:proxy-service-b6gjp:portname1/proxy/: foo (200; 20.671829ms)
Mar 25 09:52:09.849: INFO: (18) /api/v1/namespaces/proxy-4885/services/https:proxy-service-b6gjp:tlsportname1/proxy/: tls baz (200; 20.881447ms)
Mar 25 09:52:09.849: INFO: (18) /api/v1/namespaces/proxy-4885/services/https:proxy-service-b6gjp:tlsportname2/proxy/: tls qux (200; 21.039437ms)
Mar 25 09:52:09.849: INFO: (18) /api/v1/namespaces/proxy-4885/services/proxy-service-b6gjp:portname1/proxy/: foo (200; 21.516582ms)
Mar 25 09:52:09.860: INFO: (19) /api/v1/namespaces/proxy-4885/pods/https:proxy-service-b6gjp-x86nh:443/proxy/: <a href="/api/v1/namespaces/proxy-4885/pods/https:proxy-service-b6gjp-x86nh:443/proxy/tlsrewritem... (200; 10.515887ms)
Mar 25 09:52:09.864: INFO: (19) /api/v1/namespaces/proxy-4885/pods/http:proxy-service-b6gjp-x86nh:162/proxy/: bar (200; 13.689571ms)
Mar 25 09:52:09.868: INFO: (19) /api/v1/namespaces/proxy-4885/pods/http:proxy-service-b6gjp-x86nh:160/proxy/: foo (200; 17.694512ms)
Mar 25 09:52:09.868: INFO: (19) /api/v1/namespaces/proxy-4885/pods/https:proxy-service-b6gjp-x86nh:462/proxy/: tls qux (200; 18.449311ms)
Mar 25 09:52:09.868: INFO: (19) /api/v1/namespaces/proxy-4885/pods/proxy-service-b6gjp-x86nh/proxy/: <a href="/api/v1/namespaces/proxy-4885/pods/proxy-service-b6gjp-x86nh/proxy/rewriteme">test</a> (200; 18.158379ms)
Mar 25 09:52:09.868: INFO: (19) /api/v1/namespaces/proxy-4885/pods/http:proxy-service-b6gjp-x86nh:1080/proxy/: <a href="/api/v1/namespaces/proxy-4885/pods/http:proxy-service-b6gjp-x86nh:1080/proxy/rewriteme">... (200; 18.354478ms)
Mar 25 09:52:09.868: INFO: (19) /api/v1/namespaces/proxy-4885/pods/proxy-service-b6gjp-x86nh:1080/proxy/: <a href="/api/v1/namespaces/proxy-4885/pods/proxy-service-b6gjp-x86nh:1080/proxy/rewriteme">test<... (200; 17.864312ms)
Mar 25 09:52:09.868: INFO: (19) /api/v1/namespaces/proxy-4885/pods/https:proxy-service-b6gjp-x86nh:460/proxy/: tls baz (200; 18.886557ms)
Mar 25 09:52:09.874: INFO: (19) /api/v1/namespaces/proxy-4885/pods/proxy-service-b6gjp-x86nh:160/proxy/: foo (200; 24.060866ms)
Mar 25 09:52:09.874: INFO: (19) /api/v1/namespaces/proxy-4885/services/https:proxy-service-b6gjp:tlsportname2/proxy/: tls qux (200; 24.374513ms)
Mar 25 09:52:09.874: INFO: (19) /api/v1/namespaces/proxy-4885/pods/proxy-service-b6gjp-x86nh:162/proxy/: bar (200; 24.159225ms)
Mar 25 09:52:09.875: INFO: (19) /api/v1/namespaces/proxy-4885/services/http:proxy-service-b6gjp:portname2/proxy/: bar (200; 25.765653ms)
Mar 25 09:52:09.875: INFO: (19) /api/v1/namespaces/proxy-4885/services/proxy-service-b6gjp:portname1/proxy/: foo (200; 25.900153ms)
Mar 25 09:52:09.880: INFO: (19) /api/v1/namespaces/proxy-4885/services/http:proxy-service-b6gjp:portname1/proxy/: foo (200; 29.4724ms)
Mar 25 09:52:09.880: INFO: (19) /api/v1/namespaces/proxy-4885/services/proxy-service-b6gjp:portname2/proxy/: bar (200; 30.323517ms)
Mar 25 09:52:09.880: INFO: (19) /api/v1/namespaces/proxy-4885/services/https:proxy-service-b6gjp:tlsportname1/proxy/: tls baz (200; 29.69481ms)
STEP: deleting ReplicationController proxy-service-b6gjp in namespace proxy-4885, will wait for the garbage collector to delete the pods
Mar 25 09:52:09.941: INFO: Deleting ReplicationController proxy-service-b6gjp took: 6.479603ms
Mar 25 09:52:10.242: INFO: Terminating ReplicationController proxy-service-b6gjp pods took: 300.247543ms
[AfterEach] version v1
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 09:52:16.842: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-4885" for this suite.
Mar 25 09:52:22.868: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 09:52:23.055: INFO: namespace proxy-4885 deletion completed in 6.203588364s

• [SLOW TEST:21.877 seconds]
[sig-network] Proxy
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:58
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 09:52:23.056: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-416
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: validating api versions
Mar 25 09:52:23.248: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 api-versions'
Mar 25 09:52:23.326: INFO: stderr: ""
Mar 25 09:52:23.326: INFO: stdout: "admissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\napps/v1beta1\napps/v1beta2\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1\ncoordination.k8s.io/v1beta1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nmetrics.k8s.io/v1beta1\nnetworking.k8s.io/v1\nnetworking.k8s.io/v1beta1\nnode.k8s.io/v1beta1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 09:52:23.326: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-416" for this suite.
Mar 25 09:52:29.345: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 09:52:29.410: INFO: namespace kubectl-416 deletion completed in 6.079467202s

• [SLOW TEST:6.354 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl api-versions
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 09:52:29.410: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-4888
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Mar 25 09:52:29.552: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-4888,SelfLink:/api/v1/namespaces/watch-4888/configmaps/e2e-watch-test-configmap-a,UID:effc824d-b4dc-490d-a0f5-14276078e2c3,ResourceVersion:341025,Generation:0,CreationTimestamp:2020-03-25 09:52:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Mar 25 09:52:29.552: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-4888,SelfLink:/api/v1/namespaces/watch-4888/configmaps/e2e-watch-test-configmap-a,UID:effc824d-b4dc-490d-a0f5-14276078e2c3,ResourceVersion:341025,Generation:0,CreationTimestamp:2020-03-25 09:52:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Mar 25 09:52:39.559: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-4888,SelfLink:/api/v1/namespaces/watch-4888/configmaps/e2e-watch-test-configmap-a,UID:effc824d-b4dc-490d-a0f5-14276078e2c3,ResourceVersion:341056,Generation:0,CreationTimestamp:2020-03-25 09:52:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Mar 25 09:52:39.559: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-4888,SelfLink:/api/v1/namespaces/watch-4888/configmaps/e2e-watch-test-configmap-a,UID:effc824d-b4dc-490d-a0f5-14276078e2c3,ResourceVersion:341056,Generation:0,CreationTimestamp:2020-03-25 09:52:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Mar 25 09:52:49.567: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-4888,SelfLink:/api/v1/namespaces/watch-4888/configmaps/e2e-watch-test-configmap-a,UID:effc824d-b4dc-490d-a0f5-14276078e2c3,ResourceVersion:341071,Generation:0,CreationTimestamp:2020-03-25 09:52:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Mar 25 09:52:49.567: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-4888,SelfLink:/api/v1/namespaces/watch-4888/configmaps/e2e-watch-test-configmap-a,UID:effc824d-b4dc-490d-a0f5-14276078e2c3,ResourceVersion:341071,Generation:0,CreationTimestamp:2020-03-25 09:52:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Mar 25 09:52:59.574: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-4888,SelfLink:/api/v1/namespaces/watch-4888/configmaps/e2e-watch-test-configmap-a,UID:effc824d-b4dc-490d-a0f5-14276078e2c3,ResourceVersion:341087,Generation:0,CreationTimestamp:2020-03-25 09:52:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Mar 25 09:52:59.574: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-4888,SelfLink:/api/v1/namespaces/watch-4888/configmaps/e2e-watch-test-configmap-a,UID:effc824d-b4dc-490d-a0f5-14276078e2c3,ResourceVersion:341087,Generation:0,CreationTimestamp:2020-03-25 09:52:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Mar 25 09:53:09.580: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-4888,SelfLink:/api/v1/namespaces/watch-4888/configmaps/e2e-watch-test-configmap-b,UID:d65e2e16-e0f0-44a8-99de-106a5063efa7,ResourceVersion:341103,Generation:0,CreationTimestamp:2020-03-25 09:53:09 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Mar 25 09:53:09.581: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-4888,SelfLink:/api/v1/namespaces/watch-4888/configmaps/e2e-watch-test-configmap-b,UID:d65e2e16-e0f0-44a8-99de-106a5063efa7,ResourceVersion:341103,Generation:0,CreationTimestamp:2020-03-25 09:53:09 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Mar 25 09:53:19.586: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-4888,SelfLink:/api/v1/namespaces/watch-4888/configmaps/e2e-watch-test-configmap-b,UID:d65e2e16-e0f0-44a8-99de-106a5063efa7,ResourceVersion:341118,Generation:0,CreationTimestamp:2020-03-25 09:53:09 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Mar 25 09:53:19.586: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-4888,SelfLink:/api/v1/namespaces/watch-4888/configmaps/e2e-watch-test-configmap-b,UID:d65e2e16-e0f0-44a8-99de-106a5063efa7,ResourceVersion:341118,Generation:0,CreationTimestamp:2020-03-25 09:53:09 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 09:53:29.586: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-4888" for this suite.
Mar 25 09:53:35.598: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 09:53:35.667: INFO: namespace watch-4888 deletion completed in 6.077241181s

• [SLOW TEST:66.257 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 09:53:35.667: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-4158
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-map-28fafefe-1e61-4811-a161-52dd9768bc67
STEP: Creating a pod to test consume secrets
Mar 25 09:53:35.809: INFO: Waiting up to 5m0s for pod "pod-secrets-c1ccecd8-56c6-4641-8853-497921a3dd12" in namespace "secrets-4158" to be "success or failure"
Mar 25 09:53:35.813: INFO: Pod "pod-secrets-c1ccecd8-56c6-4641-8853-497921a3dd12": Phase="Pending", Reason="", readiness=false. Elapsed: 4.275648ms
Mar 25 09:53:37.817: INFO: Pod "pod-secrets-c1ccecd8-56c6-4641-8853-497921a3dd12": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008020041s
STEP: Saw pod success
Mar 25 09:53:37.817: INFO: Pod "pod-secrets-c1ccecd8-56c6-4641-8853-497921a3dd12" satisfied condition "success or failure"
Mar 25 09:53:37.820: INFO: Trying to get logs from node ip-10-90-32-23.eu-west-2.compute.internal pod pod-secrets-c1ccecd8-56c6-4641-8853-497921a3dd12 container secret-volume-test: <nil>
STEP: delete the pod
Mar 25 09:53:37.836: INFO: Waiting for pod pod-secrets-c1ccecd8-56c6-4641-8853-497921a3dd12 to disappear
Mar 25 09:53:37.837: INFO: Pod pod-secrets-c1ccecd8-56c6-4641-8853-497921a3dd12 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 09:53:37.838: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-4158" for this suite.
Mar 25 09:53:43.849: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 09:53:43.927: INFO: namespace secrets-4158 deletion completed in 6.086803188s

• [SLOW TEST:8.260 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 09:53:43.927: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-326
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1685
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Mar 25 09:53:44.060: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-326'
Mar 25 09:53:44.385: INFO: stderr: ""
Mar 25 09:53:44.385: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1690
Mar 25 09:53:44.388: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 delete pods e2e-test-nginx-pod --namespace=kubectl-326'
Mar 25 09:53:56.766: INFO: stderr: ""
Mar 25 09:53:56.766: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 09:53:56.766: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-326" for this suite.
Mar 25 09:54:02.778: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 09:54:02.847: INFO: namespace kubectl-326 deletion completed in 6.077186358s

• [SLOW TEST:18.919 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run pod
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 09:54:02.848: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-4321
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:81
Mar 25 09:54:02.978: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Mar 25 09:54:02.984: INFO: Waiting for terminating namespaces to be deleted...
Mar 25 09:54:02.986: INFO: 
Logging pods the kubelet thinks is on node ip-10-90-32-22.eu-west-2.compute.internal before test
Mar 25 09:54:02.993: INFO: sonobuoy from heptio-sonobuoy started at 2020-03-25 08:52:05 +0000 UTC (1 container statuses recorded)
Mar 25 09:54:02.993: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Mar 25 09:54:02.993: INFO: coredns-84c98f9bb6-jtxmm from kube-system started at 2020-03-23 08:59:43 +0000 UTC (1 container statuses recorded)
Mar 25 09:54:02.993: INFO: 	Container coredns ready: true, restart count 0
Mar 25 09:54:02.993: INFO: filebeat-rfcxf from kube-system started at 2020-03-23 08:46:09 +0000 UTC (1 container statuses recorded)
Mar 25 09:54:02.993: INFO: 	Container filebeat ready: true, restart count 0
Mar 25 09:54:02.993: INFO: kubernetes-dashboard-84ffbc8546-bph6j from kube-system started at 2020-03-23 08:46:30 +0000 UTC (1 container statuses recorded)
Mar 25 09:54:02.993: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Mar 25 09:54:02.993: INFO: sonobuoy-systemd-logs-daemon-set-881e638473c24530-zhx7s from heptio-sonobuoy started at 2020-03-25 08:52:11 +0000 UTC (2 container statuses recorded)
Mar 25 09:54:02.993: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Mar 25 09:54:02.993: INFO: 	Container systemd-logs ready: true, restart count 1
Mar 25 09:54:02.993: INFO: traefik-ingress-controller-d8npl from traefik-ingress started at 2020-03-23 09:01:47 +0000 UTC (1 container statuses recorded)
Mar 25 09:54:02.993: INFO: 	Container traefik-ingress-lb ready: true, restart count 0
Mar 25 09:54:02.993: INFO: 
Logging pods the kubelet thinks is on node ip-10-90-32-23.eu-west-2.compute.internal before test
Mar 25 09:54:02.997: INFO: filebeat-4w76v from kube-system started at 2020-03-23 08:49:56 +0000 UTC (1 container statuses recorded)
Mar 25 09:54:02.997: INFO: 	Container filebeat ready: true, restart count 0
Mar 25 09:54:02.997: INFO: traefik-ingress-controller-nwxk9 from traefik-ingress started at 2020-03-23 09:01:51 +0000 UTC (1 container statuses recorded)
Mar 25 09:54:02.997: INFO: 	Container traefik-ingress-lb ready: true, restart count 0
Mar 25 09:54:02.997: INFO: coredns-84c98f9bb6-jw9th from kube-system started at 2020-03-23 08:59:41 +0000 UTC (1 container statuses recorded)
Mar 25 09:54:02.997: INFO: 	Container coredns ready: true, restart count 0
Mar 25 09:54:02.997: INFO: sonobuoy-systemd-logs-daemon-set-881e638473c24530-4r6qn from heptio-sonobuoy started at 2020-03-25 08:52:11 +0000 UTC (2 container statuses recorded)
Mar 25 09:54:02.997: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Mar 25 09:54:02.997: INFO: 	Container systemd-logs ready: true, restart count 1
Mar 25 09:54:02.997: INFO: nginx-7db9fccd9b-w4mt2 from miro started at 2020-03-23 08:50:25 +0000 UTC (1 container statuses recorded)
Mar 25 09:54:02.997: INFO: 	Container nginx ready: true, restart count 0
Mar 25 09:54:02.997: INFO: 
Logging pods the kubelet thinks is on node ip-10-90-32-24.eu-west-2.compute.internal before test
Mar 25 09:54:03.003: INFO: filebeat-b24zt from kube-system started at 2020-03-23 08:53:59 +0000 UTC (1 container statuses recorded)
Mar 25 09:54:03.003: INFO: 	Container filebeat ready: true, restart count 0
Mar 25 09:54:03.003: INFO: coredns-84c98f9bb6-hdmp4 from kube-system started at 2020-03-23 08:59:41 +0000 UTC (1 container statuses recorded)
Mar 25 09:54:03.003: INFO: 	Container coredns ready: true, restart count 0
Mar 25 09:54:03.003: INFO: traefik-ingress-controller-8wz6n from traefik-ingress started at 2020-03-23 09:01:43 +0000 UTC (1 container statuses recorded)
Mar 25 09:54:03.003: INFO: 	Container traefik-ingress-lb ready: true, restart count 0
Mar 25 09:54:03.003: INFO: metrics-server-5998746b76-qchjq from kube-system started at 2020-03-23 08:59:45 +0000 UTC (1 container statuses recorded)
Mar 25 09:54:03.003: INFO: 	Container metrics-server ready: true, restart count 0
Mar 25 09:54:03.003: INFO: sonobuoy-e2e-job-da73411fd655405d from heptio-sonobuoy started at 2020-03-25 08:52:11 +0000 UTC (2 container statuses recorded)
Mar 25 09:54:03.003: INFO: 	Container e2e ready: true, restart count 0
Mar 25 09:54:03.003: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar 25 09:54:03.003: INFO: sonobuoy-systemd-logs-daemon-set-881e638473c24530-r7mb9 from heptio-sonobuoy started at 2020-03-25 08:52:11 +0000 UTC (2 container statuses recorded)
Mar 25 09:54:03.003: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Mar 25 09:54:03.003: INFO: 	Container systemd-logs ready: true, restart count 1
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.15ff836030f7fdf9], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 09:54:04.022: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-4321" for this suite.
Mar 25 09:54:10.033: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 09:54:10.103: INFO: namespace sched-pred-4321 deletion completed in 6.078739468s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:72

• [SLOW TEST:7.256 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 09:54:10.104: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-4974
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Mar 25 09:54:10.297: INFO: Waiting up to 5m0s for pod "downwardapi-volume-de4fb584-4e50-4d9d-b538-e80bb62f5591" in namespace "downward-api-4974" to be "success or failure"
Mar 25 09:54:10.305: INFO: Pod "downwardapi-volume-de4fb584-4e50-4d9d-b538-e80bb62f5591": Phase="Pending", Reason="", readiness=false. Elapsed: 7.226559ms
Mar 25 09:54:12.308: INFO: Pod "downwardapi-volume-de4fb584-4e50-4d9d-b538-e80bb62f5591": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01029266s
Mar 25 09:54:14.311: INFO: Pod "downwardapi-volume-de4fb584-4e50-4d9d-b538-e80bb62f5591": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013203957s
STEP: Saw pod success
Mar 25 09:54:14.311: INFO: Pod "downwardapi-volume-de4fb584-4e50-4d9d-b538-e80bb62f5591" satisfied condition "success or failure"
Mar 25 09:54:14.313: INFO: Trying to get logs from node ip-10-90-32-23.eu-west-2.compute.internal pod downwardapi-volume-de4fb584-4e50-4d9d-b538-e80bb62f5591 container client-container: <nil>
STEP: delete the pod
Mar 25 09:54:14.328: INFO: Waiting for pod downwardapi-volume-de4fb584-4e50-4d9d-b538-e80bb62f5591 to disappear
Mar 25 09:54:14.330: INFO: Pod downwardapi-volume-de4fb584-4e50-4d9d-b538-e80bb62f5591 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 09:54:14.330: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4974" for this suite.
Mar 25 09:54:20.341: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 09:54:20.405: INFO: namespace downward-api-4974 deletion completed in 6.072880216s

• [SLOW TEST:10.301 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 09:54:20.406: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-1541
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test substitution in container's args
Mar 25 09:54:20.543: INFO: Waiting up to 5m0s for pod "var-expansion-90457bae-d3de-42bd-b09e-dced98552008" in namespace "var-expansion-1541" to be "success or failure"
Mar 25 09:54:20.547: INFO: Pod "var-expansion-90457bae-d3de-42bd-b09e-dced98552008": Phase="Pending", Reason="", readiness=false. Elapsed: 3.778353ms
Mar 25 09:54:22.549: INFO: Pod "var-expansion-90457bae-d3de-42bd-b09e-dced98552008": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006644603s
STEP: Saw pod success
Mar 25 09:54:22.549: INFO: Pod "var-expansion-90457bae-d3de-42bd-b09e-dced98552008" satisfied condition "success or failure"
Mar 25 09:54:22.552: INFO: Trying to get logs from node ip-10-90-32-23.eu-west-2.compute.internal pod var-expansion-90457bae-d3de-42bd-b09e-dced98552008 container dapi-container: <nil>
STEP: delete the pod
Mar 25 09:54:22.566: INFO: Waiting for pod var-expansion-90457bae-d3de-42bd-b09e-dced98552008 to disappear
Mar 25 09:54:22.568: INFO: Pod var-expansion-90457bae-d3de-42bd-b09e-dced98552008 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 09:54:22.568: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-1541" for this suite.
Mar 25 09:54:28.579: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 09:54:28.646: INFO: namespace var-expansion-1541 deletion completed in 6.075041665s

• [SLOW TEST:8.240 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 09:54:28.647: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-5845
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:273
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the initial replication controller
Mar 25 09:54:28.829: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 create -f - --namespace=kubectl-5845'
Mar 25 09:54:28.990: INFO: stderr: ""
Mar 25 09:54:28.990: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Mar 25 09:54:28.990: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-5845'
Mar 25 09:54:29.067: INFO: stderr: ""
Mar 25 09:54:29.067: INFO: stdout: "update-demo-nautilus-gd655 update-demo-nautilus-gglkz "
Mar 25 09:54:29.067: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 get pods update-demo-nautilus-gd655 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-5845'
Mar 25 09:54:29.137: INFO: stderr: ""
Mar 25 09:54:29.137: INFO: stdout: ""
Mar 25 09:54:29.137: INFO: update-demo-nautilus-gd655 is created but not running
Mar 25 09:54:34.137: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-5845'
Mar 25 09:54:34.205: INFO: stderr: ""
Mar 25 09:54:34.205: INFO: stdout: "update-demo-nautilus-gd655 update-demo-nautilus-gglkz "
Mar 25 09:54:34.205: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 get pods update-demo-nautilus-gd655 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-5845'
Mar 25 09:54:34.272: INFO: stderr: ""
Mar 25 09:54:34.272: INFO: stdout: "true"
Mar 25 09:54:34.273: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 get pods update-demo-nautilus-gd655 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-5845'
Mar 25 09:54:34.338: INFO: stderr: ""
Mar 25 09:54:34.338: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar 25 09:54:34.338: INFO: validating pod update-demo-nautilus-gd655
Mar 25 09:54:34.342: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar 25 09:54:34.342: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar 25 09:54:34.342: INFO: update-demo-nautilus-gd655 is verified up and running
Mar 25 09:54:34.342: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 get pods update-demo-nautilus-gglkz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-5845'
Mar 25 09:54:34.408: INFO: stderr: ""
Mar 25 09:54:34.408: INFO: stdout: "true"
Mar 25 09:54:34.408: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 get pods update-demo-nautilus-gglkz -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-5845'
Mar 25 09:54:34.473: INFO: stderr: ""
Mar 25 09:54:34.473: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar 25 09:54:34.473: INFO: validating pod update-demo-nautilus-gglkz
Mar 25 09:54:34.478: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar 25 09:54:34.478: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar 25 09:54:34.478: INFO: update-demo-nautilus-gglkz is verified up and running
STEP: rolling-update to new replication controller
Mar 25 09:54:34.480: INFO: scanned /root for discovery docs: <nil>
Mar 25 09:54:34.480: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=kubectl-5845'
Mar 25 09:54:56.817: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Mar 25 09:54:56.817: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Mar 25 09:54:56.817: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-5845'
Mar 25 09:54:56.886: INFO: stderr: ""
Mar 25 09:54:56.886: INFO: stdout: "update-demo-kitten-hl24b update-demo-kitten-hlmgh "
Mar 25 09:54:56.886: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 get pods update-demo-kitten-hl24b -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-5845'
Mar 25 09:54:56.951: INFO: stderr: ""
Mar 25 09:54:56.951: INFO: stdout: "true"
Mar 25 09:54:56.951: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 get pods update-demo-kitten-hl24b -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-5845'
Mar 25 09:54:57.019: INFO: stderr: ""
Mar 25 09:54:57.019: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Mar 25 09:54:57.019: INFO: validating pod update-demo-kitten-hl24b
Mar 25 09:54:57.023: INFO: got data: {
  "image": "kitten.jpg"
}

Mar 25 09:54:57.023: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Mar 25 09:54:57.023: INFO: update-demo-kitten-hl24b is verified up and running
Mar 25 09:54:57.023: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 get pods update-demo-kitten-hlmgh -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-5845'
Mar 25 09:54:57.088: INFO: stderr: ""
Mar 25 09:54:57.088: INFO: stdout: "true"
Mar 25 09:54:57.088: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 get pods update-demo-kitten-hlmgh -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-5845'
Mar 25 09:54:57.153: INFO: stderr: ""
Mar 25 09:54:57.153: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Mar 25 09:54:57.153: INFO: validating pod update-demo-kitten-hlmgh
Mar 25 09:54:57.157: INFO: got data: {
  "image": "kitten.jpg"
}

Mar 25 09:54:57.157: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Mar 25 09:54:57.157: INFO: update-demo-kitten-hlmgh is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 09:54:57.157: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5845" for this suite.
Mar 25 09:55:19.168: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 09:55:19.233: INFO: namespace kubectl-5845 deletion completed in 22.073252746s

• [SLOW TEST:50.587 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 09:55:19.234: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-9702
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: executing a command with run --rm and attach with stdin
Mar 25 09:55:19.416: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 --namespace=kubectl-9702 run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Mar 25 09:55:21.466: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Mar 25 09:55:21.466: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 09:55:23.470: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9702" for this suite.
Mar 25 09:55:29.482: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 09:55:29.555: INFO: namespace kubectl-9702 deletion completed in 6.081607631s

• [SLOW TEST:10.321 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run --rm job
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 09:55:29.556: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-6303
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod liveness-9cd639a6-d8c7-4935-8a16-27ada47bb7d7 in namespace container-probe-6303
Mar 25 09:55:33.718: INFO: Started pod liveness-9cd639a6-d8c7-4935-8a16-27ada47bb7d7 in namespace container-probe-6303
STEP: checking the pod's current state and verifying that restartCount is present
Mar 25 09:55:33.720: INFO: Initial restart count of pod liveness-9cd639a6-d8c7-4935-8a16-27ada47bb7d7 is 0
Mar 25 09:55:53.751: INFO: Restart count of pod container-probe-6303/liveness-9cd639a6-d8c7-4935-8a16-27ada47bb7d7 is now 1 (20.031615861s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 09:55:53.762: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-6303" for this suite.
Mar 25 09:55:59.775: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 09:55:59.845: INFO: namespace container-probe-6303 deletion completed in 6.080101528s

• [SLOW TEST:30.289 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 09:55:59.845: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-1262
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-433f2066-ec8b-4084-aee7-a1369fc37827
STEP: Creating a pod to test consume secrets
Mar 25 09:55:59.987: INFO: Waiting up to 5m0s for pod "pod-secrets-e06a13b7-fbd3-4fe4-b63b-5cd8e0c91bf1" in namespace "secrets-1262" to be "success or failure"
Mar 25 09:55:59.991: INFO: Pod "pod-secrets-e06a13b7-fbd3-4fe4-b63b-5cd8e0c91bf1": Phase="Pending", Reason="", readiness=false. Elapsed: 3.636301ms
Mar 25 09:56:01.994: INFO: Pod "pod-secrets-e06a13b7-fbd3-4fe4-b63b-5cd8e0c91bf1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006818158s
STEP: Saw pod success
Mar 25 09:56:01.994: INFO: Pod "pod-secrets-e06a13b7-fbd3-4fe4-b63b-5cd8e0c91bf1" satisfied condition "success or failure"
Mar 25 09:56:01.996: INFO: Trying to get logs from node ip-10-90-32-23.eu-west-2.compute.internal pod pod-secrets-e06a13b7-fbd3-4fe4-b63b-5cd8e0c91bf1 container secret-volume-test: <nil>
STEP: delete the pod
Mar 25 09:56:02.016: INFO: Waiting for pod pod-secrets-e06a13b7-fbd3-4fe4-b63b-5cd8e0c91bf1 to disappear
Mar 25 09:56:02.018: INFO: Pod pod-secrets-e06a13b7-fbd3-4fe4-b63b-5cd8e0c91bf1 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 09:56:02.018: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-1262" for this suite.
Mar 25 09:56:08.030: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 09:56:08.099: INFO: namespace secrets-1262 deletion completed in 6.078264475s

• [SLOW TEST:8.254 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 09:56:08.099: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7499
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Mar 25 09:56:08.238: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6fb2b820-fd4c-475b-ab2b-830a1650f5a2" in namespace "projected-7499" to be "success or failure"
Mar 25 09:56:08.246: INFO: Pod "downwardapi-volume-6fb2b820-fd4c-475b-ab2b-830a1650f5a2": Phase="Pending", Reason="", readiness=false. Elapsed: 7.644996ms
Mar 25 09:56:10.249: INFO: Pod "downwardapi-volume-6fb2b820-fd4c-475b-ab2b-830a1650f5a2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010689099s
Mar 25 09:56:12.252: INFO: Pod "downwardapi-volume-6fb2b820-fd4c-475b-ab2b-830a1650f5a2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013793723s
STEP: Saw pod success
Mar 25 09:56:12.252: INFO: Pod "downwardapi-volume-6fb2b820-fd4c-475b-ab2b-830a1650f5a2" satisfied condition "success or failure"
Mar 25 09:56:12.254: INFO: Trying to get logs from node ip-10-90-32-22.eu-west-2.compute.internal pod downwardapi-volume-6fb2b820-fd4c-475b-ab2b-830a1650f5a2 container client-container: <nil>
STEP: delete the pod
Mar 25 09:56:12.271: INFO: Waiting for pod downwardapi-volume-6fb2b820-fd4c-475b-ab2b-830a1650f5a2 to disappear
Mar 25 09:56:12.273: INFO: Pod downwardapi-volume-6fb2b820-fd4c-475b-ab2b-830a1650f5a2 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 09:56:12.274: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7499" for this suite.
Mar 25 09:56:18.285: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 09:56:18.352: INFO: namespace projected-7499 deletion completed in 6.075566548s

• [SLOW TEST:10.253 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 09:56:18.353: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-8096
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Mar 25 09:56:18.494: INFO: Pod name rollover-pod: Found 0 pods out of 1
Mar 25 09:56:23.497: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Mar 25 09:56:23.497: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Mar 25 09:56:25.500: INFO: Creating deployment "test-rollover-deployment"
Mar 25 09:56:25.508: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Mar 25 09:56:27.521: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Mar 25 09:56:27.525: INFO: Ensure that both replica sets have 1 created replica
Mar 25 09:56:27.529: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Mar 25 09:56:27.536: INFO: Updating deployment test-rollover-deployment
Mar 25 09:56:27.536: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Mar 25 09:56:29.548: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Mar 25 09:56:29.552: INFO: Make sure deployment "test-rollover-deployment" is complete
Mar 25 09:56:29.556: INFO: all replica sets need to contain the pod-template-hash label
Mar 25 09:56:29.556: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720726985, loc:(*time.Location)(0x7ed0a00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720726985, loc:(*time.Location)(0x7ed0a00)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720726989, loc:(*time.Location)(0x7ed0a00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720726985, loc:(*time.Location)(0x7ed0a00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 25 09:56:31.562: INFO: all replica sets need to contain the pod-template-hash label
Mar 25 09:56:31.562: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720726985, loc:(*time.Location)(0x7ed0a00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720726985, loc:(*time.Location)(0x7ed0a00)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720726989, loc:(*time.Location)(0x7ed0a00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720726985, loc:(*time.Location)(0x7ed0a00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 25 09:56:33.562: INFO: all replica sets need to contain the pod-template-hash label
Mar 25 09:56:33.562: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720726985, loc:(*time.Location)(0x7ed0a00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720726985, loc:(*time.Location)(0x7ed0a00)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720726989, loc:(*time.Location)(0x7ed0a00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720726985, loc:(*time.Location)(0x7ed0a00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 25 09:56:35.562: INFO: all replica sets need to contain the pod-template-hash label
Mar 25 09:56:35.562: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720726985, loc:(*time.Location)(0x7ed0a00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720726985, loc:(*time.Location)(0x7ed0a00)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720726989, loc:(*time.Location)(0x7ed0a00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720726985, loc:(*time.Location)(0x7ed0a00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 25 09:56:37.562: INFO: all replica sets need to contain the pod-template-hash label
Mar 25 09:56:37.562: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720726985, loc:(*time.Location)(0x7ed0a00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720726985, loc:(*time.Location)(0x7ed0a00)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720726989, loc:(*time.Location)(0x7ed0a00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720726985, loc:(*time.Location)(0x7ed0a00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 25 09:56:39.562: INFO: 
Mar 25 09:56:39.562: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
Mar 25 09:56:39.568: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment,GenerateName:,Namespace:deployment-8096,SelfLink:/apis/apps/v1/namespaces/deployment-8096/deployments/test-rollover-deployment,UID:cf2376c3-54d9-4202-b65e-100460c48cb8,ResourceVersion:341867,Generation:2,CreationTimestamp:2020-03-25 09:56:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2020-03-25 09:56:25 +0000 UTC 2020-03-25 09:56:25 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2020-03-25 09:56:39 +0000 UTC 2020-03-25 09:56:25 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rollover-deployment-854595fc44" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Mar 25 09:56:39.570: INFO: New ReplicaSet "test-rollover-deployment-854595fc44" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-854595fc44,GenerateName:,Namespace:deployment-8096,SelfLink:/apis/apps/v1/namespaces/deployment-8096/replicasets/test-rollover-deployment-854595fc44,UID:efd1a72b-e37e-436d-be14-6100c371b6a0,ResourceVersion:341857,Generation:2,CreationTimestamp:2020-03-25 09:56:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 854595fc44,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment cf2376c3-54d9-4202-b65e-100460c48cb8 0xc002899437 0xc002899438}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 854595fc44,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 854595fc44,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Mar 25 09:56:39.570: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Mar 25 09:56:39.570: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-controller,GenerateName:,Namespace:deployment-8096,SelfLink:/apis/apps/v1/namespaces/deployment-8096/replicasets/test-rollover-controller,UID:bbfdc03b-1cc7-4808-90cf-adfbe081e98a,ResourceVersion:341866,Generation:2,CreationTimestamp:2020-03-25 09:56:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment cf2376c3-54d9-4202-b65e-100460c48cb8 0xc002899357 0xc002899358}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Mar 25 09:56:39.571: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-9b8b997cf,GenerateName:,Namespace:deployment-8096,SelfLink:/apis/apps/v1/namespaces/deployment-8096/replicasets/test-rollover-deployment-9b8b997cf,UID:34009bc0-209a-495a-b080-a39b3d8e66a3,ResourceVersion:341831,Generation:2,CreationTimestamp:2020-03-25 09:56:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 9b8b997cf,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment cf2376c3-54d9-4202-b65e-100460c48cb8 0xc002899500 0xc002899501}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 9b8b997cf,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 9b8b997cf,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Mar 25 09:56:39.573: INFO: Pod "test-rollover-deployment-854595fc44-fb565" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-854595fc44-fb565,GenerateName:test-rollover-deployment-854595fc44-,Namespace:deployment-8096,SelfLink:/api/v1/namespaces/deployment-8096/pods/test-rollover-deployment-854595fc44-fb565,UID:8ee55f37-9d49-48c8-9041-824cf66a1e5e,ResourceVersion:341840,Generation:0,CreationTimestamp:2020-03-25 09:56:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 854595fc44,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rollover-deployment-854595fc44 efd1a72b-e37e-436d-be14-6100c371b6a0 0xc00340c117 0xc00340c118}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-58sh2 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-58sh2,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-58sh2 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-90-32-22.eu-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00340c180} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00340c1a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-25 09:56:27 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2020-03-25 09:56:29 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2020-03-25 09:56:29 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-25 09:56:27 +0000 UTC  }],Message:,Reason:,HostIP:10.90.32.22,PodIP:10.200.33.45,StartTime:2020-03-25 09:56:27 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2020-03-25 09:56:28 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://10e7e7e6e60a2ad1af77539653fb1a1301763fdf0f2ae605b819990c03b6f7db}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 09:56:39.573: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-8096" for this suite.
Mar 25 09:56:45.585: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 09:56:45.652: INFO: namespace deployment-8096 deletion completed in 6.075468583s

• [SLOW TEST:27.299 seconds]
[sig-apps] Deployment
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support rollover [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 09:56:45.652: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-1836
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating all guestbook components
Mar 25 09:56:45.783: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Mar 25 09:56:45.783: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 create -f - --namespace=kubectl-1836'
Mar 25 09:56:45.938: INFO: stderr: ""
Mar 25 09:56:45.938: INFO: stdout: "service/redis-slave created\n"
Mar 25 09:56:45.938: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Mar 25 09:56:45.938: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 create -f - --namespace=kubectl-1836'
Mar 25 09:56:46.121: INFO: stderr: ""
Mar 25 09:56:46.121: INFO: stdout: "service/redis-master created\n"
Mar 25 09:56:46.121: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Mar 25 09:56:46.121: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 create -f - --namespace=kubectl-1836'
Mar 25 09:56:46.292: INFO: stderr: ""
Mar 25 09:56:46.292: INFO: stdout: "service/frontend created\n"
Mar 25 09:56:46.292: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: guestbook
      tier: frontend
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Mar 25 09:56:46.292: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 create -f - --namespace=kubectl-1836'
Mar 25 09:56:46.473: INFO: stderr: ""
Mar 25 09:56:46.473: INFO: stdout: "deployment.apps/frontend created\n"
Mar 25 09:56:46.473: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  selector:
    matchLabels:
      app: redis
      role: master
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Mar 25 09:56:46.474: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 create -f - --namespace=kubectl-1836'
Mar 25 09:56:46.645: INFO: stderr: ""
Mar 25 09:56:46.645: INFO: stdout: "deployment.apps/redis-master created\n"
Mar 25 09:56:46.646: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  selector:
    matchLabels:
      app: redis
      role: slave
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave:v3
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Mar 25 09:56:46.646: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 create -f - --namespace=kubectl-1836'
Mar 25 09:56:46.805: INFO: stderr: ""
Mar 25 09:56:46.805: INFO: stdout: "deployment.apps/redis-slave created\n"
STEP: validating guestbook app
Mar 25 09:56:46.805: INFO: Waiting for all frontend pods to be Running.
Mar 25 09:57:06.856: INFO: Waiting for frontend to serve content.
Mar 25 09:57:06.870: INFO: Trying to add a new entry to the guestbook.
Mar 25 09:57:06.882: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Mar 25 09:57:06.891: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 delete --grace-period=0 --force -f - --namespace=kubectl-1836'
Mar 25 09:57:06.974: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar 25 09:57:06.974: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Mar 25 09:57:06.975: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 delete --grace-period=0 --force -f - --namespace=kubectl-1836'
Mar 25 09:57:07.077: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar 25 09:57:07.077: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Mar 25 09:57:07.078: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 delete --grace-period=0 --force -f - --namespace=kubectl-1836'
Mar 25 09:57:07.180: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar 25 09:57:07.180: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Mar 25 09:57:07.181: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 delete --grace-period=0 --force -f - --namespace=kubectl-1836'
Mar 25 09:57:07.268: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar 25 09:57:07.268: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Mar 25 09:57:07.268: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 delete --grace-period=0 --force -f - --namespace=kubectl-1836'
Mar 25 09:57:07.366: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar 25 09:57:07.366: INFO: stdout: "deployment.apps \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Mar 25 09:57:07.366: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 delete --grace-period=0 --force -f - --namespace=kubectl-1836'
Mar 25 09:57:07.464: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar 25 09:57:07.464: INFO: stdout: "deployment.apps \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 09:57:07.464: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1836" for this suite.
Mar 25 09:57:53.492: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 09:57:53.559: INFO: namespace kubectl-1836 deletion completed in 46.086603526s

• [SLOW TEST:67.907 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Guestbook application
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] version v1
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 09:57:53.560: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-1108
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Mar 25 09:57:53.698: INFO: (0) /api/v1/nodes/ip-10-90-32-22.eu-west-2.compute.internal/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 4.587216ms)
Mar 25 09:57:53.700: INFO: (1) /api/v1/nodes/ip-10-90-32-22.eu-west-2.compute.internal/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 2.688944ms)
Mar 25 09:57:53.703: INFO: (2) /api/v1/nodes/ip-10-90-32-22.eu-west-2.compute.internal/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 2.723701ms)
Mar 25 09:57:53.706: INFO: (3) /api/v1/nodes/ip-10-90-32-22.eu-west-2.compute.internal/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 2.634528ms)
Mar 25 09:57:53.709: INFO: (4) /api/v1/nodes/ip-10-90-32-22.eu-west-2.compute.internal/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 2.729368ms)
Mar 25 09:57:53.711: INFO: (5) /api/v1/nodes/ip-10-90-32-22.eu-west-2.compute.internal/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 2.714501ms)
Mar 25 09:57:53.714: INFO: (6) /api/v1/nodes/ip-10-90-32-22.eu-west-2.compute.internal/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 2.943275ms)
Mar 25 09:57:53.717: INFO: (7) /api/v1/nodes/ip-10-90-32-22.eu-west-2.compute.internal/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 2.835865ms)
Mar 25 09:57:53.720: INFO: (8) /api/v1/nodes/ip-10-90-32-22.eu-west-2.compute.internal/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 2.918717ms)
Mar 25 09:57:53.723: INFO: (9) /api/v1/nodes/ip-10-90-32-22.eu-west-2.compute.internal/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 2.841314ms)
Mar 25 09:57:53.726: INFO: (10) /api/v1/nodes/ip-10-90-32-22.eu-west-2.compute.internal/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 2.956491ms)
Mar 25 09:57:53.729: INFO: (11) /api/v1/nodes/ip-10-90-32-22.eu-west-2.compute.internal/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 2.877774ms)
Mar 25 09:57:53.732: INFO: (12) /api/v1/nodes/ip-10-90-32-22.eu-west-2.compute.internal/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 2.918473ms)
Mar 25 09:57:53.735: INFO: (13) /api/v1/nodes/ip-10-90-32-22.eu-west-2.compute.internal/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 2.863053ms)
Mar 25 09:57:53.737: INFO: (14) /api/v1/nodes/ip-10-90-32-22.eu-west-2.compute.internal/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 2.803014ms)
Mar 25 09:57:53.740: INFO: (15) /api/v1/nodes/ip-10-90-32-22.eu-west-2.compute.internal/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 2.785865ms)
Mar 25 09:57:53.743: INFO: (16) /api/v1/nodes/ip-10-90-32-22.eu-west-2.compute.internal/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 2.674957ms)
Mar 25 09:57:53.746: INFO: (17) /api/v1/nodes/ip-10-90-32-22.eu-west-2.compute.internal/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 2.672096ms)
Mar 25 09:57:53.749: INFO: (18) /api/v1/nodes/ip-10-90-32-22.eu-west-2.compute.internal/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 2.763368ms)
Mar 25 09:57:53.751: INFO: (19) /api/v1/nodes/ip-10-90-32-22.eu-west-2.compute.internal/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 2.660624ms)
[AfterEach] version v1
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 09:57:53.752: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-1108" for this suite.
Mar 25 09:57:59.763: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 09:57:59.829: INFO: namespace proxy-1108 deletion completed in 6.074663808s

• [SLOW TEST:6.269 seconds]
[sig-network] Proxy
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:58
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 09:57:59.829: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-3023
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0777 on tmpfs
Mar 25 09:58:00.036: INFO: Waiting up to 5m0s for pod "pod-46804913-4ebd-4be8-94ff-7fd817950f9e" in namespace "emptydir-3023" to be "success or failure"
Mar 25 09:58:00.046: INFO: Pod "pod-46804913-4ebd-4be8-94ff-7fd817950f9e": Phase="Pending", Reason="", readiness=false. Elapsed: 10.486364ms
Mar 25 09:58:02.049: INFO: Pod "pod-46804913-4ebd-4be8-94ff-7fd817950f9e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013448573s
STEP: Saw pod success
Mar 25 09:58:02.049: INFO: Pod "pod-46804913-4ebd-4be8-94ff-7fd817950f9e" satisfied condition "success or failure"
Mar 25 09:58:02.051: INFO: Trying to get logs from node ip-10-90-32-23.eu-west-2.compute.internal pod pod-46804913-4ebd-4be8-94ff-7fd817950f9e container test-container: <nil>
STEP: delete the pod
Mar 25 09:58:02.067: INFO: Waiting for pod pod-46804913-4ebd-4be8-94ff-7fd817950f9e to disappear
Mar 25 09:58:02.069: INFO: Pod pod-46804913-4ebd-4be8-94ff-7fd817950f9e no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 09:58:02.069: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3023" for this suite.
Mar 25 09:58:08.086: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 09:58:08.153: INFO: namespace emptydir-3023 deletion completed in 6.077056198s

• [SLOW TEST:8.324 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 09:58:08.154: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6854
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-99f89b97-0890-4879-b122-697eb8dda650
STEP: Creating a pod to test consume configMaps
Mar 25 09:58:08.294: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-35ebf578-3c72-47a0-ae90-2ebc718b24f9" in namespace "projected-6854" to be "success or failure"
Mar 25 09:58:08.298: INFO: Pod "pod-projected-configmaps-35ebf578-3c72-47a0-ae90-2ebc718b24f9": Phase="Pending", Reason="", readiness=false. Elapsed: 3.878096ms
Mar 25 09:58:10.301: INFO: Pod "pod-projected-configmaps-35ebf578-3c72-47a0-ae90-2ebc718b24f9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006733972s
STEP: Saw pod success
Mar 25 09:58:10.301: INFO: Pod "pod-projected-configmaps-35ebf578-3c72-47a0-ae90-2ebc718b24f9" satisfied condition "success or failure"
Mar 25 09:58:10.303: INFO: Trying to get logs from node ip-10-90-32-23.eu-west-2.compute.internal pod pod-projected-configmaps-35ebf578-3c72-47a0-ae90-2ebc718b24f9 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Mar 25 09:58:10.319: INFO: Waiting for pod pod-projected-configmaps-35ebf578-3c72-47a0-ae90-2ebc718b24f9 to disappear
Mar 25 09:58:10.321: INFO: Pod pod-projected-configmaps-35ebf578-3c72-47a0-ae90-2ebc718b24f9 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 09:58:10.321: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6854" for this suite.
Mar 25 09:58:16.332: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 09:58:16.399: INFO: namespace projected-6854 deletion completed in 6.075160344s

• [SLOW TEST:8.245 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 09:58:16.400: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-4210
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Mar 25 09:58:16.545: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-4210,SelfLink:/api/v1/namespaces/watch-4210/configmaps/e2e-watch-test-label-changed,UID:21e52376-3cc2-4acd-8f49-eb730a93b939,ResourceVersion:342318,Generation:0,CreationTimestamp:2020-03-25 09:58:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Mar 25 09:58:16.545: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-4210,SelfLink:/api/v1/namespaces/watch-4210/configmaps/e2e-watch-test-label-changed,UID:21e52376-3cc2-4acd-8f49-eb730a93b939,ResourceVersion:342319,Generation:0,CreationTimestamp:2020-03-25 09:58:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Mar 25 09:58:16.545: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-4210,SelfLink:/api/v1/namespaces/watch-4210/configmaps/e2e-watch-test-label-changed,UID:21e52376-3cc2-4acd-8f49-eb730a93b939,ResourceVersion:342320,Generation:0,CreationTimestamp:2020-03-25 09:58:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Mar 25 09:58:26.568: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-4210,SelfLink:/api/v1/namespaces/watch-4210/configmaps/e2e-watch-test-label-changed,UID:21e52376-3cc2-4acd-8f49-eb730a93b939,ResourceVersion:342339,Generation:0,CreationTimestamp:2020-03-25 09:58:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Mar 25 09:58:26.568: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-4210,SelfLink:/api/v1/namespaces/watch-4210/configmaps/e2e-watch-test-label-changed,UID:21e52376-3cc2-4acd-8f49-eb730a93b939,ResourceVersion:342340,Generation:0,CreationTimestamp:2020-03-25 09:58:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Mar 25 09:58:26.568: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-4210,SelfLink:/api/v1/namespaces/watch-4210/configmaps/e2e-watch-test-label-changed,UID:21e52376-3cc2-4acd-8f49-eb730a93b939,ResourceVersion:342341,Generation:0,CreationTimestamp:2020-03-25 09:58:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 09:58:26.569: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-4210" for this suite.
Mar 25 09:58:32.580: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 09:58:32.650: INFO: namespace watch-4210 deletion completed in 6.078770848s

• [SLOW TEST:16.250 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 09:58:32.650: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-2294
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test substitution in container's command
Mar 25 09:58:32.840: INFO: Waiting up to 5m0s for pod "var-expansion-c120d147-b65e-40d1-b4db-d9f108ea6473" in namespace "var-expansion-2294" to be "success or failure"
Mar 25 09:58:32.847: INFO: Pod "var-expansion-c120d147-b65e-40d1-b4db-d9f108ea6473": Phase="Pending", Reason="", readiness=false. Elapsed: 7.057176ms
Mar 25 09:58:34.850: INFO: Pod "var-expansion-c120d147-b65e-40d1-b4db-d9f108ea6473": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010377179s
STEP: Saw pod success
Mar 25 09:58:34.850: INFO: Pod "var-expansion-c120d147-b65e-40d1-b4db-d9f108ea6473" satisfied condition "success or failure"
Mar 25 09:58:34.853: INFO: Trying to get logs from node ip-10-90-32-23.eu-west-2.compute.internal pod var-expansion-c120d147-b65e-40d1-b4db-d9f108ea6473 container dapi-container: <nil>
STEP: delete the pod
Mar 25 09:58:34.868: INFO: Waiting for pod var-expansion-c120d147-b65e-40d1-b4db-d9f108ea6473 to disappear
Mar 25 09:58:34.870: INFO: Pod var-expansion-c120d147-b65e-40d1-b4db-d9f108ea6473 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 09:58:34.870: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-2294" for this suite.
Mar 25 09:58:40.881: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 09:58:40.946: INFO: namespace var-expansion-2294 deletion completed in 6.072542913s

• [SLOW TEST:8.295 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 09:58:40.946: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-9749
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Mar 25 09:58:41.107: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:watch-9749,SelfLink:/api/v1/namespaces/watch-9749/configmaps/e2e-watch-test-resource-version,UID:cb76c275-50cd-4cdc-bf54-dc0718cf9217,ResourceVersion:342402,Generation:0,CreationTimestamp:2020-03-25 09:58:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Mar 25 09:58:41.107: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:watch-9749,SelfLink:/api/v1/namespaces/watch-9749/configmaps/e2e-watch-test-resource-version,UID:cb76c275-50cd-4cdc-bf54-dc0718cf9217,ResourceVersion:342403,Generation:0,CreationTimestamp:2020-03-25 09:58:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 09:58:41.107: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-9749" for this suite.
Mar 25 09:58:47.118: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 09:58:47.190: INFO: namespace watch-9749 deletion completed in 6.080026794s

• [SLOW TEST:6.244 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 09:58:47.191: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-8651
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:273
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a replication controller
Mar 25 09:58:47.323: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 create -f - --namespace=kubectl-8651'
Mar 25 09:58:47.477: INFO: stderr: ""
Mar 25 09:58:47.477: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Mar 25 09:58:47.477: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-8651'
Mar 25 09:58:47.564: INFO: stderr: ""
Mar 25 09:58:47.564: INFO: stdout: "update-demo-nautilus-wzb2d update-demo-nautilus-xjh2h "
Mar 25 09:58:47.564: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 get pods update-demo-nautilus-wzb2d -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-8651'
Mar 25 09:58:47.634: INFO: stderr: ""
Mar 25 09:58:47.634: INFO: stdout: ""
Mar 25 09:58:47.634: INFO: update-demo-nautilus-wzb2d is created but not running
Mar 25 09:58:52.634: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-8651'
Mar 25 09:58:52.709: INFO: stderr: ""
Mar 25 09:58:52.709: INFO: stdout: "update-demo-nautilus-wzb2d update-demo-nautilus-xjh2h "
Mar 25 09:58:52.709: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 get pods update-demo-nautilus-wzb2d -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-8651'
Mar 25 09:58:52.776: INFO: stderr: ""
Mar 25 09:58:52.776: INFO: stdout: "true"
Mar 25 09:58:52.776: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 get pods update-demo-nautilus-wzb2d -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-8651'
Mar 25 09:58:52.841: INFO: stderr: ""
Mar 25 09:58:52.841: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar 25 09:58:52.841: INFO: validating pod update-demo-nautilus-wzb2d
Mar 25 09:58:52.846: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar 25 09:58:52.846: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar 25 09:58:52.846: INFO: update-demo-nautilus-wzb2d is verified up and running
Mar 25 09:58:52.846: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 get pods update-demo-nautilus-xjh2h -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-8651'
Mar 25 09:58:52.911: INFO: stderr: ""
Mar 25 09:58:52.911: INFO: stdout: "true"
Mar 25 09:58:52.911: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 get pods update-demo-nautilus-xjh2h -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-8651'
Mar 25 09:58:52.976: INFO: stderr: ""
Mar 25 09:58:52.976: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar 25 09:58:52.976: INFO: validating pod update-demo-nautilus-xjh2h
Mar 25 09:58:52.982: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar 25 09:58:52.982: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar 25 09:58:52.982: INFO: update-demo-nautilus-xjh2h is verified up and running
STEP: using delete to clean up resources
Mar 25 09:58:52.982: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 delete --grace-period=0 --force -f - --namespace=kubectl-8651'
Mar 25 09:58:53.052: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar 25 09:58:53.052: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Mar 25 09:58:53.053: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-8651'
Mar 25 09:58:53.122: INFO: stderr: "No resources found.\n"
Mar 25 09:58:53.122: INFO: stdout: ""
Mar 25 09:58:53.122: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 get pods -l name=update-demo --namespace=kubectl-8651 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Mar 25 09:58:53.190: INFO: stderr: ""
Mar 25 09:58:53.190: INFO: stdout: "update-demo-nautilus-wzb2d\nupdate-demo-nautilus-xjh2h\n"
Mar 25 09:58:53.691: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-8651'
Mar 25 09:58:53.777: INFO: stderr: "No resources found.\n"
Mar 25 09:58:53.777: INFO: stdout: ""
Mar 25 09:58:53.777: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 get pods -l name=update-demo --namespace=kubectl-8651 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Mar 25 09:58:53.844: INFO: stderr: ""
Mar 25 09:58:53.844: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 09:58:53.844: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8651" for this suite.
Mar 25 09:59:15.855: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 09:59:15.929: INFO: namespace kubectl-8651 deletion completed in 22.082429545s

• [SLOW TEST:28.739 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 09:59:15.930: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-1052
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Mar 25 09:59:16.067: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9a8e87ad-54e0-4119-8bf1-a498740ca7ce" in namespace "downward-api-1052" to be "success or failure"
Mar 25 09:59:16.074: INFO: Pod "downwardapi-volume-9a8e87ad-54e0-4119-8bf1-a498740ca7ce": Phase="Pending", Reason="", readiness=false. Elapsed: 7.378627ms
Mar 25 09:59:18.077: INFO: Pod "downwardapi-volume-9a8e87ad-54e0-4119-8bf1-a498740ca7ce": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010291816s
STEP: Saw pod success
Mar 25 09:59:18.077: INFO: Pod "downwardapi-volume-9a8e87ad-54e0-4119-8bf1-a498740ca7ce" satisfied condition "success or failure"
Mar 25 09:59:18.080: INFO: Trying to get logs from node ip-10-90-32-22.eu-west-2.compute.internal pod downwardapi-volume-9a8e87ad-54e0-4119-8bf1-a498740ca7ce container client-container: <nil>
STEP: delete the pod
Mar 25 09:59:18.097: INFO: Waiting for pod downwardapi-volume-9a8e87ad-54e0-4119-8bf1-a498740ca7ce to disappear
Mar 25 09:59:18.099: INFO: Pod downwardapi-volume-9a8e87ad-54e0-4119-8bf1-a498740ca7ce no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 09:59:18.099: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1052" for this suite.
Mar 25 09:59:24.117: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 09:59:24.188: INFO: namespace downward-api-1052 deletion completed in 6.086504997s

• [SLOW TEST:8.258 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 09:59:24.189: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-6337
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0644 on node default medium
Mar 25 09:59:24.379: INFO: Waiting up to 5m0s for pod "pod-b31b7d3c-53ea-4e2b-b347-c78ef34cafe6" in namespace "emptydir-6337" to be "success or failure"
Mar 25 09:59:24.382: INFO: Pod "pod-b31b7d3c-53ea-4e2b-b347-c78ef34cafe6": Phase="Pending", Reason="", readiness=false. Elapsed: 3.587342ms
Mar 25 09:59:26.385: INFO: Pod "pod-b31b7d3c-53ea-4e2b-b347-c78ef34cafe6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006441397s
STEP: Saw pod success
Mar 25 09:59:26.385: INFO: Pod "pod-b31b7d3c-53ea-4e2b-b347-c78ef34cafe6" satisfied condition "success or failure"
Mar 25 09:59:26.387: INFO: Trying to get logs from node ip-10-90-32-23.eu-west-2.compute.internal pod pod-b31b7d3c-53ea-4e2b-b347-c78ef34cafe6 container test-container: <nil>
STEP: delete the pod
Mar 25 09:59:26.401: INFO: Waiting for pod pod-b31b7d3c-53ea-4e2b-b347-c78ef34cafe6 to disappear
Mar 25 09:59:26.404: INFO: Pod pod-b31b7d3c-53ea-4e2b-b347-c78ef34cafe6 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 09:59:26.404: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6337" for this suite.
Mar 25 09:59:32.415: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 09:59:32.487: INFO: namespace emptydir-6337 deletion completed in 6.080307889s

• [SLOW TEST:8.298 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 09:59:32.487: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-1789
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Mar 25 09:59:32.630: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-1789,SelfLink:/api/v1/namespaces/watch-1789/configmaps/e2e-watch-test-watch-closed,UID:1fdf92c9-1119-4d77-a94e-d44cf35eff3f,ResourceVersion:342594,Generation:0,CreationTimestamp:2020-03-25 09:59:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Mar 25 09:59:32.630: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-1789,SelfLink:/api/v1/namespaces/watch-1789/configmaps/e2e-watch-test-watch-closed,UID:1fdf92c9-1119-4d77-a94e-d44cf35eff3f,ResourceVersion:342595,Generation:0,CreationTimestamp:2020-03-25 09:59:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Mar 25 09:59:32.641: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-1789,SelfLink:/api/v1/namespaces/watch-1789/configmaps/e2e-watch-test-watch-closed,UID:1fdf92c9-1119-4d77-a94e-d44cf35eff3f,ResourceVersion:342596,Generation:0,CreationTimestamp:2020-03-25 09:59:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Mar 25 09:59:32.641: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-1789,SelfLink:/api/v1/namespaces/watch-1789/configmaps/e2e-watch-test-watch-closed,UID:1fdf92c9-1119-4d77-a94e-d44cf35eff3f,ResourceVersion:342597,Generation:0,CreationTimestamp:2020-03-25 09:59:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 09:59:32.641: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-1789" for this suite.
Mar 25 09:59:38.652: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 09:59:38.719: INFO: namespace watch-1789 deletion completed in 6.075552491s

• [SLOW TEST:6.232 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 09:59:38.719: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-2282
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 09:59:40.873: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-2282" for this suite.
Mar 25 10:00:30.884: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 10:00:30.953: INFO: namespace kubelet-test-2282 deletion completed in 50.077050838s

• [SLOW TEST:52.234 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when scheduling a busybox command in a pod
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:40
    should print the output to logs [NodeConformance] [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 10:00:30.953: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-558
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-b77954e0-50cf-435a-a965-1254f9f87516
STEP: Creating a pod to test consume configMaps
Mar 25 10:00:31.093: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-09752580-55ae-4fa1-971d-f88db0b1b4ff" in namespace "projected-558" to be "success or failure"
Mar 25 10:00:31.097: INFO: Pod "pod-projected-configmaps-09752580-55ae-4fa1-971d-f88db0b1b4ff": Phase="Pending", Reason="", readiness=false. Elapsed: 3.736012ms
Mar 25 10:00:33.100: INFO: Pod "pod-projected-configmaps-09752580-55ae-4fa1-971d-f88db0b1b4ff": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006803124s
STEP: Saw pod success
Mar 25 10:00:33.100: INFO: Pod "pod-projected-configmaps-09752580-55ae-4fa1-971d-f88db0b1b4ff" satisfied condition "success or failure"
Mar 25 10:00:33.102: INFO: Trying to get logs from node ip-10-90-32-23.eu-west-2.compute.internal pod pod-projected-configmaps-09752580-55ae-4fa1-971d-f88db0b1b4ff container projected-configmap-volume-test: <nil>
STEP: delete the pod
Mar 25 10:00:33.117: INFO: Waiting for pod pod-projected-configmaps-09752580-55ae-4fa1-971d-f88db0b1b4ff to disappear
Mar 25 10:00:33.119: INFO: Pod pod-projected-configmaps-09752580-55ae-4fa1-971d-f88db0b1b4ff no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 10:00:33.119: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-558" for this suite.
Mar 25 10:00:39.130: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 10:00:39.198: INFO: namespace projected-558 deletion completed in 6.075612115s

• [SLOW TEST:8.245 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 10:00:39.200: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-638
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Mar 25 10:00:39.347: INFO: Create a RollingUpdate DaemonSet
Mar 25 10:00:39.352: INFO: Check that daemon pods launch on every node of the cluster
Mar 25 10:00:39.362: INFO: Number of nodes with available pods: 0
Mar 25 10:00:39.362: INFO: Node ip-10-90-32-22.eu-west-2.compute.internal is running more than one daemon pod
Mar 25 10:00:40.367: INFO: Number of nodes with available pods: 0
Mar 25 10:00:40.367: INFO: Node ip-10-90-32-22.eu-west-2.compute.internal is running more than one daemon pod
Mar 25 10:00:41.367: INFO: Number of nodes with available pods: 1
Mar 25 10:00:41.367: INFO: Node ip-10-90-32-22.eu-west-2.compute.internal is running more than one daemon pod
Mar 25 10:00:42.368: INFO: Number of nodes with available pods: 3
Mar 25 10:00:42.368: INFO: Number of running nodes: 3, number of available pods: 3
Mar 25 10:00:42.368: INFO: Update the DaemonSet to trigger a rollout
Mar 25 10:00:42.375: INFO: Updating DaemonSet daemon-set
Mar 25 10:00:57.389: INFO: Roll back the DaemonSet before rollout is complete
Mar 25 10:00:57.396: INFO: Updating DaemonSet daemon-set
Mar 25 10:00:57.396: INFO: Make sure DaemonSet rollback is complete
Mar 25 10:00:57.400: INFO: Wrong image for pod: daemon-set-hk2z7. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Mar 25 10:00:57.400: INFO: Pod daemon-set-hk2z7 is not available
Mar 25 10:00:58.409: INFO: Wrong image for pod: daemon-set-hk2z7. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Mar 25 10:00:58.409: INFO: Pod daemon-set-hk2z7 is not available
Mar 25 10:00:59.409: INFO: Wrong image for pod: daemon-set-hk2z7. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Mar 25 10:00:59.409: INFO: Pod daemon-set-hk2z7 is not available
Mar 25 10:01:00.409: INFO: Pod daemon-set-kfpjw is not available
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-638, will wait for the garbage collector to delete the pods
Mar 25 10:01:00.474: INFO: Deleting DaemonSet.extensions daemon-set took: 6.439117ms
Mar 25 10:01:00.774: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.283164ms
Mar 25 10:02:11.277: INFO: Number of nodes with available pods: 0
Mar 25 10:02:11.277: INFO: Number of running nodes: 0, number of available pods: 0
Mar 25 10:02:11.279: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-638/daemonsets","resourceVersion":"342979"},"items":null}

Mar 25 10:02:11.280: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-638/pods","resourceVersion":"342979"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 10:02:11.288: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-638" for this suite.
Mar 25 10:02:17.299: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 10:02:17.364: INFO: namespace daemonsets-638 deletion completed in 6.073397464s

• [SLOW TEST:98.165 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 10:02:17.365: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9362
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating the pod
Mar 25 10:02:20.033: INFO: Successfully updated pod "labelsupdate435d4977-3876-41ac-b019-cf5c6a65a132"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 10:02:22.047: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9362" for this suite.
Mar 25 10:02:44.058: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 10:02:44.126: INFO: namespace projected-9362 deletion completed in 22.075899712s

• [SLOW TEST:26.761 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 10:02:44.127: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-9231
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Mar 25 10:02:44.258: INFO: Creating deployment "test-recreate-deployment"
Mar 25 10:02:44.262: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Mar 25 10:02:44.281: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
Mar 25 10:02:46.286: INFO: Waiting deployment "test-recreate-deployment" to complete
Mar 25 10:02:46.288: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Mar 25 10:02:46.295: INFO: Updating deployment test-recreate-deployment
Mar 25 10:02:46.295: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
Mar 25 10:02:46.382: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment,GenerateName:,Namespace:deployment-9231,SelfLink:/apis/apps/v1/namespaces/deployment-9231/deployments/test-recreate-deployment,UID:17c1ae50-20a9-4241-a4e5-d2f306ba69db,ResourceVersion:343138,Generation:2,CreationTimestamp:2020-03-25 10:02:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[{Available False 2020-03-25 10:02:46 +0000 UTC 2020-03-25 10:02:46 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2020-03-25 10:02:46 +0000 UTC 2020-03-25 10:02:44 +0000 UTC ReplicaSetUpdated ReplicaSet "test-recreate-deployment-5c8c9cc69d" is progressing.}],ReadyReplicas:0,CollisionCount:nil,},}

Mar 25 10:02:46.386: INFO: New ReplicaSet "test-recreate-deployment-5c8c9cc69d" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-5c8c9cc69d,GenerateName:,Namespace:deployment-9231,SelfLink:/apis/apps/v1/namespaces/deployment-9231/replicasets/test-recreate-deployment-5c8c9cc69d,UID:08f6644f-35d2-49d8-a2d5-a97fc6add13f,ResourceVersion:343135,Generation:1,CreationTimestamp:2020-03-25 10:02:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5c8c9cc69d,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 17c1ae50-20a9-4241-a4e5-d2f306ba69db 0xc0028fcd67 0xc0028fcd68}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 5c8c9cc69d,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5c8c9cc69d,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Mar 25 10:02:46.386: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Mar 25 10:02:46.386: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-6df85df6b9,GenerateName:,Namespace:deployment-9231,SelfLink:/apis/apps/v1/namespaces/deployment-9231/replicasets/test-recreate-deployment-6df85df6b9,UID:46a83c07-55c4-493a-8e86-d4313620dc6c,ResourceVersion:343127,Generation:2,CreationTimestamp:2020-03-25 10:02:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 6df85df6b9,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 17c1ae50-20a9-4241-a4e5-d2f306ba69db 0xc0028fce37 0xc0028fce38}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 6df85df6b9,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 6df85df6b9,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Mar 25 10:02:46.388: INFO: Pod "test-recreate-deployment-5c8c9cc69d-6k8v5" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-5c8c9cc69d-6k8v5,GenerateName:test-recreate-deployment-5c8c9cc69d-,Namespace:deployment-9231,SelfLink:/api/v1/namespaces/deployment-9231/pods/test-recreate-deployment-5c8c9cc69d-6k8v5,UID:8998ac93-3e86-45ad-bf02-9c8624dfa8cb,ResourceVersion:343139,Generation:0,CreationTimestamp:2020-03-25 10:02:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5c8c9cc69d,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-recreate-deployment-5c8c9cc69d 08f6644f-35d2-49d8-a2d5-a97fc6add13f 0xc0028fd987 0xc0028fd988}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-qk8hb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qk8hb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-qk8hb true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-90-32-23.eu-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0028fd9f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0028fda10}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-25 10:02:46 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-03-25 10:02:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-03-25 10:02:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-25 10:02:46 +0000 UTC  }],Message:,Reason:,HostIP:10.90.32.23,PodIP:,StartTime:2020-03-25 10:02:46 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 10:02:46.389: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-9231" for this suite.
Mar 25 10:02:52.399: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 10:02:52.463: INFO: namespace deployment-9231 deletion completed in 6.072217415s

• [SLOW TEST:8.337 seconds]
[sig-apps] Deployment
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 10:02:52.464: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-2104
STEP: Waiting for a default service account to be provisioned in namespace
[It] should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Mar 25 10:02:52.594: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
STEP: Creating rc "condition-test" that asks for more than the allowed pod quota
STEP: Checking rc "condition-test" has the desired failure condition set
STEP: Scaling down rc "condition-test" to satisfy pod quota
Mar 25 10:02:54.633: INFO: Updating replication controller "condition-test"
STEP: Checking rc "condition-test" has no failure condition set
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 10:02:54.638: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-2104" for this suite.
Mar 25 10:03:00.648: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 10:03:00.715: INFO: namespace replication-controller-2104 deletion completed in 6.074640989s

• [SLOW TEST:8.251 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 10:03:00.715: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-5609
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Mar 25 10:03:00.853: INFO: Waiting up to 5m0s for pod "downwardapi-volume-22373bd1-d943-4cea-9c36-34697ac990b7" in namespace "downward-api-5609" to be "success or failure"
Mar 25 10:03:00.857: INFO: Pod "downwardapi-volume-22373bd1-d943-4cea-9c36-34697ac990b7": Phase="Pending", Reason="", readiness=false. Elapsed: 4.160343ms
Mar 25 10:03:02.860: INFO: Pod "downwardapi-volume-22373bd1-d943-4cea-9c36-34697ac990b7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007321608s
STEP: Saw pod success
Mar 25 10:03:02.860: INFO: Pod "downwardapi-volume-22373bd1-d943-4cea-9c36-34697ac990b7" satisfied condition "success or failure"
Mar 25 10:03:02.862: INFO: Trying to get logs from node ip-10-90-32-22.eu-west-2.compute.internal pod downwardapi-volume-22373bd1-d943-4cea-9c36-34697ac990b7 container client-container: <nil>
STEP: delete the pod
Mar 25 10:03:02.877: INFO: Waiting for pod downwardapi-volume-22373bd1-d943-4cea-9c36-34697ac990b7 to disappear
Mar 25 10:03:02.879: INFO: Pod downwardapi-volume-22373bd1-d943-4cea-9c36-34697ac990b7 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 10:03:02.879: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5609" for this suite.
Mar 25 10:03:08.890: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 10:03:08.958: INFO: namespace downward-api-5609 deletion completed in 6.076243372s

• [SLOW TEST:8.243 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 10:03:08.959: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-1296
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Mar 25 10:03:09.096: INFO: Waiting up to 5m0s for pod "downward-api-2b3185d6-4fdf-4774-b07f-90ffe03e8f0d" in namespace "downward-api-1296" to be "success or failure"
Mar 25 10:03:09.103: INFO: Pod "downward-api-2b3185d6-4fdf-4774-b07f-90ffe03e8f0d": Phase="Pending", Reason="", readiness=false. Elapsed: 7.008818ms
Mar 25 10:03:11.106: INFO: Pod "downward-api-2b3185d6-4fdf-4774-b07f-90ffe03e8f0d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009961209s
STEP: Saw pod success
Mar 25 10:03:11.106: INFO: Pod "downward-api-2b3185d6-4fdf-4774-b07f-90ffe03e8f0d" satisfied condition "success or failure"
Mar 25 10:03:11.108: INFO: Trying to get logs from node ip-10-90-32-23.eu-west-2.compute.internal pod downward-api-2b3185d6-4fdf-4774-b07f-90ffe03e8f0d container dapi-container: <nil>
STEP: delete the pod
Mar 25 10:03:11.123: INFO: Waiting for pod downward-api-2b3185d6-4fdf-4774-b07f-90ffe03e8f0d to disappear
Mar 25 10:03:11.125: INFO: Pod downward-api-2b3185d6-4fdf-4774-b07f-90ffe03e8f0d no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 10:03:11.125: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1296" for this suite.
Mar 25 10:03:17.136: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 10:03:17.207: INFO: namespace downward-api-1296 deletion completed in 6.079362511s

• [SLOW TEST:8.249 seconds]
[sig-node] Downward API
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 10:03:17.207: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-8632
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-8632
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a new StatefulSet
Mar 25 10:03:17.367: INFO: Found 0 stateful pods, waiting for 3
Mar 25 10:03:27.371: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Mar 25 10:03:27.371: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Mar 25 10:03:27.371: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Mar 25 10:03:27.378: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 exec --namespace=statefulset-8632 ss2-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar 25 10:03:27.550: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Mar 25 10:03:27.550: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar 25 10:03:27.550: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Mar 25 10:03:37.584: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Mar 25 10:03:47.604: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 exec --namespace=statefulset-8632 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 25 10:03:47.999: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Mar 25 10:03:47.999: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Mar 25 10:03:47.999: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Mar 25 10:03:58.013: INFO: Waiting for StatefulSet statefulset-8632/ss2 to complete update
Mar 25 10:03:58.013: INFO: Waiting for Pod statefulset-8632/ss2-0 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Mar 25 10:03:58.013: INFO: Waiting for Pod statefulset-8632/ss2-1 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Mar 25 10:03:58.013: INFO: Waiting for Pod statefulset-8632/ss2-2 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Mar 25 10:04:08.019: INFO: Waiting for StatefulSet statefulset-8632/ss2 to complete update
Mar 25 10:04:08.019: INFO: Waiting for Pod statefulset-8632/ss2-0 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Mar 25 10:04:18.019: INFO: Waiting for StatefulSet statefulset-8632/ss2 to complete update
STEP: Rolling back to a previous revision
Mar 25 10:04:28.019: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 exec --namespace=statefulset-8632 ss2-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar 25 10:04:28.189: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Mar 25 10:04:28.189: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar 25 10:04:28.189: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Mar 25 10:04:38.217: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Mar 25 10:04:48.238: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 exec --namespace=statefulset-8632 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 25 10:04:48.399: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Mar 25 10:04:48.399: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Mar 25 10:04:48.399: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Mar 25 10:04:58.413: INFO: Waiting for StatefulSet statefulset-8632/ss2 to complete update
Mar 25 10:04:58.413: INFO: Waiting for Pod statefulset-8632/ss2-0 to have revision ss2-7c9b54fd4c update revision ss2-6c5cd755cd
Mar 25 10:04:58.413: INFO: Waiting for Pod statefulset-8632/ss2-1 to have revision ss2-7c9b54fd4c update revision ss2-6c5cd755cd
Mar 25 10:04:58.413: INFO: Waiting for Pod statefulset-8632/ss2-2 to have revision ss2-7c9b54fd4c update revision ss2-6c5cd755cd
Mar 25 10:05:08.418: INFO: Waiting for StatefulSet statefulset-8632/ss2 to complete update
Mar 25 10:05:08.419: INFO: Waiting for Pod statefulset-8632/ss2-0 to have revision ss2-7c9b54fd4c update revision ss2-6c5cd755cd
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Mar 25 10:05:18.418: INFO: Deleting all statefulset in ns statefulset-8632
Mar 25 10:05:18.420: INFO: Scaling statefulset ss2 to 0
Mar 25 10:05:48.440: INFO: Waiting for statefulset status.replicas updated to 0
Mar 25 10:05:48.442: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 10:05:48.456: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-8632" for this suite.
Mar 25 10:05:54.471: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 10:05:54.541: INFO: namespace statefulset-8632 deletion completed in 6.081848645s

• [SLOW TEST:157.334 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 10:05:54.542: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-5743
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:81
Mar 25 10:05:54.675: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Mar 25 10:05:54.680: INFO: Waiting for terminating namespaces to be deleted...
Mar 25 10:05:54.682: INFO: 
Logging pods the kubelet thinks is on node ip-10-90-32-22.eu-west-2.compute.internal before test
Mar 25 10:05:54.690: INFO: traefik-ingress-controller-d8npl from traefik-ingress started at 2020-03-23 09:01:47 +0000 UTC (1 container statuses recorded)
Mar 25 10:05:54.690: INFO: 	Container traefik-ingress-lb ready: true, restart count 0
Mar 25 10:05:54.690: INFO: kubernetes-dashboard-84ffbc8546-bph6j from kube-system started at 2020-03-23 08:46:30 +0000 UTC (1 container statuses recorded)
Mar 25 10:05:54.690: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Mar 25 10:05:54.690: INFO: sonobuoy-systemd-logs-daemon-set-881e638473c24530-zhx7s from heptio-sonobuoy started at 2020-03-25 08:52:11 +0000 UTC (2 container statuses recorded)
Mar 25 10:05:54.690: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Mar 25 10:05:54.690: INFO: 	Container systemd-logs ready: true, restart count 1
Mar 25 10:05:54.690: INFO: filebeat-rfcxf from kube-system started at 2020-03-23 08:46:09 +0000 UTC (1 container statuses recorded)
Mar 25 10:05:54.690: INFO: 	Container filebeat ready: true, restart count 0
Mar 25 10:05:54.690: INFO: sonobuoy from heptio-sonobuoy started at 2020-03-25 08:52:05 +0000 UTC (1 container statuses recorded)
Mar 25 10:05:54.690: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Mar 25 10:05:54.690: INFO: coredns-84c98f9bb6-jtxmm from kube-system started at 2020-03-23 08:59:43 +0000 UTC (1 container statuses recorded)
Mar 25 10:05:54.690: INFO: 	Container coredns ready: true, restart count 0
Mar 25 10:05:54.690: INFO: 
Logging pods the kubelet thinks is on node ip-10-90-32-23.eu-west-2.compute.internal before test
Mar 25 10:05:54.694: INFO: sonobuoy-systemd-logs-daemon-set-881e638473c24530-4r6qn from heptio-sonobuoy started at 2020-03-25 08:52:11 +0000 UTC (2 container statuses recorded)
Mar 25 10:05:54.694: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Mar 25 10:05:54.694: INFO: 	Container systemd-logs ready: true, restart count 1
Mar 25 10:05:54.694: INFO: nginx-7db9fccd9b-w4mt2 from miro started at 2020-03-23 08:50:25 +0000 UTC (1 container statuses recorded)
Mar 25 10:05:54.695: INFO: 	Container nginx ready: true, restart count 0
Mar 25 10:05:54.695: INFO: filebeat-4w76v from kube-system started at 2020-03-23 08:49:56 +0000 UTC (1 container statuses recorded)
Mar 25 10:05:54.695: INFO: 	Container filebeat ready: true, restart count 0
Mar 25 10:05:54.695: INFO: traefik-ingress-controller-nwxk9 from traefik-ingress started at 2020-03-23 09:01:51 +0000 UTC (1 container statuses recorded)
Mar 25 10:05:54.695: INFO: 	Container traefik-ingress-lb ready: true, restart count 0
Mar 25 10:05:54.695: INFO: coredns-84c98f9bb6-jw9th from kube-system started at 2020-03-23 08:59:41 +0000 UTC (1 container statuses recorded)
Mar 25 10:05:54.695: INFO: 	Container coredns ready: true, restart count 0
Mar 25 10:05:54.695: INFO: 
Logging pods the kubelet thinks is on node ip-10-90-32-24.eu-west-2.compute.internal before test
Mar 25 10:05:54.700: INFO: filebeat-b24zt from kube-system started at 2020-03-23 08:53:59 +0000 UTC (1 container statuses recorded)
Mar 25 10:05:54.700: INFO: 	Container filebeat ready: true, restart count 0
Mar 25 10:05:54.700: INFO: coredns-84c98f9bb6-hdmp4 from kube-system started at 2020-03-23 08:59:41 +0000 UTC (1 container statuses recorded)
Mar 25 10:05:54.700: INFO: 	Container coredns ready: true, restart count 0
Mar 25 10:05:54.700: INFO: traefik-ingress-controller-8wz6n from traefik-ingress started at 2020-03-23 09:01:43 +0000 UTC (1 container statuses recorded)
Mar 25 10:05:54.700: INFO: 	Container traefik-ingress-lb ready: true, restart count 0
Mar 25 10:05:54.700: INFO: metrics-server-5998746b76-qchjq from kube-system started at 2020-03-23 08:59:45 +0000 UTC (1 container statuses recorded)
Mar 25 10:05:54.700: INFO: 	Container metrics-server ready: true, restart count 0
Mar 25 10:05:54.700: INFO: sonobuoy-e2e-job-da73411fd655405d from heptio-sonobuoy started at 2020-03-25 08:52:11 +0000 UTC (2 container statuses recorded)
Mar 25 10:05:54.700: INFO: 	Container e2e ready: true, restart count 0
Mar 25 10:05:54.700: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar 25 10:05:54.700: INFO: sonobuoy-systemd-logs-daemon-set-881e638473c24530-r7mb9 from heptio-sonobuoy started at 2020-03-25 08:52:11 +0000 UTC (2 container statuses recorded)
Mar 25 10:05:54.700: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Mar 25 10:05:54.700: INFO: 	Container systemd-logs ready: true, restart count 1
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: verifying the node has the label node ip-10-90-32-22.eu-west-2.compute.internal
STEP: verifying the node has the label node ip-10-90-32-23.eu-west-2.compute.internal
STEP: verifying the node has the label node ip-10-90-32-24.eu-west-2.compute.internal
Mar 25 10:05:54.737: INFO: Pod sonobuoy requesting resource cpu=0m on Node ip-10-90-32-22.eu-west-2.compute.internal
Mar 25 10:05:54.737: INFO: Pod sonobuoy-e2e-job-da73411fd655405d requesting resource cpu=0m on Node ip-10-90-32-24.eu-west-2.compute.internal
Mar 25 10:05:54.737: INFO: Pod sonobuoy-systemd-logs-daemon-set-881e638473c24530-4r6qn requesting resource cpu=0m on Node ip-10-90-32-23.eu-west-2.compute.internal
Mar 25 10:05:54.737: INFO: Pod sonobuoy-systemd-logs-daemon-set-881e638473c24530-r7mb9 requesting resource cpu=0m on Node ip-10-90-32-24.eu-west-2.compute.internal
Mar 25 10:05:54.737: INFO: Pod sonobuoy-systemd-logs-daemon-set-881e638473c24530-zhx7s requesting resource cpu=0m on Node ip-10-90-32-22.eu-west-2.compute.internal
Mar 25 10:05:54.737: INFO: Pod coredns-84c98f9bb6-hdmp4 requesting resource cpu=100m on Node ip-10-90-32-24.eu-west-2.compute.internal
Mar 25 10:05:54.737: INFO: Pod coredns-84c98f9bb6-jtxmm requesting resource cpu=100m on Node ip-10-90-32-22.eu-west-2.compute.internal
Mar 25 10:05:54.738: INFO: Pod coredns-84c98f9bb6-jw9th requesting resource cpu=100m on Node ip-10-90-32-23.eu-west-2.compute.internal
Mar 25 10:05:54.738: INFO: Pod filebeat-4w76v requesting resource cpu=200m on Node ip-10-90-32-23.eu-west-2.compute.internal
Mar 25 10:05:54.738: INFO: Pod filebeat-b24zt requesting resource cpu=200m on Node ip-10-90-32-24.eu-west-2.compute.internal
Mar 25 10:05:54.738: INFO: Pod filebeat-rfcxf requesting resource cpu=200m on Node ip-10-90-32-22.eu-west-2.compute.internal
Mar 25 10:05:54.738: INFO: Pod kubernetes-dashboard-84ffbc8546-bph6j requesting resource cpu=50m on Node ip-10-90-32-22.eu-west-2.compute.internal
Mar 25 10:05:54.738: INFO: Pod metrics-server-5998746b76-qchjq requesting resource cpu=0m on Node ip-10-90-32-24.eu-west-2.compute.internal
Mar 25 10:05:54.738: INFO: Pod nginx-7db9fccd9b-w4mt2 requesting resource cpu=0m on Node ip-10-90-32-23.eu-west-2.compute.internal
Mar 25 10:05:54.738: INFO: Pod traefik-ingress-controller-8wz6n requesting resource cpu=0m on Node ip-10-90-32-24.eu-west-2.compute.internal
Mar 25 10:05:54.738: INFO: Pod traefik-ingress-controller-d8npl requesting resource cpu=0m on Node ip-10-90-32-22.eu-west-2.compute.internal
Mar 25 10:05:54.739: INFO: Pod traefik-ingress-controller-nwxk9 requesting resource cpu=0m on Node ip-10-90-32-23.eu-west-2.compute.internal
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-3c74f329-d133-45f4-9526-e8a05c18da05.15ff8405e77981bd], Reason = [Scheduled], Message = [Successfully assigned sched-pred-5743/filler-pod-3c74f329-d133-45f4-9526-e8a05c18da05 to ip-10-90-32-22.eu-west-2.compute.internal]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-3c74f329-d133-45f4-9526-e8a05c18da05.15ff84061b0b4dec], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-3c74f329-d133-45f4-9526-e8a05c18da05.15ff84061e5168d3], Reason = [Created], Message = [Created container filler-pod-3c74f329-d133-45f4-9526-e8a05c18da05]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-3c74f329-d133-45f4-9526-e8a05c18da05.15ff8406271a4899], Reason = [Started], Message = [Started container filler-pod-3c74f329-d133-45f4-9526-e8a05c18da05]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-4d85c44a-698c-411f-94c3-e9cbf01613d3.15ff8405e8271e9d], Reason = [Scheduled], Message = [Successfully assigned sched-pred-5743/filler-pod-4d85c44a-698c-411f-94c3-e9cbf01613d3 to ip-10-90-32-23.eu-west-2.compute.internal]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-4d85c44a-698c-411f-94c3-e9cbf01613d3.15ff840619857cf7], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-4d85c44a-698c-411f-94c3-e9cbf01613d3.15ff84061c800858], Reason = [Created], Message = [Created container filler-pod-4d85c44a-698c-411f-94c3-e9cbf01613d3]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-4d85c44a-698c-411f-94c3-e9cbf01613d3.15ff84062571bf52], Reason = [Started], Message = [Started container filler-pod-4d85c44a-698c-411f-94c3-e9cbf01613d3]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-fdc9909e-b19d-46f4-ac70-f4a212b61bc7.15ff8405e8d1d671], Reason = [Scheduled], Message = [Successfully assigned sched-pred-5743/filler-pod-fdc9909e-b19d-46f4-ac70-f4a212b61bc7 to ip-10-90-32-24.eu-west-2.compute.internal]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-fdc9909e-b19d-46f4-ac70-f4a212b61bc7.15ff84061a74de8c], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-fdc9909e-b19d-46f4-ac70-f4a212b61bc7.15ff84061e059905], Reason = [Created], Message = [Created container filler-pod-fdc9909e-b19d-46f4-ac70-f4a212b61bc7]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-fdc9909e-b19d-46f4-ac70-f4a212b61bc7.15ff84062715ec76], Reason = [Started], Message = [Started container filler-pod-fdc9909e-b19d-46f4-ac70-f4a212b61bc7]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.15ff8406d88611d3], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 Insufficient cpu.]
STEP: removing the label node off the node ip-10-90-32-24.eu-west-2.compute.internal
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node ip-10-90-32-22.eu-west-2.compute.internal
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node ip-10-90-32-23.eu-west-2.compute.internal
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 10:05:59.834: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-5743" for this suite.
Mar 25 10:06:05.845: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 10:06:05.920: INFO: namespace sched-pred-5743 deletion completed in 6.082959026s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:72

• [SLOW TEST:11.378 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 10:06:05.920: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-4317
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Mar 25 10:06:06.059: INFO: Waiting up to 5m0s for pod "downwardapi-volume-56e2d620-3f99-434d-805a-a354372a9148" in namespace "projected-4317" to be "success or failure"
Mar 25 10:06:06.067: INFO: Pod "downwardapi-volume-56e2d620-3f99-434d-805a-a354372a9148": Phase="Pending", Reason="", readiness=false. Elapsed: 7.341164ms
Mar 25 10:06:08.070: INFO: Pod "downwardapi-volume-56e2d620-3f99-434d-805a-a354372a9148": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010869756s
Mar 25 10:06:10.074: INFO: Pod "downwardapi-volume-56e2d620-3f99-434d-805a-a354372a9148": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014301143s
STEP: Saw pod success
Mar 25 10:06:10.074: INFO: Pod "downwardapi-volume-56e2d620-3f99-434d-805a-a354372a9148" satisfied condition "success or failure"
Mar 25 10:06:10.076: INFO: Trying to get logs from node ip-10-90-32-24.eu-west-2.compute.internal pod downwardapi-volume-56e2d620-3f99-434d-805a-a354372a9148 container client-container: <nil>
STEP: delete the pod
Mar 25 10:06:10.092: INFO: Waiting for pod downwardapi-volume-56e2d620-3f99-434d-805a-a354372a9148 to disappear
Mar 25 10:06:10.094: INFO: Pod downwardapi-volume-56e2d620-3f99-434d-805a-a354372a9148 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 10:06:10.094: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4317" for this suite.
Mar 25 10:06:16.106: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 10:06:16.175: INFO: namespace projected-4317 deletion completed in 6.077357245s

• [SLOW TEST:10.254 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 10:06:16.175: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-4684
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Mar 25 10:06:16.306: INFO: Creating deployment "nginx-deployment"
Mar 25 10:06:16.312: INFO: Waiting for observed generation 1
Mar 25 10:06:18.319: INFO: Waiting for all required pods to come up
Mar 25 10:06:18.324: INFO: Pod name nginx: Found 10 pods out of 10
STEP: ensuring each pod is running
Mar 25 10:06:20.339: INFO: Waiting for deployment "nginx-deployment" to complete
Mar 25 10:06:20.345: INFO: Updating deployment "nginx-deployment" with a non-existent image
Mar 25 10:06:20.355: INFO: Updating deployment nginx-deployment
Mar 25 10:06:20.355: INFO: Waiting for observed generation 2
Mar 25 10:06:22.368: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Mar 25 10:06:22.370: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Mar 25 10:06:22.372: INFO: Waiting for the first rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Mar 25 10:06:22.378: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Mar 25 10:06:22.378: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Mar 25 10:06:22.380: INFO: Waiting for the second rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Mar 25 10:06:22.383: INFO: Verifying that deployment "nginx-deployment" has minimum required number of available replicas
Mar 25 10:06:22.383: INFO: Scaling up the deployment "nginx-deployment" from 10 to 30
Mar 25 10:06:22.391: INFO: Updating deployment nginx-deployment
Mar 25 10:06:22.391: INFO: Waiting for the replicasets of deployment "nginx-deployment" to have desired number of replicas
Mar 25 10:06:22.408: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Mar 25 10:06:24.416: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
Mar 25 10:06:24.430: INFO: Deployment "nginx-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment,GenerateName:,Namespace:deployment-4684,SelfLink:/apis/apps/v1/namespaces/deployment-4684/deployments/nginx-deployment,UID:cd98374f-1914-4a82-aba1-0f758263e96f,ResourceVersion:344385,Generation:3,CreationTimestamp:2020-03-25 10:06:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*30,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:33,UpdatedReplicas:13,AvailableReplicas:10,UnavailableReplicas:23,Conditions:[{Available False 2020-03-25 10:06:22 +0000 UTC 2020-03-25 10:06:22 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2020-03-25 10:06:24 +0000 UTC 2020-03-25 10:06:16 +0000 UTC ReplicaSetUpdated ReplicaSet "nginx-deployment-55fb7cb77f" is progressing.}],ReadyReplicas:10,CollisionCount:nil,},}

Mar 25 10:06:24.439: INFO: New ReplicaSet "nginx-deployment-55fb7cb77f" of Deployment "nginx-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f,GenerateName:,Namespace:deployment-4684,SelfLink:/apis/apps/v1/namespaces/deployment-4684/replicasets/nginx-deployment-55fb7cb77f,UID:a0ec6ef2-4358-4322-a9aa-4c80f4d9d59e,ResourceVersion:344292,Generation:3,CreationTimestamp:2020-03-25 10:06:20 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment nginx-deployment cd98374f-1914-4a82-aba1-0f758263e96f 0xc0020c4aa7 0xc0020c4aa8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*13,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:13,FullyLabeledReplicas:13,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Mar 25 10:06:24.439: INFO: All old ReplicaSets of Deployment "nginx-deployment":
Mar 25 10:06:24.439: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498,GenerateName:,Namespace:deployment-4684,SelfLink:/apis/apps/v1/namespaces/deployment-4684/replicasets/nginx-deployment-7b8c6f4498,UID:d67006bd-717a-4953-8cc0-3e5b94fcfad1,ResourceVersion:344394,Generation:3,CreationTimestamp:2020-03-25 10:06:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment nginx-deployment cd98374f-1914-4a82-aba1-0f758263e96f 0xc0020c4b77 0xc0020c4b78}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*20,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:20,FullyLabeledReplicas:20,ObservedGeneration:3,ReadyReplicas:11,AvailableReplicas:11,Conditions:[],},}
Mar 25 10:06:24.445: INFO: Pod "nginx-deployment-55fb7cb77f-86l7x" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-86l7x,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-4684,SelfLink:/api/v1/namespaces/deployment-4684/pods/nginx-deployment-55fb7cb77f-86l7x,UID:2a276bce-0ae4-4863-9a0d-2013a8fc8a6c,ResourceVersion:344308,Generation:0,CreationTimestamp:2020-03-25 10:06:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f a0ec6ef2-4358-4322-a9aa-4c80f4d9d59e 0xc0020c5507 0xc0020c5508}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-6crqb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6crqb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-6crqb true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-90-32-23.eu-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0020c5570} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0020c5590}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-25 10:06:22 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-03-25 10:06:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-03-25 10:06:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-25 10:06:22 +0000 UTC  }],Message:,Reason:,HostIP:10.90.32.23,PodIP:,StartTime:2020-03-25 10:06:22 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 25 10:06:24.445: INFO: Pod "nginx-deployment-55fb7cb77f-cn9dz" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-cn9dz,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-4684,SelfLink:/api/v1/namespaces/deployment-4684/pods/nginx-deployment-55fb7cb77f-cn9dz,UID:b5dc2780-f469-4f9f-9b33-970ce34c9a44,ResourceVersion:344275,Generation:0,CreationTimestamp:2020-03-25 10:06:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f a0ec6ef2-4358-4322-a9aa-4c80f4d9d59e 0xc0020c5660 0xc0020c5661}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-6crqb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6crqb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-6crqb true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-90-32-24.eu-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0020c56d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0020c56f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-25 10:06:22 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-03-25 10:06:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-03-25 10:06:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-25 10:06:22 +0000 UTC  }],Message:,Reason:,HostIP:10.90.32.24,PodIP:,StartTime:2020-03-25 10:06:22 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 25 10:06:24.445: INFO: Pod "nginx-deployment-55fb7cb77f-gxgvv" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-gxgvv,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-4684,SelfLink:/api/v1/namespaces/deployment-4684/pods/nginx-deployment-55fb7cb77f-gxgvv,UID:a45a117e-1aae-46f8-a019-0c783a0e237c,ResourceVersion:344389,Generation:0,CreationTimestamp:2020-03-25 10:06:20 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f a0ec6ef2-4358-4322-a9aa-4c80f4d9d59e 0xc0020c57c0 0xc0020c57c1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-6crqb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6crqb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-6crqb true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-90-32-23.eu-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0020c5830} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0020c5850}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-25 10:06:20 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-03-25 10:06:20 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-03-25 10:06:20 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-25 10:06:20 +0000 UTC  }],Message:,Reason:,HostIP:10.90.32.23,PodIP:10.200.96.188,StartTime:2020-03-25 10:06:20 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: manifest for nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 25 10:06:24.445: INFO: Pod "nginx-deployment-55fb7cb77f-h4sl2" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-h4sl2,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-4684,SelfLink:/api/v1/namespaces/deployment-4684/pods/nginx-deployment-55fb7cb77f-h4sl2,UID:6664a571-27fe-4237-899a-3532c23b6e9c,ResourceVersion:344368,Generation:0,CreationTimestamp:2020-03-25 10:06:20 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f a0ec6ef2-4358-4322-a9aa-4c80f4d9d59e 0xc0020c5940 0xc0020c5941}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-6crqb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6crqb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-6crqb true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-90-32-22.eu-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0020c59b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0020c59d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-25 10:06:20 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-03-25 10:06:20 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-03-25 10:06:20 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-25 10:06:20 +0000 UTC  }],Message:,Reason:,HostIP:10.90.32.22,PodIP:10.200.33.60,StartTime:2020-03-25 10:06:20 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: manifest for nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 25 10:06:24.446: INFO: Pod "nginx-deployment-55fb7cb77f-k6p96" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-k6p96,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-4684,SelfLink:/api/v1/namespaces/deployment-4684/pods/nginx-deployment-55fb7cb77f-k6p96,UID:361c57cf-af9a-480d-bd22-eec55251a6b9,ResourceVersion:344311,Generation:0,CreationTimestamp:2020-03-25 10:06:20 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f a0ec6ef2-4358-4322-a9aa-4c80f4d9d59e 0xc0020c5ac0 0xc0020c5ac1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-6crqb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6crqb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-6crqb true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-90-32-24.eu-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0020c5b30} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0020c5b50}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-25 10:06:20 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-03-25 10:06:20 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-03-25 10:06:20 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-25 10:06:20 +0000 UTC  }],Message:,Reason:,HostIP:10.90.32.24,PodIP:10.200.90.47,StartTime:2020-03-25 10:06:20 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: manifest for nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 25 10:06:24.446: INFO: Pod "nginx-deployment-55fb7cb77f-knmjw" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-knmjw,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-4684,SelfLink:/api/v1/namespaces/deployment-4684/pods/nginx-deployment-55fb7cb77f-knmjw,UID:193a219a-84e8-403b-8111-11ab8bb6cbfd,ResourceVersion:344303,Generation:0,CreationTimestamp:2020-03-25 10:06:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f a0ec6ef2-4358-4322-a9aa-4c80f4d9d59e 0xc0020c5c40 0xc0020c5c41}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-6crqb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6crqb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-6crqb true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-90-32-24.eu-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0020c5cb0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0020c5cd0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-25 10:06:22 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-03-25 10:06:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-03-25 10:06:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-25 10:06:22 +0000 UTC  }],Message:,Reason:,HostIP:10.90.32.24,PodIP:,StartTime:2020-03-25 10:06:22 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 25 10:06:24.446: INFO: Pod "nginx-deployment-55fb7cb77f-mlrz2" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-mlrz2,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-4684,SelfLink:/api/v1/namespaces/deployment-4684/pods/nginx-deployment-55fb7cb77f-mlrz2,UID:9072930c-c9d8-420e-9c33-68e8d9368cd0,ResourceVersion:344338,Generation:0,CreationTimestamp:2020-03-25 10:06:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f a0ec6ef2-4358-4322-a9aa-4c80f4d9d59e 0xc0020c5dc0 0xc0020c5dc1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-6crqb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6crqb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-6crqb true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-90-32-24.eu-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0020c5e40} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0020c5e60}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-25 10:06:22 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-03-25 10:06:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-03-25 10:06:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-25 10:06:22 +0000 UTC  }],Message:,Reason:,HostIP:10.90.32.24,PodIP:,StartTime:2020-03-25 10:06:22 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 25 10:06:24.446: INFO: Pod "nginx-deployment-55fb7cb77f-ph9xt" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-ph9xt,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-4684,SelfLink:/api/v1/namespaces/deployment-4684/pods/nginx-deployment-55fb7cb77f-ph9xt,UID:51bcde5a-846c-4e05-8fee-e3a2b87a4f37,ResourceVersion:344300,Generation:0,CreationTimestamp:2020-03-25 10:06:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f a0ec6ef2-4358-4322-a9aa-4c80f4d9d59e 0xc0020c5f30 0xc0020c5f31}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-6crqb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6crqb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-6crqb true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-90-32-23.eu-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0020c5fa0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0020c5fc0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-25 10:06:22 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-03-25 10:06:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-03-25 10:06:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-25 10:06:22 +0000 UTC  }],Message:,Reason:,HostIP:10.90.32.23,PodIP:,StartTime:2020-03-25 10:06:22 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 25 10:06:24.447: INFO: Pod "nginx-deployment-55fb7cb77f-q5pcv" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-q5pcv,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-4684,SelfLink:/api/v1/namespaces/deployment-4684/pods/nginx-deployment-55fb7cb77f-q5pcv,UID:f02fa281-c88e-43d4-a2b7-546ae926e2a5,ResourceVersion:344286,Generation:0,CreationTimestamp:2020-03-25 10:06:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f a0ec6ef2-4358-4322-a9aa-4c80f4d9d59e 0xc003bd6090 0xc003bd6091}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-6crqb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6crqb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-6crqb true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-90-32-22.eu-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003bd6100} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003bd6120}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-25 10:06:22 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-03-25 10:06:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-03-25 10:06:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-25 10:06:22 +0000 UTC  }],Message:,Reason:,HostIP:10.90.32.22,PodIP:,StartTime:2020-03-25 10:06:22 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 25 10:06:24.447: INFO: Pod "nginx-deployment-55fb7cb77f-r4qgq" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-r4qgq,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-4684,SelfLink:/api/v1/namespaces/deployment-4684/pods/nginx-deployment-55fb7cb77f-r4qgq,UID:8e7558d7-59f5-433f-933d-262b0c5f9fa2,ResourceVersion:344336,Generation:0,CreationTimestamp:2020-03-25 10:06:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f a0ec6ef2-4358-4322-a9aa-4c80f4d9d59e 0xc003bd61f0 0xc003bd61f1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-6crqb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6crqb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-6crqb true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-90-32-22.eu-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003bd6260} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003bd6280}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-25 10:06:22 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-03-25 10:06:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-03-25 10:06:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-25 10:06:22 +0000 UTC  }],Message:,Reason:,HostIP:10.90.32.22,PodIP:,StartTime:2020-03-25 10:06:22 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 25 10:06:24.447: INFO: Pod "nginx-deployment-55fb7cb77f-snvmf" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-snvmf,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-4684,SelfLink:/api/v1/namespaces/deployment-4684/pods/nginx-deployment-55fb7cb77f-snvmf,UID:0d830c8e-1519-40ac-bad1-98b0947b3c4b,ResourceVersion:344352,Generation:0,CreationTimestamp:2020-03-25 10:06:20 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f a0ec6ef2-4358-4322-a9aa-4c80f4d9d59e 0xc003bd6350 0xc003bd6351}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-6crqb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6crqb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-6crqb true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-90-32-22.eu-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003bd63c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003bd63e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-25 10:06:20 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-03-25 10:06:20 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-03-25 10:06:20 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-25 10:06:20 +0000 UTC  }],Message:,Reason:,HostIP:10.90.32.22,PodIP:10.200.33.61,StartTime:2020-03-25 10:06:20 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: manifest for nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 25 10:06:24.447: INFO: Pod "nginx-deployment-55fb7cb77f-t797m" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-t797m,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-4684,SelfLink:/api/v1/namespaces/deployment-4684/pods/nginx-deployment-55fb7cb77f-t797m,UID:02428bb7-1e21-4260-844a-5dfd67dc8585,ResourceVersion:344325,Generation:0,CreationTimestamp:2020-03-25 10:06:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f a0ec6ef2-4358-4322-a9aa-4c80f4d9d59e 0xc003bd64d0 0xc003bd64d1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-6crqb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6crqb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-6crqb true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-90-32-22.eu-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003bd6540} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003bd6560}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-25 10:06:22 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-03-25 10:06:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-03-25 10:06:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-25 10:06:22 +0000 UTC  }],Message:,Reason:,HostIP:10.90.32.22,PodIP:,StartTime:2020-03-25 10:06:22 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 25 10:06:24.447: INFO: Pod "nginx-deployment-55fb7cb77f-z9v5x" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-z9v5x,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-4684,SelfLink:/api/v1/namespaces/deployment-4684/pods/nginx-deployment-55fb7cb77f-z9v5x,UID:0b6192b8-5788-4e6d-a64a-1deee225e7fb,ResourceVersion:344163,Generation:0,CreationTimestamp:2020-03-25 10:06:20 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f a0ec6ef2-4358-4322-a9aa-4c80f4d9d59e 0xc003bd6630 0xc003bd6631}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-6crqb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6crqb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-6crqb true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-90-32-23.eu-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003bd66a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003bd66c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-25 10:06:20 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-03-25 10:06:20 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-03-25 10:06:20 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-25 10:06:20 +0000 UTC  }],Message:,Reason:,HostIP:10.90.32.23,PodIP:,StartTime:2020-03-25 10:06:20 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 25 10:06:24.448: INFO: Pod "nginx-deployment-7b8c6f4498-2lf4n" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-2lf4n,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-4684,SelfLink:/api/v1/namespaces/deployment-4684/pods/nginx-deployment-7b8c6f4498-2lf4n,UID:70e7b43a-cda5-49f3-adb3-af8de38d5ae6,ResourceVersion:344328,Generation:0,CreationTimestamp:2020-03-25 10:06:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 d67006bd-717a-4953-8cc0-3e5b94fcfad1 0xc003bd6790 0xc003bd6791}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-6crqb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6crqb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-6crqb true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-90-32-23.eu-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003bd67f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003bd6810}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-25 10:06:22 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-03-25 10:06:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-03-25 10:06:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-25 10:06:22 +0000 UTC  }],Message:,Reason:,HostIP:10.90.32.23,PodIP:,StartTime:2020-03-25 10:06:22 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 25 10:06:24.448: INFO: Pod "nginx-deployment-7b8c6f4498-59dnk" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-59dnk,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-4684,SelfLink:/api/v1/namespaces/deployment-4684/pods/nginx-deployment-7b8c6f4498-59dnk,UID:8f4d44db-3202-4d1e-b4fc-169655fe3522,ResourceVersion:344297,Generation:0,CreationTimestamp:2020-03-25 10:06:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 d67006bd-717a-4953-8cc0-3e5b94fcfad1 0xc003bd68d0 0xc003bd68d1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-6crqb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6crqb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-6crqb true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-90-32-24.eu-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003bd6930} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003bd6950}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-25 10:06:22 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-03-25 10:06:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-03-25 10:06:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-25 10:06:22 +0000 UTC  }],Message:,Reason:,HostIP:10.90.32.24,PodIP:,StartTime:2020-03-25 10:06:22 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 25 10:06:24.448: INFO: Pod "nginx-deployment-7b8c6f4498-7nt7j" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-7nt7j,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-4684,SelfLink:/api/v1/namespaces/deployment-4684/pods/nginx-deployment-7b8c6f4498-7nt7j,UID:570dd376-af8a-44fa-96f7-2268d1686ece,ResourceVersion:344280,Generation:0,CreationTimestamp:2020-03-25 10:06:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 d67006bd-717a-4953-8cc0-3e5b94fcfad1 0xc003bd6a10 0xc003bd6a11}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-6crqb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6crqb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-6crqb true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-90-32-23.eu-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003bd6a70} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003bd6a90}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-25 10:06:22 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-03-25 10:06:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-03-25 10:06:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-25 10:06:22 +0000 UTC  }],Message:,Reason:,HostIP:10.90.32.23,PodIP:,StartTime:2020-03-25 10:06:22 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 25 10:06:24.448: INFO: Pod "nginx-deployment-7b8c6f4498-9cwwr" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-9cwwr,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-4684,SelfLink:/api/v1/namespaces/deployment-4684/pods/nginx-deployment-7b8c6f4498-9cwwr,UID:a5d1733d-939e-4f0f-af93-a16996ffb420,ResourceVersion:344307,Generation:0,CreationTimestamp:2020-03-25 10:06:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 d67006bd-717a-4953-8cc0-3e5b94fcfad1 0xc003bd6b50 0xc003bd6b51}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-6crqb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6crqb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-6crqb true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-90-32-22.eu-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003bd6bb0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003bd6bd0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-25 10:06:22 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-03-25 10:06:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-03-25 10:06:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-25 10:06:22 +0000 UTC  }],Message:,Reason:,HostIP:10.90.32.22,PodIP:,StartTime:2020-03-25 10:06:22 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 25 10:06:24.449: INFO: Pod "nginx-deployment-7b8c6f4498-f6tnd" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-f6tnd,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-4684,SelfLink:/api/v1/namespaces/deployment-4684/pods/nginx-deployment-7b8c6f4498-f6tnd,UID:f5723980-7777-4868-a4f0-24bd2e5a9cac,ResourceVersion:344294,Generation:0,CreationTimestamp:2020-03-25 10:06:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 d67006bd-717a-4953-8cc0-3e5b94fcfad1 0xc003bd6c90 0xc003bd6c91}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-6crqb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6crqb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-6crqb true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-90-32-23.eu-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003bd6cf0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003bd6d10}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-25 10:06:22 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-03-25 10:06:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-03-25 10:06:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-25 10:06:22 +0000 UTC  }],Message:,Reason:,HostIP:10.90.32.23,PodIP:,StartTime:2020-03-25 10:06:22 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 25 10:06:24.449: INFO: Pod "nginx-deployment-7b8c6f4498-fvsq4" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-fvsq4,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-4684,SelfLink:/api/v1/namespaces/deployment-4684/pods/nginx-deployment-7b8c6f4498-fvsq4,UID:44df26dc-4a13-43d2-ac69-ae756f7474d9,ResourceVersion:344293,Generation:0,CreationTimestamp:2020-03-25 10:06:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 d67006bd-717a-4953-8cc0-3e5b94fcfad1 0xc003bd6dd0 0xc003bd6dd1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-6crqb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6crqb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-6crqb true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-90-32-22.eu-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003bd6e30} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003bd6e50}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-25 10:06:22 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-03-25 10:06:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-03-25 10:06:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-25 10:06:22 +0000 UTC  }],Message:,Reason:,HostIP:10.90.32.22,PodIP:,StartTime:2020-03-25 10:06:22 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 25 10:06:24.449: INFO: Pod "nginx-deployment-7b8c6f4498-fw4cc" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-fw4cc,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-4684,SelfLink:/api/v1/namespaces/deployment-4684/pods/nginx-deployment-7b8c6f4498-fw4cc,UID:b44c3c0b-b916-4c23-a002-40e35782ffca,ResourceVersion:344142,Generation:0,CreationTimestamp:2020-03-25 10:06:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 d67006bd-717a-4953-8cc0-3e5b94fcfad1 0xc003bd6f10 0xc003bd6f11}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-6crqb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6crqb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-6crqb true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-90-32-22.eu-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003bd6f80} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003bd6fa0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-25 10:06:16 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2020-03-25 10:06:19 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2020-03-25 10:06:19 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-25 10:06:16 +0000 UTC  }],Message:,Reason:,HostIP:10.90.32.22,PodIP:10.200.33.59,StartTime:2020-03-25 10:06:16 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2020-03-25 10:06:18 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://dec958d9e539208520fb040f7aad85ce5bff67614a42cb08b050077ecea3b89b}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 25 10:06:24.449: INFO: Pod "nginx-deployment-7b8c6f4498-g9nm7" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-g9nm7,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-4684,SelfLink:/api/v1/namespaces/deployment-4684/pods/nginx-deployment-7b8c6f4498-g9nm7,UID:4a733337-e096-41ba-9b4a-cfb9fd43e441,ResourceVersion:344129,Generation:0,CreationTimestamp:2020-03-25 10:06:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 d67006bd-717a-4953-8cc0-3e5b94fcfad1 0xc003bd7070 0xc003bd7071}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-6crqb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6crqb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-6crqb true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-90-32-24.eu-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003bd70d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003bd70f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-25 10:06:16 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2020-03-25 10:06:18 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2020-03-25 10:06:18 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-25 10:06:16 +0000 UTC  }],Message:,Reason:,HostIP:10.90.32.24,PodIP:10.200.90.46,StartTime:2020-03-25 10:06:16 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2020-03-25 10:06:17 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://74e5014e8f6918bea557fccbeab6b27a06880e9f575ee75da8eec1a21506bf6f}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 25 10:06:24.449: INFO: Pod "nginx-deployment-7b8c6f4498-hrzxt" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-hrzxt,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-4684,SelfLink:/api/v1/namespaces/deployment-4684/pods/nginx-deployment-7b8c6f4498-hrzxt,UID:aa3f579b-e26c-4211-b677-e37294cbba76,ResourceVersion:344136,Generation:0,CreationTimestamp:2020-03-25 10:06:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 d67006bd-717a-4953-8cc0-3e5b94fcfad1 0xc003bd71c0 0xc003bd71c1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-6crqb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6crqb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-6crqb true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-90-32-23.eu-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003bd7220} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003bd7240}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-25 10:06:16 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2020-03-25 10:06:18 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2020-03-25 10:06:18 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-25 10:06:16 +0000 UTC  }],Message:,Reason:,HostIP:10.90.32.23,PodIP:10.200.96.186,StartTime:2020-03-25 10:06:16 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2020-03-25 10:06:17 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://c5fe79ca77bf19743396f62f34c5af51be37df6c103d1cb3777155aa0d6e3b56}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 25 10:06:24.450: INFO: Pod "nginx-deployment-7b8c6f4498-phbdv" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-phbdv,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-4684,SelfLink:/api/v1/namespaces/deployment-4684/pods/nginx-deployment-7b8c6f4498-phbdv,UID:2fa71e8f-198d-4f72-bc55-22cfe480735e,ResourceVersion:344327,Generation:0,CreationTimestamp:2020-03-25 10:06:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 d67006bd-717a-4953-8cc0-3e5b94fcfad1 0xc003bd7310 0xc003bd7311}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-6crqb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6crqb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-6crqb true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-90-32-24.eu-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003bd7370} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003bd7390}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-25 10:06:22 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-03-25 10:06:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-03-25 10:06:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-25 10:06:22 +0000 UTC  }],Message:,Reason:,HostIP:10.90.32.24,PodIP:,StartTime:2020-03-25 10:06:22 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 25 10:06:24.450: INFO: Pod "nginx-deployment-7b8c6f4498-psfsf" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-psfsf,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-4684,SelfLink:/api/v1/namespaces/deployment-4684/pods/nginx-deployment-7b8c6f4498-psfsf,UID:5c41bc36-c11f-4f59-ab00-232d64f7cf2b,ResourceVersion:344132,Generation:0,CreationTimestamp:2020-03-25 10:06:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 d67006bd-717a-4953-8cc0-3e5b94fcfad1 0xc003bd7450 0xc003bd7451}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-6crqb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6crqb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-6crqb true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-90-32-24.eu-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003bd74b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003bd74d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-25 10:06:16 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2020-03-25 10:06:18 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2020-03-25 10:06:18 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-25 10:06:16 +0000 UTC  }],Message:,Reason:,HostIP:10.90.32.24,PodIP:10.200.90.44,StartTime:2020-03-25 10:06:16 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2020-03-25 10:06:17 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://d99cb1067a545029cc8c53fd5c3c1faf8c4555a44c49a2a15de2b5ebca77ed54}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 25 10:06:24.450: INFO: Pod "nginx-deployment-7b8c6f4498-pz2dj" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-pz2dj,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-4684,SelfLink:/api/v1/namespaces/deployment-4684/pods/nginx-deployment-7b8c6f4498-pz2dj,UID:2c7486c3-d7cc-48eb-bd0e-a929dce2db60,ResourceVersion:344372,Generation:0,CreationTimestamp:2020-03-25 10:06:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 d67006bd-717a-4953-8cc0-3e5b94fcfad1 0xc003bd75a0 0xc003bd75a1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-6crqb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6crqb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-6crqb true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-90-32-24.eu-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003bd7600} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003bd7620}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-25 10:06:22 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2020-03-25 10:06:24 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2020-03-25 10:06:24 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-25 10:06:22 +0000 UTC  }],Message:,Reason:,HostIP:10.90.32.24,PodIP:10.200.90.50,StartTime:2020-03-25 10:06:22 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2020-03-25 10:06:23 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://179d32dfb18fa36b0f01ff8c8621ca268920160756341f6fde8cb3d67b3b2c04}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 25 10:06:24.450: INFO: Pod "nginx-deployment-7b8c6f4498-qst4z" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-qst4z,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-4684,SelfLink:/api/v1/namespaces/deployment-4684/pods/nginx-deployment-7b8c6f4498-qst4z,UID:d565682f-cecf-42c3-9a48-27e448f898ab,ResourceVersion:344115,Generation:0,CreationTimestamp:2020-03-25 10:06:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 d67006bd-717a-4953-8cc0-3e5b94fcfad1 0xc003bd76f0 0xc003bd76f1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-6crqb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6crqb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-6crqb true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-90-32-23.eu-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003bd7750} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003bd7770}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-25 10:06:16 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2020-03-25 10:06:17 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2020-03-25 10:06:17 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-25 10:06:16 +0000 UTC  }],Message:,Reason:,HostIP:10.90.32.23,PodIP:10.200.96.185,StartTime:2020-03-25 10:06:16 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2020-03-25 10:06:17 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://dd6d2ff1b6d367963c8fe39ca38b90fca5c0626f77172568ae8e146c54328253}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 25 10:06:24.451: INFO: Pod "nginx-deployment-7b8c6f4498-r9gf2" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-r9gf2,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-4684,SelfLink:/api/v1/namespaces/deployment-4684/pods/nginx-deployment-7b8c6f4498-r9gf2,UID:80cbdf92-ca45-4673-aafa-93e870f55fb6,ResourceVersion:344121,Generation:0,CreationTimestamp:2020-03-25 10:06:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 d67006bd-717a-4953-8cc0-3e5b94fcfad1 0xc003bd7840 0xc003bd7841}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-6crqb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6crqb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-6crqb true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-90-32-22.eu-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003bd78a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003bd78c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-25 10:06:16 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2020-03-25 10:06:17 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2020-03-25 10:06:17 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-25 10:06:16 +0000 UTC  }],Message:,Reason:,HostIP:10.90.32.22,PodIP:10.200.33.56,StartTime:2020-03-25 10:06:16 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2020-03-25 10:06:17 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://b01be9653818fcadaf9bc07547d944c1daf03260f733088fd4330d5e5d5cf210}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 25 10:06:24.451: INFO: Pod "nginx-deployment-7b8c6f4498-scbm8" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-scbm8,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-4684,SelfLink:/api/v1/namespaces/deployment-4684/pods/nginx-deployment-7b8c6f4498-scbm8,UID:988b3f35-2f30-4bab-b1ac-e69f73404bb3,ResourceVersion:344126,Generation:0,CreationTimestamp:2020-03-25 10:06:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 d67006bd-717a-4953-8cc0-3e5b94fcfad1 0xc003bd7990 0xc003bd7991}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-6crqb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6crqb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-6crqb true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-90-32-24.eu-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003bd79f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003bd7a10}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-25 10:06:16 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2020-03-25 10:06:18 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2020-03-25 10:06:18 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-25 10:06:16 +0000 UTC  }],Message:,Reason:,HostIP:10.90.32.24,PodIP:10.200.90.45,StartTime:2020-03-25 10:06:16 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2020-03-25 10:06:17 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://7f3c2844140fd1b06cfd431c70d3c265dfe182284c3431fcde83de9b583da025}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 25 10:06:24.451: INFO: Pod "nginx-deployment-7b8c6f4498-tm222" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-tm222,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-4684,SelfLink:/api/v1/namespaces/deployment-4684/pods/nginx-deployment-7b8c6f4498-tm222,UID:852a3d41-5e88-4a8a-907c-51623f3df00b,ResourceVersion:344393,Generation:0,CreationTimestamp:2020-03-25 10:06:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 d67006bd-717a-4953-8cc0-3e5b94fcfad1 0xc003bd7ae0 0xc003bd7ae1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-6crqb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6crqb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-6crqb true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-90-32-22.eu-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003bd7b40} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003bd7b60}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-25 10:06:22 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2020-03-25 10:06:24 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2020-03-25 10:06:24 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-25 10:06:22 +0000 UTC  }],Message:,Reason:,HostIP:10.90.32.22,PodIP:10.200.33.62,StartTime:2020-03-25 10:06:22 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2020-03-25 10:06:23 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://29fe6662b3f65d9b9167a76eb243b8f3f15d396e8dfe10870eed357efd9d12cd}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 25 10:06:24.451: INFO: Pod "nginx-deployment-7b8c6f4498-v79wc" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-v79wc,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-4684,SelfLink:/api/v1/namespaces/deployment-4684/pods/nginx-deployment-7b8c6f4498-v79wc,UID:bc66070e-f914-4207-86f4-d61d4c509424,ResourceVersion:344107,Generation:0,CreationTimestamp:2020-03-25 10:06:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 d67006bd-717a-4953-8cc0-3e5b94fcfad1 0xc003bd7c30 0xc003bd7c31}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-6crqb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6crqb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-6crqb true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-90-32-23.eu-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003bd7c90} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003bd7cb0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-25 10:06:16 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2020-03-25 10:06:17 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2020-03-25 10:06:17 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-25 10:06:16 +0000 UTC  }],Message:,Reason:,HostIP:10.90.32.23,PodIP:10.200.96.184,StartTime:2020-03-25 10:06:16 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2020-03-25 10:06:17 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://33d599d3b6d8cec55d1ddcfca4a81a8d4b8a4879f6bf00fd492c24eb2b7117c1}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 25 10:06:24.451: INFO: Pod "nginx-deployment-7b8c6f4498-zhwlj" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-zhwlj,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-4684,SelfLink:/api/v1/namespaces/deployment-4684/pods/nginx-deployment-7b8c6f4498-zhwlj,UID:ef165af1-a8ce-44d6-ae54-8f4b027bdf26,ResourceVersion:344339,Generation:0,CreationTimestamp:2020-03-25 10:06:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 d67006bd-717a-4953-8cc0-3e5b94fcfad1 0xc003bd7d80 0xc003bd7d81}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-6crqb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6crqb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-6crqb true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-90-32-23.eu-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003bd7de0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003bd7e00}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-25 10:06:22 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-03-25 10:06:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-03-25 10:06:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-25 10:06:22 +0000 UTC  }],Message:,Reason:,HostIP:10.90.32.23,PodIP:,StartTime:2020-03-25 10:06:22 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 25 10:06:24.451: INFO: Pod "nginx-deployment-7b8c6f4498-zj69l" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-zj69l,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-4684,SelfLink:/api/v1/namespaces/deployment-4684/pods/nginx-deployment-7b8c6f4498-zj69l,UID:ab1da1fd-6611-40e3-b194-3ec8246a87e8,ResourceVersion:344383,Generation:0,CreationTimestamp:2020-03-25 10:06:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 d67006bd-717a-4953-8cc0-3e5b94fcfad1 0xc003bd7ec0 0xc003bd7ec1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-6crqb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6crqb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-6crqb true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-90-32-23.eu-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003bd7f20} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003bd7f40}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-25 10:06:22 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2020-03-25 10:06:24 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2020-03-25 10:06:24 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-25 10:06:22 +0000 UTC  }],Message:,Reason:,HostIP:10.90.32.23,PodIP:10.200.96.189,StartTime:2020-03-25 10:06:22 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2020-03-25 10:06:23 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://e4a69bbbcb2480bad4753b0d1464f078e7885dffaac827d3c8e8de6a1e864195}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 25 10:06:24.451: INFO: Pod "nginx-deployment-7b8c6f4498-zwshs" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-zwshs,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-4684,SelfLink:/api/v1/namespaces/deployment-4684/pods/nginx-deployment-7b8c6f4498-zwshs,UID:093b8238-fa00-4830-ad49-69be269cf1f9,ResourceVersion:344302,Generation:0,CreationTimestamp:2020-03-25 10:06:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 d67006bd-717a-4953-8cc0-3e5b94fcfad1 0xc000936080 0xc000936081}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-6crqb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6crqb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-6crqb true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-90-32-22.eu-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0009360e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000936100}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-25 10:06:22 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-03-25 10:06:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-03-25 10:06:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-25 10:06:22 +0000 UTC  }],Message:,Reason:,HostIP:10.90.32.22,PodIP:,StartTime:2020-03-25 10:06:22 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 10:06:24.451: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-4684" for this suite.
Mar 25 10:06:32.462: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 10:06:32.529: INFO: namespace deployment-4684 deletion completed in 8.074527196s

• [SLOW TEST:16.354 seconds]
[sig-apps] Deployment
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 10:06:32.529: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-2543
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 10:06:55.835: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-2543" for this suite.
Mar 25 10:07:01.846: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 10:07:01.912: INFO: namespace container-runtime-2543 deletion completed in 6.073690378s

• [SLOW TEST:29.383 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  blackbox test
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
    when starting a container that exits
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 10:07:01.912: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-9302
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Mar 25 10:07:02.074: INFO: Number of nodes with available pods: 0
Mar 25 10:07:02.074: INFO: Node ip-10-90-32-22.eu-west-2.compute.internal is running more than one daemon pod
Mar 25 10:07:03.079: INFO: Number of nodes with available pods: 0
Mar 25 10:07:03.079: INFO: Node ip-10-90-32-22.eu-west-2.compute.internal is running more than one daemon pod
Mar 25 10:07:04.080: INFO: Number of nodes with available pods: 2
Mar 25 10:07:04.080: INFO: Node ip-10-90-32-24.eu-west-2.compute.internal is running more than one daemon pod
Mar 25 10:07:05.080: INFO: Number of nodes with available pods: 3
Mar 25 10:07:05.080: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Mar 25 10:07:05.105: INFO: Number of nodes with available pods: 2
Mar 25 10:07:05.105: INFO: Node ip-10-90-32-23.eu-west-2.compute.internal is running more than one daemon pod
Mar 25 10:07:06.112: INFO: Number of nodes with available pods: 2
Mar 25 10:07:06.112: INFO: Node ip-10-90-32-23.eu-west-2.compute.internal is running more than one daemon pod
Mar 25 10:07:07.111: INFO: Number of nodes with available pods: 3
Mar 25 10:07:07.111: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-9302, will wait for the garbage collector to delete the pods
Mar 25 10:07:07.174: INFO: Deleting DaemonSet.extensions daemon-set took: 6.712972ms
Mar 25 10:07:07.474: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.161264ms
Mar 25 10:07:19.576: INFO: Number of nodes with available pods: 0
Mar 25 10:07:19.576: INFO: Number of running nodes: 0, number of available pods: 0
Mar 25 10:07:19.578: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-9302/daemonsets","resourceVersion":"344904"},"items":null}

Mar 25 10:07:19.580: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-9302/pods","resourceVersion":"344904"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 10:07:19.588: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-9302" for this suite.
Mar 25 10:07:25.600: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 10:07:25.670: INFO: namespace daemonsets-9302 deletion completed in 6.078564431s

• [SLOW TEST:23.758 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 10:07:25.670: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-9234
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:63
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Mar 25 10:07:29.852: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Mar 25 10:07:29.854: INFO: Pod pod-with-poststart-http-hook still exists
Mar 25 10:07:31.854: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Mar 25 10:07:31.857: INFO: Pod pod-with-poststart-http-hook still exists
Mar 25 10:07:33.854: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Mar 25 10:07:33.857: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 10:07:33.857: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-9234" for this suite.
Mar 25 10:07:55.868: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 10:07:55.935: INFO: namespace container-lifecycle-hook-9234 deletion completed in 22.075358024s

• [SLOW TEST:30.265 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when create a pod with lifecycle hook
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 10:07:55.936: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-5885
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 10:07:56.083: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-5885" for this suite.
Mar 25 10:08:18.096: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 10:08:18.170: INFO: namespace kubelet-test-5885 deletion completed in 22.083855893s

• [SLOW TEST:22.234 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should be possible to delete [NodeConformance] [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 10:08:18.170: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-1140
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating service multi-endpoint-test in namespace services-1140
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-1140 to expose endpoints map[]
Mar 25 10:08:18.314: INFO: successfully validated that service multi-endpoint-test in namespace services-1140 exposes endpoints map[] (4.108144ms elapsed)
STEP: Creating pod pod1 in namespace services-1140
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-1140 to expose endpoints map[pod1:[100]]
Mar 25 10:08:20.342: INFO: successfully validated that service multi-endpoint-test in namespace services-1140 exposes endpoints map[pod1:[100]] (2.0209854s elapsed)
STEP: Creating pod pod2 in namespace services-1140
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-1140 to expose endpoints map[pod1:[100] pod2:[101]]
Mar 25 10:08:22.378: INFO: successfully validated that service multi-endpoint-test in namespace services-1140 exposes endpoints map[pod1:[100] pod2:[101]] (2.030819281s elapsed)
STEP: Deleting pod pod1 in namespace services-1140
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-1140 to expose endpoints map[pod2:[101]]
Mar 25 10:08:22.395: INFO: successfully validated that service multi-endpoint-test in namespace services-1140 exposes endpoints map[pod2:[101]] (12.00859ms elapsed)
STEP: Deleting pod pod2 in namespace services-1140
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-1140 to expose endpoints map[]
Mar 25 10:08:22.405: INFO: successfully validated that service multi-endpoint-test in namespace services-1140 exposes endpoints map[] (3.239052ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 10:08:22.418: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-1140" for this suite.
Mar 25 10:08:28.429: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 10:08:28.497: INFO: namespace services-1140 deletion completed in 6.075963325s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:92

• [SLOW TEST:10.327 seconds]
[sig-network] Services
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 10:08:28.498: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svcaccounts-3214
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: getting the auto-created API token
Mar 25 10:08:29.174: INFO: created pod pod-service-account-defaultsa
Mar 25 10:08:29.174: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Mar 25 10:08:29.183: INFO: created pod pod-service-account-mountsa
Mar 25 10:08:29.183: INFO: pod pod-service-account-mountsa service account token volume mount: true
Mar 25 10:08:29.203: INFO: created pod pod-service-account-nomountsa
Mar 25 10:08:29.203: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Mar 25 10:08:29.215: INFO: created pod pod-service-account-defaultsa-mountspec
Mar 25 10:08:29.215: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Mar 25 10:08:29.225: INFO: created pod pod-service-account-mountsa-mountspec
Mar 25 10:08:29.225: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Mar 25 10:08:29.237: INFO: created pod pod-service-account-nomountsa-mountspec
Mar 25 10:08:29.237: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Mar 25 10:08:29.247: INFO: created pod pod-service-account-defaultsa-nomountspec
Mar 25 10:08:29.247: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Mar 25 10:08:29.257: INFO: created pod pod-service-account-mountsa-nomountspec
Mar 25 10:08:29.257: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Mar 25 10:08:29.268: INFO: created pod pod-service-account-nomountsa-nomountspec
Mar 25 10:08:29.268: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 10:08:29.268: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-3214" for this suite.
Mar 25 10:08:35.295: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 10:08:35.359: INFO: namespace svcaccounts-3214 deletion completed in 6.079918223s

• [SLOW TEST:6.861 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:23
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 10:08:35.359: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-3964
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 10:08:39.513: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-3964" for this suite.
Mar 25 10:09:23.524: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 10:09:23.592: INFO: namespace kubelet-test-3964 deletion completed in 44.0763532s

• [SLOW TEST:48.233 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when scheduling a read only busybox container
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:187
    should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 10:09:23.593: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-419
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-2f240204-df8b-4d50-956e-f633923e8881
STEP: Creating a pod to test consume configMaps
Mar 25 10:09:23.731: INFO: Waiting up to 5m0s for pod "pod-configmaps-2005ba07-eb96-4df1-8eaa-3777a1d73ad3" in namespace "configmap-419" to be "success or failure"
Mar 25 10:09:23.735: INFO: Pod "pod-configmaps-2005ba07-eb96-4df1-8eaa-3777a1d73ad3": Phase="Pending", Reason="", readiness=false. Elapsed: 3.599136ms
Mar 25 10:09:25.738: INFO: Pod "pod-configmaps-2005ba07-eb96-4df1-8eaa-3777a1d73ad3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00660957s
STEP: Saw pod success
Mar 25 10:09:25.738: INFO: Pod "pod-configmaps-2005ba07-eb96-4df1-8eaa-3777a1d73ad3" satisfied condition "success or failure"
Mar 25 10:09:25.740: INFO: Trying to get logs from node ip-10-90-32-23.eu-west-2.compute.internal pod pod-configmaps-2005ba07-eb96-4df1-8eaa-3777a1d73ad3 container configmap-volume-test: <nil>
STEP: delete the pod
Mar 25 10:09:25.755: INFO: Waiting for pod pod-configmaps-2005ba07-eb96-4df1-8eaa-3777a1d73ad3 to disappear
Mar 25 10:09:25.757: INFO: Pod pod-configmaps-2005ba07-eb96-4df1-8eaa-3777a1d73ad3 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 10:09:25.757: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-419" for this suite.
Mar 25 10:09:31.768: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 10:09:31.834: INFO: namespace configmap-419 deletion completed in 6.073914512s

• [SLOW TEST:8.241 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 10:09:31.834: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6147
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-ec8f90ed-da77-4272-ad1c-6857a0a0b089
STEP: Creating a pod to test consume secrets
Mar 25 10:09:31.975: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-4c766b7b-90e9-4f9c-a890-2ecbef7924f2" in namespace "projected-6147" to be "success or failure"
Mar 25 10:09:31.979: INFO: Pod "pod-projected-secrets-4c766b7b-90e9-4f9c-a890-2ecbef7924f2": Phase="Pending", Reason="", readiness=false. Elapsed: 3.924632ms
Mar 25 10:09:33.982: INFO: Pod "pod-projected-secrets-4c766b7b-90e9-4f9c-a890-2ecbef7924f2": Phase="Running", Reason="", readiness=true. Elapsed: 2.006891773s
Mar 25 10:09:35.985: INFO: Pod "pod-projected-secrets-4c766b7b-90e9-4f9c-a890-2ecbef7924f2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010034003s
STEP: Saw pod success
Mar 25 10:09:35.985: INFO: Pod "pod-projected-secrets-4c766b7b-90e9-4f9c-a890-2ecbef7924f2" satisfied condition "success or failure"
Mar 25 10:09:35.987: INFO: Trying to get logs from node ip-10-90-32-23.eu-west-2.compute.internal pod pod-projected-secrets-4c766b7b-90e9-4f9c-a890-2ecbef7924f2 container projected-secret-volume-test: <nil>
STEP: delete the pod
Mar 25 10:09:36.019: INFO: Waiting for pod pod-projected-secrets-4c766b7b-90e9-4f9c-a890-2ecbef7924f2 to disappear
Mar 25 10:09:36.022: INFO: Pod pod-projected-secrets-4c766b7b-90e9-4f9c-a890-2ecbef7924f2 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 10:09:36.023: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6147" for this suite.
Mar 25 10:09:42.041: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 10:09:42.108: INFO: namespace projected-6147 deletion completed in 6.081581787s

• [SLOW TEST:10.275 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 10:09:42.109: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-9586
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Mar 25 10:09:42.249: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Mar 25 10:09:47.252: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Mar 25 10:09:47.252: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
Mar 25 10:09:49.277: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment,GenerateName:,Namespace:deployment-9586,SelfLink:/apis/apps/v1/namespaces/deployment-9586/deployments/test-cleanup-deployment,UID:986af029-eb1d-4764-86ca-c80bf57c4197,ResourceVersion:345492,Generation:1,CreationTimestamp:2020-03-25 10:09:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 1,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2020-03-25 10:09:47 +0000 UTC 2020-03-25 10:09:47 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2020-03-25 10:09:48 +0000 UTC 2020-03-25 10:09:47 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-cleanup-deployment-55bbcbc84c" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Mar 25 10:09:49.280: INFO: New ReplicaSet "test-cleanup-deployment-55bbcbc84c" of Deployment "test-cleanup-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-55bbcbc84c,GenerateName:,Namespace:deployment-9586,SelfLink:/apis/apps/v1/namespaces/deployment-9586/replicasets/test-cleanup-deployment-55bbcbc84c,UID:b8460e01-fec9-40b8-89c5-a1001f43020a,ResourceVersion:345481,Generation:1,CreationTimestamp:2020-03-25 10:09:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 55bbcbc84c,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment 986af029-eb1d-4764-86ca-c80bf57c4197 0xc002b70b47 0xc002b70b48}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: 55bbcbc84c,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 55bbcbc84c,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Mar 25 10:09:49.282: INFO: Pod "test-cleanup-deployment-55bbcbc84c-pnhcq" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-55bbcbc84c-pnhcq,GenerateName:test-cleanup-deployment-55bbcbc84c-,Namespace:deployment-9586,SelfLink:/api/v1/namespaces/deployment-9586/pods/test-cleanup-deployment-55bbcbc84c-pnhcq,UID:89611188-1a90-427e-bda8-2ab8eca88b45,ResourceVersion:345480,Generation:0,CreationTimestamp:2020-03-25 10:09:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 55bbcbc84c,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-deployment-55bbcbc84c b8460e01-fec9-40b8-89c5-a1001f43020a 0xc002b71197 0xc002b71198}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-9h5mn {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9h5mn,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-9h5mn true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-90-32-24.eu-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002b71200} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002b71220}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-25 10:09:47 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2020-03-25 10:09:48 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2020-03-25 10:09:48 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-25 10:09:47 +0000 UTC  }],Message:,Reason:,HostIP:10.90.32.24,PodIP:10.200.90.58,StartTime:2020-03-25 10:09:47 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2020-03-25 10:09:48 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://1e465d16810a061ed5b8c564177399f4aef6cc5abdbf33d7e5156da86ab63ed9}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 10:09:49.282: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-9586" for this suite.
Mar 25 10:09:55.292: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 10:09:55.358: INFO: namespace deployment-9586 deletion completed in 6.073354947s

• [SLOW TEST:13.249 seconds]
[sig-apps] Deployment
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 10:09:55.358: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7764
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Mar 25 10:09:55.496: INFO: Waiting up to 5m0s for pod "downwardapi-volume-82b57534-c6b3-43c0-9f18-01eac166337c" in namespace "projected-7764" to be "success or failure"
Mar 25 10:09:55.501: INFO: Pod "downwardapi-volume-82b57534-c6b3-43c0-9f18-01eac166337c": Phase="Pending", Reason="", readiness=false. Elapsed: 4.233698ms
Mar 25 10:09:57.503: INFO: Pod "downwardapi-volume-82b57534-c6b3-43c0-9f18-01eac166337c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006835168s
STEP: Saw pod success
Mar 25 10:09:57.503: INFO: Pod "downwardapi-volume-82b57534-c6b3-43c0-9f18-01eac166337c" satisfied condition "success or failure"
Mar 25 10:09:57.505: INFO: Trying to get logs from node ip-10-90-32-23.eu-west-2.compute.internal pod downwardapi-volume-82b57534-c6b3-43c0-9f18-01eac166337c container client-container: <nil>
STEP: delete the pod
Mar 25 10:09:57.520: INFO: Waiting for pod downwardapi-volume-82b57534-c6b3-43c0-9f18-01eac166337c to disappear
Mar 25 10:09:57.522: INFO: Pod downwardapi-volume-82b57534-c6b3-43c0-9f18-01eac166337c no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 10:09:57.522: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7764" for this suite.
Mar 25 10:10:03.534: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 10:10:03.604: INFO: namespace projected-7764 deletion completed in 6.078801018s

• [SLOW TEST:8.246 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 10:10:03.604: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-8903
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Mar 25 10:10:05.756: INFO: Expected: &{} to match Container's Termination Message:  --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 10:10:05.767: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-8903" for this suite.
Mar 25 10:10:11.779: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 10:10:11.847: INFO: namespace container-runtime-8903 deletion completed in 6.077209747s

• [SLOW TEST:8.243 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  blackbox test
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
    on terminated container
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:129
      should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 10:10:11.847: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-4011
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod liveness-87c75bb8-b149-4356-bf95-367969e1b34f in namespace container-probe-4011
Mar 25 10:10:13.998: INFO: Started pod liveness-87c75bb8-b149-4356-bf95-367969e1b34f in namespace container-probe-4011
STEP: checking the pod's current state and verifying that restartCount is present
Mar 25 10:10:14.000: INFO: Initial restart count of pod liveness-87c75bb8-b149-4356-bf95-367969e1b34f is 0
Mar 25 10:10:28.023: INFO: Restart count of pod container-probe-4011/liveness-87c75bb8-b149-4356-bf95-367969e1b34f is now 1 (14.02293414s elapsed)
Mar 25 10:10:48.052: INFO: Restart count of pod container-probe-4011/liveness-87c75bb8-b149-4356-bf95-367969e1b34f is now 2 (34.052250046s elapsed)
Mar 25 10:11:08.091: INFO: Restart count of pod container-probe-4011/liveness-87c75bb8-b149-4356-bf95-367969e1b34f is now 3 (54.091586658s elapsed)
Mar 25 10:11:28.121: INFO: Restart count of pod container-probe-4011/liveness-87c75bb8-b149-4356-bf95-367969e1b34f is now 4 (1m14.120857172s elapsed)
Mar 25 10:12:42.232: INFO: Restart count of pod container-probe-4011/liveness-87c75bb8-b149-4356-bf95-367969e1b34f is now 5 (2m28.232000118s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 10:12:42.241: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-4011" for this suite.
Mar 25 10:12:48.253: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 10:12:48.320: INFO: namespace container-probe-4011 deletion completed in 6.075464442s

• [SLOW TEST:156.473 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 10:12:48.320: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-1456
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: validating cluster-info
Mar 25 10:12:48.452: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 cluster-info'
Mar 25 10:12:48.520: INFO: stderr: ""
Mar 25 10:12:48.520: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://10.100.200.1:443\x1b[0m\n\x1b[0;32mCoreDNS\x1b[0m is running at \x1b[0;33mhttps://10.100.200.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 10:12:48.520: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1456" for this suite.
Mar 25 10:12:54.531: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 10:12:54.601: INFO: namespace kubectl-1456 deletion completed in 6.078428284s

• [SLOW TEST:6.281 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl cluster-info
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 10:12:54.601: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-2660
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Mar 25 10:12:54.746: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Mar 25 10:12:54.757: INFO: Number of nodes with available pods: 0
Mar 25 10:12:54.757: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Mar 25 10:12:54.775: INFO: Number of nodes with available pods: 0
Mar 25 10:12:54.775: INFO: Node ip-10-90-32-22.eu-west-2.compute.internal is running more than one daemon pod
Mar 25 10:12:55.778: INFO: Number of nodes with available pods: 0
Mar 25 10:12:55.778: INFO: Node ip-10-90-32-22.eu-west-2.compute.internal is running more than one daemon pod
Mar 25 10:12:56.778: INFO: Number of nodes with available pods: 1
Mar 25 10:12:56.778: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Mar 25 10:12:56.799: INFO: Number of nodes with available pods: 0
Mar 25 10:12:56.799: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Mar 25 10:12:56.814: INFO: Number of nodes with available pods: 0
Mar 25 10:12:56.814: INFO: Node ip-10-90-32-22.eu-west-2.compute.internal is running more than one daemon pod
Mar 25 10:12:57.817: INFO: Number of nodes with available pods: 0
Mar 25 10:12:57.817: INFO: Node ip-10-90-32-22.eu-west-2.compute.internal is running more than one daemon pod
Mar 25 10:12:58.817: INFO: Number of nodes with available pods: 0
Mar 25 10:12:58.817: INFO: Node ip-10-90-32-22.eu-west-2.compute.internal is running more than one daemon pod
Mar 25 10:12:59.817: INFO: Number of nodes with available pods: 0
Mar 25 10:12:59.817: INFO: Node ip-10-90-32-22.eu-west-2.compute.internal is running more than one daemon pod
Mar 25 10:13:00.825: INFO: Number of nodes with available pods: 0
Mar 25 10:13:00.827: INFO: Node ip-10-90-32-22.eu-west-2.compute.internal is running more than one daemon pod
Mar 25 10:13:01.817: INFO: Number of nodes with available pods: 0
Mar 25 10:13:01.817: INFO: Node ip-10-90-32-22.eu-west-2.compute.internal is running more than one daemon pod
Mar 25 10:13:02.817: INFO: Number of nodes with available pods: 1
Mar 25 10:13:02.817: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-2660, will wait for the garbage collector to delete the pods
Mar 25 10:13:02.880: INFO: Deleting DaemonSet.extensions daemon-set took: 7.1289ms
Mar 25 10:13:03.181: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.33551ms
Mar 25 10:13:09.483: INFO: Number of nodes with available pods: 0
Mar 25 10:13:09.483: INFO: Number of running nodes: 0, number of available pods: 0
Mar 25 10:13:09.487: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-2660/daemonsets","resourceVersion":"345978"},"items":null}

Mar 25 10:13:09.488: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-2660/pods","resourceVersion":"345978"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 10:13:09.503: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-2660" for this suite.
Mar 25 10:13:15.515: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 10:13:15.591: INFO: namespace daemonsets-2660 deletion completed in 6.08537757s

• [SLOW TEST:20.990 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 10:13:15.592: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-345
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name projected-secret-test-8a25b371-9589-4625-816c-d94c79b45866
STEP: Creating a pod to test consume secrets
Mar 25 10:13:15.733: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-179e86eb-764c-423b-aaf5-d4353e6a0d2c" in namespace "projected-345" to be "success or failure"
Mar 25 10:13:15.740: INFO: Pod "pod-projected-secrets-179e86eb-764c-423b-aaf5-d4353e6a0d2c": Phase="Pending", Reason="", readiness=false. Elapsed: 6.905441ms
Mar 25 10:13:17.743: INFO: Pod "pod-projected-secrets-179e86eb-764c-423b-aaf5-d4353e6a0d2c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010089854s
STEP: Saw pod success
Mar 25 10:13:17.743: INFO: Pod "pod-projected-secrets-179e86eb-764c-423b-aaf5-d4353e6a0d2c" satisfied condition "success or failure"
Mar 25 10:13:17.745: INFO: Trying to get logs from node ip-10-90-32-23.eu-west-2.compute.internal pod pod-projected-secrets-179e86eb-764c-423b-aaf5-d4353e6a0d2c container secret-volume-test: <nil>
STEP: delete the pod
Mar 25 10:13:17.762: INFO: Waiting for pod pod-projected-secrets-179e86eb-764c-423b-aaf5-d4353e6a0d2c to disappear
Mar 25 10:13:17.763: INFO: Pod pod-projected-secrets-179e86eb-764c-423b-aaf5-d4353e6a0d2c no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 10:13:17.763: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-345" for this suite.
Mar 25 10:13:23.774: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 10:13:23.842: INFO: namespace projected-345 deletion completed in 6.075993843s

• [SLOW TEST:8.251 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 10:13:23.843: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-7770
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir volume type on node default medium
Mar 25 10:13:23.980: INFO: Waiting up to 5m0s for pod "pod-8a249a62-8679-4fb8-ba54-e363e4a28d40" in namespace "emptydir-7770" to be "success or failure"
Mar 25 10:13:23.987: INFO: Pod "pod-8a249a62-8679-4fb8-ba54-e363e4a28d40": Phase="Pending", Reason="", readiness=false. Elapsed: 7.403206ms
Mar 25 10:13:25.990: INFO: Pod "pod-8a249a62-8679-4fb8-ba54-e363e4a28d40": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01029824s
STEP: Saw pod success
Mar 25 10:13:25.990: INFO: Pod "pod-8a249a62-8679-4fb8-ba54-e363e4a28d40" satisfied condition "success or failure"
Mar 25 10:13:25.992: INFO: Trying to get logs from node ip-10-90-32-23.eu-west-2.compute.internal pod pod-8a249a62-8679-4fb8-ba54-e363e4a28d40 container test-container: <nil>
STEP: delete the pod
Mar 25 10:13:26.007: INFO: Waiting for pod pod-8a249a62-8679-4fb8-ba54-e363e4a28d40 to disappear
Mar 25 10:13:26.009: INFO: Pod pod-8a249a62-8679-4fb8-ba54-e363e4a28d40 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 10:13:26.009: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7770" for this suite.
Mar 25 10:13:32.020: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 10:13:32.090: INFO: namespace emptydir-7770 deletion completed in 6.078436611s

• [SLOW TEST:8.248 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 10:13:32.091: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-1536
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-map-29004152-f4f0-4eb9-b969-b9d9bb7e2122
STEP: Creating a pod to test consume configMaps
Mar 25 10:13:32.231: INFO: Waiting up to 5m0s for pod "pod-configmaps-e0e469b1-fe13-44fa-854f-840afa6e7f4f" in namespace "configmap-1536" to be "success or failure"
Mar 25 10:13:32.238: INFO: Pod "pod-configmaps-e0e469b1-fe13-44fa-854f-840afa6e7f4f": Phase="Pending", Reason="", readiness=false. Elapsed: 7.021016ms
Mar 25 10:13:34.241: INFO: Pod "pod-configmaps-e0e469b1-fe13-44fa-854f-840afa6e7f4f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009861482s
STEP: Saw pod success
Mar 25 10:13:34.241: INFO: Pod "pod-configmaps-e0e469b1-fe13-44fa-854f-840afa6e7f4f" satisfied condition "success or failure"
Mar 25 10:13:34.243: INFO: Trying to get logs from node ip-10-90-32-23.eu-west-2.compute.internal pod pod-configmaps-e0e469b1-fe13-44fa-854f-840afa6e7f4f container configmap-volume-test: <nil>
STEP: delete the pod
Mar 25 10:13:34.258: INFO: Waiting for pod pod-configmaps-e0e469b1-fe13-44fa-854f-840afa6e7f4f to disappear
Mar 25 10:13:34.260: INFO: Pod pod-configmaps-e0e469b1-fe13-44fa-854f-840afa6e7f4f no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 10:13:34.260: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1536" for this suite.
Mar 25 10:13:40.271: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 10:13:40.343: INFO: namespace configmap-1536 deletion completed in 6.080567767s

• [SLOW TEST:8.252 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 10:13:40.343: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-7850
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Mar 25 10:13:40.482: INFO: Waiting up to 5m0s for pod "downwardapi-volume-3550dab5-9141-4834-b86f-eeafdee96b0d" in namespace "downward-api-7850" to be "success or failure"
Mar 25 10:13:40.486: INFO: Pod "downwardapi-volume-3550dab5-9141-4834-b86f-eeafdee96b0d": Phase="Pending", Reason="", readiness=false. Elapsed: 3.704867ms
Mar 25 10:13:42.489: INFO: Pod "downwardapi-volume-3550dab5-9141-4834-b86f-eeafdee96b0d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006840437s
STEP: Saw pod success
Mar 25 10:13:42.489: INFO: Pod "downwardapi-volume-3550dab5-9141-4834-b86f-eeafdee96b0d" satisfied condition "success or failure"
Mar 25 10:13:42.491: INFO: Trying to get logs from node ip-10-90-32-23.eu-west-2.compute.internal pod downwardapi-volume-3550dab5-9141-4834-b86f-eeafdee96b0d container client-container: <nil>
STEP: delete the pod
Mar 25 10:13:42.506: INFO: Waiting for pod downwardapi-volume-3550dab5-9141-4834-b86f-eeafdee96b0d to disappear
Mar 25 10:13:42.508: INFO: Pod downwardapi-volume-3550dab5-9141-4834-b86f-eeafdee96b0d no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 10:13:42.508: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7850" for this suite.
Mar 25 10:13:48.520: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 10:13:48.588: INFO: namespace downward-api-7850 deletion completed in 6.077201833s

• [SLOW TEST:8.245 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 10:13:48.589: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-1169
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Mar 25 10:13:48.728: INFO: Waiting up to 5m0s for pod "downward-api-43f6f874-537f-4a1b-a6e4-c0b0f73a6b6c" in namespace "downward-api-1169" to be "success or failure"
Mar 25 10:13:48.735: INFO: Pod "downward-api-43f6f874-537f-4a1b-a6e4-c0b0f73a6b6c": Phase="Pending", Reason="", readiness=false. Elapsed: 6.995869ms
Mar 25 10:13:50.738: INFO: Pod "downward-api-43f6f874-537f-4a1b-a6e4-c0b0f73a6b6c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009960905s
STEP: Saw pod success
Mar 25 10:13:50.738: INFO: Pod "downward-api-43f6f874-537f-4a1b-a6e4-c0b0f73a6b6c" satisfied condition "success or failure"
Mar 25 10:13:50.741: INFO: Trying to get logs from node ip-10-90-32-23.eu-west-2.compute.internal pod downward-api-43f6f874-537f-4a1b-a6e4-c0b0f73a6b6c container dapi-container: <nil>
STEP: delete the pod
Mar 25 10:13:50.787: INFO: Waiting for pod downward-api-43f6f874-537f-4a1b-a6e4-c0b0f73a6b6c to disappear
Mar 25 10:13:50.791: INFO: Pod downward-api-43f6f874-537f-4a1b-a6e4-c0b0f73a6b6c no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 10:13:50.791: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1169" for this suite.
Mar 25 10:13:56.803: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 10:13:56.867: INFO: namespace downward-api-1169 deletion completed in 6.073432338s

• [SLOW TEST:8.278 seconds]
[sig-node] Downward API
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 10:13:56.867: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-wrapper-4673
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Mar 25 10:13:57.260: INFO: Pod name wrapped-volume-race-b401f8a2-f22a-4b33-896d-9a5e1a883c95: Found 3 pods out of 5
Mar 25 10:14:02.269: INFO: Pod name wrapped-volume-race-b401f8a2-f22a-4b33-896d-9a5e1a883c95: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-b401f8a2-f22a-4b33-896d-9a5e1a883c95 in namespace emptydir-wrapper-4673, will wait for the garbage collector to delete the pods
Mar 25 10:14:12.345: INFO: Deleting ReplicationController wrapped-volume-race-b401f8a2-f22a-4b33-896d-9a5e1a883c95 took: 8.589062ms
Mar 25 10:14:14.445: INFO: Terminating ReplicationController wrapped-volume-race-b401f8a2-f22a-4b33-896d-9a5e1a883c95 pods took: 2.100271691s
STEP: Creating RC which spawns configmap-volume pods
Mar 25 10:14:59.862: INFO: Pod name wrapped-volume-race-90b05545-11a4-44e1-9138-cd1b57978776: Found 0 pods out of 5
Mar 25 10:15:04.868: INFO: Pod name wrapped-volume-race-90b05545-11a4-44e1-9138-cd1b57978776: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-90b05545-11a4-44e1-9138-cd1b57978776 in namespace emptydir-wrapper-4673, will wait for the garbage collector to delete the pods
Mar 25 10:15:16.948: INFO: Deleting ReplicationController wrapped-volume-race-90b05545-11a4-44e1-9138-cd1b57978776 took: 8.387911ms
Mar 25 10:15:17.348: INFO: Terminating ReplicationController wrapped-volume-race-90b05545-11a4-44e1-9138-cd1b57978776 pods took: 400.228815ms
STEP: Creating RC which spawns configmap-volume pods
Mar 25 10:15:59.865: INFO: Pod name wrapped-volume-race-fec6f2a5-2ef2-48f9-a2e2-ab3f842f90b5: Found 0 pods out of 5
Mar 25 10:16:04.872: INFO: Pod name wrapped-volume-race-fec6f2a5-2ef2-48f9-a2e2-ab3f842f90b5: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-fec6f2a5-2ef2-48f9-a2e2-ab3f842f90b5 in namespace emptydir-wrapper-4673, will wait for the garbage collector to delete the pods
Mar 25 10:16:14.948: INFO: Deleting ReplicationController wrapped-volume-race-fec6f2a5-2ef2-48f9-a2e2-ab3f842f90b5 took: 8.725499ms
Mar 25 10:16:15.349: INFO: Terminating ReplicationController wrapped-volume-race-fec6f2a5-2ef2-48f9-a2e2-ab3f842f90b5 pods took: 400.352867ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 10:16:59.651: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-4673" for this suite.
Mar 25 10:17:05.662: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 10:17:05.732: INFO: namespace emptydir-wrapper-4673 deletion completed in 6.078058648s

• [SLOW TEST:188.865 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 10:17:05.733: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-9880
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Mar 25 10:17:05.917: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Mar 25 10:17:05.926: INFO: Pod name sample-pod: Found 0 pods out of 1
Mar 25 10:17:10.929: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Mar 25 10:17:10.929: INFO: Creating deployment "test-rolling-update-deployment"
Mar 25 10:17:10.935: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Mar 25 10:17:10.945: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Mar 25 10:17:12.950: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Mar 25 10:17:12.951: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
Mar 25 10:17:12.957: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment,GenerateName:,Namespace:deployment-9880,SelfLink:/apis/apps/v1/namespaces/deployment-9880/deployments/test-rolling-update-deployment,UID:89f7585b-cc77-4663-b2ec-d4510b64aa9e,ResourceVersion:347367,Generation:1,CreationTimestamp:2020-03-25 10:17:10 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2020-03-25 10:17:10 +0000 UTC 2020-03-25 10:17:10 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2020-03-25 10:17:12 +0000 UTC 2020-03-25 10:17:10 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rolling-update-deployment-79f6b9d75c" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Mar 25 10:17:12.959: INFO: New ReplicaSet "test-rolling-update-deployment-79f6b9d75c" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-79f6b9d75c,GenerateName:,Namespace:deployment-9880,SelfLink:/apis/apps/v1/namespaces/deployment-9880/replicasets/test-rolling-update-deployment-79f6b9d75c,UID:dedfeaea-7ad6-49ee-a977-1983b01ca4e7,ResourceVersion:347356,Generation:1,CreationTimestamp:2020-03-25 10:17:10 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 79f6b9d75c,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 89f7585b-cc77-4663-b2ec-d4510b64aa9e 0xc00223f1f7 0xc00223f1f8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 79f6b9d75c,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 79f6b9d75c,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Mar 25 10:17:12.959: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Mar 25 10:17:12.960: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-controller,GenerateName:,Namespace:deployment-9880,SelfLink:/apis/apps/v1/namespaces/deployment-9880/replicasets/test-rolling-update-controller,UID:bb8b70f9-0fe8-4980-85d2-7bc318468e92,ResourceVersion:347365,Generation:2,CreationTimestamp:2020-03-25 10:17:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305832,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 89f7585b-cc77-4663-b2ec-d4510b64aa9e 0xc00223f127 0xc00223f128}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Mar 25 10:17:12.962: INFO: Pod "test-rolling-update-deployment-79f6b9d75c-2q5pz" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-79f6b9d75c-2q5pz,GenerateName:test-rolling-update-deployment-79f6b9d75c-,Namespace:deployment-9880,SelfLink:/api/v1/namespaces/deployment-9880/pods/test-rolling-update-deployment-79f6b9d75c-2q5pz,UID:b2010fc9-1625-4595-85dc-fbfde467a5bc,ResourceVersion:347355,Generation:0,CreationTimestamp:2020-03-25 10:17:10 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 79f6b9d75c,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rolling-update-deployment-79f6b9d75c dedfeaea-7ad6-49ee-a977-1983b01ca4e7 0xc00223fb07 0xc00223fb08}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-m6crx {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-m6crx,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-m6crx true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-90-32-22.eu-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00223fb70} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00223fb90}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-25 10:17:10 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2020-03-25 10:17:12 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2020-03-25 10:17:12 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-25 10:17:10 +0000 UTC  }],Message:,Reason:,HostIP:10.90.32.22,PodIP:10.200.33.91,StartTime:2020-03-25 10:17:10 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2020-03-25 10:17:11 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://10779cf16993eb3f3b27e0b18b73ce0516fb9af4ef02bf03625a9967df104e61}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 10:17:12.962: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-9880" for this suite.
Mar 25 10:17:18.973: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 10:17:19.040: INFO: namespace deployment-9880 deletion completed in 6.075715588s

• [SLOW TEST:13.308 seconds]
[sig-apps] Deployment
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 10:17:19.041: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-4213
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-configmap-lqgl
STEP: Creating a pod to test atomic-volume-subpath
Mar 25 10:17:19.236: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-lqgl" in namespace "subpath-4213" to be "success or failure"
Mar 25 10:17:19.240: INFO: Pod "pod-subpath-test-configmap-lqgl": Phase="Pending", Reason="", readiness=false. Elapsed: 3.697818ms
Mar 25 10:17:21.243: INFO: Pod "pod-subpath-test-configmap-lqgl": Phase="Running", Reason="", readiness=true. Elapsed: 2.006935872s
Mar 25 10:17:23.246: INFO: Pod "pod-subpath-test-configmap-lqgl": Phase="Running", Reason="", readiness=true. Elapsed: 4.010048102s
Mar 25 10:17:25.250: INFO: Pod "pod-subpath-test-configmap-lqgl": Phase="Running", Reason="", readiness=true. Elapsed: 6.013210753s
Mar 25 10:17:27.253: INFO: Pod "pod-subpath-test-configmap-lqgl": Phase="Running", Reason="", readiness=true. Elapsed: 8.016219246s
Mar 25 10:17:29.258: INFO: Pod "pod-subpath-test-configmap-lqgl": Phase="Running", Reason="", readiness=true. Elapsed: 10.021942078s
Mar 25 10:17:31.277: INFO: Pod "pod-subpath-test-configmap-lqgl": Phase="Running", Reason="", readiness=true. Elapsed: 12.040369311s
Mar 25 10:17:33.280: INFO: Pod "pod-subpath-test-configmap-lqgl": Phase="Running", Reason="", readiness=true. Elapsed: 14.043597324s
Mar 25 10:17:35.283: INFO: Pod "pod-subpath-test-configmap-lqgl": Phase="Running", Reason="", readiness=true. Elapsed: 16.046742261s
Mar 25 10:17:37.286: INFO: Pod "pod-subpath-test-configmap-lqgl": Phase="Running", Reason="", readiness=true. Elapsed: 18.049766189s
Mar 25 10:17:39.289: INFO: Pod "pod-subpath-test-configmap-lqgl": Phase="Running", Reason="", readiness=true. Elapsed: 20.052821113s
Mar 25 10:17:41.291: INFO: Pod "pod-subpath-test-configmap-lqgl": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.055072495s
STEP: Saw pod success
Mar 25 10:17:41.291: INFO: Pod "pod-subpath-test-configmap-lqgl" satisfied condition "success or failure"
Mar 25 10:17:41.293: INFO: Trying to get logs from node ip-10-90-32-23.eu-west-2.compute.internal pod pod-subpath-test-configmap-lqgl container test-container-subpath-configmap-lqgl: <nil>
STEP: delete the pod
Mar 25 10:17:41.309: INFO: Waiting for pod pod-subpath-test-configmap-lqgl to disappear
Mar 25 10:17:41.311: INFO: Pod pod-subpath-test-configmap-lqgl no longer exists
STEP: Deleting pod pod-subpath-test-configmap-lqgl
Mar 25 10:17:41.311: INFO: Deleting pod "pod-subpath-test-configmap-lqgl" in namespace "subpath-4213"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 10:17:41.313: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-4213" for this suite.
Mar 25 10:17:47.324: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 10:17:47.394: INFO: namespace subpath-4213 deletion completed in 6.078872498s

• [SLOW TEST:28.354 seconds]
[sig-storage] Subpath
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with configmap pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 10:17:47.395: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-5846
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Mar 25 10:17:50.064: INFO: Successfully updated pod "pod-update-activedeadlineseconds-d8a79fb6-1c13-45ec-90a4-1654db5d25e5"
Mar 25 10:17:50.064: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-d8a79fb6-1c13-45ec-90a4-1654db5d25e5" in namespace "pods-5846" to be "terminated due to deadline exceeded"
Mar 25 10:17:50.066: INFO: Pod "pod-update-activedeadlineseconds-d8a79fb6-1c13-45ec-90a4-1654db5d25e5": Phase="Running", Reason="", readiness=true. Elapsed: 2.134428ms
Mar 25 10:17:52.070: INFO: Pod "pod-update-activedeadlineseconds-d8a79fb6-1c13-45ec-90a4-1654db5d25e5": Phase="Running", Reason="", readiness=true. Elapsed: 2.005751525s
Mar 25 10:17:54.074: INFO: Pod "pod-update-activedeadlineseconds-d8a79fb6-1c13-45ec-90a4-1654db5d25e5": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 4.009536323s
Mar 25 10:17:54.074: INFO: Pod "pod-update-activedeadlineseconds-d8a79fb6-1c13-45ec-90a4-1654db5d25e5" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 10:17:54.074: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-5846" for this suite.
Mar 25 10:18:00.086: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 10:18:00.163: INFO: namespace pods-5846 deletion completed in 6.085455658s

• [SLOW TEST:12.769 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 10:18:00.164: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-4121
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap configmap-4121/configmap-test-e34ca38c-af89-4cea-97d2-109b6f6263f9
STEP: Creating a pod to test consume configMaps
Mar 25 10:18:00.307: INFO: Waiting up to 5m0s for pod "pod-configmaps-eed44d89-892e-42fe-9729-8493086ff59f" in namespace "configmap-4121" to be "success or failure"
Mar 25 10:18:00.309: INFO: Pod "pod-configmaps-eed44d89-892e-42fe-9729-8493086ff59f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.258032ms
Mar 25 10:18:02.313: INFO: Pod "pod-configmaps-eed44d89-892e-42fe-9729-8493086ff59f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0058899s
STEP: Saw pod success
Mar 25 10:18:02.313: INFO: Pod "pod-configmaps-eed44d89-892e-42fe-9729-8493086ff59f" satisfied condition "success or failure"
Mar 25 10:18:02.315: INFO: Trying to get logs from node ip-10-90-32-23.eu-west-2.compute.internal pod pod-configmaps-eed44d89-892e-42fe-9729-8493086ff59f container env-test: <nil>
STEP: delete the pod
Mar 25 10:18:02.330: INFO: Waiting for pod pod-configmaps-eed44d89-892e-42fe-9729-8493086ff59f to disappear
Mar 25 10:18:02.332: INFO: Pod pod-configmaps-eed44d89-892e-42fe-9729-8493086ff59f no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 10:18:02.332: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4121" for this suite.
Mar 25 10:18:08.343: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 10:18:08.410: INFO: namespace configmap-4121 deletion completed in 6.075854874s

• [SLOW TEST:8.246 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 10:18:08.411: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-4481
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating the pod
Mar 25 10:18:13.076: INFO: Successfully updated pod "labelsupdate3d8e42ac-a161-4396-bd17-5b239afaa8f5"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 10:18:15.090: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4481" for this suite.
Mar 25 10:18:37.101: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 10:18:37.168: INFO: namespace downward-api-4481 deletion completed in 22.075550487s

• [SLOW TEST:28.757 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] version v1
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 10:18:37.168: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-4400
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Mar 25 10:18:37.313: INFO: (0) /api/v1/nodes/ip-10-90-32-22.eu-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 4.481935ms)
Mar 25 10:18:37.316: INFO: (1) /api/v1/nodes/ip-10-90-32-22.eu-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 3.100063ms)
Mar 25 10:18:37.320: INFO: (2) /api/v1/nodes/ip-10-90-32-22.eu-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 3.029292ms)
Mar 25 10:18:37.322: INFO: (3) /api/v1/nodes/ip-10-90-32-22.eu-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 2.923078ms)
Mar 25 10:18:37.325: INFO: (4) /api/v1/nodes/ip-10-90-32-22.eu-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 2.943637ms)
Mar 25 10:18:37.328: INFO: (5) /api/v1/nodes/ip-10-90-32-22.eu-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 2.771938ms)
Mar 25 10:18:37.331: INFO: (6) /api/v1/nodes/ip-10-90-32-22.eu-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 2.81021ms)
Mar 25 10:18:37.334: INFO: (7) /api/v1/nodes/ip-10-90-32-22.eu-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 2.932129ms)
Mar 25 10:18:37.337: INFO: (8) /api/v1/nodes/ip-10-90-32-22.eu-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 2.9148ms)
Mar 25 10:18:37.340: INFO: (9) /api/v1/nodes/ip-10-90-32-22.eu-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 2.973532ms)
Mar 25 10:18:37.343: INFO: (10) /api/v1/nodes/ip-10-90-32-22.eu-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 2.827477ms)
Mar 25 10:18:37.346: INFO: (11) /api/v1/nodes/ip-10-90-32-22.eu-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 3.036447ms)
Mar 25 10:18:37.349: INFO: (12) /api/v1/nodes/ip-10-90-32-22.eu-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 2.900677ms)
Mar 25 10:18:37.352: INFO: (13) /api/v1/nodes/ip-10-90-32-22.eu-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 2.954485ms)
Mar 25 10:18:37.355: INFO: (14) /api/v1/nodes/ip-10-90-32-22.eu-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 2.996843ms)
Mar 25 10:18:37.358: INFO: (15) /api/v1/nodes/ip-10-90-32-22.eu-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 2.894543ms)
Mar 25 10:18:37.361: INFO: (16) /api/v1/nodes/ip-10-90-32-22.eu-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 3.027118ms)
Mar 25 10:18:37.364: INFO: (17) /api/v1/nodes/ip-10-90-32-22.eu-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 2.991167ms)
Mar 25 10:18:37.367: INFO: (18) /api/v1/nodes/ip-10-90-32-22.eu-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 2.869275ms)
Mar 25 10:18:37.370: INFO: (19) /api/v1/nodes/ip-10-90-32-22.eu-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 2.941179ms)
[AfterEach] version v1
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 10:18:37.370: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-4400" for this suite.
Mar 25 10:18:43.381: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 10:18:43.452: INFO: namespace proxy-4400 deletion completed in 6.079042035s

• [SLOW TEST:6.283 seconds]
[sig-network] Proxy
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:58
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 10:18:43.453: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-9842
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secret-namespace-3356
STEP: Creating secret with name secret-test-b9730756-c404-46c7-b11b-150126d80652
STEP: Creating a pod to test consume secrets
Mar 25 10:18:43.724: INFO: Waiting up to 5m0s for pod "pod-secrets-22811c7a-c27e-44cc-94f8-c92c1f035b53" in namespace "secrets-9842" to be "success or failure"
Mar 25 10:18:43.734: INFO: Pod "pod-secrets-22811c7a-c27e-44cc-94f8-c92c1f035b53": Phase="Pending", Reason="", readiness=false. Elapsed: 10.457669ms
Mar 25 10:18:45.737: INFO: Pod "pod-secrets-22811c7a-c27e-44cc-94f8-c92c1f035b53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013633194s
STEP: Saw pod success
Mar 25 10:18:45.737: INFO: Pod "pod-secrets-22811c7a-c27e-44cc-94f8-c92c1f035b53" satisfied condition "success or failure"
Mar 25 10:18:45.739: INFO: Trying to get logs from node ip-10-90-32-23.eu-west-2.compute.internal pod pod-secrets-22811c7a-c27e-44cc-94f8-c92c1f035b53 container secret-volume-test: <nil>
STEP: delete the pod
Mar 25 10:18:45.756: INFO: Waiting for pod pod-secrets-22811c7a-c27e-44cc-94f8-c92c1f035b53 to disappear
Mar 25 10:18:45.759: INFO: Pod pod-secrets-22811c7a-c27e-44cc-94f8-c92c1f035b53 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 10:18:45.759: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9842" for this suite.
Mar 25 10:18:51.770: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 10:18:51.839: INFO: namespace secrets-9842 deletion completed in 6.077437174s
STEP: Destroying namespace "secret-namespace-3356" for this suite.
Mar 25 10:18:57.847: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 10:18:57.915: INFO: namespace secret-namespace-3356 deletion completed in 6.076582992s

• [SLOW TEST:14.463 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-api-machinery] Aggregator 
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 10:18:57.916: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename aggregator
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in aggregator-2207
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:76
Mar 25 10:18:58.047: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
[It] Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Registering the sample API server.
Mar 25 10:18:58.626: INFO: deployment "sample-apiserver-deployment" doesn't have the required revision set
Mar 25 10:19:00.665: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720728338, loc:(*time.Location)(0x7ed0a00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720728338, loc:(*time.Location)(0x7ed0a00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720728338, loc:(*time.Location)(0x7ed0a00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720728338, loc:(*time.Location)(0x7ed0a00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 25 10:19:02.670: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720728338, loc:(*time.Location)(0x7ed0a00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720728338, loc:(*time.Location)(0x7ed0a00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720728338, loc:(*time.Location)(0x7ed0a00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720728338, loc:(*time.Location)(0x7ed0a00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 25 10:19:04.668: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720728338, loc:(*time.Location)(0x7ed0a00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720728338, loc:(*time.Location)(0x7ed0a00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720728338, loc:(*time.Location)(0x7ed0a00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720728338, loc:(*time.Location)(0x7ed0a00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 25 10:19:06.668: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720728338, loc:(*time.Location)(0x7ed0a00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720728338, loc:(*time.Location)(0x7ed0a00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720728338, loc:(*time.Location)(0x7ed0a00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720728338, loc:(*time.Location)(0x7ed0a00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 25 10:19:08.668: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720728338, loc:(*time.Location)(0x7ed0a00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720728338, loc:(*time.Location)(0x7ed0a00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720728338, loc:(*time.Location)(0x7ed0a00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720728338, loc:(*time.Location)(0x7ed0a00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 25 10:19:12.591: INFO: Waited 1.917823299s for the sample-apiserver to be ready to handle requests.
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:67
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 10:19:13.974: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "aggregator-2207" for this suite.
Mar 25 10:19:19.986: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 10:19:20.061: INFO: namespace aggregator-2207 deletion completed in 6.083781735s

• [SLOW TEST:22.145 seconds]
[sig-api-machinery] Aggregator
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 10:19:20.061: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-3759
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0644 on node default medium
Mar 25 10:19:20.200: INFO: Waiting up to 5m0s for pod "pod-f6a215cb-d727-4888-aae4-fc91fe3c90e4" in namespace "emptydir-3759" to be "success or failure"
Mar 25 10:19:20.205: INFO: Pod "pod-f6a215cb-d727-4888-aae4-fc91fe3c90e4": Phase="Pending", Reason="", readiness=false. Elapsed: 5.47369ms
Mar 25 10:19:22.208: INFO: Pod "pod-f6a215cb-d727-4888-aae4-fc91fe3c90e4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008549525s
Mar 25 10:19:24.212: INFO: Pod "pod-f6a215cb-d727-4888-aae4-fc91fe3c90e4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011765471s
STEP: Saw pod success
Mar 25 10:19:24.212: INFO: Pod "pod-f6a215cb-d727-4888-aae4-fc91fe3c90e4" satisfied condition "success or failure"
Mar 25 10:19:24.214: INFO: Trying to get logs from node ip-10-90-32-23.eu-west-2.compute.internal pod pod-f6a215cb-d727-4888-aae4-fc91fe3c90e4 container test-container: <nil>
STEP: delete the pod
Mar 25 10:19:24.230: INFO: Waiting for pod pod-f6a215cb-d727-4888-aae4-fc91fe3c90e4 to disappear
Mar 25 10:19:24.231: INFO: Pod pod-f6a215cb-d727-4888-aae4-fc91fe3c90e4 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 10:19:24.232: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3759" for this suite.
Mar 25 10:19:30.246: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 10:19:30.324: INFO: namespace emptydir-3759 deletion completed in 6.089927127s

• [SLOW TEST:10.263 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 10:19:30.325: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1772
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-map-5a6e4591-fbcc-4065-a538-c7ae8b775ad1
STEP: Creating a pod to test consume secrets
Mar 25 10:19:30.467: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-e5e30dd4-5f1a-4d7c-bae2-c2f011b2f853" in namespace "projected-1772" to be "success or failure"
Mar 25 10:19:30.471: INFO: Pod "pod-projected-secrets-e5e30dd4-5f1a-4d7c-bae2-c2f011b2f853": Phase="Pending", Reason="", readiness=false. Elapsed: 3.543996ms
Mar 25 10:19:32.482: INFO: Pod "pod-projected-secrets-e5e30dd4-5f1a-4d7c-bae2-c2f011b2f853": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01428963s
STEP: Saw pod success
Mar 25 10:19:32.482: INFO: Pod "pod-projected-secrets-e5e30dd4-5f1a-4d7c-bae2-c2f011b2f853" satisfied condition "success or failure"
Mar 25 10:19:32.484: INFO: Trying to get logs from node ip-10-90-32-23.eu-west-2.compute.internal pod pod-projected-secrets-e5e30dd4-5f1a-4d7c-bae2-c2f011b2f853 container projected-secret-volume-test: <nil>
STEP: delete the pod
Mar 25 10:19:32.498: INFO: Waiting for pod pod-projected-secrets-e5e30dd4-5f1a-4d7c-bae2-c2f011b2f853 to disappear
Mar 25 10:19:32.500: INFO: Pod pod-projected-secrets-e5e30dd4-5f1a-4d7c-bae2-c2f011b2f853 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 10:19:32.500: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1772" for this suite.
Mar 25 10:19:38.510: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 10:19:38.578: INFO: namespace projected-1772 deletion completed in 6.075681076s

• [SLOW TEST:8.254 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 10:19:38.579: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-996
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:63
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Mar 25 10:19:42.759: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar 25 10:19:42.761: INFO: Pod pod-with-poststart-exec-hook still exists
Mar 25 10:19:44.761: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar 25 10:19:44.764: INFO: Pod pod-with-poststart-exec-hook still exists
Mar 25 10:19:46.761: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar 25 10:19:46.764: INFO: Pod pod-with-poststart-exec-hook still exists
Mar 25 10:19:48.761: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar 25 10:19:48.764: INFO: Pod pod-with-poststart-exec-hook still exists
Mar 25 10:19:50.761: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar 25 10:19:50.764: INFO: Pod pod-with-poststart-exec-hook still exists
Mar 25 10:19:52.761: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar 25 10:19:52.764: INFO: Pod pod-with-poststart-exec-hook still exists
Mar 25 10:19:54.761: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar 25 10:19:54.764: INFO: Pod pod-with-poststart-exec-hook still exists
Mar 25 10:19:56.761: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar 25 10:19:56.764: INFO: Pod pod-with-poststart-exec-hook still exists
Mar 25 10:19:58.761: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar 25 10:19:58.764: INFO: Pod pod-with-poststart-exec-hook still exists
Mar 25 10:20:00.761: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar 25 10:20:00.766: INFO: Pod pod-with-poststart-exec-hook still exists
Mar 25 10:20:02.761: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar 25 10:20:02.765: INFO: Pod pod-with-poststart-exec-hook still exists
Mar 25 10:20:04.761: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar 25 10:20:04.764: INFO: Pod pod-with-poststart-exec-hook still exists
Mar 25 10:20:06.761: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar 25 10:20:06.764: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 10:20:06.764: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-996" for this suite.
Mar 25 10:20:28.777: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 10:20:28.842: INFO: namespace container-lifecycle-hook-996 deletion completed in 22.073731758s

• [SLOW TEST:50.264 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when create a pod with lifecycle hook
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 10:20:28.843: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-8750
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-8750
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace statefulset-8750
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-8750
Mar 25 10:20:28.994: INFO: Found 0 stateful pods, waiting for 1
Mar 25 10:20:38.997: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Mar 25 10:20:38.999: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 exec --namespace=statefulset-8750 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar 25 10:20:39.313: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Mar 25 10:20:39.313: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar 25 10:20:39.313: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Mar 25 10:20:39.316: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Mar 25 10:20:49.319: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Mar 25 10:20:49.319: INFO: Waiting for statefulset status.replicas updated to 0
Mar 25 10:20:49.333: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999998207s
Mar 25 10:20:50.336: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.996149298s
Mar 25 10:20:51.339: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.99302053s
Mar 25 10:20:52.342: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.989784586s
Mar 25 10:20:53.345: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.986581005s
Mar 25 10:20:54.348: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.983349026s
Mar 25 10:20:55.351: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.980337358s
Mar 25 10:20:56.355: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.977381125s
Mar 25 10:20:57.358: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.974141361s
Mar 25 10:20:58.361: INFO: Verifying statefulset ss doesn't scale past 1 for another 970.970718ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-8750
Mar 25 10:20:59.364: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 exec --namespace=statefulset-8750 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 25 10:20:59.534: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Mar 25 10:20:59.534: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Mar 25 10:20:59.534: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Mar 25 10:20:59.537: INFO: Found 1 stateful pods, waiting for 3
Mar 25 10:21:09.540: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Mar 25 10:21:09.540: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Mar 25 10:21:09.540: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Mar 25 10:21:09.544: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 exec --namespace=statefulset-8750 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar 25 10:21:09.696: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Mar 25 10:21:09.696: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar 25 10:21:09.696: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Mar 25 10:21:09.696: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 exec --namespace=statefulset-8750 ss-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar 25 10:21:09.857: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Mar 25 10:21:09.857: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar 25 10:21:09.857: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Mar 25 10:21:09.857: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 exec --namespace=statefulset-8750 ss-2 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar 25 10:21:10.037: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Mar 25 10:21:10.037: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar 25 10:21:10.037: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Mar 25 10:21:10.037: INFO: Waiting for statefulset status.replicas updated to 0
Mar 25 10:21:10.040: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
Mar 25 10:21:20.045: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Mar 25 10:21:20.045: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Mar 25 10:21:20.045: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Mar 25 10:21:20.063: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999982031s
Mar 25 10:21:21.066: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.992529284s
Mar 25 10:21:22.071: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.989025444s
Mar 25 10:21:23.074: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.98470987s
Mar 25 10:21:24.077: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.981523728s
Mar 25 10:21:25.082: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.978410173s
Mar 25 10:21:26.085: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.973047752s
Mar 25 10:21:27.089: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.96984741s
Mar 25 10:21:28.092: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.966368317s
Mar 25 10:21:29.096: INFO: Verifying statefulset ss doesn't scale past 3 for another 963.134069ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-8750
Mar 25 10:21:30.099: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 exec --namespace=statefulset-8750 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 25 10:21:30.274: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Mar 25 10:21:30.274: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Mar 25 10:21:30.274: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Mar 25 10:21:30.274: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 exec --namespace=statefulset-8750 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 25 10:21:30.438: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Mar 25 10:21:30.438: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Mar 25 10:21:30.438: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Mar 25 10:21:30.438: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-563117487 exec --namespace=statefulset-8750 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 25 10:21:30.631: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Mar 25 10:21:30.631: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Mar 25 10:21:30.631: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Mar 25 10:21:30.631: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Mar 25 10:22:00.643: INFO: Deleting all statefulset in ns statefulset-8750
Mar 25 10:22:00.646: INFO: Scaling statefulset ss to 0
Mar 25 10:22:00.653: INFO: Waiting for statefulset status.replicas updated to 0
Mar 25 10:22:00.656: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 10:22:00.672: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-8750" for this suite.
Mar 25 10:22:06.691: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 10:22:06.766: INFO: namespace statefulset-8750 deletion completed in 6.090019247s

• [SLOW TEST:97.923 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 10:22:06.766: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-9986
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 pods, got 1 pods
STEP: expected 0 rs, got 1 rs
STEP: Gathering metrics
Mar 25 10:22:07.452: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W0325 10:22:07.452363      16 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 10:22:07.452: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-9986" for this suite.
Mar 25 10:22:13.463: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 10:22:13.530: INFO: namespace gc-9986 deletion completed in 6.075555944s

• [SLOW TEST:6.764 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 10:22:13.531: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-3012
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test override arguments
Mar 25 10:22:13.669: INFO: Waiting up to 5m0s for pod "client-containers-fcbf0d35-abf0-48af-a208-dc5378198955" in namespace "containers-3012" to be "success or failure"
Mar 25 10:22:13.672: INFO: Pod "client-containers-fcbf0d35-abf0-48af-a208-dc5378198955": Phase="Pending", Reason="", readiness=false. Elapsed: 3.506002ms
Mar 25 10:22:15.675: INFO: Pod "client-containers-fcbf0d35-abf0-48af-a208-dc5378198955": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006349355s
Mar 25 10:22:17.678: INFO: Pod "client-containers-fcbf0d35-abf0-48af-a208-dc5378198955": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009303829s
STEP: Saw pod success
Mar 25 10:22:17.678: INFO: Pod "client-containers-fcbf0d35-abf0-48af-a208-dc5378198955" satisfied condition "success or failure"
Mar 25 10:22:17.680: INFO: Trying to get logs from node ip-10-90-32-23.eu-west-2.compute.internal pod client-containers-fcbf0d35-abf0-48af-a208-dc5378198955 container test-container: <nil>
STEP: delete the pod
Mar 25 10:22:17.694: INFO: Waiting for pod client-containers-fcbf0d35-abf0-48af-a208-dc5378198955 to disappear
Mar 25 10:22:17.696: INFO: Pod client-containers-fcbf0d35-abf0-48af-a208-dc5378198955 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 10:22:17.696: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-3012" for this suite.
Mar 25 10:22:23.707: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 10:22:23.774: INFO: namespace containers-3012 deletion completed in 6.075124117s

• [SLOW TEST:10.244 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 10:22:23.775: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-9838
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-9838
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a new StatefulSet
Mar 25 10:22:23.923: INFO: Found 0 stateful pods, waiting for 3
Mar 25 10:22:33.926: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Mar 25 10:22:33.926: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Mar 25 10:22:33.926: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Mar 25 10:22:33.951: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Mar 25 10:22:43.987: INFO: Updating stateful set ss2
Mar 25 10:22:44.010: INFO: Waiting for Pod statefulset-9838/ss2-2 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
STEP: Restoring Pods to the correct revision when they are deleted
Mar 25 10:22:54.062: INFO: Found 1 stateful pods, waiting for 3
Mar 25 10:23:04.075: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Mar 25 10:23:04.076: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Mar 25 10:23:04.076: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Mar 25 10:23:04.099: INFO: Updating stateful set ss2
Mar 25 10:23:04.123: INFO: Waiting for Pod statefulset-9838/ss2-1 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Mar 25 10:23:14.184: INFO: Updating stateful set ss2
Mar 25 10:23:14.216: INFO: Waiting for StatefulSet statefulset-9838/ss2 to complete update
Mar 25 10:23:14.216: INFO: Waiting for Pod statefulset-9838/ss2-0 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Mar 25 10:23:24.223: INFO: Waiting for StatefulSet statefulset-9838/ss2 to complete update
Mar 25 10:23:24.223: INFO: Waiting for Pod statefulset-9838/ss2-0 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Mar 25 10:23:34.225: INFO: Deleting all statefulset in ns statefulset-9838
Mar 25 10:23:34.230: INFO: Scaling statefulset ss2 to 0
Mar 25 10:24:04.278: INFO: Waiting for statefulset status.replicas updated to 0
Mar 25 10:24:04.280: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 10:24:04.291: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-9838" for this suite.
Mar 25 10:24:10.319: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 10:24:10.419: INFO: namespace statefulset-9838 deletion completed in 6.124200609s

• [SLOW TEST:106.644 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 10:24:10.420: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3340
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Mar 25 10:24:10.569: INFO: Waiting up to 5m0s for pod "downwardapi-volume-355305cc-0141-45cd-825f-508ecbb14092" in namespace "projected-3340" to be "success or failure"
Mar 25 10:24:10.574: INFO: Pod "downwardapi-volume-355305cc-0141-45cd-825f-508ecbb14092": Phase="Pending", Reason="", readiness=false. Elapsed: 5.604695ms
Mar 25 10:24:12.579: INFO: Pod "downwardapi-volume-355305cc-0141-45cd-825f-508ecbb14092": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009762996s
STEP: Saw pod success
Mar 25 10:24:12.579: INFO: Pod "downwardapi-volume-355305cc-0141-45cd-825f-508ecbb14092" satisfied condition "success or failure"
Mar 25 10:24:12.581: INFO: Trying to get logs from node ip-10-90-32-23.eu-west-2.compute.internal pod downwardapi-volume-355305cc-0141-45cd-825f-508ecbb14092 container client-container: <nil>
STEP: delete the pod
Mar 25 10:24:12.598: INFO: Waiting for pod downwardapi-volume-355305cc-0141-45cd-825f-508ecbb14092 to disappear
Mar 25 10:24:12.599: INFO: Pod downwardapi-volume-355305cc-0141-45cd-825f-508ecbb14092 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 10:24:12.599: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3340" for this suite.
Mar 25 10:24:18.610: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 10:24:18.681: INFO: namespace projected-3340 deletion completed in 6.078969962s

• [SLOW TEST:8.262 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 10:24:18.682: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-6909
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-downwardapi-6slr
STEP: Creating a pod to test atomic-volume-subpath
Mar 25 10:24:18.827: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-6slr" in namespace "subpath-6909" to be "success or failure"
Mar 25 10:24:18.831: INFO: Pod "pod-subpath-test-downwardapi-6slr": Phase="Pending", Reason="", readiness=false. Elapsed: 3.393107ms
Mar 25 10:24:20.837: INFO: Pod "pod-subpath-test-downwardapi-6slr": Phase="Running", Reason="", readiness=true. Elapsed: 2.00997746s
Mar 25 10:24:22.840: INFO: Pod "pod-subpath-test-downwardapi-6slr": Phase="Running", Reason="", readiness=true. Elapsed: 4.012829908s
Mar 25 10:24:24.844: INFO: Pod "pod-subpath-test-downwardapi-6slr": Phase="Running", Reason="", readiness=true. Elapsed: 6.016225387s
Mar 25 10:24:26.847: INFO: Pod "pod-subpath-test-downwardapi-6slr": Phase="Running", Reason="", readiness=true. Elapsed: 8.019106771s
Mar 25 10:24:28.850: INFO: Pod "pod-subpath-test-downwardapi-6slr": Phase="Running", Reason="", readiness=true. Elapsed: 10.022174949s
Mar 25 10:24:30.852: INFO: Pod "pod-subpath-test-downwardapi-6slr": Phase="Running", Reason="", readiness=true. Elapsed: 12.024868146s
Mar 25 10:24:32.855: INFO: Pod "pod-subpath-test-downwardapi-6slr": Phase="Running", Reason="", readiness=true. Elapsed: 14.027535411s
Mar 25 10:24:34.858: INFO: Pod "pod-subpath-test-downwardapi-6slr": Phase="Running", Reason="", readiness=true. Elapsed: 16.03057583s
Mar 25 10:24:36.861: INFO: Pod "pod-subpath-test-downwardapi-6slr": Phase="Running", Reason="", readiness=true. Elapsed: 18.033375487s
Mar 25 10:24:38.863: INFO: Pod "pod-subpath-test-downwardapi-6slr": Phase="Running", Reason="", readiness=true. Elapsed: 20.036022852s
Mar 25 10:24:40.866: INFO: Pod "pod-subpath-test-downwardapi-6slr": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.038884914s
STEP: Saw pod success
Mar 25 10:24:40.866: INFO: Pod "pod-subpath-test-downwardapi-6slr" satisfied condition "success or failure"
Mar 25 10:24:40.868: INFO: Trying to get logs from node ip-10-90-32-23.eu-west-2.compute.internal pod pod-subpath-test-downwardapi-6slr container test-container-subpath-downwardapi-6slr: <nil>
STEP: delete the pod
Mar 25 10:24:40.885: INFO: Waiting for pod pod-subpath-test-downwardapi-6slr to disappear
Mar 25 10:24:40.887: INFO: Pod pod-subpath-test-downwardapi-6slr no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-6slr
Mar 25 10:24:40.887: INFO: Deleting pod "pod-subpath-test-downwardapi-6slr" in namespace "subpath-6909"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 10:24:40.888: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-6909" for this suite.
Mar 25 10:24:46.899: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 10:24:46.977: INFO: namespace subpath-6909 deletion completed in 6.085566416s

• [SLOW TEST:28.295 seconds]
[sig-storage] Subpath
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with downward pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 10:24:46.977: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-7235
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0777 on tmpfs
Mar 25 10:24:47.116: INFO: Waiting up to 5m0s for pod "pod-2b293063-583c-4f24-9b5e-af16114ecd49" in namespace "emptydir-7235" to be "success or failure"
Mar 25 10:24:47.120: INFO: Pod "pod-2b293063-583c-4f24-9b5e-af16114ecd49": Phase="Pending", Reason="", readiness=false. Elapsed: 3.978395ms
Mar 25 10:24:49.123: INFO: Pod "pod-2b293063-583c-4f24-9b5e-af16114ecd49": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006923256s
Mar 25 10:24:51.126: INFO: Pod "pod-2b293063-583c-4f24-9b5e-af16114ecd49": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009874779s
STEP: Saw pod success
Mar 25 10:24:51.126: INFO: Pod "pod-2b293063-583c-4f24-9b5e-af16114ecd49" satisfied condition "success or failure"
Mar 25 10:24:51.128: INFO: Trying to get logs from node ip-10-90-32-23.eu-west-2.compute.internal pod pod-2b293063-583c-4f24-9b5e-af16114ecd49 container test-container: <nil>
STEP: delete the pod
Mar 25 10:24:51.143: INFO: Waiting for pod pod-2b293063-583c-4f24-9b5e-af16114ecd49 to disappear
Mar 25 10:24:51.145: INFO: Pod pod-2b293063-583c-4f24-9b5e-af16114ecd49 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 10:24:51.145: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7235" for this suite.
Mar 25 10:24:57.156: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 10:24:57.221: INFO: namespace emptydir-7235 deletion completed in 6.072820389s

• [SLOW TEST:10.244 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar 25 10:24:57.221: INFO: >>> kubeConfig: /tmp/kubeconfig-563117487
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-8726
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Mar 25 10:24:57.358: INFO: Waiting up to 5m0s for pod "downward-api-849cf959-a21f-4b15-a80a-f111fa2d5ce0" in namespace "downward-api-8726" to be "success or failure"
Mar 25 10:24:57.362: INFO: Pod "downward-api-849cf959-a21f-4b15-a80a-f111fa2d5ce0": Phase="Pending", Reason="", readiness=false. Elapsed: 3.918917ms
Mar 25 10:24:59.370: INFO: Pod "downward-api-849cf959-a21f-4b15-a80a-f111fa2d5ce0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011732506s
Mar 25 10:25:01.381: INFO: Pod "downward-api-849cf959-a21f-4b15-a80a-f111fa2d5ce0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023163898s
STEP: Saw pod success
Mar 25 10:25:01.381: INFO: Pod "downward-api-849cf959-a21f-4b15-a80a-f111fa2d5ce0" satisfied condition "success or failure"
Mar 25 10:25:01.392: INFO: Trying to get logs from node ip-10-90-32-23.eu-west-2.compute.internal pod downward-api-849cf959-a21f-4b15-a80a-f111fa2d5ce0 container dapi-container: <nil>
STEP: delete the pod
Mar 25 10:25:01.438: INFO: Waiting for pod downward-api-849cf959-a21f-4b15-a80a-f111fa2d5ce0 to disappear
Mar 25 10:25:01.451: INFO: Pod downward-api-849cf959-a21f-4b15-a80a-f111fa2d5ce0 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar 25 10:25:01.451: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8726" for this suite.
Mar 25 10:25:07.497: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 10:25:07.573: INFO: namespace downward-api-8726 deletion completed in 6.107504314s

• [SLOW TEST:10.352 seconds]
[sig-node] Downward API
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSMar 25 10:25:07.573: INFO: Running AfterSuite actions on all nodes
Mar 25 10:25:07.573: INFO: Running AfterSuite actions on node 1
Mar 25 10:25:07.573: INFO: Skipping dumping logs from cluster

Ran 215 of 4412 Specs in 5554.819 seconds
SUCCESS! -- 215 Passed | 0 Failed | 0 Pending | 4197 Skipped
PASS

Ginkgo ran 1 suite in 1h32m36.69058645s
Test Suite Passed
