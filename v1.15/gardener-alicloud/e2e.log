Conformance test: not doing test setup.
I1203 14:44:23.915783    5085 e2e.go:243] Starting e2e run "db7a8e30-0527-4959-a38a-c797d2f95ed8" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1575384262 - Will randomize all specs
Will run 215 of 4413 specs

Dec  3 14:45:00.653: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Deleting namespaces
STEP: Waiting for namespaces to vanish
I1203 14:45:00.689983    5085 e2e.go:98] Waiting for deletion of the following namespaces: []
Dec  3 14:45:02.695: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Dec  3 14:45:02.711: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Dec  3 14:45:02.763: INFO: 22 / 22 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Dec  3 14:45:02.763: INFO: expected 12 pod replicas in namespace 'kube-system', 12 are Running and Ready.
Dec  3 14:45:02.763: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Dec  3 14:45:02.773: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'calico-node' (0 seconds elapsed)
Dec  3 14:45:02.773: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'csi-disk-plugin-alicloud' (0 seconds elapsed)
Dec  3 14:45:02.773: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'kube-proxy' (0 seconds elapsed)
Dec  3 14:45:02.773: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'node-exporter' (0 seconds elapsed)
Dec  3 14:45:02.773: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'node-problem-detector' (0 seconds elapsed)
Dec  3 14:45:02.773: INFO: e2e test version: v1.15.6
Dec  3 14:45:02.777: INFO: kube-apiserver version: v1.15.6
SSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 14:45:02.777: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir-wrapper
Dec  3 14:45:02.815: INFO: Found PodSecurityPolicies; assuming PodSecurityPolicy is enabled.
Dec  3 14:45:02.834: INFO: Found ClusterRoles; assuming RBAC is enabled.
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-wrapper-4985
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 14:45:07.006: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-4985" for this suite.
Dec  3 14:45:13.028: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:45:13.191: INFO: namespace emptydir-wrapper-4985 deletion completed in 6.176778457s
â€¢SSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 14:45:13.191: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-5223
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Dec  3 14:45:13.337: INFO: Creating deployment "nginx-deployment"
Dec  3 14:45:13.343: INFO: Waiting for observed generation 1
Dec  3 14:45:15.352: INFO: Waiting for all required pods to come up
Dec  3 14:45:15.361: INFO: Pod name nginx: Found 10 pods out of 10
STEP: ensuring each pod is running
Dec  3 14:45:29.371: INFO: Waiting for deployment "nginx-deployment" to complete
Dec  3 14:45:29.381: INFO: Updating deployment "nginx-deployment" with a non-existent image
Dec  3 14:45:29.390: INFO: Updating deployment nginx-deployment
Dec  3 14:45:29.390: INFO: Waiting for observed generation 2
Dec  3 14:45:31.399: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Dec  3 14:45:31.404: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Dec  3 14:45:31.408: INFO: Waiting for the first rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Dec  3 14:45:31.421: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Dec  3 14:45:31.468: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Dec  3 14:45:31.473: INFO: Waiting for the second rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Dec  3 14:45:31.482: INFO: Verifying that deployment "nginx-deployment" has minimum required number of available replicas
Dec  3 14:45:31.482: INFO: Scaling up the deployment "nginx-deployment" from 10 to 30
Dec  3 14:45:31.491: INFO: Updating deployment nginx-deployment
Dec  3 14:45:31.491: INFO: Waiting for the replicasets of deployment "nginx-deployment" to have desired number of replicas
Dec  3 14:45:31.499: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Dec  3 14:45:33.509: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
Dec  3 14:45:33.518: INFO: Deployment "nginx-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment,GenerateName:,Namespace:deployment-5223,SelfLink:/apis/apps/v1/namespaces/deployment-5223/deployments/nginx-deployment,UID:3dfa2dad-335c-4894-9878-7016f1886eaf,ResourceVersion:5207,Generation:3,CreationTimestamp:2019-12-03 14:45:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*30,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:33,UpdatedReplicas:13,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[{Available False 2019-12-03 14:45:31 +0000 UTC 2019-12-03 14:45:31 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-12-03 14:45:31 +0000 UTC 2019-12-03 14:45:13 +0000 UTC ReplicaSetUpdated ReplicaSet "nginx-deployment-55fb7cb77f" is progressing.}],ReadyReplicas:8,CollisionCount:nil,},}

Dec  3 14:45:33.523: INFO: New ReplicaSet "nginx-deployment-55fb7cb77f" of Deployment "nginx-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f,GenerateName:,Namespace:deployment-5223,SelfLink:/apis/apps/v1/namespaces/deployment-5223/replicasets/nginx-deployment-55fb7cb77f,UID:1cdfae11-4c87-4746-bfe2-87a39e926f7d,ResourceVersion:5201,Generation:3,CreationTimestamp:2019-12-03 14:45:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 3dfa2dad-335c-4894-9878-7016f1886eaf 0xc0032997c7 0xc0032997c8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*13,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:13,FullyLabeledReplicas:13,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Dec  3 14:45:33.523: INFO: All old ReplicaSets of Deployment "nginx-deployment":
Dec  3 14:45:33.523: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498,GenerateName:,Namespace:deployment-5223,SelfLink:/apis/apps/v1/namespaces/deployment-5223/replicasets/nginx-deployment-7b8c6f4498,UID:dc1ec4f9-3b4d-4aff-9758-4a6da9501c01,ResourceVersion:5206,Generation:3,CreationTimestamp:2019-12-03 14:45:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 3dfa2dad-335c-4894-9878-7016f1886eaf 0xc003299897 0xc003299898}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*20,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:20,FullyLabeledReplicas:20,ObservedGeneration:3,ReadyReplicas:8,AvailableReplicas:8,Conditions:[],},}
Dec  3 14:45:33.536: INFO: Pod "nginx-deployment-55fb7cb77f-2brwg" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-2brwg,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-5223,SelfLink:/api/v1/namespaces/deployment-5223/pods/nginx-deployment-55fb7cb77f-2brwg,UID:cd9daee6-8259-4e3a-94dd-0c366adedfe6,ResourceVersion:5229,Generation:0,CreationTimestamp:2019-12-03 14:45:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.64.0.20/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 1cdfae11-4c87-4746-bfe2-87a39e926f7d 0xc002a54060 0xc002a54061}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-rbb4k {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-rbb4k,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-rbb4k true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw8afzp8040eoqk0qbhwz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002a540d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002a540f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:45:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:45:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:45:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:45:31 +0000 UTC  }],Message:,Reason:,HostIP:10.250.31.245,PodIP:,StartTime:2019-12-03 14:45:31 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  3 14:45:33.536: INFO: Pod "nginx-deployment-55fb7cb77f-4sdjr" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-4sdjr,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-5223,SelfLink:/api/v1/namespaces/deployment-5223/pods/nginx-deployment-55fb7cb77f-4sdjr,UID:b0840bfc-8e93-4011-9794-1be3a1971190,ResourceVersion:5232,Generation:0,CreationTimestamp:2019-12-03 14:45:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.64.0.21/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 1cdfae11-4c87-4746-bfe2-87a39e926f7d 0xc002a541d0 0xc002a541d1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-rbb4k {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-rbb4k,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-rbb4k true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw8afzp8040eoqk0qbhwz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002a54240} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002a54260}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:45:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:45:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:45:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:45:31 +0000 UTC  }],Message:,Reason:,HostIP:10.250.31.245,PodIP:,StartTime:2019-12-03 14:45:31 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  3 14:45:33.536: INFO: Pod "nginx-deployment-55fb7cb77f-78bvd" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-78bvd,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-5223,SelfLink:/api/v1/namespaces/deployment-5223/pods/nginx-deployment-55fb7cb77f-78bvd,UID:26ef5113-81d9-493b-acb6-5095f83d4108,ResourceVersion:5218,Generation:0,CreationTimestamp:2019-12-03 14:45:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 1cdfae11-4c87-4746-bfe2-87a39e926f7d 0xc002a54330 0xc002a54331}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-rbb4k {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-rbb4k,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-rbb4k true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw8afzp8040eoqk0qbhxz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002a543a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002a543c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:45:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:45:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:45:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:45:31 +0000 UTC  }],Message:,Reason:,HostIP:10.250.31.244,PodIP:,StartTime:2019-12-03 14:45:31 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  3 14:45:33.536: INFO: Pod "nginx-deployment-55fb7cb77f-7jmwc" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-7jmwc,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-5223,SelfLink:/api/v1/namespaces/deployment-5223/pods/nginx-deployment-55fb7cb77f-7jmwc,UID:b83dd653-9593-45ba-8aa8-3aecc32eea05,ResourceVersion:5219,Generation:0,CreationTimestamp:2019-12-03 14:45:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 1cdfae11-4c87-4746-bfe2-87a39e926f7d 0xc002a54490 0xc002a54491}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-rbb4k {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-rbb4k,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-rbb4k true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw8afzp8040eoqk0qbhwz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002a54500} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002a54520}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:45:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:45:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:45:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:45:31 +0000 UTC  }],Message:,Reason:,HostIP:10.250.31.245,PodIP:,StartTime:2019-12-03 14:45:31 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  3 14:45:33.537: INFO: Pod "nginx-deployment-55fb7cb77f-7xdst" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-7xdst,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-5223,SelfLink:/api/v1/namespaces/deployment-5223/pods/nginx-deployment-55fb7cb77f-7xdst,UID:cdf90e64-2080-407e-aad6-f1b89cdd58ff,ResourceVersion:5148,Generation:0,CreationTimestamp:2019-12-03 14:45:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.64.1.13/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 1cdfae11-4c87-4746-bfe2-87a39e926f7d 0xc002a54600 0xc002a54601}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-rbb4k {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-rbb4k,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-rbb4k true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw8afzp8040eoqk0qbhxz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002a54670} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002a54690}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:45:29 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:45:29 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:45:29 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:45:29 +0000 UTC  }],Message:,Reason:,HostIP:10.250.31.244,PodIP:,StartTime:2019-12-03 14:45:29 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  3 14:45:33.537: INFO: Pod "nginx-deployment-55fb7cb77f-94fxz" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-94fxz,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-5223,SelfLink:/api/v1/namespaces/deployment-5223/pods/nginx-deployment-55fb7cb77f-94fxz,UID:2955836c-038e-4032-8d4a-35bbc753d1fe,ResourceVersion:5147,Generation:0,CreationTimestamp:2019-12-03 14:45:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.64.1.12/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 1cdfae11-4c87-4746-bfe2-87a39e926f7d 0xc002a54770 0xc002a54771}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-rbb4k {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-rbb4k,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-rbb4k true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw8afzp8040eoqk0qbhxz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002a547e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002a54800}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:45:29 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:45:29 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:45:29 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:45:29 +0000 UTC  }],Message:,Reason:,HostIP:10.250.31.244,PodIP:,StartTime:2019-12-03 14:45:29 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  3 14:45:33.537: INFO: Pod "nginx-deployment-55fb7cb77f-96h27" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-96h27,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-5223,SelfLink:/api/v1/namespaces/deployment-5223/pods/nginx-deployment-55fb7cb77f-96h27,UID:7176bb56-54cf-4e52-8ba0-d9db0307b832,ResourceVersion:5215,Generation:0,CreationTimestamp:2019-12-03 14:45:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 1cdfae11-4c87-4746-bfe2-87a39e926f7d 0xc002a548d0 0xc002a548d1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-rbb4k {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-rbb4k,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-rbb4k true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw8afzp8040eoqk0qbhxz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002a54940} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002a54960}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:45:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:45:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:45:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:45:31 +0000 UTC  }],Message:,Reason:,HostIP:10.250.31.244,PodIP:,StartTime:2019-12-03 14:45:31 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  3 14:45:33.537: INFO: Pod "nginx-deployment-55fb7cb77f-9vxt8" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-9vxt8,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-5223,SelfLink:/api/v1/namespaces/deployment-5223/pods/nginx-deployment-55fb7cb77f-9vxt8,UID:aec39930-db77-4ce2-9f14-c64651f9b35a,ResourceVersion:5212,Generation:0,CreationTimestamp:2019-12-03 14:45:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 1cdfae11-4c87-4746-bfe2-87a39e926f7d 0xc002a54a30 0xc002a54a31}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-rbb4k {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-rbb4k,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-rbb4k true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw8afzp8040eoqk0qbhwz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002a54aa0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002a54ac0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:45:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:45:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:45:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:45:31 +0000 UTC  }],Message:,Reason:,HostIP:10.250.31.245,PodIP:,StartTime:2019-12-03 14:45:31 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  3 14:45:33.537: INFO: Pod "nginx-deployment-55fb7cb77f-rmhff" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-rmhff,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-5223,SelfLink:/api/v1/namespaces/deployment-5223/pods/nginx-deployment-55fb7cb77f-rmhff,UID:03685143-18bf-4313-ad13-61ed93353189,ResourceVersion:5221,Generation:0,CreationTimestamp:2019-12-03 14:45:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 1cdfae11-4c87-4746-bfe2-87a39e926f7d 0xc002a54b90 0xc002a54b91}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-rbb4k {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-rbb4k,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-rbb4k true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw8afzp8040eoqk0qbhxz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002a54c00} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002a54c20}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:45:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:45:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:45:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:45:31 +0000 UTC  }],Message:,Reason:,HostIP:10.250.31.244,PodIP:,StartTime:2019-12-03 14:45:31 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  3 14:45:33.537: INFO: Pod "nginx-deployment-55fb7cb77f-rvfqs" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-rvfqs,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-5223,SelfLink:/api/v1/namespaces/deployment-5223/pods/nginx-deployment-55fb7cb77f-rvfqs,UID:d5c238e9-33e7-4019-aefd-769f07389494,ResourceVersion:5149,Generation:0,CreationTimestamp:2019-12-03 14:45:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.64.1.14/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 1cdfae11-4c87-4746-bfe2-87a39e926f7d 0xc002a54d00 0xc002a54d01}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-rbb4k {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-rbb4k,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-rbb4k true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw8afzp8040eoqk0qbhxz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002a54d70} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002a54d90}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:45:29 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:45:29 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:45:29 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:45:29 +0000 UTC  }],Message:,Reason:,HostIP:10.250.31.244,PodIP:,StartTime:2019-12-03 14:45:29 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  3 14:45:33.538: INFO: Pod "nginx-deployment-55fb7cb77f-vbjgh" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-vbjgh,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-5223,SelfLink:/api/v1/namespaces/deployment-5223/pods/nginx-deployment-55fb7cb77f-vbjgh,UID:d3ba4cfc-3227-4440-89c4-8dee7c6a118a,ResourceVersion:5213,Generation:0,CreationTimestamp:2019-12-03 14:45:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 1cdfae11-4c87-4746-bfe2-87a39e926f7d 0xc002a54e60 0xc002a54e61}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-rbb4k {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-rbb4k,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-rbb4k true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw8afzp8040eoqk0qbhxz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002a54ed0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002a54ef0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:45:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:45:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:45:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:45:31 +0000 UTC  }],Message:,Reason:,HostIP:10.250.31.244,PodIP:,StartTime:2019-12-03 14:45:31 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  3 14:45:33.538: INFO: Pod "nginx-deployment-55fb7cb77f-vmxqf" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-vmxqf,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-5223,SelfLink:/api/v1/namespaces/deployment-5223/pods/nginx-deployment-55fb7cb77f-vmxqf,UID:451ae5b7-e3f4-44d7-ab33-7e2641cdd78d,ResourceVersion:5145,Generation:0,CreationTimestamp:2019-12-03 14:45:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.64.0.19/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 1cdfae11-4c87-4746-bfe2-87a39e926f7d 0xc002a54fd0 0xc002a54fd1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-rbb4k {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-rbb4k,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-rbb4k true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw8afzp8040eoqk0qbhwz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002a55040} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002a55060}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:45:29 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:45:29 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:45:29 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:45:29 +0000 UTC  }],Message:,Reason:,HostIP:10.250.31.245,PodIP:,StartTime:2019-12-03 14:45:29 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  3 14:45:33.538: INFO: Pod "nginx-deployment-55fb7cb77f-wfjkn" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-wfjkn,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-5223,SelfLink:/api/v1/namespaces/deployment-5223/pods/nginx-deployment-55fb7cb77f-wfjkn,UID:1f4d870a-9032-4bec-ba42-0917cc4dcf44,ResourceVersion:5144,Generation:0,CreationTimestamp:2019-12-03 14:45:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.64.0.18/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 1cdfae11-4c87-4746-bfe2-87a39e926f7d 0xc002a55140 0xc002a55141}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-rbb4k {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-rbb4k,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-rbb4k true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw8afzp8040eoqk0qbhwz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002a551b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002a551d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:45:29 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:45:29 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:45:29 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:45:29 +0000 UTC  }],Message:,Reason:,HostIP:10.250.31.245,PodIP:,StartTime:2019-12-03 14:45:29 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  3 14:45:33.538: INFO: Pod "nginx-deployment-7b8c6f4498-5grvw" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-5grvw,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-5223,SelfLink:/api/v1/namespaces/deployment-5223/pods/nginx-deployment-7b8c6f4498-5grvw,UID:e2a5908a-7efd-42ec-b997-623d191e4b6c,ResourceVersion:5048,Generation:0,CreationTimestamp:2019-12-03 14:45:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.64.1.5/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 dc1ec4f9-3b4d-4aff-9758-4a6da9501c01 0xc002a552b0 0xc002a552b1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-rbb4k {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-rbb4k,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-rbb4k true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw8afzp8040eoqk0qbhxz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002a55310} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002a55330}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:45:13 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:45:18 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:45:18 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:45:13 +0000 UTC  }],Message:,Reason:,HostIP:10.250.31.244,PodIP:100.64.1.5,StartTime:2019-12-03 14:45:13 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-12-03 14:45:17 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://2eacc6d8b56118bd04f3a4098c8f8a7a9c2b76aa705cecaf6240ae35b6091c69}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  3 14:45:33.538: INFO: Pod "nginx-deployment-7b8c6f4498-5pqtm" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-5pqtm,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-5223,SelfLink:/api/v1/namespaces/deployment-5223/pods/nginx-deployment-7b8c6f4498-5pqtm,UID:d819268d-4886-4c8b-915c-d6860d089b75,ResourceVersion:5216,Generation:0,CreationTimestamp:2019-12-03 14:45:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 dc1ec4f9-3b4d-4aff-9758-4a6da9501c01 0xc002a55400 0xc002a55401}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-rbb4k {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-rbb4k,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-rbb4k true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw8afzp8040eoqk0qbhwz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002a55460} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002a55480}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:45:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:45:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:45:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:45:31 +0000 UTC  }],Message:,Reason:,HostIP:10.250.31.245,PodIP:,StartTime:2019-12-03 14:45:31 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  3 14:45:33.539: INFO: Pod "nginx-deployment-7b8c6f4498-5qd2h" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-5qd2h,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-5223,SelfLink:/api/v1/namespaces/deployment-5223/pods/nginx-deployment-7b8c6f4498-5qd2h,UID:6664b2d4-a930-4db4-b579-571b16b18912,ResourceVersion:5214,Generation:0,CreationTimestamp:2019-12-03 14:45:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 dc1ec4f9-3b4d-4aff-9758-4a6da9501c01 0xc002a55547 0xc002a55548}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-rbb4k {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-rbb4k,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-rbb4k true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw8afzp8040eoqk0qbhwz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002a555b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002a555d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:45:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:45:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:45:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:45:31 +0000 UTC  }],Message:,Reason:,HostIP:10.250.31.245,PodIP:,StartTime:2019-12-03 14:45:31 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  3 14:45:33.539: INFO: Pod "nginx-deployment-7b8c6f4498-6b4gt" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-6b4gt,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-5223,SelfLink:/api/v1/namespaces/deployment-5223/pods/nginx-deployment-7b8c6f4498-6b4gt,UID:6b44c7ad-5971-4e14-ab81-6536c61d57eb,ResourceVersion:5055,Generation:0,CreationTimestamp:2019-12-03 14:45:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.64.1.6/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 dc1ec4f9-3b4d-4aff-9758-4a6da9501c01 0xc002a556a7 0xc002a556a8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-rbb4k {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-rbb4k,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-rbb4k true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw8afzp8040eoqk0qbhxz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002a55710} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002a55730}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:45:13 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:45:19 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:45:19 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:45:13 +0000 UTC  }],Message:,Reason:,HostIP:10.250.31.244,PodIP:100.64.1.6,StartTime:2019-12-03 14:45:13 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-12-03 14:45:19 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://1354af14d3b985f84de7a8294ab8e3aa0a1cb0ce7cb732d525ba0bce1ed00071}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  3 14:45:33.539: INFO: Pod "nginx-deployment-7b8c6f4498-89q6l" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-89q6l,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-5223,SelfLink:/api/v1/namespaces/deployment-5223/pods/nginx-deployment-7b8c6f4498-89q6l,UID:60e3dd19-77cf-4aff-b2c3-7b86bbca9abc,ResourceVersion:5208,Generation:0,CreationTimestamp:2019-12-03 14:45:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 dc1ec4f9-3b4d-4aff-9758-4a6da9501c01 0xc002a55800 0xc002a55801}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-rbb4k {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-rbb4k,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-rbb4k true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw8afzp8040eoqk0qbhwz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002a55860} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002a55880}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:45:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:45:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:45:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:45:31 +0000 UTC  }],Message:,Reason:,HostIP:10.250.31.245,PodIP:,StartTime:2019-12-03 14:45:31 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  3 14:45:33.539: INFO: Pod "nginx-deployment-7b8c6f4498-bpx4q" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-bpx4q,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-5223,SelfLink:/api/v1/namespaces/deployment-5223/pods/nginx-deployment-7b8c6f4498-bpx4q,UID:706e4b5d-7c95-4572-b302-7a9319df5d98,ResourceVersion:5079,Generation:0,CreationTimestamp:2019-12-03 14:45:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.64.1.8/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 dc1ec4f9-3b4d-4aff-9758-4a6da9501c01 0xc002a55957 0xc002a55958}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-rbb4k {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-rbb4k,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-rbb4k true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw8afzp8040eoqk0qbhxz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002a559c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002a559e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:45:13 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:45:23 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:45:23 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:45:13 +0000 UTC  }],Message:,Reason:,HostIP:10.250.31.244,PodIP:100.64.1.8,StartTime:2019-12-03 14:45:13 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-12-03 14:45:22 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://3356e7b6ad264c791929a5c2fd4d606c2062a71ea278abc6dd6a7a23b931f7eb}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  3 14:45:33.539: INFO: Pod "nginx-deployment-7b8c6f4498-clzcf" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-clzcf,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-5223,SelfLink:/api/v1/namespaces/deployment-5223/pods/nginx-deployment-7b8c6f4498-clzcf,UID:1b268619-7d84-45cb-85cc-248a15860b95,ResourceVersion:5069,Generation:0,CreationTimestamp:2019-12-03 14:45:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.64.1.7/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 dc1ec4f9-3b4d-4aff-9758-4a6da9501c01 0xc002a55ac0 0xc002a55ac1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-rbb4k {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-rbb4k,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-rbb4k true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw8afzp8040eoqk0qbhxz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002a55b20} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002a55b40}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:45:13 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:45:21 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:45:21 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:45:13 +0000 UTC  }],Message:,Reason:,HostIP:10.250.31.244,PodIP:100.64.1.7,StartTime:2019-12-03 14:45:13 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-12-03 14:45:20 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://baf59f8ad5380802b36f26a73e65673f79c53ba09014b19b2606b6180fbb2c25}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  3 14:45:33.540: INFO: Pod "nginx-deployment-7b8c6f4498-cwv8p" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-cwv8p,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-5223,SelfLink:/api/v1/namespaces/deployment-5223/pods/nginx-deployment-7b8c6f4498-cwv8p,UID:fa1bae2a-61ea-42ee-b51a-d2e3b9d88f69,ResourceVersion:5231,Generation:0,CreationTimestamp:2019-12-03 14:45:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.64.1.16/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 dc1ec4f9-3b4d-4aff-9758-4a6da9501c01 0xc002a55c20 0xc002a55c21}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-rbb4k {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-rbb4k,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-rbb4k true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw8afzp8040eoqk0qbhxz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002a55c80} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002a55ca0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:45:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:45:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:45:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:45:31 +0000 UTC  }],Message:,Reason:,HostIP:10.250.31.244,PodIP:,StartTime:2019-12-03 14:45:31 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  3 14:45:33.540: INFO: Pod "nginx-deployment-7b8c6f4498-fzvk8" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-fzvk8,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-5223,SelfLink:/api/v1/namespaces/deployment-5223/pods/nginx-deployment-7b8c6f4498-fzvk8,UID:7196af56-808b-4bdc-8bb3-89c6de714d97,ResourceVersion:5222,Generation:0,CreationTimestamp:2019-12-03 14:45:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 dc1ec4f9-3b4d-4aff-9758-4a6da9501c01 0xc002a55d67 0xc002a55d68}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-rbb4k {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-rbb4k,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-rbb4k true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw8afzp8040eoqk0qbhxz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002a55dd0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002a55df0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:45:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:45:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:45:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:45:31 +0000 UTC  }],Message:,Reason:,HostIP:10.250.31.244,PodIP:,StartTime:2019-12-03 14:45:31 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  3 14:45:33.540: INFO: Pod "nginx-deployment-7b8c6f4498-khjw5" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-khjw5,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-5223,SelfLink:/api/v1/namespaces/deployment-5223/pods/nginx-deployment-7b8c6f4498-khjw5,UID:c1f42154-7aa3-47e1-b82f-783e5b093133,ResourceVersion:5065,Generation:0,CreationTimestamp:2019-12-03 14:45:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.64.0.17/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 dc1ec4f9-3b4d-4aff-9758-4a6da9501c01 0xc002a55ec7 0xc002a55ec8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-rbb4k {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-rbb4k,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-rbb4k true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw8afzp8040eoqk0qbhwz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002a55f30} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002a55f50}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:45:13 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:45:20 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:45:20 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:45:13 +0000 UTC  }],Message:,Reason:,HostIP:10.250.31.245,PodIP:100.64.0.17,StartTime:2019-12-03 14:45:13 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-12-03 14:45:20 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://4bcc98eccde82977b4f2f477c4a33e52507c97058f0781532195df140311feb2}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  3 14:45:33.540: INFO: Pod "nginx-deployment-7b8c6f4498-kwz52" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-kwz52,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-5223,SelfLink:/api/v1/namespaces/deployment-5223/pods/nginx-deployment-7b8c6f4498-kwz52,UID:04a4decb-e802-4232-9293-12acbaa93bde,ResourceVersion:5217,Generation:0,CreationTimestamp:2019-12-03 14:45:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 dc1ec4f9-3b4d-4aff-9758-4a6da9501c01 0xc002b9a020 0xc002b9a021}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-rbb4k {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-rbb4k,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-rbb4k true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw8afzp8040eoqk0qbhwz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002b9a080} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002b9a0a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:45:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:45:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:45:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:45:31 +0000 UTC  }],Message:,Reason:,HostIP:10.250.31.245,PodIP:,StartTime:2019-12-03 14:45:31 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  3 14:45:33.540: INFO: Pod "nginx-deployment-7b8c6f4498-l2ttj" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-l2ttj,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-5223,SelfLink:/api/v1/namespaces/deployment-5223/pods/nginx-deployment-7b8c6f4498-l2ttj,UID:7a7c47d3-22a7-4f30-914b-efbbdf2b3d75,ResourceVersion:5043,Generation:0,CreationTimestamp:2019-12-03 14:45:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.64.0.15/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 dc1ec4f9-3b4d-4aff-9758-4a6da9501c01 0xc002b9a177 0xc002b9a178}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-rbb4k {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-rbb4k,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-rbb4k true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw8afzp8040eoqk0qbhwz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002b9a1e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002b9a200}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:45:13 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:45:17 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:45:17 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:45:13 +0000 UTC  }],Message:,Reason:,HostIP:10.250.31.245,PodIP:100.64.0.15,StartTime:2019-12-03 14:45:13 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-12-03 14:45:17 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://713e4221a9e5156bb79413749b4c17adda9759d786204937850c005ac8a0edd8}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  3 14:45:33.540: INFO: Pod "nginx-deployment-7b8c6f4498-ltkd9" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-ltkd9,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-5223,SelfLink:/api/v1/namespaces/deployment-5223/pods/nginx-deployment-7b8c6f4498-ltkd9,UID:fe77f31f-c415-46f0-8b9c-49c6e9f918c1,ResourceVersion:5228,Generation:0,CreationTimestamp:2019-12-03 14:45:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.64.1.15/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 dc1ec4f9-3b4d-4aff-9758-4a6da9501c01 0xc002b9a2e0 0xc002b9a2e1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-rbb4k {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-rbb4k,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-rbb4k true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw8afzp8040eoqk0qbhxz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002b9a340} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002b9a360}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:45:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:45:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:45:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:45:31 +0000 UTC  }],Message:,Reason:,HostIP:10.250.31.244,PodIP:,StartTime:2019-12-03 14:45:31 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  3 14:45:33.541: INFO: Pod "nginx-deployment-7b8c6f4498-lv9pm" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-lv9pm,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-5223,SelfLink:/api/v1/namespaces/deployment-5223/pods/nginx-deployment-7b8c6f4498-lv9pm,UID:e5087214-9d45-4d79-8ad4-6f1265732d88,ResourceVersion:5210,Generation:0,CreationTimestamp:2019-12-03 14:45:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 dc1ec4f9-3b4d-4aff-9758-4a6da9501c01 0xc002b9a427 0xc002b9a428}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-rbb4k {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-rbb4k,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-rbb4k true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw8afzp8040eoqk0qbhxz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002b9a490} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002b9a4b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:45:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:45:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:45:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:45:31 +0000 UTC  }],Message:,Reason:,HostIP:10.250.31.244,PodIP:,StartTime:2019-12-03 14:45:31 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  3 14:45:33.541: INFO: Pod "nginx-deployment-7b8c6f4498-qr68z" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-qr68z,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-5223,SelfLink:/api/v1/namespaces/deployment-5223/pods/nginx-deployment-7b8c6f4498-qr68z,UID:111be0cc-1952-4966-a4ba-48c76539b8c2,ResourceVersion:5209,Generation:0,CreationTimestamp:2019-12-03 14:45:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 dc1ec4f9-3b4d-4aff-9758-4a6da9501c01 0xc002b9a577 0xc002b9a578}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-rbb4k {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-rbb4k,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-rbb4k true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw8afzp8040eoqk0qbhwz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002b9a5e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002b9a600}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:45:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:45:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:45:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:45:31 +0000 UTC  }],Message:,Reason:,HostIP:10.250.31.245,PodIP:,StartTime:2019-12-03 14:45:31 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  3 14:45:33.541: INFO: Pod "nginx-deployment-7b8c6f4498-skdx7" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-skdx7,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-5223,SelfLink:/api/v1/namespaces/deployment-5223/pods/nginx-deployment-7b8c6f4498-skdx7,UID:bf83f778-2506-4a3e-b6d9-7ff737fd0908,ResourceVersion:5211,Generation:0,CreationTimestamp:2019-12-03 14:45:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 dc1ec4f9-3b4d-4aff-9758-4a6da9501c01 0xc002b9a6c7 0xc002b9a6c8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-rbb4k {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-rbb4k,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-rbb4k true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw8afzp8040eoqk0qbhwz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002b9a730} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002b9a750}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:45:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:45:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:45:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:45:31 +0000 UTC  }],Message:,Reason:,HostIP:10.250.31.245,PodIP:,StartTime:2019-12-03 14:45:31 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  3 14:45:33.541: INFO: Pod "nginx-deployment-7b8c6f4498-trxfh" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-trxfh,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-5223,SelfLink:/api/v1/namespaces/deployment-5223/pods/nginx-deployment-7b8c6f4498-trxfh,UID:cd3460d3-6b00-4c90-ab23-8249380a3554,ResourceVersion:5204,Generation:0,CreationTimestamp:2019-12-03 14:45:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 dc1ec4f9-3b4d-4aff-9758-4a6da9501c01 0xc002b9a817 0xc002b9a818}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-rbb4k {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-rbb4k,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-rbb4k true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw8afzp8040eoqk0qbhxz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002b9a880} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002b9a8a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:45:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:45:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:45:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:45:31 +0000 UTC  }],Message:,Reason:,HostIP:10.250.31.244,PodIP:,StartTime:2019-12-03 14:45:31 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  3 14:45:33.541: INFO: Pod "nginx-deployment-7b8c6f4498-wtnrz" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-wtnrz,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-5223,SelfLink:/api/v1/namespaces/deployment-5223/pods/nginx-deployment-7b8c6f4498-wtnrz,UID:71597587-5f54-4f98-b1ed-8f52408f00b7,ResourceVersion:5220,Generation:0,CreationTimestamp:2019-12-03 14:45:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 dc1ec4f9-3b4d-4aff-9758-4a6da9501c01 0xc002b9a967 0xc002b9a968}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-rbb4k {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-rbb4k,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-rbb4k true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw8afzp8040eoqk0qbhxz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002b9a9d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002b9a9f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:45:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:45:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:45:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:45:31 +0000 UTC  }],Message:,Reason:,HostIP:10.250.31.244,PodIP:,StartTime:2019-12-03 14:45:31 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  3 14:45:33.541: INFO: Pod "nginx-deployment-7b8c6f4498-xhncp" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-xhncp,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-5223,SelfLink:/api/v1/namespaces/deployment-5223/pods/nginx-deployment-7b8c6f4498-xhncp,UID:b52baa3a-e9f3-4c7e-93d3-3d73a3c8837d,ResourceVersion:5059,Generation:0,CreationTimestamp:2019-12-03 14:45:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.64.0.16/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 dc1ec4f9-3b4d-4aff-9758-4a6da9501c01 0xc002b9aac7 0xc002b9aac8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-rbb4k {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-rbb4k,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-rbb4k true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw8afzp8040eoqk0qbhwz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002b9ab30} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002b9ab50}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:45:13 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:45:19 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:45:19 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:45:13 +0000 UTC  }],Message:,Reason:,HostIP:10.250.31.245,PodIP:100.64.0.16,StartTime:2019-12-03 14:45:13 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-12-03 14:45:19 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://3e8035b4344d286b0892d87b1474359e8597983456491b939d7266ae0774585c}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  3 14:45:33.542: INFO: Pod "nginx-deployment-7b8c6f4498-xhnh8" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-xhnh8,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-5223,SelfLink:/api/v1/namespaces/deployment-5223/pods/nginx-deployment-7b8c6f4498-xhnh8,UID:9f17dc86-d798-4ce5-82de-62ae7b4606c9,ResourceVersion:5085,Generation:0,CreationTimestamp:2019-12-03 14:45:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.64.1.9/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 dc1ec4f9-3b4d-4aff-9758-4a6da9501c01 0xc002b9ac30 0xc002b9ac31}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-rbb4k {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-rbb4k,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-rbb4k true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw8afzp8040eoqk0qbhxz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002b9ac90} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002b9acb0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:45:13 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:45:24 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:45:24 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:45:13 +0000 UTC  }],Message:,Reason:,HostIP:10.250.31.244,PodIP:100.64.1.9,StartTime:2019-12-03 14:45:13 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-12-03 14:45:24 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://1cc2ef8f74d55d8a33100f5d5eb2f1616d043681b7f08fd47b867f8bd1931a7f}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 14:45:33.542: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-5223" for this suite.
Dec  3 14:45:39.561: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:45:39.732: INFO: namespace deployment-5223 deletion completed in 6.184781547s
â€¢SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 14:45:39.733: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-3576
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: validating cluster-info
Dec  3 14:45:39.878: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmwqx-5aq.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config cluster-info'
Dec  3 14:45:40.187: INFO: stderr: ""
Dec  3 14:45:40.187: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://api.tmwqx-5aq.it.internal.staging.k8s.ondemand.com\x1b[0m\n\x1b[0;32mCoreDNS\x1b[0m is running at \x1b[0;33mhttps://api.tmwqx-5aq.it.internal.staging.k8s.ondemand.com/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\x1b[0;32mkubernetes-dashboard\x1b[0m is running at \x1b[0;33mhttps://api.tmwqx-5aq.it.internal.staging.k8s.ondemand.com/api/v1/namespaces/kube-system/services/https:kubernetes-dashboard:/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 14:45:40.187: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3576" for this suite.
Dec  3 14:45:46.210: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:45:46.376: INFO: namespace kubectl-3576 deletion completed in 6.180892931s
â€¢SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 14:45:46.376: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-4361
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0777 on tmpfs
Dec  3 14:45:46.528: INFO: Waiting up to 5m0s for pod "pod-3305774f-aad0-4a4e-9fc1-c70473326227" in namespace "emptydir-4361" to be "success or failure"
Dec  3 14:45:46.533: INFO: Pod "pod-3305774f-aad0-4a4e-9fc1-c70473326227": Phase="Pending", Reason="", readiness=false. Elapsed: 4.553629ms
Dec  3 14:45:48.539: INFO: Pod "pod-3305774f-aad0-4a4e-9fc1-c70473326227": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010105853s
Dec  3 14:45:50.544: INFO: Pod "pod-3305774f-aad0-4a4e-9fc1-c70473326227": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015784184s
STEP: Saw pod success
Dec  3 14:45:50.544: INFO: Pod "pod-3305774f-aad0-4a4e-9fc1-c70473326227" satisfied condition "success or failure"
Dec  3 14:45:50.549: INFO: Trying to get logs from node izgw8afzp8040eoqk0qbhxz pod pod-3305774f-aad0-4a4e-9fc1-c70473326227 container test-container: <nil>
STEP: delete the pod
Dec  3 14:45:50.711: INFO: Waiting for pod pod-3305774f-aad0-4a4e-9fc1-c70473326227 to disappear
Dec  3 14:45:50.715: INFO: Pod pod-3305774f-aad0-4a4e-9fc1-c70473326227 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 14:45:50.716: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4361" for this suite.
Dec  3 14:45:56.738: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:45:56.987: INFO: namespace emptydir-4361 deletion completed in 6.264636167s
â€¢S
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 14:45:56.988: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-7258
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod test-webserver-0995068d-b2ed-4882-b758-3087db47f31a in namespace container-probe-7258
Dec  3 14:45:59.152: INFO: Started pod test-webserver-0995068d-b2ed-4882-b758-3087db47f31a in namespace container-probe-7258
STEP: checking the pod's current state and verifying that restartCount is present
Dec  3 14:45:59.157: INFO: Initial restart count of pod test-webserver-0995068d-b2ed-4882-b758-3087db47f31a is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 14:49:59.876: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-7258" for this suite.
Dec  3 14:50:05.898: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:50:06.065: INFO: namespace container-probe-7258 deletion completed in 6.180475849s
â€¢SSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 14:50:06.065: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-8984
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap that has name configmap-test-emptyKey-82873152-86b6-490d-8a36-fb274b029020
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 14:50:06.216: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8984" for this suite.
Dec  3 14:50:12.235: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:50:12.448: INFO: namespace configmap-8984 deletion completed in 6.22707712s
â€¢SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 14:50:12.448: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-329
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-f79bf83d-6ca0-4fd7-bc24-84d2b129e88b
STEP: Creating a pod to test consume secrets
Dec  3 14:50:12.605: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-52ee77bc-0ac8-49f1-8c9c-7f0f962248db" in namespace "projected-329" to be "success or failure"
Dec  3 14:50:12.610: INFO: Pod "pod-projected-secrets-52ee77bc-0ac8-49f1-8c9c-7f0f962248db": Phase="Pending", Reason="", readiness=false. Elapsed: 4.256681ms
Dec  3 14:50:14.615: INFO: Pod "pod-projected-secrets-52ee77bc-0ac8-49f1-8c9c-7f0f962248db": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009785953s
STEP: Saw pod success
Dec  3 14:50:14.615: INFO: Pod "pod-projected-secrets-52ee77bc-0ac8-49f1-8c9c-7f0f962248db" satisfied condition "success or failure"
Dec  3 14:50:14.620: INFO: Trying to get logs from node izgw8afzp8040eoqk0qbhxz pod pod-projected-secrets-52ee77bc-0ac8-49f1-8c9c-7f0f962248db container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec  3 14:50:14.642: INFO: Waiting for pod pod-projected-secrets-52ee77bc-0ac8-49f1-8c9c-7f0f962248db to disappear
Dec  3 14:50:14.646: INFO: Pod pod-projected-secrets-52ee77bc-0ac8-49f1-8c9c-7f0f962248db no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 14:50:14.646: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-329" for this suite.
Dec  3 14:50:20.672: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:50:20.837: INFO: namespace projected-329 deletion completed in 6.18410219s
â€¢SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 14:50:20.838: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3255
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Dec  3 14:50:20.991: INFO: Waiting up to 5m0s for pod "downwardapi-volume-3b00e4b9-79e3-4000-b92d-802212cd2854" in namespace "projected-3255" to be "success or failure"
Dec  3 14:50:20.996: INFO: Pod "downwardapi-volume-3b00e4b9-79e3-4000-b92d-802212cd2854": Phase="Pending", Reason="", readiness=false. Elapsed: 4.39961ms
Dec  3 14:50:23.001: INFO: Pod "downwardapi-volume-3b00e4b9-79e3-4000-b92d-802212cd2854": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009819538s
STEP: Saw pod success
Dec  3 14:50:23.001: INFO: Pod "downwardapi-volume-3b00e4b9-79e3-4000-b92d-802212cd2854" satisfied condition "success or failure"
Dec  3 14:50:23.007: INFO: Trying to get logs from node izgw8afzp8040eoqk0qbhxz pod downwardapi-volume-3b00e4b9-79e3-4000-b92d-802212cd2854 container client-container: <nil>
STEP: delete the pod
Dec  3 14:50:23.027: INFO: Waiting for pod downwardapi-volume-3b00e4b9-79e3-4000-b92d-802212cd2854 to disappear
Dec  3 14:50:23.031: INFO: Pod downwardapi-volume-3b00e4b9-79e3-4000-b92d-802212cd2854 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 14:50:23.031: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3255" for this suite.
Dec  3 14:50:29.053: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:50:29.265: INFO: namespace projected-3255 deletion completed in 6.226095522s
â€¢SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 14:50:29.265: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3582
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-map-f45e1e36-eec9-4128-94f0-7e8d1e41f950
STEP: Creating a pod to test consume secrets
Dec  3 14:50:29.422: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-131ab2a2-d711-4945-bb52-958378a0baf1" in namespace "projected-3582" to be "success or failure"
Dec  3 14:50:29.426: INFO: Pod "pod-projected-secrets-131ab2a2-d711-4945-bb52-958378a0baf1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.253522ms
Dec  3 14:50:31.432: INFO: Pod "pod-projected-secrets-131ab2a2-d711-4945-bb52-958378a0baf1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009849011s
STEP: Saw pod success
Dec  3 14:50:31.432: INFO: Pod "pod-projected-secrets-131ab2a2-d711-4945-bb52-958378a0baf1" satisfied condition "success or failure"
Dec  3 14:50:31.436: INFO: Trying to get logs from node izgw8afzp8040eoqk0qbhxz pod pod-projected-secrets-131ab2a2-d711-4945-bb52-958378a0baf1 container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec  3 14:50:31.458: INFO: Waiting for pod pod-projected-secrets-131ab2a2-d711-4945-bb52-958378a0baf1 to disappear
Dec  3 14:50:31.462: INFO: Pod pod-projected-secrets-131ab2a2-d711-4945-bb52-958378a0baf1 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 14:50:31.462: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3582" for this suite.
Dec  3 14:50:37.484: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:50:37.657: INFO: namespace projected-3582 deletion completed in 6.187441718s
â€¢SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 14:50:37.657: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replicaset-2231
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Dec  3 14:50:37.801: INFO: Creating ReplicaSet my-hostname-basic-793f9ac5-70f7-4193-a3ae-3c072d5d89ef
Dec  3 14:50:37.810: INFO: Pod name my-hostname-basic-793f9ac5-70f7-4193-a3ae-3c072d5d89ef: Found 0 pods out of 1
Dec  3 14:50:42.816: INFO: Pod name my-hostname-basic-793f9ac5-70f7-4193-a3ae-3c072d5d89ef: Found 1 pods out of 1
Dec  3 14:50:42.816: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-793f9ac5-70f7-4193-a3ae-3c072d5d89ef" is running
Dec  3 14:50:42.822: INFO: Pod "my-hostname-basic-793f9ac5-70f7-4193-a3ae-3c072d5d89ef-d9cz8" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-12-03 14:50:37 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-12-03 14:50:40 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-12-03 14:50:40 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-12-03 14:50:37 +0000 UTC Reason: Message:}])
Dec  3 14:50:42.822: INFO: Trying to dial the pod
Dec  3 14:50:47.928: INFO: Controller my-hostname-basic-793f9ac5-70f7-4193-a3ae-3c072d5d89ef: Got expected result from replica 1 [my-hostname-basic-793f9ac5-70f7-4193-a3ae-3c072d5d89ef-d9cz8]: "my-hostname-basic-793f9ac5-70f7-4193-a3ae-3c072d5d89ef-d9cz8", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 14:50:47.928: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-2231" for this suite.
Dec  3 14:50:53.952: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:50:54.116: INFO: namespace replicaset-2231 deletion completed in 6.179923295s
â€¢
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 14:50:54.116: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-5605
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Dec  3 14:50:54.270: INFO: Waiting up to 5m0s for pod "downward-api-2f6ff716-cd91-4a4f-87b5-0a21785049ce" in namespace "downward-api-5605" to be "success or failure"
Dec  3 14:50:54.274: INFO: Pod "downward-api-2f6ff716-cd91-4a4f-87b5-0a21785049ce": Phase="Pending", Reason="", readiness=false. Elapsed: 4.292056ms
Dec  3 14:50:56.280: INFO: Pod "downward-api-2f6ff716-cd91-4a4f-87b5-0a21785049ce": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009745565s
Dec  3 14:50:58.285: INFO: Pod "downward-api-2f6ff716-cd91-4a4f-87b5-0a21785049ce": Phase="Pending", Reason="", readiness=false. Elapsed: 4.015401861s
Dec  3 14:51:00.291: INFO: Pod "downward-api-2f6ff716-cd91-4a4f-87b5-0a21785049ce": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.021291275s
STEP: Saw pod success
Dec  3 14:51:00.291: INFO: Pod "downward-api-2f6ff716-cd91-4a4f-87b5-0a21785049ce" satisfied condition "success or failure"
Dec  3 14:51:00.296: INFO: Trying to get logs from node izgw8afzp8040eoqk0qbhxz pod downward-api-2f6ff716-cd91-4a4f-87b5-0a21785049ce container dapi-container: <nil>
STEP: delete the pod
Dec  3 14:51:00.324: INFO: Waiting for pod downward-api-2f6ff716-cd91-4a4f-87b5-0a21785049ce to disappear
Dec  3 14:51:00.328: INFO: Pod downward-api-2f6ff716-cd91-4a4f-87b5-0a21785049ce no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 14:51:00.329: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5605" for this suite.
Dec  3 14:51:06.351: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:51:06.556: INFO: namespace downward-api-5605 deletion completed in 6.219321767s
â€¢SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 14:51:06.556: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1289
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Dec  3 14:51:06.714: INFO: Waiting up to 5m0s for pod "downwardapi-volume-614f0065-5b21-4f46-b95c-ef0a07f7b907" in namespace "projected-1289" to be "success or failure"
Dec  3 14:51:06.719: INFO: Pod "downwardapi-volume-614f0065-5b21-4f46-b95c-ef0a07f7b907": Phase="Pending", Reason="", readiness=false. Elapsed: 4.243271ms
Dec  3 14:51:08.724: INFO: Pod "downwardapi-volume-614f0065-5b21-4f46-b95c-ef0a07f7b907": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009830865s
STEP: Saw pod success
Dec  3 14:51:08.724: INFO: Pod "downwardapi-volume-614f0065-5b21-4f46-b95c-ef0a07f7b907" satisfied condition "success or failure"
Dec  3 14:51:08.729: INFO: Trying to get logs from node izgw8afzp8040eoqk0qbhxz pod downwardapi-volume-614f0065-5b21-4f46-b95c-ef0a07f7b907 container client-container: <nil>
STEP: delete the pod
Dec  3 14:51:08.750: INFO: Waiting for pod downwardapi-volume-614f0065-5b21-4f46-b95c-ef0a07f7b907 to disappear
Dec  3 14:51:08.755: INFO: Pod downwardapi-volume-614f0065-5b21-4f46-b95c-ef0a07f7b907 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 14:51:08.755: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1289" for this suite.
Dec  3 14:51:14.776: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:51:14.941: INFO: namespace projected-1289 deletion completed in 6.178916191s
â€¢SSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 14:51:14.941: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-1868
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-downwardapi-75ss
STEP: Creating a pod to test atomic-volume-subpath
Dec  3 14:51:15.102: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-75ss" in namespace "subpath-1868" to be "success or failure"
Dec  3 14:51:15.106: INFO: Pod "pod-subpath-test-downwardapi-75ss": Phase="Pending", Reason="", readiness=false. Elapsed: 4.091952ms
Dec  3 14:51:17.112: INFO: Pod "pod-subpath-test-downwardapi-75ss": Phase="Running", Reason="", readiness=true. Elapsed: 2.009582964s
Dec  3 14:51:19.117: INFO: Pod "pod-subpath-test-downwardapi-75ss": Phase="Running", Reason="", readiness=true. Elapsed: 4.014973279s
Dec  3 14:51:21.123: INFO: Pod "pod-subpath-test-downwardapi-75ss": Phase="Running", Reason="", readiness=true. Elapsed: 6.02055995s
Dec  3 14:51:23.128: INFO: Pod "pod-subpath-test-downwardapi-75ss": Phase="Running", Reason="", readiness=true. Elapsed: 8.02610223s
Dec  3 14:51:25.134: INFO: Pod "pod-subpath-test-downwardapi-75ss": Phase="Running", Reason="", readiness=true. Elapsed: 10.031980315s
Dec  3 14:51:27.140: INFO: Pod "pod-subpath-test-downwardapi-75ss": Phase="Running", Reason="", readiness=true. Elapsed: 12.038091256s
Dec  3 14:51:29.146: INFO: Pod "pod-subpath-test-downwardapi-75ss": Phase="Running", Reason="", readiness=true. Elapsed: 14.043339384s
Dec  3 14:51:31.151: INFO: Pod "pod-subpath-test-downwardapi-75ss": Phase="Running", Reason="", readiness=true. Elapsed: 16.048982545s
Dec  3 14:51:33.157: INFO: Pod "pod-subpath-test-downwardapi-75ss": Phase="Running", Reason="", readiness=true. Elapsed: 18.054189115s
Dec  3 14:51:35.162: INFO: Pod "pod-subpath-test-downwardapi-75ss": Phase="Running", Reason="", readiness=true. Elapsed: 20.059431033s
Dec  3 14:51:37.167: INFO: Pod "pod-subpath-test-downwardapi-75ss": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.064659141s
STEP: Saw pod success
Dec  3 14:51:37.167: INFO: Pod "pod-subpath-test-downwardapi-75ss" satisfied condition "success or failure"
Dec  3 14:51:37.171: INFO: Trying to get logs from node izgw8afzp8040eoqk0qbhxz pod pod-subpath-test-downwardapi-75ss container test-container-subpath-downwardapi-75ss: <nil>
STEP: delete the pod
Dec  3 14:51:37.196: INFO: Waiting for pod pod-subpath-test-downwardapi-75ss to disappear
Dec  3 14:51:37.200: INFO: Pod pod-subpath-test-downwardapi-75ss no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-75ss
Dec  3 14:51:37.200: INFO: Deleting pod "pod-subpath-test-downwardapi-75ss" in namespace "subpath-1868"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 14:51:37.204: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-1868" for this suite.
Dec  3 14:51:43.226: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:51:43.392: INFO: namespace subpath-1868 deletion completed in 6.180410673s
â€¢SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 14:51:43.392: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in namespaces-9560
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-4245
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-6565
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 14:51:49.857: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-9560" for this suite.
Dec  3 14:51:55.879: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:51:56.084: INFO: namespace namespaces-9560 deletion completed in 6.219603683s
STEP: Destroying namespace "nsdeletetest-4245" for this suite.
Dec  3 14:51:56.088: INFO: Namespace nsdeletetest-4245 was already deleted
STEP: Destroying namespace "nsdeletetest-6565" for this suite.
Dec  3 14:52:02.103: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:52:02.311: INFO: namespace nsdeletetest-6565 deletion completed in 6.223100796s
â€¢SSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 14:52:02.312: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-2632
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test use defaults
Dec  3 14:52:02.467: INFO: Waiting up to 5m0s for pod "client-containers-441514c6-85af-4427-a156-0fe2461606cd" in namespace "containers-2632" to be "success or failure"
Dec  3 14:52:02.471: INFO: Pod "client-containers-441514c6-85af-4427-a156-0fe2461606cd": Phase="Pending", Reason="", readiness=false. Elapsed: 4.246213ms
Dec  3 14:52:04.476: INFO: Pod "client-containers-441514c6-85af-4427-a156-0fe2461606cd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009078708s
Dec  3 14:52:06.481: INFO: Pod "client-containers-441514c6-85af-4427-a156-0fe2461606cd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014272288s
STEP: Saw pod success
Dec  3 14:52:06.481: INFO: Pod "client-containers-441514c6-85af-4427-a156-0fe2461606cd" satisfied condition "success or failure"
Dec  3 14:52:06.485: INFO: Trying to get logs from node izgw8afzp8040eoqk0qbhxz pod client-containers-441514c6-85af-4427-a156-0fe2461606cd container test-container: <nil>
STEP: delete the pod
Dec  3 14:52:06.507: INFO: Waiting for pod client-containers-441514c6-85af-4427-a156-0fe2461606cd to disappear
Dec  3 14:52:06.511: INFO: Pod client-containers-441514c6-85af-4427-a156-0fe2461606cd no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 14:52:06.511: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-2632" for this suite.
Dec  3 14:52:12.533: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:52:12.696: INFO: namespace containers-2632 deletion completed in 6.177495651s
â€¢SSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 14:52:12.696: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-1108
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0666 on node default medium
Dec  3 14:52:12.849: INFO: Waiting up to 5m0s for pod "pod-ecc0d619-4661-4e8e-af60-b40f7d8c98b6" in namespace "emptydir-1108" to be "success or failure"
Dec  3 14:52:12.853: INFO: Pod "pod-ecc0d619-4661-4e8e-af60-b40f7d8c98b6": Phase="Pending", Reason="", readiness=false. Elapsed: 4.343002ms
Dec  3 14:52:14.859: INFO: Pod "pod-ecc0d619-4661-4e8e-af60-b40f7d8c98b6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009829514s
STEP: Saw pod success
Dec  3 14:52:14.859: INFO: Pod "pod-ecc0d619-4661-4e8e-af60-b40f7d8c98b6" satisfied condition "success or failure"
Dec  3 14:52:14.863: INFO: Trying to get logs from node izgw8afzp8040eoqk0qbhxz pod pod-ecc0d619-4661-4e8e-af60-b40f7d8c98b6 container test-container: <nil>
STEP: delete the pod
Dec  3 14:52:14.885: INFO: Waiting for pod pod-ecc0d619-4661-4e8e-af60-b40f7d8c98b6 to disappear
Dec  3 14:52:14.889: INFO: Pod pod-ecc0d619-4661-4e8e-af60-b40f7d8c98b6 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 14:52:14.889: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1108" for this suite.
Dec  3 14:52:20.910: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:52:21.079: INFO: namespace emptydir-1108 deletion completed in 6.18286352s
â€¢SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 14:52:21.080: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-737
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Dec  3 14:52:21.226: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Dec  3 14:52:21.235: INFO: Pod name sample-pod: Found 0 pods out of 1
Dec  3 14:52:26.240: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Dec  3 14:52:26.240: INFO: Creating deployment "test-rolling-update-deployment"
Dec  3 14:52:26.245: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Dec  3 14:52:26.255: INFO: deployment "test-rolling-update-deployment" doesn't have the required revision set
Dec  3 14:52:28.265: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Dec  3 14:52:28.270: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710981546, loc:(*time.Location)(0x7ed1a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710981546, loc:(*time.Location)(0x7ed1a20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710981546, loc:(*time.Location)(0x7ed1a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710981546, loc:(*time.Location)(0x7ed1a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-79f6b9d75c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  3 14:52:30.276: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
Dec  3 14:52:30.290: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment,GenerateName:,Namespace:deployment-737,SelfLink:/apis/apps/v1/namespaces/deployment-737/deployments/test-rolling-update-deployment,UID:561cebae-0de1-4e7d-8977-d2f3ae44f859,ResourceVersion:6949,Generation:1,CreationTimestamp:2019-12-03 14:52:26 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-12-03 14:52:26 +0000 UTC 2019-12-03 14:52:26 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-12-03 14:52:29 +0000 UTC 2019-12-03 14:52:26 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rolling-update-deployment-79f6b9d75c" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Dec  3 14:52:30.295: INFO: New ReplicaSet "test-rolling-update-deployment-79f6b9d75c" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-79f6b9d75c,GenerateName:,Namespace:deployment-737,SelfLink:/apis/apps/v1/namespaces/deployment-737/replicasets/test-rolling-update-deployment-79f6b9d75c,UID:5256cd46-c647-4ae6-9590-ab605a7fb210,ResourceVersion:6942,Generation:1,CreationTimestamp:2019-12-03 14:52:26 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 79f6b9d75c,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 561cebae-0de1-4e7d-8977-d2f3ae44f859 0xc002cf9f47 0xc002cf9f48}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 79f6b9d75c,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 79f6b9d75c,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Dec  3 14:52:30.296: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Dec  3 14:52:30.296: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-controller,GenerateName:,Namespace:deployment-737,SelfLink:/apis/apps/v1/namespaces/deployment-737/replicasets/test-rolling-update-controller,UID:8b6caede-df9f-4a35-a7df-fdf42dcebcb9,ResourceVersion:6948,Generation:2,CreationTimestamp:2019-12-03 14:52:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305832,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 561cebae-0de1-4e7d-8977-d2f3ae44f859 0xc002cf9e4f 0xc002cf9e60}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Dec  3 14:52:30.301: INFO: Pod "test-rolling-update-deployment-79f6b9d75c-mbgrq" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-79f6b9d75c-mbgrq,GenerateName:test-rolling-update-deployment-79f6b9d75c-,Namespace:deployment-737,SelfLink:/api/v1/namespaces/deployment-737/pods/test-rolling-update-deployment-79f6b9d75c-mbgrq,UID:b7de147d-2ae1-43a0-9210-e88f18af1c73,ResourceVersion:6941,Generation:0,CreationTimestamp:2019-12-03 14:52:26 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 79f6b9d75c,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.64.1.40/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-rolling-update-deployment-79f6b9d75c 5256cd46-c647-4ae6-9590-ab605a7fb210 0xc001ed4a87 0xc001ed4a88}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-54mxn {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-54mxn,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-54mxn true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw8afzp8040eoqk0qbhxz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001ed4af0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001ed4b10}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:52:26 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:52:29 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:52:29 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:52:26 +0000 UTC  }],Message:,Reason:,HostIP:10.250.31.244,PodIP:100.64.1.40,StartTime:2019-12-03 14:52:26 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-12-03 14:52:28 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://753a2187644e045b9c565f74ad7ee7918a57807bc641bf1e68260db287180d1d}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 14:52:30.301: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-737" for this suite.
Dec  3 14:52:36.323: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:52:36.486: INFO: namespace deployment-737 deletion completed in 6.177779006s
â€¢SSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 14:52:36.486: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-2357
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0666 on tmpfs
Dec  3 14:52:36.640: INFO: Waiting up to 5m0s for pod "pod-49346423-f940-41c1-a7f3-a870aee18afd" in namespace "emptydir-2357" to be "success or failure"
Dec  3 14:52:36.644: INFO: Pod "pod-49346423-f940-41c1-a7f3-a870aee18afd": Phase="Pending", Reason="", readiness=false. Elapsed: 4.365883ms
Dec  3 14:52:38.649: INFO: Pod "pod-49346423-f940-41c1-a7f3-a870aee18afd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009482059s
STEP: Saw pod success
Dec  3 14:52:38.649: INFO: Pod "pod-49346423-f940-41c1-a7f3-a870aee18afd" satisfied condition "success or failure"
Dec  3 14:52:38.654: INFO: Trying to get logs from node izgw8afzp8040eoqk0qbhxz pod pod-49346423-f940-41c1-a7f3-a870aee18afd container test-container: <nil>
STEP: delete the pod
Dec  3 14:52:38.674: INFO: Waiting for pod pod-49346423-f940-41c1-a7f3-a870aee18afd to disappear
Dec  3 14:52:38.678: INFO: Pod pod-49346423-f940-41c1-a7f3-a870aee18afd no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 14:52:38.678: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2357" for this suite.
Dec  3 14:52:44.700: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:52:44.870: INFO: namespace emptydir-2357 deletion completed in 6.184111511s
â€¢SSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 14:52:44.870: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-5569
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating service multi-endpoint-test in namespace services-5569
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-5569 to expose endpoints map[]
Dec  3 14:52:45.026: INFO: successfully validated that service multi-endpoint-test in namespace services-5569 exposes endpoints map[] (4.17037ms elapsed)
STEP: Creating pod pod1 in namespace services-5569
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-5569 to expose endpoints map[pod1:[100]]
Dec  3 14:52:47.061: INFO: successfully validated that service multi-endpoint-test in namespace services-5569 exposes endpoints map[pod1:[100]] (2.027510303s elapsed)
STEP: Creating pod pod2 in namespace services-5569
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-5569 to expose endpoints map[pod1:[100] pod2:[101]]
Dec  3 14:52:49.107: INFO: successfully validated that service multi-endpoint-test in namespace services-5569 exposes endpoints map[pod1:[100] pod2:[101]] (2.039984484s elapsed)
STEP: Deleting pod pod1 in namespace services-5569
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-5569 to expose endpoints map[pod2:[101]]
Dec  3 14:52:49.120: INFO: successfully validated that service multi-endpoint-test in namespace services-5569 exposes endpoints map[pod2:[101]] (7.9463ms elapsed)
STEP: Deleting pod pod2 in namespace services-5569
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-5569 to expose endpoints map[]
Dec  3 14:52:49.129: INFO: successfully validated that service multi-endpoint-test in namespace services-5569 exposes endpoints map[] (3.872584ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 14:52:49.140: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-5569" for this suite.
Dec  3 14:53:11.162: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:53:11.325: INFO: namespace services-5569 deletion completed in 22.178053989s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:92
â€¢SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 14:53:11.326: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-2042
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Dec  3 14:53:13.499: INFO: Expected: &{OK} to match Container's Termination Message: OK --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 14:53:13.512: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-2042" for this suite.
Dec  3 14:53:19.534: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:53:19.701: INFO: namespace container-runtime-2042 deletion completed in 6.181434978s
â€¢SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 14:53:19.702: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6616
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-map-d650d2b4-28d2-4e97-8c54-ac817ce9b7c0
STEP: Creating a pod to test consume configMaps
Dec  3 14:53:19.860: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-b1005595-ed99-42e5-b42b-0f7a167425a9" in namespace "projected-6616" to be "success or failure"
Dec  3 14:53:19.865: INFO: Pod "pod-projected-configmaps-b1005595-ed99-42e5-b42b-0f7a167425a9": Phase="Pending", Reason="", readiness=false. Elapsed: 4.181197ms
Dec  3 14:53:21.870: INFO: Pod "pod-projected-configmaps-b1005595-ed99-42e5-b42b-0f7a167425a9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009215143s
STEP: Saw pod success
Dec  3 14:53:21.870: INFO: Pod "pod-projected-configmaps-b1005595-ed99-42e5-b42b-0f7a167425a9" satisfied condition "success or failure"
Dec  3 14:53:21.874: INFO: Trying to get logs from node izgw8afzp8040eoqk0qbhxz pod pod-projected-configmaps-b1005595-ed99-42e5-b42b-0f7a167425a9 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec  3 14:53:21.895: INFO: Waiting for pod pod-projected-configmaps-b1005595-ed99-42e5-b42b-0f7a167425a9 to disappear
Dec  3 14:53:21.899: INFO: Pod pod-projected-configmaps-b1005595-ed99-42e5-b42b-0f7a167425a9 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 14:53:21.899: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6616" for this suite.
Dec  3 14:53:27.921: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:53:28.092: INFO: namespace projected-6616 deletion completed in 6.185934144s
â€¢
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 14:53:28.092: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-383
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 14:53:50.477: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-383" for this suite.
Dec  3 14:53:56.499: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:53:56.709: INFO: namespace container-runtime-383 deletion completed in 6.224345277s
â€¢
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 14:53:56.709: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-2410
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
Dec  3 14:54:02.892: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 14:54:02.892: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
W1203 14:54:02.892439    5085 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
STEP: Destroying namespace "gc-2410" for this suite.
Dec  3 14:54:08.912: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:54:09.074: INFO: namespace gc-2410 deletion completed in 6.177068387s
â€¢SSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 14:54:09.074: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-6806
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Performing setup for networking test in namespace pod-network-test-6806
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Dec  3 14:54:09.218: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Dec  3 14:54:31.307: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 100.64.0.34 8081 | grep -v '^\s*$'] Namespace:pod-network-test-6806 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  3 14:54:31.307: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec  3 14:54:32.739: INFO: Found all expected endpoints: [netserver-0]
Dec  3 14:54:32.743: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 100.64.1.55 8081 | grep -v '^\s*$'] Namespace:pod-network-test-6806 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  3 14:54:32.743: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec  3 14:54:34.241: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 14:54:34.242: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-6806" for this suite.
Dec  3 14:54:50.264: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:54:50.435: INFO: namespace pod-network-test-6806 deletion completed in 16.186122514s
â€¢SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 14:54:50.436: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-4214
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: starting the proxy server
Dec  3 14:54:50.582: INFO: Asynchronously running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl kubectl --server=https://api.tmwqx-5aq.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 14:54:50.665: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4214" for this suite.
Dec  3 14:54:56.687: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:54:56.852: INFO: namespace kubectl-4214 deletion completed in 6.180737356s
â€¢SSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 14:54:56.852: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-6822
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:63
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Dec  3 14:55:01.056: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  3 14:55:01.061: INFO: Pod pod-with-poststart-exec-hook still exists
Dec  3 14:55:03.061: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  3 14:55:03.066: INFO: Pod pod-with-poststart-exec-hook still exists
Dec  3 14:55:05.061: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  3 14:55:05.066: INFO: Pod pod-with-poststart-exec-hook still exists
Dec  3 14:55:07.061: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  3 14:55:07.066: INFO: Pod pod-with-poststart-exec-hook still exists
Dec  3 14:55:09.061: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  3 14:55:09.066: INFO: Pod pod-with-poststart-exec-hook still exists
Dec  3 14:55:11.061: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  3 14:55:11.066: INFO: Pod pod-with-poststart-exec-hook still exists
Dec  3 14:55:13.061: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  3 14:55:13.066: INFO: Pod pod-with-poststart-exec-hook still exists
Dec  3 14:55:15.061: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  3 14:55:15.066: INFO: Pod pod-with-poststart-exec-hook still exists
Dec  3 14:55:17.061: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  3 14:55:17.066: INFO: Pod pod-with-poststart-exec-hook still exists
Dec  3 14:55:19.061: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  3 14:55:19.066: INFO: Pod pod-with-poststart-exec-hook still exists
Dec  3 14:55:21.061: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  3 14:55:21.067: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 14:55:21.067: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-6822" for this suite.
Dec  3 14:55:43.089: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:55:43.254: INFO: namespace container-lifecycle-hook-6822 deletion completed in 22.179792687s
â€¢SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 14:55:43.255: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-8139
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Dec  3 14:55:43.436: INFO: Number of nodes with available pods: 0
Dec  3 14:55:43.436: INFO: Node izgw8afzp8040eoqk0qbhwz is running more than one daemon pod
Dec  3 14:55:44.450: INFO: Number of nodes with available pods: 0
Dec  3 14:55:44.450: INFO: Node izgw8afzp8040eoqk0qbhwz is running more than one daemon pod
Dec  3 14:55:45.450: INFO: Number of nodes with available pods: 2
Dec  3 14:55:45.450: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Stop a daemon pod, check that the daemon pod is revived.
Dec  3 14:55:45.473: INFO: Number of nodes with available pods: 1
Dec  3 14:55:45.473: INFO: Node izgw8afzp8040eoqk0qbhxz is running more than one daemon pod
Dec  3 14:55:46.486: INFO: Number of nodes with available pods: 1
Dec  3 14:55:46.486: INFO: Node izgw8afzp8040eoqk0qbhxz is running more than one daemon pod
Dec  3 14:55:47.486: INFO: Number of nodes with available pods: 1
Dec  3 14:55:47.486: INFO: Node izgw8afzp8040eoqk0qbhxz is running more than one daemon pod
Dec  3 14:55:48.486: INFO: Number of nodes with available pods: 1
Dec  3 14:55:48.487: INFO: Node izgw8afzp8040eoqk0qbhxz is running more than one daemon pod
Dec  3 14:55:49.486: INFO: Number of nodes with available pods: 1
Dec  3 14:55:49.486: INFO: Node izgw8afzp8040eoqk0qbhxz is running more than one daemon pod
Dec  3 14:55:50.486: INFO: Number of nodes with available pods: 1
Dec  3 14:55:50.486: INFO: Node izgw8afzp8040eoqk0qbhxz is running more than one daemon pod
Dec  3 14:55:51.487: INFO: Number of nodes with available pods: 1
Dec  3 14:55:51.487: INFO: Node izgw8afzp8040eoqk0qbhxz is running more than one daemon pod
Dec  3 14:55:52.486: INFO: Number of nodes with available pods: 1
Dec  3 14:55:52.486: INFO: Node izgw8afzp8040eoqk0qbhxz is running more than one daemon pod
Dec  3 14:55:53.486: INFO: Number of nodes with available pods: 1
Dec  3 14:55:53.486: INFO: Node izgw8afzp8040eoqk0qbhxz is running more than one daemon pod
Dec  3 14:55:54.485: INFO: Number of nodes with available pods: 1
Dec  3 14:55:54.485: INFO: Node izgw8afzp8040eoqk0qbhxz is running more than one daemon pod
Dec  3 14:55:55.486: INFO: Number of nodes with available pods: 1
Dec  3 14:55:55.486: INFO: Node izgw8afzp8040eoqk0qbhxz is running more than one daemon pod
Dec  3 14:55:56.486: INFO: Number of nodes with available pods: 1
Dec  3 14:55:56.486: INFO: Node izgw8afzp8040eoqk0qbhxz is running more than one daemon pod
Dec  3 14:55:57.486: INFO: Number of nodes with available pods: 1
Dec  3 14:55:57.486: INFO: Node izgw8afzp8040eoqk0qbhxz is running more than one daemon pod
Dec  3 14:55:58.486: INFO: Number of nodes with available pods: 2
Dec  3 14:55:58.486: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-8139, will wait for the garbage collector to delete the pods
Dec  3 14:55:58.553: INFO: Deleting DaemonSet.extensions daemon-set took: 7.026882ms
Dec  3 14:55:58.653: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.34559ms
Dec  3 14:56:05.658: INFO: Number of nodes with available pods: 0
Dec  3 14:56:05.659: INFO: Number of running nodes: 0, number of available pods: 0
Dec  3 14:56:05.665: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-8139/daemonsets","resourceVersion":"7971"},"items":null}

Dec  3 14:56:05.670: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-8139/pods","resourceVersion":"7971"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 14:56:05.686: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-8139" for this suite.
Dec  3 14:56:11.706: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:56:11.874: INFO: namespace daemonsets-8139 deletion completed in 6.182551161s
â€¢SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 14:56:11.874: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-9880
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Dec  3 14:56:12.027: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ed4b8cfb-00b9-4455-adcc-eb4324df9acb" in namespace "downward-api-9880" to be "success or failure"
Dec  3 14:56:12.031: INFO: Pod "downwardapi-volume-ed4b8cfb-00b9-4455-adcc-eb4324df9acb": Phase="Pending", Reason="", readiness=false. Elapsed: 4.303988ms
Dec  3 14:56:14.036: INFO: Pod "downwardapi-volume-ed4b8cfb-00b9-4455-adcc-eb4324df9acb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009241825s
STEP: Saw pod success
Dec  3 14:56:14.037: INFO: Pod "downwardapi-volume-ed4b8cfb-00b9-4455-adcc-eb4324df9acb" satisfied condition "success or failure"
Dec  3 14:56:14.041: INFO: Trying to get logs from node izgw8afzp8040eoqk0qbhxz pod downwardapi-volume-ed4b8cfb-00b9-4455-adcc-eb4324df9acb container client-container: <nil>
STEP: delete the pod
Dec  3 14:56:14.065: INFO: Waiting for pod downwardapi-volume-ed4b8cfb-00b9-4455-adcc-eb4324df9acb to disappear
Dec  3 14:56:14.069: INFO: Pod downwardapi-volume-ed4b8cfb-00b9-4455-adcc-eb4324df9acb no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 14:56:14.069: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9880" for this suite.
Dec  3 14:56:20.090: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:56:20.257: INFO: namespace downward-api-9880 deletion completed in 6.180676136s
â€¢SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 14:56:20.257: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-135
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-upd-5a5dbc2e-5091-452a-b0b8-e1ef7f6bf84b
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 14:56:22.532: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-135" for this suite.
Dec  3 14:56:44.555: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:56:44.989: INFO: namespace configmap-135 deletion completed in 22.448477111s
â€¢SS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 14:56:44.989: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-3089
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Dec  3 14:56:47.672: INFO: Successfully updated pod "pod-update-activedeadlineseconds-200c68a9-9cf8-4813-b2e1-d92d4df91452"
Dec  3 14:56:47.672: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-200c68a9-9cf8-4813-b2e1-d92d4df91452" in namespace "pods-3089" to be "terminated due to deadline exceeded"
Dec  3 14:56:47.676: INFO: Pod "pod-update-activedeadlineseconds-200c68a9-9cf8-4813-b2e1-d92d4df91452": Phase="Running", Reason="", readiness=true. Elapsed: 4.368025ms
Dec  3 14:56:49.682: INFO: Pod "pod-update-activedeadlineseconds-200c68a9-9cf8-4813-b2e1-d92d4df91452": Phase="Running", Reason="", readiness=true. Elapsed: 2.009553107s
Dec  3 14:56:51.687: INFO: Pod "pod-update-activedeadlineseconds-200c68a9-9cf8-4813-b2e1-d92d4df91452": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 4.014874657s
Dec  3 14:56:51.687: INFO: Pod "pod-update-activedeadlineseconds-200c68a9-9cf8-4813-b2e1-d92d4df91452" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 14:56:51.687: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-3089" for this suite.
Dec  3 14:56:57.709: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:56:57.913: INFO: namespace pods-3089 deletion completed in 6.217964253s
â€¢SS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 14:56:57.913: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-5923
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Dec  3 14:56:58.068: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0778d6a4-713f-49d4-a742-8b801654f038" in namespace "downward-api-5923" to be "success or failure"
Dec  3 14:56:58.072: INFO: Pod "downwardapi-volume-0778d6a4-713f-49d4-a742-8b801654f038": Phase="Pending", Reason="", readiness=false. Elapsed: 4.452809ms
Dec  3 14:57:00.078: INFO: Pod "downwardapi-volume-0778d6a4-713f-49d4-a742-8b801654f038": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009855801s
STEP: Saw pod success
Dec  3 14:57:00.078: INFO: Pod "downwardapi-volume-0778d6a4-713f-49d4-a742-8b801654f038" satisfied condition "success or failure"
Dec  3 14:57:00.082: INFO: Trying to get logs from node izgw8afzp8040eoqk0qbhxz pod downwardapi-volume-0778d6a4-713f-49d4-a742-8b801654f038 container client-container: <nil>
STEP: delete the pod
Dec  3 14:57:00.104: INFO: Waiting for pod downwardapi-volume-0778d6a4-713f-49d4-a742-8b801654f038 to disappear
Dec  3 14:57:00.109: INFO: Pod downwardapi-volume-0778d6a4-713f-49d4-a742-8b801654f038 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 14:57:00.109: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5923" for this suite.
Dec  3 14:57:06.130: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:57:06.293: INFO: namespace downward-api-5923 deletion completed in 6.176118287s
â€¢SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 14:57:06.293: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6228
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating the pod
Dec  3 14:57:08.989: INFO: Successfully updated pod "labelsupdate30fd5579-3cc1-4b0e-be1f-af2d82f0193e"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 14:57:13.032: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6228" for this suite.
Dec  3 14:57:35.055: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:57:35.214: INFO: namespace projected-6228 deletion completed in 22.174135147s
â€¢SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 14:57:35.215: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-1964
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Dec  3 14:57:35.389: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:watch-1964,SelfLink:/api/v1/namespaces/watch-1964/configmaps/e2e-watch-test-resource-version,UID:37fc0f1e-231b-4e18-ae2b-097d5686a66f,ResourceVersion:8355,Generation:0,CreationTimestamp:2019-12-03 14:57:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec  3 14:57:35.390: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:watch-1964,SelfLink:/api/v1/namespaces/watch-1964/configmaps/e2e-watch-test-resource-version,UID:37fc0f1e-231b-4e18-ae2b-097d5686a66f,ResourceVersion:8356,Generation:0,CreationTimestamp:2019-12-03 14:57:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 14:57:35.390: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-1964" for this suite.
Dec  3 14:57:41.408: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:57:41.611: INFO: namespace watch-1964 deletion completed in 6.216886666s
â€¢SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 14:57:41.612: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-4021
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1612
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Dec  3 14:57:41.756: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmwqx-5aq.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-4021'
Dec  3 14:57:42.078: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Dec  3 14:57:42.078: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
STEP: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1617
Dec  3 14:57:42.083: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmwqx-5aq.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config delete jobs e2e-test-nginx-job --namespace=kubectl-4021'
Dec  3 14:57:42.174: INFO: stderr: ""
Dec  3 14:57:42.174: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 14:57:42.174: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4021" for this suite.
Dec  3 14:57:48.193: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:57:48.364: INFO: namespace kubectl-4021 deletion completed in 6.185476097s
â€¢SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 14:57:48.365: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1696
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name projected-secret-test-41cd703b-1391-45ea-b198-9f0151afd08e
STEP: Creating a pod to test consume secrets
Dec  3 14:57:48.523: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-593dc8ef-a195-460a-9548-52212e197a27" in namespace "projected-1696" to be "success or failure"
Dec  3 14:57:48.527: INFO: Pod "pod-projected-secrets-593dc8ef-a195-460a-9548-52212e197a27": Phase="Pending", Reason="", readiness=false. Elapsed: 4.147599ms
Dec  3 14:57:50.532: INFO: Pod "pod-projected-secrets-593dc8ef-a195-460a-9548-52212e197a27": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009656248s
STEP: Saw pod success
Dec  3 14:57:50.533: INFO: Pod "pod-projected-secrets-593dc8ef-a195-460a-9548-52212e197a27" satisfied condition "success or failure"
Dec  3 14:57:50.537: INFO: Trying to get logs from node izgw8afzp8040eoqk0qbhxz pod pod-projected-secrets-593dc8ef-a195-460a-9548-52212e197a27 container secret-volume-test: <nil>
STEP: delete the pod
Dec  3 14:57:50.558: INFO: Waiting for pod pod-projected-secrets-593dc8ef-a195-460a-9548-52212e197a27 to disappear
Dec  3 14:57:50.562: INFO: Pod pod-projected-secrets-593dc8ef-a195-460a-9548-52212e197a27 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 14:57:50.562: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1696" for this suite.
Dec  3 14:57:56.585: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:57:56.748: INFO: namespace projected-1696 deletion completed in 6.178143569s
â€¢SSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 14:57:56.749: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-2668
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:63
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Dec  3 14:58:00.958: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec  3 14:58:00.962: INFO: Pod pod-with-poststart-http-hook still exists
Dec  3 14:58:02.962: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec  3 14:58:02.967: INFO: Pod pod-with-poststart-http-hook still exists
Dec  3 14:58:04.962: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec  3 14:58:04.967: INFO: Pod pod-with-poststart-http-hook still exists
Dec  3 14:58:06.962: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec  3 14:58:06.967: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 14:58:06.967: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-2668" for this suite.
Dec  3 14:58:28.989: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:58:29.153: INFO: namespace container-lifecycle-hook-2668 deletion completed in 22.178398795s
â€¢SSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 14:58:29.154: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-4789
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-map-99c5f756-b665-42b4-97fc-9f353214834f
STEP: Creating a pod to test consume configMaps
Dec  3 14:58:29.317: INFO: Waiting up to 5m0s for pod "pod-configmaps-9b3640cf-14cf-42b5-aea3-0f32d58791f3" in namespace "configmap-4789" to be "success or failure"
Dec  3 14:58:29.321: INFO: Pod "pod-configmaps-9b3640cf-14cf-42b5-aea3-0f32d58791f3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.237997ms
Dec  3 14:58:31.327: INFO: Pod "pod-configmaps-9b3640cf-14cf-42b5-aea3-0f32d58791f3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00942698s
STEP: Saw pod success
Dec  3 14:58:31.327: INFO: Pod "pod-configmaps-9b3640cf-14cf-42b5-aea3-0f32d58791f3" satisfied condition "success or failure"
Dec  3 14:58:31.331: INFO: Trying to get logs from node izgw8afzp8040eoqk0qbhxz pod pod-configmaps-9b3640cf-14cf-42b5-aea3-0f32d58791f3 container configmap-volume-test: <nil>
STEP: delete the pod
Dec  3 14:58:31.357: INFO: Waiting for pod pod-configmaps-9b3640cf-14cf-42b5-aea3-0f32d58791f3 to disappear
Dec  3 14:58:31.361: INFO: Pod pod-configmaps-9b3640cf-14cf-42b5-aea3-0f32d58791f3 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 14:58:31.361: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4789" for this suite.
Dec  3 14:58:37.382: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:58:37.544: INFO: namespace configmap-4789 deletion completed in 6.17568402s
â€¢SSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 14:58:37.544: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-3061
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Dec  3 14:58:37.698: INFO: Pod name rollover-pod: Found 0 pods out of 1
Dec  3 14:58:42.704: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Dec  3 14:58:42.704: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Dec  3 14:58:44.710: INFO: Creating deployment "test-rollover-deployment"
Dec  3 14:58:44.719: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Dec  3 14:58:46.729: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Dec  3 14:58:46.738: INFO: Ensure that both replica sets have 1 created replica
Dec  3 14:58:46.747: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Dec  3 14:58:46.756: INFO: Updating deployment test-rollover-deployment
Dec  3 14:58:46.756: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Dec  3 14:58:48.765: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Dec  3 14:58:48.774: INFO: Make sure deployment "test-rollover-deployment" is complete
Dec  3 14:58:48.784: INFO: all replica sets need to contain the pod-template-hash label
Dec  3 14:58:48.784: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710981924, loc:(*time.Location)(0x7ed1a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710981924, loc:(*time.Location)(0x7ed1a20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710981928, loc:(*time.Location)(0x7ed1a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710981924, loc:(*time.Location)(0x7ed1a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  3 14:58:50.794: INFO: all replica sets need to contain the pod-template-hash label
Dec  3 14:58:50.794: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710981924, loc:(*time.Location)(0x7ed1a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710981924, loc:(*time.Location)(0x7ed1a20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710981928, loc:(*time.Location)(0x7ed1a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710981924, loc:(*time.Location)(0x7ed1a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  3 14:58:52.794: INFO: all replica sets need to contain the pod-template-hash label
Dec  3 14:58:52.794: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710981924, loc:(*time.Location)(0x7ed1a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710981924, loc:(*time.Location)(0x7ed1a20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710981928, loc:(*time.Location)(0x7ed1a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710981924, loc:(*time.Location)(0x7ed1a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  3 14:58:54.794: INFO: all replica sets need to contain the pod-template-hash label
Dec  3 14:58:54.794: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710981924, loc:(*time.Location)(0x7ed1a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710981924, loc:(*time.Location)(0x7ed1a20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710981928, loc:(*time.Location)(0x7ed1a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710981924, loc:(*time.Location)(0x7ed1a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  3 14:58:56.795: INFO: all replica sets need to contain the pod-template-hash label
Dec  3 14:58:56.795: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710981924, loc:(*time.Location)(0x7ed1a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710981924, loc:(*time.Location)(0x7ed1a20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710981928, loc:(*time.Location)(0x7ed1a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710981924, loc:(*time.Location)(0x7ed1a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  3 14:58:58.795: INFO: 
Dec  3 14:58:58.795: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
Dec  3 14:58:58.808: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment,GenerateName:,Namespace:deployment-3061,SelfLink:/apis/apps/v1/namespaces/deployment-3061/deployments/test-rollover-deployment,UID:40c77246-fc7a-4373-bee1-60781b377567,ResourceVersion:8762,Generation:2,CreationTimestamp:2019-12-03 14:58:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-12-03 14:58:44 +0000 UTC 2019-12-03 14:58:44 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-12-03 14:58:58 +0000 UTC 2019-12-03 14:58:44 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rollover-deployment-854595fc44" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Dec  3 14:58:58.813: INFO: New ReplicaSet "test-rollover-deployment-854595fc44" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-854595fc44,GenerateName:,Namespace:deployment-3061,SelfLink:/apis/apps/v1/namespaces/deployment-3061/replicasets/test-rollover-deployment-854595fc44,UID:db5f88d1-d23f-4238-bd7b-ffcf667ba96b,ResourceVersion:8755,Generation:2,CreationTimestamp:2019-12-03 14:58:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 854595fc44,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 40c77246-fc7a-4373-bee1-60781b377567 0xc0031c11e7 0xc0031c11e8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 854595fc44,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 854595fc44,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Dec  3 14:58:58.813: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Dec  3 14:58:58.814: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-controller,GenerateName:,Namespace:deployment-3061,SelfLink:/apis/apps/v1/namespaces/deployment-3061/replicasets/test-rollover-controller,UID:5721f372-b567-41bd-8d02-692e8a760365,ResourceVersion:8761,Generation:2,CreationTimestamp:2019-12-03 14:58:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 40c77246-fc7a-4373-bee1-60781b377567 0xc0031c110f 0xc0031c1120}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Dec  3 14:58:58.814: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-9b8b997cf,GenerateName:,Namespace:deployment-3061,SelfLink:/apis/apps/v1/namespaces/deployment-3061/replicasets/test-rollover-deployment-9b8b997cf,UID:c4602329-e3c4-4d4c-bc32-b31a39e30a6f,ResourceVersion:8708,Generation:2,CreationTimestamp:2019-12-03 14:58:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 9b8b997cf,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 40c77246-fc7a-4373-bee1-60781b377567 0xc0031c12a0 0xc0031c12a1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 9b8b997cf,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 9b8b997cf,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Dec  3 14:58:58.819: INFO: Pod "test-rollover-deployment-854595fc44-kh4hw" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-854595fc44-kh4hw,GenerateName:test-rollover-deployment-854595fc44-,Namespace:deployment-3061,SelfLink:/api/v1/namespaces/deployment-3061/pods/test-rollover-deployment-854595fc44-kh4hw,UID:6f63d3bc-2bf9-4d11-83ce-217f31663e4a,ResourceVersion:8721,Generation:0,CreationTimestamp:2019-12-03 14:58:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 854595fc44,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.64.1.73/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-rollover-deployment-854595fc44 db5f88d1-d23f-4238-bd7b-ffcf667ba96b 0xc0031c1e67 0xc0031c1e68}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-wfhjz {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wfhjz,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-wfhjz true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw8afzp8040eoqk0qbhxz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0031c1ed0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0031c1ef0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:58:46 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:58:48 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:58:48 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:58:46 +0000 UTC  }],Message:,Reason:,HostIP:10.250.31.244,PodIP:100.64.1.73,StartTime:2019-12-03 14:58:46 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-12-03 14:58:47 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://f852b21b32cb460550f940ca9546a4514fd623f48c909aafa9b02e086e6152e9}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 14:58:58.819: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-3061" for this suite.
Dec  3 14:59:04.841: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:59:05.052: INFO: namespace deployment-3061 deletion completed in 6.225417309s
â€¢SSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 14:59:05.052: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-2505
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating the pod
Dec  3 14:59:07.744: INFO: Successfully updated pod "labelsupdate397ba8d6-2de7-421d-8308-125dffdd1337"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 14:59:09.771: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2505" for this suite.
Dec  3 14:59:31.793: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:59:31.996: INFO: namespace downward-api-2505 deletion completed in 22.216700806s
â€¢SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 14:59:31.997: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-4675
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Dec  3 14:59:32.179: INFO: Number of nodes with available pods: 0
Dec  3 14:59:32.180: INFO: Node izgw8afzp8040eoqk0qbhwz is running more than one daemon pod
Dec  3 14:59:33.192: INFO: Number of nodes with available pods: 0
Dec  3 14:59:33.192: INFO: Node izgw8afzp8040eoqk0qbhwz is running more than one daemon pod
Dec  3 14:59:34.193: INFO: Number of nodes with available pods: 2
Dec  3 14:59:34.193: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Dec  3 14:59:34.218: INFO: Number of nodes with available pods: 1
Dec  3 14:59:34.218: INFO: Node izgw8afzp8040eoqk0qbhwz is running more than one daemon pod
Dec  3 14:59:35.231: INFO: Number of nodes with available pods: 1
Dec  3 14:59:35.231: INFO: Node izgw8afzp8040eoqk0qbhwz is running more than one daemon pod
Dec  3 14:59:36.231: INFO: Number of nodes with available pods: 2
Dec  3 14:59:36.231: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-4675, will wait for the garbage collector to delete the pods
Dec  3 14:59:36.301: INFO: Deleting DaemonSet.extensions daemon-set took: 6.820819ms
Dec  3 14:59:36.801: INFO: Terminating DaemonSet.extensions daemon-set pods took: 500.388359ms
Dec  3 14:59:39.707: INFO: Number of nodes with available pods: 0
Dec  3 14:59:39.707: INFO: Number of running nodes: 0, number of available pods: 0
Dec  3 14:59:39.711: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-4675/daemonsets","resourceVersion":"8961"},"items":null}

Dec  3 14:59:39.716: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-4675/pods","resourceVersion":"8961"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 14:59:39.731: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-4675" for this suite.
Dec  3 14:59:45.749: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:59:45.956: INFO: namespace daemonsets-4675 deletion completed in 6.220316412s
â€¢SSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 14:59:45.956: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-4350
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Dec  3 14:59:46.109: INFO: Waiting up to 5m0s for pod "downwardapi-volume-bb2ead9d-e25c-44c0-884a-7ddc13219263" in namespace "projected-4350" to be "success or failure"
Dec  3 14:59:46.113: INFO: Pod "downwardapi-volume-bb2ead9d-e25c-44c0-884a-7ddc13219263": Phase="Pending", Reason="", readiness=false. Elapsed: 4.51743ms
Dec  3 14:59:48.119: INFO: Pod "downwardapi-volume-bb2ead9d-e25c-44c0-884a-7ddc13219263": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00995417s
STEP: Saw pod success
Dec  3 14:59:48.119: INFO: Pod "downwardapi-volume-bb2ead9d-e25c-44c0-884a-7ddc13219263" satisfied condition "success or failure"
Dec  3 14:59:48.123: INFO: Trying to get logs from node izgw8afzp8040eoqk0qbhxz pod downwardapi-volume-bb2ead9d-e25c-44c0-884a-7ddc13219263 container client-container: <nil>
STEP: delete the pod
Dec  3 14:59:48.144: INFO: Waiting for pod downwardapi-volume-bb2ead9d-e25c-44c0-884a-7ddc13219263 to disappear
Dec  3 14:59:48.148: INFO: Pod downwardapi-volume-bb2ead9d-e25c-44c0-884a-7ddc13219263 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 14:59:48.148: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4350" for this suite.
Dec  3 14:59:54.170: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:59:54.338: INFO: namespace projected-4350 deletion completed in 6.181916271s
â€¢SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 14:59:54.338: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-5493
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:63
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Dec  3 14:59:58.531: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  3 14:59:58.536: INFO: Pod pod-with-prestop-exec-hook still exists
Dec  3 15:00:00.536: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  3 15:00:00.542: INFO: Pod pod-with-prestop-exec-hook still exists
Dec  3 15:00:02.536: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  3 15:00:02.542: INFO: Pod pod-with-prestop-exec-hook still exists
Dec  3 15:00:04.536: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  3 15:00:04.541: INFO: Pod pod-with-prestop-exec-hook still exists
Dec  3 15:00:06.536: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  3 15:00:06.541: INFO: Pod pod-with-prestop-exec-hook still exists
Dec  3 15:00:08.536: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  3 15:00:08.543: INFO: Pod pod-with-prestop-exec-hook still exists
Dec  3 15:00:10.536: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  3 15:00:10.541: INFO: Pod pod-with-prestop-exec-hook still exists
Dec  3 15:00:12.536: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  3 15:00:12.542: INFO: Pod pod-with-prestop-exec-hook still exists
Dec  3 15:00:14.536: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  3 15:00:14.542: INFO: Pod pod-with-prestop-exec-hook still exists
Dec  3 15:00:16.536: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  3 15:00:16.541: INFO: Pod pod-with-prestop-exec-hook still exists
Dec  3 15:00:18.536: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  3 15:00:18.541: INFO: Pod pod-with-prestop-exec-hook still exists
Dec  3 15:00:20.536: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  3 15:00:20.542: INFO: Pod pod-with-prestop-exec-hook still exists
Dec  3 15:00:22.536: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  3 15:00:22.541: INFO: Pod pod-with-prestop-exec-hook still exists
Dec  3 15:00:24.536: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  3 15:00:24.541: INFO: Pod pod-with-prestop-exec-hook still exists
Dec  3 15:00:26.536: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  3 15:00:26.541: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:00:26.555: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-5493" for this suite.
Dec  3 15:00:48.578: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:00:48.786: INFO: namespace container-lifecycle-hook-5493 deletion completed in 22.223525251s
â€¢SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:00:48.787: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8894
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-aaa34e22-004c-49a3-a234-841eb079570e
STEP: Creating a pod to test consume configMaps
Dec  3 15:00:48.944: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-f1508522-7e08-4ab0-be94-aaa3e67332bf" in namespace "projected-8894" to be "success or failure"
Dec  3 15:00:48.948: INFO: Pod "pod-projected-configmaps-f1508522-7e08-4ab0-be94-aaa3e67332bf": Phase="Pending", Reason="", readiness=false. Elapsed: 4.544923ms
Dec  3 15:00:50.954: INFO: Pod "pod-projected-configmaps-f1508522-7e08-4ab0-be94-aaa3e67332bf": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009823027s
Dec  3 15:00:52.959: INFO: Pod "pod-projected-configmaps-f1508522-7e08-4ab0-be94-aaa3e67332bf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015314957s
STEP: Saw pod success
Dec  3 15:00:52.959: INFO: Pod "pod-projected-configmaps-f1508522-7e08-4ab0-be94-aaa3e67332bf" satisfied condition "success or failure"
Dec  3 15:00:52.964: INFO: Trying to get logs from node izgw8afzp8040eoqk0qbhxz pod pod-projected-configmaps-f1508522-7e08-4ab0-be94-aaa3e67332bf container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec  3 15:00:52.984: INFO: Waiting for pod pod-projected-configmaps-f1508522-7e08-4ab0-be94-aaa3e67332bf to disappear
Dec  3 15:00:52.988: INFO: Pod pod-projected-configmaps-f1508522-7e08-4ab0-be94-aaa3e67332bf no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:00:52.988: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8894" for this suite.
Dec  3 15:00:59.011: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:00:59.172: INFO: namespace projected-8894 deletion completed in 6.175308452s
â€¢SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:00:59.173: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-1107
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Dec  3 15:00:59.331: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f4367388-6ece-4f1a-9fd6-4cbad2f194ae" in namespace "downward-api-1107" to be "success or failure"
Dec  3 15:00:59.336: INFO: Pod "downwardapi-volume-f4367388-6ece-4f1a-9fd6-4cbad2f194ae": Phase="Pending", Reason="", readiness=false. Elapsed: 4.113573ms
Dec  3 15:01:01.341: INFO: Pod "downwardapi-volume-f4367388-6ece-4f1a-9fd6-4cbad2f194ae": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009705547s
STEP: Saw pod success
Dec  3 15:01:01.341: INFO: Pod "downwardapi-volume-f4367388-6ece-4f1a-9fd6-4cbad2f194ae" satisfied condition "success or failure"
Dec  3 15:01:01.346: INFO: Trying to get logs from node izgw8afzp8040eoqk0qbhxz pod downwardapi-volume-f4367388-6ece-4f1a-9fd6-4cbad2f194ae container client-container: <nil>
STEP: delete the pod
Dec  3 15:01:01.367: INFO: Waiting for pod downwardapi-volume-f4367388-6ece-4f1a-9fd6-4cbad2f194ae to disappear
Dec  3 15:01:01.371: INFO: Pod downwardapi-volume-f4367388-6ece-4f1a-9fd6-4cbad2f194ae no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:01:01.371: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1107" for this suite.
Dec  3 15:01:07.393: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:01:07.558: INFO: namespace downward-api-1107 deletion completed in 6.179005773s
â€¢SSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:01:07.558: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-111
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Dec  3 15:01:07.710: INFO: Waiting up to 5m0s for pod "downwardapi-volume-491edf21-4872-4a95-9d56-7cb2fb69aea4" in namespace "downward-api-111" to be "success or failure"
Dec  3 15:01:07.714: INFO: Pod "downwardapi-volume-491edf21-4872-4a95-9d56-7cb2fb69aea4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.203341ms
Dec  3 15:01:09.720: INFO: Pod "downwardapi-volume-491edf21-4872-4a95-9d56-7cb2fb69aea4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010046571s
STEP: Saw pod success
Dec  3 15:01:09.720: INFO: Pod "downwardapi-volume-491edf21-4872-4a95-9d56-7cb2fb69aea4" satisfied condition "success or failure"
Dec  3 15:01:09.725: INFO: Trying to get logs from node izgw8afzp8040eoqk0qbhxz pod downwardapi-volume-491edf21-4872-4a95-9d56-7cb2fb69aea4 container client-container: <nil>
STEP: delete the pod
Dec  3 15:01:09.746: INFO: Waiting for pod downwardapi-volume-491edf21-4872-4a95-9d56-7cb2fb69aea4 to disappear
Dec  3 15:01:09.750: INFO: Pod downwardapi-volume-491edf21-4872-4a95-9d56-7cb2fb69aea4 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:01:09.750: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-111" for this suite.
Dec  3 15:01:15.772: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:01:15.940: INFO: namespace downward-api-111 deletion completed in 6.181923707s
â€¢SSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:01:15.940: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-1836
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the container
STEP: wait for the container to reach Failed
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Dec  3 15:01:18.113: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:01:18.126: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-1836" for this suite.
Dec  3 15:01:24.148: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:01:24.358: INFO: namespace container-runtime-1836 deletion completed in 6.224671018s
â€¢S
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:01:24.358: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-4911
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-map-b03a3cbb-efe1-4142-a8c2-5675e8d6e503
STEP: Creating a pod to test consume secrets
Dec  3 15:01:24.515: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-d72bd9cb-b099-4468-ba37-37c9945535f9" in namespace "projected-4911" to be "success or failure"
Dec  3 15:01:24.520: INFO: Pod "pod-projected-secrets-d72bd9cb-b099-4468-ba37-37c9945535f9": Phase="Pending", Reason="", readiness=false. Elapsed: 4.196923ms
Dec  3 15:01:26.525: INFO: Pod "pod-projected-secrets-d72bd9cb-b099-4468-ba37-37c9945535f9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009318577s
STEP: Saw pod success
Dec  3 15:01:26.525: INFO: Pod "pod-projected-secrets-d72bd9cb-b099-4468-ba37-37c9945535f9" satisfied condition "success or failure"
Dec  3 15:01:26.529: INFO: Trying to get logs from node izgw8afzp8040eoqk0qbhxz pod pod-projected-secrets-d72bd9cb-b099-4468-ba37-37c9945535f9 container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec  3 15:01:26.553: INFO: Waiting for pod pod-projected-secrets-d72bd9cb-b099-4468-ba37-37c9945535f9 to disappear
Dec  3 15:01:26.557: INFO: Pod pod-projected-secrets-d72bd9cb-b099-4468-ba37-37c9945535f9 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:01:26.557: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4911" for this suite.
Dec  3 15:01:32.578: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:01:32.739: INFO: namespace projected-4911 deletion completed in 6.174440956s
â€¢SSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:01:32.739: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-4006
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Dec  3 15:01:32.891: INFO: Waiting up to 5m0s for pod "downward-api-45f1eda3-ea7d-43a2-9ca7-962d1f05d493" in namespace "downward-api-4006" to be "success or failure"
Dec  3 15:01:32.896: INFO: Pod "downward-api-45f1eda3-ea7d-43a2-9ca7-962d1f05d493": Phase="Pending", Reason="", readiness=false. Elapsed: 4.438662ms
Dec  3 15:01:34.901: INFO: Pod "downward-api-45f1eda3-ea7d-43a2-9ca7-962d1f05d493": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010200364s
STEP: Saw pod success
Dec  3 15:01:34.902: INFO: Pod "downward-api-45f1eda3-ea7d-43a2-9ca7-962d1f05d493" satisfied condition "success or failure"
Dec  3 15:01:34.906: INFO: Trying to get logs from node izgw8afzp8040eoqk0qbhxz pod downward-api-45f1eda3-ea7d-43a2-9ca7-962d1f05d493 container dapi-container: <nil>
STEP: delete the pod
Dec  3 15:01:34.927: INFO: Waiting for pod downward-api-45f1eda3-ea7d-43a2-9ca7-962d1f05d493 to disappear
Dec  3 15:01:34.931: INFO: Pod downward-api-45f1eda3-ea7d-43a2-9ca7-962d1f05d493 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:01:34.931: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4006" for this suite.
Dec  3 15:01:40.952: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:01:41.125: INFO: namespace downward-api-4006 deletion completed in 6.187021679s
â€¢SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:01:41.126: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-3977
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secret-namespace-3147
STEP: Creating secret with name secret-test-c7033d54-b9aa-49b8-a167-52f9949e9ffa
STEP: Creating a pod to test consume secrets
Dec  3 15:01:41.427: INFO: Waiting up to 5m0s for pod "pod-secrets-958d65c8-194c-403c-9ab3-cba98821f544" in namespace "secrets-3977" to be "success or failure"
Dec  3 15:01:41.432: INFO: Pod "pod-secrets-958d65c8-194c-403c-9ab3-cba98821f544": Phase="Pending", Reason="", readiness=false. Elapsed: 4.209001ms
Dec  3 15:01:43.437: INFO: Pod "pod-secrets-958d65c8-194c-403c-9ab3-cba98821f544": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009405723s
STEP: Saw pod success
Dec  3 15:01:43.437: INFO: Pod "pod-secrets-958d65c8-194c-403c-9ab3-cba98821f544" satisfied condition "success or failure"
Dec  3 15:01:43.441: INFO: Trying to get logs from node izgw8afzp8040eoqk0qbhxz pod pod-secrets-958d65c8-194c-403c-9ab3-cba98821f544 container secret-volume-test: <nil>
STEP: delete the pod
Dec  3 15:01:43.464: INFO: Waiting for pod pod-secrets-958d65c8-194c-403c-9ab3-cba98821f544 to disappear
Dec  3 15:01:43.469: INFO: Pod pod-secrets-958d65c8-194c-403c-9ab3-cba98821f544 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:01:43.469: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3977" for this suite.
Dec  3 15:01:49.491: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:01:49.652: INFO: namespace secrets-3977 deletion completed in 6.175625473s
STEP: Destroying namespace "secret-namespace-3147" for this suite.
Dec  3 15:01:55.666: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:01:55.831: INFO: namespace secret-namespace-3147 deletion completed in 6.178452479s
â€¢SSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:01:55.831: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-305
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:01:55.982: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-305" for this suite.
Dec  3 15:02:02.003: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:02:02.218: INFO: namespace services-305 deletion completed in 6.230809268s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:92
â€¢SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:02:02.219: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-8330
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:03:02.379: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-8330" for this suite.
Dec  3 15:03:24.402: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:03:24.576: INFO: namespace container-probe-8330 deletion completed in 22.189068163s
â€¢SSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:03:24.576: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-8019
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
Dec  3 15:03:24.725: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:03:27.894: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-8019" for this suite.
Dec  3 15:03:33.917: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:03:34.079: INFO: namespace init-container-8019 deletion completed in 6.176827355s
â€¢S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:03:34.079: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-589
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating Redis RC
Dec  3 15:03:34.223: INFO: namespace kubectl-589
Dec  3 15:03:34.223: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmwqx-5aq.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config create -f - --namespace=kubectl-589'
Dec  3 15:03:34.479: INFO: stderr: ""
Dec  3 15:03:34.479: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Dec  3 15:03:35.485: INFO: Selector matched 1 pods for map[app:redis]
Dec  3 15:03:35.485: INFO: Found 0 / 1
Dec  3 15:03:36.485: INFO: Selector matched 1 pods for map[app:redis]
Dec  3 15:03:36.485: INFO: Found 1 / 1
Dec  3 15:03:36.485: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Dec  3 15:03:36.489: INFO: Selector matched 1 pods for map[app:redis]
Dec  3 15:03:36.489: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Dec  3 15:03:36.489: INFO: wait on redis-master startup in kubectl-589 
Dec  3 15:03:36.489: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmwqx-5aq.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config logs redis-master-4zknj redis-master --namespace=kubectl-589'
Dec  3 15:03:36.650: INFO: stderr: ""
Dec  3 15:03:36.650: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 03 Dec 15:03:35.395 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 03 Dec 15:03:35.395 # Server started, Redis version 3.2.12\n1:M 03 Dec 15:03:35.395 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 03 Dec 15:03:35.395 * The server is now ready to accept connections on port 6379\n"
STEP: exposing RC
Dec  3 15:03:36.650: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmwqx-5aq.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=kubectl-589'
Dec  3 15:03:36.756: INFO: stderr: ""
Dec  3 15:03:36.756: INFO: stdout: "service/rm2 exposed\n"
Dec  3 15:03:36.761: INFO: Service rm2 in namespace kubectl-589 found.
STEP: exposing service
Dec  3 15:03:38.770: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmwqx-5aq.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=kubectl-589'
Dec  3 15:03:38.927: INFO: stderr: ""
Dec  3 15:03:38.927: INFO: stdout: "service/rm3 exposed\n"
Dec  3 15:03:38.931: INFO: Service rm3 in namespace kubectl-589 found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:03:40.941: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-589" for this suite.
Dec  3 15:04:02.963: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:04:03.168: INFO: namespace kubectl-589 deletion completed in 22.219447466s
â€¢SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:04:03.169: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-6138
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Dec  3 15:04:03.314: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmwqx-5aq.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config version'
Dec  3 15:04:03.425: INFO: stderr: ""
Dec  3 15:04:03.425: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"15\", GitVersion:\"v1.15.6\", GitCommit:\"7015f71e75f670eb9e7ebd4b5749639d42e20079\", GitTreeState:\"clean\", BuildDate:\"2019-11-13T11:20:18Z\", GoVersion:\"go1.12.12\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"15\", GitVersion:\"v1.15.6\", GitCommit:\"7015f71e75f670eb9e7ebd4b5749639d42e20079\", GitTreeState:\"clean\", BuildDate:\"2019-11-13T11:11:50Z\", GoVersion:\"go1.12.12\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:04:03.425: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6138" for this suite.
Dec  3 15:04:09.446: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:04:09.608: INFO: namespace kubectl-6138 deletion completed in 6.177725222s
â€¢SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:04:09.609: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-783
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:81
Dec  3 15:04:09.755: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Dec  3 15:04:09.765: INFO: Waiting for terminating namespaces to be deleted...
Dec  3 15:04:09.769: INFO: 
Logging pods the kubelet thinks is on node izgw8afzp8040eoqk0qbhwz before test
Dec  3 15:04:09.807: INFO: blackbox-exporter-c87bdd467-vpznr from kube-system started at 2019-12-03 14:26:11 +0000 UTC (1 container statuses recorded)
Dec  3 15:04:09.807: INFO: 	Container blackbox-exporter ready: true, restart count 0
Dec  3 15:04:09.807: INFO: calico-typha-vertical-autoscaler-656557779f-vhn2k from kube-system started at 2019-12-03 14:26:51 +0000 UTC (1 container statuses recorded)
Dec  3 15:04:09.807: INFO: 	Container autoscaler ready: true, restart count 3
Dec  3 15:04:09.807: INFO: kube-proxy-6sx94 from kube-system started at 2019-12-03 14:26:11 +0000 UTC (1 container statuses recorded)
Dec  3 15:04:09.807: INFO: 	Container kube-proxy ready: true, restart count 0
Dec  3 15:04:09.807: INFO: addons-kubernetes-dashboard-5c8d9945bc-8pg45 from kube-system started at 2019-12-03 14:26:51 +0000 UTC (1 container statuses recorded)
Dec  3 15:04:09.807: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Dec  3 15:04:09.807: INFO: metrics-server-85dc4959bc-8q2rm from kube-system started at 2019-12-03 14:26:53 +0000 UTC (1 container statuses recorded)
Dec  3 15:04:09.807: INFO: 	Container metrics-server ready: true, restart count 0
Dec  3 15:04:09.807: INFO: node-problem-detector-zgkv5 from kube-system started at 2019-12-03 14:26:11 +0000 UTC (1 container statuses recorded)
Dec  3 15:04:09.807: INFO: 	Container node-problem-detector ready: true, restart count 0
Dec  3 15:04:09.807: INFO: coredns-858b686868-4hmrg from kube-system started at 2019-12-03 14:26:51 +0000 UTC (1 container statuses recorded)
Dec  3 15:04:09.807: INFO: 	Container coredns ready: true, restart count 0
Dec  3 15:04:09.807: INFO: calico-node-7g9r2 from kube-system started at 2019-12-03 14:26:11 +0000 UTC (1 container statuses recorded)
Dec  3 15:04:09.807: INFO: 	Container calico-node ready: true, restart count 0
Dec  3 15:04:09.807: INFO: addons-nginx-ingress-nginx-ingress-k8s-backend-88d6cff74-c9t7s from kube-system started at 2019-12-03 14:26:51 +0000 UTC (1 container statuses recorded)
Dec  3 15:04:09.807: INFO: 	Container nginx-ingress-nginx-ingress-k8s-backend ready: true, restart count 0
Dec  3 15:04:09.807: INFO: csi-disk-plugin-alicloud-zkswz from kube-system started at 2019-12-03 14:26:51 +0000 UTC (2 container statuses recorded)
Dec  3 15:04:09.807: INFO: 	Container csi-diskplugin ready: true, restart count 0
Dec  3 15:04:09.807: INFO: 	Container driver-registrar ready: true, restart count 0
Dec  3 15:04:09.807: INFO: vpn-shoot-6568b69f46-dhptx from kube-system started at 2019-12-03 14:26:53 +0000 UTC (1 container statuses recorded)
Dec  3 15:04:09.807: INFO: 	Container vpn-shoot ready: true, restart count 0
Dec  3 15:04:09.807: INFO: node-exporter-mt7nx from kube-system started at 2019-12-03 14:26:11 +0000 UTC (1 container statuses recorded)
Dec  3 15:04:09.807: INFO: 	Container node-exporter ready: true, restart count 0
Dec  3 15:04:09.807: INFO: calico-kube-controllers-5d785bc598-n44xt from kube-system started at 2019-12-03 14:26:51 +0000 UTC (1 container statuses recorded)
Dec  3 15:04:09.807: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Dec  3 15:04:09.807: INFO: coredns-858b686868-b8rw9 from kube-system started at 2019-12-03 14:26:51 +0000 UTC (1 container statuses recorded)
Dec  3 15:04:09.807: INFO: 	Container coredns ready: true, restart count 0
Dec  3 15:04:09.807: INFO: addons-nginx-ingress-controller-8468678b64-fjw65 from kube-system started at 2019-12-03 14:26:51 +0000 UTC (1 container statuses recorded)
Dec  3 15:04:09.807: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Dec  3 15:04:09.807: INFO: calico-typha-horizontal-autoscaler-554dfbfdd7-hrqhh from kube-system started at 2019-12-03 14:26:51 +0000 UTC (1 container statuses recorded)
Dec  3 15:04:09.807: INFO: 	Container autoscaler ready: true, restart count 0
Dec  3 15:04:09.807: INFO: 
Logging pods the kubelet thinks is on node izgw8afzp8040eoqk0qbhxz before test
Dec  3 15:04:09.861: INFO: node-problem-detector-c9wdn from kube-system started at 2019-12-03 14:26:15 +0000 UTC (1 container statuses recorded)
Dec  3 15:04:09.861: INFO: 	Container node-problem-detector ready: true, restart count 0
Dec  3 15:04:09.862: INFO: csi-disk-plugin-alicloud-fqxvx from kube-system started at 2019-12-03 14:26:55 +0000 UTC (2 container statuses recorded)
Dec  3 15:04:09.862: INFO: 	Container csi-diskplugin ready: true, restart count 0
Dec  3 15:04:09.862: INFO: 	Container driver-registrar ready: true, restart count 0
Dec  3 15:04:09.862: INFO: calico-typha-deploy-5547c4cdc6-hndl5 from kube-system started at 2019-12-03 14:29:45 +0000 UTC (1 container statuses recorded)
Dec  3 15:04:09.862: INFO: 	Container calico-typha ready: true, restart count 0
Dec  3 15:04:09.862: INFO: node-exporter-9jl8n from kube-system started at 2019-12-03 14:26:15 +0000 UTC (1 container statuses recorded)
Dec  3 15:04:09.862: INFO: 	Container node-exporter ready: true, restart count 0
Dec  3 15:04:09.862: INFO: kube-proxy-t75hh from kube-system started at 2019-12-03 14:26:15 +0000 UTC (1 container statuses recorded)
Dec  3 15:04:09.862: INFO: 	Container kube-proxy ready: true, restart count 0
Dec  3 15:04:09.862: INFO: calico-node-4fgj7 from kube-system started at 2019-12-03 14:26:15 +0000 UTC (1 container statuses recorded)
Dec  3 15:04:09.862: INFO: 	Container calico-node ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.15dce4b84ce44567], Reason = [FailedScheduling], Message = [0/2 nodes are available: 2 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:04:10.895: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-783" for this suite.
Dec  3 15:04:16.918: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:04:17.080: INFO: namespace sched-pred-783 deletion completed in 6.177254059s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:72
â€¢SSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:04:17.081: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-9729
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Dec  3 15:04:17.236: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Dec  3 15:04:22.242: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Dec  3 15:04:22.242: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
Dec  3 15:04:24.283: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment,GenerateName:,Namespace:deployment-9729,SelfLink:/apis/apps/v1/namespaces/deployment-9729/deployments/test-cleanup-deployment,UID:de363f2b-a0ce-4f14-8729-7894ab224799,ResourceVersion:10164,Generation:1,CreationTimestamp:2019-12-03 15:04:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 1,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-12-03 15:04:22 +0000 UTC 2019-12-03 15:04:22 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-12-03 15:04:23 +0000 UTC 2019-12-03 15:04:22 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-cleanup-deployment-55bbcbc84c" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Dec  3 15:04:24.288: INFO: New ReplicaSet "test-cleanup-deployment-55bbcbc84c" of Deployment "test-cleanup-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-55bbcbc84c,GenerateName:,Namespace:deployment-9729,SelfLink:/apis/apps/v1/namespaces/deployment-9729/replicasets/test-cleanup-deployment-55bbcbc84c,UID:24b58ea8-e816-4ff0-8fd4-486280a39eb3,ResourceVersion:10157,Generation:1,CreationTimestamp:2019-12-03 15:04:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 55bbcbc84c,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment de363f2b-a0ce-4f14-8729-7894ab224799 0xc001ed5b57 0xc001ed5b58}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: 55bbcbc84c,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 55bbcbc84c,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Dec  3 15:04:24.293: INFO: Pod "test-cleanup-deployment-55bbcbc84c-jhlbp" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-55bbcbc84c-jhlbp,GenerateName:test-cleanup-deployment-55bbcbc84c-,Namespace:deployment-9729,SelfLink:/api/v1/namespaces/deployment-9729/pods/test-cleanup-deployment-55bbcbc84c-jhlbp,UID:f64d6c42-1e1f-4078-9bad-ec5f104fe045,ResourceVersion:10156,Generation:0,CreationTimestamp:2019-12-03 15:04:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 55bbcbc84c,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.64.1.90/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-deployment-55bbcbc84c 24b58ea8-e816-4ff0-8fd4-486280a39eb3 0xc001f8c737 0xc001f8c738}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-7zjqn {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7zjqn,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-7zjqn true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw8afzp8040eoqk0qbhxz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001f8c880} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001f8c8c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 15:04:22 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 15:04:23 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 15:04:23 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 15:04:22 +0000 UTC  }],Message:,Reason:,HostIP:10.250.31.244,PodIP:100.64.1.90,StartTime:2019-12-03 15:04:22 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-12-03 15:04:23 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://7ddd63969aee028909e22a25538515416664fad3dec8aa697128f489a79b78c8}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:04:24.293: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-9729" for this suite.
Dec  3 15:04:30.316: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:04:30.498: INFO: namespace deployment-9729 deletion completed in 6.197207771s
â€¢SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:04:30.499: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename events
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in events-828
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Dec  3 15:04:32.673: INFO: &Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-628bc3a3-efa7-45f3-8152-f48a9ec47631,GenerateName:,Namespace:events-828,SelfLink:/api/v1/namespaces/events-828/pods/send-events-628bc3a3-efa7-45f3-8152-f48a9ec47631,UID:e172dce8-e16f-4cf1-bb41-24310f8ceac0,ResourceVersion:10211,Generation:0,CreationTimestamp:2019-12-03 15:04:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 646589208,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.64.1.91/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-pdtzr {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-pdtzr,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-pdtzr true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw8afzp8040eoqk0qbhxz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002281c50} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002281c90}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 15:04:30 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 15:04:31 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 15:04:31 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 15:04:30 +0000 UTC  }],Message:,Reason:,HostIP:10.250.31.244,PodIP:100.64.1.91,StartTime:2019-12-03 15:04:30 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2019-12-03 15:04:31 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 docker-pullable://gcr.io/kubernetes-e2e-test-images/serve-hostname@sha256:bab70473a6d8ef65a22625dc9a1b0f0452e811530fdbe77e4408523460177ff1 docker://c45185a7c662fd7fd1a1553e42e40c0dca74f50de028093fe95231043b72eab7}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}

STEP: checking for scheduler event about the pod
Dec  3 15:04:34.679: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Dec  3 15:04:36.685: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:04:36.691: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-828" for this suite.
Dec  3 15:05:08.712: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:05:08.871: INFO: namespace events-828 deletion completed in 32.17244107s
â€¢SSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:05:08.871: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-2089
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Dec  3 15:05:09.015: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:05:09.564: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-2089" for this suite.
Dec  3 15:05:15.587: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:05:15.748: INFO: namespace custom-resource-definition-2089 deletion completed in 6.176140722s
â€¢SSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:05:15.749: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replicaset-3956
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Dec  3 15:05:18.933: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:05:18.947: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-3956" for this suite.
Dec  3 15:05:40.970: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:05:41.141: INFO: namespace replicaset-3956 deletion completed in 22.184783857s
â€¢SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Delete Grace Period 
  should be submitted and removed [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:05:41.142: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-8210
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Delete Grace Period
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:47
[It] should be submitted and removed [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: setting up selector
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
Dec  3 15:05:43.321: INFO: Asynchronously running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl kubectl --server=https://api.tmwqx-5aq.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config proxy -p 0'
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
Dec  3 15:05:58.469: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:05:58.475: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-8210" for this suite.
Dec  3 15:06:04.496: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:06:04.663: INFO: namespace pods-8210 deletion completed in 6.183472455s
â€¢SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:06:04.664: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-9409
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:06:07.851: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-9409" for this suite.
Dec  3 15:06:29.874: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:06:30.075: INFO: namespace replication-controller-9409 deletion completed in 22.215649391s
â€¢SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:06:30.076: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-4987
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Dec  3 15:06:32.757: INFO: Successfully updated pod "pod-update-f596c562-6fe7-47fd-b29e-3acaaa41d1bd"
STEP: verifying the updated pod is in kubernetes
Dec  3 15:06:32.766: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:06:32.766: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-4987" for this suite.
Dec  3 15:06:54.789: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:06:54.950: INFO: namespace pods-4987 deletion completed in 22.176535512s
â€¢SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:06:54.951: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-5931
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Dec  3 15:06:55.120: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"4b03c832-fa59-4313-b8d5-0055c42d06d5", Controller:(*bool)(0xc00327f28a), BlockOwnerDeletion:(*bool)(0xc00327f28b)}}
Dec  3 15:06:55.125: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"725ea4fc-52a5-4b3b-ab02-4e07b1ed2277", Controller:(*bool)(0xc001b28f26), BlockOwnerDeletion:(*bool)(0xc001b28f27)}}
Dec  3 15:06:55.131: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"318e225c-cb70-4989-ac7a-42465a05cc16", Controller:(*bool)(0xc0033ac806), BlockOwnerDeletion:(*bool)(0xc0033ac807)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:07:00.142: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-5931" for this suite.
Dec  3 15:07:06.164: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:07:06.325: INFO: namespace gc-5931 deletion completed in 6.175513661s
â€¢
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:07:06.325: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svcaccounts-7371
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: getting the auto-created API token
Dec  3 15:07:06.998: INFO: created pod pod-service-account-defaultsa
Dec  3 15:07:06.998: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Dec  3 15:07:07.004: INFO: created pod pod-service-account-mountsa
Dec  3 15:07:07.004: INFO: pod pod-service-account-mountsa service account token volume mount: true
Dec  3 15:07:07.009: INFO: created pod pod-service-account-nomountsa
Dec  3 15:07:07.009: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Dec  3 15:07:07.015: INFO: created pod pod-service-account-defaultsa-mountspec
Dec  3 15:07:07.015: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Dec  3 15:07:07.020: INFO: created pod pod-service-account-mountsa-mountspec
Dec  3 15:07:07.020: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Dec  3 15:07:07.025: INFO: created pod pod-service-account-nomountsa-mountspec
Dec  3 15:07:07.025: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Dec  3 15:07:07.030: INFO: created pod pod-service-account-defaultsa-nomountspec
Dec  3 15:07:07.030: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Dec  3 15:07:07.036: INFO: created pod pod-service-account-mountsa-nomountspec
Dec  3 15:07:07.036: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Dec  3 15:07:07.040: INFO: created pod pod-service-account-nomountsa-nomountspec
Dec  3 15:07:07.040: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:07:07.040: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-7371" for this suite.
Dec  3 15:07:13.063: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:07:13.223: INFO: namespace svcaccounts-7371 deletion completed in 6.175328284s
â€¢SSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:07:13.224: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-4335
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-map-5c95b8fc-a61b-4d01-a328-db5a490c91f4
STEP: Creating a pod to test consume secrets
Dec  3 15:07:13.379: INFO: Waiting up to 5m0s for pod "pod-secrets-6ed11a40-3c70-4fdc-8605-d98237d06be5" in namespace "secrets-4335" to be "success or failure"
Dec  3 15:07:13.383: INFO: Pod "pod-secrets-6ed11a40-3c70-4fdc-8605-d98237d06be5": Phase="Pending", Reason="", readiness=false. Elapsed: 4.123862ms
Dec  3 15:07:15.388: INFO: Pod "pod-secrets-6ed11a40-3c70-4fdc-8605-d98237d06be5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009304274s
STEP: Saw pod success
Dec  3 15:07:15.388: INFO: Pod "pod-secrets-6ed11a40-3c70-4fdc-8605-d98237d06be5" satisfied condition "success or failure"
Dec  3 15:07:15.393: INFO: Trying to get logs from node izgw8afzp8040eoqk0qbhxz pod pod-secrets-6ed11a40-3c70-4fdc-8605-d98237d06be5 container secret-volume-test: <nil>
STEP: delete the pod
Dec  3 15:07:15.416: INFO: Waiting for pod pod-secrets-6ed11a40-3c70-4fdc-8605-d98237d06be5 to disappear
Dec  3 15:07:15.420: INFO: Pod pod-secrets-6ed11a40-3c70-4fdc-8605-d98237d06be5 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:07:15.420: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-4335" for this suite.
Dec  3 15:07:21.442: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:07:21.608: INFO: namespace secrets-4335 deletion completed in 6.180362062s
â€¢SSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:07:21.609: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-9581
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Dec  3 15:07:23.781: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:07:23.792: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-9581" for this suite.
Dec  3 15:07:29.814: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:07:29.973: INFO: namespace container-runtime-9581 deletion completed in 6.173265215s
â€¢SSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:07:29.974: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-5646
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Dec  3 15:07:30.124: INFO: Waiting up to 5m0s for pod "downwardapi-volume-dad50eeb-2f8c-4dd1-becc-d5670d9fec78" in namespace "downward-api-5646" to be "success or failure"
Dec  3 15:07:30.128: INFO: Pod "downwardapi-volume-dad50eeb-2f8c-4dd1-becc-d5670d9fec78": Phase="Pending", Reason="", readiness=false. Elapsed: 4.240023ms
Dec  3 15:07:32.134: INFO: Pod "downwardapi-volume-dad50eeb-2f8c-4dd1-becc-d5670d9fec78": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009776946s
STEP: Saw pod success
Dec  3 15:07:32.134: INFO: Pod "downwardapi-volume-dad50eeb-2f8c-4dd1-becc-d5670d9fec78" satisfied condition "success or failure"
Dec  3 15:07:32.139: INFO: Trying to get logs from node izgw8afzp8040eoqk0qbhxz pod downwardapi-volume-dad50eeb-2f8c-4dd1-becc-d5670d9fec78 container client-container: <nil>
STEP: delete the pod
Dec  3 15:07:32.162: INFO: Waiting for pod downwardapi-volume-dad50eeb-2f8c-4dd1-becc-d5670d9fec78 to disappear
Dec  3 15:07:32.166: INFO: Pod downwardapi-volume-dad50eeb-2f8c-4dd1-becc-d5670d9fec78 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:07:32.167: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5646" for this suite.
Dec  3 15:07:38.189: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:07:38.349: INFO: namespace downward-api-5646 deletion completed in 6.175402793s
â€¢SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:07:38.350: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename svc-latency
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svc-latency-3540
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating replication controller svc-latency-rc in namespace svc-latency-3540
I1203 15:07:38.500355    5085 runners.go:180] Created replication controller with name: svc-latency-rc, namespace: svc-latency-3540, replica count: 1
I1203 15:07:39.550904    5085 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1203 15:07:40.551200    5085 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Dec  3 15:07:40.660: INFO: Created: latency-svc-dpxzc
Dec  3 15:07:40.663: INFO: Got endpoints: latency-svc-dpxzc [11.822252ms]
Dec  3 15:07:40.672: INFO: Created: latency-svc-zwhs5
Dec  3 15:07:40.674: INFO: Created: latency-svc-ssl7s
Dec  3 15:07:40.675: INFO: Got endpoints: latency-svc-zwhs5 [11.651142ms]
Dec  3 15:07:40.677: INFO: Got endpoints: latency-svc-ssl7s [14.206049ms]
Dec  3 15:07:40.677: INFO: Created: latency-svc-bn848
Dec  3 15:07:40.681: INFO: Got endpoints: latency-svc-bn848 [17.749092ms]
Dec  3 15:07:40.681: INFO: Created: latency-svc-65scp
Dec  3 15:07:40.687: INFO: Got endpoints: latency-svc-65scp [23.585213ms]
Dec  3 15:07:40.687: INFO: Created: latency-svc-4xcxz
Dec  3 15:07:40.691: INFO: Got endpoints: latency-svc-4xcxz [28.020534ms]
Dec  3 15:07:40.698: INFO: Created: latency-svc-vgnb8
Dec  3 15:07:40.699: INFO: Got endpoints: latency-svc-vgnb8 [35.969473ms]
Dec  3 15:07:40.702: INFO: Created: latency-svc-mrc8l
Dec  3 15:07:40.705: INFO: Got endpoints: latency-svc-mrc8l [41.938471ms]
Dec  3 15:07:40.706: INFO: Created: latency-svc-wzjl4
Dec  3 15:07:40.707: INFO: Got endpoints: latency-svc-wzjl4 [43.749822ms]
Dec  3 15:07:40.709: INFO: Created: latency-svc-hr629
Dec  3 15:07:40.712: INFO: Created: latency-svc-97mcw
Dec  3 15:07:40.712: INFO: Got endpoints: latency-svc-hr629 [48.77728ms]
Dec  3 15:07:40.714: INFO: Got endpoints: latency-svc-97mcw [50.376381ms]
Dec  3 15:07:40.716: INFO: Created: latency-svc-lb8r9
Dec  3 15:07:40.720: INFO: Got endpoints: latency-svc-lb8r9 [56.677999ms]
Dec  3 15:07:40.720: INFO: Created: latency-svc-76t4f
Dec  3 15:07:40.722: INFO: Got endpoints: latency-svc-76t4f [58.606678ms]
Dec  3 15:07:40.724: INFO: Created: latency-svc-mpmsw
Dec  3 15:07:40.726: INFO: Got endpoints: latency-svc-mpmsw [62.381311ms]
Dec  3 15:07:40.733: INFO: Created: latency-svc-92n4g
Dec  3 15:07:40.735: INFO: Got endpoints: latency-svc-92n4g [71.612516ms]
Dec  3 15:07:40.737: INFO: Created: latency-svc-wm8c4
Dec  3 15:07:40.740: INFO: Got endpoints: latency-svc-wm8c4 [76.281214ms]
Dec  3 15:07:40.740: INFO: Created: latency-svc-jkfls
Dec  3 15:07:40.743: INFO: Got endpoints: latency-svc-jkfls [68.42811ms]
Dec  3 15:07:40.743: INFO: Created: latency-svc-v77ht
Dec  3 15:07:40.747: INFO: Got endpoints: latency-svc-v77ht [11.742476ms]
Dec  3 15:07:40.747: INFO: Created: latency-svc-wbjlj
Dec  3 15:07:40.750: INFO: Got endpoints: latency-svc-wbjlj [73.006554ms]
Dec  3 15:07:40.751: INFO: Created: latency-svc-qztz8
Dec  3 15:07:40.752: INFO: Got endpoints: latency-svc-qztz8 [71.433392ms]
Dec  3 15:07:40.754: INFO: Created: latency-svc-j4wtw
Dec  3 15:07:40.756: INFO: Got endpoints: latency-svc-j4wtw [69.060529ms]
Dec  3 15:07:40.758: INFO: Created: latency-svc-s82dd
Dec  3 15:07:40.761: INFO: Got endpoints: latency-svc-s82dd [69.855195ms]
Dec  3 15:07:40.762: INFO: Created: latency-svc-zf5wm
Dec  3 15:07:40.763: INFO: Got endpoints: latency-svc-zf5wm [64.284374ms]
Dec  3 15:07:40.768: INFO: Created: latency-svc-l4vmn
Dec  3 15:07:40.771: INFO: Created: latency-svc-sqsjx
Dec  3 15:07:40.772: INFO: Got endpoints: latency-svc-l4vmn [66.630047ms]
Dec  3 15:07:40.773: INFO: Got endpoints: latency-svc-sqsjx [66.162132ms]
Dec  3 15:07:40.776: INFO: Created: latency-svc-ht67t
Dec  3 15:07:40.777: INFO: Got endpoints: latency-svc-ht67t [65.335637ms]
Dec  3 15:07:40.781: INFO: Created: latency-svc-2knhl
Dec  3 15:07:40.782: INFO: Got endpoints: latency-svc-2knhl [68.651586ms]
Dec  3 15:07:40.785: INFO: Created: latency-svc-t6vz2
Dec  3 15:07:40.795: INFO: Got endpoints: latency-svc-t6vz2 [74.876541ms]
Dec  3 15:07:40.796: INFO: Created: latency-svc-sl2sr
Dec  3 15:07:40.800: INFO: Created: latency-svc-zxg98
Dec  3 15:07:40.800: INFO: Got endpoints: latency-svc-sl2sr [78.223489ms]
Dec  3 15:07:40.802: INFO: Got endpoints: latency-svc-zxg98 [76.328764ms]
Dec  3 15:07:40.806: INFO: Created: latency-svc-9jdnb
Dec  3 15:07:40.807: INFO: Got endpoints: latency-svc-9jdnb [67.628437ms]
Dec  3 15:07:40.809: INFO: Created: latency-svc-66xsg
Dec  3 15:07:40.811: INFO: Got endpoints: latency-svc-66xsg [67.805091ms]
Dec  3 15:07:40.815: INFO: Created: latency-svc-mk4hf
Dec  3 15:07:40.817: INFO: Got endpoints: latency-svc-mk4hf [70.478102ms]
Dec  3 15:07:40.818: INFO: Created: latency-svc-q65lb
Dec  3 15:07:40.821: INFO: Created: latency-svc-jn5qw
Dec  3 15:07:40.825: INFO: Created: latency-svc-wq4lr
Dec  3 15:07:40.828: INFO: Created: latency-svc-m9lf2
Dec  3 15:07:40.832: INFO: Created: latency-svc-dctcr
Dec  3 15:07:40.836: INFO: Created: latency-svc-68mj7
Dec  3 15:07:40.840: INFO: Created: latency-svc-d6bhs
Dec  3 15:07:40.843: INFO: Created: latency-svc-5v44z
Dec  3 15:07:40.846: INFO: Created: latency-svc-5vlcb
Dec  3 15:07:40.857: INFO: Created: latency-svc-dlwf9
Dec  3 15:07:40.861: INFO: Created: latency-svc-z9rnv
Dec  3 15:07:40.862: INFO: Got endpoints: latency-svc-q65lb [111.924288ms]
Dec  3 15:07:40.865: INFO: Created: latency-svc-bhwnc
Dec  3 15:07:40.869: INFO: Created: latency-svc-99gdt
Dec  3 15:07:40.873: INFO: Created: latency-svc-flxdj
Dec  3 15:07:40.877: INFO: Created: latency-svc-x968q
Dec  3 15:07:40.881: INFO: Created: latency-svc-jr42c
Dec  3 15:07:40.912: INFO: Got endpoints: latency-svc-jn5qw [160.027738ms]
Dec  3 15:07:40.920: INFO: Created: latency-svc-f9w6r
Dec  3 15:07:40.962: INFO: Got endpoints: latency-svc-wq4lr [206.292357ms]
Dec  3 15:07:40.970: INFO: Created: latency-svc-tndng
Dec  3 15:07:41.012: INFO: Got endpoints: latency-svc-m9lf2 [251.289554ms]
Dec  3 15:07:41.021: INFO: Created: latency-svc-qmvwv
Dec  3 15:07:41.062: INFO: Got endpoints: latency-svc-dctcr [298.849411ms]
Dec  3 15:07:41.070: INFO: Created: latency-svc-wncrz
Dec  3 15:07:41.113: INFO: Got endpoints: latency-svc-68mj7 [340.764015ms]
Dec  3 15:07:41.120: INFO: Created: latency-svc-bzsv9
Dec  3 15:07:41.163: INFO: Got endpoints: latency-svc-d6bhs [389.364647ms]
Dec  3 15:07:41.170: INFO: Created: latency-svc-dlklh
Dec  3 15:07:41.212: INFO: Got endpoints: latency-svc-5v44z [435.007764ms]
Dec  3 15:07:41.220: INFO: Created: latency-svc-r7rt2
Dec  3 15:07:41.262: INFO: Got endpoints: latency-svc-5vlcb [479.861855ms]
Dec  3 15:07:41.270: INFO: Created: latency-svc-pzggx
Dec  3 15:07:41.314: INFO: Got endpoints: latency-svc-dlwf9 [518.809868ms]
Dec  3 15:07:41.322: INFO: Created: latency-svc-q4k55
Dec  3 15:07:41.363: INFO: Got endpoints: latency-svc-z9rnv [562.475777ms]
Dec  3 15:07:41.371: INFO: Created: latency-svc-pwb9t
Dec  3 15:07:41.413: INFO: Got endpoints: latency-svc-bhwnc [610.793525ms]
Dec  3 15:07:41.421: INFO: Created: latency-svc-48xls
Dec  3 15:07:41.462: INFO: Got endpoints: latency-svc-99gdt [655.105621ms]
Dec  3 15:07:41.470: INFO: Created: latency-svc-zgg78
Dec  3 15:07:41.513: INFO: Got endpoints: latency-svc-flxdj [701.611688ms]
Dec  3 15:07:41.523: INFO: Created: latency-svc-kdldp
Dec  3 15:07:41.563: INFO: Got endpoints: latency-svc-x968q [745.553222ms]
Dec  3 15:07:41.571: INFO: Created: latency-svc-6vx5b
Dec  3 15:07:41.613: INFO: Got endpoints: latency-svc-jr42c [750.441472ms]
Dec  3 15:07:41.623: INFO: Created: latency-svc-lgq2w
Dec  3 15:07:41.663: INFO: Got endpoints: latency-svc-f9w6r [750.270076ms]
Dec  3 15:07:41.671: INFO: Created: latency-svc-lj7jx
Dec  3 15:07:41.712: INFO: Got endpoints: latency-svc-tndng [750.091702ms]
Dec  3 15:07:41.721: INFO: Created: latency-svc-pjbpt
Dec  3 15:07:41.763: INFO: Got endpoints: latency-svc-qmvwv [750.368501ms]
Dec  3 15:07:41.771: INFO: Created: latency-svc-gpcs9
Dec  3 15:07:41.813: INFO: Got endpoints: latency-svc-wncrz [750.296176ms]
Dec  3 15:07:41.821: INFO: Created: latency-svc-j5nt5
Dec  3 15:07:41.863: INFO: Got endpoints: latency-svc-bzsv9 [750.059517ms]
Dec  3 15:07:41.871: INFO: Created: latency-svc-rchfh
Dec  3 15:07:41.913: INFO: Got endpoints: latency-svc-dlklh [750.360281ms]
Dec  3 15:07:41.922: INFO: Created: latency-svc-5pgx6
Dec  3 15:07:41.963: INFO: Got endpoints: latency-svc-r7rt2 [750.524103ms]
Dec  3 15:07:41.971: INFO: Created: latency-svc-bcjgf
Dec  3 15:07:42.013: INFO: Got endpoints: latency-svc-pzggx [750.438264ms]
Dec  3 15:07:42.022: INFO: Created: latency-svc-4drh6
Dec  3 15:07:42.063: INFO: Got endpoints: latency-svc-q4k55 [748.927715ms]
Dec  3 15:07:42.072: INFO: Created: latency-svc-k4t5w
Dec  3 15:07:42.113: INFO: Got endpoints: latency-svc-pwb9t [750.087455ms]
Dec  3 15:07:42.122: INFO: Created: latency-svc-g7lt7
Dec  3 15:07:42.163: INFO: Got endpoints: latency-svc-48xls [750.266181ms]
Dec  3 15:07:42.173: INFO: Created: latency-svc-h77sb
Dec  3 15:07:42.213: INFO: Got endpoints: latency-svc-zgg78 [750.294521ms]
Dec  3 15:07:42.238: INFO: Created: latency-svc-5krd2
Dec  3 15:07:42.263: INFO: Got endpoints: latency-svc-kdldp [750.097632ms]
Dec  3 15:07:42.271: INFO: Created: latency-svc-kw5vx
Dec  3 15:07:42.313: INFO: Got endpoints: latency-svc-6vx5b [750.501969ms]
Dec  3 15:07:42.329: INFO: Created: latency-svc-7jdzz
Dec  3 15:07:42.363: INFO: Got endpoints: latency-svc-lgq2w [750.24112ms]
Dec  3 15:07:42.373: INFO: Created: latency-svc-nzrll
Dec  3 15:07:42.413: INFO: Got endpoints: latency-svc-lj7jx [749.834059ms]
Dec  3 15:07:42.422: INFO: Created: latency-svc-h2krs
Dec  3 15:07:42.463: INFO: Got endpoints: latency-svc-pjbpt [750.320143ms]
Dec  3 15:07:42.472: INFO: Created: latency-svc-xwbwt
Dec  3 15:07:42.513: INFO: Got endpoints: latency-svc-gpcs9 [749.702935ms]
Dec  3 15:07:42.521: INFO: Created: latency-svc-wxl7z
Dec  3 15:07:42.563: INFO: Got endpoints: latency-svc-j5nt5 [749.688012ms]
Dec  3 15:07:42.571: INFO: Created: latency-svc-q9khd
Dec  3 15:07:42.613: INFO: Got endpoints: latency-svc-rchfh [750.353997ms]
Dec  3 15:07:42.621: INFO: Created: latency-svc-9558p
Dec  3 15:07:42.663: INFO: Got endpoints: latency-svc-5pgx6 [750.021434ms]
Dec  3 15:07:42.671: INFO: Created: latency-svc-s28hc
Dec  3 15:07:42.712: INFO: Got endpoints: latency-svc-bcjgf [749.296647ms]
Dec  3 15:07:42.720: INFO: Created: latency-svc-cm4r5
Dec  3 15:07:42.763: INFO: Got endpoints: latency-svc-4drh6 [749.861836ms]
Dec  3 15:07:42.771: INFO: Created: latency-svc-h795r
Dec  3 15:07:42.813: INFO: Got endpoints: latency-svc-k4t5w [749.750965ms]
Dec  3 15:07:42.820: INFO: Created: latency-svc-9lnsh
Dec  3 15:07:42.863: INFO: Got endpoints: latency-svc-g7lt7 [749.767212ms]
Dec  3 15:07:42.871: INFO: Created: latency-svc-ss675
Dec  3 15:07:42.913: INFO: Got endpoints: latency-svc-h77sb [749.578419ms]
Dec  3 15:07:42.922: INFO: Created: latency-svc-bvt87
Dec  3 15:07:42.963: INFO: Got endpoints: latency-svc-5krd2 [750.179307ms]
Dec  3 15:07:42.972: INFO: Created: latency-svc-qtzdn
Dec  3 15:07:43.013: INFO: Got endpoints: latency-svc-kw5vx [749.864648ms]
Dec  3 15:07:43.021: INFO: Created: latency-svc-zln86
Dec  3 15:07:43.063: INFO: Got endpoints: latency-svc-7jdzz [749.287932ms]
Dec  3 15:07:43.072: INFO: Created: latency-svc-vmtll
Dec  3 15:07:43.113: INFO: Got endpoints: latency-svc-nzrll [749.681183ms]
Dec  3 15:07:43.121: INFO: Created: latency-svc-cc2t7
Dec  3 15:07:43.163: INFO: Got endpoints: latency-svc-h2krs [749.884733ms]
Dec  3 15:07:43.171: INFO: Created: latency-svc-lxfkl
Dec  3 15:07:43.212: INFO: Got endpoints: latency-svc-xwbwt [749.641492ms]
Dec  3 15:07:43.220: INFO: Created: latency-svc-7zf7p
Dec  3 15:07:43.262: INFO: Got endpoints: latency-svc-wxl7z [749.632894ms]
Dec  3 15:07:43.270: INFO: Created: latency-svc-kx8g9
Dec  3 15:07:43.313: INFO: Got endpoints: latency-svc-q9khd [750.063998ms]
Dec  3 15:07:43.320: INFO: Created: latency-svc-cl7k7
Dec  3 15:07:43.363: INFO: Got endpoints: latency-svc-9558p [749.668522ms]
Dec  3 15:07:43.371: INFO: Created: latency-svc-4k2nh
Dec  3 15:07:43.413: INFO: Got endpoints: latency-svc-s28hc [749.942447ms]
Dec  3 15:07:43.422: INFO: Created: latency-svc-tprdg
Dec  3 15:07:43.462: INFO: Got endpoints: latency-svc-cm4r5 [749.870601ms]
Dec  3 15:07:43.474: INFO: Created: latency-svc-mnvz9
Dec  3 15:07:43.513: INFO: Got endpoints: latency-svc-h795r [749.846676ms]
Dec  3 15:07:43.521: INFO: Created: latency-svc-9jtxv
Dec  3 15:07:43.563: INFO: Got endpoints: latency-svc-9lnsh [750.091868ms]
Dec  3 15:07:43.571: INFO: Created: latency-svc-ml5qw
Dec  3 15:07:43.613: INFO: Got endpoints: latency-svc-ss675 [749.918485ms]
Dec  3 15:07:43.622: INFO: Created: latency-svc-rlz9t
Dec  3 15:07:43.663: INFO: Got endpoints: latency-svc-bvt87 [749.895067ms]
Dec  3 15:07:43.672: INFO: Created: latency-svc-pg2w5
Dec  3 15:07:43.712: INFO: Got endpoints: latency-svc-qtzdn [749.094316ms]
Dec  3 15:07:43.721: INFO: Created: latency-svc-dvhnd
Dec  3 15:07:43.763: INFO: Got endpoints: latency-svc-zln86 [749.776034ms]
Dec  3 15:07:43.771: INFO: Created: latency-svc-npbsw
Dec  3 15:07:43.813: INFO: Got endpoints: latency-svc-vmtll [750.114849ms]
Dec  3 15:07:43.821: INFO: Created: latency-svc-xmsv6
Dec  3 15:07:43.863: INFO: Got endpoints: latency-svc-cc2t7 [749.863891ms]
Dec  3 15:07:43.871: INFO: Created: latency-svc-ssxv2
Dec  3 15:07:43.913: INFO: Got endpoints: latency-svc-lxfkl [749.8482ms]
Dec  3 15:07:43.921: INFO: Created: latency-svc-9s59f
Dec  3 15:07:43.963: INFO: Got endpoints: latency-svc-7zf7p [750.228495ms]
Dec  3 15:07:43.972: INFO: Created: latency-svc-znh2r
Dec  3 15:07:44.013: INFO: Got endpoints: latency-svc-kx8g9 [750.219481ms]
Dec  3 15:07:44.022: INFO: Created: latency-svc-w4q2p
Dec  3 15:07:44.063: INFO: Got endpoints: latency-svc-cl7k7 [750.162532ms]
Dec  3 15:07:44.072: INFO: Created: latency-svc-7qddq
Dec  3 15:07:44.113: INFO: Got endpoints: latency-svc-4k2nh [749.871127ms]
Dec  3 15:07:44.121: INFO: Created: latency-svc-bc9l7
Dec  3 15:07:44.163: INFO: Got endpoints: latency-svc-tprdg [749.60506ms]
Dec  3 15:07:44.174: INFO: Created: latency-svc-dczqv
Dec  3 15:07:44.219: INFO: Got endpoints: latency-svc-mnvz9 [756.824487ms]
Dec  3 15:07:44.228: INFO: Created: latency-svc-9t2hj
Dec  3 15:07:44.263: INFO: Got endpoints: latency-svc-9jtxv [749.978335ms]
Dec  3 15:07:44.284: INFO: Created: latency-svc-r7mm5
Dec  3 15:07:44.319: INFO: Got endpoints: latency-svc-ml5qw [756.499162ms]
Dec  3 15:07:44.328: INFO: Created: latency-svc-9x7jb
Dec  3 15:07:44.363: INFO: Got endpoints: latency-svc-rlz9t [749.765108ms]
Dec  3 15:07:44.371: INFO: Created: latency-svc-2rfwv
Dec  3 15:07:44.412: INFO: Got endpoints: latency-svc-pg2w5 [749.538584ms]
Dec  3 15:07:44.420: INFO: Created: latency-svc-56dpr
Dec  3 15:07:44.462: INFO: Got endpoints: latency-svc-dvhnd [750.002896ms]
Dec  3 15:07:44.470: INFO: Created: latency-svc-nhhr6
Dec  3 15:07:44.512: INFO: Got endpoints: latency-svc-npbsw [749.72302ms]
Dec  3 15:07:44.521: INFO: Created: latency-svc-8h4sx
Dec  3 15:07:44.563: INFO: Got endpoints: latency-svc-xmsv6 [749.73908ms]
Dec  3 15:07:44.571: INFO: Created: latency-svc-cn7sq
Dec  3 15:07:44.613: INFO: Got endpoints: latency-svc-ssxv2 [749.86208ms]
Dec  3 15:07:44.621: INFO: Created: latency-svc-ltncr
Dec  3 15:07:44.663: INFO: Got endpoints: latency-svc-9s59f [750.606715ms]
Dec  3 15:07:44.672: INFO: Created: latency-svc-f7dw5
Dec  3 15:07:44.713: INFO: Got endpoints: latency-svc-znh2r [749.941589ms]
Dec  3 15:07:44.721: INFO: Created: latency-svc-x9ttt
Dec  3 15:07:44.763: INFO: Got endpoints: latency-svc-w4q2p [750.163016ms]
Dec  3 15:07:44.772: INFO: Created: latency-svc-p2krc
Dec  3 15:07:44.814: INFO: Got endpoints: latency-svc-7qddq [750.983142ms]
Dec  3 15:07:44.822: INFO: Created: latency-svc-44rkk
Dec  3 15:07:44.863: INFO: Got endpoints: latency-svc-bc9l7 [749.560766ms]
Dec  3 15:07:44.871: INFO: Created: latency-svc-ssvtd
Dec  3 15:07:44.912: INFO: Got endpoints: latency-svc-dczqv [749.490485ms]
Dec  3 15:07:44.921: INFO: Created: latency-svc-rm9hm
Dec  3 15:07:44.962: INFO: Got endpoints: latency-svc-9t2hj [742.905295ms]
Dec  3 15:07:44.970: INFO: Created: latency-svc-szn4g
Dec  3 15:07:45.013: INFO: Got endpoints: latency-svc-r7mm5 [750.403216ms]
Dec  3 15:07:45.024: INFO: Created: latency-svc-rzlcs
Dec  3 15:07:45.063: INFO: Got endpoints: latency-svc-9x7jb [743.901204ms]
Dec  3 15:07:45.071: INFO: Created: latency-svc-bs9xh
Dec  3 15:07:45.112: INFO: Got endpoints: latency-svc-2rfwv [749.799769ms]
Dec  3 15:07:45.123: INFO: Created: latency-svc-qxjvl
Dec  3 15:07:45.163: INFO: Got endpoints: latency-svc-56dpr [750.613523ms]
Dec  3 15:07:45.172: INFO: Created: latency-svc-8bkxq
Dec  3 15:07:45.213: INFO: Got endpoints: latency-svc-nhhr6 [750.13347ms]
Dec  3 15:07:45.221: INFO: Created: latency-svc-gsqtj
Dec  3 15:07:45.263: INFO: Got endpoints: latency-svc-8h4sx [750.378053ms]
Dec  3 15:07:45.271: INFO: Created: latency-svc-nw8c8
Dec  3 15:07:45.313: INFO: Got endpoints: latency-svc-cn7sq [749.73491ms]
Dec  3 15:07:45.322: INFO: Created: latency-svc-2ql9g
Dec  3 15:07:45.362: INFO: Got endpoints: latency-svc-ltncr [749.653996ms]
Dec  3 15:07:45.370: INFO: Created: latency-svc-2zfmp
Dec  3 15:07:45.412: INFO: Got endpoints: latency-svc-f7dw5 [748.955675ms]
Dec  3 15:07:45.420: INFO: Created: latency-svc-qwn7x
Dec  3 15:07:45.462: INFO: Got endpoints: latency-svc-x9ttt [749.172968ms]
Dec  3 15:07:45.470: INFO: Created: latency-svc-9z8n6
Dec  3 15:07:45.513: INFO: Got endpoints: latency-svc-p2krc [749.6459ms]
Dec  3 15:07:45.521: INFO: Created: latency-svc-gtlmx
Dec  3 15:07:45.562: INFO: Got endpoints: latency-svc-44rkk [748.087163ms]
Dec  3 15:07:45.571: INFO: Created: latency-svc-d8c8d
Dec  3 15:07:45.613: INFO: Got endpoints: latency-svc-ssvtd [750.017238ms]
Dec  3 15:07:45.621: INFO: Created: latency-svc-dzjbw
Dec  3 15:07:45.663: INFO: Got endpoints: latency-svc-rm9hm [750.32702ms]
Dec  3 15:07:45.671: INFO: Created: latency-svc-wfrf4
Dec  3 15:07:45.713: INFO: Got endpoints: latency-svc-szn4g [750.123365ms]
Dec  3 15:07:45.721: INFO: Created: latency-svc-zrtf2
Dec  3 15:07:45.763: INFO: Got endpoints: latency-svc-rzlcs [749.411122ms]
Dec  3 15:07:45.771: INFO: Created: latency-svc-nckrz
Dec  3 15:07:45.813: INFO: Got endpoints: latency-svc-bs9xh [749.400342ms]
Dec  3 15:07:45.821: INFO: Created: latency-svc-j79bg
Dec  3 15:07:45.863: INFO: Got endpoints: latency-svc-qxjvl [750.181432ms]
Dec  3 15:07:45.871: INFO: Created: latency-svc-dqttv
Dec  3 15:07:45.912: INFO: Got endpoints: latency-svc-8bkxq [749.142387ms]
Dec  3 15:07:45.920: INFO: Created: latency-svc-j2bzk
Dec  3 15:07:45.962: INFO: Got endpoints: latency-svc-gsqtj [749.743899ms]
Dec  3 15:07:45.972: INFO: Created: latency-svc-48nv7
Dec  3 15:07:46.013: INFO: Got endpoints: latency-svc-nw8c8 [749.528369ms]
Dec  3 15:07:46.021: INFO: Created: latency-svc-bnfm4
Dec  3 15:07:46.063: INFO: Got endpoints: latency-svc-2ql9g [750.24031ms]
Dec  3 15:07:46.071: INFO: Created: latency-svc-f8z5x
Dec  3 15:07:46.112: INFO: Got endpoints: latency-svc-2zfmp [749.796425ms]
Dec  3 15:07:46.120: INFO: Created: latency-svc-tsl5q
Dec  3 15:07:46.163: INFO: Got endpoints: latency-svc-qwn7x [750.462322ms]
Dec  3 15:07:46.176: INFO: Created: latency-svc-khzs6
Dec  3 15:07:46.212: INFO: Got endpoints: latency-svc-9z8n6 [750.256015ms]
Dec  3 15:07:46.221: INFO: Created: latency-svc-k9lgk
Dec  3 15:07:46.263: INFO: Got endpoints: latency-svc-gtlmx [749.762351ms]
Dec  3 15:07:46.270: INFO: Created: latency-svc-j66j7
Dec  3 15:07:46.312: INFO: Got endpoints: latency-svc-d8c8d [749.987104ms]
Dec  3 15:07:46.321: INFO: Created: latency-svc-8z87d
Dec  3 15:07:46.363: INFO: Got endpoints: latency-svc-dzjbw [749.715211ms]
Dec  3 15:07:46.371: INFO: Created: latency-svc-7xjtd
Dec  3 15:07:46.413: INFO: Got endpoints: latency-svc-wfrf4 [749.599956ms]
Dec  3 15:07:46.421: INFO: Created: latency-svc-9xtlq
Dec  3 15:07:46.463: INFO: Got endpoints: latency-svc-zrtf2 [750.021619ms]
Dec  3 15:07:46.470: INFO: Created: latency-svc-s879t
Dec  3 15:07:46.512: INFO: Got endpoints: latency-svc-nckrz [749.645396ms]
Dec  3 15:07:46.522: INFO: Created: latency-svc-hdg4h
Dec  3 15:07:46.564: INFO: Got endpoints: latency-svc-j79bg [750.916465ms]
Dec  3 15:07:46.573: INFO: Created: latency-svc-xvq64
Dec  3 15:07:46.612: INFO: Got endpoints: latency-svc-dqttv [749.703367ms]
Dec  3 15:07:46.621: INFO: Created: latency-svc-mcdmw
Dec  3 15:07:46.662: INFO: Got endpoints: latency-svc-j2bzk [749.880057ms]
Dec  3 15:07:46.670: INFO: Created: latency-svc-hbgnx
Dec  3 15:07:46.713: INFO: Got endpoints: latency-svc-48nv7 [750.202808ms]
Dec  3 15:07:46.721: INFO: Created: latency-svc-2xvgt
Dec  3 15:07:46.762: INFO: Got endpoints: latency-svc-bnfm4 [749.684894ms]
Dec  3 15:07:46.772: INFO: Created: latency-svc-f7tfq
Dec  3 15:07:46.813: INFO: Got endpoints: latency-svc-f8z5x [749.643153ms]
Dec  3 15:07:46.820: INFO: Created: latency-svc-q6kkq
Dec  3 15:07:46.862: INFO: Got endpoints: latency-svc-tsl5q [749.897546ms]
Dec  3 15:07:46.872: INFO: Created: latency-svc-qr6sj
Dec  3 15:07:46.912: INFO: Got endpoints: latency-svc-khzs6 [749.553004ms]
Dec  3 15:07:46.920: INFO: Created: latency-svc-9gh5j
Dec  3 15:07:46.963: INFO: Got endpoints: latency-svc-k9lgk [750.133186ms]
Dec  3 15:07:46.971: INFO: Created: latency-svc-nk6xd
Dec  3 15:07:47.013: INFO: Got endpoints: latency-svc-j66j7 [750.087877ms]
Dec  3 15:07:47.021: INFO: Created: latency-svc-8v45d
Dec  3 15:07:47.063: INFO: Got endpoints: latency-svc-8z87d [750.195446ms]
Dec  3 15:07:47.071: INFO: Created: latency-svc-sn7ht
Dec  3 15:07:47.113: INFO: Got endpoints: latency-svc-7xjtd [750.621089ms]
Dec  3 15:07:47.123: INFO: Created: latency-svc-lwksd
Dec  3 15:07:47.163: INFO: Got endpoints: latency-svc-9xtlq [750.671554ms]
Dec  3 15:07:47.172: INFO: Created: latency-svc-7wnhr
Dec  3 15:07:47.213: INFO: Got endpoints: latency-svc-s879t [750.128622ms]
Dec  3 15:07:47.221: INFO: Created: latency-svc-p8794
Dec  3 15:07:47.263: INFO: Got endpoints: latency-svc-hdg4h [750.073866ms]
Dec  3 15:07:47.270: INFO: Created: latency-svc-22wsx
Dec  3 15:07:47.313: INFO: Got endpoints: latency-svc-xvq64 [749.076553ms]
Dec  3 15:07:47.321: INFO: Created: latency-svc-znzjz
Dec  3 15:07:47.363: INFO: Got endpoints: latency-svc-mcdmw [750.0083ms]
Dec  3 15:07:47.370: INFO: Created: latency-svc-f29lr
Dec  3 15:07:47.432: INFO: Got endpoints: latency-svc-hbgnx [769.450608ms]
Dec  3 15:07:47.440: INFO: Created: latency-svc-l4sg6
Dec  3 15:07:47.462: INFO: Got endpoints: latency-svc-2xvgt [749.226047ms]
Dec  3 15:07:47.469: INFO: Created: latency-svc-h789w
Dec  3 15:07:47.513: INFO: Got endpoints: latency-svc-f7tfq [750.008228ms]
Dec  3 15:07:47.521: INFO: Created: latency-svc-tqwcx
Dec  3 15:07:47.563: INFO: Got endpoints: latency-svc-q6kkq [749.923023ms]
Dec  3 15:07:47.570: INFO: Created: latency-svc-tksps
Dec  3 15:07:47.612: INFO: Got endpoints: latency-svc-qr6sj [750.03698ms]
Dec  3 15:07:47.621: INFO: Created: latency-svc-hsjqh
Dec  3 15:07:47.662: INFO: Got endpoints: latency-svc-9gh5j [749.907387ms]
Dec  3 15:07:47.670: INFO: Created: latency-svc-nlzm4
Dec  3 15:07:47.712: INFO: Got endpoints: latency-svc-nk6xd [749.701458ms]
Dec  3 15:07:47.720: INFO: Created: latency-svc-gp8f4
Dec  3 15:07:47.762: INFO: Got endpoints: latency-svc-8v45d [749.625101ms]
Dec  3 15:07:47.770: INFO: Created: latency-svc-msmwh
Dec  3 15:07:47.813: INFO: Got endpoints: latency-svc-sn7ht [750.106551ms]
Dec  3 15:07:47.821: INFO: Created: latency-svc-m7f6c
Dec  3 15:07:47.863: INFO: Got endpoints: latency-svc-lwksd [749.223706ms]
Dec  3 15:07:47.870: INFO: Created: latency-svc-6cm54
Dec  3 15:07:47.913: INFO: Got endpoints: latency-svc-7wnhr [749.530402ms]
Dec  3 15:07:47.922: INFO: Created: latency-svc-d5rts
Dec  3 15:07:47.963: INFO: Got endpoints: latency-svc-p8794 [749.529549ms]
Dec  3 15:07:47.970: INFO: Created: latency-svc-mb6l9
Dec  3 15:07:48.013: INFO: Got endpoints: latency-svc-22wsx [750.190895ms]
Dec  3 15:07:48.021: INFO: Created: latency-svc-qm9k7
Dec  3 15:07:48.063: INFO: Got endpoints: latency-svc-znzjz [749.961457ms]
Dec  3 15:07:48.072: INFO: Created: latency-svc-rz6m8
Dec  3 15:07:48.113: INFO: Got endpoints: latency-svc-f29lr [750.172563ms]
Dec  3 15:07:48.121: INFO: Created: latency-svc-w7vdb
Dec  3 15:07:48.163: INFO: Got endpoints: latency-svc-l4sg6 [730.558213ms]
Dec  3 15:07:48.170: INFO: Created: latency-svc-sv7kf
Dec  3 15:07:48.213: INFO: Got endpoints: latency-svc-h789w [750.512641ms]
Dec  3 15:07:48.221: INFO: Created: latency-svc-2hs5k
Dec  3 15:07:48.262: INFO: Got endpoints: latency-svc-tqwcx [749.904621ms]
Dec  3 15:07:48.271: INFO: Created: latency-svc-2548k
Dec  3 15:07:48.312: INFO: Got endpoints: latency-svc-tksps [749.465921ms]
Dec  3 15:07:48.321: INFO: Created: latency-svc-78zjd
Dec  3 15:07:48.363: INFO: Got endpoints: latency-svc-hsjqh [750.046807ms]
Dec  3 15:07:48.371: INFO: Created: latency-svc-ns479
Dec  3 15:07:48.415: INFO: Got endpoints: latency-svc-nlzm4 [752.053943ms]
Dec  3 15:07:48.423: INFO: Created: latency-svc-dtqq7
Dec  3 15:07:48.463: INFO: Got endpoints: latency-svc-gp8f4 [750.076216ms]
Dec  3 15:07:48.472: INFO: Created: latency-svc-tgdvj
Dec  3 15:07:48.512: INFO: Got endpoints: latency-svc-msmwh [749.954028ms]
Dec  3 15:07:48.563: INFO: Got endpoints: latency-svc-m7f6c [749.903475ms]
Dec  3 15:07:48.613: INFO: Got endpoints: latency-svc-6cm54 [750.100013ms]
Dec  3 15:07:48.663: INFO: Got endpoints: latency-svc-d5rts [749.599609ms]
Dec  3 15:07:48.713: INFO: Got endpoints: latency-svc-mb6l9 [750.066296ms]
Dec  3 15:07:48.763: INFO: Got endpoints: latency-svc-qm9k7 [749.731336ms]
Dec  3 15:07:48.813: INFO: Got endpoints: latency-svc-rz6m8 [749.857865ms]
Dec  3 15:07:48.863: INFO: Got endpoints: latency-svc-w7vdb [750.501195ms]
Dec  3 15:07:48.913: INFO: Got endpoints: latency-svc-sv7kf [750.01021ms]
Dec  3 15:07:48.963: INFO: Got endpoints: latency-svc-2hs5k [750.402269ms]
Dec  3 15:07:49.013: INFO: Got endpoints: latency-svc-2548k [750.119018ms]
Dec  3 15:07:49.063: INFO: Got endpoints: latency-svc-78zjd [750.565781ms]
Dec  3 15:07:49.113: INFO: Got endpoints: latency-svc-ns479 [749.780752ms]
Dec  3 15:07:49.163: INFO: Got endpoints: latency-svc-dtqq7 [748.412511ms]
Dec  3 15:07:49.213: INFO: Got endpoints: latency-svc-tgdvj [750.623558ms]
Dec  3 15:07:49.213: INFO: Latencies: [11.651142ms 11.742476ms 14.206049ms 17.749092ms 23.585213ms 28.020534ms 35.969473ms 41.938471ms 43.749822ms 48.77728ms 50.376381ms 56.677999ms 58.606678ms 62.381311ms 64.284374ms 65.335637ms 66.162132ms 66.630047ms 67.628437ms 67.805091ms 68.42811ms 68.651586ms 69.060529ms 69.855195ms 70.478102ms 71.433392ms 71.612516ms 73.006554ms 74.876541ms 76.281214ms 76.328764ms 78.223489ms 111.924288ms 160.027738ms 206.292357ms 251.289554ms 298.849411ms 340.764015ms 389.364647ms 435.007764ms 479.861855ms 518.809868ms 562.475777ms 610.793525ms 655.105621ms 701.611688ms 730.558213ms 742.905295ms 743.901204ms 745.553222ms 748.087163ms 748.412511ms 748.927715ms 748.955675ms 749.076553ms 749.094316ms 749.142387ms 749.172968ms 749.223706ms 749.226047ms 749.287932ms 749.296647ms 749.400342ms 749.411122ms 749.465921ms 749.490485ms 749.528369ms 749.529549ms 749.530402ms 749.538584ms 749.553004ms 749.560766ms 749.578419ms 749.599609ms 749.599956ms 749.60506ms 749.625101ms 749.632894ms 749.641492ms 749.643153ms 749.645396ms 749.6459ms 749.653996ms 749.668522ms 749.681183ms 749.684894ms 749.688012ms 749.701458ms 749.702935ms 749.703367ms 749.715211ms 749.72302ms 749.731336ms 749.73491ms 749.73908ms 749.743899ms 749.750965ms 749.762351ms 749.765108ms 749.767212ms 749.776034ms 749.780752ms 749.796425ms 749.799769ms 749.834059ms 749.846676ms 749.8482ms 749.857865ms 749.861836ms 749.86208ms 749.863891ms 749.864648ms 749.870601ms 749.871127ms 749.880057ms 749.884733ms 749.895067ms 749.897546ms 749.903475ms 749.904621ms 749.907387ms 749.918485ms 749.923023ms 749.941589ms 749.942447ms 749.954028ms 749.961457ms 749.978335ms 749.987104ms 750.002896ms 750.008228ms 750.0083ms 750.01021ms 750.017238ms 750.021434ms 750.021619ms 750.03698ms 750.046807ms 750.059517ms 750.063998ms 750.066296ms 750.073866ms 750.076216ms 750.087455ms 750.087877ms 750.091702ms 750.091868ms 750.097632ms 750.100013ms 750.106551ms 750.114849ms 750.119018ms 750.123365ms 750.128622ms 750.133186ms 750.13347ms 750.162532ms 750.163016ms 750.172563ms 750.179307ms 750.181432ms 750.190895ms 750.195446ms 750.202808ms 750.219481ms 750.228495ms 750.24031ms 750.24112ms 750.256015ms 750.266181ms 750.270076ms 750.294521ms 750.296176ms 750.320143ms 750.32702ms 750.353997ms 750.360281ms 750.368501ms 750.378053ms 750.402269ms 750.403216ms 750.438264ms 750.441472ms 750.462322ms 750.501195ms 750.501969ms 750.512641ms 750.524103ms 750.565781ms 750.606715ms 750.613523ms 750.621089ms 750.623558ms 750.671554ms 750.916465ms 750.983142ms 752.053943ms 756.499162ms 756.824487ms 769.450608ms]
Dec  3 15:07:49.213: INFO: 50 %ile: 749.776034ms
Dec  3 15:07:49.214: INFO: 90 %ile: 750.403216ms
Dec  3 15:07:49.214: INFO: 99 %ile: 756.824487ms
Dec  3 15:07:49.214: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:07:49.214: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svc-latency-3540" for this suite.
Dec  3 15:07:57.236: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:07:57.399: INFO: namespace svc-latency-3540 deletion completed in 8.177840515s
â€¢S
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:07:57.399: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-5315
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating secret secrets-5315/secret-test-70b71e7e-91fa-4ee9-943d-a26636bc4342
STEP: Creating a pod to test consume secrets
Dec  3 15:07:57.556: INFO: Waiting up to 5m0s for pod "pod-configmaps-c1effcba-59ed-47fa-a68b-eb0d5984ee2f" in namespace "secrets-5315" to be "success or failure"
Dec  3 15:07:57.560: INFO: Pod "pod-configmaps-c1effcba-59ed-47fa-a68b-eb0d5984ee2f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.078808ms
Dec  3 15:07:59.566: INFO: Pod "pod-configmaps-c1effcba-59ed-47fa-a68b-eb0d5984ee2f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009466523s
STEP: Saw pod success
Dec  3 15:07:59.566: INFO: Pod "pod-configmaps-c1effcba-59ed-47fa-a68b-eb0d5984ee2f" satisfied condition "success or failure"
Dec  3 15:07:59.571: INFO: Trying to get logs from node izgw8afzp8040eoqk0qbhxz pod pod-configmaps-c1effcba-59ed-47fa-a68b-eb0d5984ee2f container env-test: <nil>
STEP: delete the pod
Dec  3 15:07:59.594: INFO: Waiting for pod pod-configmaps-c1effcba-59ed-47fa-a68b-eb0d5984ee2f to disappear
Dec  3 15:07:59.598: INFO: Pod pod-configmaps-c1effcba-59ed-47fa-a68b-eb0d5984ee2f no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:07:59.599: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5315" for this suite.
Dec  3 15:08:05.620: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:08:05.788: INFO: namespace secrets-5315 deletion completed in 6.181841693s
â€¢SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:08:05.788: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-5534
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0644 on tmpfs
Dec  3 15:08:05.941: INFO: Waiting up to 5m0s for pod "pod-8b74d433-fab5-4fab-8215-f38e2de14e96" in namespace "emptydir-5534" to be "success or failure"
Dec  3 15:08:05.945: INFO: Pod "pod-8b74d433-fab5-4fab-8215-f38e2de14e96": Phase="Pending", Reason="", readiness=false. Elapsed: 4.310757ms
Dec  3 15:08:07.951: INFO: Pod "pod-8b74d433-fab5-4fab-8215-f38e2de14e96": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010060703s
Dec  3 15:08:09.957: INFO: Pod "pod-8b74d433-fab5-4fab-8215-f38e2de14e96": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015336628s
STEP: Saw pod success
Dec  3 15:08:09.957: INFO: Pod "pod-8b74d433-fab5-4fab-8215-f38e2de14e96" satisfied condition "success or failure"
Dec  3 15:08:09.961: INFO: Trying to get logs from node izgw8afzp8040eoqk0qbhxz pod pod-8b74d433-fab5-4fab-8215-f38e2de14e96 container test-container: <nil>
STEP: delete the pod
Dec  3 15:08:09.982: INFO: Waiting for pod pod-8b74d433-fab5-4fab-8215-f38e2de14e96 to disappear
Dec  3 15:08:09.986: INFO: Pod pod-8b74d433-fab5-4fab-8215-f38e2de14e96 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:08:09.987: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5534" for this suite.
Dec  3 15:08:16.008: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:08:16.225: INFO: namespace emptydir-5534 deletion completed in 6.230858046s
â€¢SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:08:16.225: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-705
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0666 on tmpfs
Dec  3 15:08:16.376: INFO: Waiting up to 5m0s for pod "pod-195c38dc-5fc2-4da5-a108-87a6a6b38a94" in namespace "emptydir-705" to be "success or failure"
Dec  3 15:08:16.381: INFO: Pod "pod-195c38dc-5fc2-4da5-a108-87a6a6b38a94": Phase="Pending", Reason="", readiness=false. Elapsed: 4.200294ms
Dec  3 15:08:18.385: INFO: Pod "pod-195c38dc-5fc2-4da5-a108-87a6a6b38a94": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009176556s
Dec  3 15:08:20.390: INFO: Pod "pod-195c38dc-5fc2-4da5-a108-87a6a6b38a94": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014158549s
STEP: Saw pod success
Dec  3 15:08:20.391: INFO: Pod "pod-195c38dc-5fc2-4da5-a108-87a6a6b38a94" satisfied condition "success or failure"
Dec  3 15:08:20.395: INFO: Trying to get logs from node izgw8afzp8040eoqk0qbhxz pod pod-195c38dc-5fc2-4da5-a108-87a6a6b38a94 container test-container: <nil>
STEP: delete the pod
Dec  3 15:08:20.416: INFO: Waiting for pod pod-195c38dc-5fc2-4da5-a108-87a6a6b38a94 to disappear
Dec  3 15:08:20.420: INFO: Pod pod-195c38dc-5fc2-4da5-a108-87a6a6b38a94 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:08:20.420: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-705" for this suite.
Dec  3 15:08:26.442: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:08:26.604: INFO: namespace emptydir-705 deletion completed in 6.176998741s
â€¢SSS
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:08:26.605: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-5564
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Dec  3 15:08:26.757: INFO: Waiting up to 5m0s for pod "downward-api-1eab53ec-60f0-4522-a612-59daeb1d3ede" in namespace "downward-api-5564" to be "success or failure"
Dec  3 15:08:26.762: INFO: Pod "downward-api-1eab53ec-60f0-4522-a612-59daeb1d3ede": Phase="Pending", Reason="", readiness=false. Elapsed: 4.506967ms
Dec  3 15:08:28.767: INFO: Pod "downward-api-1eab53ec-60f0-4522-a612-59daeb1d3ede": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009959563s
STEP: Saw pod success
Dec  3 15:08:28.767: INFO: Pod "downward-api-1eab53ec-60f0-4522-a612-59daeb1d3ede" satisfied condition "success or failure"
Dec  3 15:08:28.771: INFO: Trying to get logs from node izgw8afzp8040eoqk0qbhxz pod downward-api-1eab53ec-60f0-4522-a612-59daeb1d3ede container dapi-container: <nil>
STEP: delete the pod
Dec  3 15:08:28.794: INFO: Waiting for pod downward-api-1eab53ec-60f0-4522-a612-59daeb1d3ede to disappear
Dec  3 15:08:28.798: INFO: Pod downward-api-1eab53ec-60f0-4522-a612-59daeb1d3ede no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:08:28.799: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5564" for this suite.
Dec  3 15:08:34.821: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:08:35.006: INFO: namespace downward-api-5564 deletion completed in 6.200057745s
â€¢SSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:08:35.007: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-3600
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
Dec  3 15:08:35.160: INFO: observed the pod list
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:08:45.606: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-3600" for this suite.
Dec  3 15:08:51.629: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:08:51.790: INFO: namespace pods-3600 deletion completed in 6.1756363s
â€¢SSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:08:51.790: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-1737
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Dec  3 15:08:51.941: INFO: Waiting up to 5m0s for pod "downward-api-791d6343-1309-4b85-ac4a-bbc7c02567d0" in namespace "downward-api-1737" to be "success or failure"
Dec  3 15:08:51.946: INFO: Pod "downward-api-791d6343-1309-4b85-ac4a-bbc7c02567d0": Phase="Pending", Reason="", readiness=false. Elapsed: 4.219417ms
Dec  3 15:08:53.951: INFO: Pod "downward-api-791d6343-1309-4b85-ac4a-bbc7c02567d0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009875043s
STEP: Saw pod success
Dec  3 15:08:53.951: INFO: Pod "downward-api-791d6343-1309-4b85-ac4a-bbc7c02567d0" satisfied condition "success or failure"
Dec  3 15:08:53.956: INFO: Trying to get logs from node izgw8afzp8040eoqk0qbhxz pod downward-api-791d6343-1309-4b85-ac4a-bbc7c02567d0 container dapi-container: <nil>
STEP: delete the pod
Dec  3 15:08:53.977: INFO: Waiting for pod downward-api-791d6343-1309-4b85-ac4a-bbc7c02567d0 to disappear
Dec  3 15:08:53.981: INFO: Pod downward-api-791d6343-1309-4b85-ac4a-bbc7c02567d0 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:08:53.981: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1737" for this suite.
Dec  3 15:09:00.003: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:09:00.169: INFO: namespace downward-api-1737 deletion completed in 6.180242137s
â€¢
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:09:00.169: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-4360
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-projected-zms4
STEP: Creating a pod to test atomic-volume-subpath
Dec  3 15:09:00.329: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-zms4" in namespace "subpath-4360" to be "success or failure"
Dec  3 15:09:00.333: INFO: Pod "pod-subpath-test-projected-zms4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.148286ms
Dec  3 15:09:02.339: INFO: Pod "pod-subpath-test-projected-zms4": Phase="Running", Reason="", readiness=true. Elapsed: 2.009398971s
Dec  3 15:09:04.344: INFO: Pod "pod-subpath-test-projected-zms4": Phase="Running", Reason="", readiness=true. Elapsed: 4.014994018s
Dec  3 15:09:06.349: INFO: Pod "pod-subpath-test-projected-zms4": Phase="Running", Reason="", readiness=true. Elapsed: 6.020256868s
Dec  3 15:09:08.355: INFO: Pod "pod-subpath-test-projected-zms4": Phase="Running", Reason="", readiness=true. Elapsed: 8.025808014s
Dec  3 15:09:10.361: INFO: Pod "pod-subpath-test-projected-zms4": Phase="Running", Reason="", readiness=true. Elapsed: 10.031361734s
Dec  3 15:09:12.366: INFO: Pod "pod-subpath-test-projected-zms4": Phase="Running", Reason="", readiness=true. Elapsed: 12.036905931s
Dec  3 15:09:14.371: INFO: Pod "pod-subpath-test-projected-zms4": Phase="Running", Reason="", readiness=true. Elapsed: 14.042196145s
Dec  3 15:09:16.377: INFO: Pod "pod-subpath-test-projected-zms4": Phase="Running", Reason="", readiness=true. Elapsed: 16.047661106s
Dec  3 15:09:18.382: INFO: Pod "pod-subpath-test-projected-zms4": Phase="Running", Reason="", readiness=true. Elapsed: 18.053098617s
Dec  3 15:09:20.388: INFO: Pod "pod-subpath-test-projected-zms4": Phase="Running", Reason="", readiness=true. Elapsed: 20.058736039s
Dec  3 15:09:22.393: INFO: Pod "pod-subpath-test-projected-zms4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.06404057s
STEP: Saw pod success
Dec  3 15:09:22.393: INFO: Pod "pod-subpath-test-projected-zms4" satisfied condition "success or failure"
Dec  3 15:09:22.398: INFO: Trying to get logs from node izgw8afzp8040eoqk0qbhxz pod pod-subpath-test-projected-zms4 container test-container-subpath-projected-zms4: <nil>
STEP: delete the pod
Dec  3 15:09:22.424: INFO: Waiting for pod pod-subpath-test-projected-zms4 to disappear
Dec  3 15:09:22.428: INFO: Pod pod-subpath-test-projected-zms4 no longer exists
STEP: Deleting pod pod-subpath-test-projected-zms4
Dec  3 15:09:22.428: INFO: Deleting pod "pod-subpath-test-projected-zms4" in namespace "subpath-4360"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:09:22.432: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-4360" for this suite.
Dec  3 15:09:28.454: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:09:28.615: INFO: namespace subpath-4360 deletion completed in 6.175796834s
â€¢SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:09:28.616: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-4508
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-02fd66c3-7b7f-4926-b578-27e592b57e16
STEP: Creating a pod to test consume configMaps
Dec  3 15:09:28.870: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-3b3d80fa-47b7-4c75-8853-89c84811ae58" in namespace "projected-4508" to be "success or failure"
Dec  3 15:09:28.875: INFO: Pod "pod-projected-configmaps-3b3d80fa-47b7-4c75-8853-89c84811ae58": Phase="Pending", Reason="", readiness=false. Elapsed: 4.340407ms
Dec  3 15:09:30.880: INFO: Pod "pod-projected-configmaps-3b3d80fa-47b7-4c75-8853-89c84811ae58": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00976331s
STEP: Saw pod success
Dec  3 15:09:30.880: INFO: Pod "pod-projected-configmaps-3b3d80fa-47b7-4c75-8853-89c84811ae58" satisfied condition "success or failure"
Dec  3 15:09:30.885: INFO: Trying to get logs from node izgw8afzp8040eoqk0qbhxz pod pod-projected-configmaps-3b3d80fa-47b7-4c75-8853-89c84811ae58 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec  3 15:09:30.906: INFO: Waiting for pod pod-projected-configmaps-3b3d80fa-47b7-4c75-8853-89c84811ae58 to disappear
Dec  3 15:09:30.910: INFO: Pod pod-projected-configmaps-3b3d80fa-47b7-4c75-8853-89c84811ae58 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:09:30.910: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4508" for this suite.
Dec  3 15:09:36.932: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:09:37.100: INFO: namespace projected-4508 deletion completed in 6.18247555s
â€¢SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:09:37.101: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-9533
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:81
Dec  3 15:09:37.252: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Dec  3 15:09:37.261: INFO: Waiting for terminating namespaces to be deleted...
Dec  3 15:09:37.265: INFO: 
Logging pods the kubelet thinks is on node izgw8afzp8040eoqk0qbhwz before test
Dec  3 15:09:37.286: INFO: coredns-858b686868-b8rw9 from kube-system started at 2019-12-03 14:26:51 +0000 UTC (1 container statuses recorded)
Dec  3 15:09:37.286: INFO: 	Container coredns ready: true, restart count 0
Dec  3 15:09:37.286: INFO: calico-typha-horizontal-autoscaler-554dfbfdd7-hrqhh from kube-system started at 2019-12-03 14:26:51 +0000 UTC (1 container statuses recorded)
Dec  3 15:09:37.286: INFO: 	Container autoscaler ready: true, restart count 0
Dec  3 15:09:37.286: INFO: addons-nginx-ingress-controller-8468678b64-fjw65 from kube-system started at 2019-12-03 14:26:51 +0000 UTC (1 container statuses recorded)
Dec  3 15:09:37.286: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Dec  3 15:09:37.286: INFO: calico-typha-vertical-autoscaler-656557779f-vhn2k from kube-system started at 2019-12-03 14:26:51 +0000 UTC (1 container statuses recorded)
Dec  3 15:09:37.286: INFO: 	Container autoscaler ready: true, restart count 3
Dec  3 15:09:37.286: INFO: blackbox-exporter-c87bdd467-vpznr from kube-system started at 2019-12-03 14:26:11 +0000 UTC (1 container statuses recorded)
Dec  3 15:09:37.286: INFO: 	Container blackbox-exporter ready: true, restart count 0
Dec  3 15:09:37.286: INFO: kube-proxy-6sx94 from kube-system started at 2019-12-03 14:26:11 +0000 UTC (1 container statuses recorded)
Dec  3 15:09:37.286: INFO: 	Container kube-proxy ready: true, restart count 0
Dec  3 15:09:37.286: INFO: coredns-858b686868-4hmrg from kube-system started at 2019-12-03 14:26:51 +0000 UTC (1 container statuses recorded)
Dec  3 15:09:37.286: INFO: 	Container coredns ready: true, restart count 0
Dec  3 15:09:37.286: INFO: addons-kubernetes-dashboard-5c8d9945bc-8pg45 from kube-system started at 2019-12-03 14:26:51 +0000 UTC (1 container statuses recorded)
Dec  3 15:09:37.286: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Dec  3 15:09:37.286: INFO: metrics-server-85dc4959bc-8q2rm from kube-system started at 2019-12-03 14:26:53 +0000 UTC (1 container statuses recorded)
Dec  3 15:09:37.286: INFO: 	Container metrics-server ready: true, restart count 0
Dec  3 15:09:37.286: INFO: node-problem-detector-zgkv5 from kube-system started at 2019-12-03 14:26:11 +0000 UTC (1 container statuses recorded)
Dec  3 15:09:37.286: INFO: 	Container node-problem-detector ready: true, restart count 0
Dec  3 15:09:37.286: INFO: addons-nginx-ingress-nginx-ingress-k8s-backend-88d6cff74-c9t7s from kube-system started at 2019-12-03 14:26:51 +0000 UTC (1 container statuses recorded)
Dec  3 15:09:37.286: INFO: 	Container nginx-ingress-nginx-ingress-k8s-backend ready: true, restart count 0
Dec  3 15:09:37.286: INFO: calico-node-7g9r2 from kube-system started at 2019-12-03 14:26:11 +0000 UTC (1 container statuses recorded)
Dec  3 15:09:37.286: INFO: 	Container calico-node ready: true, restart count 0
Dec  3 15:09:37.286: INFO: calico-kube-controllers-5d785bc598-n44xt from kube-system started at 2019-12-03 14:26:51 +0000 UTC (1 container statuses recorded)
Dec  3 15:09:37.286: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Dec  3 15:09:37.286: INFO: csi-disk-plugin-alicloud-zkswz from kube-system started at 2019-12-03 14:26:51 +0000 UTC (2 container statuses recorded)
Dec  3 15:09:37.286: INFO: 	Container csi-diskplugin ready: true, restart count 0
Dec  3 15:09:37.286: INFO: 	Container driver-registrar ready: true, restart count 0
Dec  3 15:09:37.286: INFO: vpn-shoot-6568b69f46-dhptx from kube-system started at 2019-12-03 14:26:53 +0000 UTC (1 container statuses recorded)
Dec  3 15:09:37.286: INFO: 	Container vpn-shoot ready: true, restart count 0
Dec  3 15:09:37.286: INFO: node-exporter-mt7nx from kube-system started at 2019-12-03 14:26:11 +0000 UTC (1 container statuses recorded)
Dec  3 15:09:37.286: INFO: 	Container node-exporter ready: true, restart count 0
Dec  3 15:09:37.286: INFO: 
Logging pods the kubelet thinks is on node izgw8afzp8040eoqk0qbhxz before test
Dec  3 15:09:37.305: INFO: calico-typha-deploy-5547c4cdc6-hndl5 from kube-system started at 2019-12-03 14:29:45 +0000 UTC (1 container statuses recorded)
Dec  3 15:09:37.305: INFO: 	Container calico-typha ready: true, restart count 0
Dec  3 15:09:37.305: INFO: node-exporter-9jl8n from kube-system started at 2019-12-03 14:26:15 +0000 UTC (1 container statuses recorded)
Dec  3 15:09:37.305: INFO: 	Container node-exporter ready: true, restart count 0
Dec  3 15:09:37.305: INFO: kube-proxy-t75hh from kube-system started at 2019-12-03 14:26:15 +0000 UTC (1 container statuses recorded)
Dec  3 15:09:37.305: INFO: 	Container kube-proxy ready: true, restart count 0
Dec  3 15:09:37.305: INFO: calico-node-4fgj7 from kube-system started at 2019-12-03 14:26:15 +0000 UTC (1 container statuses recorded)
Dec  3 15:09:37.305: INFO: 	Container calico-node ready: true, restart count 0
Dec  3 15:09:37.305: INFO: node-problem-detector-c9wdn from kube-system started at 2019-12-03 14:26:15 +0000 UTC (1 container statuses recorded)
Dec  3 15:09:37.305: INFO: 	Container node-problem-detector ready: true, restart count 0
Dec  3 15:09:37.305: INFO: csi-disk-plugin-alicloud-fqxvx from kube-system started at 2019-12-03 14:26:55 +0000 UTC (2 container statuses recorded)
Dec  3 15:09:37.305: INFO: 	Container csi-diskplugin ready: true, restart count 0
Dec  3 15:09:37.305: INFO: 	Container driver-registrar ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-dc5217ac-aa47-4c89-9480-b702fc20c915 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-dc5217ac-aa47-4c89-9480-b702fc20c915 off the node izgw8afzp8040eoqk0qbhxz
STEP: verifying the node doesn't have the label kubernetes.io/e2e-dc5217ac-aa47-4c89-9480-b702fc20c915
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:09:41.381: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-9533" for this suite.
Dec  3 15:09:59.400: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:09:59.560: INFO: namespace sched-pred-9533 deletion completed in 18.174793442s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:72
â€¢SSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:09:59.561: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-6882
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Dec  3 15:09:59.722: INFO: Waiting up to 5m0s for pod "downwardapi-volume-71af2706-55e1-4e96-8a42-2682d6490971" in namespace "downward-api-6882" to be "success or failure"
Dec  3 15:09:59.727: INFO: Pod "downwardapi-volume-71af2706-55e1-4e96-8a42-2682d6490971": Phase="Pending", Reason="", readiness=false. Elapsed: 4.983811ms
Dec  3 15:10:01.733: INFO: Pod "downwardapi-volume-71af2706-55e1-4e96-8a42-2682d6490971": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010502454s
STEP: Saw pod success
Dec  3 15:10:01.733: INFO: Pod "downwardapi-volume-71af2706-55e1-4e96-8a42-2682d6490971" satisfied condition "success or failure"
Dec  3 15:10:01.737: INFO: Trying to get logs from node izgw8afzp8040eoqk0qbhxz pod downwardapi-volume-71af2706-55e1-4e96-8a42-2682d6490971 container client-container: <nil>
STEP: delete the pod
Dec  3 15:10:01.768: INFO: Waiting for pod downwardapi-volume-71af2706-55e1-4e96-8a42-2682d6490971 to disappear
Dec  3 15:10:01.773: INFO: Pod downwardapi-volume-71af2706-55e1-4e96-8a42-2682d6490971 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:10:01.773: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6882" for this suite.
Dec  3 15:10:07.795: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:10:07.961: INFO: namespace downward-api-6882 deletion completed in 6.180401059s
â€¢SS
------------------------------
[sig-storage] EmptyDir volumes 
  pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:10:07.961: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-84
STEP: Waiting for a default service account to be provisioned in namespace
[It] pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating Pod
STEP: Waiting for the pod running
STEP: Geting the pod
STEP: Reading file content from the nginx-container
Dec  3 15:10:12.138: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmwqx-5aq.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec pod-sharedvolume-53f0fcb6-5169-4559-acd1-0057fceb17c7 -c busybox-main-container --namespace=emptydir-84 -- cat /usr/share/volumeshare/shareddata.txt'
Dec  3 15:10:12.928: INFO: stderr: ""
Dec  3 15:10:12.928: INFO: stdout: "Hello from the busy-box sub-container\n"
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:10:12.928: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-84" for this suite.
Dec  3 15:10:18.952: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:10:19.125: INFO: namespace emptydir-84 deletion completed in 6.188254631s
â€¢SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:10:19.125: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-5820
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-404558a6-6ae4-4201-b6ae-87cb7dc1cb6f
STEP: Creating a pod to test consume configMaps
Dec  3 15:10:19.289: INFO: Waiting up to 5m0s for pod "pod-configmaps-221ee351-a18c-402b-97cd-83d64b20674b" in namespace "configmap-5820" to be "success or failure"
Dec  3 15:10:19.293: INFO: Pod "pod-configmaps-221ee351-a18c-402b-97cd-83d64b20674b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.307831ms
Dec  3 15:10:21.298: INFO: Pod "pod-configmaps-221ee351-a18c-402b-97cd-83d64b20674b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009889326s
STEP: Saw pod success
Dec  3 15:10:21.299: INFO: Pod "pod-configmaps-221ee351-a18c-402b-97cd-83d64b20674b" satisfied condition "success or failure"
Dec  3 15:10:21.303: INFO: Trying to get logs from node izgw8afzp8040eoqk0qbhxz pod pod-configmaps-221ee351-a18c-402b-97cd-83d64b20674b container configmap-volume-test: <nil>
STEP: delete the pod
Dec  3 15:10:21.325: INFO: Waiting for pod pod-configmaps-221ee351-a18c-402b-97cd-83d64b20674b to disappear
Dec  3 15:10:21.329: INFO: Pod pod-configmaps-221ee351-a18c-402b-97cd-83d64b20674b no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:10:21.329: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5820" for this suite.
Dec  3 15:10:27.351: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:10:27.518: INFO: namespace configmap-5820 deletion completed in 6.181560405s
â€¢SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:10:27.519: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-7876
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-0d33cb32-3533-4f71-a856-fe56e9c651f5
STEP: Creating a pod to test consume configMaps
Dec  3 15:10:27.674: INFO: Waiting up to 5m0s for pod "pod-configmaps-d88720d1-713b-4ec8-a4aa-ff3e7f79bfa2" in namespace "configmap-7876" to be "success or failure"
Dec  3 15:10:27.678: INFO: Pod "pod-configmaps-d88720d1-713b-4ec8-a4aa-ff3e7f79bfa2": Phase="Pending", Reason="", readiness=false. Elapsed: 4.154164ms
Dec  3 15:10:29.684: INFO: Pod "pod-configmaps-d88720d1-713b-4ec8-a4aa-ff3e7f79bfa2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010020372s
STEP: Saw pod success
Dec  3 15:10:29.684: INFO: Pod "pod-configmaps-d88720d1-713b-4ec8-a4aa-ff3e7f79bfa2" satisfied condition "success or failure"
Dec  3 15:10:29.689: INFO: Trying to get logs from node izgw8afzp8040eoqk0qbhxz pod pod-configmaps-d88720d1-713b-4ec8-a4aa-ff3e7f79bfa2 container configmap-volume-test: <nil>
STEP: delete the pod
Dec  3 15:10:29.707: INFO: Waiting for pod pod-configmaps-d88720d1-713b-4ec8-a4aa-ff3e7f79bfa2 to disappear
Dec  3 15:10:29.712: INFO: Pod pod-configmaps-d88720d1-713b-4ec8-a4aa-ff3e7f79bfa2 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:10:29.712: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7876" for this suite.
Dec  3 15:10:35.733: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:10:35.911: INFO: namespace configmap-7876 deletion completed in 6.192333249s
â€¢SSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:10:35.912: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-2728
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl label
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1210
STEP: creating the pod
Dec  3 15:10:36.062: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmwqx-5aq.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config create -f - --namespace=kubectl-2728'
Dec  3 15:10:36.267: INFO: stderr: ""
Dec  3 15:10:36.267: INFO: stdout: "pod/pause created\n"
Dec  3 15:10:36.267: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Dec  3 15:10:36.267: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-2728" to be "running and ready"
Dec  3 15:10:36.271: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 4.26608ms
Dec  3 15:10:38.276: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.00955794s
Dec  3 15:10:38.276: INFO: Pod "pause" satisfied condition "running and ready"
Dec  3 15:10:38.276: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: adding the label testing-label with value testing-label-value to a pod
Dec  3 15:10:38.276: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmwqx-5aq.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config label pods pause testing-label=testing-label-value --namespace=kubectl-2728'
Dec  3 15:10:38.435: INFO: stderr: ""
Dec  3 15:10:38.435: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Dec  3 15:10:38.435: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmwqx-5aq.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pod pause -L testing-label --namespace=kubectl-2728'
Dec  3 15:10:38.581: INFO: stderr: ""
Dec  3 15:10:38.582: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Dec  3 15:10:38.582: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmwqx-5aq.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config label pods pause testing-label- --namespace=kubectl-2728'
Dec  3 15:10:38.734: INFO: stderr: ""
Dec  3 15:10:38.734: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Dec  3 15:10:38.735: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmwqx-5aq.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pod pause -L testing-label --namespace=kubectl-2728'
Dec  3 15:10:38.823: INFO: stderr: ""
Dec  3 15:10:38.823: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    \n"
[AfterEach] [k8s.io] Kubectl label
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1217
STEP: using delete to clean up resources
Dec  3 15:10:38.823: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmwqx-5aq.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config delete --grace-period=0 --force -f - --namespace=kubectl-2728'
Dec  3 15:10:38.912: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  3 15:10:38.912: INFO: stdout: "pod \"pause\" force deleted\n"
Dec  3 15:10:38.912: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmwqx-5aq.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get rc,svc -l name=pause --no-headers --namespace=kubectl-2728'
Dec  3 15:10:39.009: INFO: stderr: "No resources found.\n"
Dec  3 15:10:39.009: INFO: stdout: ""
Dec  3 15:10:39.009: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmwqx-5aq.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods -l name=pause --namespace=kubectl-2728 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec  3 15:10:39.139: INFO: stderr: ""
Dec  3 15:10:39.139: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:10:39.139: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2728" for this suite.
Dec  3 15:10:45.162: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:10:45.341: INFO: namespace kubectl-2728 deletion completed in 6.193860668s
â€¢SSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:10:45.341: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-1163
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test env composition
Dec  3 15:10:45.499: INFO: Waiting up to 5m0s for pod "var-expansion-3136aa04-6c1d-40ec-86b4-d5bda9888ab9" in namespace "var-expansion-1163" to be "success or failure"
Dec  3 15:10:45.503: INFO: Pod "var-expansion-3136aa04-6c1d-40ec-86b4-d5bda9888ab9": Phase="Pending", Reason="", readiness=false. Elapsed: 4.285373ms
Dec  3 15:10:47.508: INFO: Pod "var-expansion-3136aa04-6c1d-40ec-86b4-d5bda9888ab9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009795036s
STEP: Saw pod success
Dec  3 15:10:47.509: INFO: Pod "var-expansion-3136aa04-6c1d-40ec-86b4-d5bda9888ab9" satisfied condition "success or failure"
Dec  3 15:10:47.513: INFO: Trying to get logs from node izgw8afzp8040eoqk0qbhxz pod var-expansion-3136aa04-6c1d-40ec-86b4-d5bda9888ab9 container dapi-container: <nil>
STEP: delete the pod
Dec  3 15:10:47.535: INFO: Waiting for pod var-expansion-3136aa04-6c1d-40ec-86b4-d5bda9888ab9 to disappear
Dec  3 15:10:47.540: INFO: Pod var-expansion-3136aa04-6c1d-40ec-86b4-d5bda9888ab9 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:10:47.540: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-1163" for this suite.
Dec  3 15:10:53.562: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:10:53.732: INFO: namespace var-expansion-1163 deletion completed in 6.1839908s
â€¢SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:10:53.732: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-4928
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Dec  3 15:10:53.895: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-4928,SelfLink:/api/v1/namespaces/watch-4928/configmaps/e2e-watch-test-watch-closed,UID:8be3275f-df05-41b5-b67d-0b6f7096d453,ResourceVersion:13261,Generation:0,CreationTimestamp:2019-12-03 15:10:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec  3 15:10:53.895: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-4928,SelfLink:/api/v1/namespaces/watch-4928/configmaps/e2e-watch-test-watch-closed,UID:8be3275f-df05-41b5-b67d-0b6f7096d453,ResourceVersion:13262,Generation:0,CreationTimestamp:2019-12-03 15:10:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Dec  3 15:10:53.913: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-4928,SelfLink:/api/v1/namespaces/watch-4928/configmaps/e2e-watch-test-watch-closed,UID:8be3275f-df05-41b5-b67d-0b6f7096d453,ResourceVersion:13263,Generation:0,CreationTimestamp:2019-12-03 15:10:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec  3 15:10:53.913: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-4928,SelfLink:/api/v1/namespaces/watch-4928/configmaps/e2e-watch-test-watch-closed,UID:8be3275f-df05-41b5-b67d-0b6f7096d453,ResourceVersion:13265,Generation:0,CreationTimestamp:2019-12-03 15:10:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:10:53.914: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-4928" for this suite.
Dec  3 15:10:59.932: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:11:00.101: INFO: namespace watch-4928 deletion completed in 6.182392541s
â€¢SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:11:00.101: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2673
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name s-test-opt-del-0a7b0f1f-487f-4383-aef3-efd82cc46af7
STEP: Creating secret with name s-test-opt-upd-7ef32224-9cb9-40cd-a1e4-c8e6b5ae2477
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-0a7b0f1f-487f-4383-aef3-efd82cc46af7
STEP: Updating secret s-test-opt-upd-7ef32224-9cb9-40cd-a1e4-c8e6b5ae2477
STEP: Creating secret with name s-test-opt-create-2c387714-a7d9-4455-8cdc-de0ef292e457
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:12:23.129: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2673" for this suite.
Dec  3 15:12:45.151: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:12:45.367: INFO: namespace projected-2673 deletion completed in 22.231751444s
â€¢SSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:12:45.367: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-6127
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0644 on tmpfs
Dec  3 15:12:45.522: INFO: Waiting up to 5m0s for pod "pod-ac048e61-2fb7-4586-9f45-fa0e237e4ed9" in namespace "emptydir-6127" to be "success or failure"
Dec  3 15:12:45.526: INFO: Pod "pod-ac048e61-2fb7-4586-9f45-fa0e237e4ed9": Phase="Pending", Reason="", readiness=false. Elapsed: 4.209774ms
Dec  3 15:12:47.532: INFO: Pod "pod-ac048e61-2fb7-4586-9f45-fa0e237e4ed9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009820526s
STEP: Saw pod success
Dec  3 15:12:47.532: INFO: Pod "pod-ac048e61-2fb7-4586-9f45-fa0e237e4ed9" satisfied condition "success or failure"
Dec  3 15:12:47.537: INFO: Trying to get logs from node izgw8afzp8040eoqk0qbhxz pod pod-ac048e61-2fb7-4586-9f45-fa0e237e4ed9 container test-container: <nil>
STEP: delete the pod
Dec  3 15:12:47.558: INFO: Waiting for pod pod-ac048e61-2fb7-4586-9f45-fa0e237e4ed9 to disappear
Dec  3 15:12:47.562: INFO: Pod pod-ac048e61-2fb7-4586-9f45-fa0e237e4ed9 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:12:47.562: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6127" for this suite.
Dec  3 15:12:53.584: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:12:53.750: INFO: namespace emptydir-6127 deletion completed in 6.180264336s
â€¢SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:12:53.751: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-1477
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
Dec  3 15:13:03.973: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W1203 15:13:03.973126    5085 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:13:03.973: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-1477" for this suite.
Dec  3 15:13:09.992: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:13:10.159: INFO: namespace gc-1477 deletion completed in 6.18110626s
â€¢SSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:13:10.159: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-986
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:13:10.319: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-986" for this suite.
Dec  3 15:13:32.342: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:13:32.550: INFO: namespace kubelet-test-986 deletion completed in 22.224997829s
â€¢SSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:13:32.551: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-2637
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0644 on node default medium
Dec  3 15:13:32.703: INFO: Waiting up to 5m0s for pod "pod-fa1282fb-15dd-45f1-a1fc-a7713db99e17" in namespace "emptydir-2637" to be "success or failure"
Dec  3 15:13:32.707: INFO: Pod "pod-fa1282fb-15dd-45f1-a1fc-a7713db99e17": Phase="Pending", Reason="", readiness=false. Elapsed: 4.379855ms
Dec  3 15:13:34.713: INFO: Pod "pod-fa1282fb-15dd-45f1-a1fc-a7713db99e17": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009841224s
STEP: Saw pod success
Dec  3 15:13:34.713: INFO: Pod "pod-fa1282fb-15dd-45f1-a1fc-a7713db99e17" satisfied condition "success or failure"
Dec  3 15:13:34.718: INFO: Trying to get logs from node izgw8afzp8040eoqk0qbhxz pod pod-fa1282fb-15dd-45f1-a1fc-a7713db99e17 container test-container: <nil>
STEP: delete the pod
Dec  3 15:13:34.740: INFO: Waiting for pod pod-fa1282fb-15dd-45f1-a1fc-a7713db99e17 to disappear
Dec  3 15:13:34.745: INFO: Pod pod-fa1282fb-15dd-45f1-a1fc-a7713db99e17 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:13:34.745: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2637" for this suite.
Dec  3 15:13:40.767: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:13:40.936: INFO: namespace emptydir-2637 deletion completed in 6.1839395s
â€¢SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:13:40.937: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-6919
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1456
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Dec  3 15:13:41.087: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmwqx-5aq.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=kubectl-6919'
Dec  3 15:13:41.225: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Dec  3 15:13:41.225: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: verifying the pod controlled by rc e2e-test-nginx-rc was created
STEP: confirm that you can get logs from an rc
Dec  3 15:13:41.234: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-glrnf]
Dec  3 15:13:41.234: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-glrnf" in namespace "kubectl-6919" to be "running and ready"
Dec  3 15:13:41.239: INFO: Pod "e2e-test-nginx-rc-glrnf": Phase="Pending", Reason="", readiness=false. Elapsed: 4.427005ms
Dec  3 15:13:43.244: INFO: Pod "e2e-test-nginx-rc-glrnf": Phase="Running", Reason="", readiness=true. Elapsed: 2.009638525s
Dec  3 15:13:43.244: INFO: Pod "e2e-test-nginx-rc-glrnf" satisfied condition "running and ready"
Dec  3 15:13:43.244: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-glrnf]
Dec  3 15:13:43.244: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmwqx-5aq.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config logs rc/e2e-test-nginx-rc --namespace=kubectl-6919'
Dec  3 15:13:43.352: INFO: stderr: ""
Dec  3 15:13:43.352: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1461
Dec  3 15:13:43.352: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmwqx-5aq.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config delete rc e2e-test-nginx-rc --namespace=kubectl-6919'
Dec  3 15:13:43.448: INFO: stderr: ""
Dec  3 15:13:43.448: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:13:43.448: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6919" for this suite.
Dec  3 15:14:05.471: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:14:05.682: INFO: namespace kubectl-6919 deletion completed in 22.226458552s
â€¢SSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:14:05.683: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-7691
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-5c65805a-63a1-409a-b991-2b3af7b2e44c
STEP: Creating a pod to test consume secrets
Dec  3 15:14:05.841: INFO: Waiting up to 5m0s for pod "pod-secrets-1bf8bb7e-7dff-463c-84fd-15812d6104e1" in namespace "secrets-7691" to be "success or failure"
Dec  3 15:14:05.845: INFO: Pod "pod-secrets-1bf8bb7e-7dff-463c-84fd-15812d6104e1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.298101ms
Dec  3 15:14:07.850: INFO: Pod "pod-secrets-1bf8bb7e-7dff-463c-84fd-15812d6104e1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009867377s
STEP: Saw pod success
Dec  3 15:14:07.851: INFO: Pod "pod-secrets-1bf8bb7e-7dff-463c-84fd-15812d6104e1" satisfied condition "success or failure"
Dec  3 15:14:07.855: INFO: Trying to get logs from node izgw8afzp8040eoqk0qbhxz pod pod-secrets-1bf8bb7e-7dff-463c-84fd-15812d6104e1 container secret-volume-test: <nil>
STEP: delete the pod
Dec  3 15:14:07.877: INFO: Waiting for pod pod-secrets-1bf8bb7e-7dff-463c-84fd-15812d6104e1 to disappear
Dec  3 15:14:07.881: INFO: Pod pod-secrets-1bf8bb7e-7dff-463c-84fd-15812d6104e1 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:14:07.881: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7691" for this suite.
Dec  3 15:14:13.904: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:14:14.108: INFO: namespace secrets-7691 deletion completed in 6.219627852s
â€¢SSSSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:14:14.109: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-3145
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating replication controller my-hostname-basic-14b7b809-5663-4197-8f99-93cadeecb306
Dec  3 15:14:14.265: INFO: Pod name my-hostname-basic-14b7b809-5663-4197-8f99-93cadeecb306: Found 0 pods out of 1
Dec  3 15:14:19.271: INFO: Pod name my-hostname-basic-14b7b809-5663-4197-8f99-93cadeecb306: Found 1 pods out of 1
Dec  3 15:14:19.271: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-14b7b809-5663-4197-8f99-93cadeecb306" are running
Dec  3 15:14:19.276: INFO: Pod "my-hostname-basic-14b7b809-5663-4197-8f99-93cadeecb306-sjkkw" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-12-03 15:14:14 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-12-03 15:14:15 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-12-03 15:14:15 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-12-03 15:14:14 +0000 UTC Reason: Message:}])
Dec  3 15:14:19.276: INFO: Trying to dial the pod
Dec  3 15:14:24.382: INFO: Controller my-hostname-basic-14b7b809-5663-4197-8f99-93cadeecb306: Got expected result from replica 1 [my-hostname-basic-14b7b809-5663-4197-8f99-93cadeecb306-sjkkw]: "my-hostname-basic-14b7b809-5663-4197-8f99-93cadeecb306-sjkkw", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:14:24.382: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-3145" for this suite.
Dec  3 15:14:30.409: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:14:30.579: INFO: namespace replication-controller-3145 deletion completed in 6.188990022s
â€¢SSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:14:30.579: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-9667
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-upd-8d6ca643-498d-4ed1-87bc-cfd1742c3995
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-8d6ca643-498d-4ed1-87bc-cfd1742c3995
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:14:34.870: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9667" for this suite.
Dec  3 15:14:50.893: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:14:51.056: INFO: namespace configmap-9667 deletion completed in 16.177895338s
â€¢S
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:14:51.056: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-1942
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Dec  3 15:14:51.201: INFO: Creating deployment "test-recreate-deployment"
Dec  3 15:14:51.206: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Dec  3 15:14:51.217: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
Dec  3 15:14:53.228: INFO: Waiting deployment "test-recreate-deployment" to complete
Dec  3 15:14:53.232: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Dec  3 15:14:53.241: INFO: Updating deployment test-recreate-deployment
Dec  3 15:14:53.241: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
Dec  3 15:14:53.278: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment,GenerateName:,Namespace:deployment-1942,SelfLink:/apis/apps/v1/namespaces/deployment-1942/deployments/test-recreate-deployment,UID:803dbb4f-13bc-4a8d-8ba7-736959b77ce2,ResourceVersion:14324,Generation:2,CreationTimestamp:2019-12-03 15:14:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[{Available False 2019-12-03 15:14:53 +0000 UTC 2019-12-03 15:14:53 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-12-03 15:14:53 +0000 UTC 2019-12-03 15:14:51 +0000 UTC ReplicaSetUpdated ReplicaSet "test-recreate-deployment-5c8c9cc69d" is progressing.}],ReadyReplicas:0,CollisionCount:nil,},}

Dec  3 15:14:53.286: INFO: New ReplicaSet "test-recreate-deployment-5c8c9cc69d" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-5c8c9cc69d,GenerateName:,Namespace:deployment-1942,SelfLink:/apis/apps/v1/namespaces/deployment-1942/replicasets/test-recreate-deployment-5c8c9cc69d,UID:ea09a871-fe4b-4836-a253-78e3d78c2a04,ResourceVersion:14323,Generation:1,CreationTimestamp:2019-12-03 15:14:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5c8c9cc69d,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 803dbb4f-13bc-4a8d-8ba7-736959b77ce2 0xc003b5f167 0xc003b5f168}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 5c8c9cc69d,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5c8c9cc69d,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Dec  3 15:14:53.286: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Dec  3 15:14:53.286: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-6df85df6b9,GenerateName:,Namespace:deployment-1942,SelfLink:/apis/apps/v1/namespaces/deployment-1942/replicasets/test-recreate-deployment-6df85df6b9,UID:67e31416-5cf8-4175-9b98-84a34522c23c,ResourceVersion:14316,Generation:2,CreationTimestamp:2019-12-03 15:14:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 6df85df6b9,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 803dbb4f-13bc-4a8d-8ba7-736959b77ce2 0xc003b5f237 0xc003b5f238}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 6df85df6b9,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 6df85df6b9,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Dec  3 15:14:53.291: INFO: Pod "test-recreate-deployment-5c8c9cc69d-vpkhj" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-5c8c9cc69d-vpkhj,GenerateName:test-recreate-deployment-5c8c9cc69d-,Namespace:deployment-1942,SelfLink:/api/v1/namespaces/deployment-1942/pods/test-recreate-deployment-5c8c9cc69d-vpkhj,UID:807ae519-b403-4d63-8d7f-f09304da6f27,ResourceVersion:14325,Generation:0,CreationTimestamp:2019-12-03 15:14:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5c8c9cc69d,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-recreate-deployment-5c8c9cc69d ea09a871-fe4b-4836-a253-78e3d78c2a04 0xc003b5fb17 0xc003b5fb18}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-hkqz5 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-hkqz5,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-hkqz5 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw8afzp8040eoqk0qbhxz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003b5fb80} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003b5fba0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 15:14:53 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 15:14:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 15:14:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 15:14:53 +0000 UTC  }],Message:,Reason:,HostIP:10.250.31.244,PodIP:,StartTime:2019-12-03 15:14:53 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:14:53.291: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-1942" for this suite.
Dec  3 15:14:59.313: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:14:59.521: INFO: namespace deployment-1942 deletion completed in 6.221964726s
â€¢SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:14:59.521: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9113
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-map-e2218683-9eb9-4eeb-9ad2-05f5831acda5
STEP: Creating a pod to test consume configMaps
Dec  3 15:14:59.699: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-73b819c2-c78f-4a36-97a2-83cb8b285d05" in namespace "projected-9113" to be "success or failure"
Dec  3 15:14:59.703: INFO: Pod "pod-projected-configmaps-73b819c2-c78f-4a36-97a2-83cb8b285d05": Phase="Pending", Reason="", readiness=false. Elapsed: 4.396069ms
Dec  3 15:15:01.708: INFO: Pod "pod-projected-configmaps-73b819c2-c78f-4a36-97a2-83cb8b285d05": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009791178s
STEP: Saw pod success
Dec  3 15:15:01.709: INFO: Pod "pod-projected-configmaps-73b819c2-c78f-4a36-97a2-83cb8b285d05" satisfied condition "success or failure"
Dec  3 15:15:01.713: INFO: Trying to get logs from node izgw8afzp8040eoqk0qbhxz pod pod-projected-configmaps-73b819c2-c78f-4a36-97a2-83cb8b285d05 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec  3 15:15:01.735: INFO: Waiting for pod pod-projected-configmaps-73b819c2-c78f-4a36-97a2-83cb8b285d05 to disappear
Dec  3 15:15:01.739: INFO: Pod pod-projected-configmaps-73b819c2-c78f-4a36-97a2-83cb8b285d05 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:15:01.739: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9113" for this suite.
Dec  3 15:15:07.762: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:15:07.927: INFO: namespace projected-9113 deletion completed in 6.180707577s
â€¢
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:15:07.927: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-5614
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
Dec  3 15:15:08.076: INFO: PodSpec: initContainers in spec.initContainers
Dec  3 15:15:53.667: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-89561e35-7ee6-4706-9f2d-d64bce373db7", GenerateName:"", Namespace:"init-container-5614", SelfLink:"/api/v1/namespaces/init-container-5614/pods/pod-init-89561e35-7ee6-4706-9f2d-d64bce373db7", UID:"7210a967-7a19-461a-85bc-86dc548c11bf", ResourceVersion:"14560", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63710982908, loc:(*time.Location)(0x7ed1a20)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"76127257"}, Annotations:map[string]string{"cni.projectcalico.org/podIP":"100.64.1.142/32", "kubernetes.io/psp":"e2e-test-privileged-psp"}, OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-s6qdm", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc002a87980), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-s6qdm", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-s6qdm", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-s6qdm", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc0033bcdd8), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"izgw8afzp8040eoqk0qbhxz", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc0020425a0), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0033bce50)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0033bce70)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc0033bce78), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc0033bce7c), PreemptionPolicy:(*v1.PreemptionPolicy)(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710982908, loc:(*time.Location)(0x7ed1a20)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710982908, loc:(*time.Location)(0x7ed1a20)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710982908, loc:(*time.Location)(0x7ed1a20)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710982908, loc:(*time.Location)(0x7ed1a20)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.250.31.244", PodIP:"100.64.1.142", StartTime:(*v1.Time)(0xc003b9caa0), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc002cc48c0)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc002cc4930)}, Ready:false, RestartCount:3, Image:"busybox:1.29", ImageID:"docker-pullable://busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"docker://cd4ce8b4e18cdf14445ed0adcd3a8432a79bfd924c00de51aee3c8ac071751ee"}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc003b9cae0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:""}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc003b9cac0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:""}}, QOSClass:"Guaranteed"}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:15:53.668: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-5614" for this suite.
Dec  3 15:16:15.690: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:16:15.861: INFO: namespace init-container-5614 deletion completed in 22.185338485s
â€¢
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:16:15.861: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-8852
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating Redis RC
Dec  3 15:16:16.010: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmwqx-5aq.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config create -f - --namespace=kubectl-8852'
Dec  3 15:16:16.279: INFO: stderr: ""
Dec  3 15:16:16.279: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Dec  3 15:16:17.284: INFO: Selector matched 1 pods for map[app:redis]
Dec  3 15:16:17.284: INFO: Found 0 / 1
Dec  3 15:16:18.285: INFO: Selector matched 1 pods for map[app:redis]
Dec  3 15:16:18.285: INFO: Found 1 / 1
Dec  3 15:16:18.285: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Dec  3 15:16:18.290: INFO: Selector matched 1 pods for map[app:redis]
Dec  3 15:16:18.290: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Dec  3 15:16:18.290: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmwqx-5aq.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config patch pod redis-master-wdg6g --namespace=kubectl-8852 -p {"metadata":{"annotations":{"x":"y"}}}'
Dec  3 15:16:18.441: INFO: stderr: ""
Dec  3 15:16:18.441: INFO: stdout: "pod/redis-master-wdg6g patched\n"
STEP: checking annotations
Dec  3 15:16:18.446: INFO: Selector matched 1 pods for map[app:redis]
Dec  3 15:16:18.446: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:16:18.446: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8852" for this suite.
Dec  3 15:16:40.471: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:16:40.681: INFO: namespace kubectl-8852 deletion completed in 22.226140747s
â€¢SSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:16:40.681: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-6012
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap configmap-6012/configmap-test-24215022-340d-4e33-b888-0db4179e9ed6
STEP: Creating a pod to test consume configMaps
Dec  3 15:16:40.845: INFO: Waiting up to 5m0s for pod "pod-configmaps-9009437c-9f1d-4393-bb9a-660cd0ab1b8e" in namespace "configmap-6012" to be "success or failure"
Dec  3 15:16:40.850: INFO: Pod "pod-configmaps-9009437c-9f1d-4393-bb9a-660cd0ab1b8e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.371849ms
Dec  3 15:16:42.855: INFO: Pod "pod-configmaps-9009437c-9f1d-4393-bb9a-660cd0ab1b8e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00959051s
STEP: Saw pod success
Dec  3 15:16:42.855: INFO: Pod "pod-configmaps-9009437c-9f1d-4393-bb9a-660cd0ab1b8e" satisfied condition "success or failure"
Dec  3 15:16:42.859: INFO: Trying to get logs from node izgw8afzp8040eoqk0qbhxz pod pod-configmaps-9009437c-9f1d-4393-bb9a-660cd0ab1b8e container env-test: <nil>
STEP: delete the pod
Dec  3 15:16:42.882: INFO: Waiting for pod pod-configmaps-9009437c-9f1d-4393-bb9a-660cd0ab1b8e to disappear
Dec  3 15:16:42.886: INFO: Pod pod-configmaps-9009437c-9f1d-4393-bb9a-660cd0ab1b8e no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:16:42.886: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6012" for this suite.
Dec  3 15:16:48.908: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:16:49.118: INFO: namespace configmap-6012 deletion completed in 6.22458574s
â€¢SSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:16:49.118: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-5969
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Dec  3 15:16:49.272: INFO: Waiting up to 5m0s for pod "downwardapi-volume-3ca38093-e5ca-466d-b301-88c7bf460bed" in namespace "downward-api-5969" to be "success or failure"
Dec  3 15:16:49.276: INFO: Pod "downwardapi-volume-3ca38093-e5ca-466d-b301-88c7bf460bed": Phase="Pending", Reason="", readiness=false. Elapsed: 4.433973ms
Dec  3 15:16:51.282: INFO: Pod "downwardapi-volume-3ca38093-e5ca-466d-b301-88c7bf460bed": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009809938s
STEP: Saw pod success
Dec  3 15:16:51.282: INFO: Pod "downwardapi-volume-3ca38093-e5ca-466d-b301-88c7bf460bed" satisfied condition "success or failure"
Dec  3 15:16:51.286: INFO: Trying to get logs from node izgw8afzp8040eoqk0qbhxz pod downwardapi-volume-3ca38093-e5ca-466d-b301-88c7bf460bed container client-container: <nil>
STEP: delete the pod
Dec  3 15:16:51.314: INFO: Waiting for pod downwardapi-volume-3ca38093-e5ca-466d-b301-88c7bf460bed to disappear
Dec  3 15:16:51.318: INFO: Pod downwardapi-volume-3ca38093-e5ca-466d-b301-88c7bf460bed no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:16:51.318: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5969" for this suite.
Dec  3 15:16:57.340: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:16:57.503: INFO: namespace downward-api-5969 deletion completed in 6.177115704s
â€¢SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:16:57.503: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-7124
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0777 on node default medium
Dec  3 15:16:57.657: INFO: Waiting up to 5m0s for pod "pod-3e4e9f53-21b6-4dfa-afbb-2cca48c79529" in namespace "emptydir-7124" to be "success or failure"
Dec  3 15:16:57.661: INFO: Pod "pod-3e4e9f53-21b6-4dfa-afbb-2cca48c79529": Phase="Pending", Reason="", readiness=false. Elapsed: 4.153029ms
Dec  3 15:16:59.667: INFO: Pod "pod-3e4e9f53-21b6-4dfa-afbb-2cca48c79529": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010045795s
STEP: Saw pod success
Dec  3 15:16:59.667: INFO: Pod "pod-3e4e9f53-21b6-4dfa-afbb-2cca48c79529" satisfied condition "success or failure"
Dec  3 15:16:59.671: INFO: Trying to get logs from node izgw8afzp8040eoqk0qbhxz pod pod-3e4e9f53-21b6-4dfa-afbb-2cca48c79529 container test-container: <nil>
STEP: delete the pod
Dec  3 15:16:59.692: INFO: Waiting for pod pod-3e4e9f53-21b6-4dfa-afbb-2cca48c79529 to disappear
Dec  3 15:16:59.697: INFO: Pod pod-3e4e9f53-21b6-4dfa-afbb-2cca48c79529 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:16:59.697: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7124" for this suite.
Dec  3 15:17:05.718: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:17:05.884: INFO: namespace emptydir-7124 deletion completed in 6.179707484s
â€¢SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:17:05.884: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7567
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Dec  3 15:17:06.037: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d992fffe-6af4-4ccc-9cbc-191891c32ad8" in namespace "projected-7567" to be "success or failure"
Dec  3 15:17:06.041: INFO: Pod "downwardapi-volume-d992fffe-6af4-4ccc-9cbc-191891c32ad8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.320391ms
Dec  3 15:17:08.047: INFO: Pod "downwardapi-volume-d992fffe-6af4-4ccc-9cbc-191891c32ad8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01013138s
STEP: Saw pod success
Dec  3 15:17:08.047: INFO: Pod "downwardapi-volume-d992fffe-6af4-4ccc-9cbc-191891c32ad8" satisfied condition "success or failure"
Dec  3 15:17:08.056: INFO: Trying to get logs from node izgw8afzp8040eoqk0qbhxz pod downwardapi-volume-d992fffe-6af4-4ccc-9cbc-191891c32ad8 container client-container: <nil>
STEP: delete the pod
Dec  3 15:17:08.079: INFO: Waiting for pod downwardapi-volume-d992fffe-6af4-4ccc-9cbc-191891c32ad8 to disappear
Dec  3 15:17:08.083: INFO: Pod downwardapi-volume-d992fffe-6af4-4ccc-9cbc-191891c32ad8 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:17:08.083: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7567" for this suite.
Dec  3 15:17:14.105: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:17:14.273: INFO: namespace projected-7567 deletion completed in 6.182798134s
â€¢SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:17:14.274: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-7425
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:81
Dec  3 15:17:14.418: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Dec  3 15:17:14.427: INFO: Waiting for terminating namespaces to be deleted...
Dec  3 15:17:14.431: INFO: 
Logging pods the kubelet thinks is on node izgw8afzp8040eoqk0qbhwz before test
Dec  3 15:17:14.451: INFO: node-problem-detector-zgkv5 from kube-system started at 2019-12-03 14:26:11 +0000 UTC (1 container statuses recorded)
Dec  3 15:17:14.451: INFO: 	Container node-problem-detector ready: true, restart count 0
Dec  3 15:17:14.451: INFO: coredns-858b686868-4hmrg from kube-system started at 2019-12-03 14:26:51 +0000 UTC (1 container statuses recorded)
Dec  3 15:17:14.451: INFO: 	Container coredns ready: true, restart count 0
Dec  3 15:17:14.451: INFO: addons-kubernetes-dashboard-5c8d9945bc-8pg45 from kube-system started at 2019-12-03 14:26:51 +0000 UTC (1 container statuses recorded)
Dec  3 15:17:14.451: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Dec  3 15:17:14.451: INFO: metrics-server-85dc4959bc-8q2rm from kube-system started at 2019-12-03 14:26:53 +0000 UTC (1 container statuses recorded)
Dec  3 15:17:14.451: INFO: 	Container metrics-server ready: true, restart count 0
Dec  3 15:17:14.451: INFO: calico-node-7g9r2 from kube-system started at 2019-12-03 14:26:11 +0000 UTC (1 container statuses recorded)
Dec  3 15:17:14.451: INFO: 	Container calico-node ready: true, restart count 0
Dec  3 15:17:14.451: INFO: addons-nginx-ingress-nginx-ingress-k8s-backend-88d6cff74-c9t7s from kube-system started at 2019-12-03 14:26:51 +0000 UTC (1 container statuses recorded)
Dec  3 15:17:14.451: INFO: 	Container nginx-ingress-nginx-ingress-k8s-backend ready: true, restart count 0
Dec  3 15:17:14.451: INFO: node-exporter-mt7nx from kube-system started at 2019-12-03 14:26:11 +0000 UTC (1 container statuses recorded)
Dec  3 15:17:14.451: INFO: 	Container node-exporter ready: true, restart count 0
Dec  3 15:17:14.451: INFO: calico-kube-controllers-5d785bc598-n44xt from kube-system started at 2019-12-03 14:26:51 +0000 UTC (1 container statuses recorded)
Dec  3 15:17:14.451: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Dec  3 15:17:14.451: INFO: csi-disk-plugin-alicloud-zkswz from kube-system started at 2019-12-03 14:26:51 +0000 UTC (2 container statuses recorded)
Dec  3 15:17:14.451: INFO: 	Container csi-diskplugin ready: true, restart count 0
Dec  3 15:17:14.451: INFO: 	Container driver-registrar ready: true, restart count 0
Dec  3 15:17:14.451: INFO: vpn-shoot-6568b69f46-dhptx from kube-system started at 2019-12-03 14:26:53 +0000 UTC (1 container statuses recorded)
Dec  3 15:17:14.451: INFO: 	Container vpn-shoot ready: true, restart count 0
Dec  3 15:17:14.451: INFO: coredns-858b686868-b8rw9 from kube-system started at 2019-12-03 14:26:51 +0000 UTC (1 container statuses recorded)
Dec  3 15:17:14.451: INFO: 	Container coredns ready: true, restart count 0
Dec  3 15:17:14.451: INFO: addons-nginx-ingress-controller-8468678b64-fjw65 from kube-system started at 2019-12-03 14:26:51 +0000 UTC (1 container statuses recorded)
Dec  3 15:17:14.451: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Dec  3 15:17:14.451: INFO: calico-typha-horizontal-autoscaler-554dfbfdd7-hrqhh from kube-system started at 2019-12-03 14:26:51 +0000 UTC (1 container statuses recorded)
Dec  3 15:17:14.451: INFO: 	Container autoscaler ready: true, restart count 0
Dec  3 15:17:14.451: INFO: blackbox-exporter-c87bdd467-vpznr from kube-system started at 2019-12-03 14:26:11 +0000 UTC (1 container statuses recorded)
Dec  3 15:17:14.451: INFO: 	Container blackbox-exporter ready: true, restart count 0
Dec  3 15:17:14.451: INFO: calico-typha-vertical-autoscaler-656557779f-vhn2k from kube-system started at 2019-12-03 14:26:51 +0000 UTC (1 container statuses recorded)
Dec  3 15:17:14.451: INFO: 	Container autoscaler ready: true, restart count 3
Dec  3 15:17:14.451: INFO: kube-proxy-6sx94 from kube-system started at 2019-12-03 14:26:11 +0000 UTC (1 container statuses recorded)
Dec  3 15:17:14.451: INFO: 	Container kube-proxy ready: true, restart count 0
Dec  3 15:17:14.451: INFO: 
Logging pods the kubelet thinks is on node izgw8afzp8040eoqk0qbhxz before test
Dec  3 15:17:14.476: INFO: node-problem-detector-c9wdn from kube-system started at 2019-12-03 14:26:15 +0000 UTC (1 container statuses recorded)
Dec  3 15:17:14.476: INFO: 	Container node-problem-detector ready: true, restart count 0
Dec  3 15:17:14.476: INFO: csi-disk-plugin-alicloud-fqxvx from kube-system started at 2019-12-03 14:26:55 +0000 UTC (2 container statuses recorded)
Dec  3 15:17:14.476: INFO: 	Container csi-diskplugin ready: true, restart count 0
Dec  3 15:17:14.476: INFO: 	Container driver-registrar ready: true, restart count 0
Dec  3 15:17:14.476: INFO: calico-typha-deploy-5547c4cdc6-hndl5 from kube-system started at 2019-12-03 14:29:45 +0000 UTC (1 container statuses recorded)
Dec  3 15:17:14.476: INFO: 	Container calico-typha ready: true, restart count 0
Dec  3 15:17:14.476: INFO: node-exporter-9jl8n from kube-system started at 2019-12-03 14:26:15 +0000 UTC (1 container statuses recorded)
Dec  3 15:17:14.476: INFO: 	Container node-exporter ready: true, restart count 0
Dec  3 15:17:14.476: INFO: kube-proxy-t75hh from kube-system started at 2019-12-03 14:26:15 +0000 UTC (1 container statuses recorded)
Dec  3 15:17:14.476: INFO: 	Container kube-proxy ready: true, restart count 0
Dec  3 15:17:14.476: INFO: calico-node-4fgj7 from kube-system started at 2019-12-03 14:26:15 +0000 UTC (1 container statuses recorded)
Dec  3 15:17:14.476: INFO: 	Container calico-node ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: verifying the node has the label node izgw8afzp8040eoqk0qbhwz
STEP: verifying the node has the label node izgw8afzp8040eoqk0qbhxz
Dec  3 15:17:14.515: INFO: Pod addons-kubernetes-dashboard-5c8d9945bc-8pg45 requesting resource cpu=50m on Node izgw8afzp8040eoqk0qbhwz
Dec  3 15:17:14.515: INFO: Pod addons-nginx-ingress-controller-8468678b64-fjw65 requesting resource cpu=100m on Node izgw8afzp8040eoqk0qbhwz
Dec  3 15:17:14.515: INFO: Pod addons-nginx-ingress-nginx-ingress-k8s-backend-88d6cff74-c9t7s requesting resource cpu=0m on Node izgw8afzp8040eoqk0qbhwz
Dec  3 15:17:14.515: INFO: Pod blackbox-exporter-c87bdd467-vpznr requesting resource cpu=5m on Node izgw8afzp8040eoqk0qbhwz
Dec  3 15:17:14.515: INFO: Pod calico-kube-controllers-5d785bc598-n44xt requesting resource cpu=0m on Node izgw8afzp8040eoqk0qbhwz
Dec  3 15:17:14.515: INFO: Pod calico-node-4fgj7 requesting resource cpu=100m on Node izgw8afzp8040eoqk0qbhxz
Dec  3 15:17:14.515: INFO: Pod calico-node-7g9r2 requesting resource cpu=100m on Node izgw8afzp8040eoqk0qbhwz
Dec  3 15:17:14.515: INFO: Pod calico-typha-deploy-5547c4cdc6-hndl5 requesting resource cpu=0m on Node izgw8afzp8040eoqk0qbhxz
Dec  3 15:17:14.515: INFO: Pod calico-typha-horizontal-autoscaler-554dfbfdd7-hrqhh requesting resource cpu=10m on Node izgw8afzp8040eoqk0qbhwz
Dec  3 15:17:14.515: INFO: Pod calico-typha-vertical-autoscaler-656557779f-vhn2k requesting resource cpu=0m on Node izgw8afzp8040eoqk0qbhwz
Dec  3 15:17:14.515: INFO: Pod coredns-858b686868-4hmrg requesting resource cpu=50m on Node izgw8afzp8040eoqk0qbhwz
Dec  3 15:17:14.515: INFO: Pod coredns-858b686868-b8rw9 requesting resource cpu=50m on Node izgw8afzp8040eoqk0qbhwz
Dec  3 15:17:14.515: INFO: Pod csi-disk-plugin-alicloud-fqxvx requesting resource cpu=0m on Node izgw8afzp8040eoqk0qbhxz
Dec  3 15:17:14.515: INFO: Pod csi-disk-plugin-alicloud-zkswz requesting resource cpu=0m on Node izgw8afzp8040eoqk0qbhwz
Dec  3 15:17:14.515: INFO: Pod kube-proxy-6sx94 requesting resource cpu=20m on Node izgw8afzp8040eoqk0qbhwz
Dec  3 15:17:14.515: INFO: Pod kube-proxy-t75hh requesting resource cpu=20m on Node izgw8afzp8040eoqk0qbhxz
Dec  3 15:17:14.515: INFO: Pod metrics-server-85dc4959bc-8q2rm requesting resource cpu=20m on Node izgw8afzp8040eoqk0qbhwz
Dec  3 15:17:14.515: INFO: Pod node-exporter-9jl8n requesting resource cpu=5m on Node izgw8afzp8040eoqk0qbhxz
Dec  3 15:17:14.515: INFO: Pod node-exporter-mt7nx requesting resource cpu=5m on Node izgw8afzp8040eoqk0qbhwz
Dec  3 15:17:14.515: INFO: Pod node-problem-detector-c9wdn requesting resource cpu=20m on Node izgw8afzp8040eoqk0qbhxz
Dec  3 15:17:14.515: INFO: Pod node-problem-detector-zgkv5 requesting resource cpu=20m on Node izgw8afzp8040eoqk0qbhwz
Dec  3 15:17:14.515: INFO: Pod vpn-shoot-6568b69f46-dhptx requesting resource cpu=100m on Node izgw8afzp8040eoqk0qbhwz
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-6eff3aa1-1643-470e-8e33-e51d2876a851.15dce56efcc236a5], Reason = [Scheduled], Message = [Successfully assigned sched-pred-7425/filler-pod-6eff3aa1-1643-470e-8e33-e51d2876a851 to izgw8afzp8040eoqk0qbhwz]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-6eff3aa1-1643-470e-8e33-e51d2876a851.15dce56f2e462fff], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-6eff3aa1-1643-470e-8e33-e51d2876a851.15dce56f31442fe8], Reason = [Created], Message = [Created container filler-pod-6eff3aa1-1643-470e-8e33-e51d2876a851]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-6eff3aa1-1643-470e-8e33-e51d2876a851.15dce56f38eb6aa1], Reason = [Started], Message = [Started container filler-pod-6eff3aa1-1643-470e-8e33-e51d2876a851]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-f7e27fd1-ce41-48be-981a-3f2e97ebb8f5.15dce56efd0cadfb], Reason = [Scheduled], Message = [Successfully assigned sched-pred-7425/filler-pod-f7e27fd1-ce41-48be-981a-3f2e97ebb8f5 to izgw8afzp8040eoqk0qbhxz]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-f7e27fd1-ce41-48be-981a-3f2e97ebb8f5.15dce56f249060d4], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-f7e27fd1-ce41-48be-981a-3f2e97ebb8f5.15dce56f2820c3f3], Reason = [Created], Message = [Created container filler-pod-f7e27fd1-ce41-48be-981a-3f2e97ebb8f5]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-f7e27fd1-ce41-48be-981a-3f2e97ebb8f5.15dce56f2f3b01bb], Reason = [Started], Message = [Started container filler-pod-f7e27fd1-ce41-48be-981a-3f2e97ebb8f5]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.15dce56f760689ac], Reason = [FailedScheduling], Message = [0/2 nodes are available: 2 Insufficient cpu.]
STEP: removing the label node off the node izgw8afzp8040eoqk0qbhxz
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node izgw8afzp8040eoqk0qbhwz
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:17:17.594: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-7425" for this suite.
Dec  3 15:17:23.613: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:17:23.783: INFO: namespace sched-pred-7425 deletion completed in 6.184629896s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:72
â€¢SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:17:23.784: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-5284
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a test externalName service
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-5284.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-5284.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-5284.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-5284.svc.cluster.local; sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec  3 15:17:50.141: INFO: DNS probes using dns-test-fb15abe4-e749-408d-9051-4b6a868467d8 succeeded

STEP: deleting the pod
STEP: changing the externalName to bar.example.com
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-5284.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-5284.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-5284.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-5284.svc.cluster.local; sleep 1; done

STEP: creating a second pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec  3 15:17:52.276: INFO: File wheezy_udp@dns-test-service-3.dns-5284.svc.cluster.local from pod  dns-5284/dns-test-d8d45cdf-221d-463f-8371-63d3d244c323 contains 'foo.example.com.
' instead of 'bar.example.com.'
Dec  3 15:17:52.367: INFO: File jessie_udp@dns-test-service-3.dns-5284.svc.cluster.local from pod  dns-5284/dns-test-d8d45cdf-221d-463f-8371-63d3d244c323 contains 'foo.example.com.
' instead of 'bar.example.com.'
Dec  3 15:17:52.367: INFO: Lookups using dns-5284/dns-test-d8d45cdf-221d-463f-8371-63d3d244c323 failed for: [wheezy_udp@dns-test-service-3.dns-5284.svc.cluster.local jessie_udp@dns-test-service-3.dns-5284.svc.cluster.local]

Dec  3 15:17:57.432: INFO: File jessie_udp@dns-test-service-3.dns-5284.svc.cluster.local from pod  dns-5284/dns-test-d8d45cdf-221d-463f-8371-63d3d244c323 contains 'foo.example.com.
' instead of 'bar.example.com.'
Dec  3 15:17:57.432: INFO: Lookups using dns-5284/dns-test-d8d45cdf-221d-463f-8371-63d3d244c323 failed for: [jessie_udp@dns-test-service-3.dns-5284.svc.cluster.local]

Dec  3 15:18:02.508: INFO: DNS probes using dns-test-d8d45cdf-221d-463f-8371-63d3d244c323 succeeded

STEP: deleting the pod
STEP: changing the service to type=ClusterIP
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-5284.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-5284.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-5284.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-5284.svc.cluster.local; sleep 1; done

STEP: creating a third pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec  3 15:18:04.741: INFO: DNS probes using dns-test-6b3981d1-a901-4356-aef0-f3e0433405a0 succeeded

STEP: deleting the pod
STEP: deleting the test externalName service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:18:04.761: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-5284" for this suite.
Dec  3 15:18:10.785: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:18:10.992: INFO: namespace dns-5284 deletion completed in 6.222305459s
â€¢SSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:18:10.992: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-8541
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-8541.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-8541.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec  3 15:18:15.753: INFO: DNS probes using dns-8541/dns-test-9e24f131-897d-4a65-a016-4ac67dd40994 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:18:15.763: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-8541" for this suite.
Dec  3 15:18:21.786: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:18:21.951: INFO: namespace dns-8541 deletion completed in 6.179928592s
â€¢SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:18:21.952: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-wrapper-6457
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Dec  3 15:18:22.343: INFO: Pod name wrapped-volume-race-49d305b0-7ac9-42e4-836d-a3c3e9e3a3ae: Found 0 pods out of 5
Dec  3 15:18:27.353: INFO: Pod name wrapped-volume-race-49d305b0-7ac9-42e4-836d-a3c3e9e3a3ae: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-49d305b0-7ac9-42e4-836d-a3c3e9e3a3ae in namespace emptydir-wrapper-6457, will wait for the garbage collector to delete the pods
Dec  3 15:18:35.452: INFO: Deleting ReplicationController wrapped-volume-race-49d305b0-7ac9-42e4-836d-a3c3e9e3a3ae took: 7.62028ms
Dec  3 15:18:35.552: INFO: Terminating ReplicationController wrapped-volume-race-49d305b0-7ac9-42e4-836d-a3c3e9e3a3ae pods took: 100.429499ms
STEP: Creating RC which spawns configmap-volume pods
Dec  3 15:19:11.671: INFO: Pod name wrapped-volume-race-153acbd1-e4b6-444e-941b-822a1d120647: Found 0 pods out of 5
Dec  3 15:19:16.681: INFO: Pod name wrapped-volume-race-153acbd1-e4b6-444e-941b-822a1d120647: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-153acbd1-e4b6-444e-941b-822a1d120647 in namespace emptydir-wrapper-6457, will wait for the garbage collector to delete the pods
Dec  3 15:19:16.769: INFO: Deleting ReplicationController wrapped-volume-race-153acbd1-e4b6-444e-941b-822a1d120647 took: 7.637367ms
Dec  3 15:19:16.869: INFO: Terminating ReplicationController wrapped-volume-race-153acbd1-e4b6-444e-941b-822a1d120647 pods took: 100.445248ms
STEP: Creating RC which spawns configmap-volume pods
Dec  3 15:19:51.589: INFO: Pod name wrapped-volume-race-26b395d7-15ed-4b32-83c2-44d2451d2308: Found 0 pods out of 5
Dec  3 15:19:56.599: INFO: Pod name wrapped-volume-race-26b395d7-15ed-4b32-83c2-44d2451d2308: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-26b395d7-15ed-4b32-83c2-44d2451d2308 in namespace emptydir-wrapper-6457, will wait for the garbage collector to delete the pods
Dec  3 15:19:56.687: INFO: Deleting ReplicationController wrapped-volume-race-26b395d7-15ed-4b32-83c2-44d2451d2308 took: 7.814488ms
Dec  3 15:19:56.787: INFO: Terminating ReplicationController wrapped-volume-race-26b395d7-15ed-4b32-83c2-44d2451d2308 pods took: 100.295163ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:20:31.770: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-6457" for this suite.
Dec  3 15:20:37.789: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:20:37.959: INFO: namespace emptydir-wrapper-6457 deletion completed in 6.184777164s
â€¢SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:20:37.959: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-9206
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name cm-test-opt-del-491c9905-be97-4e43-ad2d-e59c2b06f5b8
STEP: Creating configMap with name cm-test-opt-upd-24612f0a-de44-4f92-91f0-f47fb202dcb3
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-491c9905-be97-4e43-ad2d-e59c2b06f5b8
STEP: Updating configmap cm-test-opt-upd-24612f0a-de44-4f92-91f0-f47fb202dcb3
STEP: Creating configMap with name cm-test-opt-create-4fb5e127-595a-428c-86ba-4e929b0ad4d4
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:20:42.539: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9206" for this suite.
Dec  3 15:21:04.563: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:21:04.736: INFO: namespace configmap-9206 deletion completed in 22.188979337s
â€¢SSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:21:04.737: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-2721
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
Dec  3 15:21:34.929: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
W1203 15:21:34.929238    5085 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Dec  3 15:21:34.929: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-2721" for this suite.
Dec  3 15:21:40.949: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:21:41.114: INFO: namespace gc-2721 deletion completed in 6.179973165s
â€¢SSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:21:41.114: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-693
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:21:43.297: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-693" for this suite.
Dec  3 15:22:21.320: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:22:21.493: INFO: namespace kubelet-test-693 deletion completed in 38.188221608s
â€¢SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:22:21.493: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-2733
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:273
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a replication controller
Dec  3 15:22:21.642: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmwqx-5aq.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config create -f - --namespace=kubectl-2733'
Dec  3 15:22:22.131: INFO: stderr: ""
Dec  3 15:22:22.131: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec  3 15:22:22.131: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmwqx-5aq.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-2733'
Dec  3 15:22:22.268: INFO: stderr: ""
Dec  3 15:22:22.268: INFO: stdout: "update-demo-nautilus-4vhhx update-demo-nautilus-mjjnb "
Dec  3 15:22:22.268: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmwqx-5aq.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-4vhhx -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2733'
Dec  3 15:22:22.354: INFO: stderr: ""
Dec  3 15:22:22.354: INFO: stdout: ""
Dec  3 15:22:22.354: INFO: update-demo-nautilus-4vhhx is created but not running
Dec  3 15:22:27.355: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmwqx-5aq.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-2733'
Dec  3 15:22:27.487: INFO: stderr: ""
Dec  3 15:22:27.487: INFO: stdout: "update-demo-nautilus-4vhhx update-demo-nautilus-mjjnb "
Dec  3 15:22:27.487: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmwqx-5aq.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-4vhhx -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2733'
Dec  3 15:22:27.577: INFO: stderr: ""
Dec  3 15:22:27.577: INFO: stdout: "true"
Dec  3 15:22:27.577: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmwqx-5aq.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-4vhhx -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-2733'
Dec  3 15:22:27.665: INFO: stderr: ""
Dec  3 15:22:27.665: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec  3 15:22:27.665: INFO: validating pod update-demo-nautilus-4vhhx
Dec  3 15:22:27.762: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  3 15:22:27.763: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  3 15:22:27.763: INFO: update-demo-nautilus-4vhhx is verified up and running
Dec  3 15:22:27.763: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmwqx-5aq.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-mjjnb -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2733'
Dec  3 15:22:27.853: INFO: stderr: ""
Dec  3 15:22:27.853: INFO: stdout: "true"
Dec  3 15:22:27.853: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmwqx-5aq.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-mjjnb -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-2733'
Dec  3 15:22:27.937: INFO: stderr: ""
Dec  3 15:22:27.937: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec  3 15:22:27.937: INFO: validating pod update-demo-nautilus-mjjnb
Dec  3 15:22:28.033: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  3 15:22:28.033: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  3 15:22:28.033: INFO: update-demo-nautilus-mjjnb is verified up and running
STEP: scaling down the replication controller
Dec  3 15:22:28.035: INFO: scanned /root for discovery docs: <nil>
Dec  3 15:22:28.035: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmwqx-5aq.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=kubectl-2733'
Dec  3 15:22:29.149: INFO: stderr: ""
Dec  3 15:22:29.149: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec  3 15:22:29.149: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmwqx-5aq.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-2733'
Dec  3 15:22:29.240: INFO: stderr: ""
Dec  3 15:22:29.240: INFO: stdout: "update-demo-nautilus-4vhhx update-demo-nautilus-mjjnb "
STEP: Replicas for name=update-demo: expected=1 actual=2
Dec  3 15:22:34.241: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmwqx-5aq.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-2733'
Dec  3 15:22:34.375: INFO: stderr: ""
Dec  3 15:22:34.375: INFO: stdout: "update-demo-nautilus-mjjnb "
Dec  3 15:22:34.376: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmwqx-5aq.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-mjjnb -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2733'
Dec  3 15:22:34.464: INFO: stderr: ""
Dec  3 15:22:34.464: INFO: stdout: "true"
Dec  3 15:22:34.464: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmwqx-5aq.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-mjjnb -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-2733'
Dec  3 15:22:34.557: INFO: stderr: ""
Dec  3 15:22:34.557: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec  3 15:22:34.557: INFO: validating pod update-demo-nautilus-mjjnb
Dec  3 15:22:34.568: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  3 15:22:34.568: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  3 15:22:34.568: INFO: update-demo-nautilus-mjjnb is verified up and running
STEP: scaling up the replication controller
Dec  3 15:22:34.570: INFO: scanned /root for discovery docs: <nil>
Dec  3 15:22:34.570: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmwqx-5aq.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=kubectl-2733'
Dec  3 15:22:34.752: INFO: stderr: ""
Dec  3 15:22:34.752: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec  3 15:22:34.752: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmwqx-5aq.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-2733'
Dec  3 15:22:34.860: INFO: stderr: ""
Dec  3 15:22:34.860: INFO: stdout: "update-demo-nautilus-49zkr update-demo-nautilus-mjjnb "
Dec  3 15:22:34.860: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmwqx-5aq.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-49zkr -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2733'
Dec  3 15:22:34.953: INFO: stderr: ""
Dec  3 15:22:34.953: INFO: stdout: ""
Dec  3 15:22:34.953: INFO: update-demo-nautilus-49zkr is created but not running
Dec  3 15:22:39.954: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmwqx-5aq.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-2733'
Dec  3 15:22:40.088: INFO: stderr: ""
Dec  3 15:22:40.088: INFO: stdout: "update-demo-nautilus-49zkr update-demo-nautilus-mjjnb "
Dec  3 15:22:40.088: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmwqx-5aq.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-49zkr -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2733'
Dec  3 15:22:40.228: INFO: stderr: ""
Dec  3 15:22:40.228: INFO: stdout: "true"
Dec  3 15:22:40.228: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmwqx-5aq.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-49zkr -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-2733'
Dec  3 15:22:40.370: INFO: stderr: ""
Dec  3 15:22:40.370: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec  3 15:22:40.370: INFO: validating pod update-demo-nautilus-49zkr
Dec  3 15:22:40.466: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  3 15:22:40.466: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  3 15:22:40.467: INFO: update-demo-nautilus-49zkr is verified up and running
Dec  3 15:22:40.467: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmwqx-5aq.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-mjjnb -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2733'
Dec  3 15:22:40.550: INFO: stderr: ""
Dec  3 15:22:40.550: INFO: stdout: "true"
Dec  3 15:22:40.550: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmwqx-5aq.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-mjjnb -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-2733'
Dec  3 15:22:40.680: INFO: stderr: ""
Dec  3 15:22:40.680: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec  3 15:22:40.680: INFO: validating pod update-demo-nautilus-mjjnb
Dec  3 15:22:40.690: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  3 15:22:40.690: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  3 15:22:40.690: INFO: update-demo-nautilus-mjjnb is verified up and running
STEP: using delete to clean up resources
Dec  3 15:22:40.690: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmwqx-5aq.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config delete --grace-period=0 --force -f - --namespace=kubectl-2733'
Dec  3 15:22:40.783: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  3 15:22:40.783: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Dec  3 15:22:40.783: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmwqx-5aq.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get rc,svc -l name=update-demo --no-headers --namespace=kubectl-2733'
Dec  3 15:22:40.877: INFO: stderr: "No resources found.\n"
Dec  3 15:22:40.877: INFO: stdout: ""
Dec  3 15:22:40.877: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmwqx-5aq.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods -l name=update-demo --namespace=kubectl-2733 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec  3 15:22:40.964: INFO: stderr: ""
Dec  3 15:22:40.964: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:22:40.964: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2733" for this suite.
Dec  3 15:23:02.987: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:23:03.200: INFO: namespace kubectl-2733 deletion completed in 22.227915056s
â€¢SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:23:03.200: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-1367
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating all guestbook components
Dec  3 15:23:03.346: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Dec  3 15:23:03.346: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmwqx-5aq.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config create -f - --namespace=kubectl-1367'
Dec  3 15:23:03.623: INFO: stderr: ""
Dec  3 15:23:03.623: INFO: stdout: "service/redis-slave created\n"
Dec  3 15:23:03.623: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Dec  3 15:23:03.623: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmwqx-5aq.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config create -f - --namespace=kubectl-1367'
Dec  3 15:23:03.872: INFO: stderr: ""
Dec  3 15:23:03.872: INFO: stdout: "service/redis-master created\n"
Dec  3 15:23:03.872: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Dec  3 15:23:03.872: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmwqx-5aq.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config create -f - --namespace=kubectl-1367'
Dec  3 15:23:04.073: INFO: stderr: ""
Dec  3 15:23:04.073: INFO: stdout: "service/frontend created\n"
Dec  3 15:23:04.073: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: guestbook
      tier: frontend
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Dec  3 15:23:04.073: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmwqx-5aq.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config create -f - --namespace=kubectl-1367'
Dec  3 15:23:04.373: INFO: stderr: ""
Dec  3 15:23:04.373: INFO: stdout: "deployment.apps/frontend created\n"
Dec  3 15:23:04.374: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  selector:
    matchLabels:
      app: redis
      role: master
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Dec  3 15:23:04.374: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmwqx-5aq.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config create -f - --namespace=kubectl-1367'
Dec  3 15:23:04.636: INFO: stderr: ""
Dec  3 15:23:04.636: INFO: stdout: "deployment.apps/redis-master created\n"
Dec  3 15:23:04.636: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  selector:
    matchLabels:
      app: redis
      role: slave
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave:v3
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Dec  3 15:23:04.636: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmwqx-5aq.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config create -f - --namespace=kubectl-1367'
Dec  3 15:23:04.901: INFO: stderr: ""
Dec  3 15:23:04.901: INFO: stdout: "deployment.apps/redis-slave created\n"
STEP: validating guestbook app
Dec  3 15:23:04.901: INFO: Waiting for all frontend pods to be Running.
Dec  3 15:23:29.952: INFO: Waiting for frontend to serve content.
Dec  3 15:23:35.022: INFO: Failed to get response from guestbook. err: <nil>, response: <br />
<b>Fatal error</b>:  Uncaught exception 'Predis\Connection\ConnectionException' with message 'Connection timed out [tcp://redis-slave:6379]' in /usr/local/lib/php/Predis/Connection/AbstractConnection.php:155
Stack trace:
#0 /usr/local/lib/php/Predis/Connection/StreamConnection.php(128): Predis\Connection\AbstractConnection-&gt;onConnectionError('Connection time...', 110)
#1 /usr/local/lib/php/Predis/Connection/StreamConnection.php(178): Predis\Connection\StreamConnection-&gt;createStreamSocket(Object(Predis\Connection\Parameters), 'tcp://redis-sla...', 4)
#2 /usr/local/lib/php/Predis/Connection/StreamConnection.php(100): Predis\Connection\StreamConnection-&gt;tcpStreamInitializer(Object(Predis\Connection\Parameters))
#3 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(81): Predis\Connection\StreamConnection-&gt;createResource()
#4 /usr/local/lib/php/Predis/Connection/StreamConnection.php(258): Predis\Connection\AbstractConnection-&gt;connect()
#5 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(180): Predis\Connection\Stre in <b>/usr/local/lib/php/Predis/Connection/AbstractConnection.php</b> on line <b>155</b><br />

Dec  3 15:23:40.119: INFO: Trying to add a new entry to the guestbook.
Dec  3 15:23:40.170: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Dec  3 15:23:40.266: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmwqx-5aq.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config delete --grace-period=0 --force -f - --namespace=kubectl-1367'
Dec  3 15:23:40.440: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  3 15:23:40.440: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Dec  3 15:23:40.440: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmwqx-5aq.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config delete --grace-period=0 --force -f - --namespace=kubectl-1367'
Dec  3 15:23:40.540: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  3 15:23:40.540: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Dec  3 15:23:40.540: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmwqx-5aq.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config delete --grace-period=0 --force -f - --namespace=kubectl-1367'
Dec  3 15:23:40.702: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  3 15:23:40.702: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Dec  3 15:23:40.702: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmwqx-5aq.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config delete --grace-period=0 --force -f - --namespace=kubectl-1367'
Dec  3 15:23:40.853: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  3 15:23:40.853: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Dec  3 15:23:40.853: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmwqx-5aq.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config delete --grace-period=0 --force -f - --namespace=kubectl-1367'
Dec  3 15:23:41.002: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  3 15:23:41.003: INFO: stdout: "deployment.apps \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Dec  3 15:23:41.003: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmwqx-5aq.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config delete --grace-period=0 --force -f - --namespace=kubectl-1367'
Dec  3 15:23:41.147: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  3 15:23:41.147: INFO: stdout: "deployment.apps \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:23:41.147: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1367" for this suite.
Dec  3 15:24:19.170: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:24:19.381: INFO: namespace kubectl-1367 deletion completed in 38.225521009s
â€¢SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:24:19.382: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-1871
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: Gathering metrics
Dec  3 15:24:19.569: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W1203 15:24:19.569473    5085 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:24:19.569: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-1871" for this suite.
Dec  3 15:24:25.588: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:24:25.757: INFO: namespace gc-1871 deletion completed in 6.182993219s
â€¢
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:24:25.757: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-1759
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-1759
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating stateful set ss in namespace statefulset-1759
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-1759
Dec  3 15:24:25.921: INFO: Found 0 stateful pods, waiting for 1
Dec  3 15:24:35.927: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Dec  3 15:24:35.932: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmwqx-5aq.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-1759 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec  3 15:24:36.515: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Dec  3 15:24:36.515: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec  3 15:24:36.515: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec  3 15:24:36.520: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Dec  3 15:24:46.527: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Dec  3 15:24:46.527: INFO: Waiting for statefulset status.replicas updated to 0
Dec  3 15:24:46.546: INFO: POD   NODE                     PHASE    GRACE  CONDITIONS
Dec  3 15:24:46.546: INFO: ss-0  izgw8afzp8040eoqk0qbhxz  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 15:24:25 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 15:24:36 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 15:24:36 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 15:24:25 +0000 UTC  }]
Dec  3 15:24:46.546: INFO: ss-1                           Pending         []
Dec  3 15:24:46.546: INFO: 
Dec  3 15:24:46.546: INFO: StatefulSet ss has not reached scale 3, at 2
Dec  3 15:24:47.552: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.994463326s
Dec  3 15:24:48.558: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.98829154s
Dec  3 15:24:49.564: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.98243483s
Dec  3 15:24:50.570: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.976463932s
Dec  3 15:24:51.576: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.970135002s
Dec  3 15:24:52.582: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.964201986s
Dec  3 15:24:53.588: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.958117644s
Dec  3 15:24:54.594: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.952034251s
Dec  3 15:24:55.600: INFO: Verifying statefulset ss doesn't scale past 3 for another 946.14832ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-1759
Dec  3 15:24:56.606: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmwqx-5aq.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-1759 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  3 15:24:57.193: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Dec  3 15:24:57.193: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec  3 15:24:57.193: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec  3 15:24:57.193: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmwqx-5aq.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-1759 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  3 15:24:57.741: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Dec  3 15:24:57.741: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec  3 15:24:57.741: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec  3 15:24:57.741: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmwqx-5aq.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-1759 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  3 15:24:58.226: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Dec  3 15:24:58.226: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec  3 15:24:58.226: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec  3 15:24:58.232: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Dec  3 15:24:58.232: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Dec  3 15:24:58.232: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Dec  3 15:24:58.238: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmwqx-5aq.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-1759 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec  3 15:24:58.807: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Dec  3 15:24:58.807: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec  3 15:24:58.807: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec  3 15:24:58.807: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmwqx-5aq.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-1759 ss-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec  3 15:24:59.420: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Dec  3 15:24:59.420: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec  3 15:24:59.420: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec  3 15:24:59.420: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmwqx-5aq.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-1759 ss-2 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec  3 15:25:00.034: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Dec  3 15:25:00.034: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec  3 15:25:00.034: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec  3 15:25:00.034: INFO: Waiting for statefulset status.replicas updated to 0
Dec  3 15:25:00.040: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 1
Dec  3 15:25:10.050: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Dec  3 15:25:10.050: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Dec  3 15:25:10.050: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Dec  3 15:25:10.064: INFO: POD   NODE                     PHASE    GRACE  CONDITIONS
Dec  3 15:25:10.064: INFO: ss-0  izgw8afzp8040eoqk0qbhxz  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 15:24:25 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 15:24:58 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 15:24:58 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 15:24:25 +0000 UTC  }]
Dec  3 15:25:10.065: INFO: ss-1  izgw8afzp8040eoqk0qbhxz  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 15:24:46 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 15:24:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 15:24:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 15:24:46 +0000 UTC  }]
Dec  3 15:25:10.065: INFO: ss-2  izgw8afzp8040eoqk0qbhwz  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 15:24:46 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 15:25:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 15:25:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 15:24:46 +0000 UTC  }]
Dec  3 15:25:10.065: INFO: 
Dec  3 15:25:10.065: INFO: StatefulSet ss has not reached scale 0, at 3
Dec  3 15:25:11.070: INFO: POD   NODE                     PHASE    GRACE  CONDITIONS
Dec  3 15:25:11.071: INFO: ss-0  izgw8afzp8040eoqk0qbhxz  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 15:24:25 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 15:24:58 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 15:24:58 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 15:24:25 +0000 UTC  }]
Dec  3 15:25:11.071: INFO: ss-1  izgw8afzp8040eoqk0qbhxz  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 15:24:46 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 15:24:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 15:24:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 15:24:46 +0000 UTC  }]
Dec  3 15:25:11.071: INFO: ss-2  izgw8afzp8040eoqk0qbhwz  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 15:24:46 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 15:25:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 15:25:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 15:24:46 +0000 UTC  }]
Dec  3 15:25:11.071: INFO: 
Dec  3 15:25:11.071: INFO: StatefulSet ss has not reached scale 0, at 3
Dec  3 15:25:12.077: INFO: POD   NODE                     PHASE    GRACE  CONDITIONS
Dec  3 15:25:12.077: INFO: ss-0  izgw8afzp8040eoqk0qbhxz  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 15:24:25 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 15:24:58 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 15:24:58 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 15:24:25 +0000 UTC  }]
Dec  3 15:25:12.077: INFO: ss-1  izgw8afzp8040eoqk0qbhxz  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 15:24:46 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 15:24:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 15:24:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 15:24:46 +0000 UTC  }]
Dec  3 15:25:12.077: INFO: 
Dec  3 15:25:12.077: INFO: StatefulSet ss has not reached scale 0, at 2
Dec  3 15:25:13.082: INFO: Verifying statefulset ss doesn't scale past 0 for another 6.982654029s
Dec  3 15:25:14.088: INFO: Verifying statefulset ss doesn't scale past 0 for another 5.976855086s
Dec  3 15:25:15.093: INFO: Verifying statefulset ss doesn't scale past 0 for another 4.97139529s
Dec  3 15:25:16.099: INFO: Verifying statefulset ss doesn't scale past 0 for another 3.965816937s
Dec  3 15:25:17.104: INFO: Verifying statefulset ss doesn't scale past 0 for another 2.960757131s
Dec  3 15:25:18.109: INFO: Verifying statefulset ss doesn't scale past 0 for another 1.955273067s
Dec  3 15:25:19.115: INFO: Verifying statefulset ss doesn't scale past 0 for another 949.886121ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-1759
Dec  3 15:25:20.121: INFO: Scaling statefulset ss to 0
Dec  3 15:25:20.134: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Dec  3 15:25:20.138: INFO: Deleting all statefulset in ns statefulset-1759
Dec  3 15:25:20.143: INFO: Scaling statefulset ss to 0
Dec  3 15:25:20.155: INFO: Waiting for statefulset status.replicas updated to 0
Dec  3 15:25:20.159: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:25:20.173: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-1759" for this suite.
Dec  3 15:25:26.195: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:25:26.364: INFO: namespace statefulset-1759 deletion completed in 6.183293868s
â€¢SSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:25:26.364: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in namespaces-7990
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-5528
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-7384
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:25:50.831: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-7990" for this suite.
Dec  3 15:25:56.853: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:25:57.017: INFO: namespace namespaces-7990 deletion completed in 6.178628359s
STEP: Destroying namespace "nsdeletetest-5528" for this suite.
Dec  3 15:25:57.021: INFO: Namespace nsdeletetest-5528 was already deleted
STEP: Destroying namespace "nsdeletetest-7384" for this suite.
Dec  3 15:26:03.036: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:26:03.237: INFO: namespace nsdeletetest-7384 deletion completed in 6.215422703s
â€¢SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Aggregator 
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:26:03.237: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename aggregator
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in aggregator-4355
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:76
Dec  3 15:26:03.383: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
[It] Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Registering the sample API server.
Dec  3 15:26:03.859: INFO: deployment "sample-apiserver-deployment" doesn't have the required revision set
Dec  3 15:26:05.901: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710983563, loc:(*time.Location)(0x7ed1a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710983563, loc:(*time.Location)(0x7ed1a20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710983563, loc:(*time.Location)(0x7ed1a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710983563, loc:(*time.Location)(0x7ed1a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  3 15:26:07.906: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710983563, loc:(*time.Location)(0x7ed1a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710983563, loc:(*time.Location)(0x7ed1a20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710983563, loc:(*time.Location)(0x7ed1a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710983563, loc:(*time.Location)(0x7ed1a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  3 15:26:09.906: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710983563, loc:(*time.Location)(0x7ed1a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710983563, loc:(*time.Location)(0x7ed1a20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710983563, loc:(*time.Location)(0x7ed1a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710983563, loc:(*time.Location)(0x7ed1a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  3 15:26:11.907: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710983563, loc:(*time.Location)(0x7ed1a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710983563, loc:(*time.Location)(0x7ed1a20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710983563, loc:(*time.Location)(0x7ed1a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710983563, loc:(*time.Location)(0x7ed1a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  3 15:26:13.906: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710983563, loc:(*time.Location)(0x7ed1a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710983563, loc:(*time.Location)(0x7ed1a20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710983563, loc:(*time.Location)(0x7ed1a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710983563, loc:(*time.Location)(0x7ed1a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  3 15:26:15.906: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710983563, loc:(*time.Location)(0x7ed1a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710983563, loc:(*time.Location)(0x7ed1a20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710983563, loc:(*time.Location)(0x7ed1a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710983563, loc:(*time.Location)(0x7ed1a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  3 15:26:17.906: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710983563, loc:(*time.Location)(0x7ed1a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710983563, loc:(*time.Location)(0x7ed1a20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710983563, loc:(*time.Location)(0x7ed1a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710983563, loc:(*time.Location)(0x7ed1a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  3 15:26:19.906: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710983563, loc:(*time.Location)(0x7ed1a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710983563, loc:(*time.Location)(0x7ed1a20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710983563, loc:(*time.Location)(0x7ed1a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710983563, loc:(*time.Location)(0x7ed1a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  3 15:26:21.906: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710983563, loc:(*time.Location)(0x7ed1a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710983563, loc:(*time.Location)(0x7ed1a20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710983563, loc:(*time.Location)(0x7ed1a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710983563, loc:(*time.Location)(0x7ed1a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  3 15:26:24.870: INFO: Waited 957.104012ms for the sample-apiserver to be ready to handle requests.
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:67
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:26:25.590: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "aggregator-4355" for this suite.
Dec  3 15:26:31.610: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:26:31.786: INFO: namespace aggregator-4355 deletion completed in 6.191162885s
â€¢SSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:26:31.787: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-3318
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Performing setup for networking test in namespace pod-network-test-3318
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Dec  3 15:26:31.937: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Dec  3 15:26:50.032: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://100.64.0.61:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-3318 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  3 15:26:50.032: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec  3 15:26:50.489: INFO: Found all expected endpoints: [netserver-0]
Dec  3 15:26:50.495: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://100.64.1.168:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-3318 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  3 15:26:50.495: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec  3 15:26:50.933: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:26:50.933: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-3318" for this suite.
Dec  3 15:27:12.958: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:27:13.126: INFO: namespace pod-network-test-3318 deletion completed in 22.185034373s
â€¢SS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:27:13.127: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename hostpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in hostpath-5027
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test hostPath mode
Dec  3 15:27:13.285: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "hostpath-5027" to be "success or failure"
Dec  3 15:27:13.289: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 4.161183ms
Dec  3 15:27:15.295: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009812529s
STEP: Saw pod success
Dec  3 15:27:15.295: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Dec  3 15:27:15.300: INFO: Trying to get logs from node izgw8afzp8040eoqk0qbhxz pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Dec  3 15:27:15.363: INFO: Waiting for pod pod-host-path-test to disappear
Dec  3 15:27:15.367: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:27:15.367: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "hostpath-5027" for this suite.
Dec  3 15:27:21.390: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:27:21.551: INFO: namespace hostpath-5027 deletion completed in 6.176579444s
â€¢SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:27:21.552: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2668
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Dec  3 15:27:21.705: INFO: Waiting up to 5m0s for pod "downwardapi-volume-24fd8a6e-f086-4063-a73c-af282fe1746f" in namespace "projected-2668" to be "success or failure"
Dec  3 15:27:21.710: INFO: Pod "downwardapi-volume-24fd8a6e-f086-4063-a73c-af282fe1746f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.208463ms
Dec  3 15:27:23.715: INFO: Pod "downwardapi-volume-24fd8a6e-f086-4063-a73c-af282fe1746f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009407911s
STEP: Saw pod success
Dec  3 15:27:23.715: INFO: Pod "downwardapi-volume-24fd8a6e-f086-4063-a73c-af282fe1746f" satisfied condition "success or failure"
Dec  3 15:27:23.719: INFO: Trying to get logs from node izgw8afzp8040eoqk0qbhxz pod downwardapi-volume-24fd8a6e-f086-4063-a73c-af282fe1746f container client-container: <nil>
STEP: delete the pod
Dec  3 15:27:23.741: INFO: Waiting for pod downwardapi-volume-24fd8a6e-f086-4063-a73c-af282fe1746f to disappear
Dec  3 15:27:23.746: INFO: Pod downwardapi-volume-24fd8a6e-f086-4063-a73c-af282fe1746f no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:27:23.746: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2668" for this suite.
Dec  3 15:27:29.768: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:27:29.978: INFO: namespace projected-2668 deletion completed in 6.224055992s
â€¢SSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:27:29.978: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-6112
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Dec  3 15:27:32.163: INFO: Waiting up to 5m0s for pod "client-envvars-9ad2a48d-72a0-440b-8ec6-87f516bd91bb" in namespace "pods-6112" to be "success or failure"
Dec  3 15:27:32.168: INFO: Pod "client-envvars-9ad2a48d-72a0-440b-8ec6-87f516bd91bb": Phase="Pending", Reason="", readiness=false. Elapsed: 4.559218ms
Dec  3 15:27:34.173: INFO: Pod "client-envvars-9ad2a48d-72a0-440b-8ec6-87f516bd91bb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010119638s
STEP: Saw pod success
Dec  3 15:27:34.173: INFO: Pod "client-envvars-9ad2a48d-72a0-440b-8ec6-87f516bd91bb" satisfied condition "success or failure"
Dec  3 15:27:34.178: INFO: Trying to get logs from node izgw8afzp8040eoqk0qbhxz pod client-envvars-9ad2a48d-72a0-440b-8ec6-87f516bd91bb container env3cont: <nil>
STEP: delete the pod
Dec  3 15:27:34.201: INFO: Waiting for pod client-envvars-9ad2a48d-72a0-440b-8ec6-87f516bd91bb to disappear
Dec  3 15:27:34.206: INFO: Pod client-envvars-9ad2a48d-72a0-440b-8ec6-87f516bd91bb no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:27:34.206: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-6112" for this suite.
Dec  3 15:28:18.229: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:28:18.393: INFO: namespace pods-6112 deletion completed in 44.178630484s
â€¢SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:28:18.393: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-5903
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-1598b9cc-65d1-4316-a597-a1d12c722758
STEP: Creating a pod to test consume secrets
Dec  3 15:28:18.552: INFO: Waiting up to 5m0s for pod "pod-secrets-fd10d6c0-a511-4194-8a1d-84becf5eeb53" in namespace "secrets-5903" to be "success or failure"
Dec  3 15:28:18.556: INFO: Pod "pod-secrets-fd10d6c0-a511-4194-8a1d-84becf5eeb53": Phase="Pending", Reason="", readiness=false. Elapsed: 4.197931ms
Dec  3 15:28:20.562: INFO: Pod "pod-secrets-fd10d6c0-a511-4194-8a1d-84becf5eeb53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009783646s
STEP: Saw pod success
Dec  3 15:28:20.562: INFO: Pod "pod-secrets-fd10d6c0-a511-4194-8a1d-84becf5eeb53" satisfied condition "success or failure"
Dec  3 15:28:20.567: INFO: Trying to get logs from node izgw8afzp8040eoqk0qbhxz pod pod-secrets-fd10d6c0-a511-4194-8a1d-84becf5eeb53 container secret-volume-test: <nil>
STEP: delete the pod
Dec  3 15:28:20.589: INFO: Waiting for pod pod-secrets-fd10d6c0-a511-4194-8a1d-84becf5eeb53 to disappear
Dec  3 15:28:20.593: INFO: Pod pod-secrets-fd10d6c0-a511-4194-8a1d-84becf5eeb53 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:28:20.593: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5903" for this suite.
Dec  3 15:28:26.616: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:28:26.781: INFO: namespace secrets-5903 deletion completed in 6.17996882s
â€¢SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:28:26.781: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename prestop
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in prestop-3447
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pre_stop.go:167
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating server pod server in namespace prestop-3447
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace prestop-3447
STEP: Deleting pre-stop pod
Dec  3 15:28:38.069: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:28:38.077: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "prestop-3447" for this suite.
Dec  3 15:29:16.100: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:29:16.270: INFO: namespace prestop-3447 deletion completed in 38.185192658s
â€¢SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:29:16.270: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-6547
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Dec  3 15:29:17.436: INFO: Expected: &{} to match Container's Termination Message:  --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:29:17.449: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-6547" for this suite.
Dec  3 15:29:23.470: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:29:23.678: INFO: namespace container-runtime-6547 deletion completed in 6.221115159s
â€¢SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:29:23.678: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-8658
STEP: Waiting for a default service account to be provisioned in namespace
[It] should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Dec  3 15:29:23.823: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
STEP: Creating rc "condition-test" that asks for more than the allowed pod quota
STEP: Checking rc "condition-test" has the desired failure condition set
STEP: Scaling down rc "condition-test" to satisfy pod quota
Dec  3 15:29:24.855: INFO: Updating replication controller "condition-test"
STEP: Checking rc "condition-test" has no failure condition set
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:29:24.859: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-8658" for this suite.
Dec  3 15:29:30.881: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:29:31.040: INFO: namespace replication-controller-8658 deletion completed in 6.1738264s
â€¢SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:29:31.041: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8652
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-projected-all-test-volume-1c84e016-aba4-42f9-b746-073a39c3b35b
STEP: Creating secret with name secret-projected-all-test-volume-4e025a0b-a22a-43c1-846e-0f2fd621088d
STEP: Creating a pod to test Check all projections for projected volume plugin
Dec  3 15:29:31.202: INFO: Waiting up to 5m0s for pod "projected-volume-3adb1858-6e10-4420-8db6-877725868d50" in namespace "projected-8652" to be "success or failure"
Dec  3 15:29:31.207: INFO: Pod "projected-volume-3adb1858-6e10-4420-8db6-877725868d50": Phase="Pending", Reason="", readiness=false. Elapsed: 4.475355ms
Dec  3 15:29:33.213: INFO: Pod "projected-volume-3adb1858-6e10-4420-8db6-877725868d50": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010150338s
STEP: Saw pod success
Dec  3 15:29:33.213: INFO: Pod "projected-volume-3adb1858-6e10-4420-8db6-877725868d50" satisfied condition "success or failure"
Dec  3 15:29:33.218: INFO: Trying to get logs from node izgw8afzp8040eoqk0qbhxz pod projected-volume-3adb1858-6e10-4420-8db6-877725868d50 container projected-all-volume-test: <nil>
STEP: delete the pod
Dec  3 15:29:33.242: INFO: Waiting for pod projected-volume-3adb1858-6e10-4420-8db6-877725868d50 to disappear
Dec  3 15:29:33.246: INFO: Pod projected-volume-3adb1858-6e10-4420-8db6-877725868d50 no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:29:33.246: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8652" for this suite.
Dec  3 15:29:39.268: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:29:39.437: INFO: namespace projected-8652 deletion completed in 6.183195138s
â€¢SSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:29:39.437: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-3458
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod busybox-52ed27e3-4caf-4031-9790-cd59f8f25694 in namespace container-probe-3458
Dec  3 15:29:41.601: INFO: Started pod busybox-52ed27e3-4caf-4031-9790-cd59f8f25694 in namespace container-probe-3458
STEP: checking the pod's current state and verifying that restartCount is present
Dec  3 15:29:41.606: INFO: Initial restart count of pod busybox-52ed27e3-4caf-4031-9790-cd59f8f25694 is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:33:42.264: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-3458" for this suite.
Dec  3 15:33:48.287: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:33:48.447: INFO: namespace container-probe-3458 deletion completed in 6.174641605s
â€¢SSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:33:48.447: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-126
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test override arguments
Dec  3 15:33:48.607: INFO: Waiting up to 5m0s for pod "client-containers-187d7228-d1ab-4c97-9804-c13bbc8f3563" in namespace "containers-126" to be "success or failure"
Dec  3 15:33:48.611: INFO: Pod "client-containers-187d7228-d1ab-4c97-9804-c13bbc8f3563": Phase="Pending", Reason="", readiness=false. Elapsed: 4.46176ms
Dec  3 15:33:50.617: INFO: Pod "client-containers-187d7228-d1ab-4c97-9804-c13bbc8f3563": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009993519s
STEP: Saw pod success
Dec  3 15:33:50.617: INFO: Pod "client-containers-187d7228-d1ab-4c97-9804-c13bbc8f3563" satisfied condition "success or failure"
Dec  3 15:33:50.622: INFO: Trying to get logs from node izgw8afzp8040eoqk0qbhxz pod client-containers-187d7228-d1ab-4c97-9804-c13bbc8f3563 container test-container: <nil>
STEP: delete the pod
Dec  3 15:33:50.651: INFO: Waiting for pod client-containers-187d7228-d1ab-4c97-9804-c13bbc8f3563 to disappear
Dec  3 15:33:50.655: INFO: Pod client-containers-187d7228-d1ab-4c97-9804-c13bbc8f3563 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:33:50.655: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-126" for this suite.
Dec  3 15:33:56.677: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:33:56.884: INFO: namespace containers-126 deletion completed in 6.221038731s
â€¢SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:33:56.885: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6056
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating the pod
Dec  3 15:33:59.599: INFO: Successfully updated pod "annotationupdate1812cc10-76e2-4596-8bfc-cc9a24f497d5"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:34:01.625: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6056" for this suite.
Dec  3 15:34:23.648: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:34:23.812: INFO: namespace projected-6056 deletion completed in 22.178596207s
â€¢SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:34:23.812: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-4933
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Dec  3 15:34:23.982: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-4933,SelfLink:/api/v1/namespaces/watch-4933/configmaps/e2e-watch-test-label-changed,UID:5d331b57-9836-44a8-839f-616f9eb4579c,ResourceVersion:19197,Generation:0,CreationTimestamp:2019-12-03 15:34:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec  3 15:34:23.982: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-4933,SelfLink:/api/v1/namespaces/watch-4933/configmaps/e2e-watch-test-label-changed,UID:5d331b57-9836-44a8-839f-616f9eb4579c,ResourceVersion:19198,Generation:0,CreationTimestamp:2019-12-03 15:34:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Dec  3 15:34:23.983: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-4933,SelfLink:/api/v1/namespaces/watch-4933/configmaps/e2e-watch-test-label-changed,UID:5d331b57-9836-44a8-839f-616f9eb4579c,ResourceVersion:19199,Generation:0,CreationTimestamp:2019-12-03 15:34:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Dec  3 15:34:34.016: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-4933,SelfLink:/api/v1/namespaces/watch-4933/configmaps/e2e-watch-test-label-changed,UID:5d331b57-9836-44a8-839f-616f9eb4579c,ResourceVersion:19232,Generation:0,CreationTimestamp:2019-12-03 15:34:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec  3 15:34:34.016: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-4933,SelfLink:/api/v1/namespaces/watch-4933/configmaps/e2e-watch-test-label-changed,UID:5d331b57-9836-44a8-839f-616f9eb4579c,ResourceVersion:19233,Generation:0,CreationTimestamp:2019-12-03 15:34:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Dec  3 15:34:34.016: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-4933,SelfLink:/api/v1/namespaces/watch-4933/configmaps/e2e-watch-test-label-changed,UID:5d331b57-9836-44a8-839f-616f9eb4579c,ResourceVersion:19234,Generation:0,CreationTimestamp:2019-12-03 15:34:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:34:34.016: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-4933" for this suite.
Dec  3 15:34:40.039: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:34:40.208: INFO: namespace watch-4933 deletion completed in 6.183462264s
â€¢SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:34:40.209: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-6829
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test override command
Dec  3 15:34:40.365: INFO: Waiting up to 5m0s for pod "client-containers-c5735135-0cca-4ef0-bd22-6efe9d1044de" in namespace "containers-6829" to be "success or failure"
Dec  3 15:34:40.369: INFO: Pod "client-containers-c5735135-0cca-4ef0-bd22-6efe9d1044de": Phase="Pending", Reason="", readiness=false. Elapsed: 4.073202ms
Dec  3 15:34:42.374: INFO: Pod "client-containers-c5735135-0cca-4ef0-bd22-6efe9d1044de": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009445963s
STEP: Saw pod success
Dec  3 15:34:42.374: INFO: Pod "client-containers-c5735135-0cca-4ef0-bd22-6efe9d1044de" satisfied condition "success or failure"
Dec  3 15:34:42.379: INFO: Trying to get logs from node izgw8afzp8040eoqk0qbhxz pod client-containers-c5735135-0cca-4ef0-bd22-6efe9d1044de container test-container: <nil>
STEP: delete the pod
Dec  3 15:34:42.401: INFO: Waiting for pod client-containers-c5735135-0cca-4ef0-bd22-6efe9d1044de to disappear
Dec  3 15:34:42.406: INFO: Pod client-containers-c5735135-0cca-4ef0-bd22-6efe9d1044de no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:34:42.406: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-6829" for this suite.
Dec  3 15:34:48.430: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:34:48.604: INFO: namespace containers-6829 deletion completed in 6.18900733s
â€¢SSS
------------------------------
[sig-apps] Job 
  should delete a job [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:34:48.604: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename job
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in job-9737
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete a job [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: delete a job
STEP: deleting Job.batch foo in namespace job-9737, will wait for the garbage collector to delete the pods
Dec  3 15:34:50.825: INFO: Deleting Job.batch foo took: 6.759709ms
Dec  3 15:34:50.926: INFO: Terminating Job.batch foo pods took: 100.352106ms
STEP: Ensuring job was deleted
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:35:35.731: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-9737" for this suite.
Dec  3 15:35:41.754: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:35:41.924: INFO: namespace job-9737 deletion completed in 6.184902951s
â€¢SSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] version v1
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:35:41.924: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-2951
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Dec  3 15:35:42.090: INFO: (0) /api/v1/nodes/izgw8afzp8040eoqk0qbhwz/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 11.570543ms)
Dec  3 15:35:42.137: INFO: (1) /api/v1/nodes/izgw8afzp8040eoqk0qbhwz/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 47.277643ms)
Dec  3 15:35:42.145: INFO: (2) /api/v1/nodes/izgw8afzp8040eoqk0qbhwz/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 8.139779ms)
Dec  3 15:35:42.153: INFO: (3) /api/v1/nodes/izgw8afzp8040eoqk0qbhwz/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 8.197328ms)
Dec  3 15:35:42.162: INFO: (4) /api/v1/nodes/izgw8afzp8040eoqk0qbhwz/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 8.448885ms)
Dec  3 15:35:42.170: INFO: (5) /api/v1/nodes/izgw8afzp8040eoqk0qbhwz/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 8.073563ms)
Dec  3 15:35:42.178: INFO: (6) /api/v1/nodes/izgw8afzp8040eoqk0qbhwz/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 8.034348ms)
Dec  3 15:35:42.187: INFO: (7) /api/v1/nodes/izgw8afzp8040eoqk0qbhwz/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 8.330348ms)
Dec  3 15:35:42.194: INFO: (8) /api/v1/nodes/izgw8afzp8040eoqk0qbhwz/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 7.707126ms)
Dec  3 15:35:42.202: INFO: (9) /api/v1/nodes/izgw8afzp8040eoqk0qbhwz/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 7.920286ms)
Dec  3 15:35:42.211: INFO: (10) /api/v1/nodes/izgw8afzp8040eoqk0qbhwz/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 8.19821ms)
Dec  3 15:35:42.219: INFO: (11) /api/v1/nodes/izgw8afzp8040eoqk0qbhwz/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 7.928344ms)
Dec  3 15:35:42.227: INFO: (12) /api/v1/nodes/izgw8afzp8040eoqk0qbhwz/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 7.712206ms)
Dec  3 15:35:42.235: INFO: (13) /api/v1/nodes/izgw8afzp8040eoqk0qbhwz/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 8.063692ms)
Dec  3 15:35:42.243: INFO: (14) /api/v1/nodes/izgw8afzp8040eoqk0qbhwz/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 8.068868ms)
Dec  3 15:35:42.251: INFO: (15) /api/v1/nodes/izgw8afzp8040eoqk0qbhwz/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 8.53009ms)
Dec  3 15:35:42.259: INFO: (16) /api/v1/nodes/izgw8afzp8040eoqk0qbhwz/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 7.585732ms)
Dec  3 15:35:42.267: INFO: (17) /api/v1/nodes/izgw8afzp8040eoqk0qbhwz/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 7.92443ms)
Dec  3 15:35:42.275: INFO: (18) /api/v1/nodes/izgw8afzp8040eoqk0qbhwz/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 7.621254ms)
Dec  3 15:35:42.283: INFO: (19) /api/v1/nodes/izgw8afzp8040eoqk0qbhwz/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 8.182818ms)
[AfterEach] version v1
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:35:42.283: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-2951" for this suite.
Dec  3 15:35:48.304: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:35:48.472: INFO: namespace proxy-2951 deletion completed in 6.183383787s
â€¢SSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:35:48.473: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-4679
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-4679
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a new StatefulSet
Dec  3 15:35:48.633: INFO: Found 0 stateful pods, waiting for 3
Dec  3 15:35:58.640: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Dec  3 15:35:58.640: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Dec  3 15:35:58.640: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Dec  3 15:35:58.674: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Dec  3 15:36:08.715: INFO: Updating stateful set ss2
Dec  3 15:36:08.725: INFO: Waiting for Pod statefulset-4679/ss2-2 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Dec  3 15:36:18.736: INFO: Waiting for Pod statefulset-4679/ss2-2 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
STEP: Restoring Pods to the correct revision when they are deleted
Dec  3 15:36:28.758: INFO: Found 2 stateful pods, waiting for 3
Dec  3 15:36:38.766: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Dec  3 15:36:38.766: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Dec  3 15:36:38.766: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Dec  3 15:36:38.796: INFO: Updating stateful set ss2
Dec  3 15:36:38.805: INFO: Waiting for Pod statefulset-4679/ss2-1 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Dec  3 15:36:48.837: INFO: Updating stateful set ss2
Dec  3 15:36:48.846: INFO: Waiting for StatefulSet statefulset-4679/ss2 to complete update
Dec  3 15:36:48.846: INFO: Waiting for Pod statefulset-4679/ss2-0 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Dec  3 15:36:58.857: INFO: Deleting all statefulset in ns statefulset-4679
Dec  3 15:36:58.863: INFO: Scaling statefulset ss2 to 0
Dec  3 15:37:28.884: INFO: Waiting for statefulset status.replicas updated to 0
Dec  3 15:37:28.889: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:37:28.905: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-4679" for this suite.
Dec  3 15:37:34.929: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:37:35.096: INFO: namespace statefulset-4679 deletion completed in 6.183045532s
â€¢SSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:37:35.097: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-6254
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
Dec  3 15:37:35.246: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:37:38.681: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-6254" for this suite.
Dec  3 15:38:00.704: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:38:00.910: INFO: namespace init-container-6254 deletion completed in 22.221501588s
â€¢SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:38:00.911: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-1792
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-1792.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-1792.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-1792.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-1792.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-1792.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-1792.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-1792.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-1792.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-1792.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-1792.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-1792.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-1792.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-1792.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 221.185.109.100.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/100.109.185.221_udp@PTR;check="$$(dig +tcp +noall +answer +search 221.185.109.100.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/100.109.185.221_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-1792.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-1792.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-1792.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-1792.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-1792.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-1792.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-1792.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-1792.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-1792.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-1792.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-1792.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-1792.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-1792.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 221.185.109.100.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/100.109.185.221_udp@PTR;check="$$(dig +tcp +noall +answer +search 221.185.109.100.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/100.109.185.221_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec  3 15:38:03.190: INFO: Unable to read wheezy_udp@dns-test-service.dns-1792.svc.cluster.local from pod dns-1792/dns-test-ff6cef8e-5abb-4377-a2a3-29055e17f481: the server could not find the requested resource (get pods dns-test-ff6cef8e-5abb-4377-a2a3-29055e17f481)
Dec  3 15:38:03.236: INFO: Unable to read wheezy_tcp@dns-test-service.dns-1792.svc.cluster.local from pod dns-1792/dns-test-ff6cef8e-5abb-4377-a2a3-29055e17f481: the server could not find the requested resource (get pods dns-test-ff6cef8e-5abb-4377-a2a3-29055e17f481)
Dec  3 15:38:03.244: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-1792.svc.cluster.local from pod dns-1792/dns-test-ff6cef8e-5abb-4377-a2a3-29055e17f481: the server could not find the requested resource (get pods dns-test-ff6cef8e-5abb-4377-a2a3-29055e17f481)
Dec  3 15:38:03.252: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-1792.svc.cluster.local from pod dns-1792/dns-test-ff6cef8e-5abb-4377-a2a3-29055e17f481: the server could not find the requested resource (get pods dns-test-ff6cef8e-5abb-4377-a2a3-29055e17f481)
Dec  3 15:38:03.665: INFO: Unable to read jessie_udp@dns-test-service.dns-1792.svc.cluster.local from pod dns-1792/dns-test-ff6cef8e-5abb-4377-a2a3-29055e17f481: the server could not find the requested resource (get pods dns-test-ff6cef8e-5abb-4377-a2a3-29055e17f481)
Dec  3 15:38:03.675: INFO: Unable to read jessie_tcp@dns-test-service.dns-1792.svc.cluster.local from pod dns-1792/dns-test-ff6cef8e-5abb-4377-a2a3-29055e17f481: the server could not find the requested resource (get pods dns-test-ff6cef8e-5abb-4377-a2a3-29055e17f481)
Dec  3 15:38:03.683: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-1792.svc.cluster.local from pod dns-1792/dns-test-ff6cef8e-5abb-4377-a2a3-29055e17f481: the server could not find the requested resource (get pods dns-test-ff6cef8e-5abb-4377-a2a3-29055e17f481)
Dec  3 15:38:03.691: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-1792.svc.cluster.local from pod dns-1792/dns-test-ff6cef8e-5abb-4377-a2a3-29055e17f481: the server could not find the requested resource (get pods dns-test-ff6cef8e-5abb-4377-a2a3-29055e17f481)
Dec  3 15:38:04.056: INFO: Lookups using dns-1792/dns-test-ff6cef8e-5abb-4377-a2a3-29055e17f481 failed for: [wheezy_udp@dns-test-service.dns-1792.svc.cluster.local wheezy_tcp@dns-test-service.dns-1792.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-1792.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-1792.svc.cluster.local jessie_udp@dns-test-service.dns-1792.svc.cluster.local jessie_tcp@dns-test-service.dns-1792.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-1792.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-1792.svc.cluster.local]

Dec  3 15:38:09.065: INFO: Unable to read wheezy_udp@dns-test-service.dns-1792.svc.cluster.local from pod dns-1792/dns-test-ff6cef8e-5abb-4377-a2a3-29055e17f481: the server could not find the requested resource (get pods dns-test-ff6cef8e-5abb-4377-a2a3-29055e17f481)
Dec  3 15:38:09.073: INFO: Unable to read wheezy_tcp@dns-test-service.dns-1792.svc.cluster.local from pod dns-1792/dns-test-ff6cef8e-5abb-4377-a2a3-29055e17f481: the server could not find the requested resource (get pods dns-test-ff6cef8e-5abb-4377-a2a3-29055e17f481)
Dec  3 15:38:09.080: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-1792.svc.cluster.local from pod dns-1792/dns-test-ff6cef8e-5abb-4377-a2a3-29055e17f481: the server could not find the requested resource (get pods dns-test-ff6cef8e-5abb-4377-a2a3-29055e17f481)
Dec  3 15:38:09.087: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-1792.svc.cluster.local from pod dns-1792/dns-test-ff6cef8e-5abb-4377-a2a3-29055e17f481: the server could not find the requested resource (get pods dns-test-ff6cef8e-5abb-4377-a2a3-29055e17f481)
Dec  3 15:38:09.496: INFO: Unable to read jessie_udp@dns-test-service.dns-1792.svc.cluster.local from pod dns-1792/dns-test-ff6cef8e-5abb-4377-a2a3-29055e17f481: the server could not find the requested resource (get pods dns-test-ff6cef8e-5abb-4377-a2a3-29055e17f481)
Dec  3 15:38:09.504: INFO: Unable to read jessie_tcp@dns-test-service.dns-1792.svc.cluster.local from pod dns-1792/dns-test-ff6cef8e-5abb-4377-a2a3-29055e17f481: the server could not find the requested resource (get pods dns-test-ff6cef8e-5abb-4377-a2a3-29055e17f481)
Dec  3 15:38:09.511: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-1792.svc.cluster.local from pod dns-1792/dns-test-ff6cef8e-5abb-4377-a2a3-29055e17f481: the server could not find the requested resource (get pods dns-test-ff6cef8e-5abb-4377-a2a3-29055e17f481)
Dec  3 15:38:09.518: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-1792.svc.cluster.local from pod dns-1792/dns-test-ff6cef8e-5abb-4377-a2a3-29055e17f481: the server could not find the requested resource (get pods dns-test-ff6cef8e-5abb-4377-a2a3-29055e17f481)
Dec  3 15:38:09.881: INFO: Lookups using dns-1792/dns-test-ff6cef8e-5abb-4377-a2a3-29055e17f481 failed for: [wheezy_udp@dns-test-service.dns-1792.svc.cluster.local wheezy_tcp@dns-test-service.dns-1792.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-1792.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-1792.svc.cluster.local jessie_udp@dns-test-service.dns-1792.svc.cluster.local jessie_tcp@dns-test-service.dns-1792.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-1792.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-1792.svc.cluster.local]

Dec  3 15:38:14.066: INFO: Unable to read wheezy_udp@dns-test-service.dns-1792.svc.cluster.local from pod dns-1792/dns-test-ff6cef8e-5abb-4377-a2a3-29055e17f481: the server could not find the requested resource (get pods dns-test-ff6cef8e-5abb-4377-a2a3-29055e17f481)
Dec  3 15:38:14.074: INFO: Unable to read wheezy_tcp@dns-test-service.dns-1792.svc.cluster.local from pod dns-1792/dns-test-ff6cef8e-5abb-4377-a2a3-29055e17f481: the server could not find the requested resource (get pods dns-test-ff6cef8e-5abb-4377-a2a3-29055e17f481)
Dec  3 15:38:14.081: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-1792.svc.cluster.local from pod dns-1792/dns-test-ff6cef8e-5abb-4377-a2a3-29055e17f481: the server could not find the requested resource (get pods dns-test-ff6cef8e-5abb-4377-a2a3-29055e17f481)
Dec  3 15:38:14.089: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-1792.svc.cluster.local from pod dns-1792/dns-test-ff6cef8e-5abb-4377-a2a3-29055e17f481: the server could not find the requested resource (get pods dns-test-ff6cef8e-5abb-4377-a2a3-29055e17f481)
Dec  3 15:38:14.499: INFO: Unable to read jessie_udp@dns-test-service.dns-1792.svc.cluster.local from pod dns-1792/dns-test-ff6cef8e-5abb-4377-a2a3-29055e17f481: the server could not find the requested resource (get pods dns-test-ff6cef8e-5abb-4377-a2a3-29055e17f481)
Dec  3 15:38:14.507: INFO: Unable to read jessie_tcp@dns-test-service.dns-1792.svc.cluster.local from pod dns-1792/dns-test-ff6cef8e-5abb-4377-a2a3-29055e17f481: the server could not find the requested resource (get pods dns-test-ff6cef8e-5abb-4377-a2a3-29055e17f481)
Dec  3 15:38:14.515: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-1792.svc.cluster.local from pod dns-1792/dns-test-ff6cef8e-5abb-4377-a2a3-29055e17f481: the server could not find the requested resource (get pods dns-test-ff6cef8e-5abb-4377-a2a3-29055e17f481)
Dec  3 15:38:14.522: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-1792.svc.cluster.local from pod dns-1792/dns-test-ff6cef8e-5abb-4377-a2a3-29055e17f481: the server could not find the requested resource (get pods dns-test-ff6cef8e-5abb-4377-a2a3-29055e17f481)
Dec  3 15:38:14.886: INFO: Lookups using dns-1792/dns-test-ff6cef8e-5abb-4377-a2a3-29055e17f481 failed for: [wheezy_udp@dns-test-service.dns-1792.svc.cluster.local wheezy_tcp@dns-test-service.dns-1792.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-1792.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-1792.svc.cluster.local jessie_udp@dns-test-service.dns-1792.svc.cluster.local jessie_tcp@dns-test-service.dns-1792.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-1792.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-1792.svc.cluster.local]

Dec  3 15:38:19.064: INFO: Unable to read wheezy_udp@dns-test-service.dns-1792.svc.cluster.local from pod dns-1792/dns-test-ff6cef8e-5abb-4377-a2a3-29055e17f481: the server could not find the requested resource (get pods dns-test-ff6cef8e-5abb-4377-a2a3-29055e17f481)
Dec  3 15:38:19.072: INFO: Unable to read wheezy_tcp@dns-test-service.dns-1792.svc.cluster.local from pod dns-1792/dns-test-ff6cef8e-5abb-4377-a2a3-29055e17f481: the server could not find the requested resource (get pods dns-test-ff6cef8e-5abb-4377-a2a3-29055e17f481)
Dec  3 15:38:19.079: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-1792.svc.cluster.local from pod dns-1792/dns-test-ff6cef8e-5abb-4377-a2a3-29055e17f481: the server could not find the requested resource (get pods dns-test-ff6cef8e-5abb-4377-a2a3-29055e17f481)
Dec  3 15:38:19.086: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-1792.svc.cluster.local from pod dns-1792/dns-test-ff6cef8e-5abb-4377-a2a3-29055e17f481: the server could not find the requested resource (get pods dns-test-ff6cef8e-5abb-4377-a2a3-29055e17f481)
Dec  3 15:38:19.496: INFO: Unable to read jessie_udp@dns-test-service.dns-1792.svc.cluster.local from pod dns-1792/dns-test-ff6cef8e-5abb-4377-a2a3-29055e17f481: the server could not find the requested resource (get pods dns-test-ff6cef8e-5abb-4377-a2a3-29055e17f481)
Dec  3 15:38:19.503: INFO: Unable to read jessie_tcp@dns-test-service.dns-1792.svc.cluster.local from pod dns-1792/dns-test-ff6cef8e-5abb-4377-a2a3-29055e17f481: the server could not find the requested resource (get pods dns-test-ff6cef8e-5abb-4377-a2a3-29055e17f481)
Dec  3 15:38:19.510: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-1792.svc.cluster.local from pod dns-1792/dns-test-ff6cef8e-5abb-4377-a2a3-29055e17f481: the server could not find the requested resource (get pods dns-test-ff6cef8e-5abb-4377-a2a3-29055e17f481)
Dec  3 15:38:19.518: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-1792.svc.cluster.local from pod dns-1792/dns-test-ff6cef8e-5abb-4377-a2a3-29055e17f481: the server could not find the requested resource (get pods dns-test-ff6cef8e-5abb-4377-a2a3-29055e17f481)
Dec  3 15:38:19.882: INFO: Lookups using dns-1792/dns-test-ff6cef8e-5abb-4377-a2a3-29055e17f481 failed for: [wheezy_udp@dns-test-service.dns-1792.svc.cluster.local wheezy_tcp@dns-test-service.dns-1792.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-1792.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-1792.svc.cluster.local jessie_udp@dns-test-service.dns-1792.svc.cluster.local jessie_tcp@dns-test-service.dns-1792.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-1792.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-1792.svc.cluster.local]

Dec  3 15:38:24.065: INFO: Unable to read wheezy_udp@dns-test-service.dns-1792.svc.cluster.local from pod dns-1792/dns-test-ff6cef8e-5abb-4377-a2a3-29055e17f481: the server could not find the requested resource (get pods dns-test-ff6cef8e-5abb-4377-a2a3-29055e17f481)
Dec  3 15:38:24.072: INFO: Unable to read wheezy_tcp@dns-test-service.dns-1792.svc.cluster.local from pod dns-1792/dns-test-ff6cef8e-5abb-4377-a2a3-29055e17f481: the server could not find the requested resource (get pods dns-test-ff6cef8e-5abb-4377-a2a3-29055e17f481)
Dec  3 15:38:24.080: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-1792.svc.cluster.local from pod dns-1792/dns-test-ff6cef8e-5abb-4377-a2a3-29055e17f481: the server could not find the requested resource (get pods dns-test-ff6cef8e-5abb-4377-a2a3-29055e17f481)
Dec  3 15:38:24.087: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-1792.svc.cluster.local from pod dns-1792/dns-test-ff6cef8e-5abb-4377-a2a3-29055e17f481: the server could not find the requested resource (get pods dns-test-ff6cef8e-5abb-4377-a2a3-29055e17f481)
Dec  3 15:38:24.497: INFO: Unable to read jessie_udp@dns-test-service.dns-1792.svc.cluster.local from pod dns-1792/dns-test-ff6cef8e-5abb-4377-a2a3-29055e17f481: the server could not find the requested resource (get pods dns-test-ff6cef8e-5abb-4377-a2a3-29055e17f481)
Dec  3 15:38:24.504: INFO: Unable to read jessie_tcp@dns-test-service.dns-1792.svc.cluster.local from pod dns-1792/dns-test-ff6cef8e-5abb-4377-a2a3-29055e17f481: the server could not find the requested resource (get pods dns-test-ff6cef8e-5abb-4377-a2a3-29055e17f481)
Dec  3 15:38:24.512: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-1792.svc.cluster.local from pod dns-1792/dns-test-ff6cef8e-5abb-4377-a2a3-29055e17f481: the server could not find the requested resource (get pods dns-test-ff6cef8e-5abb-4377-a2a3-29055e17f481)
Dec  3 15:38:24.519: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-1792.svc.cluster.local from pod dns-1792/dns-test-ff6cef8e-5abb-4377-a2a3-29055e17f481: the server could not find the requested resource (get pods dns-test-ff6cef8e-5abb-4377-a2a3-29055e17f481)
Dec  3 15:38:24.882: INFO: Lookups using dns-1792/dns-test-ff6cef8e-5abb-4377-a2a3-29055e17f481 failed for: [wheezy_udp@dns-test-service.dns-1792.svc.cluster.local wheezy_tcp@dns-test-service.dns-1792.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-1792.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-1792.svc.cluster.local jessie_udp@dns-test-service.dns-1792.svc.cluster.local jessie_tcp@dns-test-service.dns-1792.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-1792.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-1792.svc.cluster.local]

Dec  3 15:38:29.065: INFO: Unable to read wheezy_udp@dns-test-service.dns-1792.svc.cluster.local from pod dns-1792/dns-test-ff6cef8e-5abb-4377-a2a3-29055e17f481: the server could not find the requested resource (get pods dns-test-ff6cef8e-5abb-4377-a2a3-29055e17f481)
Dec  3 15:38:29.072: INFO: Unable to read wheezy_tcp@dns-test-service.dns-1792.svc.cluster.local from pod dns-1792/dns-test-ff6cef8e-5abb-4377-a2a3-29055e17f481: the server could not find the requested resource (get pods dns-test-ff6cef8e-5abb-4377-a2a3-29055e17f481)
Dec  3 15:38:29.079: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-1792.svc.cluster.local from pod dns-1792/dns-test-ff6cef8e-5abb-4377-a2a3-29055e17f481: the server could not find the requested resource (get pods dns-test-ff6cef8e-5abb-4377-a2a3-29055e17f481)
Dec  3 15:38:29.086: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-1792.svc.cluster.local from pod dns-1792/dns-test-ff6cef8e-5abb-4377-a2a3-29055e17f481: the server could not find the requested resource (get pods dns-test-ff6cef8e-5abb-4377-a2a3-29055e17f481)
Dec  3 15:38:29.535: INFO: Unable to read jessie_udp@dns-test-service.dns-1792.svc.cluster.local from pod dns-1792/dns-test-ff6cef8e-5abb-4377-a2a3-29055e17f481: the server could not find the requested resource (get pods dns-test-ff6cef8e-5abb-4377-a2a3-29055e17f481)
Dec  3 15:38:29.544: INFO: Unable to read jessie_tcp@dns-test-service.dns-1792.svc.cluster.local from pod dns-1792/dns-test-ff6cef8e-5abb-4377-a2a3-29055e17f481: the server could not find the requested resource (get pods dns-test-ff6cef8e-5abb-4377-a2a3-29055e17f481)
Dec  3 15:38:29.551: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-1792.svc.cluster.local from pod dns-1792/dns-test-ff6cef8e-5abb-4377-a2a3-29055e17f481: the server could not find the requested resource (get pods dns-test-ff6cef8e-5abb-4377-a2a3-29055e17f481)
Dec  3 15:38:29.559: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-1792.svc.cluster.local from pod dns-1792/dns-test-ff6cef8e-5abb-4377-a2a3-29055e17f481: the server could not find the requested resource (get pods dns-test-ff6cef8e-5abb-4377-a2a3-29055e17f481)
Dec  3 15:38:29.924: INFO: Lookups using dns-1792/dns-test-ff6cef8e-5abb-4377-a2a3-29055e17f481 failed for: [wheezy_udp@dns-test-service.dns-1792.svc.cluster.local wheezy_tcp@dns-test-service.dns-1792.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-1792.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-1792.svc.cluster.local jessie_udp@dns-test-service.dns-1792.svc.cluster.local jessie_tcp@dns-test-service.dns-1792.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-1792.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-1792.svc.cluster.local]

Dec  3 15:38:35.360: INFO: DNS probes using dns-1792/dns-test-ff6cef8e-5abb-4377-a2a3-29055e17f481 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:38:35.387: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-1792" for this suite.
Dec  3 15:38:41.407: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:38:41.608: INFO: namespace dns-1792 deletion completed in 6.215676148s
â€¢SSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:38:41.609: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3039
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name cm-test-opt-del-17362f3b-bb38-4839-a0d2-1b9f3167635c
STEP: Creating configMap with name cm-test-opt-upd-27598124-1b94-47c3-9615-07ed2d23021a
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-17362f3b-bb38-4839-a0d2-1b9f3167635c
STEP: Updating configmap cm-test-opt-upd-27598124-1b94-47c3-9615-07ed2d23021a
STEP: Creating configMap with name cm-test-opt-create-81407ec9-9621-4766-b477-f6fe57037614
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:38:46.140: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3039" for this suite.
Dec  3 15:39:08.164: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:39:08.373: INFO: namespace projected-3039 deletion completed in 22.224474677s
â€¢SSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:39:08.373: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-9082
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Dec  3 15:39:08.529: INFO: Waiting up to 5m0s for pod "downwardapi-volume-8ac6f505-243b-4e70-9f49-2cd1817e933f" in namespace "downward-api-9082" to be "success or failure"
Dec  3 15:39:08.533: INFO: Pod "downwardapi-volume-8ac6f505-243b-4e70-9f49-2cd1817e933f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.37406ms
Dec  3 15:39:10.538: INFO: Pod "downwardapi-volume-8ac6f505-243b-4e70-9f49-2cd1817e933f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009446178s
STEP: Saw pod success
Dec  3 15:39:10.538: INFO: Pod "downwardapi-volume-8ac6f505-243b-4e70-9f49-2cd1817e933f" satisfied condition "success or failure"
Dec  3 15:39:10.543: INFO: Trying to get logs from node izgw8afzp8040eoqk0qbhxz pod downwardapi-volume-8ac6f505-243b-4e70-9f49-2cd1817e933f container client-container: <nil>
STEP: delete the pod
Dec  3 15:39:10.567: INFO: Waiting for pod downwardapi-volume-8ac6f505-243b-4e70-9f49-2cd1817e933f to disappear
Dec  3 15:39:10.571: INFO: Pod downwardapi-volume-8ac6f505-243b-4e70-9f49-2cd1817e933f no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:39:10.571: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9082" for this suite.
Dec  3 15:39:16.593: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:39:16.760: INFO: namespace downward-api-9082 deletion completed in 6.181421151s
â€¢SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:39:16.760: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-6381
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0644 on node default medium
Dec  3 15:39:16.914: INFO: Waiting up to 5m0s for pod "pod-66fe1643-c636-40c8-b43e-f43c424c51fe" in namespace "emptydir-6381" to be "success or failure"
Dec  3 15:39:16.919: INFO: Pod "pod-66fe1643-c636-40c8-b43e-f43c424c51fe": Phase="Pending", Reason="", readiness=false. Elapsed: 4.214466ms
Dec  3 15:39:18.925: INFO: Pod "pod-66fe1643-c636-40c8-b43e-f43c424c51fe": Phase="Running", Reason="", readiness=true. Elapsed: 2.010167049s
Dec  3 15:39:20.930: INFO: Pod "pod-66fe1643-c636-40c8-b43e-f43c424c51fe": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016080816s
STEP: Saw pod success
Dec  3 15:39:20.931: INFO: Pod "pod-66fe1643-c636-40c8-b43e-f43c424c51fe" satisfied condition "success or failure"
Dec  3 15:39:20.935: INFO: Trying to get logs from node izgw8afzp8040eoqk0qbhxz pod pod-66fe1643-c636-40c8-b43e-f43c424c51fe container test-container: <nil>
STEP: delete the pod
Dec  3 15:39:20.957: INFO: Waiting for pod pod-66fe1643-c636-40c8-b43e-f43c424c51fe to disappear
Dec  3 15:39:20.962: INFO: Pod pod-66fe1643-c636-40c8-b43e-f43c424c51fe no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:39:20.962: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6381" for this suite.
Dec  3 15:39:26.984: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:39:27.153: INFO: namespace emptydir-6381 deletion completed in 6.183183886s
â€¢SSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:39:27.153: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svcaccounts-9270
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: getting the auto-created API token
STEP: reading a file in the container
Dec  3 15:39:29.834: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl exec --namespace=svcaccounts-9270 pod-service-account-908b28fd-3949-4372-a359-ba58f187c974 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
STEP: reading a file in the container
Dec  3 15:39:30.639: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl exec --namespace=svcaccounts-9270 pod-service-account-908b28fd-3949-4372-a359-ba58f187c974 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
STEP: reading a file in the container
Dec  3 15:39:31.273: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl exec --namespace=svcaccounts-9270 pod-service-account-908b28fd-3949-4372-a359-ba58f187c974 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:39:31.858: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-9270" for this suite.
Dec  3 15:39:37.888: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:39:38.059: INFO: namespace svcaccounts-9270 deletion completed in 6.191101009s
â€¢SSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:39:38.060: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5027
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Dec  3 15:39:38.220: INFO: Waiting up to 5m0s for pod "downwardapi-volume-00b6b908-c592-4d62-8d21-6f8a9d1cf018" in namespace "projected-5027" to be "success or failure"
Dec  3 15:39:38.224: INFO: Pod "downwardapi-volume-00b6b908-c592-4d62-8d21-6f8a9d1cf018": Phase="Pending", Reason="", readiness=false. Elapsed: 4.642034ms
Dec  3 15:39:40.230: INFO: Pod "downwardapi-volume-00b6b908-c592-4d62-8d21-6f8a9d1cf018": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009896098s
STEP: Saw pod success
Dec  3 15:39:40.230: INFO: Pod "downwardapi-volume-00b6b908-c592-4d62-8d21-6f8a9d1cf018" satisfied condition "success or failure"
Dec  3 15:39:40.234: INFO: Trying to get logs from node izgw8afzp8040eoqk0qbhxz pod downwardapi-volume-00b6b908-c592-4d62-8d21-6f8a9d1cf018 container client-container: <nil>
STEP: delete the pod
Dec  3 15:39:40.259: INFO: Waiting for pod downwardapi-volume-00b6b908-c592-4d62-8d21-6f8a9d1cf018 to disappear
Dec  3 15:39:40.264: INFO: Pod downwardapi-volume-00b6b908-c592-4d62-8d21-6f8a9d1cf018 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:39:40.264: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5027" for this suite.
Dec  3 15:39:46.285: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:39:46.458: INFO: namespace projected-5027 deletion completed in 6.186480643s
â€¢SSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:39:46.458: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-2026
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-map-7bff139e-0e92-4f68-b436-ebfcb2ad7ec9
STEP: Creating a pod to test consume configMaps
Dec  3 15:39:46.615: INFO: Waiting up to 5m0s for pod "pod-configmaps-7a1b4c81-09a6-4556-8a2f-1151179db03d" in namespace "configmap-2026" to be "success or failure"
Dec  3 15:39:46.619: INFO: Pod "pod-configmaps-7a1b4c81-09a6-4556-8a2f-1151179db03d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.15771ms
Dec  3 15:39:48.625: INFO: Pod "pod-configmaps-7a1b4c81-09a6-4556-8a2f-1151179db03d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009847366s
STEP: Saw pod success
Dec  3 15:39:48.625: INFO: Pod "pod-configmaps-7a1b4c81-09a6-4556-8a2f-1151179db03d" satisfied condition "success or failure"
Dec  3 15:39:48.630: INFO: Trying to get logs from node izgw8afzp8040eoqk0qbhxz pod pod-configmaps-7a1b4c81-09a6-4556-8a2f-1151179db03d container configmap-volume-test: <nil>
STEP: delete the pod
Dec  3 15:39:48.652: INFO: Waiting for pod pod-configmaps-7a1b4c81-09a6-4556-8a2f-1151179db03d to disappear
Dec  3 15:39:48.657: INFO: Pod pod-configmaps-7a1b4c81-09a6-4556-8a2f-1151179db03d no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:39:48.657: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2026" for this suite.
Dec  3 15:39:54.679: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:39:54.888: INFO: namespace configmap-2026 deletion completed in 6.223737679s
â€¢SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:39:54.888: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-3621
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1721
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Dec  3 15:39:55.034: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmwqx-5aq.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config run e2e-test-nginx-pod --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --labels=run=e2e-test-nginx-pod --namespace=kubectl-3621'
Dec  3 15:39:55.172: INFO: stderr: ""
Dec  3 15:39:55.172: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod is running
STEP: verifying the pod e2e-test-nginx-pod was created
Dec  3 15:40:00.222: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmwqx-5aq.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pod e2e-test-nginx-pod --namespace=kubectl-3621 -o json'
Dec  3 15:40:00.310: INFO: stderr: ""
Dec  3 15:40:00.310: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"annotations\": {\n            \"cni.projectcalico.org/podIP\": \"100.64.1.199/32\",\n            \"kubernetes.io/psp\": \"e2e-test-privileged-psp\"\n        },\n        \"creationTimestamp\": \"2019-12-03T15:39:55Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"kubectl-3621\",\n        \"resourceVersion\": \"20629\",\n        \"selfLink\": \"/api/v1/namespaces/kubectl-3621/pods/e2e-test-nginx-pod\",\n        \"uid\": \"a35c2b85-0f62-42aa-ac95-53097ad6f710\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-2hms9\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"izgw8afzp8040eoqk0qbhxz\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-2hms9\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-2hms9\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-12-03T15:39:55Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-12-03T15:39:56Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-12-03T15:39:56Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-12-03T15:39:55Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://be80156805c90bbb358857258f0531b38ad6c8facea691e30dc0dd5655b1147b\",\n                \"image\": \"nginx:1.14-alpine\",\n                \"imageID\": \"docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2019-12-03T15:39:56Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.250.31.244\",\n        \"phase\": \"Running\",\n        \"podIP\": \"100.64.1.199\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2019-12-03T15:39:55Z\"\n    }\n}\n"
STEP: replace the image in the pod
Dec  3 15:40:00.311: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmwqx-5aq.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config replace -f - --namespace=kubectl-3621'
Dec  3 15:40:00.580: INFO: stderr: ""
Dec  3 15:40:00.580: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
STEP: verifying the pod e2e-test-nginx-pod has the right image docker.io/library/busybox:1.29
[AfterEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1726
Dec  3 15:40:00.585: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmwqx-5aq.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config delete pods e2e-test-nginx-pod --namespace=kubectl-3621'
Dec  3 15:40:02.479: INFO: stderr: ""
Dec  3 15:40:02.479: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:40:02.479: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3621" for this suite.
Dec  3 15:40:08.502: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:40:08.668: INFO: namespace kubectl-3621 deletion completed in 6.181882058s
â€¢SSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:40:08.669: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-3297
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Dec  3 15:40:08.838: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Dec  3 15:40:08.852: INFO: Number of nodes with available pods: 0
Dec  3 15:40:08.852: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Dec  3 15:40:08.873: INFO: Number of nodes with available pods: 0
Dec  3 15:40:08.873: INFO: Node izgw8afzp8040eoqk0qbhwz is running more than one daemon pod
Dec  3 15:40:09.879: INFO: Number of nodes with available pods: 0
Dec  3 15:40:09.879: INFO: Node izgw8afzp8040eoqk0qbhwz is running more than one daemon pod
Dec  3 15:40:10.879: INFO: Number of nodes with available pods: 1
Dec  3 15:40:10.879: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Dec  3 15:40:10.899: INFO: Number of nodes with available pods: 0
Dec  3 15:40:10.899: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Dec  3 15:40:10.913: INFO: Number of nodes with available pods: 0
Dec  3 15:40:10.913: INFO: Node izgw8afzp8040eoqk0qbhwz is running more than one daemon pod
Dec  3 15:40:11.918: INFO: Number of nodes with available pods: 0
Dec  3 15:40:11.919: INFO: Node izgw8afzp8040eoqk0qbhwz is running more than one daemon pod
Dec  3 15:40:12.919: INFO: Number of nodes with available pods: 0
Dec  3 15:40:12.919: INFO: Node izgw8afzp8040eoqk0qbhwz is running more than one daemon pod
Dec  3 15:40:13.919: INFO: Number of nodes with available pods: 0
Dec  3 15:40:13.919: INFO: Node izgw8afzp8040eoqk0qbhwz is running more than one daemon pod
Dec  3 15:40:14.919: INFO: Number of nodes with available pods: 0
Dec  3 15:40:14.919: INFO: Node izgw8afzp8040eoqk0qbhwz is running more than one daemon pod
Dec  3 15:40:15.919: INFO: Number of nodes with available pods: 0
Dec  3 15:40:15.919: INFO: Node izgw8afzp8040eoqk0qbhwz is running more than one daemon pod
Dec  3 15:40:16.919: INFO: Number of nodes with available pods: 0
Dec  3 15:40:16.919: INFO: Node izgw8afzp8040eoqk0qbhwz is running more than one daemon pod
Dec  3 15:40:17.919: INFO: Number of nodes with available pods: 0
Dec  3 15:40:17.919: INFO: Node izgw8afzp8040eoqk0qbhwz is running more than one daemon pod
Dec  3 15:40:18.919: INFO: Number of nodes with available pods: 0
Dec  3 15:40:18.919: INFO: Node izgw8afzp8040eoqk0qbhwz is running more than one daemon pod
Dec  3 15:40:19.919: INFO: Number of nodes with available pods: 0
Dec  3 15:40:19.919: INFO: Node izgw8afzp8040eoqk0qbhwz is running more than one daemon pod
Dec  3 15:40:20.919: INFO: Number of nodes with available pods: 0
Dec  3 15:40:20.919: INFO: Node izgw8afzp8040eoqk0qbhwz is running more than one daemon pod
Dec  3 15:40:21.919: INFO: Number of nodes with available pods: 0
Dec  3 15:40:21.919: INFO: Node izgw8afzp8040eoqk0qbhwz is running more than one daemon pod
Dec  3 15:40:22.919: INFO: Number of nodes with available pods: 0
Dec  3 15:40:22.919: INFO: Node izgw8afzp8040eoqk0qbhwz is running more than one daemon pod
Dec  3 15:40:23.919: INFO: Number of nodes with available pods: 1
Dec  3 15:40:23.919: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-3297, will wait for the garbage collector to delete the pods
Dec  3 15:40:23.991: INFO: Deleting DaemonSet.extensions daemon-set took: 7.547411ms
Dec  3 15:40:24.091: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.341891ms
Dec  3 15:40:31.496: INFO: Number of nodes with available pods: 0
Dec  3 15:40:31.497: INFO: Number of running nodes: 0, number of available pods: 0
Dec  3 15:40:31.501: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-3297/daemonsets","resourceVersion":"20790"},"items":null}

Dec  3 15:40:31.505: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-3297/pods","resourceVersion":"20790"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:40:31.529: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-3297" for this suite.
Dec  3 15:40:37.550: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:40:37.723: INFO: namespace daemonsets-3297 deletion completed in 6.188785863s
â€¢SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:40:37.724: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-6367
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Performing setup for networking test in namespace pod-network-test-6367
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Dec  3 15:40:37.869: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Dec  3 15:41:01.960: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.64.1.201:8080/dial?request=hostName&protocol=udp&host=100.64.1.200&port=8081&tries=1'] Namespace:pod-network-test-6367 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  3 15:41:01.960: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec  3 15:41:02.434: INFO: Waiting for endpoints: map[]
Dec  3 15:41:02.439: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.64.1.201:8080/dial?request=hostName&protocol=udp&host=100.64.0.68&port=8081&tries=1'] Namespace:pod-network-test-6367 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  3 15:41:02.439: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec  3 15:41:02.911: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:41:02.911: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-6367" for this suite.
Dec  3 15:41:24.935: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:41:25.143: INFO: namespace pod-network-test-6367 deletion completed in 22.223865793s
â€¢SSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:41:25.144: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6558
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-map-90c9293e-5756-45ee-b60e-0ee0a0d90155
STEP: Creating a pod to test consume configMaps
Dec  3 15:41:25.305: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-dfaa6925-34ae-4d93-8ee7-913aa3740e30" in namespace "projected-6558" to be "success or failure"
Dec  3 15:41:25.309: INFO: Pod "pod-projected-configmaps-dfaa6925-34ae-4d93-8ee7-913aa3740e30": Phase="Pending", Reason="", readiness=false. Elapsed: 4.054434ms
Dec  3 15:41:27.314: INFO: Pod "pod-projected-configmaps-dfaa6925-34ae-4d93-8ee7-913aa3740e30": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009345481s
STEP: Saw pod success
Dec  3 15:41:27.314: INFO: Pod "pod-projected-configmaps-dfaa6925-34ae-4d93-8ee7-913aa3740e30" satisfied condition "success or failure"
Dec  3 15:41:27.319: INFO: Trying to get logs from node izgw8afzp8040eoqk0qbhxz pod pod-projected-configmaps-dfaa6925-34ae-4d93-8ee7-913aa3740e30 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec  3 15:41:27.340: INFO: Waiting for pod pod-projected-configmaps-dfaa6925-34ae-4d93-8ee7-913aa3740e30 to disappear
Dec  3 15:41:27.344: INFO: Pod pod-projected-configmaps-dfaa6925-34ae-4d93-8ee7-913aa3740e30 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:41:27.345: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6558" for this suite.
Dec  3 15:41:33.366: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:41:33.543: INFO: namespace projected-6558 deletion completed in 6.190995844s
â€¢SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:41:33.543: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-3138
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name secret-emptykey-test-1d86bbc2-9854-483e-824a-29ce5780e51f
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:41:33.694: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3138" for this suite.
Dec  3 15:41:39.713: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:41:39.879: INFO: namespace secrets-3138 deletion completed in 6.179771783s
â€¢SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:41:39.879: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-4838
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with configMap that has name projected-configmap-test-upd-99f5801f-ed3a-410a-be15-e6f83dd200a5
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-99f5801f-ed3a-410a-be15-e6f83dd200a5
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:41:44.172: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4838" for this suite.
Dec  3 15:42:06.195: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:42:06.407: INFO: namespace projected-4838 deletion completed in 22.227183589s
â€¢
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:42:06.408: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-7938
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Dec  3 15:42:06.561: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d0e5247f-4462-4eaa-a508-9f185d7c0f62" in namespace "downward-api-7938" to be "success or failure"
Dec  3 15:42:06.565: INFO: Pod "downwardapi-volume-d0e5247f-4462-4eaa-a508-9f185d7c0f62": Phase="Pending", Reason="", readiness=false. Elapsed: 4.505453ms
Dec  3 15:42:08.571: INFO: Pod "downwardapi-volume-d0e5247f-4462-4eaa-a508-9f185d7c0f62": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010157113s
STEP: Saw pod success
Dec  3 15:42:08.571: INFO: Pod "downwardapi-volume-d0e5247f-4462-4eaa-a508-9f185d7c0f62" satisfied condition "success or failure"
Dec  3 15:42:08.576: INFO: Trying to get logs from node izgw8afzp8040eoqk0qbhxz pod downwardapi-volume-d0e5247f-4462-4eaa-a508-9f185d7c0f62 container client-container: <nil>
STEP: delete the pod
Dec  3 15:42:08.597: INFO: Waiting for pod downwardapi-volume-d0e5247f-4462-4eaa-a508-9f185d7c0f62 to disappear
Dec  3 15:42:08.602: INFO: Pod downwardapi-volume-d0e5247f-4462-4eaa-a508-9f185d7c0f62 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:42:08.602: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7938" for this suite.
Dec  3 15:42:14.625: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:42:14.797: INFO: namespace downward-api-7938 deletion completed in 6.187617362s
â€¢SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:42:14.798: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-3535
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: validating api versions
Dec  3 15:42:14.945: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmwqx-5aq.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config api-versions'
Dec  3 15:42:15.070: INFO: stderr: ""
Dec  3 15:42:15.070: INFO: stdout: "admissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\napps/v1beta1\napps/v1beta2\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncert.gardener.cloud/v1alpha1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1\ncoordination.k8s.io/v1beta1\ncrd.projectcalico.org/v1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nmetrics.k8s.io/v1beta1\nnetworking.k8s.io/v1\nnetworking.k8s.io/v1beta1\nnode.k8s.io/v1beta1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1\nscheduling.k8s.io/v1beta1\nsnapshot.storage.k8s.io/v1alpha1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:42:15.070: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3535" for this suite.
Dec  3 15:42:21.092: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:42:21.255: INFO: namespace kubectl-3535 deletion completed in 6.179199834s
â€¢SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:42:21.256: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-163
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Dec  3 15:42:47.423: INFO: Container started at 2019-12-03 15:42:22 +0000 UTC, pod became ready at 2019-12-03 15:42:45 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:42:47.423: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-163" for this suite.
Dec  3 15:43:09.445: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:43:09.611: INFO: namespace container-probe-163 deletion completed in 22.180587503s
â€¢SSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:43:09.612: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-5809
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating service endpoint-test2 in namespace services-5809
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-5809 to expose endpoints map[]
Dec  3 15:43:09.769: INFO: successfully validated that service endpoint-test2 in namespace services-5809 exposes endpoints map[] (4.133876ms elapsed)
STEP: Creating pod pod1 in namespace services-5809
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-5809 to expose endpoints map[pod1:[80]]
Dec  3 15:43:11.803: INFO: successfully validated that service endpoint-test2 in namespace services-5809 exposes endpoints map[pod1:[80]] (2.02717086s elapsed)
STEP: Creating pod pod2 in namespace services-5809
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-5809 to expose endpoints map[pod1:[80] pod2:[80]]
Dec  3 15:43:13.848: INFO: successfully validated that service endpoint-test2 in namespace services-5809 exposes endpoints map[pod1:[80] pod2:[80]] (2.039544327s elapsed)
STEP: Deleting pod pod1 in namespace services-5809
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-5809 to expose endpoints map[pod2:[80]]
Dec  3 15:43:13.862: INFO: successfully validated that service endpoint-test2 in namespace services-5809 exposes endpoints map[pod2:[80]] (8.340671ms elapsed)
STEP: Deleting pod pod2 in namespace services-5809
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-5809 to expose endpoints map[]
Dec  3 15:43:13.871: INFO: successfully validated that service endpoint-test2 in namespace services-5809 exposes endpoints map[] (3.992396ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:43:13.882: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-5809" for this suite.
Dec  3 15:43:19.903: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:43:20.070: INFO: namespace services-5809 deletion completed in 6.180815337s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:92
â€¢SSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:43:20.070: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-7588
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod liveness-7d4d8444-c4b0-4f0e-a6a7-d0c7af268092 in namespace container-probe-7588
Dec  3 15:43:24.233: INFO: Started pod liveness-7d4d8444-c4b0-4f0e-a6a7-d0c7af268092 in namespace container-probe-7588
STEP: checking the pod's current state and verifying that restartCount is present
Dec  3 15:43:24.237: INFO: Initial restart count of pod liveness-7d4d8444-c4b0-4f0e-a6a7-d0c7af268092 is 0
Dec  3 15:43:48.307: INFO: Restart count of pod container-probe-7588/liveness-7d4d8444-c4b0-4f0e-a6a7-d0c7af268092 is now 1 (24.069192287s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:43:48.315: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-7588" for this suite.
Dec  3 15:43:54.336: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:43:54.496: INFO: namespace container-probe-7588 deletion completed in 6.173368538s
â€¢SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:43:54.496: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-117
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap configmap-117/configmap-test-c3e0d5e1-da15-46b6-869f-9df2e3f60e6b
STEP: Creating a pod to test consume configMaps
Dec  3 15:43:54.653: INFO: Waiting up to 5m0s for pod "pod-configmaps-f7ccead8-f361-420e-94bf-b92b134e4cf4" in namespace "configmap-117" to be "success or failure"
Dec  3 15:43:54.658: INFO: Pod "pod-configmaps-f7ccead8-f361-420e-94bf-b92b134e4cf4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.391641ms
Dec  3 15:43:56.663: INFO: Pod "pod-configmaps-f7ccead8-f361-420e-94bf-b92b134e4cf4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009521174s
STEP: Saw pod success
Dec  3 15:43:56.663: INFO: Pod "pod-configmaps-f7ccead8-f361-420e-94bf-b92b134e4cf4" satisfied condition "success or failure"
Dec  3 15:43:56.668: INFO: Trying to get logs from node izgw8afzp8040eoqk0qbhxz pod pod-configmaps-f7ccead8-f361-420e-94bf-b92b134e4cf4 container env-test: <nil>
STEP: delete the pod
Dec  3 15:43:56.689: INFO: Waiting for pod pod-configmaps-f7ccead8-f361-420e-94bf-b92b134e4cf4 to disappear
Dec  3 15:43:56.693: INFO: Pod pod-configmaps-f7ccead8-f361-420e-94bf-b92b134e4cf4 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:43:56.693: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-117" for this suite.
Dec  3 15:44:02.715: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:44:02.920: INFO: namespace configmap-117 deletion completed in 6.219611615s
â€¢SSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:44:02.921: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-9436
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-map-49f5d880-0fa5-4ddc-98f1-7efcdf24e3fe
STEP: Creating a pod to test consume configMaps
Dec  3 15:44:03.093: INFO: Waiting up to 5m0s for pod "pod-configmaps-214b79e1-7108-45c4-92a4-202395b41cfc" in namespace "configmap-9436" to be "success or failure"
Dec  3 15:44:03.098: INFO: Pod "pod-configmaps-214b79e1-7108-45c4-92a4-202395b41cfc": Phase="Pending", Reason="", readiness=false. Elapsed: 4.586217ms
Dec  3 15:44:05.103: INFO: Pod "pod-configmaps-214b79e1-7108-45c4-92a4-202395b41cfc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010174449s
STEP: Saw pod success
Dec  3 15:44:05.103: INFO: Pod "pod-configmaps-214b79e1-7108-45c4-92a4-202395b41cfc" satisfied condition "success or failure"
Dec  3 15:44:05.108: INFO: Trying to get logs from node izgw8afzp8040eoqk0qbhxz pod pod-configmaps-214b79e1-7108-45c4-92a4-202395b41cfc container configmap-volume-test: <nil>
STEP: delete the pod
Dec  3 15:44:05.129: INFO: Waiting for pod pod-configmaps-214b79e1-7108-45c4-92a4-202395b41cfc to disappear
Dec  3 15:44:05.133: INFO: Pod pod-configmaps-214b79e1-7108-45c4-92a4-202395b41cfc no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:44:05.133: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9436" for this suite.
Dec  3 15:44:11.160: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:44:11.364: INFO: namespace configmap-9436 deletion completed in 6.222589241s
â€¢SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:44:11.365: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-1591
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Dec  3 15:44:11.514: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:44:13.883: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-1591" for this suite.
Dec  3 15:44:57.906: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:44:58.074: INFO: namespace pods-1591 deletion completed in 44.182389639s
â€¢SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:44:58.075: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-2253
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:45:02.240: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-2253" for this suite.
Dec  3 15:45:08.263: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:45:08.425: INFO: namespace kubelet-test-2253 deletion completed in 6.177204977s
â€¢SSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:45:08.425: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-5559
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-5559
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace statefulset-5559
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-5559
Dec  3 15:45:08.593: INFO: Found 0 stateful pods, waiting for 1
Dec  3 15:45:18.599: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Dec  3 15:45:18.604: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmwqx-5aq.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-5559 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec  3 15:45:19.175: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Dec  3 15:45:19.175: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec  3 15:45:19.175: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec  3 15:45:19.181: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Dec  3 15:45:29.187: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Dec  3 15:45:29.187: INFO: Waiting for statefulset status.replicas updated to 0
Dec  3 15:45:29.206: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999312s
Dec  3 15:45:30.212: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.994927448s
Dec  3 15:45:31.218: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.988952618s
Dec  3 15:45:32.224: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.983367261s
Dec  3 15:45:33.229: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.977471345s
Dec  3 15:45:34.235: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.971868404s
Dec  3 15:45:35.241: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.965874541s
Dec  3 15:45:36.247: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.960043421s
Dec  3 15:45:37.253: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.954383223s
Dec  3 15:45:38.259: INFO: Verifying statefulset ss doesn't scale past 1 for another 948.343746ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-5559
Dec  3 15:45:39.265: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmwqx-5aq.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-5559 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  3 15:45:39.817: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Dec  3 15:45:39.817: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec  3 15:45:39.818: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec  3 15:45:39.823: INFO: Found 1 stateful pods, waiting for 3
Dec  3 15:45:49.829: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Dec  3 15:45:49.829: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Dec  3 15:45:49.829: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Dec  3 15:45:49.838: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmwqx-5aq.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-5559 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec  3 15:45:50.456: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Dec  3 15:45:50.457: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec  3 15:45:50.457: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec  3 15:45:50.457: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmwqx-5aq.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-5559 ss-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec  3 15:45:51.010: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Dec  3 15:45:51.010: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec  3 15:45:51.010: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec  3 15:45:51.010: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmwqx-5aq.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-5559 ss-2 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec  3 15:45:51.549: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Dec  3 15:45:51.549: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec  3 15:45:51.549: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec  3 15:45:51.549: INFO: Waiting for statefulset status.replicas updated to 0
Dec  3 15:45:51.554: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 1
Dec  3 15:46:01.565: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Dec  3 15:46:01.565: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Dec  3 15:46:01.565: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Dec  3 15:46:01.580: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999637s
Dec  3 15:46:02.586: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.994454257s
Dec  3 15:46:03.592: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.98815974s
Dec  3 15:46:04.598: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.981904565s
Dec  3 15:46:05.604: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.975960952s
Dec  3 15:46:06.610: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.970376066s
Dec  3 15:46:07.616: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.964135628s
Dec  3 15:46:08.622: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.958297614s
Dec  3 15:46:09.628: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.952231313s
Dec  3 15:46:10.634: INFO: Verifying statefulset ss doesn't scale past 3 for another 946.409411ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-5559
Dec  3 15:46:11.642: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmwqx-5aq.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-5559 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  3 15:46:12.199: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Dec  3 15:46:12.199: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec  3 15:46:12.199: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec  3 15:46:12.199: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmwqx-5aq.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-5559 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  3 15:46:12.711: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Dec  3 15:46:12.711: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec  3 15:46:12.711: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec  3 15:46:12.712: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmwqx-5aq.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-5559 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  3 15:46:13.336: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Dec  3 15:46:13.336: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec  3 15:46:13.336: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec  3 15:46:13.336: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Dec  3 15:46:33.357: INFO: Deleting all statefulset in ns statefulset-5559
Dec  3 15:46:33.361: INFO: Scaling statefulset ss to 0
Dec  3 15:46:33.375: INFO: Waiting for statefulset status.replicas updated to 0
Dec  3 15:46:33.379: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:46:33.393: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-5559" for this suite.
Dec  3 15:46:39.415: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:46:39.619: INFO: namespace statefulset-5559 deletion completed in 6.218810122s
â€¢SSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:46:39.620: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-3112
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test override all
Dec  3 15:46:39.771: INFO: Waiting up to 5m0s for pod "client-containers-88e0776c-75a8-4818-b09a-77c543e123ab" in namespace "containers-3112" to be "success or failure"
Dec  3 15:46:39.775: INFO: Pod "client-containers-88e0776c-75a8-4818-b09a-77c543e123ab": Phase="Pending", Reason="", readiness=false. Elapsed: 4.123832ms
Dec  3 15:46:41.780: INFO: Pod "client-containers-88e0776c-75a8-4818-b09a-77c543e123ab": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009464149s
STEP: Saw pod success
Dec  3 15:46:41.780: INFO: Pod "client-containers-88e0776c-75a8-4818-b09a-77c543e123ab" satisfied condition "success or failure"
Dec  3 15:46:41.785: INFO: Trying to get logs from node izgw8afzp8040eoqk0qbhxz pod client-containers-88e0776c-75a8-4818-b09a-77c543e123ab container test-container: <nil>
STEP: delete the pod
Dec  3 15:46:41.806: INFO: Waiting for pod client-containers-88e0776c-75a8-4818-b09a-77c543e123ab to disappear
Dec  3 15:46:41.810: INFO: Pod client-containers-88e0776c-75a8-4818-b09a-77c543e123ab no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:46:41.810: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-3112" for this suite.
Dec  3 15:46:47.832: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:46:47.998: INFO: namespace containers-3112 deletion completed in 6.181075328s
â€¢SSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:46:47.999: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-215
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1516
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Dec  3 15:46:48.146: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmwqx-5aq.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=kubectl-215'
Dec  3 15:46:48.297: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Dec  3 15:46:48.297: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: rolling-update to same image controller
Dec  3 15:46:48.307: INFO: scanned /root for discovery docs: <nil>
Dec  3 15:46:48.308: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmwqx-5aq.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config rolling-update e2e-test-nginx-rc --update-period=1s --image=docker.io/library/nginx:1.14-alpine --image-pull-policy=IfNotPresent --namespace=kubectl-215'
Dec  3 15:47:01.250: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Dec  3 15:47:01.250: INFO: stdout: "Created e2e-test-nginx-rc-06f1bb398fb3fab023692bb928ca9c10\nScaling up e2e-test-nginx-rc-06f1bb398fb3fab023692bb928ca9c10 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-06f1bb398fb3fab023692bb928ca9c10 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-06f1bb398fb3fab023692bb928ca9c10 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
Dec  3 15:47:01.250: INFO: stdout: "Created e2e-test-nginx-rc-06f1bb398fb3fab023692bb928ca9c10\nScaling up e2e-test-nginx-rc-06f1bb398fb3fab023692bb928ca9c10 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-06f1bb398fb3fab023692bb928ca9c10 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-06f1bb398fb3fab023692bb928ca9c10 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
Dec  3 15:47:01.250: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmwqx-5aq.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=kubectl-215'
Dec  3 15:47:01.386: INFO: stderr: ""
Dec  3 15:47:01.386: INFO: stdout: "e2e-test-nginx-rc-06f1bb398fb3fab023692bb928ca9c10-mwtvh "
Dec  3 15:47:01.386: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmwqx-5aq.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods e2e-test-nginx-rc-06f1bb398fb3fab023692bb928ca9c10-mwtvh -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-215'
Dec  3 15:47:01.517: INFO: stderr: ""
Dec  3 15:47:01.517: INFO: stdout: "true"
Dec  3 15:47:01.517: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmwqx-5aq.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods e2e-test-nginx-rc-06f1bb398fb3fab023692bb928ca9c10-mwtvh -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-215'
Dec  3 15:47:01.694: INFO: stderr: ""
Dec  3 15:47:01.694: INFO: stdout: "docker.io/library/nginx:1.14-alpine"
Dec  3 15:47:01.694: INFO: e2e-test-nginx-rc-06f1bb398fb3fab023692bb928ca9c10-mwtvh is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1522
Dec  3 15:47:01.695: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmwqx-5aq.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config delete rc e2e-test-nginx-rc --namespace=kubectl-215'
Dec  3 15:47:01.785: INFO: stderr: ""
Dec  3 15:47:01.785: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:47:01.785: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-215" for this suite.
Dec  3 15:47:07.807: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:47:08.010: INFO: namespace kubectl-215 deletion completed in 6.216793031s
â€¢SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:47:08.010: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-7909
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test substitution in container's args
Dec  3 15:47:08.164: INFO: Waiting up to 5m0s for pod "var-expansion-bdc470ba-8a1c-4c4b-bcfd-a98b84226f7e" in namespace "var-expansion-7909" to be "success or failure"
Dec  3 15:47:08.169: INFO: Pod "var-expansion-bdc470ba-8a1c-4c4b-bcfd-a98b84226f7e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.201797ms
Dec  3 15:47:10.174: INFO: Pod "var-expansion-bdc470ba-8a1c-4c4b-bcfd-a98b84226f7e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009809486s
STEP: Saw pod success
Dec  3 15:47:10.174: INFO: Pod "var-expansion-bdc470ba-8a1c-4c4b-bcfd-a98b84226f7e" satisfied condition "success or failure"
Dec  3 15:47:10.179: INFO: Trying to get logs from node izgw8afzp8040eoqk0qbhxz pod var-expansion-bdc470ba-8a1c-4c4b-bcfd-a98b84226f7e container dapi-container: <nil>
STEP: delete the pod
Dec  3 15:47:10.201: INFO: Waiting for pod var-expansion-bdc470ba-8a1c-4c4b-bcfd-a98b84226f7e to disappear
Dec  3 15:47:10.205: INFO: Pod var-expansion-bdc470ba-8a1c-4c4b-bcfd-a98b84226f7e no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:47:10.205: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-7909" for this suite.
Dec  3 15:47:16.226: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:47:16.438: INFO: namespace var-expansion-7909 deletion completed in 6.225611845s
â€¢SSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:47:16.439: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-791
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:63
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Dec  3 15:47:20.634: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec  3 15:47:20.638: INFO: Pod pod-with-prestop-http-hook still exists
Dec  3 15:47:22.639: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec  3 15:47:22.645: INFO: Pod pod-with-prestop-http-hook still exists
Dec  3 15:47:24.639: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec  3 15:47:24.644: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:47:24.658: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-791" for this suite.
Dec  3 15:47:46.682: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:47:46.893: INFO: namespace container-lifecycle-hook-791 deletion completed in 22.227278134s
â€¢SSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:47:46.894: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-6106
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:47:49.082: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-6106" for this suite.
Dec  3 15:48:27.105: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:48:27.268: INFO: namespace kubelet-test-6106 deletion completed in 38.178158838s
â€¢SSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:48:27.269: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-4196
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-map-c6dfd71a-5361-4e0f-84ae-53eeccdcadd4
STEP: Creating a pod to test consume secrets
Dec  3 15:48:27.428: INFO: Waiting up to 5m0s for pod "pod-secrets-7f333c74-2185-48f3-8f73-093e722083ee" in namespace "secrets-4196" to be "success or failure"
Dec  3 15:48:27.433: INFO: Pod "pod-secrets-7f333c74-2185-48f3-8f73-093e722083ee": Phase="Pending", Reason="", readiness=false. Elapsed: 4.127719ms
Dec  3 15:48:29.438: INFO: Pod "pod-secrets-7f333c74-2185-48f3-8f73-093e722083ee": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009713027s
STEP: Saw pod success
Dec  3 15:48:29.438: INFO: Pod "pod-secrets-7f333c74-2185-48f3-8f73-093e722083ee" satisfied condition "success or failure"
Dec  3 15:48:29.443: INFO: Trying to get logs from node izgw8afzp8040eoqk0qbhxz pod pod-secrets-7f333c74-2185-48f3-8f73-093e722083ee container secret-volume-test: <nil>
STEP: delete the pod
Dec  3 15:48:29.472: INFO: Waiting for pod pod-secrets-7f333c74-2185-48f3-8f73-093e722083ee to disappear
Dec  3 15:48:29.476: INFO: Pod pod-secrets-7f333c74-2185-48f3-8f73-093e722083ee no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:48:29.477: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-4196" for this suite.
Dec  3 15:48:35.499: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:48:35.667: INFO: namespace secrets-4196 deletion completed in 6.182504202s
â€¢SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:48:35.668: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-4506
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-1347fe4e-7452-4a7e-a4af-daf0b846e222
STEP: Creating a pod to test consume configMaps
Dec  3 15:48:35.826: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-d5a7b995-aad3-4ede-a3ed-1b5f209d5432" in namespace "projected-4506" to be "success or failure"
Dec  3 15:48:35.831: INFO: Pod "pod-projected-configmaps-d5a7b995-aad3-4ede-a3ed-1b5f209d5432": Phase="Pending", Reason="", readiness=false. Elapsed: 4.279431ms
Dec  3 15:48:37.837: INFO: Pod "pod-projected-configmaps-d5a7b995-aad3-4ede-a3ed-1b5f209d5432": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010149954s
STEP: Saw pod success
Dec  3 15:48:37.837: INFO: Pod "pod-projected-configmaps-d5a7b995-aad3-4ede-a3ed-1b5f209d5432" satisfied condition "success or failure"
Dec  3 15:48:37.841: INFO: Trying to get logs from node izgw8afzp8040eoqk0qbhxz pod pod-projected-configmaps-d5a7b995-aad3-4ede-a3ed-1b5f209d5432 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec  3 15:48:37.862: INFO: Waiting for pod pod-projected-configmaps-d5a7b995-aad3-4ede-a3ed-1b5f209d5432 to disappear
Dec  3 15:48:37.866: INFO: Pod pod-projected-configmaps-d5a7b995-aad3-4ede-a3ed-1b5f209d5432 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:48:37.866: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4506" for this suite.
Dec  3 15:48:43.890: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:48:44.059: INFO: namespace projected-4506 deletion completed in 6.185563719s
â€¢SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:48:44.060: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-3681
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1685
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Dec  3 15:48:44.206: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmwqx-5aq.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-3681'
Dec  3 15:48:44.319: INFO: stderr: ""
Dec  3 15:48:44.319: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1690
Dec  3 15:48:44.324: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmwqx-5aq.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config delete pods e2e-test-nginx-pod --namespace=kubectl-3681'
Dec  3 15:48:55.604: INFO: stderr: ""
Dec  3 15:48:55.604: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:48:55.604: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3681" for this suite.
Dec  3 15:49:01.627: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:49:01.803: INFO: namespace kubectl-3681 deletion completed in 6.190646278s
â€¢
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:49:01.803: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-5426
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Performing setup for networking test in namespace pod-network-test-5426
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Dec  3 15:49:01.952: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Dec  3 15:49:22.060: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.64.1.225:8080/dial?request=hostName&protocol=http&host=100.64.1.224&port=8080&tries=1'] Namespace:pod-network-test-5426 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  3 15:49:22.060: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec  3 15:49:22.503: INFO: Waiting for endpoints: map[]
Dec  3 15:49:22.507: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.64.1.225:8080/dial?request=hostName&protocol=http&host=100.64.0.71&port=8080&tries=1'] Namespace:pod-network-test-5426 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  3 15:49:22.507: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec  3 15:49:23.020: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:49:23.021: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-5426" for this suite.
Dec  3 15:49:45.044: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:49:45.214: INFO: namespace pod-network-test-5426 deletion completed in 22.184968611s
â€¢
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:49:45.214: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-735
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Dec  3 15:49:45.376: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-735,SelfLink:/api/v1/namespaces/watch-735/configmaps/e2e-watch-test-configmap-a,UID:1cbf1d33-accb-4c87-b4cc-37b210fbc79f,ResourceVersion:23106,Generation:0,CreationTimestamp:2019-12-03 15:49:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec  3 15:49:45.377: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-735,SelfLink:/api/v1/namespaces/watch-735/configmaps/e2e-watch-test-configmap-a,UID:1cbf1d33-accb-4c87-b4cc-37b210fbc79f,ResourceVersion:23106,Generation:0,CreationTimestamp:2019-12-03 15:49:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Dec  3 15:49:55.387: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-735,SelfLink:/api/v1/namespaces/watch-735/configmaps/e2e-watch-test-configmap-a,UID:1cbf1d33-accb-4c87-b4cc-37b210fbc79f,ResourceVersion:23138,Generation:0,CreationTimestamp:2019-12-03 15:49:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Dec  3 15:49:55.387: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-735,SelfLink:/api/v1/namespaces/watch-735/configmaps/e2e-watch-test-configmap-a,UID:1cbf1d33-accb-4c87-b4cc-37b210fbc79f,ResourceVersion:23138,Generation:0,CreationTimestamp:2019-12-03 15:49:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Dec  3 15:50:05.398: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-735,SelfLink:/api/v1/namespaces/watch-735/configmaps/e2e-watch-test-configmap-a,UID:1cbf1d33-accb-4c87-b4cc-37b210fbc79f,ResourceVersion:23170,Generation:0,CreationTimestamp:2019-12-03 15:49:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec  3 15:50:05.398: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-735,SelfLink:/api/v1/namespaces/watch-735/configmaps/e2e-watch-test-configmap-a,UID:1cbf1d33-accb-4c87-b4cc-37b210fbc79f,ResourceVersion:23170,Generation:0,CreationTimestamp:2019-12-03 15:49:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Dec  3 15:50:15.406: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-735,SelfLink:/api/v1/namespaces/watch-735/configmaps/e2e-watch-test-configmap-a,UID:1cbf1d33-accb-4c87-b4cc-37b210fbc79f,ResourceVersion:23202,Generation:0,CreationTimestamp:2019-12-03 15:49:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec  3 15:50:15.406: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-735,SelfLink:/api/v1/namespaces/watch-735/configmaps/e2e-watch-test-configmap-a,UID:1cbf1d33-accb-4c87-b4cc-37b210fbc79f,ResourceVersion:23202,Generation:0,CreationTimestamp:2019-12-03 15:49:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Dec  3 15:50:25.413: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-735,SelfLink:/api/v1/namespaces/watch-735/configmaps/e2e-watch-test-configmap-b,UID:76b0e687-6edb-4eff-8814-c32f099e4254,ResourceVersion:23234,Generation:0,CreationTimestamp:2019-12-03 15:50:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec  3 15:50:25.413: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-735,SelfLink:/api/v1/namespaces/watch-735/configmaps/e2e-watch-test-configmap-b,UID:76b0e687-6edb-4eff-8814-c32f099e4254,ResourceVersion:23234,Generation:0,CreationTimestamp:2019-12-03 15:50:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Dec  3 15:50:35.420: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-735,SelfLink:/api/v1/namespaces/watch-735/configmaps/e2e-watch-test-configmap-b,UID:76b0e687-6edb-4eff-8814-c32f099e4254,ResourceVersion:23265,Generation:0,CreationTimestamp:2019-12-03 15:50:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec  3 15:50:35.420: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-735,SelfLink:/api/v1/namespaces/watch-735/configmaps/e2e-watch-test-configmap-b,UID:76b0e687-6edb-4eff-8814-c32f099e4254,ResourceVersion:23265,Generation:0,CreationTimestamp:2019-12-03 15:50:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:50:45.421: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-735" for this suite.
Dec  3 15:50:51.450: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:50:51.629: INFO: namespace watch-735 deletion completed in 6.199768787s
â€¢SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:50:51.630: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-4009
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Dec  3 15:50:51.802: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Dec  3 15:50:51.815: INFO: Number of nodes with available pods: 0
Dec  3 15:50:51.815: INFO: Node izgw8afzp8040eoqk0qbhwz is running more than one daemon pod
Dec  3 15:50:52.829: INFO: Number of nodes with available pods: 0
Dec  3 15:50:52.829: INFO: Node izgw8afzp8040eoqk0qbhwz is running more than one daemon pod
Dec  3 15:50:53.829: INFO: Number of nodes with available pods: 2
Dec  3 15:50:53.829: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Dec  3 15:50:53.863: INFO: Wrong image for pod: daemon-set-f45dd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Dec  3 15:50:53.863: INFO: Wrong image for pod: daemon-set-pl7ng. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Dec  3 15:50:54.874: INFO: Wrong image for pod: daemon-set-f45dd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Dec  3 15:50:54.874: INFO: Wrong image for pod: daemon-set-pl7ng. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Dec  3 15:50:55.873: INFO: Wrong image for pod: daemon-set-f45dd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Dec  3 15:50:55.874: INFO: Wrong image for pod: daemon-set-pl7ng. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Dec  3 15:50:56.874: INFO: Wrong image for pod: daemon-set-f45dd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Dec  3 15:50:56.874: INFO: Wrong image for pod: daemon-set-pl7ng. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Dec  3 15:50:56.874: INFO: Pod daemon-set-pl7ng is not available
Dec  3 15:50:57.874: INFO: Pod daemon-set-dwlks is not available
Dec  3 15:50:57.874: INFO: Wrong image for pod: daemon-set-f45dd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Dec  3 15:50:58.874: INFO: Pod daemon-set-dwlks is not available
Dec  3 15:50:58.874: INFO: Wrong image for pod: daemon-set-f45dd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Dec  3 15:50:59.874: INFO: Pod daemon-set-dwlks is not available
Dec  3 15:50:59.874: INFO: Wrong image for pod: daemon-set-f45dd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Dec  3 15:51:00.874: INFO: Wrong image for pod: daemon-set-f45dd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Dec  3 15:51:01.874: INFO: Wrong image for pod: daemon-set-f45dd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Dec  3 15:51:01.874: INFO: Pod daemon-set-f45dd is not available
Dec  3 15:51:02.874: INFO: Wrong image for pod: daemon-set-f45dd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Dec  3 15:51:02.874: INFO: Pod daemon-set-f45dd is not available
Dec  3 15:51:03.874: INFO: Wrong image for pod: daemon-set-f45dd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Dec  3 15:51:03.874: INFO: Pod daemon-set-f45dd is not available
Dec  3 15:51:04.874: INFO: Wrong image for pod: daemon-set-f45dd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Dec  3 15:51:04.874: INFO: Pod daemon-set-f45dd is not available
Dec  3 15:51:05.874: INFO: Pod daemon-set-5vgnl is not available
STEP: Check that daemon pods are still running on every node of the cluster.
Dec  3 15:51:05.892: INFO: Number of nodes with available pods: 1
Dec  3 15:51:05.892: INFO: Node izgw8afzp8040eoqk0qbhxz is running more than one daemon pod
Dec  3 15:51:06.905: INFO: Number of nodes with available pods: 2
Dec  3 15:51:06.905: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-4009, will wait for the garbage collector to delete the pods
Dec  3 15:51:06.989: INFO: Deleting DaemonSet.extensions daemon-set took: 6.716882ms
Dec  3 15:51:07.490: INFO: Terminating DaemonSet.extensions daemon-set pods took: 500.38026ms
Dec  3 15:51:15.695: INFO: Number of nodes with available pods: 0
Dec  3 15:51:15.695: INFO: Number of running nodes: 0, number of available pods: 0
Dec  3 15:51:15.699: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-4009/daemonsets","resourceVersion":"23453"},"items":null}

Dec  3 15:51:15.703: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-4009/pods","resourceVersion":"23453"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:51:15.720: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-4009" for this suite.
Dec  3 15:51:21.739: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:51:21.902: INFO: namespace daemonsets-4009 deletion completed in 6.177720409s
â€¢SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:51:21.903: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-6503
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0666 on node default medium
Dec  3 15:51:22.056: INFO: Waiting up to 5m0s for pod "pod-aa0c074b-2719-4e9e-ad1e-7af636aeda2a" in namespace "emptydir-6503" to be "success or failure"
Dec  3 15:51:22.060: INFO: Pod "pod-aa0c074b-2719-4e9e-ad1e-7af636aeda2a": Phase="Pending", Reason="", readiness=false. Elapsed: 4.376649ms
Dec  3 15:51:24.066: INFO: Pod "pod-aa0c074b-2719-4e9e-ad1e-7af636aeda2a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0095029s
STEP: Saw pod success
Dec  3 15:51:24.066: INFO: Pod "pod-aa0c074b-2719-4e9e-ad1e-7af636aeda2a" satisfied condition "success or failure"
Dec  3 15:51:24.070: INFO: Trying to get logs from node izgw8afzp8040eoqk0qbhxz pod pod-aa0c074b-2719-4e9e-ad1e-7af636aeda2a container test-container: <nil>
STEP: delete the pod
Dec  3 15:51:24.092: INFO: Waiting for pod pod-aa0c074b-2719-4e9e-ad1e-7af636aeda2a to disappear
Dec  3 15:51:24.096: INFO: Pod pod-aa0c074b-2719-4e9e-ad1e-7af636aeda2a no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:51:24.096: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6503" for this suite.
Dec  3 15:51:30.118: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:51:30.324: INFO: namespace emptydir-6503 deletion completed in 6.220136098s
â€¢SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] version v1
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:51:30.325: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-9272
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-k2bjx in namespace proxy-9272
I1203 15:51:30.481841    5085 runners.go:180] Created replication controller with name: proxy-service-k2bjx, namespace: proxy-9272, replica count: 1
I1203 15:51:31.532354    5085 runners.go:180] proxy-service-k2bjx Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1203 15:51:32.532639    5085 runners.go:180] proxy-service-k2bjx Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1203 15:51:33.532861    5085 runners.go:180] proxy-service-k2bjx Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Dec  3 15:51:33.537: INFO: setup took 3.068753122s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Dec  3 15:51:33.557: INFO: (0) /api/v1/namespaces/proxy-9272/pods/http:proxy-service-k2bjx-jphmj:160/proxy/: foo (200; 19.504537ms)
Dec  3 15:51:33.562: INFO: (0) /api/v1/namespaces/proxy-9272/pods/proxy-service-k2bjx-jphmj:1080/proxy/: <a href="/api/v1/namespaces/proxy-9272/pods/proxy-service-k2bjx-jphmj:1080/proxy/rewriteme">test<... (200; 24.382058ms)
Dec  3 15:51:33.564: INFO: (0) /api/v1/namespaces/proxy-9272/services/http:proxy-service-k2bjx:portname1/proxy/: foo (200; 26.057839ms)
Dec  3 15:51:33.564: INFO: (0) /api/v1/namespaces/proxy-9272/services/proxy-service-k2bjx:portname1/proxy/: foo (200; 26.151979ms)
Dec  3 15:51:33.564: INFO: (0) /api/v1/namespaces/proxy-9272/pods/proxy-service-k2bjx-jphmj:160/proxy/: foo (200; 26.167682ms)
Dec  3 15:51:33.566: INFO: (0) /api/v1/namespaces/proxy-9272/services/proxy-service-k2bjx:portname2/proxy/: bar (200; 28.109548ms)
Dec  3 15:51:33.566: INFO: (0) /api/v1/namespaces/proxy-9272/services/http:proxy-service-k2bjx:portname2/proxy/: bar (200; 28.067928ms)
Dec  3 15:51:33.566: INFO: (0) /api/v1/namespaces/proxy-9272/pods/http:proxy-service-k2bjx-jphmj:1080/proxy/: <a href="/api/v1/namespaces/proxy-9272/pods/http:proxy-service-k2bjx-jphmj:1080/proxy/rewriteme">... (200; 28.204409ms)
Dec  3 15:51:33.566: INFO: (0) /api/v1/namespaces/proxy-9272/pods/proxy-service-k2bjx-jphmj:162/proxy/: bar (200; 28.18159ms)
Dec  3 15:51:33.566: INFO: (0) /api/v1/namespaces/proxy-9272/pods/proxy-service-k2bjx-jphmj/proxy/: <a href="/api/v1/namespaces/proxy-9272/pods/proxy-service-k2bjx-jphmj/proxy/rewriteme">test</a> (200; 28.33713ms)
Dec  3 15:51:33.566: INFO: (0) /api/v1/namespaces/proxy-9272/pods/http:proxy-service-k2bjx-jphmj:162/proxy/: bar (200; 28.362121ms)
Dec  3 15:51:33.570: INFO: (0) /api/v1/namespaces/proxy-9272/pods/https:proxy-service-k2bjx-jphmj:443/proxy/: <a href="/api/v1/namespaces/proxy-9272/pods/https:proxy-service-k2bjx-jphmj:443/proxy/tlsrewritem... (200; 32.857166ms)
Dec  3 15:51:33.572: INFO: (0) /api/v1/namespaces/proxy-9272/pods/https:proxy-service-k2bjx-jphmj:462/proxy/: tls qux (200; 34.769638ms)
Dec  3 15:51:33.575: INFO: (0) /api/v1/namespaces/proxy-9272/services/https:proxy-service-k2bjx:tlsportname1/proxy/: tls baz (200; 37.052608ms)
Dec  3 15:51:33.577: INFO: (0) /api/v1/namespaces/proxy-9272/services/https:proxy-service-k2bjx:tlsportname2/proxy/: tls qux (200; 39.31645ms)
Dec  3 15:51:33.582: INFO: (0) /api/v1/namespaces/proxy-9272/pods/https:proxy-service-k2bjx-jphmj:460/proxy/: tls baz (200; 44.096686ms)
Dec  3 15:51:33.590: INFO: (1) /api/v1/namespaces/proxy-9272/pods/proxy-service-k2bjx-jphmj:1080/proxy/: <a href="/api/v1/namespaces/proxy-9272/pods/proxy-service-k2bjx-jphmj:1080/proxy/rewriteme">test<... (200; 8.177595ms)
Dec  3 15:51:33.591: INFO: (1) /api/v1/namespaces/proxy-9272/pods/http:proxy-service-k2bjx-jphmj:160/proxy/: foo (200; 9.096211ms)
Dec  3 15:51:33.591: INFO: (1) /api/v1/namespaces/proxy-9272/pods/https:proxy-service-k2bjx-jphmj:460/proxy/: tls baz (200; 9.399051ms)
Dec  3 15:51:33.591: INFO: (1) /api/v1/namespaces/proxy-9272/pods/http:proxy-service-k2bjx-jphmj:1080/proxy/: <a href="/api/v1/namespaces/proxy-9272/pods/http:proxy-service-k2bjx-jphmj:1080/proxy/rewriteme">... (200; 9.32981ms)
Dec  3 15:51:33.591: INFO: (1) /api/v1/namespaces/proxy-9272/pods/proxy-service-k2bjx-jphmj/proxy/: <a href="/api/v1/namespaces/proxy-9272/pods/proxy-service-k2bjx-jphmj/proxy/rewriteme">test</a> (200; 9.338153ms)
Dec  3 15:51:33.591: INFO: (1) /api/v1/namespaces/proxy-9272/pods/https:proxy-service-k2bjx-jphmj:462/proxy/: tls qux (200; 9.274583ms)
Dec  3 15:51:33.591: INFO: (1) /api/v1/namespaces/proxy-9272/pods/proxy-service-k2bjx-jphmj:160/proxy/: foo (200; 9.337267ms)
Dec  3 15:51:33.591: INFO: (1) /api/v1/namespaces/proxy-9272/pods/http:proxy-service-k2bjx-jphmj:162/proxy/: bar (200; 9.48244ms)
Dec  3 15:51:33.593: INFO: (1) /api/v1/namespaces/proxy-9272/pods/https:proxy-service-k2bjx-jphmj:443/proxy/: <a href="/api/v1/namespaces/proxy-9272/pods/https:proxy-service-k2bjx-jphmj:443/proxy/tlsrewritem... (200; 11.524232ms)
Dec  3 15:51:33.593: INFO: (1) /api/v1/namespaces/proxy-9272/pods/proxy-service-k2bjx-jphmj:162/proxy/: bar (200; 11.399313ms)
Dec  3 15:51:33.593: INFO: (1) /api/v1/namespaces/proxy-9272/services/https:proxy-service-k2bjx:tlsportname2/proxy/: tls qux (200; 11.385868ms)
Dec  3 15:51:33.593: INFO: (1) /api/v1/namespaces/proxy-9272/services/https:proxy-service-k2bjx:tlsportname1/proxy/: tls baz (200; 11.360863ms)
Dec  3 15:51:33.595: INFO: (1) /api/v1/namespaces/proxy-9272/services/http:proxy-service-k2bjx:portname1/proxy/: foo (200; 13.639342ms)
Dec  3 15:51:33.595: INFO: (1) /api/v1/namespaces/proxy-9272/services/proxy-service-k2bjx:portname1/proxy/: foo (200; 13.611149ms)
Dec  3 15:51:33.598: INFO: (1) /api/v1/namespaces/proxy-9272/services/proxy-service-k2bjx:portname2/proxy/: bar (200; 15.7353ms)
Dec  3 15:51:33.600: INFO: (1) /api/v1/namespaces/proxy-9272/services/http:proxy-service-k2bjx:portname2/proxy/: bar (200; 18.113745ms)
Dec  3 15:51:33.609: INFO: (2) /api/v1/namespaces/proxy-9272/pods/https:proxy-service-k2bjx-jphmj:460/proxy/: tls baz (200; 9.22789ms)
Dec  3 15:51:33.609: INFO: (2) /api/v1/namespaces/proxy-9272/pods/proxy-service-k2bjx-jphmj:1080/proxy/: <a href="/api/v1/namespaces/proxy-9272/pods/proxy-service-k2bjx-jphmj:1080/proxy/rewriteme">test<... (200; 9.246888ms)
Dec  3 15:51:33.609: INFO: (2) /api/v1/namespaces/proxy-9272/services/https:proxy-service-k2bjx:tlsportname1/proxy/: tls baz (200; 9.281749ms)
Dec  3 15:51:33.609: INFO: (2) /api/v1/namespaces/proxy-9272/services/proxy-service-k2bjx:portname2/proxy/: bar (200; 9.292776ms)
Dec  3 15:51:33.609: INFO: (2) /api/v1/namespaces/proxy-9272/services/proxy-service-k2bjx:portname1/proxy/: foo (200; 9.377659ms)
Dec  3 15:51:33.609: INFO: (2) /api/v1/namespaces/proxy-9272/services/http:proxy-service-k2bjx:portname1/proxy/: foo (200; 9.323952ms)
Dec  3 15:51:33.612: INFO: (2) /api/v1/namespaces/proxy-9272/pods/https:proxy-service-k2bjx-jphmj:462/proxy/: tls qux (200; 11.290048ms)
Dec  3 15:51:33.612: INFO: (2) /api/v1/namespaces/proxy-9272/pods/http:proxy-service-k2bjx-jphmj:1080/proxy/: <a href="/api/v1/namespaces/proxy-9272/pods/http:proxy-service-k2bjx-jphmj:1080/proxy/rewriteme">... (200; 11.276075ms)
Dec  3 15:51:33.612: INFO: (2) /api/v1/namespaces/proxy-9272/pods/proxy-service-k2bjx-jphmj/proxy/: <a href="/api/v1/namespaces/proxy-9272/pods/proxy-service-k2bjx-jphmj/proxy/rewriteme">test</a> (200; 11.328048ms)
Dec  3 15:51:33.612: INFO: (2) /api/v1/namespaces/proxy-9272/pods/https:proxy-service-k2bjx-jphmj:443/proxy/: <a href="/api/v1/namespaces/proxy-9272/pods/https:proxy-service-k2bjx-jphmj:443/proxy/tlsrewritem... (200; 11.501692ms)
Dec  3 15:51:33.612: INFO: (2) /api/v1/namespaces/proxy-9272/pods/http:proxy-service-k2bjx-jphmj:162/proxy/: bar (200; 11.311876ms)
Dec  3 15:51:33.612: INFO: (2) /api/v1/namespaces/proxy-9272/services/https:proxy-service-k2bjx:tlsportname2/proxy/: tls qux (200; 11.391025ms)
Dec  3 15:51:33.616: INFO: (2) /api/v1/namespaces/proxy-9272/services/http:proxy-service-k2bjx:portname2/proxy/: bar (200; 15.51781ms)
Dec  3 15:51:33.616: INFO: (2) /api/v1/namespaces/proxy-9272/pods/proxy-service-k2bjx-jphmj:160/proxy/: foo (200; 15.693021ms)
Dec  3 15:51:33.616: INFO: (2) /api/v1/namespaces/proxy-9272/pods/http:proxy-service-k2bjx-jphmj:160/proxy/: foo (200; 15.624289ms)
Dec  3 15:51:33.618: INFO: (2) /api/v1/namespaces/proxy-9272/pods/proxy-service-k2bjx-jphmj:162/proxy/: bar (200; 17.893215ms)
Dec  3 15:51:33.627: INFO: (3) /api/v1/namespaces/proxy-9272/pods/http:proxy-service-k2bjx-jphmj:1080/proxy/: <a href="/api/v1/namespaces/proxy-9272/pods/http:proxy-service-k2bjx-jphmj:1080/proxy/rewriteme">... (200; 8.685342ms)
Dec  3 15:51:33.627: INFO: (3) /api/v1/namespaces/proxy-9272/pods/http:proxy-service-k2bjx-jphmj:162/proxy/: bar (200; 8.729871ms)
Dec  3 15:51:33.627: INFO: (3) /api/v1/namespaces/proxy-9272/pods/http:proxy-service-k2bjx-jphmj:160/proxy/: foo (200; 8.954585ms)
Dec  3 15:51:33.627: INFO: (3) /api/v1/namespaces/proxy-9272/pods/https:proxy-service-k2bjx-jphmj:462/proxy/: tls qux (200; 8.805059ms)
Dec  3 15:51:33.627: INFO: (3) /api/v1/namespaces/proxy-9272/pods/proxy-service-k2bjx-jphmj:160/proxy/: foo (200; 9.098692ms)
Dec  3 15:51:33.629: INFO: (3) /api/v1/namespaces/proxy-9272/pods/https:proxy-service-k2bjx-jphmj:443/proxy/: <a href="/api/v1/namespaces/proxy-9272/pods/https:proxy-service-k2bjx-jphmj:443/proxy/tlsrewritem... (200; 10.637718ms)
Dec  3 15:51:33.629: INFO: (3) /api/v1/namespaces/proxy-9272/pods/proxy-service-k2bjx-jphmj:162/proxy/: bar (200; 10.766777ms)
Dec  3 15:51:33.629: INFO: (3) /api/v1/namespaces/proxy-9272/pods/proxy-service-k2bjx-jphmj/proxy/: <a href="/api/v1/namespaces/proxy-9272/pods/proxy-service-k2bjx-jphmj/proxy/rewriteme">test</a> (200; 10.856176ms)
Dec  3 15:51:33.630: INFO: (3) /api/v1/namespaces/proxy-9272/pods/proxy-service-k2bjx-jphmj:1080/proxy/: <a href="/api/v1/namespaces/proxy-9272/pods/proxy-service-k2bjx-jphmj:1080/proxy/rewriteme">test<... (200; 11.398533ms)
Dec  3 15:51:33.630: INFO: (3) /api/v1/namespaces/proxy-9272/pods/https:proxy-service-k2bjx-jphmj:460/proxy/: tls baz (200; 11.626188ms)
Dec  3 15:51:33.630: INFO: (3) /api/v1/namespaces/proxy-9272/services/https:proxy-service-k2bjx:tlsportname1/proxy/: tls baz (200; 11.727762ms)
Dec  3 15:51:33.630: INFO: (3) /api/v1/namespaces/proxy-9272/services/proxy-service-k2bjx:portname1/proxy/: foo (200; 11.624379ms)
Dec  3 15:51:33.630: INFO: (3) /api/v1/namespaces/proxy-9272/services/http:proxy-service-k2bjx:portname1/proxy/: foo (200; 11.896388ms)
Dec  3 15:51:33.631: INFO: (3) /api/v1/namespaces/proxy-9272/services/https:proxy-service-k2bjx:tlsportname2/proxy/: tls qux (200; 13.056248ms)
Dec  3 15:51:33.634: INFO: (3) /api/v1/namespaces/proxy-9272/services/http:proxy-service-k2bjx:portname2/proxy/: bar (200; 15.287465ms)
Dec  3 15:51:33.636: INFO: (3) /api/v1/namespaces/proxy-9272/services/proxy-service-k2bjx:portname2/proxy/: bar (200; 17.423712ms)
Dec  3 15:51:33.645: INFO: (4) /api/v1/namespaces/proxy-9272/pods/https:proxy-service-k2bjx-jphmj:443/proxy/: <a href="/api/v1/namespaces/proxy-9272/pods/https:proxy-service-k2bjx-jphmj:443/proxy/tlsrewritem... (200; 9.316838ms)
Dec  3 15:51:33.645: INFO: (4) /api/v1/namespaces/proxy-9272/pods/http:proxy-service-k2bjx-jphmj:162/proxy/: bar (200; 9.551538ms)
Dec  3 15:51:33.645: INFO: (4) /api/v1/namespaces/proxy-9272/pods/proxy-service-k2bjx-jphmj:162/proxy/: bar (200; 9.303886ms)
Dec  3 15:51:33.645: INFO: (4) /api/v1/namespaces/proxy-9272/pods/proxy-service-k2bjx-jphmj:1080/proxy/: <a href="/api/v1/namespaces/proxy-9272/pods/proxy-service-k2bjx-jphmj:1080/proxy/rewriteme">test<... (200; 9.252771ms)
Dec  3 15:51:33.645: INFO: (4) /api/v1/namespaces/proxy-9272/pods/proxy-service-k2bjx-jphmj:160/proxy/: foo (200; 9.347793ms)
Dec  3 15:51:33.645: INFO: (4) /api/v1/namespaces/proxy-9272/pods/proxy-service-k2bjx-jphmj/proxy/: <a href="/api/v1/namespaces/proxy-9272/pods/proxy-service-k2bjx-jphmj/proxy/rewriteme">test</a> (200; 9.375783ms)
Dec  3 15:51:33.646: INFO: (4) /api/v1/namespaces/proxy-9272/pods/https:proxy-service-k2bjx-jphmj:462/proxy/: tls qux (200; 10.628611ms)
Dec  3 15:51:33.646: INFO: (4) /api/v1/namespaces/proxy-9272/pods/http:proxy-service-k2bjx-jphmj:160/proxy/: foo (200; 10.494237ms)
Dec  3 15:51:33.647: INFO: (4) /api/v1/namespaces/proxy-9272/services/https:proxy-service-k2bjx:tlsportname1/proxy/: tls baz (200; 10.544539ms)
Dec  3 15:51:33.647: INFO: (4) /api/v1/namespaces/proxy-9272/pods/https:proxy-service-k2bjx-jphmj:460/proxy/: tls baz (200; 10.520086ms)
Dec  3 15:51:33.647: INFO: (4) /api/v1/namespaces/proxy-9272/services/https:proxy-service-k2bjx:tlsportname2/proxy/: tls qux (200; 10.361791ms)
Dec  3 15:51:33.647: INFO: (4) /api/v1/namespaces/proxy-9272/pods/http:proxy-service-k2bjx-jphmj:1080/proxy/: <a href="/api/v1/namespaces/proxy-9272/pods/http:proxy-service-k2bjx-jphmj:1080/proxy/rewriteme">... (200; 10.651241ms)
Dec  3 15:51:33.651: INFO: (4) /api/v1/namespaces/proxy-9272/services/proxy-service-k2bjx:portname2/proxy/: bar (200; 14.788048ms)
Dec  3 15:51:33.651: INFO: (4) /api/v1/namespaces/proxy-9272/services/proxy-service-k2bjx:portname1/proxy/: foo (200; 14.88799ms)
Dec  3 15:51:33.651: INFO: (4) /api/v1/namespaces/proxy-9272/services/http:proxy-service-k2bjx:portname2/proxy/: bar (200; 14.842248ms)
Dec  3 15:51:33.653: INFO: (4) /api/v1/namespaces/proxy-9272/services/http:proxy-service-k2bjx:portname1/proxy/: foo (200; 17.051874ms)
Dec  3 15:51:33.662: INFO: (5) /api/v1/namespaces/proxy-9272/pods/proxy-service-k2bjx-jphmj:160/proxy/: foo (200; 8.925707ms)
Dec  3 15:51:33.662: INFO: (5) /api/v1/namespaces/proxy-9272/pods/proxy-service-k2bjx-jphmj:162/proxy/: bar (200; 8.887038ms)
Dec  3 15:51:33.662: INFO: (5) /api/v1/namespaces/proxy-9272/pods/https:proxy-service-k2bjx-jphmj:460/proxy/: tls baz (200; 8.885817ms)
Dec  3 15:51:33.662: INFO: (5) /api/v1/namespaces/proxy-9272/pods/https:proxy-service-k2bjx-jphmj:462/proxy/: tls qux (200; 8.841623ms)
Dec  3 15:51:33.662: INFO: (5) /api/v1/namespaces/proxy-9272/pods/proxy-service-k2bjx-jphmj:1080/proxy/: <a href="/api/v1/namespaces/proxy-9272/pods/proxy-service-k2bjx-jphmj:1080/proxy/rewriteme">test<... (200; 8.997536ms)
Dec  3 15:51:33.662: INFO: (5) /api/v1/namespaces/proxy-9272/pods/proxy-service-k2bjx-jphmj/proxy/: <a href="/api/v1/namespaces/proxy-9272/pods/proxy-service-k2bjx-jphmj/proxy/rewriteme">test</a> (200; 8.920297ms)
Dec  3 15:51:33.662: INFO: (5) /api/v1/namespaces/proxy-9272/pods/https:proxy-service-k2bjx-jphmj:443/proxy/: <a href="/api/v1/namespaces/proxy-9272/pods/https:proxy-service-k2bjx-jphmj:443/proxy/tlsrewritem... (200; 9.118981ms)
Dec  3 15:51:33.664: INFO: (5) /api/v1/namespaces/proxy-9272/pods/http:proxy-service-k2bjx-jphmj:160/proxy/: foo (200; 11.046444ms)
Dec  3 15:51:33.664: INFO: (5) /api/v1/namespaces/proxy-9272/pods/http:proxy-service-k2bjx-jphmj:162/proxy/: bar (200; 11.054752ms)
Dec  3 15:51:33.664: INFO: (5) /api/v1/namespaces/proxy-9272/pods/http:proxy-service-k2bjx-jphmj:1080/proxy/: <a href="/api/v1/namespaces/proxy-9272/pods/http:proxy-service-k2bjx-jphmj:1080/proxy/rewriteme">... (200; 11.047628ms)
Dec  3 15:51:33.667: INFO: (5) /api/v1/namespaces/proxy-9272/services/https:proxy-service-k2bjx:tlsportname2/proxy/: tls qux (200; 13.252954ms)
Dec  3 15:51:33.667: INFO: (5) /api/v1/namespaces/proxy-9272/services/https:proxy-service-k2bjx:tlsportname1/proxy/: tls baz (200; 13.35503ms)
Dec  3 15:51:33.669: INFO: (5) /api/v1/namespaces/proxy-9272/services/http:proxy-service-k2bjx:portname1/proxy/: foo (200; 15.201785ms)
Dec  3 15:51:33.669: INFO: (5) /api/v1/namespaces/proxy-9272/services/proxy-service-k2bjx:portname2/proxy/: bar (200; 15.267314ms)
Dec  3 15:51:33.671: INFO: (5) /api/v1/namespaces/proxy-9272/services/proxy-service-k2bjx:portname1/proxy/: foo (200; 17.518119ms)
Dec  3 15:51:33.671: INFO: (5) /api/v1/namespaces/proxy-9272/services/http:proxy-service-k2bjx:portname2/proxy/: bar (200; 17.633948ms)
Dec  3 15:51:33.681: INFO: (6) /api/v1/namespaces/proxy-9272/pods/proxy-service-k2bjx-jphmj:1080/proxy/: <a href="/api/v1/namespaces/proxy-9272/pods/proxy-service-k2bjx-jphmj:1080/proxy/rewriteme">test<... (200; 9.67671ms)
Dec  3 15:51:33.681: INFO: (6) /api/v1/namespaces/proxy-9272/pods/http:proxy-service-k2bjx-jphmj:160/proxy/: foo (200; 9.721211ms)
Dec  3 15:51:33.681: INFO: (6) /api/v1/namespaces/proxy-9272/pods/proxy-service-k2bjx-jphmj:162/proxy/: bar (200; 9.549902ms)
Dec  3 15:51:33.681: INFO: (6) /api/v1/namespaces/proxy-9272/services/https:proxy-service-k2bjx:tlsportname1/proxy/: tls baz (200; 9.793716ms)
Dec  3 15:51:33.681: INFO: (6) /api/v1/namespaces/proxy-9272/pods/http:proxy-service-k2bjx-jphmj:1080/proxy/: <a href="/api/v1/namespaces/proxy-9272/pods/http:proxy-service-k2bjx-jphmj:1080/proxy/rewriteme">... (200; 9.56485ms)
Dec  3 15:51:33.681: INFO: (6) /api/v1/namespaces/proxy-9272/pods/https:proxy-service-k2bjx-jphmj:462/proxy/: tls qux (200; 9.635193ms)
Dec  3 15:51:33.681: INFO: (6) /api/v1/namespaces/proxy-9272/pods/https:proxy-service-k2bjx-jphmj:460/proxy/: tls baz (200; 9.620375ms)
Dec  3 15:51:33.681: INFO: (6) /api/v1/namespaces/proxy-9272/pods/http:proxy-service-k2bjx-jphmj:162/proxy/: bar (200; 9.657379ms)
Dec  3 15:51:33.681: INFO: (6) /api/v1/namespaces/proxy-9272/pods/proxy-service-k2bjx-jphmj:160/proxy/: foo (200; 9.744159ms)
Dec  3 15:51:33.681: INFO: (6) /api/v1/namespaces/proxy-9272/pods/https:proxy-service-k2bjx-jphmj:443/proxy/: <a href="/api/v1/namespaces/proxy-9272/pods/https:proxy-service-k2bjx-jphmj:443/proxy/tlsrewritem... (200; 9.868542ms)
Dec  3 15:51:33.681: INFO: (6) /api/v1/namespaces/proxy-9272/pods/proxy-service-k2bjx-jphmj/proxy/: <a href="/api/v1/namespaces/proxy-9272/pods/proxy-service-k2bjx-jphmj/proxy/rewriteme">test</a> (200; 9.655376ms)
Dec  3 15:51:33.682: INFO: (6) /api/v1/namespaces/proxy-9272/services/https:proxy-service-k2bjx:tlsportname2/proxy/: tls qux (200; 10.617634ms)
Dec  3 15:51:33.684: INFO: (6) /api/v1/namespaces/proxy-9272/services/proxy-service-k2bjx:portname1/proxy/: foo (200; 13.096066ms)
Dec  3 15:51:33.684: INFO: (6) /api/v1/namespaces/proxy-9272/services/proxy-service-k2bjx:portname2/proxy/: bar (200; 13.105096ms)
Dec  3 15:51:33.687: INFO: (6) /api/v1/namespaces/proxy-9272/services/http:proxy-service-k2bjx:portname1/proxy/: foo (200; 15.326776ms)
Dec  3 15:51:33.687: INFO: (6) /api/v1/namespaces/proxy-9272/services/http:proxy-service-k2bjx:portname2/proxy/: bar (200; 15.309075ms)
Dec  3 15:51:33.696: INFO: (7) /api/v1/namespaces/proxy-9272/pods/https:proxy-service-k2bjx-jphmj:443/proxy/: <a href="/api/v1/namespaces/proxy-9272/pods/https:proxy-service-k2bjx-jphmj:443/proxy/tlsrewritem... (200; 8.913705ms)
Dec  3 15:51:33.696: INFO: (7) /api/v1/namespaces/proxy-9272/pods/proxy-service-k2bjx-jphmj:162/proxy/: bar (200; 9.038207ms)
Dec  3 15:51:33.696: INFO: (7) /api/v1/namespaces/proxy-9272/pods/http:proxy-service-k2bjx-jphmj:162/proxy/: bar (200; 9.058746ms)
Dec  3 15:51:33.696: INFO: (7) /api/v1/namespaces/proxy-9272/pods/proxy-service-k2bjx-jphmj/proxy/: <a href="/api/v1/namespaces/proxy-9272/pods/proxy-service-k2bjx-jphmj/proxy/rewriteme">test</a> (200; 9.095188ms)
Dec  3 15:51:33.696: INFO: (7) /api/v1/namespaces/proxy-9272/pods/http:proxy-service-k2bjx-jphmj:1080/proxy/: <a href="/api/v1/namespaces/proxy-9272/pods/http:proxy-service-k2bjx-jphmj:1080/proxy/rewriteme">... (200; 9.048292ms)
Dec  3 15:51:33.696: INFO: (7) /api/v1/namespaces/proxy-9272/pods/proxy-service-k2bjx-jphmj:1080/proxy/: <a href="/api/v1/namespaces/proxy-9272/pods/proxy-service-k2bjx-jphmj:1080/proxy/rewriteme">test<... (200; 9.000351ms)
Dec  3 15:51:33.698: INFO: (7) /api/v1/namespaces/proxy-9272/pods/proxy-service-k2bjx-jphmj:160/proxy/: foo (200; 11.014004ms)
Dec  3 15:51:33.698: INFO: (7) /api/v1/namespaces/proxy-9272/pods/https:proxy-service-k2bjx-jphmj:462/proxy/: tls qux (200; 11.184425ms)
Dec  3 15:51:33.698: INFO: (7) /api/v1/namespaces/proxy-9272/pods/https:proxy-service-k2bjx-jphmj:460/proxy/: tls baz (200; 11.092344ms)
Dec  3 15:51:33.698: INFO: (7) /api/v1/namespaces/proxy-9272/services/proxy-service-k2bjx:portname1/proxy/: foo (200; 11.211964ms)
Dec  3 15:51:33.700: INFO: (7) /api/v1/namespaces/proxy-9272/services/https:proxy-service-k2bjx:tlsportname1/proxy/: tls baz (200; 13.250557ms)
Dec  3 15:51:33.700: INFO: (7) /api/v1/namespaces/proxy-9272/services/https:proxy-service-k2bjx:tlsportname2/proxy/: tls qux (200; 13.281151ms)
Dec  3 15:51:33.702: INFO: (7) /api/v1/namespaces/proxy-9272/services/proxy-service-k2bjx:portname2/proxy/: bar (200; 15.365539ms)
Dec  3 15:51:33.702: INFO: (7) /api/v1/namespaces/proxy-9272/services/http:proxy-service-k2bjx:portname2/proxy/: bar (200; 15.341495ms)
Dec  3 15:51:33.704: INFO: (7) /api/v1/namespaces/proxy-9272/services/http:proxy-service-k2bjx:portname1/proxy/: foo (200; 17.521335ms)
Dec  3 15:51:33.704: INFO: (7) /api/v1/namespaces/proxy-9272/pods/http:proxy-service-k2bjx-jphmj:160/proxy/: foo (200; 17.513544ms)
Dec  3 15:51:33.713: INFO: (8) /api/v1/namespaces/proxy-9272/pods/http:proxy-service-k2bjx-jphmj:160/proxy/: foo (200; 8.281499ms)
Dec  3 15:51:33.713: INFO: (8) /api/v1/namespaces/proxy-9272/pods/https:proxy-service-k2bjx-jphmj:443/proxy/: <a href="/api/v1/namespaces/proxy-9272/pods/https:proxy-service-k2bjx-jphmj:443/proxy/tlsrewritem... (200; 8.210582ms)
Dec  3 15:51:33.713: INFO: (8) /api/v1/namespaces/proxy-9272/pods/proxy-service-k2bjx-jphmj:160/proxy/: foo (200; 8.850409ms)
Dec  3 15:51:33.713: INFO: (8) /api/v1/namespaces/proxy-9272/pods/proxy-service-k2bjx-jphmj:1080/proxy/: <a href="/api/v1/namespaces/proxy-9272/pods/proxy-service-k2bjx-jphmj:1080/proxy/rewriteme">test<... (200; 8.296343ms)
Dec  3 15:51:33.713: INFO: (8) /api/v1/namespaces/proxy-9272/pods/proxy-service-k2bjx-jphmj:162/proxy/: bar (200; 8.41172ms)
Dec  3 15:51:33.713: INFO: (8) /api/v1/namespaces/proxy-9272/pods/proxy-service-k2bjx-jphmj/proxy/: <a href="/api/v1/namespaces/proxy-9272/pods/proxy-service-k2bjx-jphmj/proxy/rewriteme">test</a> (200; 8.707291ms)
Dec  3 15:51:33.716: INFO: (8) /api/v1/namespaces/proxy-9272/pods/https:proxy-service-k2bjx-jphmj:460/proxy/: tls baz (200; 11.097446ms)
Dec  3 15:51:33.716: INFO: (8) /api/v1/namespaces/proxy-9272/pods/http:proxy-service-k2bjx-jphmj:162/proxy/: bar (200; 11.217415ms)
Dec  3 15:51:33.716: INFO: (8) /api/v1/namespaces/proxy-9272/pods/http:proxy-service-k2bjx-jphmj:1080/proxy/: <a href="/api/v1/namespaces/proxy-9272/pods/http:proxy-service-k2bjx-jphmj:1080/proxy/rewriteme">... (200; 10.90064ms)
Dec  3 15:51:33.716: INFO: (8) /api/v1/namespaces/proxy-9272/pods/https:proxy-service-k2bjx-jphmj:462/proxy/: tls qux (200; 11.089993ms)
Dec  3 15:51:33.718: INFO: (8) /api/v1/namespaces/proxy-9272/services/http:proxy-service-k2bjx:portname1/proxy/: foo (200; 13.36497ms)
Dec  3 15:51:33.718: INFO: (8) /api/v1/namespaces/proxy-9272/services/https:proxy-service-k2bjx:tlsportname2/proxy/: tls qux (200; 13.490278ms)
Dec  3 15:51:33.718: INFO: (8) /api/v1/namespaces/proxy-9272/services/https:proxy-service-k2bjx:tlsportname1/proxy/: tls baz (200; 13.260309ms)
Dec  3 15:51:33.718: INFO: (8) /api/v1/namespaces/proxy-9272/services/proxy-service-k2bjx:portname1/proxy/: foo (200; 13.395703ms)
Dec  3 15:51:33.718: INFO: (8) /api/v1/namespaces/proxy-9272/services/http:proxy-service-k2bjx:portname2/proxy/: bar (200; 13.346067ms)
Dec  3 15:51:33.720: INFO: (8) /api/v1/namespaces/proxy-9272/services/proxy-service-k2bjx:portname2/proxy/: bar (200; 15.636297ms)
Dec  3 15:51:33.730: INFO: (9) /api/v1/namespaces/proxy-9272/pods/proxy-service-k2bjx-jphmj:160/proxy/: foo (200; 9.158228ms)
Dec  3 15:51:33.730: INFO: (9) /api/v1/namespaces/proxy-9272/pods/https:proxy-service-k2bjx-jphmj:462/proxy/: tls qux (200; 8.934496ms)
Dec  3 15:51:33.730: INFO: (9) /api/v1/namespaces/proxy-9272/pods/http:proxy-service-k2bjx-jphmj:162/proxy/: bar (200; 8.652007ms)
Dec  3 15:51:33.730: INFO: (9) /api/v1/namespaces/proxy-9272/pods/http:proxy-service-k2bjx-jphmj:160/proxy/: foo (200; 8.785731ms)
Dec  3 15:51:33.730: INFO: (9) /api/v1/namespaces/proxy-9272/pods/http:proxy-service-k2bjx-jphmj:1080/proxy/: <a href="/api/v1/namespaces/proxy-9272/pods/http:proxy-service-k2bjx-jphmj:1080/proxy/rewriteme">... (200; 8.414278ms)
Dec  3 15:51:33.732: INFO: (9) /api/v1/namespaces/proxy-9272/pods/https:proxy-service-k2bjx-jphmj:460/proxy/: tls baz (200; 10.74874ms)
Dec  3 15:51:33.732: INFO: (9) /api/v1/namespaces/proxy-9272/pods/proxy-service-k2bjx-jphmj/proxy/: <a href="/api/v1/namespaces/proxy-9272/pods/proxy-service-k2bjx-jphmj/proxy/rewriteme">test</a> (200; 10.476569ms)
Dec  3 15:51:33.732: INFO: (9) /api/v1/namespaces/proxy-9272/pods/proxy-service-k2bjx-jphmj:1080/proxy/: <a href="/api/v1/namespaces/proxy-9272/pods/proxy-service-k2bjx-jphmj:1080/proxy/rewriteme">test<... (200; 10.441028ms)
Dec  3 15:51:33.732: INFO: (9) /api/v1/namespaces/proxy-9272/pods/proxy-service-k2bjx-jphmj:162/proxy/: bar (200; 10.719879ms)
Dec  3 15:51:33.732: INFO: (9) /api/v1/namespaces/proxy-9272/pods/https:proxy-service-k2bjx-jphmj:443/proxy/: <a href="/api/v1/namespaces/proxy-9272/pods/https:proxy-service-k2bjx-jphmj:443/proxy/tlsrewritem... (200; 10.660782ms)
Dec  3 15:51:33.734: INFO: (9) /api/v1/namespaces/proxy-9272/services/http:proxy-service-k2bjx:portname1/proxy/: foo (200; 13.491903ms)
Dec  3 15:51:33.734: INFO: (9) /api/v1/namespaces/proxy-9272/services/https:proxy-service-k2bjx:tlsportname1/proxy/: tls baz (200; 13.319875ms)
Dec  3 15:51:33.734: INFO: (9) /api/v1/namespaces/proxy-9272/services/https:proxy-service-k2bjx:tlsportname2/proxy/: tls qux (200; 12.71221ms)
Dec  3 15:51:33.734: INFO: (9) /api/v1/namespaces/proxy-9272/services/http:proxy-service-k2bjx:portname2/proxy/: bar (200; 13.397655ms)
Dec  3 15:51:33.736: INFO: (9) /api/v1/namespaces/proxy-9272/services/proxy-service-k2bjx:portname1/proxy/: foo (200; 15.020961ms)
Dec  3 15:51:33.738: INFO: (9) /api/v1/namespaces/proxy-9272/services/proxy-service-k2bjx:portname2/proxy/: bar (200; 17.033007ms)
Dec  3 15:51:33.747: INFO: (10) /api/v1/namespaces/proxy-9272/pods/https:proxy-service-k2bjx-jphmj:443/proxy/: <a href="/api/v1/namespaces/proxy-9272/pods/https:proxy-service-k2bjx-jphmj:443/proxy/tlsrewritem... (200; 8.85536ms)
Dec  3 15:51:33.747: INFO: (10) /api/v1/namespaces/proxy-9272/pods/https:proxy-service-k2bjx-jphmj:462/proxy/: tls qux (200; 8.990829ms)
Dec  3 15:51:33.747: INFO: (10) /api/v1/namespaces/proxy-9272/pods/proxy-service-k2bjx-jphmj:1080/proxy/: <a href="/api/v1/namespaces/proxy-9272/pods/proxy-service-k2bjx-jphmj:1080/proxy/rewriteme">test<... (200; 8.905417ms)
Dec  3 15:51:33.747: INFO: (10) /api/v1/namespaces/proxy-9272/pods/proxy-service-k2bjx-jphmj/proxy/: <a href="/api/v1/namespaces/proxy-9272/pods/proxy-service-k2bjx-jphmj/proxy/rewriteme">test</a> (200; 8.920274ms)
Dec  3 15:51:33.747: INFO: (10) /api/v1/namespaces/proxy-9272/pods/proxy-service-k2bjx-jphmj:160/proxy/: foo (200; 8.939673ms)
Dec  3 15:51:33.747: INFO: (10) /api/v1/namespaces/proxy-9272/pods/proxy-service-k2bjx-jphmj:162/proxy/: bar (200; 8.899146ms)
Dec  3 15:51:33.749: INFO: (10) /api/v1/namespaces/proxy-9272/pods/http:proxy-service-k2bjx-jphmj:160/proxy/: foo (200; 10.831323ms)
Dec  3 15:51:33.749: INFO: (10) /api/v1/namespaces/proxy-9272/pods/http:proxy-service-k2bjx-jphmj:1080/proxy/: <a href="/api/v1/namespaces/proxy-9272/pods/http:proxy-service-k2bjx-jphmj:1080/proxy/rewriteme">... (200; 10.946318ms)
Dec  3 15:51:33.749: INFO: (10) /api/v1/namespaces/proxy-9272/pods/https:proxy-service-k2bjx-jphmj:460/proxy/: tls baz (200; 10.82342ms)
Dec  3 15:51:33.749: INFO: (10) /api/v1/namespaces/proxy-9272/pods/http:proxy-service-k2bjx-jphmj:162/proxy/: bar (200; 10.871841ms)
Dec  3 15:51:33.752: INFO: (10) /api/v1/namespaces/proxy-9272/services/https:proxy-service-k2bjx:tlsportname1/proxy/: tls baz (200; 13.196237ms)
Dec  3 15:51:33.752: INFO: (10) /api/v1/namespaces/proxy-9272/services/https:proxy-service-k2bjx:tlsportname2/proxy/: tls qux (200; 13.203736ms)
Dec  3 15:51:33.754: INFO: (10) /api/v1/namespaces/proxy-9272/services/proxy-service-k2bjx:portname2/proxy/: bar (200; 15.199353ms)
Dec  3 15:51:33.754: INFO: (10) /api/v1/namespaces/proxy-9272/services/http:proxy-service-k2bjx:portname1/proxy/: foo (200; 15.246115ms)
Dec  3 15:51:33.756: INFO: (10) /api/v1/namespaces/proxy-9272/services/http:proxy-service-k2bjx:portname2/proxy/: bar (200; 17.537264ms)
Dec  3 15:51:33.756: INFO: (10) /api/v1/namespaces/proxy-9272/services/proxy-service-k2bjx:portname1/proxy/: foo (200; 17.406152ms)
Dec  3 15:51:33.765: INFO: (11) /api/v1/namespaces/proxy-9272/pods/http:proxy-service-k2bjx-jphmj:160/proxy/: foo (200; 8.827266ms)
Dec  3 15:51:33.765: INFO: (11) /api/v1/namespaces/proxy-9272/services/http:proxy-service-k2bjx:portname1/proxy/: foo (200; 8.887975ms)
Dec  3 15:51:33.765: INFO: (11) /api/v1/namespaces/proxy-9272/pods/https:proxy-service-k2bjx-jphmj:460/proxy/: tls baz (200; 8.798109ms)
Dec  3 15:51:33.765: INFO: (11) /api/v1/namespaces/proxy-9272/services/https:proxy-service-k2bjx:tlsportname2/proxy/: tls qux (200; 8.877006ms)
Dec  3 15:51:33.766: INFO: (11) /api/v1/namespaces/proxy-9272/services/proxy-service-k2bjx:portname2/proxy/: bar (200; 9.874652ms)
Dec  3 15:51:33.766: INFO: (11) /api/v1/namespaces/proxy-9272/pods/http:proxy-service-k2bjx-jphmj:162/proxy/: bar (200; 9.85777ms)
Dec  3 15:51:33.766: INFO: (11) /api/v1/namespaces/proxy-9272/pods/http:proxy-service-k2bjx-jphmj:1080/proxy/: <a href="/api/v1/namespaces/proxy-9272/pods/http:proxy-service-k2bjx-jphmj:1080/proxy/rewriteme">... (200; 9.83771ms)
Dec  3 15:51:33.766: INFO: (11) /api/v1/namespaces/proxy-9272/pods/https:proxy-service-k2bjx-jphmj:462/proxy/: tls qux (200; 9.914095ms)
Dec  3 15:51:33.766: INFO: (11) /api/v1/namespaces/proxy-9272/services/https:proxy-service-k2bjx:tlsportname1/proxy/: tls baz (200; 9.969364ms)
Dec  3 15:51:33.767: INFO: (11) /api/v1/namespaces/proxy-9272/pods/proxy-service-k2bjx-jphmj/proxy/: <a href="/api/v1/namespaces/proxy-9272/pods/proxy-service-k2bjx-jphmj/proxy/rewriteme">test</a> (200; 10.833591ms)
Dec  3 15:51:33.767: INFO: (11) /api/v1/namespaces/proxy-9272/pods/https:proxy-service-k2bjx-jphmj:443/proxy/: <a href="/api/v1/namespaces/proxy-9272/pods/https:proxy-service-k2bjx-jphmj:443/proxy/tlsrewritem... (200; 10.840083ms)
Dec  3 15:51:33.770: INFO: (11) /api/v1/namespaces/proxy-9272/services/proxy-service-k2bjx:portname1/proxy/: foo (200; 13.397977ms)
Dec  3 15:51:33.770: INFO: (11) /api/v1/namespaces/proxy-9272/pods/proxy-service-k2bjx-jphmj:1080/proxy/: <a href="/api/v1/namespaces/proxy-9272/pods/proxy-service-k2bjx-jphmj:1080/proxy/rewriteme">test<... (200; 13.266552ms)
Dec  3 15:51:33.770: INFO: (11) /api/v1/namespaces/proxy-9272/pods/proxy-service-k2bjx-jphmj:160/proxy/: foo (200; 13.492016ms)
Dec  3 15:51:33.772: INFO: (11) /api/v1/namespaces/proxy-9272/pods/proxy-service-k2bjx-jphmj:162/proxy/: bar (200; 15.438827ms)
Dec  3 15:51:33.772: INFO: (11) /api/v1/namespaces/proxy-9272/services/http:proxy-service-k2bjx:portname2/proxy/: bar (200; 15.500613ms)
Dec  3 15:51:33.781: INFO: (12) /api/v1/namespaces/proxy-9272/pods/proxy-service-k2bjx-jphmj/proxy/: <a href="/api/v1/namespaces/proxy-9272/pods/proxy-service-k2bjx-jphmj/proxy/rewriteme">test</a> (200; 8.569949ms)
Dec  3 15:51:33.781: INFO: (12) /api/v1/namespaces/proxy-9272/pods/http:proxy-service-k2bjx-jphmj:160/proxy/: foo (200; 8.765025ms)
Dec  3 15:51:33.781: INFO: (12) /api/v1/namespaces/proxy-9272/pods/https:proxy-service-k2bjx-jphmj:443/proxy/: <a href="/api/v1/namespaces/proxy-9272/pods/https:proxy-service-k2bjx-jphmj:443/proxy/tlsrewritem... (200; 8.770722ms)
Dec  3 15:51:33.781: INFO: (12) /api/v1/namespaces/proxy-9272/pods/https:proxy-service-k2bjx-jphmj:460/proxy/: tls baz (200; 8.659314ms)
Dec  3 15:51:33.781: INFO: (12) /api/v1/namespaces/proxy-9272/pods/http:proxy-service-k2bjx-jphmj:1080/proxy/: <a href="/api/v1/namespaces/proxy-9272/pods/http:proxy-service-k2bjx-jphmj:1080/proxy/rewriteme">... (200; 8.639765ms)
Dec  3 15:51:33.781: INFO: (12) /api/v1/namespaces/proxy-9272/pods/http:proxy-service-k2bjx-jphmj:162/proxy/: bar (200; 8.656846ms)
Dec  3 15:51:33.781: INFO: (12) /api/v1/namespaces/proxy-9272/pods/https:proxy-service-k2bjx-jphmj:462/proxy/: tls qux (200; 8.815531ms)
Dec  3 15:51:33.783: INFO: (12) /api/v1/namespaces/proxy-9272/pods/proxy-service-k2bjx-jphmj:1080/proxy/: <a href="/api/v1/namespaces/proxy-9272/pods/proxy-service-k2bjx-jphmj:1080/proxy/rewriteme">test<... (200; 10.987633ms)
Dec  3 15:51:33.783: INFO: (12) /api/v1/namespaces/proxy-9272/pods/proxy-service-k2bjx-jphmj:162/proxy/: bar (200; 10.973743ms)
Dec  3 15:51:33.783: INFO: (12) /api/v1/namespaces/proxy-9272/pods/proxy-service-k2bjx-jphmj:160/proxy/: foo (200; 11.006084ms)
Dec  3 15:51:33.785: INFO: (12) /api/v1/namespaces/proxy-9272/services/https:proxy-service-k2bjx:tlsportname1/proxy/: tls baz (200; 13.109486ms)
Dec  3 15:51:33.785: INFO: (12) /api/v1/namespaces/proxy-9272/services/https:proxy-service-k2bjx:tlsportname2/proxy/: tls qux (200; 13.123932ms)
Dec  3 15:51:33.788: INFO: (12) /api/v1/namespaces/proxy-9272/services/http:proxy-service-k2bjx:portname1/proxy/: foo (200; 15.336312ms)
Dec  3 15:51:33.788: INFO: (12) /api/v1/namespaces/proxy-9272/services/proxy-service-k2bjx:portname2/proxy/: bar (200; 15.386766ms)
Dec  3 15:51:33.790: INFO: (12) /api/v1/namespaces/proxy-9272/services/proxy-service-k2bjx:portname1/proxy/: foo (200; 17.783704ms)
Dec  3 15:51:33.790: INFO: (12) /api/v1/namespaces/proxy-9272/services/http:proxy-service-k2bjx:portname2/proxy/: bar (200; 17.771121ms)
Dec  3 15:51:33.799: INFO: (13) /api/v1/namespaces/proxy-9272/pods/http:proxy-service-k2bjx-jphmj:1080/proxy/: <a href="/api/v1/namespaces/proxy-9272/pods/http:proxy-service-k2bjx-jphmj:1080/proxy/rewriteme">... (200; 8.695404ms)
Dec  3 15:51:33.799: INFO: (13) /api/v1/namespaces/proxy-9272/pods/https:proxy-service-k2bjx-jphmj:460/proxy/: tls baz (200; 8.703603ms)
Dec  3 15:51:33.799: INFO: (13) /api/v1/namespaces/proxy-9272/pods/proxy-service-k2bjx-jphmj:160/proxy/: foo (200; 8.956038ms)
Dec  3 15:51:33.799: INFO: (13) /api/v1/namespaces/proxy-9272/pods/proxy-service-k2bjx-jphmj/proxy/: <a href="/api/v1/namespaces/proxy-9272/pods/proxy-service-k2bjx-jphmj/proxy/rewriteme">test</a> (200; 8.836614ms)
Dec  3 15:51:33.799: INFO: (13) /api/v1/namespaces/proxy-9272/pods/http:proxy-service-k2bjx-jphmj:162/proxy/: bar (200; 8.765424ms)
Dec  3 15:51:33.799: INFO: (13) /api/v1/namespaces/proxy-9272/pods/proxy-service-k2bjx-jphmj:1080/proxy/: <a href="/api/v1/namespaces/proxy-9272/pods/proxy-service-k2bjx-jphmj:1080/proxy/rewriteme">test<... (200; 8.783215ms)
Dec  3 15:51:33.801: INFO: (13) /api/v1/namespaces/proxy-9272/pods/http:proxy-service-k2bjx-jphmj:160/proxy/: foo (200; 11.03549ms)
Dec  3 15:51:33.801: INFO: (13) /api/v1/namespaces/proxy-9272/pods/https:proxy-service-k2bjx-jphmj:462/proxy/: tls qux (200; 11.17951ms)
Dec  3 15:51:33.801: INFO: (13) /api/v1/namespaces/proxy-9272/pods/proxy-service-k2bjx-jphmj:162/proxy/: bar (200; 11.134086ms)
Dec  3 15:51:33.801: INFO: (13) /api/v1/namespaces/proxy-9272/pods/https:proxy-service-k2bjx-jphmj:443/proxy/: <a href="/api/v1/namespaces/proxy-9272/pods/https:proxy-service-k2bjx-jphmj:443/proxy/tlsrewritem... (200; 11.166189ms)
Dec  3 15:51:33.803: INFO: (13) /api/v1/namespaces/proxy-9272/services/https:proxy-service-k2bjx:tlsportname2/proxy/: tls qux (200; 13.213954ms)
Dec  3 15:51:33.803: INFO: (13) /api/v1/namespaces/proxy-9272/services/https:proxy-service-k2bjx:tlsportname1/proxy/: tls baz (200; 13.155563ms)
Dec  3 15:51:33.806: INFO: (13) /api/v1/namespaces/proxy-9272/services/http:proxy-service-k2bjx:portname2/proxy/: bar (200; 15.37452ms)
Dec  3 15:51:33.806: INFO: (13) /api/v1/namespaces/proxy-9272/services/proxy-service-k2bjx:portname1/proxy/: foo (200; 15.470145ms)
Dec  3 15:51:33.808: INFO: (13) /api/v1/namespaces/proxy-9272/services/http:proxy-service-k2bjx:portname1/proxy/: foo (200; 17.61334ms)
Dec  3 15:51:33.808: INFO: (13) /api/v1/namespaces/proxy-9272/services/proxy-service-k2bjx:portname2/proxy/: bar (200; 17.656086ms)
Dec  3 15:51:33.816: INFO: (14) /api/v1/namespaces/proxy-9272/pods/https:proxy-service-k2bjx-jphmj:443/proxy/: <a href="/api/v1/namespaces/proxy-9272/pods/https:proxy-service-k2bjx-jphmj:443/proxy/tlsrewritem... (200; 7.893906ms)
Dec  3 15:51:33.816: INFO: (14) /api/v1/namespaces/proxy-9272/pods/proxy-service-k2bjx-jphmj/proxy/: <a href="/api/v1/namespaces/proxy-9272/pods/proxy-service-k2bjx-jphmj/proxy/rewriteme">test</a> (200; 8.161029ms)
Dec  3 15:51:33.816: INFO: (14) /api/v1/namespaces/proxy-9272/pods/proxy-service-k2bjx-jphmj:162/proxy/: bar (200; 8.057867ms)
Dec  3 15:51:33.816: INFO: (14) /api/v1/namespaces/proxy-9272/pods/proxy-service-k2bjx-jphmj:1080/proxy/: <a href="/api/v1/namespaces/proxy-9272/pods/proxy-service-k2bjx-jphmj:1080/proxy/rewriteme">test<... (200; 7.984619ms)
Dec  3 15:51:33.816: INFO: (14) /api/v1/namespaces/proxy-9272/pods/http:proxy-service-k2bjx-jphmj:160/proxy/: foo (200; 8.546587ms)
Dec  3 15:51:33.817: INFO: (14) /api/v1/namespaces/proxy-9272/pods/http:proxy-service-k2bjx-jphmj:1080/proxy/: <a href="/api/v1/namespaces/proxy-9272/pods/http:proxy-service-k2bjx-jphmj:1080/proxy/rewriteme">... (200; 8.517152ms)
Dec  3 15:51:33.817: INFO: (14) /api/v1/namespaces/proxy-9272/pods/proxy-service-k2bjx-jphmj:160/proxy/: foo (200; 8.311574ms)
Dec  3 15:51:33.817: INFO: (14) /api/v1/namespaces/proxy-9272/pods/http:proxy-service-k2bjx-jphmj:162/proxy/: bar (200; 8.168979ms)
Dec  3 15:51:33.817: INFO: (14) /api/v1/namespaces/proxy-9272/pods/https:proxy-service-k2bjx-jphmj:460/proxy/: tls baz (200; 8.126752ms)
Dec  3 15:51:33.817: INFO: (14) /api/v1/namespaces/proxy-9272/pods/https:proxy-service-k2bjx-jphmj:462/proxy/: tls qux (200; 8.272449ms)
Dec  3 15:51:33.819: INFO: (14) /api/v1/namespaces/proxy-9272/services/http:proxy-service-k2bjx:portname1/proxy/: foo (200; 10.404158ms)
Dec  3 15:51:33.819: INFO: (14) /api/v1/namespaces/proxy-9272/services/https:proxy-service-k2bjx:tlsportname2/proxy/: tls qux (200; 10.939588ms)
Dec  3 15:51:33.821: INFO: (14) /api/v1/namespaces/proxy-9272/services/http:proxy-service-k2bjx:portname2/proxy/: bar (200; 12.222597ms)
Dec  3 15:51:33.821: INFO: (14) /api/v1/namespaces/proxy-9272/services/https:proxy-service-k2bjx:tlsportname1/proxy/: tls baz (200; 12.222706ms)
Dec  3 15:51:33.823: INFO: (14) /api/v1/namespaces/proxy-9272/services/proxy-service-k2bjx:portname1/proxy/: foo (200; 14.512736ms)
Dec  3 15:51:33.823: INFO: (14) /api/v1/namespaces/proxy-9272/services/proxy-service-k2bjx:portname2/proxy/: bar (200; 14.473182ms)
Dec  3 15:51:33.833: INFO: (15) /api/v1/namespaces/proxy-9272/pods/proxy-service-k2bjx-jphmj:1080/proxy/: <a href="/api/v1/namespaces/proxy-9272/pods/proxy-service-k2bjx-jphmj:1080/proxy/rewriteme">test<... (200; 9.1549ms)
Dec  3 15:51:33.833: INFO: (15) /api/v1/namespaces/proxy-9272/pods/https:proxy-service-k2bjx-jphmj:460/proxy/: tls baz (200; 8.86082ms)
Dec  3 15:51:33.833: INFO: (15) /api/v1/namespaces/proxy-9272/services/https:proxy-service-k2bjx:tlsportname2/proxy/: tls qux (200; 9.256683ms)
Dec  3 15:51:33.833: INFO: (15) /api/v1/namespaces/proxy-9272/pods/https:proxy-service-k2bjx-jphmj:462/proxy/: tls qux (200; 9.118414ms)
Dec  3 15:51:33.833: INFO: (15) /api/v1/namespaces/proxy-9272/pods/http:proxy-service-k2bjx-jphmj:160/proxy/: foo (200; 9.00466ms)
Dec  3 15:51:33.833: INFO: (15) /api/v1/namespaces/proxy-9272/pods/https:proxy-service-k2bjx-jphmj:443/proxy/: <a href="/api/v1/namespaces/proxy-9272/pods/https:proxy-service-k2bjx-jphmj:443/proxy/tlsrewritem... (200; 9.310753ms)
Dec  3 15:51:33.833: INFO: (15) /api/v1/namespaces/proxy-9272/services/proxy-service-k2bjx:portname2/proxy/: bar (200; 9.50482ms)
Dec  3 15:51:33.835: INFO: (15) /api/v1/namespaces/proxy-9272/pods/http:proxy-service-k2bjx-jphmj:1080/proxy/: <a href="/api/v1/namespaces/proxy-9272/pods/http:proxy-service-k2bjx-jphmj:1080/proxy/rewriteme">... (200; 11.438483ms)
Dec  3 15:51:33.835: INFO: (15) /api/v1/namespaces/proxy-9272/services/https:proxy-service-k2bjx:tlsportname1/proxy/: tls baz (200; 11.069439ms)
Dec  3 15:51:33.835: INFO: (15) /api/v1/namespaces/proxy-9272/pods/proxy-service-k2bjx-jphmj/proxy/: <a href="/api/v1/namespaces/proxy-9272/pods/proxy-service-k2bjx-jphmj/proxy/rewriteme">test</a> (200; 11.615267ms)
Dec  3 15:51:33.835: INFO: (15) /api/v1/namespaces/proxy-9272/pods/proxy-service-k2bjx-jphmj:160/proxy/: foo (200; 11.468588ms)
Dec  3 15:51:33.835: INFO: (15) /api/v1/namespaces/proxy-9272/pods/http:proxy-service-k2bjx-jphmj:162/proxy/: bar (200; 11.362193ms)
Dec  3 15:51:33.837: INFO: (15) /api/v1/namespaces/proxy-9272/pods/proxy-service-k2bjx-jphmj:162/proxy/: bar (200; 13.769455ms)
Dec  3 15:51:33.840: INFO: (15) /api/v1/namespaces/proxy-9272/services/http:proxy-service-k2bjx:portname2/proxy/: bar (200; 15.739389ms)
Dec  3 15:51:33.840: INFO: (15) /api/v1/namespaces/proxy-9272/services/proxy-service-k2bjx:portname1/proxy/: foo (200; 15.657082ms)
Dec  3 15:51:33.842: INFO: (15) /api/v1/namespaces/proxy-9272/services/http:proxy-service-k2bjx:portname1/proxy/: foo (200; 18.022981ms)
Dec  3 15:51:33.850: INFO: (16) /api/v1/namespaces/proxy-9272/pods/http:proxy-service-k2bjx-jphmj:1080/proxy/: <a href="/api/v1/namespaces/proxy-9272/pods/http:proxy-service-k2bjx-jphmj:1080/proxy/rewriteme">... (200; 8.477367ms)
Dec  3 15:51:33.850: INFO: (16) /api/v1/namespaces/proxy-9272/pods/https:proxy-service-k2bjx-jphmj:460/proxy/: tls baz (200; 8.624236ms)
Dec  3 15:51:33.850: INFO: (16) /api/v1/namespaces/proxy-9272/pods/http:proxy-service-k2bjx-jphmj:160/proxy/: foo (200; 8.528883ms)
Dec  3 15:51:33.850: INFO: (16) /api/v1/namespaces/proxy-9272/pods/https:proxy-service-k2bjx-jphmj:443/proxy/: <a href="/api/v1/namespaces/proxy-9272/pods/https:proxy-service-k2bjx-jphmj:443/proxy/tlsrewritem... (200; 8.496651ms)
Dec  3 15:51:33.850: INFO: (16) /api/v1/namespaces/proxy-9272/pods/https:proxy-service-k2bjx-jphmj:462/proxy/: tls qux (200; 8.502893ms)
Dec  3 15:51:33.850: INFO: (16) /api/v1/namespaces/proxy-9272/pods/proxy-service-k2bjx-jphmj:1080/proxy/: <a href="/api/v1/namespaces/proxy-9272/pods/proxy-service-k2bjx-jphmj:1080/proxy/rewriteme">test<... (200; 8.468993ms)
Dec  3 15:51:33.850: INFO: (16) /api/v1/namespaces/proxy-9272/pods/proxy-service-k2bjx-jphmj:160/proxy/: foo (200; 8.71143ms)
Dec  3 15:51:33.853: INFO: (16) /api/v1/namespaces/proxy-9272/pods/http:proxy-service-k2bjx-jphmj:162/proxy/: bar (200; 10.783099ms)
Dec  3 15:51:33.853: INFO: (16) /api/v1/namespaces/proxy-9272/pods/proxy-service-k2bjx-jphmj:162/proxy/: bar (200; 10.672064ms)
Dec  3 15:51:33.853: INFO: (16) /api/v1/namespaces/proxy-9272/services/https:proxy-service-k2bjx:tlsportname1/proxy/: tls baz (200; 10.787231ms)
Dec  3 15:51:33.853: INFO: (16) /api/v1/namespaces/proxy-9272/pods/proxy-service-k2bjx-jphmj/proxy/: <a href="/api/v1/namespaces/proxy-9272/pods/proxy-service-k2bjx-jphmj/proxy/rewriteme">test</a> (200; 10.691771ms)
Dec  3 15:51:33.855: INFO: (16) /api/v1/namespaces/proxy-9272/services/https:proxy-service-k2bjx:tlsportname2/proxy/: tls qux (200; 12.986987ms)
Dec  3 15:51:33.857: INFO: (16) /api/v1/namespaces/proxy-9272/services/proxy-service-k2bjx:portname1/proxy/: foo (200; 15.2435ms)
Dec  3 15:51:33.857: INFO: (16) /api/v1/namespaces/proxy-9272/services/http:proxy-service-k2bjx:portname1/proxy/: foo (200; 15.310392ms)
Dec  3 15:51:33.859: INFO: (16) /api/v1/namespaces/proxy-9272/services/proxy-service-k2bjx:portname2/proxy/: bar (200; 17.48413ms)
Dec  3 15:51:33.860: INFO: (16) /api/v1/namespaces/proxy-9272/services/http:proxy-service-k2bjx:portname2/proxy/: bar (200; 17.716539ms)
Dec  3 15:51:33.868: INFO: (17) /api/v1/namespaces/proxy-9272/pods/proxy-service-k2bjx-jphmj/proxy/: <a href="/api/v1/namespaces/proxy-9272/pods/proxy-service-k2bjx-jphmj/proxy/rewriteme">test</a> (200; 8.615685ms)
Dec  3 15:51:33.868: INFO: (17) /api/v1/namespaces/proxy-9272/pods/http:proxy-service-k2bjx-jphmj:1080/proxy/: <a href="/api/v1/namespaces/proxy-9272/pods/http:proxy-service-k2bjx-jphmj:1080/proxy/rewriteme">... (200; 8.700679ms)
Dec  3 15:51:33.868: INFO: (17) /api/v1/namespaces/proxy-9272/pods/http:proxy-service-k2bjx-jphmj:160/proxy/: foo (200; 8.540041ms)
Dec  3 15:51:33.868: INFO: (17) /api/v1/namespaces/proxy-9272/pods/https:proxy-service-k2bjx-jphmj:443/proxy/: <a href="/api/v1/namespaces/proxy-9272/pods/https:proxy-service-k2bjx-jphmj:443/proxy/tlsrewritem... (200; 8.640485ms)
Dec  3 15:51:33.869: INFO: (17) /api/v1/namespaces/proxy-9272/pods/https:proxy-service-k2bjx-jphmj:460/proxy/: tls baz (200; 8.945001ms)
Dec  3 15:51:33.869: INFO: (17) /api/v1/namespaces/proxy-9272/pods/https:proxy-service-k2bjx-jphmj:462/proxy/: tls qux (200; 8.972873ms)
Dec  3 15:51:33.869: INFO: (17) /api/v1/namespaces/proxy-9272/pods/http:proxy-service-k2bjx-jphmj:162/proxy/: bar (200; 8.978634ms)
Dec  3 15:51:33.869: INFO: (17) /api/v1/namespaces/proxy-9272/pods/proxy-service-k2bjx-jphmj:160/proxy/: foo (200; 9.036509ms)
Dec  3 15:51:33.869: INFO: (17) /api/v1/namespaces/proxy-9272/pods/proxy-service-k2bjx-jphmj:1080/proxy/: <a href="/api/v1/namespaces/proxy-9272/pods/proxy-service-k2bjx-jphmj:1080/proxy/rewriteme">test<... (200; 9.051624ms)
Dec  3 15:51:33.869: INFO: (17) /api/v1/namespaces/proxy-9272/pods/proxy-service-k2bjx-jphmj:162/proxy/: bar (200; 9.115477ms)
Dec  3 15:51:33.871: INFO: (17) /api/v1/namespaces/proxy-9272/services/https:proxy-service-k2bjx:tlsportname2/proxy/: tls qux (200; 10.939093ms)
Dec  3 15:51:33.871: INFO: (17) /api/v1/namespaces/proxy-9272/services/https:proxy-service-k2bjx:tlsportname1/proxy/: tls baz (200; 10.8104ms)
Dec  3 15:51:33.876: INFO: (17) /api/v1/namespaces/proxy-9272/services/http:proxy-service-k2bjx:portname1/proxy/: foo (200; 15.77508ms)
Dec  3 15:51:33.878: INFO: (17) /api/v1/namespaces/proxy-9272/services/http:proxy-service-k2bjx:portname2/proxy/: bar (200; 17.891441ms)
Dec  3 15:51:33.878: INFO: (17) /api/v1/namespaces/proxy-9272/services/proxy-service-k2bjx:portname1/proxy/: foo (200; 18.087703ms)
Dec  3 15:51:33.878: INFO: (17) /api/v1/namespaces/proxy-9272/services/proxy-service-k2bjx:portname2/proxy/: bar (200; 17.977288ms)
Dec  3 15:51:33.887: INFO: (18) /api/v1/namespaces/proxy-9272/pods/http:proxy-service-k2bjx-jphmj:160/proxy/: foo (200; 8.934811ms)
Dec  3 15:51:33.887: INFO: (18) /api/v1/namespaces/proxy-9272/pods/http:proxy-service-k2bjx-jphmj:1080/proxy/: <a href="/api/v1/namespaces/proxy-9272/pods/http:proxy-service-k2bjx-jphmj:1080/proxy/rewriteme">... (200; 9.091744ms)
Dec  3 15:51:33.887: INFO: (18) /api/v1/namespaces/proxy-9272/pods/proxy-service-k2bjx-jphmj:162/proxy/: bar (200; 9.051802ms)
Dec  3 15:51:33.887: INFO: (18) /api/v1/namespaces/proxy-9272/pods/http:proxy-service-k2bjx-jphmj:162/proxy/: bar (200; 9.079071ms)
Dec  3 15:51:33.887: INFO: (18) /api/v1/namespaces/proxy-9272/pods/https:proxy-service-k2bjx-jphmj:462/proxy/: tls qux (200; 9.175827ms)
Dec  3 15:51:33.889: INFO: (18) /api/v1/namespaces/proxy-9272/pods/proxy-service-k2bjx-jphmj:1080/proxy/: <a href="/api/v1/namespaces/proxy-9272/pods/proxy-service-k2bjx-jphmj:1080/proxy/rewriteme">test<... (200; 11.075813ms)
Dec  3 15:51:33.889: INFO: (18) /api/v1/namespaces/proxy-9272/pods/proxy-service-k2bjx-jphmj:160/proxy/: foo (200; 11.079254ms)
Dec  3 15:51:33.889: INFO: (18) /api/v1/namespaces/proxy-9272/pods/https:proxy-service-k2bjx-jphmj:460/proxy/: tls baz (200; 11.230421ms)
Dec  3 15:51:33.889: INFO: (18) /api/v1/namespaces/proxy-9272/pods/proxy-service-k2bjx-jphmj/proxy/: <a href="/api/v1/namespaces/proxy-9272/pods/proxy-service-k2bjx-jphmj/proxy/rewriteme">test</a> (200; 11.116566ms)
Dec  3 15:51:33.889: INFO: (18) /api/v1/namespaces/proxy-9272/pods/https:proxy-service-k2bjx-jphmj:443/proxy/: <a href="/api/v1/namespaces/proxy-9272/pods/https:proxy-service-k2bjx-jphmj:443/proxy/tlsrewritem... (200; 11.081515ms)
Dec  3 15:51:33.889: INFO: (18) /api/v1/namespaces/proxy-9272/services/https:proxy-service-k2bjx:tlsportname2/proxy/: tls qux (200; 11.163149ms)
Dec  3 15:51:33.891: INFO: (18) /api/v1/namespaces/proxy-9272/services/proxy-service-k2bjx:portname2/proxy/: bar (200; 13.41034ms)
Dec  3 15:51:33.891: INFO: (18) /api/v1/namespaces/proxy-9272/services/https:proxy-service-k2bjx:tlsportname1/proxy/: tls baz (200; 13.518436ms)
Dec  3 15:51:33.894: INFO: (18) /api/v1/namespaces/proxy-9272/services/proxy-service-k2bjx:portname1/proxy/: foo (200; 15.694727ms)
Dec  3 15:51:33.894: INFO: (18) /api/v1/namespaces/proxy-9272/services/http:proxy-service-k2bjx:portname2/proxy/: bar (200; 15.603504ms)
Dec  3 15:51:33.896: INFO: (18) /api/v1/namespaces/proxy-9272/services/http:proxy-service-k2bjx:portname1/proxy/: foo (200; 17.484784ms)
Dec  3 15:51:33.905: INFO: (19) /api/v1/namespaces/proxy-9272/pods/http:proxy-service-k2bjx-jphmj:162/proxy/: bar (200; 8.715131ms)
Dec  3 15:51:33.905: INFO: (19) /api/v1/namespaces/proxy-9272/pods/proxy-service-k2bjx-jphmj/proxy/: <a href="/api/v1/namespaces/proxy-9272/pods/proxy-service-k2bjx-jphmj/proxy/rewriteme">test</a> (200; 8.879286ms)
Dec  3 15:51:33.905: INFO: (19) /api/v1/namespaces/proxy-9272/pods/http:proxy-service-k2bjx-jphmj:1080/proxy/: <a href="/api/v1/namespaces/proxy-9272/pods/http:proxy-service-k2bjx-jphmj:1080/proxy/rewriteme">... (200; 8.67138ms)
Dec  3 15:51:33.905: INFO: (19) /api/v1/namespaces/proxy-9272/pods/proxy-service-k2bjx-jphmj:1080/proxy/: <a href="/api/v1/namespaces/proxy-9272/pods/proxy-service-k2bjx-jphmj:1080/proxy/rewriteme">test<... (200; 8.859911ms)
Dec  3 15:51:33.905: INFO: (19) /api/v1/namespaces/proxy-9272/pods/proxy-service-k2bjx-jphmj:160/proxy/: foo (200; 8.912702ms)
Dec  3 15:51:33.907: INFO: (19) /api/v1/namespaces/proxy-9272/pods/https:proxy-service-k2bjx-jphmj:462/proxy/: tls qux (200; 10.891431ms)
Dec  3 15:51:33.907: INFO: (19) /api/v1/namespaces/proxy-9272/services/proxy-service-k2bjx:portname1/proxy/: foo (200; 10.951148ms)
Dec  3 15:51:33.907: INFO: (19) /api/v1/namespaces/proxy-9272/pods/https:proxy-service-k2bjx-jphmj:460/proxy/: tls baz (200; 11.021309ms)
Dec  3 15:51:33.907: INFO: (19) /api/v1/namespaces/proxy-9272/pods/proxy-service-k2bjx-jphmj:162/proxy/: bar (200; 10.935621ms)
Dec  3 15:51:33.907: INFO: (19) /api/v1/namespaces/proxy-9272/pods/https:proxy-service-k2bjx-jphmj:443/proxy/: <a href="/api/v1/namespaces/proxy-9272/pods/https:proxy-service-k2bjx-jphmj:443/proxy/tlsrewritem... (200; 10.882021ms)
Dec  3 15:51:33.909: INFO: (19) /api/v1/namespaces/proxy-9272/services/https:proxy-service-k2bjx:tlsportname2/proxy/: tls qux (200; 12.935744ms)
Dec  3 15:51:33.909: INFO: (19) /api/v1/namespaces/proxy-9272/services/https:proxy-service-k2bjx:tlsportname1/proxy/: tls baz (200; 12.999067ms)
Dec  3 15:51:33.911: INFO: (19) /api/v1/namespaces/proxy-9272/services/proxy-service-k2bjx:portname2/proxy/: bar (200; 15.097678ms)
Dec  3 15:51:33.911: INFO: (19) /api/v1/namespaces/proxy-9272/pods/http:proxy-service-k2bjx-jphmj:160/proxy/: foo (200; 15.140422ms)
Dec  3 15:51:33.913: INFO: (19) /api/v1/namespaces/proxy-9272/services/http:proxy-service-k2bjx:portname1/proxy/: foo (200; 17.311358ms)
Dec  3 15:51:33.913: INFO: (19) /api/v1/namespaces/proxy-9272/services/http:proxy-service-k2bjx:portname2/proxy/: bar (200; 17.420597ms)
STEP: deleting ReplicationController proxy-service-k2bjx in namespace proxy-9272, will wait for the garbage collector to delete the pods
Dec  3 15:51:33.974: INFO: Deleting ReplicationController proxy-service-k2bjx took: 6.61382ms
Dec  3 15:51:34.475: INFO: Terminating ReplicationController proxy-service-k2bjx pods took: 500.310086ms
[AfterEach] version v1
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:51:45.675: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-9272" for this suite.
Dec  3 15:51:51.699: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:51:51.867: INFO: namespace proxy-9272 deletion completed in 6.182895436s
â€¢SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:51:51.868: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-4941
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-4941
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a new StatefulSet
Dec  3 15:51:52.030: INFO: Found 0 stateful pods, waiting for 3
Dec  3 15:52:02.036: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Dec  3 15:52:02.036: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Dec  3 15:52:02.036: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Dec  3 15:52:02.050: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmwqx-5aq.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4941 ss2-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec  3 15:52:02.983: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Dec  3 15:52:02.983: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec  3 15:52:02.983: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Dec  3 15:52:13.025: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Dec  3 15:52:23.052: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmwqx-5aq.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4941 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  3 15:52:23.753: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Dec  3 15:52:23.753: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec  3 15:52:23.753: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

STEP: Rolling back to a previous revision
Dec  3 15:52:43.782: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmwqx-5aq.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4941 ss2-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec  3 15:52:44.374: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Dec  3 15:52:44.375: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec  3 15:52:44.375: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec  3 15:52:54.415: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Dec  3 15:53:04.444: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmwqx-5aq.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4941 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  3 15:53:05.083: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Dec  3 15:53:05.083: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec  3 15:53:05.083: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec  3 15:53:15.113: INFO: Waiting for StatefulSet statefulset-4941/ss2 to complete update
Dec  3 15:53:15.113: INFO: Waiting for Pod statefulset-4941/ss2-0 to have revision ss2-7c9b54fd4c update revision ss2-6c5cd755cd
Dec  3 15:53:25.124: INFO: Waiting for StatefulSet statefulset-4941/ss2 to complete update
Dec  3 15:53:25.125: INFO: Waiting for Pod statefulset-4941/ss2-0 to have revision ss2-7c9b54fd4c update revision ss2-6c5cd755cd
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Dec  3 15:53:35.124: INFO: Deleting all statefulset in ns statefulset-4941
Dec  3 15:53:35.129: INFO: Scaling statefulset ss2 to 0
Dec  3 15:54:05.150: INFO: Waiting for statefulset status.replicas updated to 0
Dec  3 15:54:05.155: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:54:05.170: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-4941" for this suite.
Dec  3 15:54:11.193: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:54:11.357: INFO: namespace statefulset-4941 deletion completed in 6.179399064s
â€¢SSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] version v1
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:54:11.358: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-9968
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Dec  3 15:54:11.522: INFO: (0) /api/v1/nodes/izgw8afzp8040eoqk0qbhwz:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 13.140291ms)
Dec  3 15:54:11.568: INFO: (1) /api/v1/nodes/izgw8afzp8040eoqk0qbhwz:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 46.035913ms)
Dec  3 15:54:11.576: INFO: (2) /api/v1/nodes/izgw8afzp8040eoqk0qbhwz:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 7.986365ms)
Dec  3 15:54:11.584: INFO: (3) /api/v1/nodes/izgw8afzp8040eoqk0qbhwz:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 7.765824ms)
Dec  3 15:54:11.592: INFO: (4) /api/v1/nodes/izgw8afzp8040eoqk0qbhwz:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 7.455194ms)
Dec  3 15:54:11.599: INFO: (5) /api/v1/nodes/izgw8afzp8040eoqk0qbhwz:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 7.536635ms)
Dec  3 15:54:11.607: INFO: (6) /api/v1/nodes/izgw8afzp8040eoqk0qbhwz:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 7.722765ms)
Dec  3 15:54:11.615: INFO: (7) /api/v1/nodes/izgw8afzp8040eoqk0qbhwz:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 7.225825ms)
Dec  3 15:54:11.622: INFO: (8) /api/v1/nodes/izgw8afzp8040eoqk0qbhwz:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 7.412514ms)
Dec  3 15:54:11.629: INFO: (9) /api/v1/nodes/izgw8afzp8040eoqk0qbhwz:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 7.161597ms)
Dec  3 15:54:11.637: INFO: (10) /api/v1/nodes/izgw8afzp8040eoqk0qbhwz:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 7.486943ms)
Dec  3 15:54:11.644: INFO: (11) /api/v1/nodes/izgw8afzp8040eoqk0qbhwz:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 7.108745ms)
Dec  3 15:54:11.652: INFO: (12) /api/v1/nodes/izgw8afzp8040eoqk0qbhwz:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 7.400217ms)
Dec  3 15:54:11.659: INFO: (13) /api/v1/nodes/izgw8afzp8040eoqk0qbhwz:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 7.246529ms)
Dec  3 15:54:11.666: INFO: (14) /api/v1/nodes/izgw8afzp8040eoqk0qbhwz:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 7.154177ms)
Dec  3 15:54:11.677: INFO: (15) /api/v1/nodes/izgw8afzp8040eoqk0qbhwz:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 10.937748ms)
Dec  3 15:54:11.685: INFO: (16) /api/v1/nodes/izgw8afzp8040eoqk0qbhwz:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 7.309623ms)
Dec  3 15:54:11.692: INFO: (17) /api/v1/nodes/izgw8afzp8040eoqk0qbhwz:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 7.378244ms)
Dec  3 15:54:11.699: INFO: (18) /api/v1/nodes/izgw8afzp8040eoqk0qbhwz:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 7.001484ms)
Dec  3 15:54:11.706: INFO: (19) /api/v1/nodes/izgw8afzp8040eoqk0qbhwz:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 7.108756ms)
[AfterEach] version v1
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:54:11.707: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-9968" for this suite.
Dec  3 15:54:17.728: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:54:17.938: INFO: namespace proxy-9968 deletion completed in 6.22662669s
â€¢SSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:54:17.938: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-3821
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-d16a1f72-eda4-4755-b119-ae4317465d0c
STEP: Creating a pod to test consume configMaps
Dec  3 15:54:18.098: INFO: Waiting up to 5m0s for pod "pod-configmaps-dc9c0622-d4a3-4bb6-8401-1d49b5a98ea4" in namespace "configmap-3821" to be "success or failure"
Dec  3 15:54:18.102: INFO: Pod "pod-configmaps-dc9c0622-d4a3-4bb6-8401-1d49b5a98ea4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.270985ms
Dec  3 15:54:20.107: INFO: Pod "pod-configmaps-dc9c0622-d4a3-4bb6-8401-1d49b5a98ea4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009349031s
STEP: Saw pod success
Dec  3 15:54:20.107: INFO: Pod "pod-configmaps-dc9c0622-d4a3-4bb6-8401-1d49b5a98ea4" satisfied condition "success or failure"
Dec  3 15:54:20.111: INFO: Trying to get logs from node izgw8afzp8040eoqk0qbhxz pod pod-configmaps-dc9c0622-d4a3-4bb6-8401-1d49b5a98ea4 container configmap-volume-test: <nil>
STEP: delete the pod
Dec  3 15:54:20.134: INFO: Waiting for pod pod-configmaps-dc9c0622-d4a3-4bb6-8401-1d49b5a98ea4 to disappear
Dec  3 15:54:20.139: INFO: Pod pod-configmaps-dc9c0622-d4a3-4bb6-8401-1d49b5a98ea4 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:54:20.139: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3821" for this suite.
Dec  3 15:54:26.161: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:54:26.327: INFO: namespace configmap-3821 deletion completed in 6.18046503s
â€¢SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:54:26.327: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-2316
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir volume type on tmpfs
Dec  3 15:54:26.480: INFO: Waiting up to 5m0s for pod "pod-b94f644a-139c-48fb-aeac-d2e405ba22d1" in namespace "emptydir-2316" to be "success or failure"
Dec  3 15:54:26.485: INFO: Pod "pod-b94f644a-139c-48fb-aeac-d2e405ba22d1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.274149ms
Dec  3 15:54:28.490: INFO: Pod "pod-b94f644a-139c-48fb-aeac-d2e405ba22d1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009935181s
STEP: Saw pod success
Dec  3 15:54:28.490: INFO: Pod "pod-b94f644a-139c-48fb-aeac-d2e405ba22d1" satisfied condition "success or failure"
Dec  3 15:54:28.495: INFO: Trying to get logs from node izgw8afzp8040eoqk0qbhxz pod pod-b94f644a-139c-48fb-aeac-d2e405ba22d1 container test-container: <nil>
STEP: delete the pod
Dec  3 15:54:28.517: INFO: Waiting for pod pod-b94f644a-139c-48fb-aeac-d2e405ba22d1 to disappear
Dec  3 15:54:28.521: INFO: Pod pod-b94f644a-139c-48fb-aeac-d2e405ba22d1 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:54:28.521: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2316" for this suite.
Dec  3 15:54:34.542: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:54:34.710: INFO: namespace emptydir-2316 deletion completed in 6.182589165s
â€¢SSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:54:34.711: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-4556
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name s-test-opt-del-7a367b44-5c4a-4cf5-9886-58fd8ff818ec
STEP: Creating secret with name s-test-opt-upd-14cc82d4-bdde-44f8-b175-c262ca97a4d6
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-7a367b44-5c4a-4cf5-9886-58fd8ff818ec
STEP: Updating secret s-test-opt-upd-14cc82d4-bdde-44f8-b175-c262ca97a4d6
STEP: Creating secret with name s-test-opt-create-eeb1d357-efea-4856-8b84-304b73494c4b
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:54:39.288: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-4556" for this suite.
Dec  3 15:54:51.313: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:54:51.483: INFO: namespace secrets-4556 deletion completed in 12.18571893s
â€¢SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:54:51.484: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-282
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0777 on node default medium
Dec  3 15:54:51.639: INFO: Waiting up to 5m0s for pod "pod-ac9aa86d-6fc3-4695-a4d4-56a142e4b029" in namespace "emptydir-282" to be "success or failure"
Dec  3 15:54:51.644: INFO: Pod "pod-ac9aa86d-6fc3-4695-a4d4-56a142e4b029": Phase="Pending", Reason="", readiness=false. Elapsed: 4.468823ms
Dec  3 15:54:53.650: INFO: Pod "pod-ac9aa86d-6fc3-4695-a4d4-56a142e4b029": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010184382s
STEP: Saw pod success
Dec  3 15:54:53.650: INFO: Pod "pod-ac9aa86d-6fc3-4695-a4d4-56a142e4b029" satisfied condition "success or failure"
Dec  3 15:54:53.654: INFO: Trying to get logs from node izgw8afzp8040eoqk0qbhxz pod pod-ac9aa86d-6fc3-4695-a4d4-56a142e4b029 container test-container: <nil>
STEP: delete the pod
Dec  3 15:54:53.715: INFO: Waiting for pod pod-ac9aa86d-6fc3-4695-a4d4-56a142e4b029 to disappear
Dec  3 15:54:53.720: INFO: Pod pod-ac9aa86d-6fc3-4695-a4d4-56a142e4b029 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:54:53.720: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-282" for this suite.
Dec  3 15:54:59.744: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:54:59.905: INFO: namespace emptydir-282 deletion completed in 6.175870294s
â€¢SSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:54:59.905: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-996
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-f8793480-4286-4243-844e-7679658b148e
STEP: Creating a pod to test consume configMaps
Dec  3 15:55:00.063: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-118b0c25-ed1f-4f0a-920b-be185181b2bc" in namespace "projected-996" to be "success or failure"
Dec  3 15:55:00.067: INFO: Pod "pod-projected-configmaps-118b0c25-ed1f-4f0a-920b-be185181b2bc": Phase="Pending", Reason="", readiness=false. Elapsed: 4.125865ms
Dec  3 15:55:02.073: INFO: Pod "pod-projected-configmaps-118b0c25-ed1f-4f0a-920b-be185181b2bc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009933891s
STEP: Saw pod success
Dec  3 15:55:02.073: INFO: Pod "pod-projected-configmaps-118b0c25-ed1f-4f0a-920b-be185181b2bc" satisfied condition "success or failure"
Dec  3 15:55:02.077: INFO: Trying to get logs from node izgw8afzp8040eoqk0qbhxz pod pod-projected-configmaps-118b0c25-ed1f-4f0a-920b-be185181b2bc container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec  3 15:55:02.098: INFO: Waiting for pod pod-projected-configmaps-118b0c25-ed1f-4f0a-920b-be185181b2bc to disappear
Dec  3 15:55:02.103: INFO: Pod pod-projected-configmaps-118b0c25-ed1f-4f0a-920b-be185181b2bc no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:55:02.103: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-996" for this suite.
Dec  3 15:55:08.126: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:55:08.302: INFO: namespace projected-996 deletion completed in 6.191335725s
â€¢SSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:55:08.302: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-3250
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Dec  3 15:55:08.459: INFO: Pod name pod-release: Found 0 pods out of 1
Dec  3 15:55:13.465: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:55:13.482: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-3250" for this suite.
Dec  3 15:55:19.505: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:55:19.682: INFO: namespace replication-controller-3250 deletion completed in 6.191355192s
â€¢SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:55:19.682: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-5619
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-5619
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace statefulset-5619
STEP: Creating statefulset with conflicting port in namespace statefulset-5619
STEP: Waiting until pod test-pod will start running in namespace statefulset-5619
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-5619
Dec  3 15:55:21.907: INFO: Observed stateful pod in namespace: statefulset-5619, name: ss-0, uid: 3d8a1a69-d8a7-470e-9283-d89701bbefc0, status phase: Pending. Waiting for statefulset controller to delete.
Dec  3 15:55:21.921: INFO: Observed stateful pod in namespace: statefulset-5619, name: ss-0, uid: 3d8a1a69-d8a7-470e-9283-d89701bbefc0, status phase: Failed. Waiting for statefulset controller to delete.
Dec  3 15:55:21.958: INFO: Observed stateful pod in namespace: statefulset-5619, name: ss-0, uid: 3d8a1a69-d8a7-470e-9283-d89701bbefc0, status phase: Failed. Waiting for statefulset controller to delete.
Dec  3 15:55:21.959: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-5619
STEP: Removing pod with conflicting port in namespace statefulset-5619
STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-5619 and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Dec  3 15:55:23.977: INFO: Deleting all statefulset in ns statefulset-5619
Dec  3 15:55:23.981: INFO: Scaling statefulset ss to 0
Dec  3 15:55:34.002: INFO: Waiting for statefulset status.replicas updated to 0
Dec  3 15:55:34.006: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:55:34.021: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-5619" for this suite.
Dec  3 15:55:40.043: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:55:40.220: INFO: namespace statefulset-5619 deletion completed in 6.191046965s
â€¢SSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:55:40.279: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-3834
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Starting the proxy
Dec  3 15:55:40.429: INFO: Asynchronously running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl kubectl --server=https://api.tmwqx-5aq.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config proxy --unix-socket=/tmp/kubectl-proxy-unix125299528/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:55:40.495: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3834" for this suite.
Dec  3 15:55:46.516: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:55:46.684: INFO: namespace kubectl-3834 deletion completed in 6.183423011s
â€¢SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:55:46.750: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-3800
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-3800.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-3800.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-3800.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-3800.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-3800.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-3800.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe /etc/hosts
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec  3 15:55:51.507: INFO: DNS probes using dns-3800/dns-test-0b1cc4c6-9b8c-4a65-b087-8da9e96a04fb succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:55:51.517: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-3800" for this suite.
Dec  3 15:55:57.541: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:55:57.703: INFO: namespace dns-3800 deletion completed in 6.177681733s
â€¢SSSS
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:55:57.704: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-544
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Dec  3 15:55:57.858: INFO: Waiting up to 5m0s for pod "downward-api-d2f4970c-842b-4f80-8457-d163dc0f8fd7" in namespace "downward-api-544" to be "success or failure"
Dec  3 15:55:57.863: INFO: Pod "downward-api-d2f4970c-842b-4f80-8457-d163dc0f8fd7": Phase="Pending", Reason="", readiness=false. Elapsed: 4.167849ms
Dec  3 15:55:59.869: INFO: Pod "downward-api-d2f4970c-842b-4f80-8457-d163dc0f8fd7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010705372s
STEP: Saw pod success
Dec  3 15:55:59.869: INFO: Pod "downward-api-d2f4970c-842b-4f80-8457-d163dc0f8fd7" satisfied condition "success or failure"
Dec  3 15:55:59.874: INFO: Trying to get logs from node izgw8afzp8040eoqk0qbhxz pod downward-api-d2f4970c-842b-4f80-8457-d163dc0f8fd7 container dapi-container: <nil>
STEP: delete the pod
Dec  3 15:55:59.894: INFO: Waiting for pod downward-api-d2f4970c-842b-4f80-8457-d163dc0f8fd7 to disappear
Dec  3 15:55:59.899: INFO: Pod downward-api-d2f4970c-842b-4f80-8457-d163dc0f8fd7 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:55:59.899: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-544" for this suite.
Dec  3 15:56:05.920: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:56:06.091: INFO: namespace downward-api-544 deletion completed in 6.185304444s
â€¢SS
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:56:06.092: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-3376
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Dec  3 15:56:06.240: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:56:08.295: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-3376" for this suite.
Dec  3 15:56:58.317: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:56:58.500: INFO: namespace pods-3376 deletion completed in 50.196948812s
â€¢SSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:56:58.501: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-3804
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:57:00.687: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-3804" for this suite.
Dec  3 15:57:50.715: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:57:50.884: INFO: namespace kubelet-test-3804 deletion completed in 50.188880853s
â€¢SSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:57:50.885: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5774
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Dec  3 15:57:51.037: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c83ceca4-63d3-400e-816f-9e3184bb1dcf" in namespace "projected-5774" to be "success or failure"
Dec  3 15:57:51.041: INFO: Pod "downwardapi-volume-c83ceca4-63d3-400e-816f-9e3184bb1dcf": Phase="Pending", Reason="", readiness=false. Elapsed: 4.209288ms
Dec  3 15:57:53.047: INFO: Pod "downwardapi-volume-c83ceca4-63d3-400e-816f-9e3184bb1dcf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009721003s
STEP: Saw pod success
Dec  3 15:57:53.047: INFO: Pod "downwardapi-volume-c83ceca4-63d3-400e-816f-9e3184bb1dcf" satisfied condition "success or failure"
Dec  3 15:57:53.052: INFO: Trying to get logs from node izgw8afzp8040eoqk0qbhxz pod downwardapi-volume-c83ceca4-63d3-400e-816f-9e3184bb1dcf container client-container: <nil>
STEP: delete the pod
Dec  3 15:57:53.073: INFO: Waiting for pod downwardapi-volume-c83ceca4-63d3-400e-816f-9e3184bb1dcf to disappear
Dec  3 15:57:53.076: INFO: Pod downwardapi-volume-c83ceca4-63d3-400e-816f-9e3184bb1dcf no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:57:53.077: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5774" for this suite.
Dec  3 15:57:59.099: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:57:59.274: INFO: namespace projected-5774 deletion completed in 6.190427003s
â€¢SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:57:59.275: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-1782
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-configmap-d2rp
STEP: Creating a pod to test atomic-volume-subpath
Dec  3 15:57:59.439: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-d2rp" in namespace "subpath-1782" to be "success or failure"
Dec  3 15:57:59.444: INFO: Pod "pod-subpath-test-configmap-d2rp": Phase="Pending", Reason="", readiness=false. Elapsed: 4.482149ms
Dec  3 15:58:01.449: INFO: Pod "pod-subpath-test-configmap-d2rp": Phase="Running", Reason="", readiness=true. Elapsed: 2.010073507s
Dec  3 15:58:03.455: INFO: Pod "pod-subpath-test-configmap-d2rp": Phase="Running", Reason="", readiness=true. Elapsed: 4.015794151s
Dec  3 15:58:05.461: INFO: Pod "pod-subpath-test-configmap-d2rp": Phase="Running", Reason="", readiness=true. Elapsed: 6.021224762s
Dec  3 15:58:07.466: INFO: Pod "pod-subpath-test-configmap-d2rp": Phase="Running", Reason="", readiness=true. Elapsed: 8.026927861s
Dec  3 15:58:09.474: INFO: Pod "pod-subpath-test-configmap-d2rp": Phase="Running", Reason="", readiness=true. Elapsed: 10.03413447s
Dec  3 15:58:11.479: INFO: Pod "pod-subpath-test-configmap-d2rp": Phase="Running", Reason="", readiness=true. Elapsed: 12.039464359s
Dec  3 15:58:13.484: INFO: Pod "pod-subpath-test-configmap-d2rp": Phase="Running", Reason="", readiness=true. Elapsed: 14.044868431s
Dec  3 15:58:15.489: INFO: Pod "pod-subpath-test-configmap-d2rp": Phase="Running", Reason="", readiness=true. Elapsed: 16.049987156s
Dec  3 15:58:17.495: INFO: Pod "pod-subpath-test-configmap-d2rp": Phase="Running", Reason="", readiness=true. Elapsed: 18.05538391s
Dec  3 15:58:19.500: INFO: Pod "pod-subpath-test-configmap-d2rp": Phase="Running", Reason="", readiness=true. Elapsed: 20.060718884s
Dec  3 15:58:21.506: INFO: Pod "pod-subpath-test-configmap-d2rp": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.066410055s
STEP: Saw pod success
Dec  3 15:58:21.506: INFO: Pod "pod-subpath-test-configmap-d2rp" satisfied condition "success or failure"
Dec  3 15:58:21.511: INFO: Trying to get logs from node izgw8afzp8040eoqk0qbhxz pod pod-subpath-test-configmap-d2rp container test-container-subpath-configmap-d2rp: <nil>
STEP: delete the pod
Dec  3 15:58:21.533: INFO: Waiting for pod pod-subpath-test-configmap-d2rp to disappear
Dec  3 15:58:21.537: INFO: Pod pod-subpath-test-configmap-d2rp no longer exists
STEP: Deleting pod pod-subpath-test-configmap-d2rp
Dec  3 15:58:21.537: INFO: Deleting pod "pod-subpath-test-configmap-d2rp" in namespace "subpath-1782"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:58:21.542: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-1782" for this suite.
Dec  3 15:58:27.565: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:58:27.775: INFO: namespace subpath-1782 deletion completed in 6.225010948s
â€¢SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:58:27.775: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-4331
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0777 on tmpfs
Dec  3 15:58:27.931: INFO: Waiting up to 5m0s for pod "pod-17f76d9b-86cb-4ff6-bf45-2ddcc79d242b" in namespace "emptydir-4331" to be "success or failure"
Dec  3 15:58:27.936: INFO: Pod "pod-17f76d9b-86cb-4ff6-bf45-2ddcc79d242b": Phase="Pending", Reason="", readiness=false. Elapsed: 5.250442ms
Dec  3 15:58:29.943: INFO: Pod "pod-17f76d9b-86cb-4ff6-bf45-2ddcc79d242b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011722175s
STEP: Saw pod success
Dec  3 15:58:29.943: INFO: Pod "pod-17f76d9b-86cb-4ff6-bf45-2ddcc79d242b" satisfied condition "success or failure"
Dec  3 15:58:29.948: INFO: Trying to get logs from node izgw8afzp8040eoqk0qbhxz pod pod-17f76d9b-86cb-4ff6-bf45-2ddcc79d242b container test-container: <nil>
STEP: delete the pod
Dec  3 15:58:29.975: INFO: Waiting for pod pod-17f76d9b-86cb-4ff6-bf45-2ddcc79d242b to disappear
Dec  3 15:58:29.980: INFO: Pod pod-17f76d9b-86cb-4ff6-bf45-2ddcc79d242b no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:58:29.980: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4331" for this suite.
Dec  3 15:58:36.005: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:58:36.170: INFO: namespace emptydir-4331 deletion completed in 6.183033004s
â€¢
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:58:36.287: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-6903
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: executing a command with run --rm and attach with stdin
Dec  3 15:58:36.434: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmwqx-5aq.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-6903 run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Dec  3 15:58:38.783: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Dec  3 15:58:38.783: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:58:40.792: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6903" for this suite.
Dec  3 15:58:46.815: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:58:47.021: INFO: namespace kubectl-6903 deletion completed in 6.22067873s
â€¢
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:58:47.021: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-985
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1557
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Dec  3 15:58:47.166: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmwqx-5aq.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --generator=deployment/apps.v1 --namespace=kubectl-985'
Dec  3 15:58:47.264: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Dec  3 15:58:47.264: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the deployment e2e-test-nginx-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1562
Dec  3 15:58:49.276: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmwqx-5aq.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config delete deployment e2e-test-nginx-deployment --namespace=kubectl-985'
Dec  3 15:58:49.425: INFO: stderr: ""
Dec  3 15:58:49.425: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:58:49.425: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-985" for this suite.
Dec  3 15:58:55.447: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:58:55.617: INFO: namespace kubectl-985 deletion completed in 6.183655254s
â€¢SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:58:55.617: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-kubelet-etc-hosts-8059
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Dec  3 15:58:59.902: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-8059 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  3 15:58:59.902: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec  3 15:59:00.359: INFO: Exec stderr: ""
Dec  3 15:59:00.359: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-8059 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  3 15:59:00.359: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec  3 15:59:00.830: INFO: Exec stderr: ""
Dec  3 15:59:00.830: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-8059 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  3 15:59:00.830: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec  3 15:59:01.301: INFO: Exec stderr: ""
Dec  3 15:59:01.301: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-8059 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  3 15:59:01.301: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec  3 15:59:01.707: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Dec  3 15:59:01.708: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-8059 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  3 15:59:01.708: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec  3 15:59:02.085: INFO: Exec stderr: ""
Dec  3 15:59:02.085: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-8059 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  3 15:59:02.085: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec  3 15:59:02.538: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Dec  3 15:59:02.538: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-8059 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  3 15:59:02.538: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec  3 15:59:02.933: INFO: Exec stderr: ""
Dec  3 15:59:02.933: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-8059 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  3 15:59:02.933: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec  3 15:59:03.351: INFO: Exec stderr: ""
Dec  3 15:59:03.351: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-8059 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  3 15:59:03.351: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec  3 15:59:03.801: INFO: Exec stderr: ""
Dec  3 15:59:03.801: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-8059 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  3 15:59:03.801: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec  3 15:59:04.197: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:59:04.197: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-kubelet-etc-hosts-8059" for this suite.
Dec  3 15:59:48.222: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:59:48.386: INFO: namespace e2e-kubelet-etc-hosts-8059 deletion completed in 44.18031964s
â€¢SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:59:48.387: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-6806
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
Dec  3 16:00:28.575: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W1203 16:00:28.575937    5085 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 16:00:28.576: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-6806" for this suite.
Dec  3 16:00:34.596: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:00:34.764: INFO: namespace gc-6806 deletion completed in 6.182911002s
â€¢SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 16:00:34.764: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-8625
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:273
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the initial replication controller
Dec  3 16:00:34.912: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmwqx-5aq.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config create -f - --namespace=kubectl-8625'
Dec  3 16:00:35.171: INFO: stderr: ""
Dec  3 16:00:35.171: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec  3 16:00:35.171: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmwqx-5aq.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-8625'
Dec  3 16:00:35.267: INFO: stderr: ""
Dec  3 16:00:35.267: INFO: stdout: "update-demo-nautilus-9jq2m update-demo-nautilus-dfd4n "
Dec  3 16:00:35.267: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmwqx-5aq.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-9jq2m -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-8625'
Dec  3 16:00:35.403: INFO: stderr: ""
Dec  3 16:00:35.403: INFO: stdout: ""
Dec  3 16:00:35.403: INFO: update-demo-nautilus-9jq2m is created but not running
Dec  3 16:00:40.404: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmwqx-5aq.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-8625'
Dec  3 16:00:40.495: INFO: stderr: ""
Dec  3 16:00:40.495: INFO: stdout: "update-demo-nautilus-9jq2m update-demo-nautilus-dfd4n "
Dec  3 16:00:40.495: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmwqx-5aq.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-9jq2m -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-8625'
Dec  3 16:00:40.628: INFO: stderr: ""
Dec  3 16:00:40.628: INFO: stdout: "true"
Dec  3 16:00:40.628: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmwqx-5aq.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-9jq2m -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-8625'
Dec  3 16:00:40.722: INFO: stderr: ""
Dec  3 16:00:40.722: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec  3 16:00:40.722: INFO: validating pod update-demo-nautilus-9jq2m
Dec  3 16:00:40.784: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  3 16:00:40.784: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  3 16:00:40.785: INFO: update-demo-nautilus-9jq2m is verified up and running
Dec  3 16:00:40.785: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmwqx-5aq.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-dfd4n -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-8625'
Dec  3 16:00:40.874: INFO: stderr: ""
Dec  3 16:00:40.874: INFO: stdout: "true"
Dec  3 16:00:40.874: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmwqx-5aq.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-dfd4n -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-8625'
Dec  3 16:00:41.004: INFO: stderr: ""
Dec  3 16:00:41.004: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec  3 16:00:41.004: INFO: validating pod update-demo-nautilus-dfd4n
Dec  3 16:00:41.100: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  3 16:00:41.100: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  3 16:00:41.100: INFO: update-demo-nautilus-dfd4n is verified up and running
STEP: rolling-update to new replication controller
Dec  3 16:00:41.103: INFO: scanned /root for discovery docs: <nil>
Dec  3 16:00:41.103: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmwqx-5aq.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config rolling-update update-demo-nautilus --update-period=1s -f - --namespace=kubectl-8625'
Dec  3 16:01:03.502: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Dec  3 16:01:03.502: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec  3 16:01:03.502: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmwqx-5aq.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-8625'
Dec  3 16:01:03.641: INFO: stderr: ""
Dec  3 16:01:03.641: INFO: stdout: "update-demo-kitten-6sgk6 update-demo-kitten-pfwjz "
Dec  3 16:01:03.641: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmwqx-5aq.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-kitten-6sgk6 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-8625'
Dec  3 16:01:03.728: INFO: stderr: ""
Dec  3 16:01:03.728: INFO: stdout: "true"
Dec  3 16:01:03.728: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmwqx-5aq.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-kitten-6sgk6 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-8625'
Dec  3 16:01:03.816: INFO: stderr: ""
Dec  3 16:01:03.816: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Dec  3 16:01:03.816: INFO: validating pod update-demo-kitten-6sgk6
Dec  3 16:01:03.912: INFO: got data: {
  "image": "kitten.jpg"
}

Dec  3 16:01:03.912: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Dec  3 16:01:03.912: INFO: update-demo-kitten-6sgk6 is verified up and running
Dec  3 16:01:03.912: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmwqx-5aq.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-kitten-pfwjz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-8625'
Dec  3 16:01:04.041: INFO: stderr: ""
Dec  3 16:01:04.041: INFO: stdout: "true"
Dec  3 16:01:04.041: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmwqx-5aq.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-kitten-pfwjz -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-8625'
Dec  3 16:01:04.135: INFO: stderr: ""
Dec  3 16:01:04.135: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Dec  3 16:01:04.135: INFO: validating pod update-demo-kitten-pfwjz
Dec  3 16:01:04.231: INFO: got data: {
  "image": "kitten.jpg"
}

Dec  3 16:01:04.232: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Dec  3 16:01:04.232: INFO: update-demo-kitten-pfwjz is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 16:01:04.232: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8625" for this suite.
Dec  3 16:01:26.254: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:01:26.421: INFO: namespace kubectl-8625 deletion completed in 22.181297862s
â€¢S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 16:01:26.421: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-9248
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Dec  3 16:01:26.569: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmwqx-5aq.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config create -f - --namespace=kubectl-9248'
Dec  3 16:01:26.821: INFO: stderr: ""
Dec  3 16:01:26.821: INFO: stdout: "replicationcontroller/redis-master created\n"
Dec  3 16:01:26.821: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmwqx-5aq.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config create -f - --namespace=kubectl-9248'
Dec  3 16:01:27.124: INFO: stderr: ""
Dec  3 16:01:27.124: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Dec  3 16:01:28.130: INFO: Selector matched 1 pods for map[app:redis]
Dec  3 16:01:28.130: INFO: Found 0 / 1
Dec  3 16:01:29.130: INFO: Selector matched 1 pods for map[app:redis]
Dec  3 16:01:29.130: INFO: Found 1 / 1
Dec  3 16:01:29.130: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Dec  3 16:01:29.136: INFO: Selector matched 1 pods for map[app:redis]
Dec  3 16:01:29.136: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Dec  3 16:01:29.136: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmwqx-5aq.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config describe pod redis-master-mdn6x --namespace=kubectl-9248'
Dec  3 16:01:29.243: INFO: stderr: ""
Dec  3 16:01:29.243: INFO: stdout: "Name:           redis-master-mdn6x\nNamespace:      kubectl-9248\nPriority:       0\nNode:           izgw8afzp8040eoqk0qbhxz/10.250.31.244\nStart Time:     Tue, 03 Dec 2019 16:01:26 +0000\nLabels:         app=redis\n                role=master\nAnnotations:    cni.projectcalico.org/podIP: 100.64.1.12/32\n                kubernetes.io/psp: e2e-test-privileged-psp\nStatus:         Running\nIP:             100.64.1.12\nControlled By:  ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   docker://b1a563c816cd2ed2e770a14d0df9a8d7119ff9b5f42bbe56105f3855b3867265\n    Image:          gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Image ID:       docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Tue, 03 Dec 2019 16:01:27 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-dh8m9 (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-dh8m9:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-dh8m9\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age   From                              Message\n  ----    ------     ----  ----                              -------\n  Normal  Scheduled  3s    default-scheduler                 Successfully assigned kubectl-9248/redis-master-mdn6x to izgw8afzp8040eoqk0qbhxz\n  Normal  Pulled     2s    kubelet, izgw8afzp8040eoqk0qbhxz  Container image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\" already present on machine\n  Normal  Created    2s    kubelet, izgw8afzp8040eoqk0qbhxz  Created container redis-master\n  Normal  Started    2s    kubelet, izgw8afzp8040eoqk0qbhxz  Started container redis-master\n"
Dec  3 16:01:29.243: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmwqx-5aq.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config describe rc redis-master --namespace=kubectl-9248'
Dec  3 16:01:29.436: INFO: stderr: ""
Dec  3 16:01:29.436: INFO: stdout: "Name:         redis-master\nNamespace:    kubectl-9248\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  3s    replication-controller  Created pod: redis-master-mdn6x\n"
Dec  3 16:01:29.436: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmwqx-5aq.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config describe service redis-master --namespace=kubectl-9248'
Dec  3 16:01:29.614: INFO: stderr: ""
Dec  3 16:01:29.615: INFO: stdout: "Name:              redis-master\nNamespace:         kubectl-9248\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                100.105.196.34\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         100.64.1.12:6379\nSession Affinity:  None\nEvents:            <none>\n"
Dec  3 16:01:29.622: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmwqx-5aq.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config describe node izgw8afzp8040eoqk0qbhwz'
Dec  3 16:01:29.839: INFO: stderr: ""
Dec  3 16:01:29.839: INFO: stdout: "Name:               izgw8afzp8040eoqk0qbhwz\nRoles:              <none>\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/instance-type=ecs.sn2ne.large\n                    beta.kubernetes.io/os=linux\n                    failure-domain.beta.kubernetes.io/region=eu-central-1\n                    failure-domain.beta.kubernetes.io/zone=eu-central-1b\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=izgw8afzp8040eoqk0qbhwz\n                    kubernetes.io/os=linux\n                    node.kubernetes.io/role=node\n                    topology.diskplugin.csi.alibabacloud.com/zone=eu-central-1b\n                    worker.garden.sapcloud.io/group=worker-1\n                    worker.gardener.cloud/pool=worker-1\nAnnotations:        csi.volume.kubernetes.io/nodeid: {\"diskplugin.csi.alibabacloud.com\":\"i-gw8afzp8040eoqk0qbhw\"}\n                    node.alpha.kubernetes.io/ttl: 0\n                    projectcalico.org/IPv4Address: 10.250.31.245/19\n                    projectcalico.org/IPv4IPIPTunnelAddr: 100.64.0.1\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Tue, 03 Dec 2019 14:26:11 +0000\nTaints:             <none>\nUnschedulable:      false\nConditions:\n  Type                          Status  LastHeartbeatTime                 LastTransitionTime                Reason                          Message\n  ----                          ------  -----------------                 ------------------                ------                          -------\n  FrequentKubeletRestart        False   Tue, 03 Dec 2019 16:01:22 +0000   Tue, 03 Dec 2019 14:27:27 +0000   NoFrequentKubeletRestart        kubelet is functioning properly\n  FrequentDockerRestart         False   Tue, 03 Dec 2019 16:01:22 +0000   Tue, 03 Dec 2019 14:27:27 +0000   NoFrequentDockerRestart         docker is functioning properly\n  FrequentContainerdRestart     False   Tue, 03 Dec 2019 16:01:22 +0000   Tue, 03 Dec 2019 14:27:27 +0000   NoFrequentContainerdRestart     containerd is functioning properly\n  KernelDeadlock                False   Tue, 03 Dec 2019 16:01:22 +0000   Tue, 03 Dec 2019 14:27:27 +0000   KernelHasNoDeadlock             kernel has no deadlock\n  ReadonlyFilesystem            False   Tue, 03 Dec 2019 16:01:22 +0000   Tue, 03 Dec 2019 14:27:27 +0000   FilesystemIsNotReadOnly         Filesystem is not read-only\n  CorruptDockerOverlay2         False   Tue, 03 Dec 2019 16:01:22 +0000   Tue, 03 Dec 2019 14:27:27 +0000   NoCorruptDockerOverlay2         docker overlay2 is functioning properly\n  FrequentUnregisterNetDevice   False   Tue, 03 Dec 2019 16:01:22 +0000   Tue, 03 Dec 2019 14:27:27 +0000   NoFrequentUnregisterNetDevice   node is functioning properly\n  NetworkUnavailable            False   Tue, 03 Dec 2019 14:27:09 +0000   Tue, 03 Dec 2019 14:27:09 +0000   CalicoIsUp                      Calico is running on this node\n  MemoryPressure                False   Tue, 03 Dec 2019 16:01:20 +0000   Tue, 03 Dec 2019 14:26:11 +0000   KubeletHasSufficientMemory      kubelet has sufficient memory available\n  DiskPressure                  False   Tue, 03 Dec 2019 16:01:20 +0000   Tue, 03 Dec 2019 14:26:11 +0000   KubeletHasNoDiskPressure        kubelet has no disk pressure\n  PIDPressure                   False   Tue, 03 Dec 2019 16:01:20 +0000   Tue, 03 Dec 2019 14:26:11 +0000   KubeletHasSufficientPID         kubelet has sufficient PID available\n  Ready                         True    Tue, 03 Dec 2019 16:01:20 +0000   Tue, 03 Dec 2019 14:26:51 +0000   KubeletReady                    kubelet is posting ready status\nAddresses:\n  InternalIP:  10.250.31.245\nCapacity:\n attachable-volumes-csi-diskplugin.csi.alibabacloud.com:  15\n cpu:                                                     2\n ephemeral-storage:                                       33136428Ki\n hugepages-1Gi:                                           0\n hugepages-2Mi:                                           0\n memory:                                                  8169216Ki\n pods:                                                    110\nAllocatable:\n attachable-volumes-csi-diskplugin.csi.alibabacloud.com:  15\n cpu:                                                     1920m\n ephemeral-storage:                                       32235117134\n hugepages-1Gi:                                           0\n hugepages-2Mi:                                           0\n memory:                                                  6873271495\n pods:                                                    110\nSystem Info:\n Machine ID:                 926bf36fac504f7c98b1e08ea6a32fb4\n System UUID:                926bf36f-ac50-4f7c-98b1-e08ea6a32fb4\n Boot ID:                    a8d933dd-a4b5-4302-84f2-080ca3c5e246\n Kernel Version:             4.19.66-coreos\n OS Image:                   Container Linux by CoreOS 2191.4.1 (Rhyolite)\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  docker://18.6.3\n Kubelet Version:            v1.15.6\n Kube-Proxy Version:         v1.15.6\nPodCIDR:                     100.64.0.0/24\nProviderID:                  eu-central-1.i-gw8afzp8040eoqk0qbhw\nNon-terminated Pods:         (16 in total)\n  Namespace                  Name                                                              CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                  ----                                                              ------------  ----------  ---------------  -------------  ---\n  kube-system                addons-kubernetes-dashboard-5c8d9945bc-8pg45                      50m (2%)      100m (5%)   50Mi (0%)        256Mi (3%)     97m\n  kube-system                addons-nginx-ingress-controller-8468678b64-fjw65                  100m (5%)     2 (104%)    100Mi (1%)       1Gi (15%)      97m\n  kube-system                addons-nginx-ingress-nginx-ingress-k8s-backend-88d6cff74-c9t7s    0 (0%)        0 (0%)      0 (0%)           0 (0%)         97m\n  kube-system                blackbox-exporter-c87bdd467-vpznr                                 5m (0%)       10m (0%)    5Mi (0%)         35Mi (0%)      97m\n  kube-system                calico-kube-controllers-5d785bc598-n44xt                          0 (0%)        0 (0%)      0 (0%)           0 (0%)         97m\n  kube-system                calico-node-7g9r2                                                 100m (5%)     500m (26%)  100Mi (1%)       700Mi (10%)    95m\n  kube-system                calico-typha-horizontal-autoscaler-554dfbfdd7-hrqhh               10m (0%)      10m (0%)    0 (0%)           0 (0%)         97m\n  kube-system                calico-typha-vertical-autoscaler-656557779f-vhn2k                 0 (0%)        0 (0%)      0 (0%)           0 (0%)         97m\n  kube-system                coredns-858b686868-4hmrg                                          50m (2%)      100m (5%)   15Mi (0%)        100Mi (1%)     97m\n  kube-system                coredns-858b686868-b8rw9                                          50m (2%)      100m (5%)   15Mi (0%)        100Mi (1%)     97m\n  kube-system                csi-disk-plugin-alicloud-zkswz                                    0 (0%)        0 (0%)      0 (0%)           0 (0%)         94m\n  kube-system                kube-proxy-6sx94                                                  20m (1%)      0 (0%)      64Mi (0%)        0 (0%)         95m\n  kube-system                metrics-server-85dc4959bc-8q2rm                                   20m (1%)      80m (4%)    100Mi (1%)       400Mi (6%)     97m\n  kube-system                node-exporter-mt7nx                                               5m (0%)       25m (1%)    10Mi (0%)        100Mi (1%)     95m\n  kube-system                node-problem-detector-zgkv5                                       20m (1%)      200m (10%)  20Mi (0%)        100Mi (1%)     95m\n  kube-system                vpn-shoot-6568b69f46-dhptx                                        100m (5%)     1 (52%)     100Mi (1%)       1000Mi (15%)   97m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource                                                Requests    Limits\n  --------                                                --------    ------\n  cpu                                                     530m (27%)  4125m (214%)\n  memory                                                  579Mi (8%)  3815Mi (58%)\n  ephemeral-storage                                       0 (0%)      0 (0%)\n  attachable-volumes-csi-diskplugin.csi.alibabacloud.com  0           0\nEvents:                                                   <none>\n"
Dec  3 16:01:29.840: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmwqx-5aq.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config describe namespace kubectl-9248'
Dec  3 16:01:30.018: INFO: stderr: ""
Dec  3 16:01:30.018: INFO: stdout: "Name:         kubectl-9248\nLabels:       e2e-framework=kubectl\n              e2e-run=db7a8e30-0527-4959-a38a-c797d2f95ed8\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 16:01:30.018: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9248" for this suite.
Dec  3 16:01:52.043: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:01:52.223: INFO: namespace kubectl-9248 deletion completed in 22.196265961s
â€¢SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 16:01:52.224: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-526
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod busybox-c3afa0d6-2962-474a-94f6-09892e42065d in namespace container-probe-526
Dec  3 16:01:54.389: INFO: Started pod busybox-c3afa0d6-2962-474a-94f6-09892e42065d in namespace container-probe-526
STEP: checking the pod's current state and verifying that restartCount is present
Dec  3 16:01:54.393: INFO: Initial restart count of pod busybox-c3afa0d6-2962-474a-94f6-09892e42065d is 0
Dec  3 16:02:44.533: INFO: Restart count of pod container-probe-526/busybox-c3afa0d6-2962-474a-94f6-09892e42065d is now 1 (50.140310544s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 16:02:44.541: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-526" for this suite.
Dec  3 16:02:50.564: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:02:50.772: INFO: namespace container-probe-526 deletion completed in 6.222589368s
â€¢
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 16:02:50.772: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-4271
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1420
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Dec  3 16:02:50.918: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmwqx-5aq.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-4271'
Dec  3 16:02:51.312: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Dec  3 16:02:51.312: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1426
Dec  3 16:02:51.319: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmwqx-5aq.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config delete deployment e2e-test-nginx-deployment --namespace=kubectl-4271'
Dec  3 16:02:51.420: INFO: stderr: ""
Dec  3 16:02:51.421: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 16:02:51.421: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4271" for this suite.
Dec  3 16:03:13.442: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:03:13.602: INFO: namespace kubectl-4271 deletion completed in 22.175480717s
â€¢SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 16:03:13.602: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-2743
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating the pod
Dec  3 16:03:16.299: INFO: Successfully updated pod "annotationupdate69e5d5c3-e128-4487-ac63-b073132d1753"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 16:03:20.367: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2743" for this suite.
Dec  3 16:03:42.390: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:03:42.550: INFO: namespace downward-api-2743 deletion completed in 22.174492162s
â€¢SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 16:03:42.550: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-881
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-d7c78ecc-d7d0-4cc8-96b7-d1d567229a05
STEP: Creating a pod to test consume secrets
Dec  3 16:03:42.706: INFO: Waiting up to 5m0s for pod "pod-secrets-8b14b738-ca2b-4e54-b994-1e9b26ace10d" in namespace "secrets-881" to be "success or failure"
Dec  3 16:03:42.710: INFO: Pod "pod-secrets-8b14b738-ca2b-4e54-b994-1e9b26ace10d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.232341ms
Dec  3 16:03:44.715: INFO: Pod "pod-secrets-8b14b738-ca2b-4e54-b994-1e9b26ace10d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009749199s
STEP: Saw pod success
Dec  3 16:03:44.715: INFO: Pod "pod-secrets-8b14b738-ca2b-4e54-b994-1e9b26ace10d" satisfied condition "success or failure"
Dec  3 16:03:44.720: INFO: Trying to get logs from node izgw8afzp8040eoqk0qbhxz pod pod-secrets-8b14b738-ca2b-4e54-b994-1e9b26ace10d container secret-volume-test: <nil>
STEP: delete the pod
Dec  3 16:03:44.743: INFO: Waiting for pod pod-secrets-8b14b738-ca2b-4e54-b994-1e9b26ace10d to disappear
Dec  3 16:03:44.747: INFO: Pod pod-secrets-8b14b738-ca2b-4e54-b994-1e9b26ace10d no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 16:03:44.747: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-881" for this suite.
Dec  3 16:03:50.769: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:03:50.977: INFO: namespace secrets-881 deletion completed in 6.222680845s
â€¢SSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 16:03:50.978: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8277
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-4f0be46c-d6a8-4634-92f1-060ee6f4d851
STEP: Creating a pod to test consume secrets
Dec  3 16:03:51.137: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-b0838159-048f-400b-ade1-0c1108a318ad" in namespace "projected-8277" to be "success or failure"
Dec  3 16:03:51.142: INFO: Pod "pod-projected-secrets-b0838159-048f-400b-ade1-0c1108a318ad": Phase="Pending", Reason="", readiness=false. Elapsed: 4.610193ms
Dec  3 16:03:53.147: INFO: Pod "pod-projected-secrets-b0838159-048f-400b-ade1-0c1108a318ad": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01031612s
STEP: Saw pod success
Dec  3 16:03:53.147: INFO: Pod "pod-projected-secrets-b0838159-048f-400b-ade1-0c1108a318ad" satisfied condition "success or failure"
Dec  3 16:03:53.152: INFO: Trying to get logs from node izgw8afzp8040eoqk0qbhxz pod pod-projected-secrets-b0838159-048f-400b-ade1-0c1108a318ad container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec  3 16:03:53.171: INFO: Waiting for pod pod-projected-secrets-b0838159-048f-400b-ade1-0c1108a318ad to disappear
Dec  3 16:03:53.174: INFO: Pod pod-projected-secrets-b0838159-048f-400b-ade1-0c1108a318ad no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 16:03:53.175: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8277" for this suite.
Dec  3 16:03:59.196: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:03:59.362: INFO: namespace projected-8277 deletion completed in 6.179503734s
â€¢SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 16:03:59.362: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-432
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-38c10522-ec7e-4e86-a2a6-7e1d8032ef35
STEP: Creating a pod to test consume secrets
Dec  3 16:03:59.521: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-e4573882-bf97-4500-ae14-de8f6c96e813" in namespace "projected-432" to be "success or failure"
Dec  3 16:03:59.525: INFO: Pod "pod-projected-secrets-e4573882-bf97-4500-ae14-de8f6c96e813": Phase="Pending", Reason="", readiness=false. Elapsed: 4.623981ms
Dec  3 16:04:01.531: INFO: Pod "pod-projected-secrets-e4573882-bf97-4500-ae14-de8f6c96e813": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01030824s
STEP: Saw pod success
Dec  3 16:04:01.531: INFO: Pod "pod-projected-secrets-e4573882-bf97-4500-ae14-de8f6c96e813" satisfied condition "success or failure"
Dec  3 16:04:01.536: INFO: Trying to get logs from node izgw8afzp8040eoqk0qbhxz pod pod-projected-secrets-e4573882-bf97-4500-ae14-de8f6c96e813 container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec  3 16:04:01.559: INFO: Waiting for pod pod-projected-secrets-e4573882-bf97-4500-ae14-de8f6c96e813 to disappear
Dec  3 16:04:01.564: INFO: Pod pod-projected-secrets-e4573882-bf97-4500-ae14-de8f6c96e813 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 16:04:01.564: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-432" for this suite.
Dec  3 16:04:07.589: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:04:07.753: INFO: namespace projected-432 deletion completed in 6.180191119s
â€¢SSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 16:04:07.753: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-8657
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test substitution in container's command
Dec  3 16:04:07.907: INFO: Waiting up to 5m0s for pod "var-expansion-e785fce9-8102-4c1d-bb0b-1cd3fe144cf0" in namespace "var-expansion-8657" to be "success or failure"
Dec  3 16:04:07.912: INFO: Pod "var-expansion-e785fce9-8102-4c1d-bb0b-1cd3fe144cf0": Phase="Pending", Reason="", readiness=false. Elapsed: 4.481108ms
Dec  3 16:04:09.917: INFO: Pod "var-expansion-e785fce9-8102-4c1d-bb0b-1cd3fe144cf0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009790831s
STEP: Saw pod success
Dec  3 16:04:09.917: INFO: Pod "var-expansion-e785fce9-8102-4c1d-bb0b-1cd3fe144cf0" satisfied condition "success or failure"
Dec  3 16:04:09.922: INFO: Trying to get logs from node izgw8afzp8040eoqk0qbhxz pod var-expansion-e785fce9-8102-4c1d-bb0b-1cd3fe144cf0 container dapi-container: <nil>
STEP: delete the pod
Dec  3 16:04:09.943: INFO: Waiting for pod var-expansion-e785fce9-8102-4c1d-bb0b-1cd3fe144cf0 to disappear
Dec  3 16:04:09.946: INFO: Pod var-expansion-e785fce9-8102-4c1d-bb0b-1cd3fe144cf0 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 16:04:09.947: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-8657" for this suite.
Dec  3 16:04:15.968: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:04:16.131: INFO: namespace var-expansion-8657 deletion completed in 6.177700037s
â€¢SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 16:04:16.132: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-539
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:179
[It] should be submitted and removed  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 16:04:16.287: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-539" for this suite.
Dec  3 16:04:38.305: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:04:38.471: INFO: namespace pods-539 deletion completed in 22.179581094s
â€¢SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 16:04:38.472: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-8775
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
Dec  3 16:04:38.624: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 16:04:41.955: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-8775" for this suite.
Dec  3 16:04:47.976: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:04:48.145: INFO: namespace init-container-8775 deletion completed in 6.182351414s
â€¢SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 16:04:48.145: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-8258
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-7710abcf-8511-442a-89b4-c76e1b7f23ff
STEP: Creating a pod to test consume secrets
Dec  3 16:04:48.302: INFO: Waiting up to 5m0s for pod "pod-secrets-2c0e5451-81d4-4a05-814a-32c783efad9e" in namespace "secrets-8258" to be "success or failure"
Dec  3 16:04:48.306: INFO: Pod "pod-secrets-2c0e5451-81d4-4a05-814a-32c783efad9e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.012442ms
Dec  3 16:04:50.312: INFO: Pod "pod-secrets-2c0e5451-81d4-4a05-814a-32c783efad9e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00961899s
STEP: Saw pod success
Dec  3 16:04:50.312: INFO: Pod "pod-secrets-2c0e5451-81d4-4a05-814a-32c783efad9e" satisfied condition "success or failure"
Dec  3 16:04:50.316: INFO: Trying to get logs from node izgw8afzp8040eoqk0qbhxz pod pod-secrets-2c0e5451-81d4-4a05-814a-32c783efad9e container secret-volume-test: <nil>
STEP: delete the pod
Dec  3 16:04:50.337: INFO: Waiting for pod pod-secrets-2c0e5451-81d4-4a05-814a-32c783efad9e to disappear
Dec  3 16:04:50.341: INFO: Pod pod-secrets-2c0e5451-81d4-4a05-814a-32c783efad9e no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 16:04:50.341: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8258" for this suite.
Dec  3 16:04:56.364: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:04:56.533: INFO: namespace secrets-8258 deletion completed in 6.182993138s
â€¢SSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 16:04:56.533: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-6227
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-ae121efe-0417-4eda-a302-d34374619cf9
STEP: Creating a pod to test consume configMaps
Dec  3 16:04:56.693: INFO: Waiting up to 5m0s for pod "pod-configmaps-b84a690d-0936-4dad-8876-fc35236eadca" in namespace "configmap-6227" to be "success or failure"
Dec  3 16:04:56.698: INFO: Pod "pod-configmaps-b84a690d-0936-4dad-8876-fc35236eadca": Phase="Pending", Reason="", readiness=false. Elapsed: 4.397556ms
Dec  3 16:04:58.703: INFO: Pod "pod-configmaps-b84a690d-0936-4dad-8876-fc35236eadca": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009645903s
STEP: Saw pod success
Dec  3 16:04:58.703: INFO: Pod "pod-configmaps-b84a690d-0936-4dad-8876-fc35236eadca" satisfied condition "success or failure"
Dec  3 16:04:58.708: INFO: Trying to get logs from node izgw8afzp8040eoqk0qbhxz pod pod-configmaps-b84a690d-0936-4dad-8876-fc35236eadca container configmap-volume-test: <nil>
STEP: delete the pod
Dec  3 16:04:58.730: INFO: Waiting for pod pod-configmaps-b84a690d-0936-4dad-8876-fc35236eadca to disappear
Dec  3 16:04:58.734: INFO: Pod pod-configmaps-b84a690d-0936-4dad-8876-fc35236eadca no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 16:04:58.734: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6227" for this suite.
Dec  3 16:05:04.757: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:05:04.932: INFO: namespace configmap-6227 deletion completed in 6.189504649s
â€¢SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 16:05:04.933: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-425
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating pod
Dec  3 16:05:07.105: INFO: Pod pod-hostip-17725b6a-f4b5-458c-9442-3e004181121b has hostIP: 10.250.31.244
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 16:05:07.106: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-425" for this suite.
Dec  3 16:05:29.130: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:05:29.298: INFO: namespace pods-425 deletion completed in 22.183743611s
â€¢SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 16:05:29.298: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3398
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Dec  3 16:05:29.451: INFO: Waiting up to 5m0s for pod "downwardapi-volume-5db76ad3-bc4f-45cb-bf83-53175aac9243" in namespace "projected-3398" to be "success or failure"
Dec  3 16:05:29.455: INFO: Pod "downwardapi-volume-5db76ad3-bc4f-45cb-bf83-53175aac9243": Phase="Pending", Reason="", readiness=false. Elapsed: 4.304373ms
Dec  3 16:05:31.461: INFO: Pod "downwardapi-volume-5db76ad3-bc4f-45cb-bf83-53175aac9243": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009834106s
STEP: Saw pod success
Dec  3 16:05:31.461: INFO: Pod "downwardapi-volume-5db76ad3-bc4f-45cb-bf83-53175aac9243" satisfied condition "success or failure"
Dec  3 16:05:31.465: INFO: Trying to get logs from node izgw8afzp8040eoqk0qbhxz pod downwardapi-volume-5db76ad3-bc4f-45cb-bf83-53175aac9243 container client-container: <nil>
STEP: delete the pod
Dec  3 16:05:31.488: INFO: Waiting for pod downwardapi-volume-5db76ad3-bc4f-45cb-bf83-53175aac9243 to disappear
Dec  3 16:05:31.492: INFO: Pod downwardapi-volume-5db76ad3-bc4f-45cb-bf83-53175aac9243 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 16:05:31.492: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3398" for this suite.
Dec  3 16:05:37.514: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:05:37.687: INFO: namespace projected-3398 deletion completed in 6.187859932s
â€¢SSSSSSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 16:05:37.688: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-4533
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod liveness-fcd0af65-a301-4716-a437-a1a63e787407 in namespace container-probe-4533
Dec  3 16:05:39.850: INFO: Started pod liveness-fcd0af65-a301-4716-a437-a1a63e787407 in namespace container-probe-4533
STEP: checking the pod's current state and verifying that restartCount is present
Dec  3 16:05:39.859: INFO: Initial restart count of pod liveness-fcd0af65-a301-4716-a437-a1a63e787407 is 0
Dec  3 16:05:55.907: INFO: Restart count of pod container-probe-4533/liveness-fcd0af65-a301-4716-a437-a1a63e787407 is now 1 (16.048225721s elapsed)
Dec  3 16:06:15.960: INFO: Restart count of pod container-probe-4533/liveness-fcd0af65-a301-4716-a437-a1a63e787407 is now 2 (36.10128272s elapsed)
Dec  3 16:06:36.014: INFO: Restart count of pod container-probe-4533/liveness-fcd0af65-a301-4716-a437-a1a63e787407 is now 3 (56.15519326s elapsed)
Dec  3 16:06:54.062: INFO: Restart count of pod container-probe-4533/liveness-fcd0af65-a301-4716-a437-a1a63e787407 is now 4 (1m14.203412006s elapsed)
Dec  3 16:07:58.237: INFO: Restart count of pod container-probe-4533/liveness-fcd0af65-a301-4716-a437-a1a63e787407 is now 5 (2m18.378347716s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 16:07:58.245: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-4533" for this suite.
Dec  3 16:08:04.268: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:08:04.442: INFO: namespace container-probe-4533 deletion completed in 6.188856736s
â€¢SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 16:08:04.442: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-709
STEP: Waiting for a default service account to be provisioned in namespace
[It] should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: starting a background goroutine to produce watch events
STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 16:08:09.649: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-709" for this suite.
Dec  3 16:08:15.804: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:08:15.967: INFO: namespace watch-709 deletion completed in 6.2673426s
â€¢SSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 16:08:15.967: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7755
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Dec  3 16:08:16.120: INFO: Waiting up to 5m0s for pod "downwardapi-volume-371924f6-7579-4e87-ac56-5003eb3fcc96" in namespace "projected-7755" to be "success or failure"
Dec  3 16:08:16.124: INFO: Pod "downwardapi-volume-371924f6-7579-4e87-ac56-5003eb3fcc96": Phase="Pending", Reason="", readiness=false. Elapsed: 4.329352ms
Dec  3 16:08:18.129: INFO: Pod "downwardapi-volume-371924f6-7579-4e87-ac56-5003eb3fcc96": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009743362s
STEP: Saw pod success
Dec  3 16:08:18.129: INFO: Pod "downwardapi-volume-371924f6-7579-4e87-ac56-5003eb3fcc96" satisfied condition "success or failure"
Dec  3 16:08:18.134: INFO: Trying to get logs from node izgw8afzp8040eoqk0qbhxz pod downwardapi-volume-371924f6-7579-4e87-ac56-5003eb3fcc96 container client-container: <nil>
STEP: delete the pod
Dec  3 16:08:18.159: INFO: Waiting for pod downwardapi-volume-371924f6-7579-4e87-ac56-5003eb3fcc96 to disappear
Dec  3 16:08:18.163: INFO: Pod downwardapi-volume-371924f6-7579-4e87-ac56-5003eb3fcc96 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 16:08:18.163: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7755" for this suite.
Dec  3 16:08:24.185: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:08:24.350: INFO: namespace projected-7755 deletion completed in 6.179889614s
â€¢SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 16:08:24.351: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-955
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1292
STEP: creating an rc
Dec  3 16:08:24.495: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmwqx-5aq.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config create -f - --namespace=kubectl-955'
Dec  3 16:08:24.717: INFO: stderr: ""
Dec  3 16:08:24.717: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Waiting for Redis master to start.
Dec  3 16:08:25.723: INFO: Selector matched 1 pods for map[app:redis]
Dec  3 16:08:25.723: INFO: Found 0 / 1
Dec  3 16:08:26.722: INFO: Selector matched 1 pods for map[app:redis]
Dec  3 16:08:26.723: INFO: Found 1 / 1
Dec  3 16:08:26.723: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Dec  3 16:08:26.727: INFO: Selector matched 1 pods for map[app:redis]
Dec  3 16:08:26.727: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
STEP: checking for a matching strings
Dec  3 16:08:26.728: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmwqx-5aq.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config logs redis-master-k98hz redis-master --namespace=kubectl-955'
Dec  3 16:08:26.930: INFO: stderr: ""
Dec  3 16:08:26.930: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 03 Dec 16:08:25.688 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 03 Dec 16:08:25.688 # Server started, Redis version 3.2.12\n1:M 03 Dec 16:08:25.688 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 03 Dec 16:08:25.689 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log lines
Dec  3 16:08:26.930: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmwqx-5aq.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config logs redis-master-k98hz redis-master --namespace=kubectl-955 --tail=1'
Dec  3 16:08:27.040: INFO: stderr: ""
Dec  3 16:08:27.040: INFO: stdout: "1:M 03 Dec 16:08:25.689 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log bytes
Dec  3 16:08:27.041: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmwqx-5aq.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config logs redis-master-k98hz redis-master --namespace=kubectl-955 --limit-bytes=1'
Dec  3 16:08:27.144: INFO: stderr: ""
Dec  3 16:08:27.144: INFO: stdout: " "
STEP: exposing timestamps
Dec  3 16:08:27.144: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmwqx-5aq.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config logs redis-master-k98hz redis-master --namespace=kubectl-955 --tail=1 --timestamps'
Dec  3 16:08:27.287: INFO: stderr: ""
Dec  3 16:08:27.287: INFO: stdout: "2019-12-03T16:08:25.693604364Z 1:M 03 Dec 16:08:25.689 * The server is now ready to accept connections on port 6379\n"
STEP: restricting to a time range
Dec  3 16:08:29.787: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmwqx-5aq.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config logs redis-master-k98hz redis-master --namespace=kubectl-955 --since=1s'
Dec  3 16:08:29.948: INFO: stderr: ""
Dec  3 16:08:29.948: INFO: stdout: ""
Dec  3 16:08:29.948: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmwqx-5aq.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config logs redis-master-k98hz redis-master --namespace=kubectl-955 --since=24h'
Dec  3 16:08:30.105: INFO: stderr: ""
Dec  3 16:08:30.105: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 03 Dec 16:08:25.688 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 03 Dec 16:08:25.688 # Server started, Redis version 3.2.12\n1:M 03 Dec 16:08:25.688 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 03 Dec 16:08:25.689 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1298
STEP: using delete to clean up resources
Dec  3 16:08:30.106: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmwqx-5aq.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config delete --grace-period=0 --force -f - --namespace=kubectl-955'
Dec  3 16:08:30.202: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  3 16:08:30.202: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
Dec  3 16:08:30.202: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmwqx-5aq.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get rc,svc -l name=nginx --no-headers --namespace=kubectl-955'
Dec  3 16:08:30.303: INFO: stderr: "No resources found.\n"
Dec  3 16:08:30.303: INFO: stdout: ""
Dec  3 16:08:30.303: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmwqx-5aq.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods -l name=nginx --namespace=kubectl-955 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec  3 16:08:30.437: INFO: stderr: ""
Dec  3 16:08:30.437: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 16:08:30.438: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-955" for this suite.
Dec  3 16:08:36.462: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:08:36.624: INFO: namespace kubectl-955 deletion completed in 6.177828117s
â€¢SSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 16:08:36.624: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-8712
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-secret-gjlp
STEP: Creating a pod to test atomic-volume-subpath
Dec  3 16:08:36.787: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-gjlp" in namespace "subpath-8712" to be "success or failure"
Dec  3 16:08:36.791: INFO: Pod "pod-subpath-test-secret-gjlp": Phase="Pending", Reason="", readiness=false. Elapsed: 4.11728ms
Dec  3 16:08:38.796: INFO: Pod "pod-subpath-test-secret-gjlp": Phase="Running", Reason="", readiness=true. Elapsed: 2.00913275s
Dec  3 16:08:40.802: INFO: Pod "pod-subpath-test-secret-gjlp": Phase="Running", Reason="", readiness=true. Elapsed: 4.014684054s
Dec  3 16:08:42.807: INFO: Pod "pod-subpath-test-secret-gjlp": Phase="Running", Reason="", readiness=true. Elapsed: 6.02008326s
Dec  3 16:08:44.812: INFO: Pod "pod-subpath-test-secret-gjlp": Phase="Running", Reason="", readiness=true. Elapsed: 8.025552036s
Dec  3 16:08:46.818: INFO: Pod "pod-subpath-test-secret-gjlp": Phase="Running", Reason="", readiness=true. Elapsed: 10.030927747s
Dec  3 16:08:48.823: INFO: Pod "pod-subpath-test-secret-gjlp": Phase="Running", Reason="", readiness=true. Elapsed: 12.03649785s
Dec  3 16:08:50.829: INFO: Pod "pod-subpath-test-secret-gjlp": Phase="Running", Reason="", readiness=true. Elapsed: 14.041969813s
Dec  3 16:08:52.834: INFO: Pod "pod-subpath-test-secret-gjlp": Phase="Running", Reason="", readiness=true. Elapsed: 16.047557615s
Dec  3 16:08:54.840: INFO: Pod "pod-subpath-test-secret-gjlp": Phase="Running", Reason="", readiness=true. Elapsed: 18.05281738s
Dec  3 16:08:56.845: INFO: Pod "pod-subpath-test-secret-gjlp": Phase="Running", Reason="", readiness=true. Elapsed: 20.058009387s
Dec  3 16:08:58.850: INFO: Pod "pod-subpath-test-secret-gjlp": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.063450018s
STEP: Saw pod success
Dec  3 16:08:58.850: INFO: Pod "pod-subpath-test-secret-gjlp" satisfied condition "success or failure"
Dec  3 16:08:58.855: INFO: Trying to get logs from node izgw8afzp8040eoqk0qbhxz pod pod-subpath-test-secret-gjlp container test-container-subpath-secret-gjlp: <nil>
STEP: delete the pod
Dec  3 16:08:58.878: INFO: Waiting for pod pod-subpath-test-secret-gjlp to disappear
Dec  3 16:08:58.882: INFO: Pod pod-subpath-test-secret-gjlp no longer exists
STEP: Deleting pod pod-subpath-test-secret-gjlp
Dec  3 16:08:58.882: INFO: Deleting pod "pod-subpath-test-secret-gjlp" in namespace "subpath-8712"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 16:08:58.886: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-8712" for this suite.
Dec  3 16:09:04.908: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:09:05.079: INFO: namespace subpath-8712 deletion completed in 6.184417373s
â€¢SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 16:09:05.079: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-4364
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-c64e6ccb-6275-4256-a090-b33b87e5fd91
STEP: Creating a pod to test consume secrets
Dec  3 16:09:05.237: INFO: Waiting up to 5m0s for pod "pod-secrets-0d30b82b-5e22-4167-aa6f-a3b423578652" in namespace "secrets-4364" to be "success or failure"
Dec  3 16:09:05.241: INFO: Pod "pod-secrets-0d30b82b-5e22-4167-aa6f-a3b423578652": Phase="Pending", Reason="", readiness=false. Elapsed: 4.099611ms
Dec  3 16:09:07.247: INFO: Pod "pod-secrets-0d30b82b-5e22-4167-aa6f-a3b423578652": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009451595s
STEP: Saw pod success
Dec  3 16:09:07.247: INFO: Pod "pod-secrets-0d30b82b-5e22-4167-aa6f-a3b423578652" satisfied condition "success or failure"
Dec  3 16:09:07.251: INFO: Trying to get logs from node izgw8afzp8040eoqk0qbhxz pod pod-secrets-0d30b82b-5e22-4167-aa6f-a3b423578652 container secret-env-test: <nil>
STEP: delete the pod
Dec  3 16:09:07.275: INFO: Waiting for pod pod-secrets-0d30b82b-5e22-4167-aa6f-a3b423578652 to disappear
Dec  3 16:09:07.279: INFO: Pod pod-secrets-0d30b82b-5e22-4167-aa6f-a3b423578652 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 16:09:07.279: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-4364" for this suite.
Dec  3 16:09:13.301: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:09:13.511: INFO: namespace secrets-4364 deletion completed in 6.224852487s
â€¢SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 16:09:13.513: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-7698
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Dec  3 16:09:13.685: INFO: Create a RollingUpdate DaemonSet
Dec  3 16:09:13.690: INFO: Check that daemon pods launch on every node of the cluster
Dec  3 16:09:13.700: INFO: Number of nodes with available pods: 0
Dec  3 16:09:13.700: INFO: Node izgw8afzp8040eoqk0qbhwz is running more than one daemon pod
Dec  3 16:09:14.713: INFO: Number of nodes with available pods: 0
Dec  3 16:09:14.713: INFO: Node izgw8afzp8040eoqk0qbhwz is running more than one daemon pod
Dec  3 16:09:15.713: INFO: Number of nodes with available pods: 2
Dec  3 16:09:15.713: INFO: Number of running nodes: 2, number of available pods: 2
Dec  3 16:09:15.713: INFO: Update the DaemonSet to trigger a rollout
Dec  3 16:09:15.723: INFO: Updating DaemonSet daemon-set
Dec  3 16:09:21.746: INFO: Roll back the DaemonSet before rollout is complete
Dec  3 16:09:21.755: INFO: Updating DaemonSet daemon-set
Dec  3 16:09:21.755: INFO: Make sure DaemonSet rollback is complete
Dec  3 16:09:21.760: INFO: Wrong image for pod: daemon-set-p9hcm. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Dec  3 16:09:21.760: INFO: Pod daemon-set-p9hcm is not available
Dec  3 16:09:22.770: INFO: Wrong image for pod: daemon-set-p9hcm. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Dec  3 16:09:22.770: INFO: Pod daemon-set-p9hcm is not available
Dec  3 16:09:23.770: INFO: Wrong image for pod: daemon-set-p9hcm. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Dec  3 16:09:23.770: INFO: Pod daemon-set-p9hcm is not available
Dec  3 16:09:24.771: INFO: Pod daemon-set-8g6bn is not available
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-7698, will wait for the garbage collector to delete the pods
Dec  3 16:09:24.849: INFO: Deleting DaemonSet.extensions daemon-set took: 7.305614ms
Dec  3 16:09:24.950: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.335958ms
Dec  3 16:09:35.655: INFO: Number of nodes with available pods: 0
Dec  3 16:09:35.655: INFO: Number of running nodes: 0, number of available pods: 0
Dec  3 16:09:35.659: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-7698/daemonsets","resourceVersion":"28336"},"items":null}

Dec  3 16:09:35.663: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-7698/pods","resourceVersion":"28336"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 16:09:35.681: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-7698" for this suite.
Dec  3 16:09:41.700: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:09:41.870: INFO: namespace daemonsets-7698 deletion completed in 6.184041911s
â€¢SSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 16:09:41.870: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-1774
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-configmap-m6d4
STEP: Creating a pod to test atomic-volume-subpath
Dec  3 16:09:42.035: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-m6d4" in namespace "subpath-1774" to be "success or failure"
Dec  3 16:09:42.039: INFO: Pod "pod-subpath-test-configmap-m6d4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.387038ms
Dec  3 16:09:44.045: INFO: Pod "pod-subpath-test-configmap-m6d4": Phase="Running", Reason="", readiness=true. Elapsed: 2.009776614s
Dec  3 16:09:46.050: INFO: Pod "pod-subpath-test-configmap-m6d4": Phase="Running", Reason="", readiness=true. Elapsed: 4.01485492s
Dec  3 16:09:48.056: INFO: Pod "pod-subpath-test-configmap-m6d4": Phase="Running", Reason="", readiness=true. Elapsed: 6.020684782s
Dec  3 16:09:50.061: INFO: Pod "pod-subpath-test-configmap-m6d4": Phase="Running", Reason="", readiness=true. Elapsed: 8.026071175s
Dec  3 16:09:52.066: INFO: Pod "pod-subpath-test-configmap-m6d4": Phase="Running", Reason="", readiness=true. Elapsed: 10.03156651s
Dec  3 16:09:54.072: INFO: Pod "pod-subpath-test-configmap-m6d4": Phase="Running", Reason="", readiness=true. Elapsed: 12.036902233s
Dec  3 16:09:56.077: INFO: Pod "pod-subpath-test-configmap-m6d4": Phase="Running", Reason="", readiness=true. Elapsed: 14.042350765s
Dec  3 16:09:58.083: INFO: Pod "pod-subpath-test-configmap-m6d4": Phase="Running", Reason="", readiness=true. Elapsed: 16.047976846s
Dec  3 16:10:00.088: INFO: Pod "pod-subpath-test-configmap-m6d4": Phase="Running", Reason="", readiness=true. Elapsed: 18.053523491s
Dec  3 16:10:02.094: INFO: Pod "pod-subpath-test-configmap-m6d4": Phase="Running", Reason="", readiness=true. Elapsed: 20.058803925s
Dec  3 16:10:04.102: INFO: Pod "pod-subpath-test-configmap-m6d4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.06711079s
STEP: Saw pod success
Dec  3 16:10:04.102: INFO: Pod "pod-subpath-test-configmap-m6d4" satisfied condition "success or failure"
Dec  3 16:10:04.107: INFO: Trying to get logs from node izgw8afzp8040eoqk0qbhxz pod pod-subpath-test-configmap-m6d4 container test-container-subpath-configmap-m6d4: <nil>
STEP: delete the pod
Dec  3 16:10:04.132: INFO: Waiting for pod pod-subpath-test-configmap-m6d4 to disappear
Dec  3 16:10:04.137: INFO: Pod pod-subpath-test-configmap-m6d4 no longer exists
STEP: Deleting pod pod-subpath-test-configmap-m6d4
Dec  3 16:10:04.137: INFO: Deleting pod "pod-subpath-test-configmap-m6d4" in namespace "subpath-1774"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 16:10:04.142: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-1774" for this suite.
Dec  3 16:10:10.165: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:10:10.335: INFO: namespace subpath-1774 deletion completed in 6.185607005s
â€¢SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 16:10:10.336: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-2747
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
Dec  3 16:10:20.517: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W1203 16:10:20.517186    5085 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 16:10:20.517: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-2747" for this suite.
Dec  3 16:10:26.536: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:10:26.740: INFO: namespace gc-2747 deletion completed in 6.217949689s
â€¢SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 16:10:26.741: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-3309
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir volume type on node default medium
Dec  3 16:10:26.904: INFO: Waiting up to 5m0s for pod "pod-3273631f-b4b4-4cbb-8ad8-407e3c3fc54d" in namespace "emptydir-3309" to be "success or failure"
Dec  3 16:10:26.909: INFO: Pod "pod-3273631f-b4b4-4cbb-8ad8-407e3c3fc54d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.388614ms
Dec  3 16:10:28.914: INFO: Pod "pod-3273631f-b4b4-4cbb-8ad8-407e3c3fc54d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009963404s
Dec  3 16:10:30.920: INFO: Pod "pod-3273631f-b4b4-4cbb-8ad8-407e3c3fc54d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015323314s
STEP: Saw pod success
Dec  3 16:10:30.920: INFO: Pod "pod-3273631f-b4b4-4cbb-8ad8-407e3c3fc54d" satisfied condition "success or failure"
Dec  3 16:10:30.924: INFO: Trying to get logs from node izgw8afzp8040eoqk0qbhxz pod pod-3273631f-b4b4-4cbb-8ad8-407e3c3fc54d container test-container: <nil>
STEP: delete the pod
Dec  3 16:10:30.946: INFO: Waiting for pod pod-3273631f-b4b4-4cbb-8ad8-407e3c3fc54d to disappear
Dec  3 16:10:30.951: INFO: Pod pod-3273631f-b4b4-4cbb-8ad8-407e3c3fc54d no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 16:10:30.951: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3309" for this suite.
Dec  3 16:10:36.972: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:10:37.140: INFO: namespace emptydir-3309 deletion completed in 6.181778172s
â€¢SSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 16:10:37.141: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-8511
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:273
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a replication controller
Dec  3 16:10:37.294: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmwqx-5aq.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config create -f - --namespace=kubectl-8511'
Dec  3 16:10:37.514: INFO: stderr: ""
Dec  3 16:10:37.514: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec  3 16:10:37.514: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmwqx-5aq.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-8511'
Dec  3 16:10:37.647: INFO: stderr: ""
Dec  3 16:10:37.647: INFO: stdout: "update-demo-nautilus-dg7jx update-demo-nautilus-p4pxp "
Dec  3 16:10:37.647: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmwqx-5aq.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-dg7jx -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-8511'
Dec  3 16:10:37.781: INFO: stderr: ""
Dec  3 16:10:37.782: INFO: stdout: ""
Dec  3 16:10:37.782: INFO: update-demo-nautilus-dg7jx is created but not running
Dec  3 16:10:42.782: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmwqx-5aq.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-8511'
Dec  3 16:10:42.868: INFO: stderr: ""
Dec  3 16:10:42.868: INFO: stdout: "update-demo-nautilus-dg7jx update-demo-nautilus-p4pxp "
Dec  3 16:10:42.868: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmwqx-5aq.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-dg7jx -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-8511'
Dec  3 16:10:42.959: INFO: stderr: ""
Dec  3 16:10:42.960: INFO: stdout: "true"
Dec  3 16:10:42.960: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmwqx-5aq.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-dg7jx -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-8511'
Dec  3 16:10:43.042: INFO: stderr: ""
Dec  3 16:10:43.043: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec  3 16:10:43.043: INFO: validating pod update-demo-nautilus-dg7jx
Dec  3 16:10:43.138: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  3 16:10:43.138: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  3 16:10:43.138: INFO: update-demo-nautilus-dg7jx is verified up and running
Dec  3 16:10:43.139: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmwqx-5aq.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-p4pxp -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-8511'
Dec  3 16:10:43.227: INFO: stderr: ""
Dec  3 16:10:43.227: INFO: stdout: "true"
Dec  3 16:10:43.227: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmwqx-5aq.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-p4pxp -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-8511'
Dec  3 16:10:43.355: INFO: stderr: ""
Dec  3 16:10:43.356: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec  3 16:10:43.356: INFO: validating pod update-demo-nautilus-p4pxp
Dec  3 16:10:43.451: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  3 16:10:43.451: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  3 16:10:43.451: INFO: update-demo-nautilus-p4pxp is verified up and running
STEP: using delete to clean up resources
Dec  3 16:10:43.452: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmwqx-5aq.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config delete --grace-period=0 --force -f - --namespace=kubectl-8511'
Dec  3 16:10:43.608: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  3 16:10:43.608: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Dec  3 16:10:43.608: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmwqx-5aq.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get rc,svc -l name=update-demo --no-headers --namespace=kubectl-8511'
Dec  3 16:10:43.701: INFO: stderr: "No resources found.\n"
Dec  3 16:10:43.701: INFO: stdout: ""
Dec  3 16:10:43.701: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmwqx-5aq.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods -l name=update-demo --namespace=kubectl-8511 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec  3 16:10:43.797: INFO: stderr: ""
Dec  3 16:10:43.797: INFO: stdout: "update-demo-nautilus-dg7jx\nupdate-demo-nautilus-p4pxp\n"
Dec  3 16:10:44.297: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmwqx-5aq.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get rc,svc -l name=update-demo --no-headers --namespace=kubectl-8511'
Dec  3 16:10:44.453: INFO: stderr: "No resources found.\n"
Dec  3 16:10:44.453: INFO: stdout: ""
Dec  3 16:10:44.453: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmwqx-5aq.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods -l name=update-demo --namespace=kubectl-8511 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec  3 16:10:44.547: INFO: stderr: ""
Dec  3 16:10:44.547: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 16:10:44.547: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8511" for this suite.
Dec  3 16:10:50.572: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:10:50.744: INFO: namespace kubectl-8511 deletion completed in 6.187744399s
â€¢SSSSSSSSSSSSSDec  3 16:10:50.744: INFO: Running AfterSuite actions on all nodes
Dec  3 16:10:50.744: INFO: Running AfterSuite actions on node 1
Dec  3 16:10:50.744: INFO: Skipping dumping logs from cluster

Ran 215 of 4413 Specs in 5150.100 seconds
SUCCESS! -- 215 Passed | 0 Failed | 0 Flaked | 0 Pending | 4198 Skipped
PASS

Ginkgo ran 1 suite in 1h26m28.128221086s
Test Suite Passed
