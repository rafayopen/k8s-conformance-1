I1030 10:22:03.059648      18 test_context.go:406] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-779704590
I1030 10:22:03.059783      18 e2e.go:243] Starting e2e run "a85b9a71-388c-46b6-841d-569253640bba" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1572430921 - Will randomize all specs
Will run 215 of 4413 specs

Oct 30 10:22:03.153: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
Oct 30 10:22:03.156: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Oct 30 10:22:03.167: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Oct 30 10:22:03.194: INFO: 33 / 33 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Oct 30 10:22:03.194: INFO: expected 9 pod replicas in namespace 'kube-system', 9 are Running and Ready.
Oct 30 10:22:03.194: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Oct 30 10:22:03.200: INFO: 4 / 4 pods ready in namespace 'kube-system' in daemonset 'calico-node' (0 seconds elapsed)
Oct 30 10:22:03.200: INFO: 4 / 4 pods ready in namespace 'kube-system' in daemonset 'cert-exporter' (0 seconds elapsed)
Oct 30 10:22:03.200: INFO: 4 / 4 pods ready in namespace 'kube-system' in daemonset 'kube-proxy' (0 seconds elapsed)
Oct 30 10:22:03.200: INFO: 4 / 4 pods ready in namespace 'kube-system' in daemonset 'net-exporter' (0 seconds elapsed)
Oct 30 10:22:03.201: INFO: 4 / 4 pods ready in namespace 'kube-system' in daemonset 'node-exporter' (0 seconds elapsed)
Oct 30 10:22:03.201: INFO: e2e test version: v1.15.5
Oct 30 10:22:03.201: INFO: kube-apiserver version: v1.15.5
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 10:22:03.202: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename downward-api
Oct 30 10:22:03.226: INFO: Found PodSecurityPolicies; assuming PodSecurityPolicy is enabled.
Oct 30 10:22:03.234: INFO: Found ClusterRoles; assuming RBAC is enabled.
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-3563
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Oct 30 10:22:03.348: INFO: Waiting up to 5m0s for pod "downward-api-19c77b83-f668-4e96-b2c7-9045a80008dc" in namespace "downward-api-3563" to be "success or failure"
Oct 30 10:22:03.350: INFO: Pod "downward-api-19c77b83-f668-4e96-b2c7-9045a80008dc": Phase="Pending", Reason="", readiness=false. Elapsed: 1.953557ms
Oct 30 10:22:05.353: INFO: Pod "downward-api-19c77b83-f668-4e96-b2c7-9045a80008dc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004711395s
Oct 30 10:22:07.355: INFO: Pod "downward-api-19c77b83-f668-4e96-b2c7-9045a80008dc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007320565s
STEP: Saw pod success
Oct 30 10:22:07.355: INFO: Pod "downward-api-19c77b83-f668-4e96-b2c7-9045a80008dc" satisfied condition "success or failure"
Oct 30 10:22:07.357: INFO: Trying to get logs from node ip-10-1-5-84.eu-central-1.compute.internal pod downward-api-19c77b83-f668-4e96-b2c7-9045a80008dc container dapi-container: <nil>
STEP: delete the pod
Oct 30 10:22:07.371: INFO: Waiting for pod downward-api-19c77b83-f668-4e96-b2c7-9045a80008dc to disappear
Oct 30 10:22:07.373: INFO: Pod downward-api-19c77b83-f668-4e96-b2c7-9045a80008dc no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 10:22:07.373: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3563" for this suite.
Oct 30 10:22:13.382: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 10:22:13.458: INFO: namespace downward-api-3563 deletion completed in 6.082976011s

• [SLOW TEST:10.257 seconds]
[sig-node] Downward API
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 10:22:13.459: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9835
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-map-a0b20c7e-2a76-4f55-8321-d3682c08e3d1
STEP: Creating a pod to test consume secrets
Oct 30 10:22:13.597: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-6f84149e-edb3-4c4b-b95e-ee69e290c953" in namespace "projected-9835" to be "success or failure"
Oct 30 10:22:13.599: INFO: Pod "pod-projected-secrets-6f84149e-edb3-4c4b-b95e-ee69e290c953": Phase="Pending", Reason="", readiness=false. Elapsed: 2.059661ms
Oct 30 10:22:15.602: INFO: Pod "pod-projected-secrets-6f84149e-edb3-4c4b-b95e-ee69e290c953": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004758095s
Oct 30 10:22:17.605: INFO: Pod "pod-projected-secrets-6f84149e-edb3-4c4b-b95e-ee69e290c953": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007452162s
STEP: Saw pod success
Oct 30 10:22:17.605: INFO: Pod "pod-projected-secrets-6f84149e-edb3-4c4b-b95e-ee69e290c953" satisfied condition "success or failure"
Oct 30 10:22:17.607: INFO: Trying to get logs from node ip-10-1-5-63.eu-central-1.compute.internal pod pod-projected-secrets-6f84149e-edb3-4c4b-b95e-ee69e290c953 container projected-secret-volume-test: <nil>
STEP: delete the pod
Oct 30 10:22:17.619: INFO: Waiting for pod pod-projected-secrets-6f84149e-edb3-4c4b-b95e-ee69e290c953 to disappear
Oct 30 10:22:17.621: INFO: Pod pod-projected-secrets-6f84149e-edb3-4c4b-b95e-ee69e290c953 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 10:22:17.621: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9835" for this suite.
Oct 30 10:22:23.630: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 10:22:23.700: INFO: namespace projected-9835 deletion completed in 6.076956999s

• [SLOW TEST:10.241 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 10:22:23.700: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1499
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-866cecb8-0bfa-49b8-b346-2d9290b97c1d
STEP: Creating a pod to test consume secrets
Oct 30 10:22:23.839: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-1fc9327e-5258-4a2a-85fa-7d25f852277a" in namespace "projected-1499" to be "success or failure"
Oct 30 10:22:23.840: INFO: Pod "pod-projected-secrets-1fc9327e-5258-4a2a-85fa-7d25f852277a": Phase="Pending", Reason="", readiness=false. Elapsed: 1.676972ms
Oct 30 10:22:25.843: INFO: Pod "pod-projected-secrets-1fc9327e-5258-4a2a-85fa-7d25f852277a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.003977396s
Oct 30 10:22:27.845: INFO: Pod "pod-projected-secrets-1fc9327e-5258-4a2a-85fa-7d25f852277a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.00654344s
STEP: Saw pod success
Oct 30 10:22:27.845: INFO: Pod "pod-projected-secrets-1fc9327e-5258-4a2a-85fa-7d25f852277a" satisfied condition "success or failure"
Oct 30 10:22:27.847: INFO: Trying to get logs from node ip-10-1-5-84.eu-central-1.compute.internal pod pod-projected-secrets-1fc9327e-5258-4a2a-85fa-7d25f852277a container projected-secret-volume-test: <nil>
STEP: delete the pod
Oct 30 10:22:27.862: INFO: Waiting for pod pod-projected-secrets-1fc9327e-5258-4a2a-85fa-7d25f852277a to disappear
Oct 30 10:22:27.863: INFO: Pod pod-projected-secrets-1fc9327e-5258-4a2a-85fa-7d25f852277a no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 10:22:27.863: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1499" for this suite.
Oct 30 10:22:33.873: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 10:22:33.939: INFO: namespace projected-1499 deletion completed in 6.073184495s

• [SLOW TEST:10.239 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 10:22:33.939: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-201
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: starting the proxy server
Oct 30 10:22:34.068: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-779704590 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 10:22:34.124: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-201" for this suite.
Oct 30 10:22:40.134: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 10:22:40.199: INFO: namespace kubectl-201 deletion completed in 6.072153979s

• [SLOW TEST:6.260 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Proxy server
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 10:22:40.199: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8537
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-3ef909ec-4d80-4de4-be35-b28d9d2981f6
STEP: Creating a pod to test consume configMaps
Oct 30 10:22:40.336: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-3783884c-7a42-40b3-8f6d-fe51e395dfc6" in namespace "projected-8537" to be "success or failure"
Oct 30 10:22:40.339: INFO: Pod "pod-projected-configmaps-3783884c-7a42-40b3-8f6d-fe51e395dfc6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.314665ms
Oct 30 10:22:42.341: INFO: Pod "pod-projected-configmaps-3783884c-7a42-40b3-8f6d-fe51e395dfc6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004887555s
STEP: Saw pod success
Oct 30 10:22:42.341: INFO: Pod "pod-projected-configmaps-3783884c-7a42-40b3-8f6d-fe51e395dfc6" satisfied condition "success or failure"
Oct 30 10:22:42.343: INFO: Trying to get logs from node ip-10-1-5-63.eu-central-1.compute.internal pod pod-projected-configmaps-3783884c-7a42-40b3-8f6d-fe51e395dfc6 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Oct 30 10:22:42.356: INFO: Waiting for pod pod-projected-configmaps-3783884c-7a42-40b3-8f6d-fe51e395dfc6 to disappear
Oct 30 10:22:42.358: INFO: Pod pod-projected-configmaps-3783884c-7a42-40b3-8f6d-fe51e395dfc6 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 10:22:42.358: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8537" for this suite.
Oct 30 10:22:48.367: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 10:22:48.432: INFO: namespace projected-8537 deletion completed in 6.071468449s

• [SLOW TEST:8.233 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 10:22:48.433: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-9928
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 10:22:48.603: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-9928" for this suite.
Oct 30 10:22:54.613: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 10:22:54.683: INFO: namespace kubelet-test-9928 deletion completed in 6.077315085s

• [SLOW TEST:6.250 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should be possible to delete [NodeConformance] [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 10:22:54.684: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-6080
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0644 on node default medium
Oct 30 10:22:54.827: INFO: Waiting up to 5m0s for pod "pod-5027ae2a-403c-43b2-9f11-7147c399c222" in namespace "emptydir-6080" to be "success or failure"
Oct 30 10:22:54.832: INFO: Pod "pod-5027ae2a-403c-43b2-9f11-7147c399c222": Phase="Pending", Reason="", readiness=false. Elapsed: 5.066694ms
Oct 30 10:22:56.835: INFO: Pod "pod-5027ae2a-403c-43b2-9f11-7147c399c222": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007642142s
STEP: Saw pod success
Oct 30 10:22:56.835: INFO: Pod "pod-5027ae2a-403c-43b2-9f11-7147c399c222" satisfied condition "success or failure"
Oct 30 10:22:56.837: INFO: Trying to get logs from node ip-10-1-5-63.eu-central-1.compute.internal pod pod-5027ae2a-403c-43b2-9f11-7147c399c222 container test-container: <nil>
STEP: delete the pod
Oct 30 10:22:56.848: INFO: Waiting for pod pod-5027ae2a-403c-43b2-9f11-7147c399c222 to disappear
Oct 30 10:22:56.850: INFO: Pod pod-5027ae2a-403c-43b2-9f11-7147c399c222 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 10:22:56.850: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6080" for this suite.
Oct 30 10:23:02.862: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 10:23:02.930: INFO: namespace emptydir-6080 deletion completed in 6.07512297s

• [SLOW TEST:8.246 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 10:23:02.930: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-4614
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod liveness-3481c628-91f9-4cd1-ac92-14be352bc8dd in namespace container-probe-4614
Oct 30 10:23:07.068: INFO: Started pod liveness-3481c628-91f9-4cd1-ac92-14be352bc8dd in namespace container-probe-4614
STEP: checking the pod's current state and verifying that restartCount is present
Oct 30 10:23:07.070: INFO: Initial restart count of pod liveness-3481c628-91f9-4cd1-ac92-14be352bc8dd is 0
Oct 30 10:23:25.093: INFO: Restart count of pod container-probe-4614/liveness-3481c628-91f9-4cd1-ac92-14be352bc8dd is now 1 (18.022915548s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 10:23:25.100: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-4614" for this suite.
Oct 30 10:23:31.109: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 10:23:31.181: INFO: namespace container-probe-4614 deletion completed in 6.078955942s

• [SLOW TEST:28.251 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 10:23:31.181: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-wrapper-3519
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Oct 30 10:23:31.543: INFO: Pod name wrapped-volume-race-723c1e02-1809-4723-aed9-26badb0bc5f8: Found 4 pods out of 5
Oct 30 10:23:36.547: INFO: Pod name wrapped-volume-race-723c1e02-1809-4723-aed9-26badb0bc5f8: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-723c1e02-1809-4723-aed9-26badb0bc5f8 in namespace emptydir-wrapper-3519, will wait for the garbage collector to delete the pods
Oct 30 10:23:54.622: INFO: Deleting ReplicationController wrapped-volume-race-723c1e02-1809-4723-aed9-26badb0bc5f8 took: 6.025566ms
Oct 30 10:23:54.723: INFO: Terminating ReplicationController wrapped-volume-race-723c1e02-1809-4723-aed9-26badb0bc5f8 pods took: 100.226653ms
STEP: Creating RC which spawns configmap-volume pods
Oct 30 10:24:40.835: INFO: Pod name wrapped-volume-race-0cf195c6-e2f6-4e51-b6ff-322d6c75e1ae: Found 0 pods out of 5
Oct 30 10:24:45.840: INFO: Pod name wrapped-volume-race-0cf195c6-e2f6-4e51-b6ff-322d6c75e1ae: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-0cf195c6-e2f6-4e51-b6ff-322d6c75e1ae in namespace emptydir-wrapper-3519, will wait for the garbage collector to delete the pods
Oct 30 10:24:55.909: INFO: Deleting ReplicationController wrapped-volume-race-0cf195c6-e2f6-4e51-b6ff-322d6c75e1ae took: 4.731393ms
Oct 30 10:24:56.010: INFO: Terminating ReplicationController wrapped-volume-race-0cf195c6-e2f6-4e51-b6ff-322d6c75e1ae pods took: 100.25122ms
STEP: Creating RC which spawns configmap-volume pods
Oct 30 10:25:40.822: INFO: Pod name wrapped-volume-race-133c641d-afbc-4aff-b75f-d48e67b77d1f: Found 0 pods out of 5
Oct 30 10:25:45.826: INFO: Pod name wrapped-volume-race-133c641d-afbc-4aff-b75f-d48e67b77d1f: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-133c641d-afbc-4aff-b75f-d48e67b77d1f in namespace emptydir-wrapper-3519, will wait for the garbage collector to delete the pods
Oct 30 10:25:55.895: INFO: Deleting ReplicationController wrapped-volume-race-133c641d-afbc-4aff-b75f-d48e67b77d1f took: 4.373792ms
Oct 30 10:25:55.996: INFO: Terminating ReplicationController wrapped-volume-race-133c641d-afbc-4aff-b75f-d48e67b77d1f pods took: 100.32096ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 10:26:41.991: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-3519" for this suite.
Oct 30 10:26:48.001: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 10:26:48.071: INFO: namespace emptydir-wrapper-3519 deletion completed in 6.077523528s

• [SLOW TEST:196.890 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 10:26:48.071: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-9356
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-map-0279a530-971d-457d-a260-afe3aec0700b
STEP: Creating a pod to test consume secrets
Oct 30 10:26:48.205: INFO: Waiting up to 5m0s for pod "pod-secrets-9dc379eb-d74f-4a92-8e7e-511c95cb4303" in namespace "secrets-9356" to be "success or failure"
Oct 30 10:26:48.207: INFO: Pod "pod-secrets-9dc379eb-d74f-4a92-8e7e-511c95cb4303": Phase="Pending", Reason="", readiness=false. Elapsed: 1.735858ms
Oct 30 10:26:50.209: INFO: Pod "pod-secrets-9dc379eb-d74f-4a92-8e7e-511c95cb4303": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004268857s
STEP: Saw pod success
Oct 30 10:26:50.209: INFO: Pod "pod-secrets-9dc379eb-d74f-4a92-8e7e-511c95cb4303" satisfied condition "success or failure"
Oct 30 10:26:50.211: INFO: Trying to get logs from node ip-10-1-5-63.eu-central-1.compute.internal pod pod-secrets-9dc379eb-d74f-4a92-8e7e-511c95cb4303 container secret-volume-test: <nil>
STEP: delete the pod
Oct 30 10:26:50.222: INFO: Waiting for pod pod-secrets-9dc379eb-d74f-4a92-8e7e-511c95cb4303 to disappear
Oct 30 10:26:50.224: INFO: Pod pod-secrets-9dc379eb-d74f-4a92-8e7e-511c95cb4303 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 10:26:50.224: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9356" for this suite.
Oct 30 10:26:56.234: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 10:26:56.300: INFO: namespace secrets-9356 deletion completed in 6.07323914s

• [SLOW TEST:8.229 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 10:26:56.300: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-4843
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test substitution in container's args
Oct 30 10:26:56.433: INFO: Waiting up to 5m0s for pod "var-expansion-d91cf385-9f4b-414f-9454-4ae5b18d6b65" in namespace "var-expansion-4843" to be "success or failure"
Oct 30 10:26:56.436: INFO: Pod "var-expansion-d91cf385-9f4b-414f-9454-4ae5b18d6b65": Phase="Pending", Reason="", readiness=false. Elapsed: 2.281393ms
Oct 30 10:26:58.438: INFO: Pod "var-expansion-d91cf385-9f4b-414f-9454-4ae5b18d6b65": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004604639s
STEP: Saw pod success
Oct 30 10:26:58.438: INFO: Pod "var-expansion-d91cf385-9f4b-414f-9454-4ae5b18d6b65" satisfied condition "success or failure"
Oct 30 10:26:58.440: INFO: Trying to get logs from node ip-10-1-5-84.eu-central-1.compute.internal pod var-expansion-d91cf385-9f4b-414f-9454-4ae5b18d6b65 container dapi-container: <nil>
STEP: delete the pod
Oct 30 10:26:58.454: INFO: Waiting for pod var-expansion-d91cf385-9f4b-414f-9454-4ae5b18d6b65 to disappear
Oct 30 10:26:58.455: INFO: Pod var-expansion-d91cf385-9f4b-414f-9454-4ae5b18d6b65 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 10:26:58.455: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-4843" for this suite.
Oct 30 10:27:04.465: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 10:27:04.534: INFO: namespace var-expansion-4843 deletion completed in 6.075643554s

• [SLOW TEST:8.233 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 10:27:04.534: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-5120
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:63
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Oct 30 10:27:12.697: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct 30 10:27:12.699: INFO: Pod pod-with-poststart-exec-hook still exists
Oct 30 10:27:14.699: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct 30 10:27:14.702: INFO: Pod pod-with-poststart-exec-hook still exists
Oct 30 10:27:16.699: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct 30 10:27:16.701: INFO: Pod pod-with-poststart-exec-hook still exists
Oct 30 10:27:18.699: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct 30 10:27:18.702: INFO: Pod pod-with-poststart-exec-hook still exists
Oct 30 10:27:20.699: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct 30 10:27:20.701: INFO: Pod pod-with-poststart-exec-hook still exists
Oct 30 10:27:22.699: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct 30 10:27:22.701: INFO: Pod pod-with-poststart-exec-hook still exists
Oct 30 10:27:24.699: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct 30 10:27:24.702: INFO: Pod pod-with-poststart-exec-hook still exists
Oct 30 10:27:26.699: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct 30 10:27:26.702: INFO: Pod pod-with-poststart-exec-hook still exists
Oct 30 10:27:28.699: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct 30 10:27:28.701: INFO: Pod pod-with-poststart-exec-hook still exists
Oct 30 10:27:30.699: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct 30 10:27:30.701: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 10:27:30.701: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-5120" for this suite.
Oct 30 10:27:52.711: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 10:27:52.776: INFO: namespace container-lifecycle-hook-5120 deletion completed in 22.072460172s

• [SLOW TEST:48.242 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when create a pod with lifecycle hook
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 10:27:52.777: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-4731
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
Oct 30 10:27:52.907: INFO: observed the pod list
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
Oct 30 10:28:03.932: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 10:28:03.934: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-4731" for this suite.
Oct 30 10:28:09.943: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 10:28:10.009: INFO: namespace pods-4731 deletion completed in 6.072006102s

• [SLOW TEST:17.232 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 10:28:10.009: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-6850
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating replication controller my-hostname-basic-75065313-7e89-4a86-bc3e-2752c5d9b58b
Oct 30 10:28:10.142: INFO: Pod name my-hostname-basic-75065313-7e89-4a86-bc3e-2752c5d9b58b: Found 0 pods out of 1
Oct 30 10:28:15.145: INFO: Pod name my-hostname-basic-75065313-7e89-4a86-bc3e-2752c5d9b58b: Found 1 pods out of 1
Oct 30 10:28:15.145: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-75065313-7e89-4a86-bc3e-2752c5d9b58b" are running
Oct 30 10:28:15.147: INFO: Pod "my-hostname-basic-75065313-7e89-4a86-bc3e-2752c5d9b58b-bzbxh" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-10-30 10:28:10 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-10-30 10:28:13 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-10-30 10:28:13 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-10-30 10:28:10 +0000 UTC Reason: Message:}])
Oct 30 10:28:15.147: INFO: Trying to dial the pod
Oct 30 10:28:20.155: INFO: Controller my-hostname-basic-75065313-7e89-4a86-bc3e-2752c5d9b58b: Got expected result from replica 1 [my-hostname-basic-75065313-7e89-4a86-bc3e-2752c5d9b58b-bzbxh]: "my-hostname-basic-75065313-7e89-4a86-bc3e-2752c5d9b58b-bzbxh", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 10:28:20.155: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-6850" for this suite.
Oct 30 10:28:26.169: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 10:28:26.234: INFO: namespace replication-controller-6850 deletion completed in 6.073844031s

• [SLOW TEST:16.225 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 10:28:26.234: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-4198
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0777 on tmpfs
Oct 30 10:28:26.365: INFO: Waiting up to 5m0s for pod "pod-eeffe3fd-25f8-4c20-b964-5a09e328ef5e" in namespace "emptydir-4198" to be "success or failure"
Oct 30 10:28:26.368: INFO: Pod "pod-eeffe3fd-25f8-4c20-b964-5a09e328ef5e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.73802ms
Oct 30 10:28:28.371: INFO: Pod "pod-eeffe3fd-25f8-4c20-b964-5a09e328ef5e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005367572s
STEP: Saw pod success
Oct 30 10:28:28.371: INFO: Pod "pod-eeffe3fd-25f8-4c20-b964-5a09e328ef5e" satisfied condition "success or failure"
Oct 30 10:28:28.373: INFO: Trying to get logs from node ip-10-1-5-63.eu-central-1.compute.internal pod pod-eeffe3fd-25f8-4c20-b964-5a09e328ef5e container test-container: <nil>
STEP: delete the pod
Oct 30 10:28:28.387: INFO: Waiting for pod pod-eeffe3fd-25f8-4c20-b964-5a09e328ef5e to disappear
Oct 30 10:28:28.389: INFO: Pod pod-eeffe3fd-25f8-4c20-b964-5a09e328ef5e no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 10:28:28.389: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4198" for this suite.
Oct 30 10:28:34.399: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 10:28:34.467: INFO: namespace emptydir-4198 deletion completed in 6.075408179s

• [SLOW TEST:8.233 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 10:28:34.467: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-6068
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
Oct 30 10:28:34.596: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 10:28:37.533: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-6068" for this suite.
Oct 30 10:28:43.543: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 10:28:43.609: INFO: namespace init-container-6068 deletion completed in 6.073425274s

• [SLOW TEST:9.142 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 10:28:43.610: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2778
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating the pod
Oct 30 10:28:46.265: INFO: Successfully updated pod "annotationupdate5cca0a2f-d8ca-4018-8736-b81f6c267588"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 10:28:50.283: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2778" for this suite.
Oct 30 10:29:12.292: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 10:29:12.360: INFO: namespace projected-2778 deletion completed in 22.073981284s

• [SLOW TEST:28.750 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 10:29:12.360: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-2633
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Oct 30 10:29:12.504: INFO: DaemonSet pods can't tolerate node ip-10-1-5-17.eu-central-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 10:29:12.506: INFO: Number of nodes with available pods: 0
Oct 30 10:29:12.506: INFO: Node ip-10-1-5-63.eu-central-1.compute.internal is running more than one daemon pod
Oct 30 10:29:13.509: INFO: DaemonSet pods can't tolerate node ip-10-1-5-17.eu-central-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 10:29:13.512: INFO: Number of nodes with available pods: 0
Oct 30 10:29:13.512: INFO: Node ip-10-1-5-63.eu-central-1.compute.internal is running more than one daemon pod
Oct 30 10:29:14.510: INFO: DaemonSet pods can't tolerate node ip-10-1-5-17.eu-central-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 10:29:14.512: INFO: Number of nodes with available pods: 1
Oct 30 10:29:14.512: INFO: Node ip-10-1-5-65.eu-central-1.compute.internal is running more than one daemon pod
Oct 30 10:29:15.510: INFO: DaemonSet pods can't tolerate node ip-10-1-5-17.eu-central-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 10:29:15.512: INFO: Number of nodes with available pods: 1
Oct 30 10:29:15.512: INFO: Node ip-10-1-5-65.eu-central-1.compute.internal is running more than one daemon pod
Oct 30 10:29:16.510: INFO: DaemonSet pods can't tolerate node ip-10-1-5-17.eu-central-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 10:29:16.512: INFO: Number of nodes with available pods: 2
Oct 30 10:29:16.512: INFO: Node ip-10-1-5-65.eu-central-1.compute.internal is running more than one daemon pod
Oct 30 10:29:17.510: INFO: DaemonSet pods can't tolerate node ip-10-1-5-17.eu-central-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 10:29:17.512: INFO: Number of nodes with available pods: 3
Oct 30 10:29:17.512: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Oct 30 10:29:17.523: INFO: DaemonSet pods can't tolerate node ip-10-1-5-17.eu-central-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 10:29:17.526: INFO: Number of nodes with available pods: 2
Oct 30 10:29:17.526: INFO: Node ip-10-1-5-65.eu-central-1.compute.internal is running more than one daemon pod
Oct 30 10:29:18.529: INFO: DaemonSet pods can't tolerate node ip-10-1-5-17.eu-central-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 10:29:18.531: INFO: Number of nodes with available pods: 2
Oct 30 10:29:18.531: INFO: Node ip-10-1-5-65.eu-central-1.compute.internal is running more than one daemon pod
Oct 30 10:29:19.528: INFO: DaemonSet pods can't tolerate node ip-10-1-5-17.eu-central-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 10:29:19.530: INFO: Number of nodes with available pods: 3
Oct 30 10:29:19.530: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-2633, will wait for the garbage collector to delete the pods
Oct 30 10:29:19.590: INFO: Deleting DaemonSet.extensions daemon-set took: 4.189654ms
Oct 30 10:29:19.690: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.268435ms
Oct 30 10:29:30.892: INFO: Number of nodes with available pods: 0
Oct 30 10:29:30.892: INFO: Number of running nodes: 0, number of available pods: 0
Oct 30 10:29:30.895: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-2633/daemonsets","resourceVersion":"6944"},"items":null}

Oct 30 10:29:30.897: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-2633/pods","resourceVersion":"6944"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 10:29:30.905: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-2633" for this suite.
Oct 30 10:29:36.915: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 10:29:36.981: INFO: namespace daemonsets-2633 deletion completed in 6.073822669s

• [SLOW TEST:24.621 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 10:29:36.981: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-3068
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-ab8dfea1-00b3-4bb9-aec2-94e3ebbac340
STEP: Creating a pod to test consume configMaps
Oct 30 10:29:37.118: INFO: Waiting up to 5m0s for pod "pod-configmaps-76c4f1de-3360-4706-baa0-0f5beb7e2e12" in namespace "configmap-3068" to be "success or failure"
Oct 30 10:29:37.121: INFO: Pod "pod-configmaps-76c4f1de-3360-4706-baa0-0f5beb7e2e12": Phase="Pending", Reason="", readiness=false. Elapsed: 2.459783ms
Oct 30 10:29:39.124: INFO: Pod "pod-configmaps-76c4f1de-3360-4706-baa0-0f5beb7e2e12": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005493096s
STEP: Saw pod success
Oct 30 10:29:39.124: INFO: Pod "pod-configmaps-76c4f1de-3360-4706-baa0-0f5beb7e2e12" satisfied condition "success or failure"
Oct 30 10:29:39.125: INFO: Trying to get logs from node ip-10-1-5-84.eu-central-1.compute.internal pod pod-configmaps-76c4f1de-3360-4706-baa0-0f5beb7e2e12 container configmap-volume-test: <nil>
STEP: delete the pod
Oct 30 10:29:39.140: INFO: Waiting for pod pod-configmaps-76c4f1de-3360-4706-baa0-0f5beb7e2e12 to disappear
Oct 30 10:29:39.142: INFO: Pod pod-configmaps-76c4f1de-3360-4706-baa0-0f5beb7e2e12 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 10:29:39.142: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3068" for this suite.
Oct 30 10:29:45.152: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 10:29:45.220: INFO: namespace configmap-3068 deletion completed in 6.074721526s

• [SLOW TEST:8.238 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 10:29:45.220: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-5050
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
Oct 30 10:29:55.361: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W1030 10:29:55.361833      18 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 10:29:55.361: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-5050" for this suite.
Oct 30 10:30:01.370: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 10:30:01.437: INFO: namespace gc-5050 deletion completed in 6.073733843s

• [SLOW TEST:16.218 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 10:30:01.438: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-7199
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-downwardapi-zgch
STEP: Creating a pod to test atomic-volume-subpath
Oct 30 10:30:01.575: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-zgch" in namespace "subpath-7199" to be "success or failure"
Oct 30 10:30:01.577: INFO: Pod "pod-subpath-test-downwardapi-zgch": Phase="Pending", Reason="", readiness=false. Elapsed: 1.865843ms
Oct 30 10:30:03.580: INFO: Pod "pod-subpath-test-downwardapi-zgch": Phase="Running", Reason="", readiness=true. Elapsed: 2.004667923s
Oct 30 10:30:05.582: INFO: Pod "pod-subpath-test-downwardapi-zgch": Phase="Running", Reason="", readiness=true. Elapsed: 4.006925714s
Oct 30 10:30:07.584: INFO: Pod "pod-subpath-test-downwardapi-zgch": Phase="Running", Reason="", readiness=true. Elapsed: 6.009030653s
Oct 30 10:30:09.587: INFO: Pod "pod-subpath-test-downwardapi-zgch": Phase="Running", Reason="", readiness=true. Elapsed: 8.011350351s
Oct 30 10:30:11.589: INFO: Pod "pod-subpath-test-downwardapi-zgch": Phase="Running", Reason="", readiness=true. Elapsed: 10.013560711s
Oct 30 10:30:13.591: INFO: Pod "pod-subpath-test-downwardapi-zgch": Phase="Running", Reason="", readiness=true. Elapsed: 12.016138126s
Oct 30 10:30:15.599: INFO: Pod "pod-subpath-test-downwardapi-zgch": Phase="Running", Reason="", readiness=true. Elapsed: 14.02428437s
Oct 30 10:30:17.602: INFO: Pod "pod-subpath-test-downwardapi-zgch": Phase="Running", Reason="", readiness=true. Elapsed: 16.026517503s
Oct 30 10:30:19.604: INFO: Pod "pod-subpath-test-downwardapi-zgch": Phase="Running", Reason="", readiness=true. Elapsed: 18.029106513s
Oct 30 10:30:21.607: INFO: Pod "pod-subpath-test-downwardapi-zgch": Phase="Running", Reason="", readiness=true. Elapsed: 20.031566647s
Oct 30 10:30:23.609: INFO: Pod "pod-subpath-test-downwardapi-zgch": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.033975164s
STEP: Saw pod success
Oct 30 10:30:23.609: INFO: Pod "pod-subpath-test-downwardapi-zgch" satisfied condition "success or failure"
Oct 30 10:30:23.611: INFO: Trying to get logs from node ip-10-1-5-63.eu-central-1.compute.internal pod pod-subpath-test-downwardapi-zgch container test-container-subpath-downwardapi-zgch: <nil>
STEP: delete the pod
Oct 30 10:30:23.625: INFO: Waiting for pod pod-subpath-test-downwardapi-zgch to disappear
Oct 30 10:30:23.627: INFO: Pod pod-subpath-test-downwardapi-zgch no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-zgch
Oct 30 10:30:23.627: INFO: Deleting pod "pod-subpath-test-downwardapi-zgch" in namespace "subpath-7199"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 10:30:23.629: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-7199" for this suite.
Oct 30 10:30:29.637: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 10:30:29.706: INFO: namespace subpath-7199 deletion completed in 6.074791197s

• [SLOW TEST:28.268 seconds]
[sig-storage] Subpath
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with downward pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 10:30:29.706: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-9655
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-2328c51e-f533-45ba-ac4e-d3f818e6d327
STEP: Creating a pod to test consume secrets
Oct 30 10:30:29.841: INFO: Waiting up to 5m0s for pod "pod-secrets-e2789350-56a3-4cce-b307-2f86208cda34" in namespace "secrets-9655" to be "success or failure"
Oct 30 10:30:29.842: INFO: Pod "pod-secrets-e2789350-56a3-4cce-b307-2f86208cda34": Phase="Pending", Reason="", readiness=false. Elapsed: 1.84053ms
Oct 30 10:30:31.845: INFO: Pod "pod-secrets-e2789350-56a3-4cce-b307-2f86208cda34": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004376249s
STEP: Saw pod success
Oct 30 10:30:31.845: INFO: Pod "pod-secrets-e2789350-56a3-4cce-b307-2f86208cda34" satisfied condition "success or failure"
Oct 30 10:30:31.847: INFO: Trying to get logs from node ip-10-1-5-84.eu-central-1.compute.internal pod pod-secrets-e2789350-56a3-4cce-b307-2f86208cda34 container secret-env-test: <nil>
STEP: delete the pod
Oct 30 10:30:31.860: INFO: Waiting for pod pod-secrets-e2789350-56a3-4cce-b307-2f86208cda34 to disappear
Oct 30 10:30:31.862: INFO: Pod pod-secrets-e2789350-56a3-4cce-b307-2f86208cda34 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 10:30:31.862: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9655" for this suite.
Oct 30 10:30:37.871: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 10:30:37.939: INFO: namespace secrets-9655 deletion completed in 6.074753423s

• [SLOW TEST:8.233 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 10:30:37.939: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-4353
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 10:30:40.090: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-4353" for this suite.
Oct 30 10:31:18.099: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 10:31:18.164: INFO: namespace kubelet-test-4353 deletion completed in 38.072508224s

• [SLOW TEST:40.225 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when scheduling a read only busybox container
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:187
    should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 10:31:18.165: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename hostpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in hostpath-2509
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test hostPath mode
Oct 30 10:31:18.313: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "hostpath-2509" to be "success or failure"
Oct 30 10:31:18.316: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 3.019406ms
Oct 30 10:31:20.319: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005925652s
STEP: Saw pod success
Oct 30 10:31:20.319: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Oct 30 10:31:20.321: INFO: Trying to get logs from node ip-10-1-5-84.eu-central-1.compute.internal pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Oct 30 10:31:20.334: INFO: Waiting for pod pod-host-path-test to disappear
Oct 30 10:31:20.336: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 10:31:20.336: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "hostpath-2509" for this suite.
Oct 30 10:31:26.346: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 10:31:26.416: INFO: namespace hostpath-2509 deletion completed in 6.077676445s

• [SLOW TEST:8.251 seconds]
[sig-storage] HostPath
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] version v1
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 10:31:26.417: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-7479
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Oct 30 10:31:26.548: INFO: (0) /api/v1/nodes/ip-10-1-5-63.eu-central-1.compute.internal/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 2.469899ms)
Oct 30 10:31:26.551: INFO: (1) /api/v1/nodes/ip-10-1-5-63.eu-central-1.compute.internal/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 2.312094ms)
Oct 30 10:31:26.553: INFO: (2) /api/v1/nodes/ip-10-1-5-63.eu-central-1.compute.internal/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 2.092682ms)
Oct 30 10:31:26.556: INFO: (3) /api/v1/nodes/ip-10-1-5-63.eu-central-1.compute.internal/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 3.083497ms)
Oct 30 10:31:26.558: INFO: (4) /api/v1/nodes/ip-10-1-5-63.eu-central-1.compute.internal/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 2.149078ms)
Oct 30 10:31:26.561: INFO: (5) /api/v1/nodes/ip-10-1-5-63.eu-central-1.compute.internal/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 2.471665ms)
Oct 30 10:31:26.563: INFO: (6) /api/v1/nodes/ip-10-1-5-63.eu-central-1.compute.internal/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 2.458349ms)
Oct 30 10:31:26.565: INFO: (7) /api/v1/nodes/ip-10-1-5-63.eu-central-1.compute.internal/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 2.122179ms)
Oct 30 10:31:26.568: INFO: (8) /api/v1/nodes/ip-10-1-5-63.eu-central-1.compute.internal/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 2.302491ms)
Oct 30 10:31:26.570: INFO: (9) /api/v1/nodes/ip-10-1-5-63.eu-central-1.compute.internal/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 2.311948ms)
Oct 30 10:31:26.572: INFO: (10) /api/v1/nodes/ip-10-1-5-63.eu-central-1.compute.internal/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 2.066258ms)
Oct 30 10:31:26.574: INFO: (11) /api/v1/nodes/ip-10-1-5-63.eu-central-1.compute.internal/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 2.397389ms)
Oct 30 10:31:26.577: INFO: (12) /api/v1/nodes/ip-10-1-5-63.eu-central-1.compute.internal/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 2.301222ms)
Oct 30 10:31:26.579: INFO: (13) /api/v1/nodes/ip-10-1-5-63.eu-central-1.compute.internal/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 2.280417ms)
Oct 30 10:31:26.581: INFO: (14) /api/v1/nodes/ip-10-1-5-63.eu-central-1.compute.internal/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 2.058539ms)
Oct 30 10:31:26.583: INFO: (15) /api/v1/nodes/ip-10-1-5-63.eu-central-1.compute.internal/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 2.162357ms)
Oct 30 10:31:26.585: INFO: (16) /api/v1/nodes/ip-10-1-5-63.eu-central-1.compute.internal/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 2.142458ms)
Oct 30 10:31:26.588: INFO: (17) /api/v1/nodes/ip-10-1-5-63.eu-central-1.compute.internal/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 2.115052ms)
Oct 30 10:31:26.590: INFO: (18) /api/v1/nodes/ip-10-1-5-63.eu-central-1.compute.internal/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 2.181238ms)
Oct 30 10:31:26.592: INFO: (19) /api/v1/nodes/ip-10-1-5-63.eu-central-1.compute.internal/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 2.155515ms)
[AfterEach] version v1
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 10:31:26.592: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-7479" for this suite.
Oct 30 10:31:32.601: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 10:31:32.668: INFO: namespace proxy-7479 deletion completed in 6.072992834s

• [SLOW TEST:6.251 seconds]
[sig-network] Proxy
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:58
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 10:31:32.668: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-8764
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap configmap-8764/configmap-test-7ec64400-4232-4f5c-9018-000b74f72cbe
STEP: Creating a pod to test consume configMaps
Oct 30 10:31:32.802: INFO: Waiting up to 5m0s for pod "pod-configmaps-ee7cd3a0-abcb-47c5-b56c-e92091619893" in namespace "configmap-8764" to be "success or failure"
Oct 30 10:31:32.804: INFO: Pod "pod-configmaps-ee7cd3a0-abcb-47c5-b56c-e92091619893": Phase="Pending", Reason="", readiness=false. Elapsed: 2.251363ms
Oct 30 10:31:34.806: INFO: Pod "pod-configmaps-ee7cd3a0-abcb-47c5-b56c-e92091619893": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004680223s
STEP: Saw pod success
Oct 30 10:31:34.806: INFO: Pod "pod-configmaps-ee7cd3a0-abcb-47c5-b56c-e92091619893" satisfied condition "success or failure"
Oct 30 10:31:34.809: INFO: Trying to get logs from node ip-10-1-5-63.eu-central-1.compute.internal pod pod-configmaps-ee7cd3a0-abcb-47c5-b56c-e92091619893 container env-test: <nil>
STEP: delete the pod
Oct 30 10:31:34.822: INFO: Waiting for pod pod-configmaps-ee7cd3a0-abcb-47c5-b56c-e92091619893 to disappear
Oct 30 10:31:34.824: INFO: Pod pod-configmaps-ee7cd3a0-abcb-47c5-b56c-e92091619893 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 10:31:34.824: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8764" for this suite.
Oct 30 10:31:40.833: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 10:31:40.897: INFO: namespace configmap-8764 deletion completed in 6.071365705s

• [SLOW TEST:8.230 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-node] ConfigMap 
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 10:31:40.898: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-166
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap that has name configmap-test-emptyKey-34e33845-720e-4f94-b541-9d8f1d08ac97
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 10:31:41.026: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-166" for this suite.
Oct 30 10:31:47.036: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 10:31:47.100: INFO: namespace configmap-166 deletion completed in 6.071617075s

• [SLOW TEST:6.203 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 10:31:47.101: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1475
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-1ef47c6b-6b39-44e6-83a5-505a89a692e5
STEP: Creating a pod to test consume configMaps
Oct 30 10:31:47.235: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-3be1cde3-0934-46a6-9430-b6fb2ae6d2bc" in namespace "projected-1475" to be "success or failure"
Oct 30 10:31:47.237: INFO: Pod "pod-projected-configmaps-3be1cde3-0934-46a6-9430-b6fb2ae6d2bc": Phase="Pending", Reason="", readiness=false. Elapsed: 1.983105ms
Oct 30 10:31:49.240: INFO: Pod "pod-projected-configmaps-3be1cde3-0934-46a6-9430-b6fb2ae6d2bc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004237406s
STEP: Saw pod success
Oct 30 10:31:49.240: INFO: Pod "pod-projected-configmaps-3be1cde3-0934-46a6-9430-b6fb2ae6d2bc" satisfied condition "success or failure"
Oct 30 10:31:49.241: INFO: Trying to get logs from node ip-10-1-5-84.eu-central-1.compute.internal pod pod-projected-configmaps-3be1cde3-0934-46a6-9430-b6fb2ae6d2bc container projected-configmap-volume-test: <nil>
STEP: delete the pod
Oct 30 10:31:49.254: INFO: Waiting for pod pod-projected-configmaps-3be1cde3-0934-46a6-9430-b6fb2ae6d2bc to disappear
Oct 30 10:31:49.256: INFO: Pod pod-projected-configmaps-3be1cde3-0934-46a6-9430-b6fb2ae6d2bc no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 10:31:49.256: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1475" for this suite.
Oct 30 10:31:55.266: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 10:31:55.337: INFO: namespace projected-1475 deletion completed in 6.078347547s

• [SLOW TEST:8.236 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 10:31:55.337: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-7793
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Oct 30 10:31:55.478: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-7793,SelfLink:/api/v1/namespaces/watch-7793/configmaps/e2e-watch-test-label-changed,UID:11884e0e-32c4-475e-8011-e40a77d6b6f0,ResourceVersion:7679,Generation:0,CreationTimestamp:2019-10-30 10:31:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Oct 30 10:31:55.479: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-7793,SelfLink:/api/v1/namespaces/watch-7793/configmaps/e2e-watch-test-label-changed,UID:11884e0e-32c4-475e-8011-e40a77d6b6f0,ResourceVersion:7680,Generation:0,CreationTimestamp:2019-10-30 10:31:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Oct 30 10:31:55.479: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-7793,SelfLink:/api/v1/namespaces/watch-7793/configmaps/e2e-watch-test-label-changed,UID:11884e0e-32c4-475e-8011-e40a77d6b6f0,ResourceVersion:7681,Generation:0,CreationTimestamp:2019-10-30 10:31:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Oct 30 10:32:05.495: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-7793,SelfLink:/api/v1/namespaces/watch-7793/configmaps/e2e-watch-test-label-changed,UID:11884e0e-32c4-475e-8011-e40a77d6b6f0,ResourceVersion:7706,Generation:0,CreationTimestamp:2019-10-30 10:31:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Oct 30 10:32:05.495: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-7793,SelfLink:/api/v1/namespaces/watch-7793/configmaps/e2e-watch-test-label-changed,UID:11884e0e-32c4-475e-8011-e40a77d6b6f0,ResourceVersion:7707,Generation:0,CreationTimestamp:2019-10-30 10:31:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Oct 30 10:32:05.495: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-7793,SelfLink:/api/v1/namespaces/watch-7793/configmaps/e2e-watch-test-label-changed,UID:11884e0e-32c4-475e-8011-e40a77d6b6f0,ResourceVersion:7708,Generation:0,CreationTimestamp:2019-10-30 10:31:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 10:32:05.495: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-7793" for this suite.
Oct 30 10:32:11.504: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 10:32:11.570: INFO: namespace watch-7793 deletion completed in 6.071971163s

• [SLOW TEST:16.232 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 10:32:11.570: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-2902
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Oct 30 10:32:14.221: INFO: Successfully updated pod "pod-update-activedeadlineseconds-a5d66309-69a2-4fd1-a194-88551a2987a2"
Oct 30 10:32:14.221: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-a5d66309-69a2-4fd1-a194-88551a2987a2" in namespace "pods-2902" to be "terminated due to deadline exceeded"
Oct 30 10:32:14.223: INFO: Pod "pod-update-activedeadlineseconds-a5d66309-69a2-4fd1-a194-88551a2987a2": Phase="Running", Reason="", readiness=true. Elapsed: 2.03748ms
Oct 30 10:32:16.225: INFO: Pod "pod-update-activedeadlineseconds-a5d66309-69a2-4fd1-a194-88551a2987a2": Phase="Running", Reason="", readiness=true. Elapsed: 2.004366653s
Oct 30 10:32:18.228: INFO: Pod "pod-update-activedeadlineseconds-a5d66309-69a2-4fd1-a194-88551a2987a2": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 4.007111487s
Oct 30 10:32:18.228: INFO: Pod "pod-update-activedeadlineseconds-a5d66309-69a2-4fd1-a194-88551a2987a2" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 10:32:18.228: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-2902" for this suite.
Oct 30 10:32:24.238: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 10:32:24.315: INFO: namespace pods-2902 deletion completed in 6.084306118s

• [SLOW TEST:12.745 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 10:32:24.316: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-1954
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating service endpoint-test2 in namespace services-1954
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-1954 to expose endpoints map[]
Oct 30 10:32:24.458: INFO: Get endpoints failed (2.245748ms elapsed, ignoring for 5s): endpoints "endpoint-test2" not found
Oct 30 10:32:25.460: INFO: successfully validated that service endpoint-test2 in namespace services-1954 exposes endpoints map[] (1.004705099s elapsed)
STEP: Creating pod pod1 in namespace services-1954
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-1954 to expose endpoints map[pod1:[80]]
Oct 30 10:32:26.473: INFO: successfully validated that service endpoint-test2 in namespace services-1954 exposes endpoints map[pod1:[80]] (1.0078725s elapsed)
STEP: Creating pod pod2 in namespace services-1954
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-1954 to expose endpoints map[pod1:[80] pod2:[80]]
Oct 30 10:32:28.496: INFO: successfully validated that service endpoint-test2 in namespace services-1954 exposes endpoints map[pod1:[80] pod2:[80]] (2.019436651s elapsed)
STEP: Deleting pod pod1 in namespace services-1954
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-1954 to expose endpoints map[pod2:[80]]
Oct 30 10:32:29.509: INFO: successfully validated that service endpoint-test2 in namespace services-1954 exposes endpoints map[pod2:[80]] (1.009333625s elapsed)
STEP: Deleting pod pod2 in namespace services-1954
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-1954 to expose endpoints map[]
Oct 30 10:32:30.515: INFO: successfully validated that service endpoint-test2 in namespace services-1954 exposes endpoints map[] (1.003892795s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 10:32:30.527: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-1954" for this suite.
Oct 30 10:32:52.538: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 10:32:52.604: INFO: namespace services-1954 deletion completed in 22.07485978s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:92

• [SLOW TEST:28.289 seconds]
[sig-network] Services
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 10:32:52.605: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-wrapper-2733
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 10:32:56.775: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-2733" for this suite.
Oct 30 10:33:02.785: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 10:33:02.852: INFO: namespace emptydir-wrapper-2733 deletion completed in 6.074301167s

• [SLOW TEST:10.248 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not conflict [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 10:33:02.853: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-8560
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-upd-645e1743-31a1-4dcf-abf9-8779fe13d694
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 10:33:05.012: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8560" for this suite.
Oct 30 10:33:23.021: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 10:33:23.088: INFO: namespace configmap-8560 deletion completed in 18.073317365s

• [SLOW TEST:20.235 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 10:33:23.088: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-799
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-upd-ddd58399-2bba-40e8-90bd-8e6d1d8482b6
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-ddd58399-2bba-40e8-90bd-8e6d1d8482b6
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 10:34:55.561: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-799" for this suite.
Oct 30 10:35:17.570: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 10:35:17.634: INFO: namespace configmap-799 deletion completed in 22.070851259s

• [SLOW TEST:114.547 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 10:35:17.635: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-6059
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
Oct 30 10:35:18.788: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W1030 10:35:18.788895      18 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 10:35:18.789: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-6059" for this suite.
Oct 30 10:35:24.798: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 10:35:24.864: INFO: namespace gc-6059 deletion completed in 6.072599756s

• [SLOW TEST:7.229 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 10:35:24.864: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-8325
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:63
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Oct 30 10:35:29.027: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct 30 10:35:29.029: INFO: Pod pod-with-prestop-exec-hook still exists
Oct 30 10:35:31.029: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct 30 10:35:31.032: INFO: Pod pod-with-prestop-exec-hook still exists
Oct 30 10:35:33.029: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct 30 10:35:33.031: INFO: Pod pod-with-prestop-exec-hook still exists
Oct 30 10:35:35.029: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct 30 10:35:35.031: INFO: Pod pod-with-prestop-exec-hook still exists
Oct 30 10:35:37.029: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct 30 10:35:37.031: INFO: Pod pod-with-prestop-exec-hook still exists
Oct 30 10:35:39.029: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct 30 10:35:39.031: INFO: Pod pod-with-prestop-exec-hook still exists
Oct 30 10:35:41.029: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct 30 10:35:41.031: INFO: Pod pod-with-prestop-exec-hook still exists
Oct 30 10:35:43.029: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct 30 10:35:43.032: INFO: Pod pod-with-prestop-exec-hook still exists
Oct 30 10:35:45.029: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct 30 10:35:45.031: INFO: Pod pod-with-prestop-exec-hook still exists
Oct 30 10:35:47.029: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct 30 10:35:47.031: INFO: Pod pod-with-prestop-exec-hook still exists
Oct 30 10:35:49.029: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct 30 10:35:49.032: INFO: Pod pod-with-prestop-exec-hook still exists
Oct 30 10:35:51.029: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct 30 10:35:51.031: INFO: Pod pod-with-prestop-exec-hook still exists
Oct 30 10:35:53.029: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct 30 10:35:53.031: INFO: Pod pod-with-prestop-exec-hook still exists
Oct 30 10:35:55.029: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct 30 10:35:55.031: INFO: Pod pod-with-prestop-exec-hook still exists
Oct 30 10:35:57.029: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct 30 10:35:57.031: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 10:35:57.037: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-8325" for this suite.
Oct 30 10:36:19.047: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 10:36:19.123: INFO: namespace container-lifecycle-hook-8325 deletion completed in 22.084052768s

• [SLOW TEST:54.259 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when create a pod with lifecycle hook
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 10:36:19.124: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5067
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Oct 30 10:36:19.255: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9f4c509d-b8d9-4d12-8bd5-0cdee289e2fb" in namespace "projected-5067" to be "success or failure"
Oct 30 10:36:19.264: INFO: Pod "downwardapi-volume-9f4c509d-b8d9-4d12-8bd5-0cdee289e2fb": Phase="Pending", Reason="", readiness=false. Elapsed: 8.885373ms
Oct 30 10:36:21.266: INFO: Pod "downwardapi-volume-9f4c509d-b8d9-4d12-8bd5-0cdee289e2fb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011230702s
STEP: Saw pod success
Oct 30 10:36:21.266: INFO: Pod "downwardapi-volume-9f4c509d-b8d9-4d12-8bd5-0cdee289e2fb" satisfied condition "success or failure"
Oct 30 10:36:21.268: INFO: Trying to get logs from node ip-10-1-5-63.eu-central-1.compute.internal pod downwardapi-volume-9f4c509d-b8d9-4d12-8bd5-0cdee289e2fb container client-container: <nil>
STEP: delete the pod
Oct 30 10:36:21.280: INFO: Waiting for pod downwardapi-volume-9f4c509d-b8d9-4d12-8bd5-0cdee289e2fb to disappear
Oct 30 10:36:21.282: INFO: Pod downwardapi-volume-9f4c509d-b8d9-4d12-8bd5-0cdee289e2fb no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 10:36:21.282: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5067" for this suite.
Oct 30 10:36:27.291: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 10:36:27.354: INFO: namespace projected-5067 deletion completed in 6.070024511s

• [SLOW TEST:8.231 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 10:36:27.355: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-2773
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1557
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Oct 30 10:36:27.481: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --generator=deployment/apps.v1 --namespace=kubectl-2773'
Oct 30 10:36:27.672: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Oct 30 10:36:27.672: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the deployment e2e-test-nginx-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1562
Oct 30 10:36:29.681: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 delete deployment e2e-test-nginx-deployment --namespace=kubectl-2773'
Oct 30 10:36:29.751: INFO: stderr: ""
Oct 30 10:36:29.751: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 10:36:29.751: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2773" for this suite.
Oct 30 10:36:51.762: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 10:36:51.840: INFO: namespace kubectl-2773 deletion completed in 22.08633075s

• [SLOW TEST:24.486 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run deployment
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 10:36:51.840: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7462
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-projected-all-test-volume-159d4153-b943-41e7-9412-0872a6418d22
STEP: Creating secret with name secret-projected-all-test-volume-d9ae8db7-d1c9-4aff-a4e4-c822b14059b3
STEP: Creating a pod to test Check all projections for projected volume plugin
Oct 30 10:36:51.979: INFO: Waiting up to 5m0s for pod "projected-volume-6aaeec25-99a8-4ed0-9518-be89bd4f2cd3" in namespace "projected-7462" to be "success or failure"
Oct 30 10:36:51.983: INFO: Pod "projected-volume-6aaeec25-99a8-4ed0-9518-be89bd4f2cd3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.193244ms
Oct 30 10:36:53.985: INFO: Pod "projected-volume-6aaeec25-99a8-4ed0-9518-be89bd4f2cd3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006347475s
STEP: Saw pod success
Oct 30 10:36:53.985: INFO: Pod "projected-volume-6aaeec25-99a8-4ed0-9518-be89bd4f2cd3" satisfied condition "success or failure"
Oct 30 10:36:53.987: INFO: Trying to get logs from node ip-10-1-5-63.eu-central-1.compute.internal pod projected-volume-6aaeec25-99a8-4ed0-9518-be89bd4f2cd3 container projected-all-volume-test: <nil>
STEP: delete the pod
Oct 30 10:36:54.000: INFO: Waiting for pod projected-volume-6aaeec25-99a8-4ed0-9518-be89bd4f2cd3 to disappear
Oct 30 10:36:54.002: INFO: Pod projected-volume-6aaeec25-99a8-4ed0-9518-be89bd4f2cd3 no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 10:36:54.002: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7462" for this suite.
Oct 30 10:37:00.012: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 10:37:00.076: INFO: namespace projected-7462 deletion completed in 6.071706937s

• [SLOW TEST:8.236 seconds]
[sig-storage] Projected combined
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_combined.go:31
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 10:37:00.077: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-5863
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Oct 30 10:37:00.218: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Oct 30 10:37:00.223: INFO: Number of nodes with available pods: 0
Oct 30 10:37:00.223: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Oct 30 10:37:00.234: INFO: Number of nodes with available pods: 0
Oct 30 10:37:00.234: INFO: Node ip-10-1-5-63.eu-central-1.compute.internal is running more than one daemon pod
Oct 30 10:37:01.237: INFO: Number of nodes with available pods: 0
Oct 30 10:37:01.237: INFO: Node ip-10-1-5-63.eu-central-1.compute.internal is running more than one daemon pod
Oct 30 10:37:02.237: INFO: Number of nodes with available pods: 1
Oct 30 10:37:02.237: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Oct 30 10:37:02.247: INFO: Number of nodes with available pods: 1
Oct 30 10:37:02.247: INFO: Number of running nodes: 0, number of available pods: 1
Oct 30 10:37:03.249: INFO: Number of nodes with available pods: 0
Oct 30 10:37:03.249: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Oct 30 10:37:03.254: INFO: Number of nodes with available pods: 0
Oct 30 10:37:03.254: INFO: Node ip-10-1-5-63.eu-central-1.compute.internal is running more than one daemon pod
Oct 30 10:37:04.257: INFO: Number of nodes with available pods: 0
Oct 30 10:37:04.257: INFO: Node ip-10-1-5-63.eu-central-1.compute.internal is running more than one daemon pod
Oct 30 10:37:05.256: INFO: Number of nodes with available pods: 0
Oct 30 10:37:05.256: INFO: Node ip-10-1-5-63.eu-central-1.compute.internal is running more than one daemon pod
Oct 30 10:37:06.256: INFO: Number of nodes with available pods: 0
Oct 30 10:37:06.256: INFO: Node ip-10-1-5-63.eu-central-1.compute.internal is running more than one daemon pod
Oct 30 10:37:07.256: INFO: Number of nodes with available pods: 1
Oct 30 10:37:07.256: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-5863, will wait for the garbage collector to delete the pods
Oct 30 10:37:07.316: INFO: Deleting DaemonSet.extensions daemon-set took: 4.4134ms
Oct 30 10:37:07.416: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.213354ms
Oct 30 10:37:20.818: INFO: Number of nodes with available pods: 0
Oct 30 10:37:20.818: INFO: Number of running nodes: 0, number of available pods: 0
Oct 30 10:37:20.820: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-5863/daemonsets","resourceVersion":"8986"},"items":null}

Oct 30 10:37:20.822: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-5863/pods","resourceVersion":"8986"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 10:37:20.839: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-5863" for this suite.
Oct 30 10:37:26.848: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 10:37:26.914: INFO: namespace daemonsets-5863 deletion completed in 6.072954313s

• [SLOW TEST:26.837 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 10:37:26.914: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-9203
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0777 on tmpfs
Oct 30 10:37:27.044: INFO: Waiting up to 5m0s for pod "pod-7d0c227d-a825-4431-a3d0-bea57502e62d" in namespace "emptydir-9203" to be "success or failure"
Oct 30 10:37:27.047: INFO: Pod "pod-7d0c227d-a825-4431-a3d0-bea57502e62d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.843095ms
Oct 30 10:37:29.050: INFO: Pod "pod-7d0c227d-a825-4431-a3d0-bea57502e62d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005605984s
STEP: Saw pod success
Oct 30 10:37:29.050: INFO: Pod "pod-7d0c227d-a825-4431-a3d0-bea57502e62d" satisfied condition "success or failure"
Oct 30 10:37:29.052: INFO: Trying to get logs from node ip-10-1-5-84.eu-central-1.compute.internal pod pod-7d0c227d-a825-4431-a3d0-bea57502e62d container test-container: <nil>
STEP: delete the pod
Oct 30 10:37:29.063: INFO: Waiting for pod pod-7d0c227d-a825-4431-a3d0-bea57502e62d to disappear
Oct 30 10:37:29.065: INFO: Pod pod-7d0c227d-a825-4431-a3d0-bea57502e62d no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 10:37:29.065: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9203" for this suite.
Oct 30 10:37:35.075: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 10:37:35.140: INFO: namespace emptydir-9203 deletion completed in 6.07186435s

• [SLOW TEST:8.226 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 10:37:35.140: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-6528
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
W1030 10:38:05.789803      18 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Oct 30 10:38:05.789: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 10:38:05.789: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-6528" for this suite.
Oct 30 10:38:11.799: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 10:38:11.869: INFO: namespace gc-6528 deletion completed in 6.077650304s

• [SLOW TEST:36.730 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 10:38:11.870: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-8778
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-map-d9ac455e-ff0e-44bf-80c0-d7c7e427a9a1
STEP: Creating a pod to test consume configMaps
Oct 30 10:38:12.014: INFO: Waiting up to 5m0s for pod "pod-configmaps-e336412b-0714-4524-b230-0d9b129c5634" in namespace "configmap-8778" to be "success or failure"
Oct 30 10:38:12.016: INFO: Pod "pod-configmaps-e336412b-0714-4524-b230-0d9b129c5634": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008103ms
Oct 30 10:38:14.019: INFO: Pod "pod-configmaps-e336412b-0714-4524-b230-0d9b129c5634": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004195927s
STEP: Saw pod success
Oct 30 10:38:14.019: INFO: Pod "pod-configmaps-e336412b-0714-4524-b230-0d9b129c5634" satisfied condition "success or failure"
Oct 30 10:38:14.021: INFO: Trying to get logs from node ip-10-1-5-63.eu-central-1.compute.internal pod pod-configmaps-e336412b-0714-4524-b230-0d9b129c5634 container configmap-volume-test: <nil>
STEP: delete the pod
Oct 30 10:38:14.033: INFO: Waiting for pod pod-configmaps-e336412b-0714-4524-b230-0d9b129c5634 to disappear
Oct 30 10:38:14.035: INFO: Pod pod-configmaps-e336412b-0714-4524-b230-0d9b129c5634 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 10:38:14.035: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8778" for this suite.
Oct 30 10:38:20.044: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 10:38:20.109: INFO: namespace configmap-8778 deletion completed in 6.071441634s

• [SLOW TEST:8.239 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 10:38:20.109: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-2533
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Oct 30 10:38:20.243: INFO: Waiting up to 5m0s for pod "downward-api-5a1f949f-161a-426e-a577-de067bcbfd8a" in namespace "downward-api-2533" to be "success or failure"
Oct 30 10:38:20.244: INFO: Pod "downward-api-5a1f949f-161a-426e-a577-de067bcbfd8a": Phase="Pending", Reason="", readiness=false. Elapsed: 1.717579ms
Oct 30 10:38:22.247: INFO: Pod "downward-api-5a1f949f-161a-426e-a577-de067bcbfd8a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004372429s
STEP: Saw pod success
Oct 30 10:38:22.247: INFO: Pod "downward-api-5a1f949f-161a-426e-a577-de067bcbfd8a" satisfied condition "success or failure"
Oct 30 10:38:22.249: INFO: Trying to get logs from node ip-10-1-5-84.eu-central-1.compute.internal pod downward-api-5a1f949f-161a-426e-a577-de067bcbfd8a container dapi-container: <nil>
STEP: delete the pod
Oct 30 10:38:22.263: INFO: Waiting for pod downward-api-5a1f949f-161a-426e-a577-de067bcbfd8a to disappear
Oct 30 10:38:22.265: INFO: Pod downward-api-5a1f949f-161a-426e-a577-de067bcbfd8a no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 10:38:22.265: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2533" for this suite.
Oct 30 10:38:28.275: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 10:38:28.339: INFO: namespace downward-api-2533 deletion completed in 6.07176748s

• [SLOW TEST:8.230 seconds]
[sig-node] Downward API
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 10:38:28.340: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-6589
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating all guestbook components
Oct 30 10:38:28.468: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Oct 30 10:38:28.468: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 create -f - --namespace=kubectl-6589'
Oct 30 10:38:28.696: INFO: stderr: ""
Oct 30 10:38:28.696: INFO: stdout: "service/redis-slave created\n"
Oct 30 10:38:28.696: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Oct 30 10:38:28.696: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 create -f - --namespace=kubectl-6589'
Oct 30 10:38:28.869: INFO: stderr: ""
Oct 30 10:38:28.869: INFO: stdout: "service/redis-master created\n"
Oct 30 10:38:28.869: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Oct 30 10:38:28.869: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 create -f - --namespace=kubectl-6589'
Oct 30 10:38:29.038: INFO: stderr: ""
Oct 30 10:38:29.038: INFO: stdout: "service/frontend created\n"
Oct 30 10:38:29.039: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: guestbook
      tier: frontend
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Oct 30 10:38:29.039: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 create -f - --namespace=kubectl-6589'
Oct 30 10:38:29.208: INFO: stderr: ""
Oct 30 10:38:29.209: INFO: stdout: "deployment.apps/frontend created\n"
Oct 30 10:38:29.209: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  selector:
    matchLabels:
      app: redis
      role: master
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Oct 30 10:38:29.209: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 create -f - --namespace=kubectl-6589'
Oct 30 10:38:29.361: INFO: stderr: ""
Oct 30 10:38:29.361: INFO: stdout: "deployment.apps/redis-master created\n"
Oct 30 10:38:29.362: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  selector:
    matchLabels:
      app: redis
      role: slave
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave:v3
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Oct 30 10:38:29.362: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 create -f - --namespace=kubectl-6589'
Oct 30 10:38:29.539: INFO: stderr: ""
Oct 30 10:38:29.539: INFO: stdout: "deployment.apps/redis-slave created\n"
STEP: validating guestbook app
Oct 30 10:38:29.539: INFO: Waiting for all frontend pods to be Running.
Oct 30 10:38:49.590: INFO: Waiting for frontend to serve content.
Oct 30 10:38:49.601: INFO: Trying to add a new entry to the guestbook.
Oct 30 10:38:49.611: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Oct 30 10:38:49.619: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 delete --grace-period=0 --force -f - --namespace=kubectl-6589'
Oct 30 10:38:49.694: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct 30 10:38:49.694: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Oct 30 10:38:49.694: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 delete --grace-period=0 --force -f - --namespace=kubectl-6589'
Oct 30 10:38:49.777: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct 30 10:38:49.777: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Oct 30 10:38:49.777: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 delete --grace-period=0 --force -f - --namespace=kubectl-6589'
Oct 30 10:38:49.875: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct 30 10:38:49.875: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Oct 30 10:38:49.876: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 delete --grace-period=0 --force -f - --namespace=kubectl-6589'
Oct 30 10:38:49.966: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct 30 10:38:49.966: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Oct 30 10:38:49.966: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 delete --grace-period=0 --force -f - --namespace=kubectl-6589'
Oct 30 10:38:50.049: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct 30 10:38:50.049: INFO: stdout: "deployment.apps \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Oct 30 10:38:50.049: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 delete --grace-period=0 --force -f - --namespace=kubectl-6589'
Oct 30 10:38:50.140: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct 30 10:38:50.140: INFO: stdout: "deployment.apps \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 10:38:50.140: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6589" for this suite.
Oct 30 10:39:32.157: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 10:39:32.224: INFO: namespace kubectl-6589 deletion completed in 42.080324714s

• [SLOW TEST:63.884 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Guestbook application
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 10:39:32.224: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-7112
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1292
STEP: creating an rc
Oct 30 10:39:32.352: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 create -f - --namespace=kubectl-7112'
Oct 30 10:39:32.607: INFO: stderr: ""
Oct 30 10:39:32.607: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Waiting for Redis master to start.
Oct 30 10:39:33.611: INFO: Selector matched 1 pods for map[app:redis]
Oct 30 10:39:33.611: INFO: Found 0 / 1
Oct 30 10:39:34.610: INFO: Selector matched 1 pods for map[app:redis]
Oct 30 10:39:34.610: INFO: Found 0 / 1
Oct 30 10:39:35.610: INFO: Selector matched 1 pods for map[app:redis]
Oct 30 10:39:35.610: INFO: Found 1 / 1
Oct 30 10:39:35.610: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Oct 30 10:39:35.612: INFO: Selector matched 1 pods for map[app:redis]
Oct 30 10:39:35.612: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
STEP: checking for a matching strings
Oct 30 10:39:35.612: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 logs redis-master-f65c4 redis-master --namespace=kubectl-7112'
Oct 30 10:39:35.687: INFO: stderr: ""
Oct 30 10:39:35.687: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 30 Oct 10:39:34.701 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 30 Oct 10:39:34.701 # Server started, Redis version 3.2.12\n1:M 30 Oct 10:39:34.701 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 30 Oct 10:39:34.701 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log lines
Oct 30 10:39:35.687: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 logs redis-master-f65c4 redis-master --namespace=kubectl-7112 --tail=1'
Oct 30 10:39:35.801: INFO: stderr: ""
Oct 30 10:39:35.801: INFO: stdout: "1:M 30 Oct 10:39:34.701 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log bytes
Oct 30 10:39:35.801: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 logs redis-master-f65c4 redis-master --namespace=kubectl-7112 --limit-bytes=1'
Oct 30 10:39:35.886: INFO: stderr: ""
Oct 30 10:39:35.886: INFO: stdout: " "
STEP: exposing timestamps
Oct 30 10:39:35.886: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 logs redis-master-f65c4 redis-master --namespace=kubectl-7112 --tail=1 --timestamps'
Oct 30 10:39:35.957: INFO: stderr: ""
Oct 30 10:39:35.957: INFO: stdout: "2019-10-30T10:39:34.701303473Z 1:M 30 Oct 10:39:34.701 * The server is now ready to accept connections on port 6379\n"
STEP: restricting to a time range
Oct 30 10:39:38.458: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 logs redis-master-f65c4 redis-master --namespace=kubectl-7112 --since=1s'
Oct 30 10:39:38.529: INFO: stderr: ""
Oct 30 10:39:38.529: INFO: stdout: ""
Oct 30 10:39:38.529: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 logs redis-master-f65c4 redis-master --namespace=kubectl-7112 --since=24h'
Oct 30 10:39:38.601: INFO: stderr: ""
Oct 30 10:39:38.601: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 30 Oct 10:39:34.701 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 30 Oct 10:39:34.701 # Server started, Redis version 3.2.12\n1:M 30 Oct 10:39:34.701 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 30 Oct 10:39:34.701 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1298
STEP: using delete to clean up resources
Oct 30 10:39:38.601: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 delete --grace-period=0 --force -f - --namespace=kubectl-7112'
Oct 30 10:39:38.666: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct 30 10:39:38.666: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
Oct 30 10:39:38.666: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 get rc,svc -l name=nginx --no-headers --namespace=kubectl-7112'
Oct 30 10:39:38.734: INFO: stderr: "No resources found.\n"
Oct 30 10:39:38.734: INFO: stdout: ""
Oct 30 10:39:38.734: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 get pods -l name=nginx --namespace=kubectl-7112 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Oct 30 10:39:38.796: INFO: stderr: ""
Oct 30 10:39:38.796: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 10:39:38.796: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7112" for this suite.
Oct 30 10:40:00.805: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 10:40:00.869: INFO: namespace kubectl-7112 deletion completed in 22.07099331s

• [SLOW TEST:28.645 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl logs
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 10:40:00.870: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-7014
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0644 on node default medium
Oct 30 10:40:01.003: INFO: Waiting up to 5m0s for pod "pod-ae826b44-3d51-4c72-a7bb-1ea20f048300" in namespace "emptydir-7014" to be "success or failure"
Oct 30 10:40:01.006: INFO: Pod "pod-ae826b44-3d51-4c72-a7bb-1ea20f048300": Phase="Pending", Reason="", readiness=false. Elapsed: 2.217013ms
Oct 30 10:40:03.008: INFO: Pod "pod-ae826b44-3d51-4c72-a7bb-1ea20f048300": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00473402s
Oct 30 10:40:05.010: INFO: Pod "pod-ae826b44-3d51-4c72-a7bb-1ea20f048300": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.00692095s
STEP: Saw pod success
Oct 30 10:40:05.010: INFO: Pod "pod-ae826b44-3d51-4c72-a7bb-1ea20f048300" satisfied condition "success or failure"
Oct 30 10:40:05.012: INFO: Trying to get logs from node ip-10-1-5-84.eu-central-1.compute.internal pod pod-ae826b44-3d51-4c72-a7bb-1ea20f048300 container test-container: <nil>
STEP: delete the pod
Oct 30 10:40:05.024: INFO: Waiting for pod pod-ae826b44-3d51-4c72-a7bb-1ea20f048300 to disappear
Oct 30 10:40:05.026: INFO: Pod pod-ae826b44-3d51-4c72-a7bb-1ea20f048300 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 10:40:05.026: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7014" for this suite.
Oct 30 10:40:11.036: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 10:40:11.102: INFO: namespace emptydir-7014 deletion completed in 6.072774523s

• [SLOW TEST:10.232 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 10:40:11.102: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-7961
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test override command
Oct 30 10:40:11.236: INFO: Waiting up to 5m0s for pod "client-containers-4be61e78-d7cd-4c81-b367-21f5a49d8aab" in namespace "containers-7961" to be "success or failure"
Oct 30 10:40:11.239: INFO: Pod "client-containers-4be61e78-d7cd-4c81-b367-21f5a49d8aab": Phase="Pending", Reason="", readiness=false. Elapsed: 2.583757ms
Oct 30 10:40:13.241: INFO: Pod "client-containers-4be61e78-d7cd-4c81-b367-21f5a49d8aab": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004867338s
Oct 30 10:40:15.244: INFO: Pod "client-containers-4be61e78-d7cd-4c81-b367-21f5a49d8aab": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007464757s
STEP: Saw pod success
Oct 30 10:40:15.244: INFO: Pod "client-containers-4be61e78-d7cd-4c81-b367-21f5a49d8aab" satisfied condition "success or failure"
Oct 30 10:40:15.246: INFO: Trying to get logs from node ip-10-1-5-63.eu-central-1.compute.internal pod client-containers-4be61e78-d7cd-4c81-b367-21f5a49d8aab container test-container: <nil>
STEP: delete the pod
Oct 30 10:40:15.260: INFO: Waiting for pod client-containers-4be61e78-d7cd-4c81-b367-21f5a49d8aab to disappear
Oct 30 10:40:15.262: INFO: Pod client-containers-4be61e78-d7cd-4c81-b367-21f5a49d8aab no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 10:40:15.262: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-7961" for this suite.
Oct 30 10:40:21.272: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 10:40:21.337: INFO: namespace containers-7961 deletion completed in 6.072315017s

• [SLOW TEST:10.235 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 10:40:21.338: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9306
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Oct 30 10:40:21.471: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e6875053-095c-4446-adbf-4fb590458730" in namespace "projected-9306" to be "success or failure"
Oct 30 10:40:21.473: INFO: Pod "downwardapi-volume-e6875053-095c-4446-adbf-4fb590458730": Phase="Pending", Reason="", readiness=false. Elapsed: 2.15214ms
Oct 30 10:40:23.476: INFO: Pod "downwardapi-volume-e6875053-095c-4446-adbf-4fb590458730": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004659491s
STEP: Saw pod success
Oct 30 10:40:23.476: INFO: Pod "downwardapi-volume-e6875053-095c-4446-adbf-4fb590458730" satisfied condition "success or failure"
Oct 30 10:40:23.478: INFO: Trying to get logs from node ip-10-1-5-84.eu-central-1.compute.internal pod downwardapi-volume-e6875053-095c-4446-adbf-4fb590458730 container client-container: <nil>
STEP: delete the pod
Oct 30 10:40:23.490: INFO: Waiting for pod downwardapi-volume-e6875053-095c-4446-adbf-4fb590458730 to disappear
Oct 30 10:40:23.492: INFO: Pod downwardapi-volume-e6875053-095c-4446-adbf-4fb590458730 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 10:40:23.492: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9306" for this suite.
Oct 30 10:40:29.502: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 10:40:29.570: INFO: namespace projected-9306 deletion completed in 6.076026763s

• [SLOW TEST:8.233 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 10:40:29.571: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-823
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod test-webserver-e49eaa25-5644-4763-9b2e-9fdabb18a37c in namespace container-probe-823
Oct 30 10:40:31.709: INFO: Started pod test-webserver-e49eaa25-5644-4763-9b2e-9fdabb18a37c in namespace container-probe-823
STEP: checking the pod's current state and verifying that restartCount is present
Oct 30 10:40:31.710: INFO: Initial restart count of pod test-webserver-e49eaa25-5644-4763-9b2e-9fdabb18a37c is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 10:44:32.030: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-823" for this suite.
Oct 30 10:44:38.040: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 10:44:38.106: INFO: namespace container-probe-823 deletion completed in 6.073559039s

• [SLOW TEST:248.536 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 10:44:38.106: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-1051
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl label
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1210
STEP: creating the pod
Oct 30 10:44:38.234: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 create -f - --namespace=kubectl-1051'
Oct 30 10:44:38.384: INFO: stderr: ""
Oct 30 10:44:38.384: INFO: stdout: "pod/pause created\n"
Oct 30 10:44:38.384: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Oct 30 10:44:38.385: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-1051" to be "running and ready"
Oct 30 10:44:38.386: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 1.845576ms
Oct 30 10:44:40.389: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.004642328s
Oct 30 10:44:40.389: INFO: Pod "pause" satisfied condition "running and ready"
Oct 30 10:44:40.389: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: adding the label testing-label with value testing-label-value to a pod
Oct 30 10:44:40.389: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 label pods pause testing-label=testing-label-value --namespace=kubectl-1051'
Oct 30 10:44:40.464: INFO: stderr: ""
Oct 30 10:44:40.464: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Oct 30 10:44:40.464: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 get pod pause -L testing-label --namespace=kubectl-1051'
Oct 30 10:44:40.535: INFO: stderr: ""
Oct 30 10:44:40.535: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Oct 30 10:44:40.535: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 label pods pause testing-label- --namespace=kubectl-1051'
Oct 30 10:44:40.625: INFO: stderr: ""
Oct 30 10:44:40.625: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Oct 30 10:44:40.625: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 get pod pause -L testing-label --namespace=kubectl-1051'
Oct 30 10:44:40.714: INFO: stderr: ""
Oct 30 10:44:40.714: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    \n"
[AfterEach] [k8s.io] Kubectl label
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1217
STEP: using delete to clean up resources
Oct 30 10:44:40.714: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 delete --grace-period=0 --force -f - --namespace=kubectl-1051'
Oct 30 10:44:40.786: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct 30 10:44:40.786: INFO: stdout: "pod \"pause\" force deleted\n"
Oct 30 10:44:40.786: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 get rc,svc -l name=pause --no-headers --namespace=kubectl-1051'
Oct 30 10:44:40.887: INFO: stderr: "No resources found.\n"
Oct 30 10:44:40.887: INFO: stdout: ""
Oct 30 10:44:40.887: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 get pods -l name=pause --namespace=kubectl-1051 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Oct 30 10:44:40.973: INFO: stderr: ""
Oct 30 10:44:40.973: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 10:44:40.973: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1051" for this suite.
Oct 30 10:44:46.983: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 10:44:47.049: INFO: namespace kubectl-1051 deletion completed in 6.072672955s

• [SLOW TEST:8.942 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl label
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 10:44:47.050: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-6614
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir volume type on tmpfs
Oct 30 10:44:47.181: INFO: Waiting up to 5m0s for pod "pod-401f5576-e9fd-4cd9-94cb-a4a343f5154b" in namespace "emptydir-6614" to be "success or failure"
Oct 30 10:44:47.184: INFO: Pod "pod-401f5576-e9fd-4cd9-94cb-a4a343f5154b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.656583ms
Oct 30 10:44:49.186: INFO: Pod "pod-401f5576-e9fd-4cd9-94cb-a4a343f5154b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004860927s
STEP: Saw pod success
Oct 30 10:44:49.186: INFO: Pod "pod-401f5576-e9fd-4cd9-94cb-a4a343f5154b" satisfied condition "success or failure"
Oct 30 10:44:49.188: INFO: Trying to get logs from node ip-10-1-5-63.eu-central-1.compute.internal pod pod-401f5576-e9fd-4cd9-94cb-a4a343f5154b container test-container: <nil>
STEP: delete the pod
Oct 30 10:44:49.202: INFO: Waiting for pod pod-401f5576-e9fd-4cd9-94cb-a4a343f5154b to disappear
Oct 30 10:44:49.204: INFO: Pod pod-401f5576-e9fd-4cd9-94cb-a4a343f5154b no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 10:44:49.204: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6614" for this suite.
Oct 30 10:44:55.213: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 10:44:55.280: INFO: namespace emptydir-6614 deletion completed in 6.07353326s

• [SLOW TEST:8.230 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 10:44:55.280: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-955
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0666 on tmpfs
Oct 30 10:44:55.416: INFO: Waiting up to 5m0s for pod "pod-94dc7318-8005-4d75-b4ca-b31414327faf" in namespace "emptydir-955" to be "success or failure"
Oct 30 10:44:55.419: INFO: Pod "pod-94dc7318-8005-4d75-b4ca-b31414327faf": Phase="Pending", Reason="", readiness=false. Elapsed: 3.40352ms
Oct 30 10:44:57.421: INFO: Pod "pod-94dc7318-8005-4d75-b4ca-b31414327faf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00566353s
STEP: Saw pod success
Oct 30 10:44:57.421: INFO: Pod "pod-94dc7318-8005-4d75-b4ca-b31414327faf" satisfied condition "success or failure"
Oct 30 10:44:57.423: INFO: Trying to get logs from node ip-10-1-5-84.eu-central-1.compute.internal pod pod-94dc7318-8005-4d75-b4ca-b31414327faf container test-container: <nil>
STEP: delete the pod
Oct 30 10:44:57.435: INFO: Waiting for pod pod-94dc7318-8005-4d75-b4ca-b31414327faf to disappear
Oct 30 10:44:57.437: INFO: Pod pod-94dc7318-8005-4d75-b4ca-b31414327faf no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 10:44:57.437: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-955" for this suite.
Oct 30 10:45:03.460: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 10:45:03.526: INFO: namespace emptydir-955 deletion completed in 6.086873287s

• [SLOW TEST:8.246 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 10:45:03.526: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-7871
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0666 on node default medium
Oct 30 10:45:03.658: INFO: Waiting up to 5m0s for pod "pod-422c5b52-3adb-4122-925a-d8890a4c25b0" in namespace "emptydir-7871" to be "success or failure"
Oct 30 10:45:03.660: INFO: Pod "pod-422c5b52-3adb-4122-925a-d8890a4c25b0": Phase="Pending", Reason="", readiness=false. Elapsed: 1.95126ms
Oct 30 10:45:05.662: INFO: Pod "pod-422c5b52-3adb-4122-925a-d8890a4c25b0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004196258s
STEP: Saw pod success
Oct 30 10:45:05.662: INFO: Pod "pod-422c5b52-3adb-4122-925a-d8890a4c25b0" satisfied condition "success or failure"
Oct 30 10:45:05.664: INFO: Trying to get logs from node ip-10-1-5-63.eu-central-1.compute.internal pod pod-422c5b52-3adb-4122-925a-d8890a4c25b0 container test-container: <nil>
STEP: delete the pod
Oct 30 10:45:05.675: INFO: Waiting for pod pod-422c5b52-3adb-4122-925a-d8890a4c25b0 to disappear
Oct 30 10:45:05.677: INFO: Pod pod-422c5b52-3adb-4122-925a-d8890a4c25b0 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 10:45:05.677: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7871" for this suite.
Oct 30 10:45:11.686: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 10:45:11.751: INFO: namespace emptydir-7871 deletion completed in 6.071123552s

• [SLOW TEST:8.224 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 10:45:11.751: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-2237
STEP: Waiting for a default service account to be provisioned in namespace
[It] should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Oct 30 10:45:11.877: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
STEP: Creating rc "condition-test" that asks for more than the allowed pod quota
STEP: Checking rc "condition-test" has the desired failure condition set
STEP: Scaling down rc "condition-test" to satisfy pod quota
Oct 30 10:45:13.895: INFO: Updating replication controller "condition-test"
STEP: Checking rc "condition-test" has no failure condition set
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 10:45:14.899: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-2237" for this suite.
Oct 30 10:45:20.908: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 10:45:20.978: INFO: namespace replication-controller-2237 deletion completed in 6.075978776s

• [SLOW TEST:9.227 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 10:45:20.978: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-9922
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Oct 30 10:45:21.110: INFO: Waiting up to 5m0s for pod "downwardapi-volume-97cad173-1090-43c3-9daa-976409d8cca5" in namespace "downward-api-9922" to be "success or failure"
Oct 30 10:45:21.112: INFO: Pod "downwardapi-volume-97cad173-1090-43c3-9daa-976409d8cca5": Phase="Pending", Reason="", readiness=false. Elapsed: 1.889638ms
Oct 30 10:45:23.114: INFO: Pod "downwardapi-volume-97cad173-1090-43c3-9daa-976409d8cca5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004004322s
STEP: Saw pod success
Oct 30 10:45:23.114: INFO: Pod "downwardapi-volume-97cad173-1090-43c3-9daa-976409d8cca5" satisfied condition "success or failure"
Oct 30 10:45:23.116: INFO: Trying to get logs from node ip-10-1-5-84.eu-central-1.compute.internal pod downwardapi-volume-97cad173-1090-43c3-9daa-976409d8cca5 container client-container: <nil>
STEP: delete the pod
Oct 30 10:45:23.128: INFO: Waiting for pod downwardapi-volume-97cad173-1090-43c3-9daa-976409d8cca5 to disappear
Oct 30 10:45:23.130: INFO: Pod downwardapi-volume-97cad173-1090-43c3-9daa-976409d8cca5 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 10:45:23.130: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9922" for this suite.
Oct 30 10:45:29.139: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 10:45:29.206: INFO: namespace downward-api-9922 deletion completed in 6.073965929s

• [SLOW TEST:8.228 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 10:45:29.207: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-5942
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Oct 30 10:45:29.339: INFO: Waiting up to 5m0s for pod "downward-api-0b063723-7035-4892-ad14-5d972cefe10e" in namespace "downward-api-5942" to be "success or failure"
Oct 30 10:45:29.341: INFO: Pod "downward-api-0b063723-7035-4892-ad14-5d972cefe10e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.313121ms
Oct 30 10:45:31.343: INFO: Pod "downward-api-0b063723-7035-4892-ad14-5d972cefe10e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004621278s
STEP: Saw pod success
Oct 30 10:45:31.344: INFO: Pod "downward-api-0b063723-7035-4892-ad14-5d972cefe10e" satisfied condition "success or failure"
Oct 30 10:45:31.345: INFO: Trying to get logs from node ip-10-1-5-63.eu-central-1.compute.internal pod downward-api-0b063723-7035-4892-ad14-5d972cefe10e container dapi-container: <nil>
STEP: delete the pod
Oct 30 10:45:31.359: INFO: Waiting for pod downward-api-0b063723-7035-4892-ad14-5d972cefe10e to disappear
Oct 30 10:45:31.361: INFO: Pod downward-api-0b063723-7035-4892-ad14-5d972cefe10e no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 10:45:31.361: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5942" for this suite.
Oct 30 10:45:37.372: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 10:45:37.439: INFO: namespace downward-api-5942 deletion completed in 6.074904873s

• [SLOW TEST:8.232 seconds]
[sig-node] Downward API
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 10:45:37.439: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svcaccounts-76
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: getting the auto-created API token
STEP: reading a file in the container
Oct 30 10:45:40.082: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-76 pod-service-account-8baf7c87-3cdf-4482-9416-f4f4d0b99da4 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
STEP: reading a file in the container
Oct 30 10:45:40.241: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-76 pod-service-account-8baf7c87-3cdf-4482-9416-f4f4d0b99da4 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
STEP: reading a file in the container
Oct 30 10:45:40.400: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-76 pod-service-account-8baf7c87-3cdf-4482-9416-f4f4d0b99da4 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 10:45:40.561: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-76" for this suite.
Oct 30 10:45:46.571: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 10:45:46.641: INFO: namespace svcaccounts-76 deletion completed in 6.077882874s

• [SLOW TEST:9.203 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:23
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 10:45:46.642: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-4323
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-secret-k5tb
STEP: Creating a pod to test atomic-volume-subpath
Oct 30 10:45:46.780: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-k5tb" in namespace "subpath-4323" to be "success or failure"
Oct 30 10:45:46.782: INFO: Pod "pod-subpath-test-secret-k5tb": Phase="Pending", Reason="", readiness=false. Elapsed: 1.749735ms
Oct 30 10:45:48.787: INFO: Pod "pod-subpath-test-secret-k5tb": Phase="Running", Reason="", readiness=true. Elapsed: 2.007390966s
Oct 30 10:45:50.790: INFO: Pod "pod-subpath-test-secret-k5tb": Phase="Running", Reason="", readiness=true. Elapsed: 4.010274655s
Oct 30 10:45:52.793: INFO: Pod "pod-subpath-test-secret-k5tb": Phase="Running", Reason="", readiness=true. Elapsed: 6.012511458s
Oct 30 10:45:54.796: INFO: Pod "pod-subpath-test-secret-k5tb": Phase="Running", Reason="", readiness=true. Elapsed: 8.015490906s
Oct 30 10:45:56.798: INFO: Pod "pod-subpath-test-secret-k5tb": Phase="Running", Reason="", readiness=true. Elapsed: 10.017835223s
Oct 30 10:45:58.801: INFO: Pod "pod-subpath-test-secret-k5tb": Phase="Running", Reason="", readiness=true. Elapsed: 12.020536223s
Oct 30 10:46:00.803: INFO: Pod "pod-subpath-test-secret-k5tb": Phase="Running", Reason="", readiness=true. Elapsed: 14.023411058s
Oct 30 10:46:02.806: INFO: Pod "pod-subpath-test-secret-k5tb": Phase="Running", Reason="", readiness=true. Elapsed: 16.025812367s
Oct 30 10:46:04.808: INFO: Pod "pod-subpath-test-secret-k5tb": Phase="Running", Reason="", readiness=true. Elapsed: 18.028276987s
Oct 30 10:46:06.811: INFO: Pod "pod-subpath-test-secret-k5tb": Phase="Running", Reason="", readiness=true. Elapsed: 20.030941585s
Oct 30 10:46:08.814: INFO: Pod "pod-subpath-test-secret-k5tb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.033648159s
STEP: Saw pod success
Oct 30 10:46:08.814: INFO: Pod "pod-subpath-test-secret-k5tb" satisfied condition "success or failure"
Oct 30 10:46:08.815: INFO: Trying to get logs from node ip-10-1-5-63.eu-central-1.compute.internal pod pod-subpath-test-secret-k5tb container test-container-subpath-secret-k5tb: <nil>
STEP: delete the pod
Oct 30 10:46:08.828: INFO: Waiting for pod pod-subpath-test-secret-k5tb to disappear
Oct 30 10:46:08.830: INFO: Pod pod-subpath-test-secret-k5tb no longer exists
STEP: Deleting pod pod-subpath-test-secret-k5tb
Oct 30 10:46:08.830: INFO: Deleting pod "pod-subpath-test-secret-k5tb" in namespace "subpath-4323"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 10:46:08.832: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-4323" for this suite.
Oct 30 10:46:14.841: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 10:46:14.907: INFO: namespace subpath-4323 deletion completed in 6.072890706s

• [SLOW TEST:28.265 seconds]
[sig-storage] Subpath
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with secret pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 10:46:14.907: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-2058
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Oct 30 10:46:17.555: INFO: Successfully updated pod "pod-update-bdd72afd-cc7e-4311-ba33-008b55d09c6b"
STEP: verifying the updated pod is in kubernetes
Oct 30 10:46:17.559: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 10:46:17.559: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-2058" for this suite.
Oct 30 10:46:39.573: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 10:46:39.639: INFO: namespace pods-2058 deletion completed in 22.075364602s

• [SLOW TEST:24.732 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 10:46:39.639: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in namespaces-8042
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-9271
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-1562
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 10:46:46.033: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-8042" for this suite.
Oct 30 10:46:52.042: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 10:46:52.108: INFO: namespace namespaces-8042 deletion completed in 6.07273989s
STEP: Destroying namespace "nsdeletetest-9271" for this suite.
Oct 30 10:46:52.110: INFO: Namespace nsdeletetest-9271 was already deleted
STEP: Destroying namespace "nsdeletetest-1562" for this suite.
Oct 30 10:46:58.117: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 10:46:58.183: INFO: namespace nsdeletetest-1562 deletion completed in 6.07347217s

• [SLOW TEST:18.544 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 10:46:58.183: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-61
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-7e94a8db-fda4-4956-8f8f-2c3ed8ebcd99
STEP: Creating a pod to test consume secrets
Oct 30 10:46:58.316: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-9fa38989-82c1-49e1-83c2-051fc29935c6" in namespace "projected-61" to be "success or failure"
Oct 30 10:46:58.319: INFO: Pod "pod-projected-secrets-9fa38989-82c1-49e1-83c2-051fc29935c6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.489074ms
Oct 30 10:47:00.321: INFO: Pod "pod-projected-secrets-9fa38989-82c1-49e1-83c2-051fc29935c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00488279s
STEP: Saw pod success
Oct 30 10:47:00.321: INFO: Pod "pod-projected-secrets-9fa38989-82c1-49e1-83c2-051fc29935c6" satisfied condition "success or failure"
Oct 30 10:47:00.323: INFO: Trying to get logs from node ip-10-1-5-63.eu-central-1.compute.internal pod pod-projected-secrets-9fa38989-82c1-49e1-83c2-051fc29935c6 container projected-secret-volume-test: <nil>
STEP: delete the pod
Oct 30 10:47:00.338: INFO: Waiting for pod pod-projected-secrets-9fa38989-82c1-49e1-83c2-051fc29935c6 to disappear
Oct 30 10:47:00.341: INFO: Pod pod-projected-secrets-9fa38989-82c1-49e1-83c2-051fc29935c6 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 10:47:00.341: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-61" for this suite.
Oct 30 10:47:06.351: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 10:47:06.416: INFO: namespace projected-61 deletion completed in 6.072185555s

• [SLOW TEST:8.232 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 10:47:06.416: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1594
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-map-f43499e7-6251-48d1-be64-b28f8e5170a5
STEP: Creating a pod to test consume configMaps
Oct 30 10:47:06.550: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-d4cfdc10-72ac-4ca6-8235-42d14588d4dd" in namespace "projected-1594" to be "success or failure"
Oct 30 10:47:06.552: INFO: Pod "pod-projected-configmaps-d4cfdc10-72ac-4ca6-8235-42d14588d4dd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.334015ms
Oct 30 10:47:08.555: INFO: Pod "pod-projected-configmaps-d4cfdc10-72ac-4ca6-8235-42d14588d4dd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005006951s
STEP: Saw pod success
Oct 30 10:47:08.555: INFO: Pod "pod-projected-configmaps-d4cfdc10-72ac-4ca6-8235-42d14588d4dd" satisfied condition "success or failure"
Oct 30 10:47:08.556: INFO: Trying to get logs from node ip-10-1-5-84.eu-central-1.compute.internal pod pod-projected-configmaps-d4cfdc10-72ac-4ca6-8235-42d14588d4dd container projected-configmap-volume-test: <nil>
STEP: delete the pod
Oct 30 10:47:08.569: INFO: Waiting for pod pod-projected-configmaps-d4cfdc10-72ac-4ca6-8235-42d14588d4dd to disappear
Oct 30 10:47:08.570: INFO: Pod pod-projected-configmaps-d4cfdc10-72ac-4ca6-8235-42d14588d4dd no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 10:47:08.570: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1594" for this suite.
Oct 30 10:47:14.580: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 10:47:14.646: INFO: namespace projected-1594 deletion completed in 6.072567042s

• [SLOW TEST:8.230 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 10:47:14.646: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-679
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Oct 30 10:47:14.784: INFO: Waiting up to 5m0s for pod "downwardapi-volume-7f25c908-a29b-4da4-8698-2c3ad77e83b2" in namespace "projected-679" to be "success or failure"
Oct 30 10:47:14.788: INFO: Pod "downwardapi-volume-7f25c908-a29b-4da4-8698-2c3ad77e83b2": Phase="Pending", Reason="", readiness=false. Elapsed: 3.624682ms
Oct 30 10:47:16.790: INFO: Pod "downwardapi-volume-7f25c908-a29b-4da4-8698-2c3ad77e83b2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0059227s
STEP: Saw pod success
Oct 30 10:47:16.790: INFO: Pod "downwardapi-volume-7f25c908-a29b-4da4-8698-2c3ad77e83b2" satisfied condition "success or failure"
Oct 30 10:47:16.792: INFO: Trying to get logs from node ip-10-1-5-63.eu-central-1.compute.internal pod downwardapi-volume-7f25c908-a29b-4da4-8698-2c3ad77e83b2 container client-container: <nil>
STEP: delete the pod
Oct 30 10:47:16.804: INFO: Waiting for pod downwardapi-volume-7f25c908-a29b-4da4-8698-2c3ad77e83b2 to disappear
Oct 30 10:47:16.806: INFO: Pod downwardapi-volume-7f25c908-a29b-4da4-8698-2c3ad77e83b2 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 10:47:16.806: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-679" for this suite.
Oct 30 10:47:22.816: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 10:47:22.882: INFO: namespace projected-679 deletion completed in 6.073800683s

• [SLOW TEST:8.236 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 10:47:22.883: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-9689
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secret-namespace-4409
STEP: Creating secret with name secret-test-8202e9f0-af11-4ce0-8224-981bd5486b6f
STEP: Creating a pod to test consume secrets
Oct 30 10:47:23.144: INFO: Waiting up to 5m0s for pod "pod-secrets-1d0cfee8-3bca-4932-b49a-22e9572d2294" in namespace "secrets-9689" to be "success or failure"
Oct 30 10:47:23.147: INFO: Pod "pod-secrets-1d0cfee8-3bca-4932-b49a-22e9572d2294": Phase="Pending", Reason="", readiness=false. Elapsed: 3.231765ms
Oct 30 10:47:25.149: INFO: Pod "pod-secrets-1d0cfee8-3bca-4932-b49a-22e9572d2294": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005884713s
STEP: Saw pod success
Oct 30 10:47:25.150: INFO: Pod "pod-secrets-1d0cfee8-3bca-4932-b49a-22e9572d2294" satisfied condition "success or failure"
Oct 30 10:47:25.151: INFO: Trying to get logs from node ip-10-1-5-84.eu-central-1.compute.internal pod pod-secrets-1d0cfee8-3bca-4932-b49a-22e9572d2294 container secret-volume-test: <nil>
STEP: delete the pod
Oct 30 10:47:25.164: INFO: Waiting for pod pod-secrets-1d0cfee8-3bca-4932-b49a-22e9572d2294 to disappear
Oct 30 10:47:25.166: INFO: Pod pod-secrets-1d0cfee8-3bca-4932-b49a-22e9572d2294 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 10:47:25.166: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9689" for this suite.
Oct 30 10:47:31.176: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 10:47:31.241: INFO: namespace secrets-9689 deletion completed in 6.0717014s
STEP: Destroying namespace "secret-namespace-4409" for this suite.
Oct 30 10:47:37.248: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 10:47:37.314: INFO: namespace secret-namespace-4409 deletion completed in 6.072976601s

• [SLOW TEST:14.431 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 10:47:37.314: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-397
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Starting the proxy
Oct 30 10:47:37.442: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-779704590 proxy --unix-socket=/tmp/kubectl-proxy-unix967472405/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 10:47:37.491: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-397" for this suite.
Oct 30 10:47:43.501: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 10:47:43.566: INFO: namespace kubectl-397 deletion completed in 6.071895809s

• [SLOW TEST:6.252 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Proxy server
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 10:47:43.566: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-4216
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
Oct 30 10:47:53.737: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
W1030 10:47:53.737253      18 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Oct 30 10:47:53.737: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-4216" for this suite.
Oct 30 10:47:59.747: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 10:47:59.816: INFO: namespace gc-4216 deletion completed in 6.076578008s

• [SLOW TEST:16.250 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 10:47:59.816: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-828
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-map-8fa996fa-e24b-4539-83e9-a3154103b7a2
STEP: Creating a pod to test consume secrets
Oct 30 10:47:59.952: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-e7bf7f65-44d5-4850-bd45-ef54114e5b6a" in namespace "projected-828" to be "success or failure"
Oct 30 10:47:59.954: INFO: Pod "pod-projected-secrets-e7bf7f65-44d5-4850-bd45-ef54114e5b6a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.325287ms
Oct 30 10:48:01.956: INFO: Pod "pod-projected-secrets-e7bf7f65-44d5-4850-bd45-ef54114e5b6a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004487278s
STEP: Saw pod success
Oct 30 10:48:01.956: INFO: Pod "pod-projected-secrets-e7bf7f65-44d5-4850-bd45-ef54114e5b6a" satisfied condition "success or failure"
Oct 30 10:48:01.958: INFO: Trying to get logs from node ip-10-1-5-84.eu-central-1.compute.internal pod pod-projected-secrets-e7bf7f65-44d5-4850-bd45-ef54114e5b6a container projected-secret-volume-test: <nil>
STEP: delete the pod
Oct 30 10:48:01.971: INFO: Waiting for pod pod-projected-secrets-e7bf7f65-44d5-4850-bd45-ef54114e5b6a to disappear
Oct 30 10:48:01.973: INFO: Pod pod-projected-secrets-e7bf7f65-44d5-4850-bd45-ef54114e5b6a no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 10:48:01.973: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-828" for this suite.
Oct 30 10:48:07.983: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 10:48:08.061: INFO: namespace projected-828 deletion completed in 6.084884656s

• [SLOW TEST:8.244 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 10:48:08.061: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7812
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-map-2d3e6080-1158-48c0-aead-371208c65775
STEP: Creating a pod to test consume configMaps
Oct 30 10:48:08.195: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-7ec6e855-772f-4cdf-a6bc-876e7af5608f" in namespace "projected-7812" to be "success or failure"
Oct 30 10:48:08.199: INFO: Pod "pod-projected-configmaps-7ec6e855-772f-4cdf-a6bc-876e7af5608f": Phase="Pending", Reason="", readiness=false. Elapsed: 3.687413ms
Oct 30 10:48:10.201: INFO: Pod "pod-projected-configmaps-7ec6e855-772f-4cdf-a6bc-876e7af5608f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005890371s
STEP: Saw pod success
Oct 30 10:48:10.201: INFO: Pod "pod-projected-configmaps-7ec6e855-772f-4cdf-a6bc-876e7af5608f" satisfied condition "success or failure"
Oct 30 10:48:10.203: INFO: Trying to get logs from node ip-10-1-5-84.eu-central-1.compute.internal pod pod-projected-configmaps-7ec6e855-772f-4cdf-a6bc-876e7af5608f container projected-configmap-volume-test: <nil>
STEP: delete the pod
Oct 30 10:48:10.216: INFO: Waiting for pod pod-projected-configmaps-7ec6e855-772f-4cdf-a6bc-876e7af5608f to disappear
Oct 30 10:48:10.219: INFO: Pod pod-projected-configmaps-7ec6e855-772f-4cdf-a6bc-876e7af5608f no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 10:48:10.219: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7812" for this suite.
Oct 30 10:48:16.227: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 10:48:16.294: INFO: namespace projected-7812 deletion completed in 6.073558779s

• [SLOW TEST:8.234 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 10:48:16.295: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-9826
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-9826
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace statefulset-9826
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-9826
Oct 30 10:48:16.446: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Pending - Ready=false
Oct 30 10:48:26.449: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Oct 30 10:48:26.451: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 exec --namespace=statefulset-9826 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Oct 30 10:48:26.742: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Oct 30 10:48:26.742: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Oct 30 10:48:26.742: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Oct 30 10:48:26.744: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Oct 30 10:48:36.747: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Oct 30 10:48:36.747: INFO: Waiting for statefulset status.replicas updated to 0
Oct 30 10:48:36.756: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.9999984s
Oct 30 10:48:37.758: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.997610639s
Oct 30 10:48:38.761: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.995057592s
Oct 30 10:48:39.764: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.992127948s
Oct 30 10:48:40.767: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.989041338s
Oct 30 10:48:41.770: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.986519755s
Oct 30 10:48:42.772: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.983785354s
Oct 30 10:48:43.775: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.98086978s
Oct 30 10:48:44.778: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.977860006s
Oct 30 10:48:45.781: INFO: Verifying statefulset ss doesn't scale past 1 for another 975.239468ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-9826
Oct 30 10:48:46.784: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 exec --namespace=statefulset-9826 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 30 10:48:46.937: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Oct 30 10:48:46.937: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Oct 30 10:48:46.937: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Oct 30 10:48:46.939: INFO: Found 1 stateful pods, waiting for 3
Oct 30 10:48:56.942: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Oct 30 10:48:56.942: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Oct 30 10:48:56.942: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Oct 30 10:48:56.945: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 exec --namespace=statefulset-9826 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Oct 30 10:48:57.104: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Oct 30 10:48:57.104: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Oct 30 10:48:57.104: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Oct 30 10:48:57.104: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 exec --namespace=statefulset-9826 ss-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Oct 30 10:48:57.271: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Oct 30 10:48:57.271: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Oct 30 10:48:57.271: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Oct 30 10:48:57.271: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 exec --namespace=statefulset-9826 ss-2 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Oct 30 10:48:57.437: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Oct 30 10:48:57.437: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Oct 30 10:48:57.437: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Oct 30 10:48:57.437: INFO: Waiting for statefulset status.replicas updated to 0
Oct 30 10:48:57.439: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
Oct 30 10:49:07.444: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Oct 30 10:49:07.444: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Oct 30 10:49:07.444: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Oct 30 10:49:07.453: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999998402s
Oct 30 10:49:08.456: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.995773104s
Oct 30 10:49:09.459: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.992680563s
Oct 30 10:49:10.461: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.989918108s
Oct 30 10:49:11.464: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.987243344s
Oct 30 10:49:12.467: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.984670172s
Oct 30 10:49:13.469: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.982146033s
Oct 30 10:49:14.472: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.979359579s
Oct 30 10:49:15.475: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.976230213s
Oct 30 10:49:16.478: INFO: Verifying statefulset ss doesn't scale past 3 for another 973.702837ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-9826
Oct 30 10:49:17.481: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 exec --namespace=statefulset-9826 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 30 10:49:17.639: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Oct 30 10:49:17.639: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Oct 30 10:49:17.639: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Oct 30 10:49:17.639: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 exec --namespace=statefulset-9826 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 30 10:49:17.802: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Oct 30 10:49:17.802: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Oct 30 10:49:17.802: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Oct 30 10:49:17.802: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 exec --namespace=statefulset-9826 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 30 10:49:17.969: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Oct 30 10:49:17.969: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Oct 30 10:49:17.969: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Oct 30 10:49:17.969: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Oct 30 10:49:47.984: INFO: Deleting all statefulset in ns statefulset-9826
Oct 30 10:49:47.986: INFO: Scaling statefulset ss to 0
Oct 30 10:49:47.994: INFO: Waiting for statefulset status.replicas updated to 0
Oct 30 10:49:47.996: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 10:49:48.004: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-9826" for this suite.
Oct 30 10:49:54.017: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 10:49:54.084: INFO: namespace statefulset-9826 deletion completed in 6.076465056s

• [SLOW TEST:97.790 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 10:49:54.085: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-9727
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 10:49:58.223: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-9727" for this suite.
Oct 30 10:50:04.233: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 10:50:04.308: INFO: namespace kubelet-test-9727 deletion completed in 6.081895261s

• [SLOW TEST:10.223 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should have an terminated reason [NodeConformance] [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 10:50:04.308: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-1803
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0644 on tmpfs
Oct 30 10:50:04.446: INFO: Waiting up to 5m0s for pod "pod-0a741eef-2d69-4fad-97b7-43ed06e79f6a" in namespace "emptydir-1803" to be "success or failure"
Oct 30 10:50:04.448: INFO: Pod "pod-0a741eef-2d69-4fad-97b7-43ed06e79f6a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.698749ms
Oct 30 10:50:06.451: INFO: Pod "pod-0a741eef-2d69-4fad-97b7-43ed06e79f6a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005299509s
STEP: Saw pod success
Oct 30 10:50:06.451: INFO: Pod "pod-0a741eef-2d69-4fad-97b7-43ed06e79f6a" satisfied condition "success or failure"
Oct 30 10:50:06.453: INFO: Trying to get logs from node ip-10-1-5-63.eu-central-1.compute.internal pod pod-0a741eef-2d69-4fad-97b7-43ed06e79f6a container test-container: <nil>
STEP: delete the pod
Oct 30 10:50:06.472: INFO: Waiting for pod pod-0a741eef-2d69-4fad-97b7-43ed06e79f6a to disappear
Oct 30 10:50:06.473: INFO: Pod pod-0a741eef-2d69-4fad-97b7-43ed06e79f6a no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 10:50:06.473: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1803" for this suite.
Oct 30 10:50:12.483: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 10:50:12.548: INFO: namespace emptydir-1803 deletion completed in 6.071660868s

• [SLOW TEST:8.240 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 10:50:12.548: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-2039
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-e410b0d5-06b2-4eac-8602-bbe7d9a357dc
STEP: Creating a pod to test consume secrets
Oct 30 10:50:12.685: INFO: Waiting up to 5m0s for pod "pod-secrets-24b36c1b-d921-4d32-accf-544690514481" in namespace "secrets-2039" to be "success or failure"
Oct 30 10:50:12.687: INFO: Pod "pod-secrets-24b36c1b-d921-4d32-accf-544690514481": Phase="Pending", Reason="", readiness=false. Elapsed: 1.889188ms
Oct 30 10:50:14.690: INFO: Pod "pod-secrets-24b36c1b-d921-4d32-accf-544690514481": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004914362s
STEP: Saw pod success
Oct 30 10:50:14.690: INFO: Pod "pod-secrets-24b36c1b-d921-4d32-accf-544690514481" satisfied condition "success or failure"
Oct 30 10:50:14.692: INFO: Trying to get logs from node ip-10-1-5-84.eu-central-1.compute.internal pod pod-secrets-24b36c1b-d921-4d32-accf-544690514481 container secret-volume-test: <nil>
STEP: delete the pod
Oct 30 10:50:14.705: INFO: Waiting for pod pod-secrets-24b36c1b-d921-4d32-accf-544690514481 to disappear
Oct 30 10:50:14.707: INFO: Pod pod-secrets-24b36c1b-d921-4d32-accf-544690514481 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 10:50:14.707: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-2039" for this suite.
Oct 30 10:50:20.717: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 10:50:20.782: INFO: namespace secrets-2039 deletion completed in 6.072039073s

• [SLOW TEST:8.234 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 10:50:20.782: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8175
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-7a7a5069-86d2-4269-bd15-acfc17817a65
STEP: Creating a pod to test consume secrets
Oct 30 10:50:20.916: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-dbcec959-b569-44cf-af8f-6ec6e30ee3ed" in namespace "projected-8175" to be "success or failure"
Oct 30 10:50:20.917: INFO: Pod "pod-projected-secrets-dbcec959-b569-44cf-af8f-6ec6e30ee3ed": Phase="Pending", Reason="", readiness=false. Elapsed: 1.782667ms
Oct 30 10:50:22.920: INFO: Pod "pod-projected-secrets-dbcec959-b569-44cf-af8f-6ec6e30ee3ed": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004058049s
STEP: Saw pod success
Oct 30 10:50:22.920: INFO: Pod "pod-projected-secrets-dbcec959-b569-44cf-af8f-6ec6e30ee3ed" satisfied condition "success or failure"
Oct 30 10:50:22.921: INFO: Trying to get logs from node ip-10-1-5-63.eu-central-1.compute.internal pod pod-projected-secrets-dbcec959-b569-44cf-af8f-6ec6e30ee3ed container projected-secret-volume-test: <nil>
STEP: delete the pod
Oct 30 10:50:22.933: INFO: Waiting for pod pod-projected-secrets-dbcec959-b569-44cf-af8f-6ec6e30ee3ed to disappear
Oct 30 10:50:22.935: INFO: Pod pod-projected-secrets-dbcec959-b569-44cf-af8f-6ec6e30ee3ed no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 10:50:22.935: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8175" for this suite.
Oct 30 10:50:28.944: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 10:50:29.008: INFO: namespace projected-8175 deletion completed in 6.070770905s

• [SLOW TEST:8.226 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 10:50:29.008: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-7094
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating pod
Oct 30 10:50:31.149: INFO: Pod pod-hostip-1ec81313-e12e-424f-93e1-34b66b3c63d4 has hostIP: 10.1.5.84
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 10:50:31.149: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-7094" for this suite.
Oct 30 10:50:53.158: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 10:50:53.225: INFO: namespace pods-7094 deletion completed in 22.073335154s

• [SLOW TEST:24.216 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 10:50:53.225: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-9826
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Oct 30 10:50:53.358: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 10:50:55.456: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-9826" for this suite.
Oct 30 10:51:45.465: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 10:51:45.532: INFO: namespace pods-9826 deletion completed in 50.073292912s

• [SLOW TEST:52.306 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 10:51:45.532: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-7342
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1516
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Oct 30 10:51:45.659: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=kubectl-7342'
Oct 30 10:51:45.740: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Oct 30 10:51:45.740: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: rolling-update to same image controller
Oct 30 10:51:45.762: INFO: scanned /root for discovery docs: <nil>
Oct 30 10:51:45.762: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 rolling-update e2e-test-nginx-rc --update-period=1s --image=docker.io/library/nginx:1.14-alpine --image-pull-policy=IfNotPresent --namespace=kubectl-7342'
Oct 30 10:52:01.531: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Oct 30 10:52:01.531: INFO: stdout: "Created e2e-test-nginx-rc-e9e76922f2f841145717ac30a5f5052a\nScaling up e2e-test-nginx-rc-e9e76922f2f841145717ac30a5f5052a from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-e9e76922f2f841145717ac30a5f5052a up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-e9e76922f2f841145717ac30a5f5052a to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
Oct 30 10:52:01.531: INFO: stdout: "Created e2e-test-nginx-rc-e9e76922f2f841145717ac30a5f5052a\nScaling up e2e-test-nginx-rc-e9e76922f2f841145717ac30a5f5052a from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-e9e76922f2f841145717ac30a5f5052a up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-e9e76922f2f841145717ac30a5f5052a to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
Oct 30 10:52:01.531: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=kubectl-7342'
Oct 30 10:52:01.600: INFO: stderr: ""
Oct 30 10:52:01.600: INFO: stdout: "e2e-test-nginx-rc-e9e76922f2f841145717ac30a5f5052a-8gr5t "
Oct 30 10:52:01.600: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 get pods e2e-test-nginx-rc-e9e76922f2f841145717ac30a5f5052a-8gr5t -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7342'
Oct 30 10:52:01.663: INFO: stderr: ""
Oct 30 10:52:01.663: INFO: stdout: "true"
Oct 30 10:52:01.663: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 get pods e2e-test-nginx-rc-e9e76922f2f841145717ac30a5f5052a-8gr5t -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7342'
Oct 30 10:52:01.729: INFO: stderr: ""
Oct 30 10:52:01.729: INFO: stdout: "docker.io/library/nginx:1.14-alpine"
Oct 30 10:52:01.729: INFO: e2e-test-nginx-rc-e9e76922f2f841145717ac30a5f5052a-8gr5t is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1522
Oct 30 10:52:01.729: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 delete rc e2e-test-nginx-rc --namespace=kubectl-7342'
Oct 30 10:52:01.802: INFO: stderr: ""
Oct 30 10:52:01.802: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 10:52:01.802: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7342" for this suite.
Oct 30 10:52:07.815: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 10:52:07.881: INFO: namespace kubectl-7342 deletion completed in 6.073921549s

• [SLOW TEST:22.349 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 10:52:07.881: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-7479
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Oct 30 10:52:08.032: INFO: Creating deployment "test-recreate-deployment"
Oct 30 10:52:08.036: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Oct 30 10:52:08.046: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
Oct 30 10:52:10.053: INFO: Waiting deployment "test-recreate-deployment" to complete
Oct 30 10:52:10.055: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Oct 30 10:52:10.060: INFO: Updating deployment test-recreate-deployment
Oct 30 10:52:10.060: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
Oct 30 10:52:10.108: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment,GenerateName:,Namespace:deployment-7479,SelfLink:/apis/apps/v1/namespaces/deployment-7479/deployments/test-recreate-deployment,UID:029dd3da-b132-4936-94ff-5cbdd5fe2d25,ResourceVersion:13286,Generation:2,CreationTimestamp:2019-10-30 10:52:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[{Available False 2019-10-30 10:52:10 +0000 UTC 2019-10-30 10:52:10 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-10-30 10:52:10 +0000 UTC 2019-10-30 10:52:08 +0000 UTC ReplicaSetUpdated ReplicaSet "test-recreate-deployment-5c8c9cc69d" is progressing.}],ReadyReplicas:0,CollisionCount:nil,},}

Oct 30 10:52:10.110: INFO: New ReplicaSet "test-recreate-deployment-5c8c9cc69d" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-5c8c9cc69d,GenerateName:,Namespace:deployment-7479,SelfLink:/apis/apps/v1/namespaces/deployment-7479/replicasets/test-recreate-deployment-5c8c9cc69d,UID:53db30b9-1b4e-4b6c-b09c-12beac594ec1,ResourceVersion:13284,Generation:1,CreationTimestamp:2019-10-30 10:52:10 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5c8c9cc69d,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 029dd3da-b132-4936-94ff-5cbdd5fe2d25 0xc00383d297 0xc00383d298}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 5c8c9cc69d,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5c8c9cc69d,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Oct 30 10:52:10.110: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Oct 30 10:52:10.110: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-6df85df6b9,GenerateName:,Namespace:deployment-7479,SelfLink:/apis/apps/v1/namespaces/deployment-7479/replicasets/test-recreate-deployment-6df85df6b9,UID:bee759fd-3a05-43d7-8e7f-b1827fe82186,ResourceVersion:13275,Generation:2,CreationTimestamp:2019-10-30 10:52:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 6df85df6b9,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 029dd3da-b132-4936-94ff-5cbdd5fe2d25 0xc00383d4b7 0xc00383d4b8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 6df85df6b9,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 6df85df6b9,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Oct 30 10:52:10.112: INFO: Pod "test-recreate-deployment-5c8c9cc69d-t9xrf" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-5c8c9cc69d-t9xrf,GenerateName:test-recreate-deployment-5c8c9cc69d-,Namespace:deployment-7479,SelfLink:/api/v1/namespaces/deployment-7479/pods/test-recreate-deployment-5c8c9cc69d-t9xrf,UID:7dfa6a34-6bfb-4a7e-8aad-fa2403dcbd92,ResourceVersion:13287,Generation:0,CreationTimestamp:2019-10-30 10:52:10 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5c8c9cc69d,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-recreate-deployment-5c8c9cc69d 53db30b9-1b4e-4b6c-b09c-12beac594ec1 0xc002a00187 0xc002a00188}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-rrp74 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-rrp74,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-rrp74 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-1-5-63.eu-central-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002a001f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002a00210}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 10:52:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-30 10:52:10 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-30 10:52:10 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 10:52:10 +0000 UTC  }],Message:,Reason:,HostIP:10.1.5.63,PodIP:,StartTime:2019-10-30 10:52:10 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 10:52:10.112: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-7479" for this suite.
Oct 30 10:52:16.122: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 10:52:16.187: INFO: namespace deployment-7479 deletion completed in 6.072076391s

• [SLOW TEST:8.306 seconds]
[sig-apps] Deployment
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 10:52:16.188: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-852
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a test externalName service
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-852.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-852.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-852.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-852.svc.cluster.local; sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Oct 30 10:52:28.344: INFO: DNS probes using dns-test-97a0751e-2dff-43b0-8ace-a4fe0087537b succeeded

STEP: deleting the pod
STEP: changing the externalName to bar.example.com
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-852.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-852.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-852.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-852.svc.cluster.local; sleep 1; done

STEP: creating a second pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Oct 30 10:52:40.372: INFO: DNS probes using dns-test-a576bead-fec0-424a-8853-5942913589c4 succeeded

STEP: deleting the pod
STEP: changing the service to type=ClusterIP
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-852.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-852.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-852.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-852.svc.cluster.local; sleep 1; done

STEP: creating a third pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Oct 30 10:52:42.407: INFO: DNS probes using dns-test-53747946-7143-4665-a05a-bb2b06811845 succeeded

STEP: deleting the pod
STEP: deleting the test externalName service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 10:52:42.423: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-852" for this suite.
Oct 30 10:52:48.435: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 10:52:48.500: INFO: namespace dns-852 deletion completed in 6.073142106s

• [SLOW TEST:32.312 seconds]
[sig-network] DNS
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 10:52:48.501: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-6939
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-6939
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace statefulset-6939
STEP: Creating statefulset with conflicting port in namespace statefulset-6939
STEP: Waiting until pod test-pod will start running in namespace statefulset-6939
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-6939
Oct 30 10:52:52.654: INFO: Observed stateful pod in namespace: statefulset-6939, name: ss-0, uid: 2e69337c-6e8d-443d-a28a-4446a9ec5e86, status phase: Pending. Waiting for statefulset controller to delete.
Oct 30 10:52:52.846: INFO: Observed stateful pod in namespace: statefulset-6939, name: ss-0, uid: 2e69337c-6e8d-443d-a28a-4446a9ec5e86, status phase: Failed. Waiting for statefulset controller to delete.
Oct 30 10:52:52.851: INFO: Observed stateful pod in namespace: statefulset-6939, name: ss-0, uid: 2e69337c-6e8d-443d-a28a-4446a9ec5e86, status phase: Failed. Waiting for statefulset controller to delete.
Oct 30 10:52:52.854: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-6939
STEP: Removing pod with conflicting port in namespace statefulset-6939
STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-6939 and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Oct 30 10:52:56.872: INFO: Deleting all statefulset in ns statefulset-6939
Oct 30 10:52:56.874: INFO: Scaling statefulset ss to 0
Oct 30 10:53:06.883: INFO: Waiting for statefulset status.replicas updated to 0
Oct 30 10:53:06.885: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 10:53:06.892: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-6939" for this suite.
Oct 30 10:53:12.902: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 10:53:12.968: INFO: namespace statefulset-6939 deletion completed in 6.072455084s

• [SLOW TEST:24.467 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 10:53:12.968: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-6661
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0777 on node default medium
Oct 30 10:53:13.105: INFO: Waiting up to 5m0s for pod "pod-6b142b89-9305-40b7-89b3-0e5cc839782c" in namespace "emptydir-6661" to be "success or failure"
Oct 30 10:53:13.107: INFO: Pod "pod-6b142b89-9305-40b7-89b3-0e5cc839782c": Phase="Pending", Reason="", readiness=false. Elapsed: 1.858904ms
Oct 30 10:53:15.109: INFO: Pod "pod-6b142b89-9305-40b7-89b3-0e5cc839782c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004042632s
STEP: Saw pod success
Oct 30 10:53:15.109: INFO: Pod "pod-6b142b89-9305-40b7-89b3-0e5cc839782c" satisfied condition "success or failure"
Oct 30 10:53:15.111: INFO: Trying to get logs from node ip-10-1-5-63.eu-central-1.compute.internal pod pod-6b142b89-9305-40b7-89b3-0e5cc839782c container test-container: <nil>
STEP: delete the pod
Oct 30 10:53:15.123: INFO: Waiting for pod pod-6b142b89-9305-40b7-89b3-0e5cc839782c to disappear
Oct 30 10:53:15.125: INFO: Pod pod-6b142b89-9305-40b7-89b3-0e5cc839782c no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 10:53:15.125: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6661" for this suite.
Oct 30 10:53:21.135: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 10:53:21.200: INFO: namespace emptydir-6661 deletion completed in 6.07250107s

• [SLOW TEST:8.232 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 10:53:21.201: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-2599
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:63
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Oct 30 10:53:27.359: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Oct 30 10:53:27.361: INFO: Pod pod-with-poststart-http-hook still exists
Oct 30 10:53:29.362: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Oct 30 10:53:29.364: INFO: Pod pod-with-poststart-http-hook still exists
Oct 30 10:53:31.362: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Oct 30 10:53:31.364: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 10:53:31.364: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-2599" for this suite.
Oct 30 10:53:53.374: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 10:53:53.440: INFO: namespace container-lifecycle-hook-2599 deletion completed in 22.072840601s

• [SLOW TEST:32.239 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when create a pod with lifecycle hook
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 10:53:53.440: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replicaset-7001
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Oct 30 10:53:53.568: INFO: Creating ReplicaSet my-hostname-basic-12baa7e8-da59-44c2-822f-b745daee230c
Oct 30 10:53:53.573: INFO: Pod name my-hostname-basic-12baa7e8-da59-44c2-822f-b745daee230c: Found 0 pods out of 1
Oct 30 10:53:58.577: INFO: Pod name my-hostname-basic-12baa7e8-da59-44c2-822f-b745daee230c: Found 1 pods out of 1
Oct 30 10:53:58.577: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-12baa7e8-da59-44c2-822f-b745daee230c" is running
Oct 30 10:53:58.579: INFO: Pod "my-hostname-basic-12baa7e8-da59-44c2-822f-b745daee230c-xsl97" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-10-30 10:53:53 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-10-30 10:53:54 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-10-30 10:53:54 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-10-30 10:53:53 +0000 UTC Reason: Message:}])
Oct 30 10:53:58.579: INFO: Trying to dial the pod
Oct 30 10:54:03.586: INFO: Controller my-hostname-basic-12baa7e8-da59-44c2-822f-b745daee230c: Got expected result from replica 1 [my-hostname-basic-12baa7e8-da59-44c2-822f-b745daee230c-xsl97]: "my-hostname-basic-12baa7e8-da59-44c2-822f-b745daee230c-xsl97", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 10:54:03.586: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-7001" for this suite.
Oct 30 10:54:09.596: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 10:54:09.661: INFO: namespace replicaset-7001 deletion completed in 6.07236132s

• [SLOW TEST:16.221 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 10:54:09.661: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5730
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Oct 30 10:54:09.798: INFO: Waiting up to 5m0s for pod "downwardapi-volume-3f018ff5-43d6-4a14-9df5-9e8f0ec8d581" in namespace "projected-5730" to be "success or failure"
Oct 30 10:54:09.800: INFO: Pod "downwardapi-volume-3f018ff5-43d6-4a14-9df5-9e8f0ec8d581": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017066ms
Oct 30 10:54:11.803: INFO: Pod "downwardapi-volume-3f018ff5-43d6-4a14-9df5-9e8f0ec8d581": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004819906s
STEP: Saw pod success
Oct 30 10:54:11.803: INFO: Pod "downwardapi-volume-3f018ff5-43d6-4a14-9df5-9e8f0ec8d581" satisfied condition "success or failure"
Oct 30 10:54:11.805: INFO: Trying to get logs from node ip-10-1-5-63.eu-central-1.compute.internal pod downwardapi-volume-3f018ff5-43d6-4a14-9df5-9e8f0ec8d581 container client-container: <nil>
STEP: delete the pod
Oct 30 10:54:11.820: INFO: Waiting for pod downwardapi-volume-3f018ff5-43d6-4a14-9df5-9e8f0ec8d581 to disappear
Oct 30 10:54:11.822: INFO: Pod downwardapi-volume-3f018ff5-43d6-4a14-9df5-9e8f0ec8d581 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 10:54:11.822: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5730" for this suite.
Oct 30 10:54:17.831: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 10:54:17.896: INFO: namespace projected-5730 deletion completed in 6.0708927s

• [SLOW TEST:8.234 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 10:54:17.896: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-6750
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-5982df53-9693-49cc-acef-04c27f278393
STEP: Creating a pod to test consume secrets
Oct 30 10:54:18.034: INFO: Waiting up to 5m0s for pod "pod-secrets-7169822f-dbf4-46a3-8db5-84d8d15e679a" in namespace "secrets-6750" to be "success or failure"
Oct 30 10:54:18.036: INFO: Pod "pod-secrets-7169822f-dbf4-46a3-8db5-84d8d15e679a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.57046ms
Oct 30 10:54:20.039: INFO: Pod "pod-secrets-7169822f-dbf4-46a3-8db5-84d8d15e679a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005309175s
STEP: Saw pod success
Oct 30 10:54:20.039: INFO: Pod "pod-secrets-7169822f-dbf4-46a3-8db5-84d8d15e679a" satisfied condition "success or failure"
Oct 30 10:54:20.041: INFO: Trying to get logs from node ip-10-1-5-84.eu-central-1.compute.internal pod pod-secrets-7169822f-dbf4-46a3-8db5-84d8d15e679a container secret-volume-test: <nil>
STEP: delete the pod
Oct 30 10:54:20.054: INFO: Waiting for pod pod-secrets-7169822f-dbf4-46a3-8db5-84d8d15e679a to disappear
Oct 30 10:54:20.055: INFO: Pod pod-secrets-7169822f-dbf4-46a3-8db5-84d8d15e679a no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 10:54:20.056: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6750" for this suite.
Oct 30 10:54:26.064: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 10:54:26.130: INFO: namespace secrets-6750 deletion completed in 6.072428541s

• [SLOW TEST:8.234 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 10:54:26.131: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2276
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with configMap that has name projected-configmap-test-upd-cce6af11-d596-420e-9b87-6a5edc3a0f49
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-cce6af11-d596-420e-9b87-6a5edc3a0f49
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 10:54:30.293: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2276" for this suite.
Oct 30 10:54:52.304: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 10:54:52.369: INFO: namespace projected-2276 deletion completed in 22.073106053s

• [SLOW TEST:26.238 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 10:54:52.369: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-4563
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the container
STEP: wait for the container to reach Failed
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Oct 30 10:54:53.507: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 10:54:53.515: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-4563" for this suite.
Oct 30 10:54:59.524: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 10:54:59.590: INFO: namespace container-runtime-4563 deletion completed in 6.072367954s

• [SLOW TEST:7.221 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  blackbox test
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
    on terminated container
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:129
      should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 10:54:59.591: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-6657
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name s-test-opt-del-84a381b5-b352-463e-ba2f-baefd6ab9218
STEP: Creating secret with name s-test-opt-upd-9520224d-2c7b-455a-b089-402196e266f2
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-84a381b5-b352-463e-ba2f-baefd6ab9218
STEP: Updating secret s-test-opt-upd-9520224d-2c7b-455a-b089-402196e266f2
STEP: Creating secret with name s-test-opt-create-dc5d9fa5-65f1-4652-86ea-df1e9b7ff8f7
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 10:55:05.787: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6657" for this suite.
Oct 30 10:55:27.796: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 10:55:27.868: INFO: namespace secrets-6657 deletion completed in 22.078598485s

• [SLOW TEST:28.278 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 10:55:27.870: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-3266
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Oct 30 10:55:48.013: INFO: Container started at 2019-10-30 10:55:28 +0000 UTC, pod became ready at 2019-10-30 10:55:46 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 10:55:48.013: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-3266" for this suite.
Oct 30 10:56:10.025: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 10:56:10.091: INFO: namespace container-probe-3266 deletion completed in 22.075074684s

• [SLOW TEST:42.222 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 10:56:10.091: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename events
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in events-8073
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Oct 30 10:56:14.232: INFO: &Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-8e535fec-ff74-4f86-bdc1-6b454c0ebeb1,GenerateName:,Namespace:events-8073,SelfLink:/api/v1/namespaces/events-8073/pods/send-events-8e535fec-ff74-4f86-bdc1-6b454c0ebeb1,UID:90c8e9a6-e1ff-4c3f-a9d9-b2c5fa07530c,ResourceVersion:14581,Generation:0,CreationTimestamp:2019-10-30 10:56:10 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 219459288,},Annotations:map[string]string{kubernetes.io/psp: cert-exporter-psp,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-r8trv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-r8trv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-r8trv true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-1-5-63.eu-central-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002708290} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0027082b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 10:56:10 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 10:56:12 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 10:56:12 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 10:56:10 +0000 UTC  }],Message:,Reason:,HostIP:10.1.5.63,PodIP:192.168.247.14,StartTime:2019-10-30 10:56:10 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2019-10-30 10:56:12 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 docker-pullable://gcr.io/kubernetes-e2e-test-images/serve-hostname@sha256:bab70473a6d8ef65a22625dc9a1b0f0452e811530fdbe77e4408523460177ff1 docker://83002b5345036af70358b12d93bf930739b61e0f79e78636fe4f65fe2964a2cf}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}

STEP: checking for scheduler event about the pod
Oct 30 10:56:16.235: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Oct 30 10:56:18.238: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 10:56:18.242: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-8073" for this suite.
Oct 30 10:57:04.253: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 10:57:04.334: INFO: namespace events-8073 deletion completed in 46.087995386s

• [SLOW TEST:54.243 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 10:57:04.334: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-1056
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating Redis RC
Oct 30 10:57:04.468: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 create -f - --namespace=kubectl-1056'
Oct 30 10:57:04.619: INFO: stderr: ""
Oct 30 10:57:04.619: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Oct 30 10:57:05.622: INFO: Selector matched 1 pods for map[app:redis]
Oct 30 10:57:05.622: INFO: Found 0 / 1
Oct 30 10:57:06.622: INFO: Selector matched 1 pods for map[app:redis]
Oct 30 10:57:06.622: INFO: Found 1 / 1
Oct 30 10:57:06.622: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Oct 30 10:57:06.624: INFO: Selector matched 1 pods for map[app:redis]
Oct 30 10:57:06.624: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Oct 30 10:57:06.624: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 patch pod redis-master-dhn65 --namespace=kubectl-1056 -p {"metadata":{"annotations":{"x":"y"}}}'
Oct 30 10:57:06.695: INFO: stderr: ""
Oct 30 10:57:06.695: INFO: stdout: "pod/redis-master-dhn65 patched\n"
STEP: checking annotations
Oct 30 10:57:06.697: INFO: Selector matched 1 pods for map[app:redis]
Oct 30 10:57:06.697: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 10:57:06.697: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1056" for this suite.
Oct 30 10:57:28.707: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 10:57:28.777: INFO: namespace kubectl-1056 deletion completed in 22.077081079s

• [SLOW TEST:24.442 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl patch
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 10:57:28.777: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-3634
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod busybox-ebd0c233-4463-41eb-928a-0fd5fbc33a08 in namespace container-probe-3634
Oct 30 10:57:30.915: INFO: Started pod busybox-ebd0c233-4463-41eb-928a-0fd5fbc33a08 in namespace container-probe-3634
STEP: checking the pod's current state and verifying that restartCount is present
Oct 30 10:57:30.917: INFO: Initial restart count of pod busybox-ebd0c233-4463-41eb-928a-0fd5fbc33a08 is 0
Oct 30 10:58:20.985: INFO: Restart count of pod container-probe-3634/busybox-ebd0c233-4463-41eb-928a-0fd5fbc33a08 is now 1 (50.068114024s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 10:58:20.992: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-3634" for this suite.
Oct 30 10:58:27.002: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 10:58:27.069: INFO: namespace container-probe-3634 deletion completed in 6.074089362s

• [SLOW TEST:58.292 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 10:58:27.069: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-4229
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Oct 30 10:58:27.202: INFO: Waiting up to 5m0s for pod "downwardapi-volume-4fc3de60-1804-43ae-98bd-4fc77c5386da" in namespace "downward-api-4229" to be "success or failure"
Oct 30 10:58:27.207: INFO: Pod "downwardapi-volume-4fc3de60-1804-43ae-98bd-4fc77c5386da": Phase="Pending", Reason="", readiness=false. Elapsed: 5.001096ms
Oct 30 10:58:29.210: INFO: Pod "downwardapi-volume-4fc3de60-1804-43ae-98bd-4fc77c5386da": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007621457s
STEP: Saw pod success
Oct 30 10:58:29.210: INFO: Pod "downwardapi-volume-4fc3de60-1804-43ae-98bd-4fc77c5386da" satisfied condition "success or failure"
Oct 30 10:58:29.211: INFO: Trying to get logs from node ip-10-1-5-84.eu-central-1.compute.internal pod downwardapi-volume-4fc3de60-1804-43ae-98bd-4fc77c5386da container client-container: <nil>
STEP: delete the pod
Oct 30 10:58:29.223: INFO: Waiting for pod downwardapi-volume-4fc3de60-1804-43ae-98bd-4fc77c5386da to disappear
Oct 30 10:58:29.225: INFO: Pod downwardapi-volume-4fc3de60-1804-43ae-98bd-4fc77c5386da no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 10:58:29.225: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4229" for this suite.
Oct 30 10:58:35.235: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 10:58:35.300: INFO: namespace downward-api-4229 deletion completed in 6.072400965s

• [SLOW TEST:8.232 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 10:58:35.301: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-626
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1721
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Oct 30 10:58:35.429: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 run e2e-test-nginx-pod --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --labels=run=e2e-test-nginx-pod --namespace=kubectl-626'
Oct 30 10:58:35.624: INFO: stderr: ""
Oct 30 10:58:35.624: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod is running
STEP: verifying the pod e2e-test-nginx-pod was created
Oct 30 10:58:40.675: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 get pod e2e-test-nginx-pod --namespace=kubectl-626 -o json'
Oct 30 10:58:40.743: INFO: stderr: ""
Oct 30 10:58:40.743: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"annotations\": {\n            \"kubernetes.io/psp\": \"cert-exporter-psp\"\n        },\n        \"creationTimestamp\": \"2019-10-30T10:58:35Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"kubectl-626\",\n        \"resourceVersion\": \"15077\",\n        \"selfLink\": \"/api/v1/namespaces/kubectl-626/pods/e2e-test-nginx-pod\",\n        \"uid\": \"ef0355ab-318c-4078-973f-4c7f3f040b77\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-gvktk\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"ip-10-1-5-63.eu-central-1.compute.internal\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-gvktk\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-gvktk\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-10-30T10:58:35Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-10-30T10:58:36Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-10-30T10:58:36Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-10-30T10:58:35Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://67df1368166c6a46168a2d2c0bfff36613054ee987755822c1d53d87133011d0\",\n                \"image\": \"nginx:1.14-alpine\",\n                \"imageID\": \"docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2019-10-30T10:58:36Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.1.5.63\",\n        \"phase\": \"Running\",\n        \"podIP\": \"192.168.247.16\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2019-10-30T10:58:35Z\"\n    }\n}\n"
STEP: replace the image in the pod
Oct 30 10:58:40.743: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 replace -f - --namespace=kubectl-626'
Oct 30 10:58:40.890: INFO: stderr: ""
Oct 30 10:58:40.890: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
STEP: verifying the pod e2e-test-nginx-pod has the right image docker.io/library/busybox:1.29
[AfterEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1726
Oct 30 10:58:40.892: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 delete pods e2e-test-nginx-pod --namespace=kubectl-626'
Oct 30 10:58:42.792: INFO: stderr: ""
Oct 30 10:58:42.792: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 10:58:42.792: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-626" for this suite.
Oct 30 10:58:48.803: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 10:58:48.868: INFO: namespace kubectl-626 deletion completed in 6.073173684s

• [SLOW TEST:13.568 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl replace
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 10:58:48.869: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-8649
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Oct 30 10:58:49.001: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ce3805b2-6b38-4235-8c0b-0c80a81219ef" in namespace "downward-api-8649" to be "success or failure"
Oct 30 10:58:49.003: INFO: Pod "downwardapi-volume-ce3805b2-6b38-4235-8c0b-0c80a81219ef": Phase="Pending", Reason="", readiness=false. Elapsed: 2.12989ms
Oct 30 10:58:51.005: INFO: Pod "downwardapi-volume-ce3805b2-6b38-4235-8c0b-0c80a81219ef": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004447308s
STEP: Saw pod success
Oct 30 10:58:51.005: INFO: Pod "downwardapi-volume-ce3805b2-6b38-4235-8c0b-0c80a81219ef" satisfied condition "success or failure"
Oct 30 10:58:51.007: INFO: Trying to get logs from node ip-10-1-5-84.eu-central-1.compute.internal pod downwardapi-volume-ce3805b2-6b38-4235-8c0b-0c80a81219ef container client-container: <nil>
STEP: delete the pod
Oct 30 10:58:51.019: INFO: Waiting for pod downwardapi-volume-ce3805b2-6b38-4235-8c0b-0c80a81219ef to disappear
Oct 30 10:58:51.021: INFO: Pod downwardapi-volume-ce3805b2-6b38-4235-8c0b-0c80a81219ef no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 10:58:51.021: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8649" for this suite.
Oct 30 10:58:57.030: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 10:58:57.136: INFO: namespace downward-api-8649 deletion completed in 6.112611224s

• [SLOW TEST:8.267 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 10:58:57.136: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-6989
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Oct 30 10:58:57.285: INFO: Create a RollingUpdate DaemonSet
Oct 30 10:58:57.288: INFO: Check that daemon pods launch on every node of the cluster
Oct 30 10:58:57.291: INFO: DaemonSet pods can't tolerate node ip-10-1-5-17.eu-central-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 10:58:57.293: INFO: Number of nodes with available pods: 0
Oct 30 10:58:57.293: INFO: Node ip-10-1-5-63.eu-central-1.compute.internal is running more than one daemon pod
Oct 30 10:58:58.296: INFO: DaemonSet pods can't tolerate node ip-10-1-5-17.eu-central-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 10:58:58.298: INFO: Number of nodes with available pods: 1
Oct 30 10:58:58.298: INFO: Node ip-10-1-5-63.eu-central-1.compute.internal is running more than one daemon pod
Oct 30 10:58:59.296: INFO: DaemonSet pods can't tolerate node ip-10-1-5-17.eu-central-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 10:58:59.298: INFO: Number of nodes with available pods: 3
Oct 30 10:58:59.298: INFO: Number of running nodes: 3, number of available pods: 3
Oct 30 10:58:59.298: INFO: Update the DaemonSet to trigger a rollout
Oct 30 10:58:59.303: INFO: Updating DaemonSet daemon-set
Oct 30 10:59:06.314: INFO: Roll back the DaemonSet before rollout is complete
Oct 30 10:59:06.318: INFO: Updating DaemonSet daemon-set
Oct 30 10:59:06.318: INFO: Make sure DaemonSet rollback is complete
Oct 30 10:59:06.320: INFO: Wrong image for pod: daemon-set-j7xtx. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Oct 30 10:59:06.320: INFO: Pod daemon-set-j7xtx is not available
Oct 30 10:59:06.324: INFO: DaemonSet pods can't tolerate node ip-10-1-5-17.eu-central-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 10:59:07.326: INFO: Wrong image for pod: daemon-set-j7xtx. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Oct 30 10:59:07.326: INFO: Pod daemon-set-j7xtx is not available
Oct 30 10:59:07.329: INFO: DaemonSet pods can't tolerate node ip-10-1-5-17.eu-central-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 10:59:08.327: INFO: Pod daemon-set-72wnq is not available
Oct 30 10:59:08.329: INFO: DaemonSet pods can't tolerate node ip-10-1-5-17.eu-central-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-6989, will wait for the garbage collector to delete the pods
Oct 30 10:59:08.388: INFO: Deleting DaemonSet.extensions daemon-set took: 3.771639ms
Oct 30 10:59:08.489: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.299496ms
Oct 30 10:59:20.891: INFO: Number of nodes with available pods: 0
Oct 30 10:59:20.891: INFO: Number of running nodes: 0, number of available pods: 0
Oct 30 10:59:20.893: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-6989/daemonsets","resourceVersion":"15358"},"items":null}

Oct 30 10:59:20.894: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-6989/pods","resourceVersion":"15358"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 10:59:20.903: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-6989" for this suite.
Oct 30 10:59:26.912: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 10:59:26.978: INFO: namespace daemonsets-6989 deletion completed in 6.072211486s

• [SLOW TEST:29.841 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 10:59:26.978: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-7797
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-eb64cec7-d91d-461b-9f5d-0b5604ca1837
STEP: Creating a pod to test consume configMaps
Oct 30 10:59:27.114: INFO: Waiting up to 5m0s for pod "pod-configmaps-e46311ff-a467-45a7-a445-9af11c17ccb7" in namespace "configmap-7797" to be "success or failure"
Oct 30 10:59:27.116: INFO: Pod "pod-configmaps-e46311ff-a467-45a7-a445-9af11c17ccb7": Phase="Pending", Reason="", readiness=false. Elapsed: 1.701367ms
Oct 30 10:59:29.119: INFO: Pod "pod-configmaps-e46311ff-a467-45a7-a445-9af11c17ccb7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004138873s
STEP: Saw pod success
Oct 30 10:59:29.119: INFO: Pod "pod-configmaps-e46311ff-a467-45a7-a445-9af11c17ccb7" satisfied condition "success or failure"
Oct 30 10:59:29.120: INFO: Trying to get logs from node ip-10-1-5-63.eu-central-1.compute.internal pod pod-configmaps-e46311ff-a467-45a7-a445-9af11c17ccb7 container configmap-volume-test: <nil>
STEP: delete the pod
Oct 30 10:59:29.132: INFO: Waiting for pod pod-configmaps-e46311ff-a467-45a7-a445-9af11c17ccb7 to disappear
Oct 30 10:59:29.134: INFO: Pod pod-configmaps-e46311ff-a467-45a7-a445-9af11c17ccb7 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 10:59:29.134: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7797" for this suite.
Oct 30 10:59:35.143: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 10:59:35.210: INFO: namespace configmap-7797 deletion completed in 6.073159886s

• [SLOW TEST:8.232 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 10:59:35.211: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-6897
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Oct 30 10:59:35.342: INFO: Pod name rollover-pod: Found 0 pods out of 1
Oct 30 10:59:40.345: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Oct 30 10:59:40.345: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Oct 30 10:59:42.347: INFO: Creating deployment "test-rollover-deployment"
Oct 30 10:59:42.353: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Oct 30 10:59:44.357: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Oct 30 10:59:44.361: INFO: Ensure that both replica sets have 1 created replica
Oct 30 10:59:44.365: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Oct 30 10:59:44.369: INFO: Updating deployment test-rollover-deployment
Oct 30 10:59:44.369: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Oct 30 10:59:46.373: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Oct 30 10:59:46.377: INFO: Make sure deployment "test-rollover-deployment" is complete
Oct 30 10:59:46.380: INFO: all replica sets need to contain the pod-template-hash label
Oct 30 10:59:46.381: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708029982, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708029982, loc:(*time.Location)(0x7ed0a20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708029985, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708029982, loc:(*time.Location)(0x7ed0a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 30 10:59:48.385: INFO: all replica sets need to contain the pod-template-hash label
Oct 30 10:59:48.385: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708029982, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708029982, loc:(*time.Location)(0x7ed0a20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708029985, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708029982, loc:(*time.Location)(0x7ed0a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 30 10:59:50.385: INFO: all replica sets need to contain the pod-template-hash label
Oct 30 10:59:50.385: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708029982, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708029982, loc:(*time.Location)(0x7ed0a20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708029985, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708029982, loc:(*time.Location)(0x7ed0a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 30 10:59:52.385: INFO: all replica sets need to contain the pod-template-hash label
Oct 30 10:59:52.385: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708029982, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708029982, loc:(*time.Location)(0x7ed0a20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708029985, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708029982, loc:(*time.Location)(0x7ed0a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 30 10:59:54.385: INFO: all replica sets need to contain the pod-template-hash label
Oct 30 10:59:54.385: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708029982, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708029982, loc:(*time.Location)(0x7ed0a20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708029985, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708029982, loc:(*time.Location)(0x7ed0a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 30 10:59:56.385: INFO: 
Oct 30 10:59:56.385: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
Oct 30 10:59:56.390: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment,GenerateName:,Namespace:deployment-6897,SelfLink:/apis/apps/v1/namespaces/deployment-6897/deployments/test-rollover-deployment,UID:758b613c-204a-4e4e-9e69-13f9aa835b44,ResourceVersion:15606,Generation:2,CreationTimestamp:2019-10-30 10:59:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-10-30 10:59:42 +0000 UTC 2019-10-30 10:59:42 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-10-30 10:59:55 +0000 UTC 2019-10-30 10:59:42 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rollover-deployment-854595fc44" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Oct 30 10:59:56.392: INFO: New ReplicaSet "test-rollover-deployment-854595fc44" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-854595fc44,GenerateName:,Namespace:deployment-6897,SelfLink:/apis/apps/v1/namespaces/deployment-6897/replicasets/test-rollover-deployment-854595fc44,UID:f11c5ea2-e34c-48e6-bac0-40f2b547b863,ResourceVersion:15596,Generation:2,CreationTimestamp:2019-10-30 10:59:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 854595fc44,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 758b613c-204a-4e4e-9e69-13f9aa835b44 0xc00343e6f7 0xc00343e6f8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 854595fc44,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 854595fc44,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Oct 30 10:59:56.392: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Oct 30 10:59:56.392: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-controller,GenerateName:,Namespace:deployment-6897,SelfLink:/apis/apps/v1/namespaces/deployment-6897/replicasets/test-rollover-controller,UID:cc9a4517-4107-463a-a87b-9d46f2602bb2,ResourceVersion:15605,Generation:2,CreationTimestamp:2019-10-30 10:59:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 758b613c-204a-4e4e-9e69-13f9aa835b44 0xc00343e627 0xc00343e628}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Oct 30 10:59:56.392: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-9b8b997cf,GenerateName:,Namespace:deployment-6897,SelfLink:/apis/apps/v1/namespaces/deployment-6897/replicasets/test-rollover-deployment-9b8b997cf,UID:07ea91bc-236e-4269-89b2-dacedd7c0ac0,ResourceVersion:15545,Generation:2,CreationTimestamp:2019-10-30 10:59:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 9b8b997cf,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 758b613c-204a-4e4e-9e69-13f9aa835b44 0xc00343e7c0 0xc00343e7c1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 9b8b997cf,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 9b8b997cf,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Oct 30 10:59:56.394: INFO: Pod "test-rollover-deployment-854595fc44-5qqjs" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-854595fc44-5qqjs,GenerateName:test-rollover-deployment-854595fc44-,Namespace:deployment-6897,SelfLink:/api/v1/namespaces/deployment-6897/pods/test-rollover-deployment-854595fc44-5qqjs,UID:18d0e6c4-1906-493d-b379-09e6a6a4e9ff,ResourceVersion:15560,Generation:0,CreationTimestamp:2019-10-30 10:59:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 854595fc44,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-rollover-deployment-854595fc44 f11c5ea2-e34c-48e6-bac0-40f2b547b863 0xc00343f3a7 0xc00343f3a8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-lm2j4 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-lm2j4,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-lm2j4 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-1-5-84.eu-central-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00343f410} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00343f430}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 10:59:44 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 10:59:45 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 10:59:45 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 10:59:44 +0000 UTC  }],Message:,Reason:,HostIP:10.1.5.84,PodIP:192.168.4.202,StartTime:2019-10-30 10:59:44 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-10-30 10:59:45 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://e2d263cc7067fd8870c00588fc181eb85fded085968c3804f46342d677ad5ddc}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 10:59:56.394: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-6897" for this suite.
Oct 30 11:00:02.403: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:00:02.470: INFO: namespace deployment-6897 deletion completed in 6.073469927s

• [SLOW TEST:27.259 seconds]
[sig-apps] Deployment
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support rollover [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 11:00:02.471: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-934
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Performing setup for networking test in namespace pod-network-test-934
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Oct 30 11:00:02.598: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Oct 30 11:00:22.655: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.247.20:8080/dial?request=hostName&protocol=udp&host=192.168.16.80&port=8081&tries=1'] Namespace:pod-network-test-934 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 30 11:00:22.655: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
Oct 30 11:00:22.747: INFO: Waiting for endpoints: map[]
Oct 30 11:00:22.749: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.247.20:8080/dial?request=hostName&protocol=udp&host=192.168.247.19&port=8081&tries=1'] Namespace:pod-network-test-934 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 30 11:00:22.749: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
Oct 30 11:00:22.846: INFO: Waiting for endpoints: map[]
Oct 30 11:00:22.847: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.247.20:8080/dial?request=hostName&protocol=udp&host=192.168.4.203&port=8081&tries=1'] Namespace:pod-network-test-934 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 30 11:00:22.847: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
Oct 30 11:00:22.939: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 11:00:22.939: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-934" for this suite.
Oct 30 11:00:44.948: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:00:45.016: INFO: namespace pod-network-test-934 deletion completed in 22.074228509s

• [SLOW TEST:42.545 seconds]
[sig-network] Networking
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 11:00:45.016: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-3055
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Performing setup for networking test in namespace pod-network-test-3055
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Oct 30 11:00:45.143: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Oct 30 11:01:05.201: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 192.168.247.22 8081 | grep -v '^\s*$'] Namespace:pod-network-test-3055 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 30 11:01:05.201: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
Oct 30 11:01:06.288: INFO: Found all expected endpoints: [netserver-0]
Oct 30 11:01:06.290: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 192.168.4.204 8081 | grep -v '^\s*$'] Namespace:pod-network-test-3055 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 30 11:01:06.290: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
Oct 30 11:01:07.375: INFO: Found all expected endpoints: [netserver-1]
Oct 30 11:01:07.379: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 192.168.16.81 8081 | grep -v '^\s*$'] Namespace:pod-network-test-3055 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 30 11:01:07.379: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
Oct 30 11:01:08.472: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 11:01:08.472: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-3055" for this suite.
Oct 30 11:01:30.482: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:01:30.548: INFO: namespace pod-network-test-3055 deletion completed in 22.07287709s

• [SLOW TEST:45.532 seconds]
[sig-network] Networking
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 11:01:30.548: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-8460
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Oct 30 11:01:30.678: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 11:01:31.714: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-8460" for this suite.
Oct 30 11:01:37.725: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:01:37.790: INFO: namespace custom-resource-definition-8460 deletion completed in 6.072197232s

• [SLOW TEST:7.242 seconds]
[sig-api-machinery] CustomResourceDefinition resources
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:35
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 11:01:37.791: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-3301
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:63
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Oct 30 11:01:41.953: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Oct 30 11:01:41.955: INFO: Pod pod-with-prestop-http-hook still exists
Oct 30 11:01:43.956: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Oct 30 11:01:43.958: INFO: Pod pod-with-prestop-http-hook still exists
Oct 30 11:01:45.956: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Oct 30 11:01:45.958: INFO: Pod pod-with-prestop-http-hook still exists
Oct 30 11:01:47.956: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Oct 30 11:01:47.960: INFO: Pod pod-with-prestop-http-hook still exists
Oct 30 11:01:49.956: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Oct 30 11:01:49.958: INFO: Pod pod-with-prestop-http-hook still exists
Oct 30 11:01:51.956: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Oct 30 11:01:51.958: INFO: Pod pod-with-prestop-http-hook still exists
Oct 30 11:01:53.956: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Oct 30 11:01:53.958: INFO: Pod pod-with-prestop-http-hook still exists
Oct 30 11:01:55.956: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Oct 30 11:01:55.958: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 11:01:55.964: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-3301" for this suite.
Oct 30 11:02:17.973: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:02:18.048: INFO: namespace container-lifecycle-hook-3301 deletion completed in 22.081297522s

• [SLOW TEST:40.257 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when create a pod with lifecycle hook
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 11:02:18.048: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-6932
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
Oct 30 11:02:18.180: INFO: PodSpec: initContainers in spec.initContainers
Oct 30 11:03:00.324: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-6a9b91b4-8743-4878-b819-96cf36582da6", GenerateName:"", Namespace:"init-container-6932", SelfLink:"/api/v1/namespaces/init-container-6932/pods/pod-init-6a9b91b4-8743-4878-b819-96cf36582da6", UID:"9afe6650-66f6-4000-b3d8-7b385ab59824", ResourceVersion:"16423", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63708030138, loc:(*time.Location)(0x7ed0a20)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"180319074"}, Annotations:map[string]string{"kubernetes.io/psp":"cert-exporter-psp"}, OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-xpr6g", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc00327ebc0), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-xpr6g", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-xpr6g", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-xpr6g", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc002c22de8), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"ip-10-1-5-63.eu-central-1.compute.internal", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc002615d40), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc002c22e90)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc002c22eb0)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc002c22eb8), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc002c22ebc), PreemptionPolicy:(*v1.PreemptionPolicy)(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708030138, loc:(*time.Location)(0x7ed0a20)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708030138, loc:(*time.Location)(0x7ed0a20)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708030138, loc:(*time.Location)(0x7ed0a20)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708030138, loc:(*time.Location)(0x7ed0a20)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.1.5.63", PodIP:"192.168.247.25", StartTime:(*v1.Time)(0xc002953dc0), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc00225c700)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc00225c770)}, Ready:false, RestartCount:3, Image:"busybox:1.29", ImageID:"docker-pullable://busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"docker://ea7c3ec4af1dacbaa8583f3d88b8c76532e29034df1e2ef9e2c3c08f82bb9b4d"}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc002953e80), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:""}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc002953e60), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:""}}, QOSClass:"Guaranteed"}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 11:03:00.325: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-6932" for this suite.
Oct 30 11:03:22.335: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:03:22.405: INFO: namespace init-container-6932 deletion completed in 22.077306821s

• [SLOW TEST:64.357 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 11:03:22.405: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-2753
STEP: Waiting for a default service account to be provisioned in namespace
[It] should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: starting a background goroutine to produce watch events
STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 11:03:27.962: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-2753" for this suite.
Oct 30 11:03:34.111: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:03:34.176: INFO: namespace watch-2753 deletion completed in 6.166410849s

• [SLOW TEST:11.771 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 11:03:34.177: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-4335
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Oct 30 11:03:34.315: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-4335,SelfLink:/api/v1/namespaces/watch-4335/configmaps/e2e-watch-test-configmap-a,UID:6c1d1d5c-0448-412a-9e39-802c8177ff03,ResourceVersion:16652,Generation:0,CreationTimestamp:2019-10-30 11:03:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Oct 30 11:03:34.315: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-4335,SelfLink:/api/v1/namespaces/watch-4335/configmaps/e2e-watch-test-configmap-a,UID:6c1d1d5c-0448-412a-9e39-802c8177ff03,ResourceVersion:16652,Generation:0,CreationTimestamp:2019-10-30 11:03:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Oct 30 11:03:44.322: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-4335,SelfLink:/api/v1/namespaces/watch-4335/configmaps/e2e-watch-test-configmap-a,UID:6c1d1d5c-0448-412a-9e39-802c8177ff03,ResourceVersion:16675,Generation:0,CreationTimestamp:2019-10-30 11:03:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Oct 30 11:03:44.322: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-4335,SelfLink:/api/v1/namespaces/watch-4335/configmaps/e2e-watch-test-configmap-a,UID:6c1d1d5c-0448-412a-9e39-802c8177ff03,ResourceVersion:16675,Generation:0,CreationTimestamp:2019-10-30 11:03:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Oct 30 11:03:54.327: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-4335,SelfLink:/api/v1/namespaces/watch-4335/configmaps/e2e-watch-test-configmap-a,UID:6c1d1d5c-0448-412a-9e39-802c8177ff03,ResourceVersion:16699,Generation:0,CreationTimestamp:2019-10-30 11:03:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Oct 30 11:03:54.328: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-4335,SelfLink:/api/v1/namespaces/watch-4335/configmaps/e2e-watch-test-configmap-a,UID:6c1d1d5c-0448-412a-9e39-802c8177ff03,ResourceVersion:16699,Generation:0,CreationTimestamp:2019-10-30 11:03:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Oct 30 11:04:04.334: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-4335,SelfLink:/api/v1/namespaces/watch-4335/configmaps/e2e-watch-test-configmap-a,UID:6c1d1d5c-0448-412a-9e39-802c8177ff03,ResourceVersion:16724,Generation:0,CreationTimestamp:2019-10-30 11:03:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Oct 30 11:04:04.334: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-4335,SelfLink:/api/v1/namespaces/watch-4335/configmaps/e2e-watch-test-configmap-a,UID:6c1d1d5c-0448-412a-9e39-802c8177ff03,ResourceVersion:16724,Generation:0,CreationTimestamp:2019-10-30 11:03:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Oct 30 11:04:14.340: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-4335,SelfLink:/api/v1/namespaces/watch-4335/configmaps/e2e-watch-test-configmap-b,UID:0ee0e0d1-1e1f-4769-9e42-10f678598112,ResourceVersion:16748,Generation:0,CreationTimestamp:2019-10-30 11:04:14 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Oct 30 11:04:14.340: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-4335,SelfLink:/api/v1/namespaces/watch-4335/configmaps/e2e-watch-test-configmap-b,UID:0ee0e0d1-1e1f-4769-9e42-10f678598112,ResourceVersion:16748,Generation:0,CreationTimestamp:2019-10-30 11:04:14 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Oct 30 11:04:24.346: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-4335,SelfLink:/api/v1/namespaces/watch-4335/configmaps/e2e-watch-test-configmap-b,UID:0ee0e0d1-1e1f-4769-9e42-10f678598112,ResourceVersion:16771,Generation:0,CreationTimestamp:2019-10-30 11:04:14 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Oct 30 11:04:24.346: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-4335,SelfLink:/api/v1/namespaces/watch-4335/configmaps/e2e-watch-test-configmap-b,UID:0ee0e0d1-1e1f-4769-9e42-10f678598112,ResourceVersion:16771,Generation:0,CreationTimestamp:2019-10-30 11:04:14 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 11:04:34.346: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-4335" for this suite.
Oct 30 11:04:40.358: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:04:40.423: INFO: namespace watch-4335 deletion completed in 6.073937261s

• [SLOW TEST:66.246 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 11:04:40.423: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-874
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-874.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-874.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-874.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-874.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-874.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-874.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-874.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-874.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-874.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-874.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-874.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-874.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-874.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 53.17.31.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.31.17.53_udp@PTR;check="$$(dig +tcp +noall +answer +search 53.17.31.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.31.17.53_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-874.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-874.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-874.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-874.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-874.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-874.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-874.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-874.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-874.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-874.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-874.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-874.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-874.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 53.17.31.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.31.17.53_udp@PTR;check="$$(dig +tcp +noall +answer +search 53.17.31.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.31.17.53_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Oct 30 11:04:42.584: INFO: Unable to read wheezy_udp@dns-test-service.dns-874.svc.cluster.local from pod dns-874/dns-test-9e2ff519-839e-4fa0-a54c-3dddfc295dd3: the server could not find the requested resource (get pods dns-test-9e2ff519-839e-4fa0-a54c-3dddfc295dd3)
Oct 30 11:04:42.587: INFO: Unable to read wheezy_tcp@dns-test-service.dns-874.svc.cluster.local from pod dns-874/dns-test-9e2ff519-839e-4fa0-a54c-3dddfc295dd3: the server could not find the requested resource (get pods dns-test-9e2ff519-839e-4fa0-a54c-3dddfc295dd3)
Oct 30 11:04:42.589: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-874.svc.cluster.local from pod dns-874/dns-test-9e2ff519-839e-4fa0-a54c-3dddfc295dd3: the server could not find the requested resource (get pods dns-test-9e2ff519-839e-4fa0-a54c-3dddfc295dd3)
Oct 30 11:04:42.592: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-874.svc.cluster.local from pod dns-874/dns-test-9e2ff519-839e-4fa0-a54c-3dddfc295dd3: the server could not find the requested resource (get pods dns-test-9e2ff519-839e-4fa0-a54c-3dddfc295dd3)
Oct 30 11:04:42.599: INFO: Unable to read wheezy_udp@PodARecord from pod dns-874/dns-test-9e2ff519-839e-4fa0-a54c-3dddfc295dd3: the server could not find the requested resource (get pods dns-test-9e2ff519-839e-4fa0-a54c-3dddfc295dd3)
Oct 30 11:04:42.601: INFO: Unable to read wheezy_tcp@PodARecord from pod dns-874/dns-test-9e2ff519-839e-4fa0-a54c-3dddfc295dd3: the server could not find the requested resource (get pods dns-test-9e2ff519-839e-4fa0-a54c-3dddfc295dd3)
Oct 30 11:04:42.608: INFO: Unable to read jessie_udp@dns-test-service.dns-874.svc.cluster.local from pod dns-874/dns-test-9e2ff519-839e-4fa0-a54c-3dddfc295dd3: the server could not find the requested resource (get pods dns-test-9e2ff519-839e-4fa0-a54c-3dddfc295dd3)
Oct 30 11:04:42.610: INFO: Unable to read jessie_tcp@dns-test-service.dns-874.svc.cluster.local from pod dns-874/dns-test-9e2ff519-839e-4fa0-a54c-3dddfc295dd3: the server could not find the requested resource (get pods dns-test-9e2ff519-839e-4fa0-a54c-3dddfc295dd3)
Oct 30 11:04:42.612: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-874.svc.cluster.local from pod dns-874/dns-test-9e2ff519-839e-4fa0-a54c-3dddfc295dd3: the server could not find the requested resource (get pods dns-test-9e2ff519-839e-4fa0-a54c-3dddfc295dd3)
Oct 30 11:04:42.614: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-874.svc.cluster.local from pod dns-874/dns-test-9e2ff519-839e-4fa0-a54c-3dddfc295dd3: the server could not find the requested resource (get pods dns-test-9e2ff519-839e-4fa0-a54c-3dddfc295dd3)
Oct 30 11:04:42.621: INFO: Unable to read jessie_udp@PodARecord from pod dns-874/dns-test-9e2ff519-839e-4fa0-a54c-3dddfc295dd3: the server could not find the requested resource (get pods dns-test-9e2ff519-839e-4fa0-a54c-3dddfc295dd3)
Oct 30 11:04:42.623: INFO: Unable to read jessie_tcp@PodARecord from pod dns-874/dns-test-9e2ff519-839e-4fa0-a54c-3dddfc295dd3: the server could not find the requested resource (get pods dns-test-9e2ff519-839e-4fa0-a54c-3dddfc295dd3)
Oct 30 11:04:42.627: INFO: Lookups using dns-874/dns-test-9e2ff519-839e-4fa0-a54c-3dddfc295dd3 failed for: [wheezy_udp@dns-test-service.dns-874.svc.cluster.local wheezy_tcp@dns-test-service.dns-874.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-874.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-874.svc.cluster.local wheezy_udp@PodARecord wheezy_tcp@PodARecord jessie_udp@dns-test-service.dns-874.svc.cluster.local jessie_tcp@dns-test-service.dns-874.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-874.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-874.svc.cluster.local jessie_udp@PodARecord jessie_tcp@PodARecord]

Oct 30 11:04:47.673: INFO: DNS probes using dns-874/dns-test-9e2ff519-839e-4fa0-a54c-3dddfc295dd3 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 11:04:47.716: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-874" for this suite.
Oct 30 11:04:53.735: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:04:53.813: INFO: namespace dns-874 deletion completed in 6.0901346s

• [SLOW TEST:13.390 seconds]
[sig-network] DNS
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 11:04:53.814: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-9159
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 11:04:55.961: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-9159" for this suite.
Oct 30 11:05:45.971: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:05:46.035: INFO: namespace kubelet-test-9159 deletion completed in 50.071282879s

• [SLOW TEST:52.221 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when scheduling a busybox command in a pod
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:40
    should print the output to logs [NodeConformance] [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 11:05:46.035: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1545
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name projected-secret-test-1abf3d38-18e1-48f3-91af-437764306ae2
STEP: Creating a pod to test consume secrets
Oct 30 11:05:46.180: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-f249bd58-8149-463a-84e9-32d27985f8fa" in namespace "projected-1545" to be "success or failure"
Oct 30 11:05:46.183: INFO: Pod "pod-projected-secrets-f249bd58-8149-463a-84e9-32d27985f8fa": Phase="Pending", Reason="", readiness=false. Elapsed: 2.931241ms
Oct 30 11:05:48.185: INFO: Pod "pod-projected-secrets-f249bd58-8149-463a-84e9-32d27985f8fa": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005382784s
STEP: Saw pod success
Oct 30 11:05:48.185: INFO: Pod "pod-projected-secrets-f249bd58-8149-463a-84e9-32d27985f8fa" satisfied condition "success or failure"
Oct 30 11:05:48.188: INFO: Trying to get logs from node ip-10-1-5-84.eu-central-1.compute.internal pod pod-projected-secrets-f249bd58-8149-463a-84e9-32d27985f8fa container secret-volume-test: <nil>
STEP: delete the pod
Oct 30 11:05:48.202: INFO: Waiting for pod pod-projected-secrets-f249bd58-8149-463a-84e9-32d27985f8fa to disappear
Oct 30 11:05:48.204: INFO: Pod pod-projected-secrets-f249bd58-8149-463a-84e9-32d27985f8fa no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 11:05:48.204: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1545" for this suite.
Oct 30 11:05:54.214: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:05:54.286: INFO: namespace projected-1545 deletion completed in 6.079385739s

• [SLOW TEST:8.251 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 11:05:54.286: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2040
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating the pod
Oct 30 11:05:56.948: INFO: Successfully updated pod "labelsupdatee47019b3-988e-443d-9db8-51f22ef46101"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 11:05:58.961: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2040" for this suite.
Oct 30 11:06:20.971: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:06:21.036: INFO: namespace projected-2040 deletion completed in 22.072193707s

• [SLOW TEST:26.750 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 11:06:21.036: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-7854
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 11:06:23.182: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-7854" for this suite.
Oct 30 11:07:09.192: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:07:09.258: INFO: namespace kubelet-test-7854 deletion completed in 46.07355769s

• [SLOW TEST:48.222 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when scheduling a busybox Pod with hostAliases
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:136
    should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 11:07:09.258: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-3614
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Performing setup for networking test in namespace pod-network-test-3614
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Oct 30 11:07:09.387: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Oct 30 11:07:33.455: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://192.168.4.209:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-3614 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 30 11:07:33.455: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
Oct 30 11:07:33.547: INFO: Found all expected endpoints: [netserver-0]
Oct 30 11:07:33.549: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://192.168.16.82:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-3614 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 30 11:07:33.549: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
Oct 30 11:07:33.641: INFO: Found all expected endpoints: [netserver-1]
Oct 30 11:07:33.643: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://192.168.247.28:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-3614 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 30 11:07:33.643: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
Oct 30 11:07:33.738: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 11:07:33.738: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-3614" for this suite.
Oct 30 11:07:55.750: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:07:55.822: INFO: namespace pod-network-test-3614 deletion completed in 22.080706757s

• [SLOW TEST:46.564 seconds]
[sig-network] Networking
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 11:07:55.822: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-3928
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Oct 30 11:07:55.954: INFO: Waiting up to 5m0s for pod "downward-api-50d947b0-8698-40f5-af41-feae2ee1ce8d" in namespace "downward-api-3928" to be "success or failure"
Oct 30 11:07:55.955: INFO: Pod "downward-api-50d947b0-8698-40f5-af41-feae2ee1ce8d": Phase="Pending", Reason="", readiness=false. Elapsed: 1.838416ms
Oct 30 11:07:57.959: INFO: Pod "downward-api-50d947b0-8698-40f5-af41-feae2ee1ce8d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005239817s
STEP: Saw pod success
Oct 30 11:07:57.959: INFO: Pod "downward-api-50d947b0-8698-40f5-af41-feae2ee1ce8d" satisfied condition "success or failure"
Oct 30 11:07:57.961: INFO: Trying to get logs from node ip-10-1-5-63.eu-central-1.compute.internal pod downward-api-50d947b0-8698-40f5-af41-feae2ee1ce8d container dapi-container: <nil>
STEP: delete the pod
Oct 30 11:07:57.978: INFO: Waiting for pod downward-api-50d947b0-8698-40f5-af41-feae2ee1ce8d to disappear
Oct 30 11:07:57.982: INFO: Pod downward-api-50d947b0-8698-40f5-af41-feae2ee1ce8d no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 11:07:57.983: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3928" for this suite.
Oct 30 11:08:03.993: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:08:04.063: INFO: namespace downward-api-3928 deletion completed in 6.077928839s

• [SLOW TEST:8.241 seconds]
[sig-node] Downward API
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 11:08:04.064: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-4141
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Oct 30 11:08:04.192: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 11:08:06.231: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-4141" for this suite.
Oct 30 11:08:50.242: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:08:50.307: INFO: namespace pods-4141 deletion completed in 44.073295271s

• [SLOW TEST:46.243 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 11:08:50.308: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-7305
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap configmap-7305/configmap-test-1a272177-c5e7-4679-8133-c02dd3530d7a
STEP: Creating a pod to test consume configMaps
Oct 30 11:08:50.449: INFO: Waiting up to 5m0s for pod "pod-configmaps-5b973243-7b52-43fa-932d-e0706c08d7cd" in namespace "configmap-7305" to be "success or failure"
Oct 30 11:08:50.456: INFO: Pod "pod-configmaps-5b973243-7b52-43fa-932d-e0706c08d7cd": Phase="Pending", Reason="", readiness=false. Elapsed: 7.439962ms
Oct 30 11:08:52.459: INFO: Pod "pod-configmaps-5b973243-7b52-43fa-932d-e0706c08d7cd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009563186s
STEP: Saw pod success
Oct 30 11:08:52.459: INFO: Pod "pod-configmaps-5b973243-7b52-43fa-932d-e0706c08d7cd" satisfied condition "success or failure"
Oct 30 11:08:52.460: INFO: Trying to get logs from node ip-10-1-5-63.eu-central-1.compute.internal pod pod-configmaps-5b973243-7b52-43fa-932d-e0706c08d7cd container env-test: <nil>
STEP: delete the pod
Oct 30 11:08:52.472: INFO: Waiting for pod pod-configmaps-5b973243-7b52-43fa-932d-e0706c08d7cd to disappear
Oct 30 11:08:52.474: INFO: Pod pod-configmaps-5b973243-7b52-43fa-932d-e0706c08d7cd no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 11:08:52.474: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7305" for this suite.
Oct 30 11:08:58.483: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:08:58.547: INFO: namespace configmap-7305 deletion completed in 6.071062465s

• [SLOW TEST:8.240 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 11:08:58.548: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-3015
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating the pod
Oct 30 11:09:01.203: INFO: Successfully updated pod "annotationupdatee06afcca-8f56-408a-b253-eb55f100ce07"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 11:09:03.215: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3015" for this suite.
Oct 30 11:09:25.226: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:09:25.290: INFO: namespace downward-api-3015 deletion completed in 22.07236302s

• [SLOW TEST:26.743 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 11:09:25.291: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-1175
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
Oct 30 11:09:25.418: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 11:09:29.634: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-1175" for this suite.
Oct 30 11:09:51.644: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:09:51.709: INFO: namespace init-container-1175 deletion completed in 22.071904397s

• [SLOW TEST:26.418 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 11:09:51.709: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-9964
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Oct 30 11:09:51.848: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Oct 30 11:09:51.853: INFO: DaemonSet pods can't tolerate node ip-10-1-5-17.eu-central-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 11:09:51.855: INFO: Number of nodes with available pods: 0
Oct 30 11:09:51.855: INFO: Node ip-10-1-5-63.eu-central-1.compute.internal is running more than one daemon pod
Oct 30 11:09:52.858: INFO: DaemonSet pods can't tolerate node ip-10-1-5-17.eu-central-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 11:09:52.860: INFO: Number of nodes with available pods: 2
Oct 30 11:09:52.860: INFO: Node ip-10-1-5-65.eu-central-1.compute.internal is running more than one daemon pod
Oct 30 11:09:53.859: INFO: DaemonSet pods can't tolerate node ip-10-1-5-17.eu-central-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 11:09:53.861: INFO: Number of nodes with available pods: 3
Oct 30 11:09:53.861: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Oct 30 11:09:53.877: INFO: Wrong image for pod: daemon-set-6h9nk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 30 11:09:53.877: INFO: Wrong image for pod: daemon-set-9mkst. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 30 11:09:53.877: INFO: Wrong image for pod: daemon-set-gl77z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 30 11:09:53.886: INFO: DaemonSet pods can't tolerate node ip-10-1-5-17.eu-central-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 11:09:54.889: INFO: Wrong image for pod: daemon-set-6h9nk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 30 11:09:54.889: INFO: Wrong image for pod: daemon-set-9mkst. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 30 11:09:54.889: INFO: Wrong image for pod: daemon-set-gl77z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 30 11:09:54.892: INFO: DaemonSet pods can't tolerate node ip-10-1-5-17.eu-central-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 11:09:55.889: INFO: Wrong image for pod: daemon-set-6h9nk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 30 11:09:55.889: INFO: Wrong image for pod: daemon-set-9mkst. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 30 11:09:55.889: INFO: Pod daemon-set-9mkst is not available
Oct 30 11:09:55.889: INFO: Wrong image for pod: daemon-set-gl77z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 30 11:09:55.892: INFO: DaemonSet pods can't tolerate node ip-10-1-5-17.eu-central-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 11:09:56.889: INFO: Wrong image for pod: daemon-set-6h9nk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 30 11:09:56.889: INFO: Wrong image for pod: daemon-set-9mkst. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 30 11:09:56.889: INFO: Pod daemon-set-9mkst is not available
Oct 30 11:09:56.889: INFO: Wrong image for pod: daemon-set-gl77z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 30 11:09:56.892: INFO: DaemonSet pods can't tolerate node ip-10-1-5-17.eu-central-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 11:09:57.889: INFO: Wrong image for pod: daemon-set-6h9nk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 30 11:09:57.889: INFO: Wrong image for pod: daemon-set-9mkst. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 30 11:09:57.889: INFO: Pod daemon-set-9mkst is not available
Oct 30 11:09:57.889: INFO: Wrong image for pod: daemon-set-gl77z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 30 11:09:57.892: INFO: DaemonSet pods can't tolerate node ip-10-1-5-17.eu-central-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 11:09:58.890: INFO: Wrong image for pod: daemon-set-6h9nk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 30 11:09:58.890: INFO: Wrong image for pod: daemon-set-9mkst. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 30 11:09:58.890: INFO: Pod daemon-set-9mkst is not available
Oct 30 11:09:58.890: INFO: Wrong image for pod: daemon-set-gl77z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 30 11:09:58.892: INFO: DaemonSet pods can't tolerate node ip-10-1-5-17.eu-central-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 11:09:59.889: INFO: Wrong image for pod: daemon-set-6h9nk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 30 11:09:59.889: INFO: Wrong image for pod: daemon-set-9mkst. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 30 11:09:59.889: INFO: Pod daemon-set-9mkst is not available
Oct 30 11:09:59.889: INFO: Wrong image for pod: daemon-set-gl77z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 30 11:09:59.892: INFO: DaemonSet pods can't tolerate node ip-10-1-5-17.eu-central-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 11:10:00.889: INFO: Wrong image for pod: daemon-set-6h9nk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 30 11:10:00.889: INFO: Wrong image for pod: daemon-set-9mkst. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 30 11:10:00.889: INFO: Pod daemon-set-9mkst is not available
Oct 30 11:10:00.889: INFO: Wrong image for pod: daemon-set-gl77z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 30 11:10:00.892: INFO: DaemonSet pods can't tolerate node ip-10-1-5-17.eu-central-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 11:10:01.889: INFO: Wrong image for pod: daemon-set-6h9nk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 30 11:10:01.890: INFO: Wrong image for pod: daemon-set-9mkst. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 30 11:10:01.890: INFO: Pod daemon-set-9mkst is not available
Oct 30 11:10:01.890: INFO: Wrong image for pod: daemon-set-gl77z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 30 11:10:01.892: INFO: DaemonSet pods can't tolerate node ip-10-1-5-17.eu-central-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 11:10:02.889: INFO: Wrong image for pod: daemon-set-6h9nk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 30 11:10:02.890: INFO: Wrong image for pod: daemon-set-9mkst. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 30 11:10:02.890: INFO: Pod daemon-set-9mkst is not available
Oct 30 11:10:02.890: INFO: Wrong image for pod: daemon-set-gl77z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 30 11:10:02.892: INFO: DaemonSet pods can't tolerate node ip-10-1-5-17.eu-central-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 11:10:03.890: INFO: Wrong image for pod: daemon-set-6h9nk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 30 11:10:03.890: INFO: Wrong image for pod: daemon-set-9mkst. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 30 11:10:03.890: INFO: Pod daemon-set-9mkst is not available
Oct 30 11:10:03.890: INFO: Wrong image for pod: daemon-set-gl77z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 30 11:10:03.892: INFO: DaemonSet pods can't tolerate node ip-10-1-5-17.eu-central-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 11:10:04.889: INFO: Wrong image for pod: daemon-set-6h9nk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 30 11:10:04.889: INFO: Wrong image for pod: daemon-set-9mkst. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 30 11:10:04.889: INFO: Pod daemon-set-9mkst is not available
Oct 30 11:10:04.889: INFO: Wrong image for pod: daemon-set-gl77z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 30 11:10:04.892: INFO: DaemonSet pods can't tolerate node ip-10-1-5-17.eu-central-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 11:10:05.889: INFO: Wrong image for pod: daemon-set-6h9nk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 30 11:10:05.889: INFO: Wrong image for pod: daemon-set-gl77z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 30 11:10:05.889: INFO: Pod daemon-set-mg2jm is not available
Oct 30 11:10:05.892: INFO: DaemonSet pods can't tolerate node ip-10-1-5-17.eu-central-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 11:10:06.889: INFO: Wrong image for pod: daemon-set-6h9nk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 30 11:10:06.889: INFO: Wrong image for pod: daemon-set-gl77z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 30 11:10:06.889: INFO: Pod daemon-set-mg2jm is not available
Oct 30 11:10:06.892: INFO: DaemonSet pods can't tolerate node ip-10-1-5-17.eu-central-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 11:10:07.889: INFO: Wrong image for pod: daemon-set-6h9nk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 30 11:10:07.889: INFO: Wrong image for pod: daemon-set-gl77z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 30 11:10:07.892: INFO: DaemonSet pods can't tolerate node ip-10-1-5-17.eu-central-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 11:10:08.889: INFO: Wrong image for pod: daemon-set-6h9nk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 30 11:10:08.889: INFO: Pod daemon-set-6h9nk is not available
Oct 30 11:10:08.890: INFO: Wrong image for pod: daemon-set-gl77z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 30 11:10:08.892: INFO: DaemonSet pods can't tolerate node ip-10-1-5-17.eu-central-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 11:10:09.889: INFO: Wrong image for pod: daemon-set-gl77z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 30 11:10:09.889: INFO: Pod daemon-set-whdsm is not available
Oct 30 11:10:09.891: INFO: DaemonSet pods can't tolerate node ip-10-1-5-17.eu-central-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 11:10:10.889: INFO: Wrong image for pod: daemon-set-gl77z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 30 11:10:10.892: INFO: DaemonSet pods can't tolerate node ip-10-1-5-17.eu-central-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 11:10:11.890: INFO: Wrong image for pod: daemon-set-gl77z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 30 11:10:11.890: INFO: Pod daemon-set-gl77z is not available
Oct 30 11:10:11.892: INFO: DaemonSet pods can't tolerate node ip-10-1-5-17.eu-central-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 11:10:12.889: INFO: Wrong image for pod: daemon-set-gl77z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 30 11:10:12.889: INFO: Pod daemon-set-gl77z is not available
Oct 30 11:10:12.892: INFO: DaemonSet pods can't tolerate node ip-10-1-5-17.eu-central-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 11:10:13.890: INFO: Wrong image for pod: daemon-set-gl77z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 30 11:10:13.890: INFO: Pod daemon-set-gl77z is not available
Oct 30 11:10:13.892: INFO: DaemonSet pods can't tolerate node ip-10-1-5-17.eu-central-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 11:10:14.889: INFO: Wrong image for pod: daemon-set-gl77z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 30 11:10:14.889: INFO: Pod daemon-set-gl77z is not available
Oct 30 11:10:14.892: INFO: DaemonSet pods can't tolerate node ip-10-1-5-17.eu-central-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 11:10:15.889: INFO: Wrong image for pod: daemon-set-gl77z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 30 11:10:15.889: INFO: Pod daemon-set-gl77z is not available
Oct 30 11:10:15.892: INFO: DaemonSet pods can't tolerate node ip-10-1-5-17.eu-central-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 11:10:16.891: INFO: Wrong image for pod: daemon-set-gl77z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 30 11:10:16.891: INFO: Pod daemon-set-gl77z is not available
Oct 30 11:10:16.894: INFO: DaemonSet pods can't tolerate node ip-10-1-5-17.eu-central-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 11:10:17.889: INFO: Wrong image for pod: daemon-set-gl77z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 30 11:10:17.889: INFO: Pod daemon-set-gl77z is not available
Oct 30 11:10:17.892: INFO: DaemonSet pods can't tolerate node ip-10-1-5-17.eu-central-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 11:10:18.889: INFO: Wrong image for pod: daemon-set-gl77z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 30 11:10:18.889: INFO: Pod daemon-set-gl77z is not available
Oct 30 11:10:18.891: INFO: DaemonSet pods can't tolerate node ip-10-1-5-17.eu-central-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 11:10:19.889: INFO: Wrong image for pod: daemon-set-gl77z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 30 11:10:19.889: INFO: Pod daemon-set-gl77z is not available
Oct 30 11:10:19.892: INFO: DaemonSet pods can't tolerate node ip-10-1-5-17.eu-central-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 11:10:20.889: INFO: Pod daemon-set-xkp8x is not available
Oct 30 11:10:20.892: INFO: DaemonSet pods can't tolerate node ip-10-1-5-17.eu-central-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
STEP: Check that daemon pods are still running on every node of the cluster.
Oct 30 11:10:20.894: INFO: DaemonSet pods can't tolerate node ip-10-1-5-17.eu-central-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 11:10:20.896: INFO: Number of nodes with available pods: 2
Oct 30 11:10:20.896: INFO: Node ip-10-1-5-65.eu-central-1.compute.internal is running more than one daemon pod
Oct 30 11:10:21.900: INFO: DaemonSet pods can't tolerate node ip-10-1-5-17.eu-central-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 11:10:21.902: INFO: Number of nodes with available pods: 2
Oct 30 11:10:21.902: INFO: Node ip-10-1-5-65.eu-central-1.compute.internal is running more than one daemon pod
Oct 30 11:10:22.900: INFO: DaemonSet pods can't tolerate node ip-10-1-5-17.eu-central-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 11:10:22.902: INFO: Number of nodes with available pods: 2
Oct 30 11:10:22.902: INFO: Node ip-10-1-5-65.eu-central-1.compute.internal is running more than one daemon pod
Oct 30 11:10:23.899: INFO: DaemonSet pods can't tolerate node ip-10-1-5-17.eu-central-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 11:10:23.902: INFO: Number of nodes with available pods: 3
Oct 30 11:10:23.902: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-9964, will wait for the garbage collector to delete the pods
Oct 30 11:10:23.969: INFO: Deleting DaemonSet.extensions daemon-set took: 4.813457ms
Oct 30 11:10:24.069: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.219728ms
Oct 30 11:10:30.871: INFO: Number of nodes with available pods: 0
Oct 30 11:10:30.871: INFO: Number of running nodes: 0, number of available pods: 0
Oct 30 11:10:30.873: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-9964/daemonsets","resourceVersion":"18310"},"items":null}

Oct 30 11:10:30.875: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-9964/pods","resourceVersion":"18310"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 11:10:30.883: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-9964" for this suite.
Oct 30 11:10:36.892: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:10:36.956: INFO: namespace daemonsets-9964 deletion completed in 6.070831254s

• [SLOW TEST:45.247 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 11:10:36.956: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-2092
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Oct 30 11:10:37.094: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a82259ab-78a7-4058-8893-15341691cc34" in namespace "downward-api-2092" to be "success or failure"
Oct 30 11:10:37.096: INFO: Pod "downwardapi-volume-a82259ab-78a7-4058-8893-15341691cc34": Phase="Pending", Reason="", readiness=false. Elapsed: 1.845996ms
Oct 30 11:10:39.098: INFO: Pod "downwardapi-volume-a82259ab-78a7-4058-8893-15341691cc34": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004012411s
STEP: Saw pod success
Oct 30 11:10:39.098: INFO: Pod "downwardapi-volume-a82259ab-78a7-4058-8893-15341691cc34" satisfied condition "success or failure"
Oct 30 11:10:39.100: INFO: Trying to get logs from node ip-10-1-5-84.eu-central-1.compute.internal pod downwardapi-volume-a82259ab-78a7-4058-8893-15341691cc34 container client-container: <nil>
STEP: delete the pod
Oct 30 11:10:39.112: INFO: Waiting for pod downwardapi-volume-a82259ab-78a7-4058-8893-15341691cc34 to disappear
Oct 30 11:10:39.114: INFO: Pod downwardapi-volume-a82259ab-78a7-4058-8893-15341691cc34 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 11:10:39.114: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2092" for this suite.
Oct 30 11:10:45.124: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:10:45.194: INFO: namespace downward-api-2092 deletion completed in 6.076777109s

• [SLOW TEST:8.238 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 11:10:45.194: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-576
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-configmap-xpng
STEP: Creating a pod to test atomic-volume-subpath
Oct 30 11:10:45.330: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-xpng" in namespace "subpath-576" to be "success or failure"
Oct 30 11:10:45.333: INFO: Pod "pod-subpath-test-configmap-xpng": Phase="Pending", Reason="", readiness=false. Elapsed: 2.501064ms
Oct 30 11:10:47.336: INFO: Pod "pod-subpath-test-configmap-xpng": Phase="Running", Reason="", readiness=true. Elapsed: 2.005300093s
Oct 30 11:10:49.339: INFO: Pod "pod-subpath-test-configmap-xpng": Phase="Running", Reason="", readiness=true. Elapsed: 4.008177868s
Oct 30 11:10:51.341: INFO: Pod "pod-subpath-test-configmap-xpng": Phase="Running", Reason="", readiness=true. Elapsed: 6.010635484s
Oct 30 11:10:53.343: INFO: Pod "pod-subpath-test-configmap-xpng": Phase="Running", Reason="", readiness=true. Elapsed: 8.012937929s
Oct 30 11:10:55.346: INFO: Pod "pod-subpath-test-configmap-xpng": Phase="Running", Reason="", readiness=true. Elapsed: 10.015298463s
Oct 30 11:10:57.349: INFO: Pod "pod-subpath-test-configmap-xpng": Phase="Running", Reason="", readiness=true. Elapsed: 12.018073301s
Oct 30 11:10:59.351: INFO: Pod "pod-subpath-test-configmap-xpng": Phase="Running", Reason="", readiness=true. Elapsed: 14.020619664s
Oct 30 11:11:01.354: INFO: Pod "pod-subpath-test-configmap-xpng": Phase="Running", Reason="", readiness=true. Elapsed: 16.023186761s
Oct 30 11:11:03.356: INFO: Pod "pod-subpath-test-configmap-xpng": Phase="Running", Reason="", readiness=true. Elapsed: 18.025545269s
Oct 30 11:11:05.358: INFO: Pod "pod-subpath-test-configmap-xpng": Phase="Running", Reason="", readiness=true. Elapsed: 20.027635072s
Oct 30 11:11:07.361: INFO: Pod "pod-subpath-test-configmap-xpng": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.03036824s
STEP: Saw pod success
Oct 30 11:11:07.361: INFO: Pod "pod-subpath-test-configmap-xpng" satisfied condition "success or failure"
Oct 30 11:11:07.363: INFO: Trying to get logs from node ip-10-1-5-63.eu-central-1.compute.internal pod pod-subpath-test-configmap-xpng container test-container-subpath-configmap-xpng: <nil>
STEP: delete the pod
Oct 30 11:11:07.375: INFO: Waiting for pod pod-subpath-test-configmap-xpng to disappear
Oct 30 11:11:07.377: INFO: Pod pod-subpath-test-configmap-xpng no longer exists
STEP: Deleting pod pod-subpath-test-configmap-xpng
Oct 30 11:11:07.377: INFO: Deleting pod "pod-subpath-test-configmap-xpng" in namespace "subpath-576"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 11:11:07.378: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-576" for this suite.
Oct 30 11:11:13.388: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:11:13.455: INFO: namespace subpath-576 deletion completed in 6.073395306s

• [SLOW TEST:28.261 seconds]
[sig-storage] Subpath
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with configmap pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 11:11:13.455: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-3615
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir volume type on node default medium
Oct 30 11:11:13.587: INFO: Waiting up to 5m0s for pod "pod-8387aee0-21b5-45bf-b15a-94631bfbce4f" in namespace "emptydir-3615" to be "success or failure"
Oct 30 11:11:13.589: INFO: Pod "pod-8387aee0-21b5-45bf-b15a-94631bfbce4f": Phase="Pending", Reason="", readiness=false. Elapsed: 1.759417ms
Oct 30 11:11:15.592: INFO: Pod "pod-8387aee0-21b5-45bf-b15a-94631bfbce4f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004584104s
STEP: Saw pod success
Oct 30 11:11:15.592: INFO: Pod "pod-8387aee0-21b5-45bf-b15a-94631bfbce4f" satisfied condition "success or failure"
Oct 30 11:11:15.593: INFO: Trying to get logs from node ip-10-1-5-84.eu-central-1.compute.internal pod pod-8387aee0-21b5-45bf-b15a-94631bfbce4f container test-container: <nil>
STEP: delete the pod
Oct 30 11:11:15.606: INFO: Waiting for pod pod-8387aee0-21b5-45bf-b15a-94631bfbce4f to disappear
Oct 30 11:11:15.608: INFO: Pod pod-8387aee0-21b5-45bf-b15a-94631bfbce4f no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 11:11:15.608: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3615" for this suite.
Oct 30 11:11:21.618: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:11:21.683: INFO: namespace emptydir-3615 deletion completed in 6.072252673s

• [SLOW TEST:8.228 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 11:11:21.684: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-3220
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: validating api versions
Oct 30 11:11:21.811: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 api-versions'
Oct 30 11:11:21.876: INFO: stderr: ""
Oct 30 11:11:21.876: INFO: stdout: "admissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napplication.giantswarm.io/v1alpha1\napps/v1\napps/v1beta1\napps/v1beta2\nauditregistration.k8s.io/v1alpha1\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\nbatch/v2alpha1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1\ncoordination.k8s.io/v1beta1\ncore.giantswarm.io/v1alpha1\ncrd.projectcalico.org/v1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nmetrics.k8s.io/v1beta1\nnetworking.k8s.io/v1\nnetworking.k8s.io/v1beta1\nnode.k8s.io/v1alpha1\nnode.k8s.io/v1beta1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1alpha1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1\nscheduling.k8s.io/v1alpha1\nscheduling.k8s.io/v1beta1\nsettings.k8s.io/v1alpha1\nstorage.k8s.io/v1\nstorage.k8s.io/v1alpha1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 11:11:21.876: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3220" for this suite.
Oct 30 11:11:27.886: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:11:27.959: INFO: namespace kubectl-3220 deletion completed in 6.080306941s

• [SLOW TEST:6.276 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl api-versions
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 11:11:27.960: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-1982
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:273
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a replication controller
Oct 30 11:11:28.096: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 create -f - --namespace=kubectl-1982'
Oct 30 11:11:28.428: INFO: stderr: ""
Oct 30 11:11:28.428: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Oct 30 11:11:28.428: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1982'
Oct 30 11:11:28.501: INFO: stderr: ""
Oct 30 11:11:28.501: INFO: stdout: "update-demo-nautilus-qggs5 update-demo-nautilus-x4hfk "
Oct 30 11:11:28.501: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 get pods update-demo-nautilus-qggs5 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1982'
Oct 30 11:11:28.564: INFO: stderr: ""
Oct 30 11:11:28.564: INFO: stdout: ""
Oct 30 11:11:28.564: INFO: update-demo-nautilus-qggs5 is created but not running
Oct 30 11:11:33.564: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1982'
Oct 30 11:11:33.630: INFO: stderr: ""
Oct 30 11:11:33.630: INFO: stdout: "update-demo-nautilus-qggs5 update-demo-nautilus-x4hfk "
Oct 30 11:11:33.630: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 get pods update-demo-nautilus-qggs5 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1982'
Oct 30 11:11:33.692: INFO: stderr: ""
Oct 30 11:11:33.692: INFO: stdout: "true"
Oct 30 11:11:33.693: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 get pods update-demo-nautilus-qggs5 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1982'
Oct 30 11:11:33.755: INFO: stderr: ""
Oct 30 11:11:33.755: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Oct 30 11:11:33.755: INFO: validating pod update-demo-nautilus-qggs5
Oct 30 11:11:33.758: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct 30 11:11:33.758: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct 30 11:11:33.758: INFO: update-demo-nautilus-qggs5 is verified up and running
Oct 30 11:11:33.758: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 get pods update-demo-nautilus-x4hfk -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1982'
Oct 30 11:11:33.831: INFO: stderr: ""
Oct 30 11:11:33.831: INFO: stdout: "true"
Oct 30 11:11:33.831: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 get pods update-demo-nautilus-x4hfk -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1982'
Oct 30 11:11:33.894: INFO: stderr: ""
Oct 30 11:11:33.894: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Oct 30 11:11:33.894: INFO: validating pod update-demo-nautilus-x4hfk
Oct 30 11:11:33.897: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct 30 11:11:33.897: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct 30 11:11:33.897: INFO: update-demo-nautilus-x4hfk is verified up and running
STEP: using delete to clean up resources
Oct 30 11:11:33.897: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 delete --grace-period=0 --force -f - --namespace=kubectl-1982'
Oct 30 11:11:33.961: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct 30 11:11:33.961: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Oct 30 11:11:33.962: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-1982'
Oct 30 11:11:34.050: INFO: stderr: "No resources found.\n"
Oct 30 11:11:34.050: INFO: stdout: ""
Oct 30 11:11:34.050: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 get pods -l name=update-demo --namespace=kubectl-1982 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Oct 30 11:11:34.143: INFO: stderr: ""
Oct 30 11:11:34.143: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 11:11:34.143: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1982" for this suite.
Oct 30 11:11:56.154: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:11:56.219: INFO: namespace kubectl-1982 deletion completed in 22.071722384s

• [SLOW TEST:28.260 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 11:11:56.220: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-948
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-948
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a new StatefulSet
Oct 30 11:11:56.357: INFO: Found 0 stateful pods, waiting for 3
Oct 30 11:12:06.360: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Oct 30 11:12:06.360: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Oct 30 11:12:06.360: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Oct 30 11:12:06.366: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 exec --namespace=statefulset-948 ss2-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Oct 30 11:12:06.528: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Oct 30 11:12:06.528: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Oct 30 11:12:06.528: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Oct 30 11:12:16.552: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Oct 30 11:12:26.564: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 exec --namespace=statefulset-948 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 30 11:12:26.737: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Oct 30 11:12:26.737: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Oct 30 11:12:26.737: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Oct 30 11:12:46.750: INFO: Waiting for StatefulSet statefulset-948/ss2 to complete update
STEP: Rolling back to a previous revision
Oct 30 11:12:56.756: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 exec --namespace=statefulset-948 ss2-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Oct 30 11:12:56.919: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Oct 30 11:12:56.919: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Oct 30 11:12:56.919: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Oct 30 11:13:06.943: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Oct 30 11:13:16.955: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 exec --namespace=statefulset-948 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 30 11:13:17.121: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Oct 30 11:13:17.121: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Oct 30 11:13:17.121: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Oct 30 11:13:37.133: INFO: Waiting for StatefulSet statefulset-948/ss2 to complete update
Oct 30 11:13:37.134: INFO: Waiting for Pod statefulset-948/ss2-0 to have revision ss2-7c9b54fd4c update revision ss2-6c5cd755cd
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Oct 30 11:13:47.138: INFO: Deleting all statefulset in ns statefulset-948
Oct 30 11:13:47.140: INFO: Scaling statefulset ss2 to 0
Oct 30 11:14:07.150: INFO: Waiting for statefulset status.replicas updated to 0
Oct 30 11:14:07.151: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 11:14:07.162: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-948" for this suite.
Oct 30 11:14:13.172: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:14:13.238: INFO: namespace statefulset-948 deletion completed in 6.073083257s

• [SLOW TEST:137.018 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 11:14:13.238: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-1592
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1685
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Oct 30 11:14:13.365: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-1592'
Oct 30 11:14:13.439: INFO: stderr: ""
Oct 30 11:14:13.439: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1690
Oct 30 11:14:13.441: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 delete pods e2e-test-nginx-pod --namespace=kubectl-1592'
Oct 30 11:14:15.799: INFO: stderr: ""
Oct 30 11:14:15.799: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 11:14:15.799: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1592" for this suite.
Oct 30 11:14:21.814: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:14:21.888: INFO: namespace kubectl-1592 deletion completed in 6.086361439s

• [SLOW TEST:8.650 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run pod
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 11:14:21.889: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in namespaces-3116
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-2663
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-3892
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 11:14:46.279: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-3116" for this suite.
Oct 30 11:14:52.288: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:14:52.355: INFO: namespace namespaces-3116 deletion completed in 6.073013125s
STEP: Destroying namespace "nsdeletetest-2663" for this suite.
Oct 30 11:14:52.357: INFO: Namespace nsdeletetest-2663 was already deleted
STEP: Destroying namespace "nsdeletetest-3892" for this suite.
Oct 30 11:14:58.363: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:14:58.428: INFO: namespace nsdeletetest-3892 deletion completed in 6.071102388s

• [SLOW TEST:36.539 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 11:14:58.429: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-2181
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1612
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Oct 30 11:14:58.556: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-2181'
Oct 30 11:14:58.632: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Oct 30 11:14:58.632: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
STEP: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1617
Oct 30 11:14:58.637: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 delete jobs e2e-test-nginx-job --namespace=kubectl-2181'
Oct 30 11:14:58.706: INFO: stderr: ""
Oct 30 11:14:58.706: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 11:14:58.706: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2181" for this suite.
Oct 30 11:15:20.717: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:15:20.782: INFO: namespace kubectl-2181 deletion completed in 22.072411348s

• [SLOW TEST:22.353 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run job
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 11:15:20.782: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-8304
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:179
[It] should be submitted and removed  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 11:15:20.918: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-8304" for this suite.
Oct 30 11:15:42.931: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:15:42.995: INFO: namespace pods-8304 deletion completed in 22.072206789s

• [SLOW TEST:22.213 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should be submitted and removed  [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-storage] EmptyDir volumes 
  pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 11:15:42.995: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-6087
STEP: Waiting for a default service account to be provisioned in namespace
[It] pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating Pod
STEP: Waiting for the pod running
STEP: Geting the pod
STEP: Reading file content from the nginx-container
Oct 30 11:15:45.139: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 exec pod-sharedvolume-ea59cd96-3ae6-4d8e-9e82-ec0608f90399 -c busybox-main-container --namespace=emptydir-6087 -- cat /usr/share/volumeshare/shareddata.txt'
Oct 30 11:15:45.296: INFO: stderr: ""
Oct 30 11:15:45.296: INFO: stdout: "Hello from the busy-box sub-container\n"
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 11:15:45.296: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6087" for this suite.
Oct 30 11:15:51.306: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:15:51.371: INFO: namespace emptydir-6087 deletion completed in 6.072134001s

• [SLOW TEST:8.376 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 11:15:51.371: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-3137
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-d96b6428-63c9-4f3e-8470-55398554eb36
STEP: Creating a pod to test consume secrets
Oct 30 11:15:51.505: INFO: Waiting up to 5m0s for pod "pod-secrets-bcb28682-7116-4536-9597-285d426fd9c3" in namespace "secrets-3137" to be "success or failure"
Oct 30 11:15:51.507: INFO: Pod "pod-secrets-bcb28682-7116-4536-9597-285d426fd9c3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.575872ms
Oct 30 11:15:53.510: INFO: Pod "pod-secrets-bcb28682-7116-4536-9597-285d426fd9c3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004726734s
STEP: Saw pod success
Oct 30 11:15:53.510: INFO: Pod "pod-secrets-bcb28682-7116-4536-9597-285d426fd9c3" satisfied condition "success or failure"
Oct 30 11:15:53.511: INFO: Trying to get logs from node ip-10-1-5-63.eu-central-1.compute.internal pod pod-secrets-bcb28682-7116-4536-9597-285d426fd9c3 container secret-volume-test: <nil>
STEP: delete the pod
Oct 30 11:15:53.524: INFO: Waiting for pod pod-secrets-bcb28682-7116-4536-9597-285d426fd9c3 to disappear
Oct 30 11:15:53.526: INFO: Pod pod-secrets-bcb28682-7116-4536-9597-285d426fd9c3 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 11:15:53.526: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3137" for this suite.
Oct 30 11:15:59.536: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:15:59.602: INFO: namespace secrets-3137 deletion completed in 6.073410944s

• [SLOW TEST:8.231 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 11:15:59.602: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-7372
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Oct 30 11:16:01.757: INFO: Waiting up to 5m0s for pod "client-envvars-9ae92f1e-7f8e-49dd-8933-d6a55f95933b" in namespace "pods-7372" to be "success or failure"
Oct 30 11:16:01.760: INFO: Pod "client-envvars-9ae92f1e-7f8e-49dd-8933-d6a55f95933b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.47195ms
Oct 30 11:16:03.762: INFO: Pod "client-envvars-9ae92f1e-7f8e-49dd-8933-d6a55f95933b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004594204s
STEP: Saw pod success
Oct 30 11:16:03.762: INFO: Pod "client-envvars-9ae92f1e-7f8e-49dd-8933-d6a55f95933b" satisfied condition "success or failure"
Oct 30 11:16:03.764: INFO: Trying to get logs from node ip-10-1-5-63.eu-central-1.compute.internal pod client-envvars-9ae92f1e-7f8e-49dd-8933-d6a55f95933b container env3cont: <nil>
STEP: delete the pod
Oct 30 11:16:03.776: INFO: Waiting for pod client-envvars-9ae92f1e-7f8e-49dd-8933-d6a55f95933b to disappear
Oct 30 11:16:03.778: INFO: Pod client-envvars-9ae92f1e-7f8e-49dd-8933-d6a55f95933b no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 11:16:03.779: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-7372" for this suite.
Oct 30 11:16:49.788: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:16:49.862: INFO: namespace pods-7372 deletion completed in 46.081571391s

• [SLOW TEST:50.260 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 11:16:49.863: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-9258
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Oct 30 11:16:52.007: INFO: Expected: &{OK} to match Container's Termination Message: OK --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 11:16:52.017: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-9258" for this suite.
Oct 30 11:16:58.027: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:16:58.093: INFO: namespace container-runtime-9258 deletion completed in 6.073363376s

• [SLOW TEST:8.231 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  blackbox test
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
    on terminated container
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:129
      should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 11:16:58.094: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-9213
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:81
Oct 30 11:16:58.252: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Oct 30 11:16:58.257: INFO: Waiting for terminating namespaces to be deleted...
Oct 30 11:16:58.259: INFO: 
Logging pods the kubelet thinks is on node ip-10-1-5-63.eu-central-1.compute.internal before test
Oct 30 11:16:58.264: INFO: cert-exporter-67tpq from kube-system started at 2019-10-30 10:09:15 +0000 UTC (1 container statuses recorded)
Oct 30 11:16:58.264: INFO: 	Container cert-exporter ready: true, restart count 0
Oct 30 11:16:58.264: INFO: net-exporter-t8hlz from kube-system started at 2019-10-30 10:09:19 +0000 UTC (1 container statuses recorded)
Oct 30 11:16:58.264: INFO: 	Container net-exporter ready: true, restart count 0
Oct 30 11:16:58.264: INFO: sonobuoy-systemd-logs-daemon-set-2bfde314293a499b-dvzqw from sonobuoy started at 2019-10-30 10:21:44 +0000 UTC (2 container statuses recorded)
Oct 30 11:16:58.264: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct 30 11:16:58.264: INFO: 	Container systemd-logs ready: true, restart count 0
Oct 30 11:16:58.264: INFO: nginx-ingress-controller-867c6c9bd-9xqzh from kube-system started at 2019-10-30 10:09:20 +0000 UTC (1 container statuses recorded)
Oct 30 11:16:58.264: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Oct 30 11:16:58.264: INFO: kube-proxy-zs4h7 from kube-system started at 2019-10-30 10:03:22 +0000 UTC (1 container statuses recorded)
Oct 30 11:16:58.264: INFO: 	Container kube-proxy ready: true, restart count 0
Oct 30 11:16:58.264: INFO: calico-node-6vhqd from kube-system started at 2019-10-30 10:03:31 +0000 UTC (1 container statuses recorded)
Oct 30 11:16:58.264: INFO: 	Container calico-node ready: true, restart count 0
Oct 30 11:16:58.264: INFO: coredns-7b76874c7b-rp58r from kube-system started at 2019-10-30 10:09:10 +0000 UTC (1 container statuses recorded)
Oct 30 11:16:58.264: INFO: 	Container coredns ready: true, restart count 0
Oct 30 11:16:58.264: INFO: node-exporter-gflqf from kube-system started at 2019-10-30 10:09:37 +0000 UTC (1 container statuses recorded)
Oct 30 11:16:58.264: INFO: 	Container node-exporter ready: true, restart count 0
Oct 30 11:16:58.264: INFO: 
Logging pods the kubelet thinks is on node ip-10-1-5-65.eu-central-1.compute.internal before test
Oct 30 11:16:58.269: INFO: net-exporter-tjtcq from kube-system started at 2019-10-30 10:09:20 +0000 UTC (1 container statuses recorded)
Oct 30 11:16:58.269: INFO: 	Container net-exporter ready: true, restart count 0
Oct 30 11:16:58.269: INFO: kube-state-metrics-586fbd9595-zhpcd from kube-system started at 2019-10-30 10:10:02 +0000 UTC (2 container statuses recorded)
Oct 30 11:16:58.269: INFO: 	Container addon-resizer ready: true, restart count 0
Oct 30 11:16:58.269: INFO: 	Container kube-state-metrics ready: true, restart count 0
Oct 30 11:16:58.269: INFO: sonobuoy-systemd-logs-daemon-set-2bfde314293a499b-vdwzq from sonobuoy started at 2019-10-30 10:21:44 +0000 UTC (2 container statuses recorded)
Oct 30 11:16:58.269: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct 30 11:16:58.269: INFO: 	Container systemd-logs ready: true, restart count 0
Oct 30 11:16:58.269: INFO: kube-proxy-kfnkf from kube-system started at 2019-10-30 10:03:22 +0000 UTC (1 container statuses recorded)
Oct 30 11:16:58.269: INFO: 	Container kube-proxy ready: true, restart count 0
Oct 30 11:16:58.269: INFO: calico-node-t7qtg from kube-system started at 2019-10-30 10:03:31 +0000 UTC (1 container statuses recorded)
Oct 30 11:16:58.269: INFO: 	Container calico-node ready: true, restart count 0
Oct 30 11:16:58.269: INFO: coredns-7b76874c7b-g8w49 from kube-system started at 2019-10-30 10:09:10 +0000 UTC (1 container statuses recorded)
Oct 30 11:16:58.269: INFO: 	Container coredns ready: true, restart count 0
Oct 30 11:16:58.269: INFO: cert-exporter-nvkcc from kube-system started at 2019-10-30 10:09:15 +0000 UTC (1 container statuses recorded)
Oct 30 11:16:58.269: INFO: 	Container cert-exporter ready: true, restart count 0
Oct 30 11:16:58.269: INFO: metrics-server-586d4684b4-gg69x from kube-system started at 2019-10-30 10:09:35 +0000 UTC (1 container statuses recorded)
Oct 30 11:16:58.269: INFO: 	Container metrics-server ready: true, restart count 0
Oct 30 11:16:58.269: INFO: node-exporter-chfs6 from kube-system started at 2019-10-30 10:09:37 +0000 UTC (1 container statuses recorded)
Oct 30 11:16:58.269: INFO: 	Container node-exporter ready: true, restart count 0
Oct 30 11:16:58.269: INFO: nginx-ingress-controller-867c6c9bd-zvrzn from kube-system started at 2019-10-30 10:09:51 +0000 UTC (1 container statuses recorded)
Oct 30 11:16:58.269: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Oct 30 11:16:58.269: INFO: 
Logging pods the kubelet thinks is on node ip-10-1-5-84.eu-central-1.compute.internal before test
Oct 30 11:16:58.274: INFO: tiller-deploy-5db95cf576-vw4c4 from giantswarm started at 2019-10-30 10:08:12 +0000 UTC (1 container statuses recorded)
Oct 30 11:16:58.274: INFO: 	Container tiller ready: true, restart count 0
Oct 30 11:16:58.274: INFO: cert-exporter-r65jk from kube-system started at 2019-10-30 10:09:16 +0000 UTC (1 container statuses recorded)
Oct 30 11:16:58.274: INFO: 	Container cert-exporter ready: true, restart count 0
Oct 30 11:16:58.274: INFO: net-exporter-dvjrr from kube-system started at 2019-10-30 10:09:18 +0000 UTC (1 container statuses recorded)
Oct 30 11:16:58.274: INFO: 	Container net-exporter ready: true, restart count 0
Oct 30 11:16:58.274: INFO: nginx-ingress-controller-867c6c9bd-797qw from kube-system started at 2019-10-30 10:09:20 +0000 UTC (1 container statuses recorded)
Oct 30 11:16:58.274: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Oct 30 11:16:58.274: INFO: node-exporter-d55hm from kube-system started at 2019-10-30 10:09:37 +0000 UTC (1 container statuses recorded)
Oct 30 11:16:58.274: INFO: 	Container node-exporter ready: true, restart count 0
Oct 30 11:16:58.274: INFO: calico-node-qhcm8 from kube-system started at 2019-10-30 10:04:08 +0000 UTC (1 container statuses recorded)
Oct 30 11:16:58.274: INFO: 	Container calico-node ready: true, restart count 0
Oct 30 11:16:58.274: INFO: sonobuoy from sonobuoy started at 2019-10-30 10:21:39 +0000 UTC (1 container statuses recorded)
Oct 30 11:16:58.274: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Oct 30 11:16:58.275: INFO: sonobuoy-e2e-job-43cf25cf09454f64 from sonobuoy started at 2019-10-30 10:21:44 +0000 UTC (2 container statuses recorded)
Oct 30 11:16:58.275: INFO: 	Container e2e ready: true, restart count 0
Oct 30 11:16:58.275: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct 30 11:16:58.275: INFO: sonobuoy-systemd-logs-daemon-set-2bfde314293a499b-5db6l from sonobuoy started at 2019-10-30 10:21:44 +0000 UTC (2 container statuses recorded)
Oct 30 11:16:58.275: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct 30 11:16:58.275: INFO: 	Container systemd-logs ready: true, restart count 0
Oct 30 11:16:58.275: INFO: kube-proxy-rvmrx from kube-system started at 2019-10-30 10:04:08 +0000 UTC (1 container statuses recorded)
Oct 30 11:16:58.275: INFO: 	Container kube-proxy ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: verifying the node has the label node ip-10-1-5-63.eu-central-1.compute.internal
STEP: verifying the node has the label node ip-10-1-5-65.eu-central-1.compute.internal
STEP: verifying the node has the label node ip-10-1-5-84.eu-central-1.compute.internal
Oct 30 11:16:58.315: INFO: Pod tiller-deploy-5db95cf576-vw4c4 requesting resource cpu=0m on Node ip-10-1-5-84.eu-central-1.compute.internal
Oct 30 11:16:58.315: INFO: Pod calico-node-6vhqd requesting resource cpu=250m on Node ip-10-1-5-63.eu-central-1.compute.internal
Oct 30 11:16:58.315: INFO: Pod calico-node-qhcm8 requesting resource cpu=250m on Node ip-10-1-5-84.eu-central-1.compute.internal
Oct 30 11:16:58.315: INFO: Pod calico-node-t7qtg requesting resource cpu=250m on Node ip-10-1-5-65.eu-central-1.compute.internal
Oct 30 11:16:58.315: INFO: Pod cert-exporter-67tpq requesting resource cpu=50m on Node ip-10-1-5-63.eu-central-1.compute.internal
Oct 30 11:16:58.315: INFO: Pod cert-exporter-nvkcc requesting resource cpu=50m on Node ip-10-1-5-65.eu-central-1.compute.internal
Oct 30 11:16:58.315: INFO: Pod cert-exporter-r65jk requesting resource cpu=50m on Node ip-10-1-5-84.eu-central-1.compute.internal
Oct 30 11:16:58.315: INFO: Pod coredns-7b76874c7b-g8w49 requesting resource cpu=250m on Node ip-10-1-5-65.eu-central-1.compute.internal
Oct 30 11:16:58.315: INFO: Pod coredns-7b76874c7b-rp58r requesting resource cpu=250m on Node ip-10-1-5-63.eu-central-1.compute.internal
Oct 30 11:16:58.315: INFO: Pod kube-proxy-kfnkf requesting resource cpu=75m on Node ip-10-1-5-65.eu-central-1.compute.internal
Oct 30 11:16:58.315: INFO: Pod kube-proxy-rvmrx requesting resource cpu=75m on Node ip-10-1-5-84.eu-central-1.compute.internal
Oct 30 11:16:58.315: INFO: Pod kube-proxy-zs4h7 requesting resource cpu=75m on Node ip-10-1-5-63.eu-central-1.compute.internal
Oct 30 11:16:58.315: INFO: Pod kube-state-metrics-586fbd9595-zhpcd requesting resource cpu=490m on Node ip-10-1-5-65.eu-central-1.compute.internal
Oct 30 11:16:58.315: INFO: Pod metrics-server-586d4684b4-gg69x requesting resource cpu=0m on Node ip-10-1-5-65.eu-central-1.compute.internal
Oct 30 11:16:58.315: INFO: Pod net-exporter-dvjrr requesting resource cpu=0m on Node ip-10-1-5-84.eu-central-1.compute.internal
Oct 30 11:16:58.315: INFO: Pod net-exporter-t8hlz requesting resource cpu=0m on Node ip-10-1-5-63.eu-central-1.compute.internal
Oct 30 11:16:58.315: INFO: Pod net-exporter-tjtcq requesting resource cpu=0m on Node ip-10-1-5-65.eu-central-1.compute.internal
Oct 30 11:16:58.315: INFO: Pod nginx-ingress-controller-867c6c9bd-797qw requesting resource cpu=500m on Node ip-10-1-5-84.eu-central-1.compute.internal
Oct 30 11:16:58.315: INFO: Pod nginx-ingress-controller-867c6c9bd-9xqzh requesting resource cpu=500m on Node ip-10-1-5-63.eu-central-1.compute.internal
Oct 30 11:16:58.315: INFO: Pod nginx-ingress-controller-867c6c9bd-zvrzn requesting resource cpu=500m on Node ip-10-1-5-65.eu-central-1.compute.internal
Oct 30 11:16:58.315: INFO: Pod node-exporter-chfs6 requesting resource cpu=75m on Node ip-10-1-5-65.eu-central-1.compute.internal
Oct 30 11:16:58.315: INFO: Pod node-exporter-d55hm requesting resource cpu=75m on Node ip-10-1-5-84.eu-central-1.compute.internal
Oct 30 11:16:58.315: INFO: Pod node-exporter-gflqf requesting resource cpu=75m on Node ip-10-1-5-63.eu-central-1.compute.internal
Oct 30 11:16:58.315: INFO: Pod sonobuoy requesting resource cpu=0m on Node ip-10-1-5-84.eu-central-1.compute.internal
Oct 30 11:16:58.315: INFO: Pod sonobuoy-e2e-job-43cf25cf09454f64 requesting resource cpu=0m on Node ip-10-1-5-84.eu-central-1.compute.internal
Oct 30 11:16:58.315: INFO: Pod sonobuoy-systemd-logs-daemon-set-2bfde314293a499b-5db6l requesting resource cpu=0m on Node ip-10-1-5-84.eu-central-1.compute.internal
Oct 30 11:16:58.315: INFO: Pod sonobuoy-systemd-logs-daemon-set-2bfde314293a499b-dvzqw requesting resource cpu=0m on Node ip-10-1-5-63.eu-central-1.compute.internal
Oct 30 11:16:58.315: INFO: Pod sonobuoy-systemd-logs-daemon-set-2bfde314293a499b-vdwzq requesting resource cpu=0m on Node ip-10-1-5-65.eu-central-1.compute.internal
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-507ed53b-1846-4b25-9c78-7cd95271a922.15d26897288760e7], Reason = [Scheduled], Message = [Successfully assigned sched-pred-9213/filler-pod-507ed53b-1846-4b25-9c78-7cd95271a922 to ip-10-1-5-65.eu-central-1.compute.internal]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-507ed53b-1846-4b25-9c78-7cd95271a922.15d2689751470941], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-507ed53b-1846-4b25-9c78-7cd95271a922.15d2689753706198], Reason = [Created], Message = [Created container filler-pod-507ed53b-1846-4b25-9c78-7cd95271a922]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-507ed53b-1846-4b25-9c78-7cd95271a922.15d268975a299f24], Reason = [Started], Message = [Started container filler-pod-507ed53b-1846-4b25-9c78-7cd95271a922]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-5207341e-f045-456d-bb77-367236c489fc.15d26897282be02d], Reason = [Scheduled], Message = [Successfully assigned sched-pred-9213/filler-pod-5207341e-f045-456d-bb77-367236c489fc to ip-10-1-5-63.eu-central-1.compute.internal]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-5207341e-f045-456d-bb77-367236c489fc.15d268974e48d9d9], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-5207341e-f045-456d-bb77-367236c489fc.15d2689751475770], Reason = [Created], Message = [Created container filler-pod-5207341e-f045-456d-bb77-367236c489fc]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-5207341e-f045-456d-bb77-367236c489fc.15d2689757949a2c], Reason = [Started], Message = [Started container filler-pod-5207341e-f045-456d-bb77-367236c489fc]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-aee0101c-7497-406d-a3fb-b5c845ef02d4.15d2689728aec4a6], Reason = [Scheduled], Message = [Successfully assigned sched-pred-9213/filler-pod-aee0101c-7497-406d-a3fb-b5c845ef02d4 to ip-10-1-5-84.eu-central-1.compute.internal]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-aee0101c-7497-406d-a3fb-b5c845ef02d4.15d268974edb7ef9], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-aee0101c-7497-406d-a3fb-b5c845ef02d4.15d2689751114eb1], Reason = [Created], Message = [Created container filler-pod-aee0101c-7497-406d-a3fb-b5c845ef02d4]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-aee0101c-7497-406d-a3fb-b5c845ef02d4.15d268975820a92c], Reason = [Started], Message = [Started container filler-pod-aee0101c-7497-406d-a3fb-b5c845ef02d4]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.15d26897a082deb7], Reason = [FailedScheduling], Message = [0/4 nodes are available: 4 Insufficient cpu.]
STEP: removing the label node off the node ip-10-1-5-63.eu-central-1.compute.internal
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node ip-10-1-5-65.eu-central-1.compute.internal
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node ip-10-1-5-84.eu-central-1.compute.internal
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 11:17:01.379: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-9213" for this suite.
Oct 30 11:17:07.389: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:17:07.455: INFO: namespace sched-pred-9213 deletion completed in 6.072170384s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:72

• [SLOW TEST:9.361 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 11:17:07.456: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-3064
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
Oct 30 11:17:47.665: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W1030 11:17:47.665089      18 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 11:17:47.665: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-3064" for this suite.
Oct 30 11:17:53.674: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:17:53.740: INFO: namespace gc-3064 deletion completed in 6.072941403s

• [SLOW TEST:46.284 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 11:17:53.741: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-6584
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-projected-g4gt
STEP: Creating a pod to test atomic-volume-subpath
Oct 30 11:17:53.881: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-g4gt" in namespace "subpath-6584" to be "success or failure"
Oct 30 11:17:53.883: INFO: Pod "pod-subpath-test-projected-g4gt": Phase="Pending", Reason="", readiness=false. Elapsed: 2.482983ms
Oct 30 11:17:55.886: INFO: Pod "pod-subpath-test-projected-g4gt": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005388069s
Oct 30 11:17:57.889: INFO: Pod "pod-subpath-test-projected-g4gt": Phase="Running", Reason="", readiness=true. Elapsed: 4.007852047s
Oct 30 11:17:59.891: INFO: Pod "pod-subpath-test-projected-g4gt": Phase="Running", Reason="", readiness=true. Elapsed: 6.010605987s
Oct 30 11:18:01.894: INFO: Pod "pod-subpath-test-projected-g4gt": Phase="Running", Reason="", readiness=true. Elapsed: 8.013295842s
Oct 30 11:18:03.897: INFO: Pod "pod-subpath-test-projected-g4gt": Phase="Running", Reason="", readiness=true. Elapsed: 10.015850427s
Oct 30 11:18:05.899: INFO: Pod "pod-subpath-test-projected-g4gt": Phase="Running", Reason="", readiness=true. Elapsed: 12.018623645s
Oct 30 11:18:07.902: INFO: Pod "pod-subpath-test-projected-g4gt": Phase="Running", Reason="", readiness=true. Elapsed: 14.021441794s
Oct 30 11:18:09.905: INFO: Pod "pod-subpath-test-projected-g4gt": Phase="Running", Reason="", readiness=true. Elapsed: 16.023913888s
Oct 30 11:18:11.907: INFO: Pod "pod-subpath-test-projected-g4gt": Phase="Running", Reason="", readiness=true. Elapsed: 18.026383958s
Oct 30 11:18:13.911: INFO: Pod "pod-subpath-test-projected-g4gt": Phase="Running", Reason="", readiness=true. Elapsed: 20.030674528s
Oct 30 11:18:15.914: INFO: Pod "pod-subpath-test-projected-g4gt": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.033326891s
STEP: Saw pod success
Oct 30 11:18:15.914: INFO: Pod "pod-subpath-test-projected-g4gt" satisfied condition "success or failure"
Oct 30 11:18:15.916: INFO: Trying to get logs from node ip-10-1-5-63.eu-central-1.compute.internal pod pod-subpath-test-projected-g4gt container test-container-subpath-projected-g4gt: <nil>
STEP: delete the pod
Oct 30 11:18:15.929: INFO: Waiting for pod pod-subpath-test-projected-g4gt to disappear
Oct 30 11:18:15.931: INFO: Pod pod-subpath-test-projected-g4gt no longer exists
STEP: Deleting pod pod-subpath-test-projected-g4gt
Oct 30 11:18:15.931: INFO: Deleting pod "pod-subpath-test-projected-g4gt" in namespace "subpath-6584"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 11:18:15.933: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-6584" for this suite.
Oct 30 11:18:21.942: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:18:22.008: INFO: namespace subpath-6584 deletion completed in 6.071844165s

• [SLOW TEST:28.267 seconds]
[sig-storage] Subpath
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with projected pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Aggregator 
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 11:18:22.008: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename aggregator
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in aggregator-1206
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:76
Oct 30 11:18:22.136: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
[It] Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Registering the sample API server.
Oct 30 11:18:22.624: INFO: deployment "sample-apiserver-deployment" doesn't have the required revision set
Oct 30 11:18:24.650: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708031102, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708031102, loc:(*time.Location)(0x7ed0a20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708031102, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708031102, loc:(*time.Location)(0x7ed0a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 30 11:18:26.652: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708031102, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708031102, loc:(*time.Location)(0x7ed0a20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708031102, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708031102, loc:(*time.Location)(0x7ed0a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 30 11:18:28.652: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708031102, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708031102, loc:(*time.Location)(0x7ed0a20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708031102, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708031102, loc:(*time.Location)(0x7ed0a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 30 11:18:30.653: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708031102, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708031102, loc:(*time.Location)(0x7ed0a20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708031102, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708031102, loc:(*time.Location)(0x7ed0a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 30 11:18:32.652: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708031102, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708031102, loc:(*time.Location)(0x7ed0a20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708031102, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708031102, loc:(*time.Location)(0x7ed0a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 30 11:18:35.674: INFO: Waited 1.016955648s for the sample-apiserver to be ready to handle requests.
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:67
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 11:18:36.613: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "aggregator-1206" for this suite.
Oct 30 11:18:42.764: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:18:42.834: INFO: namespace aggregator-1206 deletion completed in 6.170993304s

• [SLOW TEST:20.826 seconds]
[sig-api-machinery] Aggregator
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 11:18:42.835: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-2649
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Oct 30 11:18:42.968: INFO: Waiting up to 5m0s for pod "downward-api-f34a6d60-4081-43e4-b0ae-f279b49ee0f7" in namespace "downward-api-2649" to be "success or failure"
Oct 30 11:18:42.971: INFO: Pod "downward-api-f34a6d60-4081-43e4-b0ae-f279b49ee0f7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.440263ms
Oct 30 11:18:44.973: INFO: Pod "downward-api-f34a6d60-4081-43e4-b0ae-f279b49ee0f7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004799294s
STEP: Saw pod success
Oct 30 11:18:44.973: INFO: Pod "downward-api-f34a6d60-4081-43e4-b0ae-f279b49ee0f7" satisfied condition "success or failure"
Oct 30 11:18:44.975: INFO: Trying to get logs from node ip-10-1-5-63.eu-central-1.compute.internal pod downward-api-f34a6d60-4081-43e4-b0ae-f279b49ee0f7 container dapi-container: <nil>
STEP: delete the pod
Oct 30 11:18:44.988: INFO: Waiting for pod downward-api-f34a6d60-4081-43e4-b0ae-f279b49ee0f7 to disappear
Oct 30 11:18:44.990: INFO: Pod downward-api-f34a6d60-4081-43e4-b0ae-f279b49ee0f7 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 11:18:44.990: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2649" for this suite.
Oct 30 11:18:51.000: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:18:51.066: INFO: namespace downward-api-2649 deletion completed in 6.073492007s

• [SLOW TEST:8.232 seconds]
[sig-node] Downward API
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 11:18:51.067: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-9590
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0644 on tmpfs
Oct 30 11:18:51.201: INFO: Waiting up to 5m0s for pod "pod-71a2b3e1-5b7f-4d1d-9ceb-bc9fc09ee128" in namespace "emptydir-9590" to be "success or failure"
Oct 30 11:18:51.203: INFO: Pod "pod-71a2b3e1-5b7f-4d1d-9ceb-bc9fc09ee128": Phase="Pending", Reason="", readiness=false. Elapsed: 2.061459ms
Oct 30 11:18:53.205: INFO: Pod "pod-71a2b3e1-5b7f-4d1d-9ceb-bc9fc09ee128": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004635205s
STEP: Saw pod success
Oct 30 11:18:53.205: INFO: Pod "pod-71a2b3e1-5b7f-4d1d-9ceb-bc9fc09ee128" satisfied condition "success or failure"
Oct 30 11:18:53.207: INFO: Trying to get logs from node ip-10-1-5-84.eu-central-1.compute.internal pod pod-71a2b3e1-5b7f-4d1d-9ceb-bc9fc09ee128 container test-container: <nil>
STEP: delete the pod
Oct 30 11:18:53.220: INFO: Waiting for pod pod-71a2b3e1-5b7f-4d1d-9ceb-bc9fc09ee128 to disappear
Oct 30 11:18:53.221: INFO: Pod pod-71a2b3e1-5b7f-4d1d-9ceb-bc9fc09ee128 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 11:18:53.221: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9590" for this suite.
Oct 30 11:18:59.231: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:18:59.298: INFO: namespace emptydir-9590 deletion completed in 6.073931204s

• [SLOW TEST:8.231 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 11:18:59.299: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-3933
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Oct 30 11:18:59.425: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 create -f - --namespace=kubectl-3933'
Oct 30 11:18:59.647: INFO: stderr: ""
Oct 30 11:18:59.647: INFO: stdout: "replicationcontroller/redis-master created\n"
Oct 30 11:18:59.647: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 create -f - --namespace=kubectl-3933'
Oct 30 11:18:59.807: INFO: stderr: ""
Oct 30 11:18:59.807: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Oct 30 11:19:00.810: INFO: Selector matched 1 pods for map[app:redis]
Oct 30 11:19:00.810: INFO: Found 0 / 1
Oct 30 11:19:01.812: INFO: Selector matched 1 pods for map[app:redis]
Oct 30 11:19:01.812: INFO: Found 1 / 1
Oct 30 11:19:01.812: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Oct 30 11:19:01.815: INFO: Selector matched 1 pods for map[app:redis]
Oct 30 11:19:01.815: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Oct 30 11:19:01.815: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 describe pod redis-master-h5k9h --namespace=kubectl-3933'
Oct 30 11:19:01.893: INFO: stderr: ""
Oct 30 11:19:01.893: INFO: stdout: "Name:           redis-master-h5k9h\nNamespace:      kubectl-3933\nPriority:       0\nNode:           ip-10-1-5-63.eu-central-1.compute.internal/10.1.5.63\nStart Time:     Wed, 30 Oct 2019 11:18:59 +0000\nLabels:         app=redis\n                role=master\nAnnotations:    kubernetes.io/psp: e2e-test-privileged-psp\nStatus:         Running\nIP:             192.168.247.52\nControlled By:  ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   docker://e6691adba017f5495e6e1e24dc58933fe13caff3d05a27873395a04af04f2aeb\n    Image:          gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Image ID:       docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Wed, 30 Oct 2019 11:19:00 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-gkbks (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-gkbks:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-gkbks\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age   From                                                 Message\n  ----    ------     ----  ----                                                 -------\n  Normal  Scheduled  2s    default-scheduler                                    Successfully assigned kubectl-3933/redis-master-h5k9h to ip-10-1-5-63.eu-central-1.compute.internal\n  Normal  Pulled     1s    kubelet, ip-10-1-5-63.eu-central-1.compute.internal  Container image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\" already present on machine\n  Normal  Created    1s    kubelet, ip-10-1-5-63.eu-central-1.compute.internal  Created container redis-master\n  Normal  Started    1s    kubelet, ip-10-1-5-63.eu-central-1.compute.internal  Started container redis-master\n"
Oct 30 11:19:01.893: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 describe rc redis-master --namespace=kubectl-3933'
Oct 30 11:19:01.977: INFO: stderr: ""
Oct 30 11:19:01.977: INFO: stdout: "Name:         redis-master\nNamespace:    kubectl-3933\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  2s    replication-controller  Created pod: redis-master-h5k9h\n"
Oct 30 11:19:01.977: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 describe service redis-master --namespace=kubectl-3933'
Oct 30 11:19:02.052: INFO: stderr: ""
Oct 30 11:19:02.052: INFO: stdout: "Name:              redis-master\nNamespace:         kubectl-3933\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                172.31.145.187\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         192.168.247.52:6379\nSession Affinity:  None\nEvents:            <none>\n"
Oct 30 11:19:02.055: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 describe node ip-10-1-5-17.eu-central-1.compute.internal'
Oct 30 11:19:02.152: INFO: stderr: ""
Oct 30 11:19:02.152: INFO: stdout: "Name:               ip-10-1-5-17.eu-central-1.compute.internal\nRoles:              master\nLabels:             aws-operator.giantswarm.io/version=5.5.0\n                    beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/instance-type=m4.xlarge\n                    beta.kubernetes.io/os=linux\n                    failure-domain.beta.kubernetes.io/region=eu-central-1\n                    failure-domain.beta.kubernetes.io/zone=eu-central-1c\n                    giantswarm.io/provider=aws\n                    ip=10.1.5.17\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=ip-10-1-5-17.eu-central-1.compute.internal\n                    kubernetes.io/os=linux\n                    kubernetes.io/role=master\n                    node-role.kubernetes.io/master=\n                    node.kubernetes.io/master=\n                    role=master\nAnnotations:        node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Wed, 30 Oct 2019 10:03:12 +0000\nTaints:             node-role.kubernetes.io/master:NoSchedule\nUnschedulable:      false\nConditions:\n  Type                 Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----                 ------  -----------------                 ------------------                ------                       -------\n  NetworkUnavailable   False   Wed, 30 Oct 2019 10:03:56 +0000   Wed, 30 Oct 2019 10:03:56 +0000   CalicoIsUp                   Calico is running on this node\n  MemoryPressure       False   Wed, 30 Oct 2019 11:18:26 +0000   Wed, 30 Oct 2019 10:03:12 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure         False   Wed, 30 Oct 2019 11:18:26 +0000   Wed, 30 Oct 2019 10:03:12 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure          False   Wed, 30 Oct 2019 11:18:26 +0000   Wed, 30 Oct 2019 10:03:12 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready                True    Wed, 30 Oct 2019 11:18:26 +0000   Wed, 30 Oct 2019 10:05:03 +0000   KubeletReady                 kubelet is posting ready status\nAddresses:\n  InternalIP:   10.1.5.17\n  InternalDNS:  ip-10-1-5-17.eu-central-1.compute.internal\n  Hostname:     ip-10-1-5-17.eu-central-1.compute.internal\nCapacity:\n attachable-volumes-aws-ebs:  39\n cpu:                         4\n ephemeral-storage:           5706380Ki\n hugepages-1Gi:               0\n hugepages-2Mi:               0\n memory:                      16424468Ki\n pods:                        110\nAllocatable:\n attachable-volumes-aws-ebs:  39\n cpu:                         3400m\n ephemeral-storage:           4657804Ki\n hugepages-1Gi:               0\n hugepages-2Mi:               0\n memory:                      14515732Ki\n pods:                        110\nSystem Info:\n Machine ID:                 e800c96fa86d46ecbf8dc04bf5e7316e\n System UUID:                ec2833ee-b145-364b-8ea2-e18bba9823c6\n Boot ID:                    a76e49f5-e04f-49bf-9b75-1223cbf48751\n Kernel Version:             4.19.68-coreos\n OS Image:                   Container Linux by CoreOS 2191.5.0 (Rhyolite)\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  docker://18.6.3\n Kubelet Version:            v1.15.5\n Kube-Proxy Version:         v1.15.5\nProviderID:                  aws:///eu-central-1c/i-0f8bd2279e076347c\nNon-terminated Pods:         (13 in total)\n  Namespace                  Name                                                                 CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                  ----                                                                 ------------  ----------  ---------------  -------------  ---\n  giantswarm                 chart-operator-b87bfffd4-qfl2l                                       250m (7%)     250m (7%)   250Mi (1%)       250Mi (1%)     69m\n  kube-system                calico-kube-controllers-6d4856d68f-4f9b5                             250m (7%)     250m (7%)   100Mi (0%)       100Mi (0%)     75m\n  kube-system                calico-node-z2lrs                                                    250m (7%)     50m (1%)    150Mi (1%)       100Mi (0%)     75m\n  kube-system                cert-exporter-n7p6n                                                  50m (1%)      50m (1%)    50Mi (0%)        50Mi (0%)      69m\n  kube-system                cluster-autoscaler-6ff4477c6-b4b9g                                   100m (2%)     100m (2%)   300Mi (2%)       300Mi (2%)     69m\n  kube-system                k8s-api-healthz-ip-10-1-5-17.eu-central-1.compute.internal           50m (1%)      0 (0%)      20Mi (0%)        0 (0%)         74m\n  kube-system                k8s-api-server-ip-10-1-5-17.eu-central-1.compute.internal            300m (8%)     0 (0%)      300Mi (2%)       0 (0%)         74m\n  kube-system                k8s-controller-manager-ip-10-1-5-17.eu-central-1.compute.internal    200m (5%)     0 (0%)      200Mi (1%)       0 (0%)         74m\n  kube-system                k8s-scheduler-ip-10-1-5-17.eu-central-1.compute.internal             100m (2%)     0 (0%)      100Mi (0%)       0 (0%)         74m\n  kube-system                kube-proxy-znrxc                                                     75m (2%)      0 (0%)      80Mi (0%)        0 (0%)         75m\n  kube-system                net-exporter-btqhr                                                   0 (0%)        0 (0%)      75Mi (0%)        75Mi (0%)      69m\n  kube-system                node-exporter-mhbnj                                                  75m (2%)      0 (0%)      50Mi (0%)        50Mi (0%)      69m\n  sonobuoy                   sonobuoy-systemd-logs-daemon-set-2bfde314293a499b-lb4v8              0 (0%)        0 (0%)      0 (0%)           0 (0%)         57m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource                    Requests      Limits\n  --------                    --------      ------\n  cpu                         1700m (50%)   700m (20%)\n  memory                      1675Mi (11%)  925Mi (6%)\n  ephemeral-storage           0 (0%)        0 (0%)\n  attachable-volumes-aws-ebs  0             0\nEvents:                       <none>\n"
Oct 30 11:19:02.153: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 describe namespace kubectl-3933'
Oct 30 11:19:02.225: INFO: stderr: ""
Oct 30 11:19:02.225: INFO: stdout: "Name:         kubectl-3933\nLabels:       e2e-framework=kubectl\n              e2e-run=a85b9a71-388c-46b6-841d-569253640bba\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 11:19:02.225: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3933" for this suite.
Oct 30 11:19:24.235: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:19:24.319: INFO: namespace kubectl-3933 deletion completed in 22.090990202s

• [SLOW TEST:25.020 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl describe
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 11:19:24.319: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6531
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Oct 30 11:19:24.459: INFO: Waiting up to 5m0s for pod "downwardapi-volume-1bf0d69f-9100-4848-b067-3f3e26b86c68" in namespace "projected-6531" to be "success or failure"
Oct 30 11:19:24.461: INFO: Pod "downwardapi-volume-1bf0d69f-9100-4848-b067-3f3e26b86c68": Phase="Pending", Reason="", readiness=false. Elapsed: 2.723739ms
Oct 30 11:19:26.463: INFO: Pod "downwardapi-volume-1bf0d69f-9100-4848-b067-3f3e26b86c68": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004808092s
STEP: Saw pod success
Oct 30 11:19:26.464: INFO: Pod "downwardapi-volume-1bf0d69f-9100-4848-b067-3f3e26b86c68" satisfied condition "success or failure"
Oct 30 11:19:26.465: INFO: Trying to get logs from node ip-10-1-5-84.eu-central-1.compute.internal pod downwardapi-volume-1bf0d69f-9100-4848-b067-3f3e26b86c68 container client-container: <nil>
STEP: delete the pod
Oct 30 11:19:26.477: INFO: Waiting for pod downwardapi-volume-1bf0d69f-9100-4848-b067-3f3e26b86c68 to disappear
Oct 30 11:19:26.479: INFO: Pod downwardapi-volume-1bf0d69f-9100-4848-b067-3f3e26b86c68 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 11:19:26.479: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6531" for this suite.
Oct 30 11:19:32.488: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:19:32.556: INFO: namespace projected-6531 deletion completed in 6.074222049s

• [SLOW TEST:8.237 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 11:19:32.557: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6169
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Oct 30 11:19:32.689: INFO: Waiting up to 5m0s for pod "downwardapi-volume-64c9eb19-aa0c-4a63-820c-ab6cb4cc0304" in namespace "projected-6169" to be "success or failure"
Oct 30 11:19:32.692: INFO: Pod "downwardapi-volume-64c9eb19-aa0c-4a63-820c-ab6cb4cc0304": Phase="Pending", Reason="", readiness=false. Elapsed: 2.345769ms
Oct 30 11:19:34.695: INFO: Pod "downwardapi-volume-64c9eb19-aa0c-4a63-820c-ab6cb4cc0304": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005416714s
STEP: Saw pod success
Oct 30 11:19:34.695: INFO: Pod "downwardapi-volume-64c9eb19-aa0c-4a63-820c-ab6cb4cc0304" satisfied condition "success or failure"
Oct 30 11:19:34.697: INFO: Trying to get logs from node ip-10-1-5-63.eu-central-1.compute.internal pod downwardapi-volume-64c9eb19-aa0c-4a63-820c-ab6cb4cc0304 container client-container: <nil>
STEP: delete the pod
Oct 30 11:19:34.711: INFO: Waiting for pod downwardapi-volume-64c9eb19-aa0c-4a63-820c-ab6cb4cc0304 to disappear
Oct 30 11:19:34.713: INFO: Pod downwardapi-volume-64c9eb19-aa0c-4a63-820c-ab6cb4cc0304 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 11:19:34.713: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6169" for this suite.
Oct 30 11:19:40.723: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:19:40.791: INFO: namespace projected-6169 deletion completed in 6.074793123s

• [SLOW TEST:8.234 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 11:19:40.792: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-8992
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating service multi-endpoint-test in namespace services-8992
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-8992 to expose endpoints map[]
Oct 30 11:19:40.929: INFO: successfully validated that service multi-endpoint-test in namespace services-8992 exposes endpoints map[] (2.144569ms elapsed)
STEP: Creating pod pod1 in namespace services-8992
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-8992 to expose endpoints map[pod1:[100]]
Oct 30 11:19:42.953: INFO: successfully validated that service multi-endpoint-test in namespace services-8992 exposes endpoints map[pod1:[100]] (2.016986519s elapsed)
STEP: Creating pod pod2 in namespace services-8992
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-8992 to expose endpoints map[pod1:[100] pod2:[101]]
Oct 30 11:19:44.975: INFO: successfully validated that service multi-endpoint-test in namespace services-8992 exposes endpoints map[pod1:[100] pod2:[101]] (2.018393861s elapsed)
STEP: Deleting pod pod1 in namespace services-8992
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-8992 to expose endpoints map[pod2:[101]]
Oct 30 11:19:45.988: INFO: successfully validated that service multi-endpoint-test in namespace services-8992 exposes endpoints map[pod2:[101]] (1.009533988s elapsed)
STEP: Deleting pod pod2 in namespace services-8992
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-8992 to expose endpoints map[]
Oct 30 11:19:46.997: INFO: successfully validated that service multi-endpoint-test in namespace services-8992 exposes endpoints map[] (1.005082021s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 11:19:47.009: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-8992" for this suite.
Oct 30 11:19:53.019: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:19:53.088: INFO: namespace services-8992 deletion completed in 6.076941982s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:92

• [SLOW TEST:12.297 seconds]
[sig-network] Services
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 11:19:53.089: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-5110
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test substitution in container's command
Oct 30 11:19:53.220: INFO: Waiting up to 5m0s for pod "var-expansion-3e3ee359-89c6-41aa-9e29-1311d2e9058b" in namespace "var-expansion-5110" to be "success or failure"
Oct 30 11:19:53.223: INFO: Pod "var-expansion-3e3ee359-89c6-41aa-9e29-1311d2e9058b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.397829ms
Oct 30 11:19:55.225: INFO: Pod "var-expansion-3e3ee359-89c6-41aa-9e29-1311d2e9058b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004567113s
STEP: Saw pod success
Oct 30 11:19:55.225: INFO: Pod "var-expansion-3e3ee359-89c6-41aa-9e29-1311d2e9058b" satisfied condition "success or failure"
Oct 30 11:19:55.226: INFO: Trying to get logs from node ip-10-1-5-84.eu-central-1.compute.internal pod var-expansion-3e3ee359-89c6-41aa-9e29-1311d2e9058b container dapi-container: <nil>
STEP: delete the pod
Oct 30 11:19:55.239: INFO: Waiting for pod var-expansion-3e3ee359-89c6-41aa-9e29-1311d2e9058b to disappear
Oct 30 11:19:55.241: INFO: Pod var-expansion-3e3ee359-89c6-41aa-9e29-1311d2e9058b no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 11:19:55.241: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-5110" for this suite.
Oct 30 11:20:01.251: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:20:01.316: INFO: namespace var-expansion-5110 deletion completed in 6.072950014s

• [SLOW TEST:8.228 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 11:20:01.317: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-5044
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:81
Oct 30 11:20:01.444: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Oct 30 11:20:01.449: INFO: Waiting for terminating namespaces to be deleted...
Oct 30 11:20:01.451: INFO: 
Logging pods the kubelet thinks is on node ip-10-1-5-63.eu-central-1.compute.internal before test
Oct 30 11:20:01.455: INFO: cert-exporter-67tpq from kube-system started at 2019-10-30 10:09:15 +0000 UTC (1 container statuses recorded)
Oct 30 11:20:01.455: INFO: 	Container cert-exporter ready: true, restart count 0
Oct 30 11:20:01.455: INFO: net-exporter-t8hlz from kube-system started at 2019-10-30 10:09:19 +0000 UTC (1 container statuses recorded)
Oct 30 11:20:01.455: INFO: 	Container net-exporter ready: true, restart count 0
Oct 30 11:20:01.455: INFO: sonobuoy-systemd-logs-daemon-set-2bfde314293a499b-dvzqw from sonobuoy started at 2019-10-30 10:21:44 +0000 UTC (2 container statuses recorded)
Oct 30 11:20:01.455: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct 30 11:20:01.455: INFO: 	Container systemd-logs ready: true, restart count 0
Oct 30 11:20:01.455: INFO: nginx-ingress-controller-867c6c9bd-9xqzh from kube-system started at 2019-10-30 10:09:20 +0000 UTC (1 container statuses recorded)
Oct 30 11:20:01.455: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Oct 30 11:20:01.455: INFO: kube-proxy-zs4h7 from kube-system started at 2019-10-30 10:03:22 +0000 UTC (1 container statuses recorded)
Oct 30 11:20:01.455: INFO: 	Container kube-proxy ready: true, restart count 0
Oct 30 11:20:01.456: INFO: calico-node-6vhqd from kube-system started at 2019-10-30 10:03:31 +0000 UTC (1 container statuses recorded)
Oct 30 11:20:01.456: INFO: 	Container calico-node ready: true, restart count 0
Oct 30 11:20:01.456: INFO: coredns-7b76874c7b-rp58r from kube-system started at 2019-10-30 10:09:10 +0000 UTC (1 container statuses recorded)
Oct 30 11:20:01.456: INFO: 	Container coredns ready: true, restart count 0
Oct 30 11:20:01.456: INFO: node-exporter-gflqf from kube-system started at 2019-10-30 10:09:37 +0000 UTC (1 container statuses recorded)
Oct 30 11:20:01.456: INFO: 	Container node-exporter ready: true, restart count 0
Oct 30 11:20:01.456: INFO: 
Logging pods the kubelet thinks is on node ip-10-1-5-65.eu-central-1.compute.internal before test
Oct 30 11:20:01.460: INFO: kube-proxy-kfnkf from kube-system started at 2019-10-30 10:03:22 +0000 UTC (1 container statuses recorded)
Oct 30 11:20:01.460: INFO: 	Container kube-proxy ready: true, restart count 0
Oct 30 11:20:01.460: INFO: calico-node-t7qtg from kube-system started at 2019-10-30 10:03:31 +0000 UTC (1 container statuses recorded)
Oct 30 11:20:01.460: INFO: 	Container calico-node ready: true, restart count 0
Oct 30 11:20:01.460: INFO: coredns-7b76874c7b-g8w49 from kube-system started at 2019-10-30 10:09:10 +0000 UTC (1 container statuses recorded)
Oct 30 11:20:01.460: INFO: 	Container coredns ready: true, restart count 0
Oct 30 11:20:01.460: INFO: cert-exporter-nvkcc from kube-system started at 2019-10-30 10:09:15 +0000 UTC (1 container statuses recorded)
Oct 30 11:20:01.460: INFO: 	Container cert-exporter ready: true, restart count 0
Oct 30 11:20:01.460: INFO: metrics-server-586d4684b4-gg69x from kube-system started at 2019-10-30 10:09:35 +0000 UTC (1 container statuses recorded)
Oct 30 11:20:01.460: INFO: 	Container metrics-server ready: true, restart count 0
Oct 30 11:20:01.460: INFO: node-exporter-chfs6 from kube-system started at 2019-10-30 10:09:37 +0000 UTC (1 container statuses recorded)
Oct 30 11:20:01.460: INFO: 	Container node-exporter ready: true, restart count 0
Oct 30 11:20:01.460: INFO: nginx-ingress-controller-867c6c9bd-zvrzn from kube-system started at 2019-10-30 10:09:51 +0000 UTC (1 container statuses recorded)
Oct 30 11:20:01.460: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Oct 30 11:20:01.460: INFO: sonobuoy-systemd-logs-daemon-set-2bfde314293a499b-vdwzq from sonobuoy started at 2019-10-30 10:21:44 +0000 UTC (2 container statuses recorded)
Oct 30 11:20:01.460: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct 30 11:20:01.460: INFO: 	Container systemd-logs ready: true, restart count 0
Oct 30 11:20:01.460: INFO: net-exporter-tjtcq from kube-system started at 2019-10-30 10:09:20 +0000 UTC (1 container statuses recorded)
Oct 30 11:20:01.460: INFO: 	Container net-exporter ready: true, restart count 0
Oct 30 11:20:01.460: INFO: kube-state-metrics-586fbd9595-zhpcd from kube-system started at 2019-10-30 10:10:02 +0000 UTC (2 container statuses recorded)
Oct 30 11:20:01.460: INFO: 	Container addon-resizer ready: true, restart count 0
Oct 30 11:20:01.460: INFO: 	Container kube-state-metrics ready: true, restart count 0
Oct 30 11:20:01.460: INFO: 
Logging pods the kubelet thinks is on node ip-10-1-5-84.eu-central-1.compute.internal before test
Oct 30 11:20:01.466: INFO: kube-proxy-rvmrx from kube-system started at 2019-10-30 10:04:08 +0000 UTC (1 container statuses recorded)
Oct 30 11:20:01.466: INFO: 	Container kube-proxy ready: true, restart count 0
Oct 30 11:20:01.466: INFO: sonobuoy from sonobuoy started at 2019-10-30 10:21:39 +0000 UTC (1 container statuses recorded)
Oct 30 11:20:01.466: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Oct 30 11:20:01.466: INFO: sonobuoy-e2e-job-43cf25cf09454f64 from sonobuoy started at 2019-10-30 10:21:44 +0000 UTC (2 container statuses recorded)
Oct 30 11:20:01.466: INFO: 	Container e2e ready: true, restart count 0
Oct 30 11:20:01.466: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct 30 11:20:01.466: INFO: sonobuoy-systemd-logs-daemon-set-2bfde314293a499b-5db6l from sonobuoy started at 2019-10-30 10:21:44 +0000 UTC (2 container statuses recorded)
Oct 30 11:20:01.466: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct 30 11:20:01.466: INFO: 	Container systemd-logs ready: true, restart count 0
Oct 30 11:20:01.466: INFO: node-exporter-d55hm from kube-system started at 2019-10-30 10:09:37 +0000 UTC (1 container statuses recorded)
Oct 30 11:20:01.466: INFO: 	Container node-exporter ready: true, restart count 0
Oct 30 11:20:01.466: INFO: calico-node-qhcm8 from kube-system started at 2019-10-30 10:04:08 +0000 UTC (1 container statuses recorded)
Oct 30 11:20:01.466: INFO: 	Container calico-node ready: true, restart count 0
Oct 30 11:20:01.466: INFO: tiller-deploy-5db95cf576-vw4c4 from giantswarm started at 2019-10-30 10:08:12 +0000 UTC (1 container statuses recorded)
Oct 30 11:20:01.466: INFO: 	Container tiller ready: true, restart count 0
Oct 30 11:20:01.466: INFO: cert-exporter-r65jk from kube-system started at 2019-10-30 10:09:16 +0000 UTC (1 container statuses recorded)
Oct 30 11:20:01.466: INFO: 	Container cert-exporter ready: true, restart count 0
Oct 30 11:20:01.466: INFO: net-exporter-dvjrr from kube-system started at 2019-10-30 10:09:18 +0000 UTC (1 container statuses recorded)
Oct 30 11:20:01.466: INFO: 	Container net-exporter ready: true, restart count 0
Oct 30 11:20:01.466: INFO: nginx-ingress-controller-867c6c9bd-797qw from kube-system started at 2019-10-30 10:09:20 +0000 UTC (1 container statuses recorded)
Oct 30 11:20:01.466: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-6297df35-7191-45ac-bca2-04490535eff9 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-6297df35-7191-45ac-bca2-04490535eff9 off the node ip-10-1-5-63.eu-central-1.compute.internal
STEP: verifying the node doesn't have the label kubernetes.io/e2e-6297df35-7191-45ac-bca2-04490535eff9
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 11:20:05.517: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-5044" for this suite.
Oct 30 11:20:13.530: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:20:13.595: INFO: namespace sched-pred-5044 deletion completed in 8.073922902s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:72

• [SLOW TEST:12.278 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 11:20:13.596: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-5274
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name cm-test-opt-del-0414226f-a2dd-42f4-b1ab-3bd3795f675b
STEP: Creating configMap with name cm-test-opt-upd-b2552a08-df4d-461c-b6bd-4d027ee3a62c
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-0414226f-a2dd-42f4-b1ab-3bd3795f675b
STEP: Updating configmap cm-test-opt-upd-b2552a08-df4d-461c-b6bd-4d027ee3a62c
STEP: Creating configMap with name cm-test-opt-create-ee903f53-203c-44b9-84b8-5485d9ba16e1
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 11:20:17.800: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5274" for this suite.
Oct 30 11:20:39.811: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:20:39.887: INFO: namespace configmap-5274 deletion completed in 22.083566915s

• [SLOW TEST:26.291 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 11:20:39.887: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-6786
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod liveness-add51d3d-6ab0-4e8c-b2fc-616e530a5683 in namespace container-probe-6786
Oct 30 11:20:44.024: INFO: Started pod liveness-add51d3d-6ab0-4e8c-b2fc-616e530a5683 in namespace container-probe-6786
STEP: checking the pod's current state and verifying that restartCount is present
Oct 30 11:20:44.027: INFO: Initial restart count of pod liveness-add51d3d-6ab0-4e8c-b2fc-616e530a5683 is 0
Oct 30 11:20:54.042: INFO: Restart count of pod container-probe-6786/liveness-add51d3d-6ab0-4e8c-b2fc-616e530a5683 is now 1 (10.014620597s elapsed)
Oct 30 11:21:14.067: INFO: Restart count of pod container-probe-6786/liveness-add51d3d-6ab0-4e8c-b2fc-616e530a5683 is now 2 (30.039810122s elapsed)
Oct 30 11:21:34.089: INFO: Restart count of pod container-probe-6786/liveness-add51d3d-6ab0-4e8c-b2fc-616e530a5683 is now 3 (50.061881522s elapsed)
Oct 30 11:21:54.114: INFO: Restart count of pod container-probe-6786/liveness-add51d3d-6ab0-4e8c-b2fc-616e530a5683 is now 4 (1m10.086729221s elapsed)
Oct 30 11:22:56.194: INFO: Restart count of pod container-probe-6786/liveness-add51d3d-6ab0-4e8c-b2fc-616e530a5683 is now 5 (2m12.166591101s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 11:22:56.200: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-6786" for this suite.
Oct 30 11:23:02.211: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:23:02.276: INFO: namespace container-probe-6786 deletion completed in 6.072371502s

• [SLOW TEST:142.389 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 11:23:02.276: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-7615
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: executing a command with run --rm and attach with stdin
Oct 30 11:23:02.404: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 --namespace=kubectl-7615 run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Oct 30 11:23:03.760: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Oct 30 11:23:03.760: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 11:23:05.764: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7615" for this suite.
Oct 30 11:23:17.774: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:23:17.848: INFO: namespace kubectl-7615 deletion completed in 12.08034295s

• [SLOW TEST:15.572 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run --rm job
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 11:23:17.848: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-519
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name s-test-opt-del-93796336-eb0c-4166-ada9-9b71db797aa9
STEP: Creating secret with name s-test-opt-upd-f7fdc2b0-c1b1-46ec-a1a3-e8d4e183544a
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-93796336-eb0c-4166-ada9-9b71db797aa9
STEP: Updating secret s-test-opt-upd-f7fdc2b0-c1b1-46ec-a1a3-e8d4e183544a
STEP: Creating secret with name s-test-opt-create-8e9ae22c-760f-49d9-acd5-958a9405d64a
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 11:23:24.055: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-519" for this suite.
Oct 30 11:23:46.066: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:23:46.129: INFO: namespace projected-519 deletion completed in 22.071086191s

• [SLOW TEST:28.281 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] version v1
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 11:23:46.130: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-2762
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Oct 30 11:23:46.262: INFO: (0) /api/v1/nodes/ip-10-1-5-63.eu-central-1.compute.internal:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 2.429832ms)
Oct 30 11:23:46.264: INFO: (1) /api/v1/nodes/ip-10-1-5-63.eu-central-1.compute.internal:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 2.135359ms)
Oct 30 11:23:46.266: INFO: (2) /api/v1/nodes/ip-10-1-5-63.eu-central-1.compute.internal:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 2.133298ms)
Oct 30 11:23:46.269: INFO: (3) /api/v1/nodes/ip-10-1-5-63.eu-central-1.compute.internal:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 2.523248ms)
Oct 30 11:23:46.271: INFO: (4) /api/v1/nodes/ip-10-1-5-63.eu-central-1.compute.internal:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 2.157969ms)
Oct 30 11:23:46.273: INFO: (5) /api/v1/nodes/ip-10-1-5-63.eu-central-1.compute.internal:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 2.231228ms)
Oct 30 11:23:46.275: INFO: (6) /api/v1/nodes/ip-10-1-5-63.eu-central-1.compute.internal:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 2.07675ms)
Oct 30 11:23:46.277: INFO: (7) /api/v1/nodes/ip-10-1-5-63.eu-central-1.compute.internal:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 2.26032ms)
Oct 30 11:23:46.280: INFO: (8) /api/v1/nodes/ip-10-1-5-63.eu-central-1.compute.internal:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 2.158599ms)
Oct 30 11:23:46.282: INFO: (9) /api/v1/nodes/ip-10-1-5-63.eu-central-1.compute.internal:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 2.226364ms)
Oct 30 11:23:46.284: INFO: (10) /api/v1/nodes/ip-10-1-5-63.eu-central-1.compute.internal:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 2.24205ms)
Oct 30 11:23:46.286: INFO: (11) /api/v1/nodes/ip-10-1-5-63.eu-central-1.compute.internal:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 2.110213ms)
Oct 30 11:23:46.289: INFO: (12) /api/v1/nodes/ip-10-1-5-63.eu-central-1.compute.internal:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 2.295988ms)
Oct 30 11:23:46.291: INFO: (13) /api/v1/nodes/ip-10-1-5-63.eu-central-1.compute.internal:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 2.359474ms)
Oct 30 11:23:46.293: INFO: (14) /api/v1/nodes/ip-10-1-5-63.eu-central-1.compute.internal:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 2.273226ms)
Oct 30 11:23:46.296: INFO: (15) /api/v1/nodes/ip-10-1-5-63.eu-central-1.compute.internal:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 2.215158ms)
Oct 30 11:23:46.298: INFO: (16) /api/v1/nodes/ip-10-1-5-63.eu-central-1.compute.internal:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 2.42119ms)
Oct 30 11:23:46.300: INFO: (17) /api/v1/nodes/ip-10-1-5-63.eu-central-1.compute.internal:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 2.226739ms)
Oct 30 11:23:46.303: INFO: (18) /api/v1/nodes/ip-10-1-5-63.eu-central-1.compute.internal:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 2.278088ms)
Oct 30 11:23:46.305: INFO: (19) /api/v1/nodes/ip-10-1-5-63.eu-central-1.compute.internal:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 2.230539ms)
[AfterEach] version v1
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 11:23:46.305: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-2762" for this suite.
Oct 30 11:23:52.314: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:23:52.380: INFO: namespace proxy-2762 deletion completed in 6.073010018s

• [SLOW TEST:6.250 seconds]
[sig-network] Proxy
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:58
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 11:23:52.381: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-3664
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Oct 30 11:23:52.508: INFO: Creating deployment "nginx-deployment"
Oct 30 11:23:52.512: INFO: Waiting for observed generation 1
Oct 30 11:23:54.521: INFO: Waiting for all required pods to come up
Oct 30 11:23:54.525: INFO: Pod name nginx: Found 10 pods out of 10
STEP: ensuring each pod is running
Oct 30 11:23:56.531: INFO: Waiting for deployment "nginx-deployment" to complete
Oct 30 11:23:56.535: INFO: Updating deployment "nginx-deployment" with a non-existent image
Oct 30 11:23:56.539: INFO: Updating deployment nginx-deployment
Oct 30 11:23:56.539: INFO: Waiting for observed generation 2
Oct 30 11:23:58.543: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Oct 30 11:23:58.545: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Oct 30 11:23:58.547: INFO: Waiting for the first rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Oct 30 11:23:58.552: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Oct 30 11:23:58.552: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Oct 30 11:23:58.554: INFO: Waiting for the second rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Oct 30 11:23:58.557: INFO: Verifying that deployment "nginx-deployment" has minimum required number of available replicas
Oct 30 11:23:58.557: INFO: Scaling up the deployment "nginx-deployment" from 10 to 30
Oct 30 11:23:58.561: INFO: Updating deployment nginx-deployment
Oct 30 11:23:58.561: INFO: Waiting for the replicasets of deployment "nginx-deployment" to have desired number of replicas
Oct 30 11:23:58.572: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Oct 30 11:23:58.575: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
Oct 30 11:23:58.585: INFO: Deployment "nginx-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment,GenerateName:,Namespace:deployment-3664,SelfLink:/apis/apps/v1/namespaces/deployment-3664/deployments/nginx-deployment,UID:a7f10d82-6b0c-4042-ade5-da61896a7a60,ResourceVersion:22527,Generation:3,CreationTimestamp:2019-10-30 11:23:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*30,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:13,UpdatedReplicas:5,AvailableReplicas:8,UnavailableReplicas:5,Conditions:[{Progressing True 2019-10-30 11:23:56 +0000 UTC 2019-10-30 11:23:52 +0000 UTC ReplicaSetUpdated ReplicaSet "nginx-deployment-55fb7cb77f" is progressing.} {Available False 2019-10-30 11:23:58 +0000 UTC 2019-10-30 11:23:58 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}],ReadyReplicas:8,CollisionCount:nil,},}

Oct 30 11:23:58.589: INFO: New ReplicaSet "nginx-deployment-55fb7cb77f" of Deployment "nginx-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f,GenerateName:,Namespace:deployment-3664,SelfLink:/apis/apps/v1/namespaces/deployment-3664/replicasets/nginx-deployment-55fb7cb77f,UID:edb1a10c-b9bd-4927-9b73-f10c4a070a90,ResourceVersion:22524,Generation:3,CreationTimestamp:2019-10-30 11:23:56 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment nginx-deployment a7f10d82-6b0c-4042-ade5-da61896a7a60 0xc0026529f7 0xc0026529f8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*13,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:5,FullyLabeledReplicas:5,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Oct 30 11:23:58.589: INFO: All old ReplicaSets of Deployment "nginx-deployment":
Oct 30 11:23:58.589: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498,GenerateName:,Namespace:deployment-3664,SelfLink:/apis/apps/v1/namespaces/deployment-3664/replicasets/nginx-deployment-7b8c6f4498,UID:6bd603ed-d361-4134-bfd5-e7944814e39f,ResourceVersion:22522,Generation:3,CreationTimestamp:2019-10-30 11:23:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment nginx-deployment a7f10d82-6b0c-4042-ade5-da61896a7a60 0xc002652ac7 0xc002652ac8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*20,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:8,FullyLabeledReplicas:8,ObservedGeneration:2,ReadyReplicas:8,AvailableReplicas:8,Conditions:[],},}
Oct 30 11:23:58.594: INFO: Pod "nginx-deployment-55fb7cb77f-5lpv7" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-5lpv7,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-3664,SelfLink:/api/v1/namespaces/deployment-3664/pods/nginx-deployment-55fb7cb77f-5lpv7,UID:56fc3b45-2f85-411b-8b2f-7513670a86f2,ResourceVersion:22448,Generation:0,CreationTimestamp:2019-10-30 11:23:56 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f edb1a10c-b9bd-4927-9b73-f10c4a070a90 0xc00335a577 0xc00335a578}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-kvkms {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kvkms,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-kvkms true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-1-5-84.eu-central-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00335a5e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00335a600}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:23:56 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:23:56 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:23:56 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:23:56 +0000 UTC  }],Message:,Reason:,HostIP:10.1.5.84,PodIP:,StartTime:2019-10-30 11:23:56 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 30 11:23:58.594: INFO: Pod "nginx-deployment-55fb7cb77f-9qb9q" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-9qb9q,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-3664,SelfLink:/api/v1/namespaces/deployment-3664/pods/nginx-deployment-55fb7cb77f-9qb9q,UID:7aeb48d7-d650-4c58-9fa4-966d0f8e9f1f,ResourceVersion:22475,Generation:0,CreationTimestamp:2019-10-30 11:23:56 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f edb1a10c-b9bd-4927-9b73-f10c4a070a90 0xc00335a6d0 0xc00335a6d1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-kvkms {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kvkms,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-kvkms true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-1-5-84.eu-central-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00335a740} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00335a760}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:23:56 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:23:56 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:23:56 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:23:56 +0000 UTC  }],Message:,Reason:,HostIP:10.1.5.84,PodIP:,StartTime:2019-10-30 11:23:56 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 30 11:23:58.594: INFO: Pod "nginx-deployment-55fb7cb77f-nfrq5" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-nfrq5,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-3664,SelfLink:/api/v1/namespaces/deployment-3664/pods/nginx-deployment-55fb7cb77f-nfrq5,UID:3ebbfbb2-0768-40f8-944f-fa07bc7a869d,ResourceVersion:22529,Generation:0,CreationTimestamp:2019-10-30 11:23:56 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f edb1a10c-b9bd-4927-9b73-f10c4a070a90 0xc00335a830 0xc00335a831}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-kvkms {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kvkms,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-kvkms true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-1-5-65.eu-central-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00335a8a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00335a8c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:23:56 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:23:56 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:23:56 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:23:56 +0000 UTC  }],Message:,Reason:,HostIP:10.1.5.65,PodIP:192.168.16.93,StartTime:2019-10-30 11:23:56 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: manifest for nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 30 11:23:58.595: INFO: Pod "nginx-deployment-55fb7cb77f-qxbc5" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-qxbc5,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-3664,SelfLink:/api/v1/namespaces/deployment-3664/pods/nginx-deployment-55fb7cb77f-qxbc5,UID:7a154bf0-f90b-406d-9d38-73a62631dbbf,ResourceVersion:22478,Generation:0,CreationTimestamp:2019-10-30 11:23:56 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f edb1a10c-b9bd-4927-9b73-f10c4a070a90 0xc00335a9b0 0xc00335a9b1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-kvkms {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kvkms,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-kvkms true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-1-5-63.eu-central-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00335aa20} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00335aa40}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:23:56 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:23:56 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:23:56 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:23:56 +0000 UTC  }],Message:,Reason:,HostIP:10.1.5.63,PodIP:,StartTime:2019-10-30 11:23:56 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 30 11:23:58.595: INFO: Pod "nginx-deployment-55fb7cb77f-v9hv2" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-v9hv2,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-3664,SelfLink:/api/v1/namespaces/deployment-3664/pods/nginx-deployment-55fb7cb77f-v9hv2,UID:37b41ab6-df69-4b1c-81ab-a9cda9c6c4d3,ResourceVersion:22532,Generation:0,CreationTimestamp:2019-10-30 11:23:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f edb1a10c-b9bd-4927-9b73-f10c4a070a90 0xc00335ab10 0xc00335ab11}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-kvkms {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kvkms,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-kvkms true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00335ab80} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00335aba0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 30 11:23:58.595: INFO: Pod "nginx-deployment-55fb7cb77f-xlfrd" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-xlfrd,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-3664,SelfLink:/api/v1/namespaces/deployment-3664/pods/nginx-deployment-55fb7cb77f-xlfrd,UID:4329e392-9f31-45b5-96a9-9316fd733d0e,ResourceVersion:22520,Generation:0,CreationTimestamp:2019-10-30 11:23:56 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f edb1a10c-b9bd-4927-9b73-f10c4a070a90 0xc00335ac07 0xc00335ac08}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-kvkms {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kvkms,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-kvkms true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-1-5-63.eu-central-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00335ac70} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00335ac90}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:23:56 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:23:56 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:23:56 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:23:56 +0000 UTC  }],Message:,Reason:,HostIP:10.1.5.63,PodIP:192.168.247.2,StartTime:2019-10-30 11:23:56 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: manifest for nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 30 11:23:58.595: INFO: Pod "nginx-deployment-7b8c6f4498-fl899" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-fl899,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-3664,SelfLink:/api/v1/namespaces/deployment-3664/pods/nginx-deployment-7b8c6f4498-fl899,UID:a83a181c-a487-42c5-8ec3-e615eed55a9e,ResourceVersion:22391,Generation:0,CreationTimestamp:2019-10-30 11:23:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 6bd603ed-d361-4134-bfd5-e7944814e39f 0xc00335ad80 0xc00335ad81}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-kvkms {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kvkms,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-kvkms true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-1-5-84.eu-central-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00335ade0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00335ae00}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:23:52 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:23:54 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:23:54 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:23:52 +0000 UTC  }],Message:,Reason:,HostIP:10.1.5.84,PodIP:192.168.4.235,StartTime:2019-10-30 11:23:52 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-10-30 11:23:53 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://c084799f8ddaf461a5cfb02089582e976058f2a3daa08aebe73c3073b2c195cf}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 30 11:23:58.595: INFO: Pod "nginx-deployment-7b8c6f4498-m7d42" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-m7d42,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-3664,SelfLink:/api/v1/namespaces/deployment-3664/pods/nginx-deployment-7b8c6f4498-m7d42,UID:2c180abe-b015-4a4b-b1b9-1e6b698ef6e3,ResourceVersion:22401,Generation:0,CreationTimestamp:2019-10-30 11:23:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 6bd603ed-d361-4134-bfd5-e7944814e39f 0xc00335aed0 0xc00335aed1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-kvkms {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kvkms,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-kvkms true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-1-5-63.eu-central-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00335af30} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00335af50}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:23:52 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:23:54 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:23:54 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:23:52 +0000 UTC  }],Message:,Reason:,HostIP:10.1.5.63,PodIP:192.168.247.61,StartTime:2019-10-30 11:23:52 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-10-30 11:23:53 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://2de18fb991e1b314627bd604c6a4eb698fb20ced543eecdc7de8e6ee3b2bc5de}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 30 11:23:58.595: INFO: Pod "nginx-deployment-7b8c6f4498-mbm2m" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-mbm2m,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-3664,SelfLink:/api/v1/namespaces/deployment-3664/pods/nginx-deployment-7b8c6f4498-mbm2m,UID:3357c90b-d781-48ba-8776-d446c84a9b5a,ResourceVersion:22404,Generation:0,CreationTimestamp:2019-10-30 11:23:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 6bd603ed-d361-4134-bfd5-e7944814e39f 0xc00335b020 0xc00335b021}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-kvkms {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kvkms,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-kvkms true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-1-5-63.eu-central-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00335b080} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00335b0a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:23:52 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:23:54 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:23:54 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:23:52 +0000 UTC  }],Message:,Reason:,HostIP:10.1.5.63,PodIP:192.168.247.63,StartTime:2019-10-30 11:23:52 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-10-30 11:23:53 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://89decde5e25a7e27e344103c02e82497af8b119825464385bb356fcc53965b6c}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 30 11:23:58.596: INFO: Pod "nginx-deployment-7b8c6f4498-mdxwj" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-mdxwj,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-3664,SelfLink:/api/v1/namespaces/deployment-3664/pods/nginx-deployment-7b8c6f4498-mdxwj,UID:3bfc58eb-4d7a-47c1-b70b-b49d8377da8c,ResourceVersion:22421,Generation:0,CreationTimestamp:2019-10-30 11:23:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 6bd603ed-d361-4134-bfd5-e7944814e39f 0xc00335b170 0xc00335b171}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-kvkms {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kvkms,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-kvkms true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-1-5-63.eu-central-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00335b1d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00335b1f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:23:52 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:23:54 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:23:54 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:23:52 +0000 UTC  }],Message:,Reason:,HostIP:10.1.5.63,PodIP:192.168.247.60,StartTime:2019-10-30 11:23:52 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-10-30 11:23:53 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://863bf7d2e1b99e6966d6bfe25496d175566daa03628e837d12ec86bd3549ab66}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 30 11:23:58.596: INFO: Pod "nginx-deployment-7b8c6f4498-mw2qj" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-mw2qj,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-3664,SelfLink:/api/v1/namespaces/deployment-3664/pods/nginx-deployment-7b8c6f4498-mw2qj,UID:2d1d820f-9bbe-4bdc-b135-6eebd9a9eecd,ResourceVersion:22410,Generation:0,CreationTimestamp:2019-10-30 11:23:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 6bd603ed-d361-4134-bfd5-e7944814e39f 0xc00335b2c0 0xc00335b2c1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-kvkms {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kvkms,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-kvkms true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-1-5-63.eu-central-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00335b320} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00335b340}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:23:52 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:23:54 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:23:54 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:23:52 +0000 UTC  }],Message:,Reason:,HostIP:10.1.5.63,PodIP:192.168.247.55,StartTime:2019-10-30 11:23:52 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-10-30 11:23:53 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://28ff6ed77d688d2d73dfd5b390ab945c4cc6117fddae54a393efb4261a4fb05e}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 30 11:23:58.596: INFO: Pod "nginx-deployment-7b8c6f4498-ncmvm" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-ncmvm,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-3664,SelfLink:/api/v1/namespaces/deployment-3664/pods/nginx-deployment-7b8c6f4498-ncmvm,UID:d5124c40-1b06-43bf-b276-347922b21cf3,ResourceVersion:22533,Generation:0,CreationTimestamp:2019-10-30 11:23:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 6bd603ed-d361-4134-bfd5-e7944814e39f 0xc00335b420 0xc00335b421}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-kvkms {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kvkms,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-kvkms true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-1-5-65.eu-central-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00335b480} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00335b4a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:23:58 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 30 11:23:58.596: INFO: Pod "nginx-deployment-7b8c6f4498-r9kxm" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-r9kxm,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-3664,SelfLink:/api/v1/namespaces/deployment-3664/pods/nginx-deployment-7b8c6f4498-r9kxm,UID:be0d9ce2-cec3-46e5-a222-367895f7c07a,ResourceVersion:22417,Generation:0,CreationTimestamp:2019-10-30 11:23:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 6bd603ed-d361-4134-bfd5-e7944814e39f 0xc00335b520 0xc00335b521}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-kvkms {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kvkms,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-kvkms true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-1-5-65.eu-central-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00335b590} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00335b5b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:23:52 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:23:54 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:23:54 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:23:52 +0000 UTC  }],Message:,Reason:,HostIP:10.1.5.65,PodIP:192.168.16.91,StartTime:2019-10-30 11:23:52 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-10-30 11:23:53 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://2da422f871bf6d565bfa982e2a056e5059001cb55a32baf08bf14c062fa9de6a}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 30 11:23:58.596: INFO: Pod "nginx-deployment-7b8c6f4498-tjgnx" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-tjgnx,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-3664,SelfLink:/api/v1/namespaces/deployment-3664/pods/nginx-deployment-7b8c6f4498-tjgnx,UID:ac6250fa-0203-4af8-90f3-49e5f3dc3862,ResourceVersion:22394,Generation:0,CreationTimestamp:2019-10-30 11:23:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 6bd603ed-d361-4134-bfd5-e7944814e39f 0xc00335b680 0xc00335b681}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-kvkms {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kvkms,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-kvkms true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-1-5-84.eu-central-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00335b6e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00335b700}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:23:52 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:23:54 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:23:54 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:23:52 +0000 UTC  }],Message:,Reason:,HostIP:10.1.5.84,PodIP:192.168.4.234,StartTime:2019-10-30 11:23:52 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-10-30 11:23:53 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://1a4ed997729095b02ba697a54179e67e073092985ae999a10b4645e927a2822a}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 30 11:23:58.596: INFO: Pod "nginx-deployment-7b8c6f4498-txbrz" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-txbrz,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-3664,SelfLink:/api/v1/namespaces/deployment-3664/pods/nginx-deployment-7b8c6f4498-txbrz,UID:6e8089f0-b6ac-4abc-aec0-1781690aaedc,ResourceVersion:22528,Generation:0,CreationTimestamp:2019-10-30 11:23:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 6bd603ed-d361-4134-bfd5-e7944814e39f 0xc00335b7e0 0xc00335b7e1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-kvkms {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kvkms,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-kvkms true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-1-5-84.eu-central-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00335b840} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00335b860}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:23:58 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 30 11:23:58.597: INFO: Pod "nginx-deployment-7b8c6f4498-zbns8" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-zbns8,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-3664,SelfLink:/api/v1/namespaces/deployment-3664/pods/nginx-deployment-7b8c6f4498-zbns8,UID:0f257926-7e41-4b45-94fd-8f2311bc77f5,ResourceVersion:22407,Generation:0,CreationTimestamp:2019-10-30 11:23:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 6bd603ed-d361-4134-bfd5-e7944814e39f 0xc00335b8f0 0xc00335b8f1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-kvkms {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kvkms,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-kvkms true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-1-5-63.eu-central-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00335b950} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00335b970}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:23:52 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:23:54 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:23:54 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:23:52 +0000 UTC  }],Message:,Reason:,HostIP:10.1.5.63,PodIP:192.168.247.62,StartTime:2019-10-30 11:23:52 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-10-30 11:23:53 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://c6431169a3e1c6a8908a75e14791f79efddc868b4ff85de3549df9092cdd03a2}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 11:23:58.597: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-3664" for this suite.
Oct 30 11:24:04.612: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:24:04.687: INFO: namespace deployment-3664 deletion completed in 6.086171693s

• [SLOW TEST:12.306 seconds]
[sig-apps] Deployment
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 11:24:04.687: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-9055
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test override arguments
Oct 30 11:24:04.826: INFO: Waiting up to 5m0s for pod "client-containers-4f79917c-0c39-4c2f-9086-a542668b483a" in namespace "containers-9055" to be "success or failure"
Oct 30 11:24:04.829: INFO: Pod "client-containers-4f79917c-0c39-4c2f-9086-a542668b483a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.889446ms
Oct 30 11:24:06.832: INFO: Pod "client-containers-4f79917c-0c39-4c2f-9086-a542668b483a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005401985s
Oct 30 11:24:08.834: INFO: Pod "client-containers-4f79917c-0c39-4c2f-9086-a542668b483a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007581048s
STEP: Saw pod success
Oct 30 11:24:08.834: INFO: Pod "client-containers-4f79917c-0c39-4c2f-9086-a542668b483a" satisfied condition "success or failure"
Oct 30 11:24:08.836: INFO: Trying to get logs from node ip-10-1-5-84.eu-central-1.compute.internal pod client-containers-4f79917c-0c39-4c2f-9086-a542668b483a container test-container: <nil>
STEP: delete the pod
Oct 30 11:24:08.848: INFO: Waiting for pod client-containers-4f79917c-0c39-4c2f-9086-a542668b483a to disappear
Oct 30 11:24:08.850: INFO: Pod client-containers-4f79917c-0c39-4c2f-9086-a542668b483a no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 11:24:08.850: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-9055" for this suite.
Oct 30 11:24:14.859: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:24:14.927: INFO: namespace containers-9055 deletion completed in 6.074241445s

• [SLOW TEST:10.240 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 11:24:14.927: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-922
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Oct 30 11:24:17.071: INFO: Expected: &{} to match Container's Termination Message:  --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 11:24:17.081: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-922" for this suite.
Oct 30 11:24:23.091: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:24:23.157: INFO: namespace container-runtime-922 deletion completed in 6.073428867s

• [SLOW TEST:8.230 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  blackbox test
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
    on terminated container
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:129
      should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 11:24:23.158: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-4071
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-4071
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a new StatefulSet
Oct 30 11:24:23.295: INFO: Found 0 stateful pods, waiting for 3
Oct 30 11:24:33.298: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Oct 30 11:24:33.298: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Oct 30 11:24:33.298: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Oct 30 11:24:33.319: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Oct 30 11:24:43.344: INFO: Updating stateful set ss2
Oct 30 11:24:43.349: INFO: Waiting for Pod statefulset-4071/ss2-2 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
STEP: Restoring Pods to the correct revision when they are deleted
Oct 30 11:24:53.382: INFO: Found 1 stateful pods, waiting for 3
Oct 30 11:25:03.386: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Oct 30 11:25:03.386: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Oct 30 11:25:03.386: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Oct 30 11:25:03.405: INFO: Updating stateful set ss2
Oct 30 11:25:03.410: INFO: Waiting for Pod statefulset-4071/ss2-1 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Oct 30 11:25:13.430: INFO: Updating stateful set ss2
Oct 30 11:25:13.434: INFO: Waiting for StatefulSet statefulset-4071/ss2 to complete update
Oct 30 11:25:13.434: INFO: Waiting for Pod statefulset-4071/ss2-0 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Oct 30 11:25:23.439: INFO: Waiting for StatefulSet statefulset-4071/ss2 to complete update
Oct 30 11:25:23.439: INFO: Waiting for Pod statefulset-4071/ss2-0 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Oct 30 11:25:33.439: INFO: Deleting all statefulset in ns statefulset-4071
Oct 30 11:25:33.441: INFO: Scaling statefulset ss2 to 0
Oct 30 11:25:53.451: INFO: Waiting for statefulset status.replicas updated to 0
Oct 30 11:25:53.453: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 11:25:53.461: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-4071" for this suite.
Oct 30 11:25:59.474: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:25:59.546: INFO: namespace statefulset-4071 deletion completed in 6.081668881s

• [SLOW TEST:96.388 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 11:25:59.547: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-3152
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0666 on node default medium
Oct 30 11:25:59.681: INFO: Waiting up to 5m0s for pod "pod-d7ee1bea-0e41-4f57-bb0a-6e32cd8632c4" in namespace "emptydir-3152" to be "success or failure"
Oct 30 11:25:59.683: INFO: Pod "pod-d7ee1bea-0e41-4f57-bb0a-6e32cd8632c4": Phase="Pending", Reason="", readiness=false. Elapsed: 1.820401ms
Oct 30 11:26:01.685: INFO: Pod "pod-d7ee1bea-0e41-4f57-bb0a-6e32cd8632c4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004106042s
STEP: Saw pod success
Oct 30 11:26:01.685: INFO: Pod "pod-d7ee1bea-0e41-4f57-bb0a-6e32cd8632c4" satisfied condition "success or failure"
Oct 30 11:26:01.687: INFO: Trying to get logs from node ip-10-1-5-84.eu-central-1.compute.internal pod pod-d7ee1bea-0e41-4f57-bb0a-6e32cd8632c4 container test-container: <nil>
STEP: delete the pod
Oct 30 11:26:01.701: INFO: Waiting for pod pod-d7ee1bea-0e41-4f57-bb0a-6e32cd8632c4 to disappear
Oct 30 11:26:01.704: INFO: Pod pod-d7ee1bea-0e41-4f57-bb0a-6e32cd8632c4 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 11:26:01.704: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3152" for this suite.
Oct 30 11:26:07.714: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:26:07.781: INFO: namespace emptydir-3152 deletion completed in 6.074455693s

• [SLOW TEST:8.235 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Delete Grace Period 
  should be submitted and removed [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 11:26:07.782: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-8687
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Delete Grace Period
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:47
[It] should be submitted and removed [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: setting up selector
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
Oct 30 11:26:09.954: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-779704590 proxy -p 0'
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
Oct 30 11:26:15.019: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 11:26:15.021: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-8687" for this suite.
Oct 30 11:26:21.031: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:26:21.102: INFO: namespace pods-8687 deletion completed in 6.078879056s

• [SLOW TEST:13.320 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  [k8s.io] Delete Grace Period
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should be submitted and removed [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 11:26:21.102: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-5088
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: validating cluster-info
Oct 30 11:26:21.230: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 cluster-info'
Oct 30 11:26:21.296: INFO: stderr: ""
Oct 30 11:26:21.296: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://172.31.0.1:443\x1b[0m\n\x1b[0;32mcluster-autoscaler\x1b[0m is running at \x1b[0;33mhttps://172.31.0.1:443/api/v1/namespaces/kube-system/services/cluster-autoscaler:metrics/proxy\x1b[0m\n\x1b[0;32mCoreDNS\x1b[0m is running at \x1b[0;33mhttps://172.31.0.1:443/api/v1/namespaces/kube-system/services/coredns:dns/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 11:26:21.296: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5088" for this suite.
Oct 30 11:26:27.306: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:26:27.371: INFO: namespace kubectl-5088 deletion completed in 6.072437083s

• [SLOW TEST:6.269 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl cluster-info
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job 
  should delete a job [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 11:26:27.372: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename job
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in job-8854
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete a job [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: delete a job
STEP: deleting Job.batch foo in namespace job-8854, will wait for the garbage collector to delete the pods
Oct 30 11:26:29.559: INFO: Deleting Job.batch foo took: 3.6664ms
Oct 30 11:26:29.660: INFO: Terminating Job.batch foo pods took: 100.200334ms
STEP: Ensuring job was deleted
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 11:27:05.862: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-8854" for this suite.
Oct 30 11:27:11.872: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:27:11.937: INFO: namespace job-8854 deletion completed in 6.072145189s

• [SLOW TEST:44.565 seconds]
[sig-apps] Job
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should delete a job [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 11:27:11.937: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-7244
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-configmap-bppb
STEP: Creating a pod to test atomic-volume-subpath
Oct 30 11:27:12.072: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-bppb" in namespace "subpath-7244" to be "success or failure"
Oct 30 11:27:12.074: INFO: Pod "pod-subpath-test-configmap-bppb": Phase="Pending", Reason="", readiness=false. Elapsed: 1.939161ms
Oct 30 11:27:14.077: INFO: Pod "pod-subpath-test-configmap-bppb": Phase="Running", Reason="", readiness=true. Elapsed: 2.004235386s
Oct 30 11:27:16.079: INFO: Pod "pod-subpath-test-configmap-bppb": Phase="Running", Reason="", readiness=true. Elapsed: 4.006389148s
Oct 30 11:27:18.081: INFO: Pod "pod-subpath-test-configmap-bppb": Phase="Running", Reason="", readiness=true. Elapsed: 6.008471202s
Oct 30 11:27:20.083: INFO: Pod "pod-subpath-test-configmap-bppb": Phase="Running", Reason="", readiness=true. Elapsed: 8.010588694s
Oct 30 11:27:22.085: INFO: Pod "pod-subpath-test-configmap-bppb": Phase="Running", Reason="", readiness=true. Elapsed: 10.013097583s
Oct 30 11:27:24.088: INFO: Pod "pod-subpath-test-configmap-bppb": Phase="Running", Reason="", readiness=true. Elapsed: 12.016075945s
Oct 30 11:27:26.091: INFO: Pod "pod-subpath-test-configmap-bppb": Phase="Running", Reason="", readiness=true. Elapsed: 14.018247157s
Oct 30 11:27:28.093: INFO: Pod "pod-subpath-test-configmap-bppb": Phase="Running", Reason="", readiness=true. Elapsed: 16.020538579s
Oct 30 11:27:30.095: INFO: Pod "pod-subpath-test-configmap-bppb": Phase="Running", Reason="", readiness=true. Elapsed: 18.023033396s
Oct 30 11:27:32.101: INFO: Pod "pod-subpath-test-configmap-bppb": Phase="Running", Reason="", readiness=true. Elapsed: 20.028483236s
Oct 30 11:27:34.104: INFO: Pod "pod-subpath-test-configmap-bppb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.031464509s
STEP: Saw pod success
Oct 30 11:27:34.104: INFO: Pod "pod-subpath-test-configmap-bppb" satisfied condition "success or failure"
Oct 30 11:27:34.105: INFO: Trying to get logs from node ip-10-1-5-84.eu-central-1.compute.internal pod pod-subpath-test-configmap-bppb container test-container-subpath-configmap-bppb: <nil>
STEP: delete the pod
Oct 30 11:27:34.119: INFO: Waiting for pod pod-subpath-test-configmap-bppb to disappear
Oct 30 11:27:34.122: INFO: Pod pod-subpath-test-configmap-bppb no longer exists
STEP: Deleting pod pod-subpath-test-configmap-bppb
Oct 30 11:27:34.122: INFO: Deleting pod "pod-subpath-test-configmap-bppb" in namespace "subpath-7244"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 11:27:34.123: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-7244" for this suite.
Oct 30 11:27:40.135: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:27:40.206: INFO: namespace subpath-7244 deletion completed in 6.078084442s

• [SLOW TEST:28.269 seconds]
[sig-storage] Subpath
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 11:27:40.206: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-5008
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Oct 30 11:27:40.350: INFO: DaemonSet pods can't tolerate node ip-10-1-5-17.eu-central-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 11:27:40.352: INFO: Number of nodes with available pods: 0
Oct 30 11:27:40.352: INFO: Node ip-10-1-5-63.eu-central-1.compute.internal is running more than one daemon pod
Oct 30 11:27:41.355: INFO: DaemonSet pods can't tolerate node ip-10-1-5-17.eu-central-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 11:27:41.357: INFO: Number of nodes with available pods: 0
Oct 30 11:27:41.357: INFO: Node ip-10-1-5-63.eu-central-1.compute.internal is running more than one daemon pod
Oct 30 11:27:42.355: INFO: DaemonSet pods can't tolerate node ip-10-1-5-17.eu-central-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 11:27:42.357: INFO: Number of nodes with available pods: 3
Oct 30 11:27:42.357: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Stop a daemon pod, check that the daemon pod is revived.
Oct 30 11:27:42.367: INFO: DaemonSet pods can't tolerate node ip-10-1-5-17.eu-central-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 11:27:42.369: INFO: Number of nodes with available pods: 2
Oct 30 11:27:42.369: INFO: Node ip-10-1-5-65.eu-central-1.compute.internal is running more than one daemon pod
Oct 30 11:27:43.372: INFO: DaemonSet pods can't tolerate node ip-10-1-5-17.eu-central-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 11:27:43.374: INFO: Number of nodes with available pods: 2
Oct 30 11:27:43.374: INFO: Node ip-10-1-5-65.eu-central-1.compute.internal is running more than one daemon pod
Oct 30 11:27:44.372: INFO: DaemonSet pods can't tolerate node ip-10-1-5-17.eu-central-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 11:27:44.374: INFO: Number of nodes with available pods: 2
Oct 30 11:27:44.375: INFO: Node ip-10-1-5-65.eu-central-1.compute.internal is running more than one daemon pod
Oct 30 11:27:45.372: INFO: DaemonSet pods can't tolerate node ip-10-1-5-17.eu-central-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 11:27:45.374: INFO: Number of nodes with available pods: 2
Oct 30 11:27:45.374: INFO: Node ip-10-1-5-65.eu-central-1.compute.internal is running more than one daemon pod
Oct 30 11:27:46.372: INFO: DaemonSet pods can't tolerate node ip-10-1-5-17.eu-central-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 11:27:46.374: INFO: Number of nodes with available pods: 2
Oct 30 11:27:46.374: INFO: Node ip-10-1-5-65.eu-central-1.compute.internal is running more than one daemon pod
Oct 30 11:27:47.372: INFO: DaemonSet pods can't tolerate node ip-10-1-5-17.eu-central-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 11:27:47.375: INFO: Number of nodes with available pods: 3
Oct 30 11:27:47.375: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-5008, will wait for the garbage collector to delete the pods
Oct 30 11:27:47.432: INFO: Deleting DaemonSet.extensions daemon-set took: 4.072798ms
Oct 30 11:27:47.533: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.231545ms
Oct 30 11:28:00.935: INFO: Number of nodes with available pods: 0
Oct 30 11:28:00.935: INFO: Number of running nodes: 0, number of available pods: 0
Oct 30 11:28:00.937: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-5008/daemonsets","resourceVersion":"23997"},"items":null}

Oct 30 11:28:00.938: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-5008/pods","resourceVersion":"23997"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 11:28:00.946: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-5008" for this suite.
Oct 30 11:28:06.955: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:28:07.021: INFO: namespace daemonsets-5008 deletion completed in 6.072179227s

• [SLOW TEST:26.815 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 11:28:07.021: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-9767
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Oct 30 11:28:09.163: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 11:28:09.172: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-9767" for this suite.
Oct 30 11:28:15.182: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:28:15.248: INFO: namespace container-runtime-9767 deletion completed in 6.07362199s

• [SLOW TEST:8.227 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  blackbox test
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
    on terminated container
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:129
      should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
      /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 11:28:15.249: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3399
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-6d3d7506-7911-4705-91fe-6d8733299c42
STEP: Creating a pod to test consume configMaps
Oct 30 11:28:15.384: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-a033f32c-55d0-419a-94bd-1c24ae89d05a" in namespace "projected-3399" to be "success or failure"
Oct 30 11:28:15.387: INFO: Pod "pod-projected-configmaps-a033f32c-55d0-419a-94bd-1c24ae89d05a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.564337ms
Oct 30 11:28:17.389: INFO: Pod "pod-projected-configmaps-a033f32c-55d0-419a-94bd-1c24ae89d05a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005205777s
STEP: Saw pod success
Oct 30 11:28:17.389: INFO: Pod "pod-projected-configmaps-a033f32c-55d0-419a-94bd-1c24ae89d05a" satisfied condition "success or failure"
Oct 30 11:28:17.391: INFO: Trying to get logs from node ip-10-1-5-84.eu-central-1.compute.internal pod pod-projected-configmaps-a033f32c-55d0-419a-94bd-1c24ae89d05a container projected-configmap-volume-test: <nil>
STEP: delete the pod
Oct 30 11:28:17.404: INFO: Waiting for pod pod-projected-configmaps-a033f32c-55d0-419a-94bd-1c24ae89d05a to disappear
Oct 30 11:28:17.406: INFO: Pod pod-projected-configmaps-a033f32c-55d0-419a-94bd-1c24ae89d05a no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 11:28:17.406: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3399" for this suite.
Oct 30 11:28:23.415: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:28:23.481: INFO: namespace projected-3399 deletion completed in 6.0721763s

• [SLOW TEST:8.232 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 11:28:23.481: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7075
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-map-1ba8eaf6-7907-48dc-879f-d3ed1fec0d49
STEP: Creating a pod to test consume configMaps
Oct 30 11:28:23.615: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-aaeb70b5-51de-431f-a4ee-32f16d7fcea5" in namespace "projected-7075" to be "success or failure"
Oct 30 11:28:23.618: INFO: Pod "pod-projected-configmaps-aaeb70b5-51de-431f-a4ee-32f16d7fcea5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.769894ms
Oct 30 11:28:25.621: INFO: Pod "pod-projected-configmaps-aaeb70b5-51de-431f-a4ee-32f16d7fcea5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005725572s
STEP: Saw pod success
Oct 30 11:28:25.621: INFO: Pod "pod-projected-configmaps-aaeb70b5-51de-431f-a4ee-32f16d7fcea5" satisfied condition "success or failure"
Oct 30 11:28:25.623: INFO: Trying to get logs from node ip-10-1-5-63.eu-central-1.compute.internal pod pod-projected-configmaps-aaeb70b5-51de-431f-a4ee-32f16d7fcea5 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Oct 30 11:28:25.635: INFO: Waiting for pod pod-projected-configmaps-aaeb70b5-51de-431f-a4ee-32f16d7fcea5 to disappear
Oct 30 11:28:25.637: INFO: Pod pod-projected-configmaps-aaeb70b5-51de-431f-a4ee-32f16d7fcea5 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 11:28:25.637: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7075" for this suite.
Oct 30 11:28:31.646: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:28:31.711: INFO: namespace projected-7075 deletion completed in 6.071848336s

• [SLOW TEST:8.231 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 11:28:31.712: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-2600
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Oct 30 11:28:31.845: INFO: Pod name pod-release: Found 0 pods out of 1
Oct 30 11:28:36.848: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 11:28:37.859: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-2600" for this suite.
Oct 30 11:28:43.869: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:28:43.933: INFO: namespace replication-controller-2600 deletion completed in 6.071268275s

• [SLOW TEST:12.221 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 11:28:43.934: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-1891
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-1891
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating stateful set ss in namespace statefulset-1891
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-1891
Oct 30 11:28:44.072: INFO: Found 0 stateful pods, waiting for 1
Oct 30 11:28:54.075: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Oct 30 11:28:54.077: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 exec --namespace=statefulset-1891 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Oct 30 11:28:54.256: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Oct 30 11:28:54.256: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Oct 30 11:28:54.256: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Oct 30 11:28:54.258: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Oct 30 11:29:04.261: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Oct 30 11:29:04.261: INFO: Waiting for statefulset status.replicas updated to 0
Oct 30 11:29:04.272: INFO: POD   NODE                                        PHASE    GRACE  CONDITIONS
Oct 30 11:29:04.272: INFO: ss-0  ip-10-1-5-84.eu-central-1.compute.internal  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:28:44 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:28:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:28:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:28:44 +0000 UTC  }]
Oct 30 11:29:04.272: INFO: 
Oct 30 11:29:04.272: INFO: StatefulSet ss has not reached scale 3, at 1
Oct 30 11:29:05.274: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.996477108s
Oct 30 11:29:06.277: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.993868746s
Oct 30 11:29:07.280: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.990830042s
Oct 30 11:29:08.283: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.98795495s
Oct 30 11:29:09.286: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.985197761s
Oct 30 11:29:10.289: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.982218681s
Oct 30 11:29:11.292: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.979071586s
Oct 30 11:29:12.294: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.976585201s
Oct 30 11:29:13.297: INFO: Verifying statefulset ss doesn't scale past 3 for another 973.723396ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-1891
Oct 30 11:29:14.301: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 exec --namespace=statefulset-1891 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 30 11:29:14.472: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Oct 30 11:29:14.472: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Oct 30 11:29:14.472: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Oct 30 11:29:14.472: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 exec --namespace=statefulset-1891 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 30 11:29:14.631: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Oct 30 11:29:14.631: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Oct 30 11:29:14.631: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Oct 30 11:29:14.631: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 exec --namespace=statefulset-1891 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 30 11:29:14.806: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Oct 30 11:29:14.806: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Oct 30 11:29:14.806: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Oct 30 11:29:14.809: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=false
Oct 30 11:29:24.812: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Oct 30 11:29:24.812: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Oct 30 11:29:24.812: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Oct 30 11:29:24.814: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 exec --namespace=statefulset-1891 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Oct 30 11:29:24.978: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Oct 30 11:29:24.978: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Oct 30 11:29:24.978: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Oct 30 11:29:24.978: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 exec --namespace=statefulset-1891 ss-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Oct 30 11:29:25.151: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Oct 30 11:29:25.151: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Oct 30 11:29:25.151: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Oct 30 11:29:25.151: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 exec --namespace=statefulset-1891 ss-2 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Oct 30 11:29:25.320: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Oct 30 11:29:25.320: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Oct 30 11:29:25.320: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Oct 30 11:29:25.320: INFO: Waiting for statefulset status.replicas updated to 0
Oct 30 11:29:25.322: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Oct 30 11:29:35.327: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Oct 30 11:29:35.327: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Oct 30 11:29:35.327: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Oct 30 11:29:35.334: INFO: POD   NODE                                        PHASE    GRACE  CONDITIONS
Oct 30 11:29:35.334: INFO: ss-0  ip-10-1-5-84.eu-central-1.compute.internal  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:28:44 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:29:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:29:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:28:44 +0000 UTC  }]
Oct 30 11:29:35.334: INFO: ss-1  ip-10-1-5-63.eu-central-1.compute.internal  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:29:04 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:29:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:29:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:29:04 +0000 UTC  }]
Oct 30 11:29:35.334: INFO: ss-2  ip-10-1-5-65.eu-central-1.compute.internal  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:29:04 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:29:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:29:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:29:04 +0000 UTC  }]
Oct 30 11:29:35.334: INFO: 
Oct 30 11:29:35.334: INFO: StatefulSet ss has not reached scale 0, at 3
Oct 30 11:29:36.337: INFO: POD   NODE                                        PHASE    GRACE  CONDITIONS
Oct 30 11:29:36.337: INFO: ss-0  ip-10-1-5-84.eu-central-1.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:28:44 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:29:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:29:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:28:44 +0000 UTC  }]
Oct 30 11:29:36.337: INFO: ss-1  ip-10-1-5-63.eu-central-1.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:29:04 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:29:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:29:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:29:04 +0000 UTC  }]
Oct 30 11:29:36.337: INFO: ss-2  ip-10-1-5-65.eu-central-1.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:29:04 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:29:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:29:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:29:04 +0000 UTC  }]
Oct 30 11:29:36.337: INFO: 
Oct 30 11:29:36.337: INFO: StatefulSet ss has not reached scale 0, at 3
Oct 30 11:29:37.340: INFO: POD   NODE                                        PHASE    GRACE  CONDITIONS
Oct 30 11:29:37.340: INFO: ss-0  ip-10-1-5-84.eu-central-1.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:28:44 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:29:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:29:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:28:44 +0000 UTC  }]
Oct 30 11:29:37.340: INFO: ss-1  ip-10-1-5-63.eu-central-1.compute.internal  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:29:04 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:29:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:29:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:29:04 +0000 UTC  }]
Oct 30 11:29:37.340: INFO: ss-2  ip-10-1-5-65.eu-central-1.compute.internal  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:29:04 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:29:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:29:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:29:04 +0000 UTC  }]
Oct 30 11:29:37.340: INFO: 
Oct 30 11:29:37.340: INFO: StatefulSet ss has not reached scale 0, at 3
Oct 30 11:29:38.343: INFO: POD   NODE                                        PHASE    GRACE  CONDITIONS
Oct 30 11:29:38.343: INFO: ss-0  ip-10-1-5-84.eu-central-1.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:28:44 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:29:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:29:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:28:44 +0000 UTC  }]
Oct 30 11:29:38.343: INFO: ss-1  ip-10-1-5-63.eu-central-1.compute.internal  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:29:04 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:29:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:29:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:29:04 +0000 UTC  }]
Oct 30 11:29:38.343: INFO: 
Oct 30 11:29:38.343: INFO: StatefulSet ss has not reached scale 0, at 2
Oct 30 11:29:39.346: INFO: POD   NODE                                        PHASE    GRACE  CONDITIONS
Oct 30 11:29:39.346: INFO: ss-0  ip-10-1-5-84.eu-central-1.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:28:44 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:29:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:29:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:28:44 +0000 UTC  }]
Oct 30 11:29:39.346: INFO: ss-1  ip-10-1-5-63.eu-central-1.compute.internal  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:29:04 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:29:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:29:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:29:04 +0000 UTC  }]
Oct 30 11:29:39.346: INFO: 
Oct 30 11:29:39.346: INFO: StatefulSet ss has not reached scale 0, at 2
Oct 30 11:29:40.349: INFO: POD   NODE                                        PHASE    GRACE  CONDITIONS
Oct 30 11:29:40.349: INFO: ss-0  ip-10-1-5-84.eu-central-1.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:28:44 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:29:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:29:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:28:44 +0000 UTC  }]
Oct 30 11:29:40.349: INFO: ss-1  ip-10-1-5-63.eu-central-1.compute.internal  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:29:04 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:29:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:29:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:29:04 +0000 UTC  }]
Oct 30 11:29:40.349: INFO: 
Oct 30 11:29:40.349: INFO: StatefulSet ss has not reached scale 0, at 2
Oct 30 11:29:41.352: INFO: POD   NODE                                        PHASE    GRACE  CONDITIONS
Oct 30 11:29:41.352: INFO: ss-0  ip-10-1-5-84.eu-central-1.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:28:44 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:29:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:29:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:28:44 +0000 UTC  }]
Oct 30 11:29:41.352: INFO: 
Oct 30 11:29:41.352: INFO: StatefulSet ss has not reached scale 0, at 1
Oct 30 11:29:42.354: INFO: POD   NODE                                        PHASE    GRACE  CONDITIONS
Oct 30 11:29:42.354: INFO: ss-0  ip-10-1-5-84.eu-central-1.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:28:44 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:29:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:29:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:28:44 +0000 UTC  }]
Oct 30 11:29:42.354: INFO: 
Oct 30 11:29:42.354: INFO: StatefulSet ss has not reached scale 0, at 1
Oct 30 11:29:43.357: INFO: POD   NODE                                        PHASE    GRACE  CONDITIONS
Oct 30 11:29:43.357: INFO: ss-0  ip-10-1-5-84.eu-central-1.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:28:44 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:29:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:29:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:28:44 +0000 UTC  }]
Oct 30 11:29:43.357: INFO: 
Oct 30 11:29:43.357: INFO: StatefulSet ss has not reached scale 0, at 1
Oct 30 11:29:44.360: INFO: POD   NODE                                        PHASE    GRACE  CONDITIONS
Oct 30 11:29:44.360: INFO: ss-0  ip-10-1-5-84.eu-central-1.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:28:44 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:29:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:29:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:28:44 +0000 UTC  }]
Oct 30 11:29:44.360: INFO: 
Oct 30 11:29:44.360: INFO: StatefulSet ss has not reached scale 0, at 1
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-1891
Oct 30 11:29:45.363: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 exec --namespace=statefulset-1891 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 30 11:29:45.453: INFO: rc: 1
Oct 30 11:29:45.453: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-779704590 exec --namespace=statefulset-1891 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  error: unable to upgrade connection: container not found ("nginx")
 [] <nil> 0xc003472030 exit status 1 <nil> <nil> true [0xc002bc18f0 0xc002bc1908 0xc002bc1920] [0xc002bc18f0 0xc002bc1908 0xc002bc1920] [0xc002bc1900 0xc002bc1918] [0xba6ac0 0xba6ac0] 0xc0031e8e40 <nil>}:
Command stdout:

stderr:
error: unable to upgrade connection: container not found ("nginx")

error:
exit status 1
Oct 30 11:29:55.454: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 exec --namespace=statefulset-1891 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 30 11:29:55.526: INFO: rc: 1
Oct 30 11:29:55.526: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-779704590 exec --namespace=statefulset-1891 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002779cb0 exit status 1 <nil> <nil> true [0xc0019cba60 0xc0019cbad0 0xc0019cbb38] [0xc0019cba60 0xc0019cbad0 0xc0019cbb38] [0xc0019cbab0 0xc0019cbb08] [0xba6ac0 0xba6ac0] 0xc0038ebbc0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Oct 30 11:30:05.527: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 exec --namespace=statefulset-1891 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 30 11:30:05.591: INFO: rc: 1
Oct 30 11:30:05.591: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-779704590 exec --namespace=statefulset-1891 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0021b8300 exit status 1 <nil> <nil> true [0xc000010070 0xc000166158 0xc000166780] [0xc000010070 0xc000166158 0xc000166780] [0xc000010790 0xc0001666a0] [0xba6ac0 0xba6ac0] 0xc0024b70e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Oct 30 11:30:15.592: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 exec --namespace=statefulset-1891 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 30 11:30:15.666: INFO: rc: 1
Oct 30 11:30:15.666: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-779704590 exec --namespace=statefulset-1891 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc00214e360 exit status 1 <nil> <nil> true [0xc000330350 0xc000330810 0xc000330c88] [0xc000330350 0xc000330810 0xc000330c88] [0xc000330710 0xc000330ab8] [0xba6ac0 0xba6ac0] 0xc002d68300 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Oct 30 11:30:25.666: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 exec --namespace=statefulset-1891 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 30 11:30:25.747: INFO: rc: 1
Oct 30 11:30:25.747: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-779704590 exec --namespace=statefulset-1891 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc00214e690 exit status 1 <nil> <nil> true [0xc000330d38 0xc000331008 0xc000331400] [0xc000330d38 0xc000331008 0xc000331400] [0xc000330f98 0xc000331290] [0xba6ac0 0xba6ac0] 0xc002d68660 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Oct 30 11:30:35.748: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 exec --namespace=statefulset-1891 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 30 11:30:35.850: INFO: rc: 1
Oct 30 11:30:35.850: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-779704590 exec --namespace=statefulset-1891 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc001b984e0 exit status 1 <nil> <nil> true [0xc002690008 0xc002690030 0xc002690060] [0xc002690008 0xc002690030 0xc002690060] [0xc002690020 0xc002690048] [0xba6ac0 0xba6ac0] 0xc002a025a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Oct 30 11:30:45.850: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 exec --namespace=statefulset-1891 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 30 11:30:45.915: INFO: rc: 1
Oct 30 11:30:45.915: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-779704590 exec --namespace=statefulset-1891 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc001b98870 exit status 1 <nil> <nil> true [0xc002690080 0xc0026900b0 0xc0026900d0] [0xc002690080 0xc0026900b0 0xc0026900d0] [0xc0026900a0 0xc0026900c8] [0xba6ac0 0xba6ac0] 0xc002a02c60 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Oct 30 11:30:55.915: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 exec --namespace=statefulset-1891 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 30 11:30:55.979: INFO: rc: 1
Oct 30 11:30:55.979: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-779704590 exec --namespace=statefulset-1891 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc00214e9f0 exit status 1 <nil> <nil> true [0xc000331578 0xc000331740 0xc000331960] [0xc000331578 0xc000331740 0xc000331960] [0xc0003316e8 0xc0003318d0] [0xba6ac0 0xba6ac0] 0xc002d689c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Oct 30 11:31:05.979: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 exec --namespace=statefulset-1891 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 30 11:31:06.046: INFO: rc: 1
Oct 30 11:31:06.046: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-779704590 exec --namespace=statefulset-1891 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc00214ed50 exit status 1 <nil> <nil> true [0xc000331a88 0xc000331c90 0xc000331df8] [0xc000331a88 0xc000331c90 0xc000331df8] [0xc000331bc8 0xc000331dd8] [0xba6ac0 0xba6ac0] 0xc002d68d20 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Oct 30 11:31:16.046: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 exec --namespace=statefulset-1891 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 30 11:31:16.111: INFO: rc: 1
Oct 30 11:31:16.111: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-779704590 exec --namespace=statefulset-1891 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc001b98ba0 exit status 1 <nil> <nil> true [0xc0026900e0 0xc002690148 0xc002690188] [0xc0026900e0 0xc002690148 0xc002690188] [0xc002690130 0xc002690178] [0xba6ac0 0xba6ac0] 0xc002a03320 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Oct 30 11:31:26.111: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 exec --namespace=statefulset-1891 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 30 11:31:26.176: INFO: rc: 1
Oct 30 11:31:26.176: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-779704590 exec --namespace=statefulset-1891 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc00214f0b0 exit status 1 <nil> <nil> true [0xc000331e08 0xc000331f70 0xc0006476b8] [0xc000331e08 0xc000331f70 0xc0006476b8] [0xc000331f08 0xc000647618] [0xba6ac0 0xba6ac0] 0xc002d69080 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Oct 30 11:31:36.177: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 exec --namespace=statefulset-1891 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 30 11:31:36.240: INFO: rc: 1
Oct 30 11:31:36.240: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-779704590 exec --namespace=statefulset-1891 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc001b98f60 exit status 1 <nil> <nil> true [0xc002690198 0xc0026901b8 0xc002690200] [0xc002690198 0xc0026901b8 0xc002690200] [0xc0026901b0 0xc0026901f0] [0xba6ac0 0xba6ac0] 0xc002a03b00 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Oct 30 11:31:46.240: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 exec --namespace=statefulset-1891 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 30 11:31:46.307: INFO: rc: 1
Oct 30 11:31:46.307: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-779704590 exec --namespace=statefulset-1891 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc001b992f0 exit status 1 <nil> <nil> true [0xc002690208 0xc002690248 0xc002690270] [0xc002690208 0xc002690248 0xc002690270] [0xc002690238 0xc002690268] [0xba6ac0 0xba6ac0] 0xc002a03f20 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Oct 30 11:31:56.308: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 exec --namespace=statefulset-1891 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 30 11:31:56.373: INFO: rc: 1
Oct 30 11:31:56.373: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-779704590 exec --namespace=statefulset-1891 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc001b99620 exit status 1 <nil> <nil> true [0xc002690278 0xc0026902a0 0xc0026902d8] [0xc002690278 0xc0026902a0 0xc0026902d8] [0xc002690290 0xc0026902c8] [0xba6ac0 0xba6ac0] 0xc002028840 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Oct 30 11:32:06.374: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 exec --namespace=statefulset-1891 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 30 11:32:06.440: INFO: rc: 1
Oct 30 11:32:06.440: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-779704590 exec --namespace=statefulset-1891 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc00214e330 exit status 1 <nil> <nil> true [0xc000330630 0xc000330a68 0xc000330d38] [0xc000330630 0xc000330a68 0xc000330d38] [0xc000330810 0xc000330c88] [0xba6ac0 0xba6ac0] 0xc002a024e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Oct 30 11:32:16.440: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 exec --namespace=statefulset-1891 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 30 11:32:16.507: INFO: rc: 1
Oct 30 11:32:16.507: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-779704590 exec --namespace=statefulset-1891 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0021b8330 exit status 1 <nil> <nil> true [0xc000010048 0xc000010790 0xc0006476e8] [0xc000010048 0xc000010790 0xc0006476e8] [0xc000010528 0xc0006476b8] [0xba6ac0 0xba6ac0] 0xc002d68300 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Oct 30 11:32:26.507: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 exec --namespace=statefulset-1891 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 30 11:32:26.571: INFO: rc: 1
Oct 30 11:32:26.572: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-779704590 exec --namespace=statefulset-1891 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002800450 exit status 1 <nil> <nil> true [0xc002690008 0xc002690030 0xc002690060] [0xc002690008 0xc002690030 0xc002690060] [0xc002690020 0xc002690048] [0xba6ac0 0xba6ac0] 0xc0020289c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Oct 30 11:32:36.572: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 exec --namespace=statefulset-1891 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 30 11:32:36.639: INFO: rc: 1
Oct 30 11:32:36.639: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-779704590 exec --namespace=statefulset-1891 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0028007e0 exit status 1 <nil> <nil> true [0xc002690080 0xc0026900b0 0xc0026900d0] [0xc002690080 0xc0026900b0 0xc0026900d0] [0xc0026900a0 0xc0026900c8] [0xba6ac0 0xba6ac0] 0xc002029f20 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Oct 30 11:32:46.639: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 exec --namespace=statefulset-1891 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 30 11:32:46.707: INFO: rc: 1
Oct 30 11:32:46.707: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-779704590 exec --namespace=statefulset-1891 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0021b86f0 exit status 1 <nil> <nil> true [0xc000647780 0xc0006478d8 0xc000647a20] [0xc000647780 0xc0006478d8 0xc000647a20] [0xc000647880 0xc0006479c8] [0xba6ac0 0xba6ac0] 0xc002d68660 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Oct 30 11:32:56.707: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 exec --namespace=statefulset-1891 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 30 11:32:56.773: INFO: rc: 1
Oct 30 11:32:56.773: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-779704590 exec --namespace=statefulset-1891 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc001b98570 exit status 1 <nil> <nil> true [0xc000166158 0xc000166780 0xc000166a60] [0xc000166158 0xc000166780 0xc000166a60] [0xc0001666a0 0xc000166a08] [0xba6ac0 0xba6ac0] 0xc0029be960 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Oct 30 11:33:06.774: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 exec --namespace=statefulset-1891 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 30 11:33:06.959: INFO: rc: 1
Oct 30 11:33:06.959: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-779704590 exec --namespace=statefulset-1891 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc00214e6f0 exit status 1 <nil> <nil> true [0xc000330db0 0xc000331130 0xc000331578] [0xc000330db0 0xc000331130 0xc000331578] [0xc000331008 0xc000331400] [0xba6ac0 0xba6ac0] 0xc002a02ba0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Oct 30 11:33:16.960: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 exec --namespace=statefulset-1891 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 30 11:33:17.028: INFO: rc: 1
Oct 30 11:33:17.028: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-779704590 exec --namespace=statefulset-1891 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002800cc0 exit status 1 <nil> <nil> true [0xc0026900e0 0xc002690148 0xc002690188] [0xc0026900e0 0xc002690148 0xc002690188] [0xc002690130 0xc002690178] [0xba6ac0 0xba6ac0] 0xc0024b7380 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Oct 30 11:33:27.028: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 exec --namespace=statefulset-1891 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 30 11:33:27.094: INFO: rc: 1
Oct 30 11:33:27.094: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-779704590 exec --namespace=statefulset-1891 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc00214eab0 exit status 1 <nil> <nil> true [0xc0003315b0 0xc0003317e8 0xc000331a88] [0xc0003315b0 0xc0003317e8 0xc000331a88] [0xc000331740 0xc000331960] [0xba6ac0 0xba6ac0] 0xc002a03260 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Oct 30 11:33:37.095: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 exec --namespace=statefulset-1891 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 30 11:33:37.165: INFO: rc: 1
Oct 30 11:33:37.165: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-779704590 exec --namespace=statefulset-1891 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002800ff0 exit status 1 <nil> <nil> true [0xc002690198 0xc0026901b8 0xc002690200] [0xc002690198 0xc0026901b8 0xc002690200] [0xc0026901b0 0xc0026901f0] [0xba6ac0 0xba6ac0] 0xc002e161e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Oct 30 11:33:47.165: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 exec --namespace=statefulset-1891 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 30 11:33:47.231: INFO: rc: 1
Oct 30 11:33:47.231: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-779704590 exec --namespace=statefulset-1891 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc00214ee10 exit status 1 <nil> <nil> true [0xc000331b50 0xc000331d68 0xc000331e08] [0xc000331b50 0xc000331d68 0xc000331e08] [0xc000331c90 0xc000331df8] [0xba6ac0 0xba6ac0] 0xc002a03a40 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Oct 30 11:33:57.231: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 exec --namespace=statefulset-1891 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 30 11:33:57.297: INFO: rc: 1
Oct 30 11:33:57.297: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-779704590 exec --namespace=statefulset-1891 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc001b989c0 exit status 1 <nil> <nil> true [0xc000166a80 0xc000166cc0 0xc000166db8] [0xc000166a80 0xc000166cc0 0xc000166db8] [0xc000166be0 0xc000166d88] [0xba6ac0 0xba6ac0] 0xc0029bf1a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Oct 30 11:34:07.298: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 exec --namespace=statefulset-1891 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 30 11:34:07.364: INFO: rc: 1
Oct 30 11:34:07.364: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-779704590 exec --namespace=statefulset-1891 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc001b984e0 exit status 1 <nil> <nil> true [0xc000010070 0xc000166158 0xc000166780] [0xc000010070 0xc000166158 0xc000166780] [0xc000010790 0xc0001666a0] [0xba6ac0 0xba6ac0] 0xc0024b70e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Oct 30 11:34:17.365: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 exec --namespace=statefulset-1891 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 30 11:34:17.432: INFO: rc: 1
Oct 30 11:34:17.432: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-779704590 exec --namespace=statefulset-1891 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc00214e390 exit status 1 <nil> <nil> true [0xc000330350 0xc000330810 0xc000330c88] [0xc000330350 0xc000330810 0xc000330c88] [0xc000330710 0xc000330ab8] [0xba6ac0 0xba6ac0] 0xc0020289c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Oct 30 11:34:27.432: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 exec --namespace=statefulset-1891 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 30 11:34:27.496: INFO: rc: 1
Oct 30 11:34:27.497: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-779704590 exec --namespace=statefulset-1891 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc00214e720 exit status 1 <nil> <nil> true [0xc000330d38 0xc000331008 0xc000331400] [0xc000330d38 0xc000331008 0xc000331400] [0xc000330f98 0xc000331290] [0xba6ac0 0xba6ac0] 0xc002029f20 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Oct 30 11:34:37.497: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 exec --namespace=statefulset-1891 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 30 11:34:37.563: INFO: rc: 1
Oct 30 11:34:37.563: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-779704590 exec --namespace=statefulset-1891 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0021b8300 exit status 1 <nil> <nil> true [0xc000647618 0xc000647780 0xc0006478d8] [0xc000647618 0xc000647780 0xc0006478d8] [0xc0006476e8 0xc000647880] [0xba6ac0 0xba6ac0] 0xc0029be960 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Oct 30 11:34:47.563: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 exec --namespace=statefulset-1891 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 30 11:34:47.628: INFO: rc: 1
Oct 30 11:34:47.628: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: 
Oct 30 11:34:47.629: INFO: Scaling statefulset ss to 0
Oct 30 11:34:47.635: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Oct 30 11:34:47.636: INFO: Deleting all statefulset in ns statefulset-1891
Oct 30 11:34:47.638: INFO: Scaling statefulset ss to 0
Oct 30 11:34:47.644: INFO: Waiting for statefulset status.replicas updated to 0
Oct 30 11:34:47.645: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 11:34:47.653: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-1891" for this suite.
Oct 30 11:34:53.663: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:34:53.728: INFO: namespace statefulset-1891 deletion completed in 6.072775422s

• [SLOW TEST:369.795 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 11:34:53.729: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-6146
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Oct 30 11:34:53.863: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Oct 30 11:34:58.866: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Oct 30 11:34:58.866: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
Oct 30 11:34:58.877: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment,GenerateName:,Namespace:deployment-6146,SelfLink:/apis/apps/v1/namespaces/deployment-6146/deployments/test-cleanup-deployment,UID:5fd6c270-1f53-4ef4-8bac-af8cd066bb79,ResourceVersion:25380,Generation:1,CreationTimestamp:2019-10-30 11:34:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[],ReadyReplicas:0,CollisionCount:nil,},}

Oct 30 11:34:58.880: INFO: New ReplicaSet of Deployment "test-cleanup-deployment" is nil.
Oct 30 11:34:58.880: INFO: All old ReplicaSets of Deployment "test-cleanup-deployment":
Oct 30 11:34:58.880: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller,GenerateName:,Namespace:deployment-6146,SelfLink:/apis/apps/v1/namespaces/deployment-6146/replicasets/test-cleanup-controller,UID:ca414e96-d5a1-48cc-8bda-6485711a997c,ResourceVersion:25381,Generation:1,CreationTimestamp:2019-10-30 11:34:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment 5fd6c270-1f53-4ef4-8bac-af8cd066bb79 0xc002c228c7 0xc002c228c8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Oct 30 11:34:58.883: INFO: Pod "test-cleanup-controller-5pfj4" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller-5pfj4,GenerateName:test-cleanup-controller-,Namespace:deployment-6146,SelfLink:/api/v1/namespaces/deployment-6146/pods/test-cleanup-controller-5pfj4,UID:43bd040a-8260-4732-ae68-af12196b2a7c,ResourceVersion:25369,Generation:0,CreationTimestamp:2019-10-30 11:34:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-controller ca414e96-d5a1-48cc-8bda-6485711a997c 0xc00252d3d7 0xc00252d3d8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-tf8xv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tf8xv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-tf8xv true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-1-5-63.eu-central-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00252d4c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00252d4e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:34:53 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:34:55 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:34:55 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:34:53 +0000 UTC  }],Message:,Reason:,HostIP:10.1.5.63,PodIP:192.168.247.17,StartTime:2019-10-30 11:34:53 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-10-30 11:34:54 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://ea2722439ecbf76812359a47d35cf949f8ba76b6c7fc17def5664105125d01d6}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 11:34:58.883: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-6146" for this suite.
Oct 30 11:35:04.899: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:35:04.973: INFO: namespace deployment-6146 deletion completed in 6.085369496s

• [SLOW TEST:11.244 seconds]
[sig-apps] Deployment
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 11:35:04.973: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2679
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Oct 30 11:35:05.117: INFO: Waiting up to 5m0s for pod "downwardapi-volume-fc633964-a82d-4ab6-bb0c-09e4bd927d95" in namespace "projected-2679" to be "success or failure"
Oct 30 11:35:05.119: INFO: Pod "downwardapi-volume-fc633964-a82d-4ab6-bb0c-09e4bd927d95": Phase="Pending", Reason="", readiness=false. Elapsed: 2.238414ms
Oct 30 11:35:07.121: INFO: Pod "downwardapi-volume-fc633964-a82d-4ab6-bb0c-09e4bd927d95": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004603296s
STEP: Saw pod success
Oct 30 11:35:07.121: INFO: Pod "downwardapi-volume-fc633964-a82d-4ab6-bb0c-09e4bd927d95" satisfied condition "success or failure"
Oct 30 11:35:07.123: INFO: Trying to get logs from node ip-10-1-5-63.eu-central-1.compute.internal pod downwardapi-volume-fc633964-a82d-4ab6-bb0c-09e4bd927d95 container client-container: <nil>
STEP: delete the pod
Oct 30 11:35:07.135: INFO: Waiting for pod downwardapi-volume-fc633964-a82d-4ab6-bb0c-09e4bd927d95 to disappear
Oct 30 11:35:07.137: INFO: Pod downwardapi-volume-fc633964-a82d-4ab6-bb0c-09e4bd927d95 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 11:35:07.137: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2679" for this suite.
Oct 30 11:35:13.146: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:35:13.211: INFO: namespace projected-2679 deletion completed in 6.071332934s

• [SLOW TEST:8.238 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 11:35:13.211: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-334
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:273
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a replication controller
Oct 30 11:35:13.339: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 create -f - --namespace=kubectl-334'
Oct 30 11:35:13.487: INFO: stderr: ""
Oct 30 11:35:13.487: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Oct 30 11:35:13.487: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-334'
Oct 30 11:35:13.559: INFO: stderr: ""
Oct 30 11:35:13.560: INFO: stdout: "update-demo-nautilus-6s6lz update-demo-nautilus-nkxpk "
Oct 30 11:35:13.560: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 get pods update-demo-nautilus-6s6lz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-334'
Oct 30 11:35:13.624: INFO: stderr: ""
Oct 30 11:35:13.624: INFO: stdout: ""
Oct 30 11:35:13.624: INFO: update-demo-nautilus-6s6lz is created but not running
Oct 30 11:35:18.624: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-334'
Oct 30 11:35:18.691: INFO: stderr: ""
Oct 30 11:35:18.691: INFO: stdout: "update-demo-nautilus-6s6lz update-demo-nautilus-nkxpk "
Oct 30 11:35:18.691: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 get pods update-demo-nautilus-6s6lz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-334'
Oct 30 11:35:18.757: INFO: stderr: ""
Oct 30 11:35:18.757: INFO: stdout: "true"
Oct 30 11:35:18.758: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 get pods update-demo-nautilus-6s6lz -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-334'
Oct 30 11:35:18.832: INFO: stderr: ""
Oct 30 11:35:18.832: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Oct 30 11:35:18.832: INFO: validating pod update-demo-nautilus-6s6lz
Oct 30 11:35:18.835: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct 30 11:35:18.835: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct 30 11:35:18.835: INFO: update-demo-nautilus-6s6lz is verified up and running
Oct 30 11:35:18.835: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 get pods update-demo-nautilus-nkxpk -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-334'
Oct 30 11:35:18.901: INFO: stderr: ""
Oct 30 11:35:18.901: INFO: stdout: "true"
Oct 30 11:35:18.901: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 get pods update-demo-nautilus-nkxpk -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-334'
Oct 30 11:35:18.965: INFO: stderr: ""
Oct 30 11:35:18.965: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Oct 30 11:35:18.965: INFO: validating pod update-demo-nautilus-nkxpk
Oct 30 11:35:18.967: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct 30 11:35:18.968: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct 30 11:35:18.968: INFO: update-demo-nautilus-nkxpk is verified up and running
STEP: scaling down the replication controller
Oct 30 11:35:18.970: INFO: scanned /root for discovery docs: <nil>
Oct 30 11:35:18.970: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=kubectl-334'
Oct 30 11:35:20.049: INFO: stderr: ""
Oct 30 11:35:20.049: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Oct 30 11:35:20.049: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-334'
Oct 30 11:35:20.121: INFO: stderr: ""
Oct 30 11:35:20.121: INFO: stdout: "update-demo-nautilus-6s6lz update-demo-nautilus-nkxpk "
STEP: Replicas for name=update-demo: expected=1 actual=2
Oct 30 11:35:25.121: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-334'
Oct 30 11:35:25.191: INFO: stderr: ""
Oct 30 11:35:25.191: INFO: stdout: "update-demo-nautilus-6s6lz update-demo-nautilus-nkxpk "
STEP: Replicas for name=update-demo: expected=1 actual=2
Oct 30 11:35:30.192: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-334'
Oct 30 11:35:30.262: INFO: stderr: ""
Oct 30 11:35:30.262: INFO: stdout: "update-demo-nautilus-6s6lz "
Oct 30 11:35:30.262: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 get pods update-demo-nautilus-6s6lz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-334'
Oct 30 11:35:30.328: INFO: stderr: ""
Oct 30 11:35:30.329: INFO: stdout: "true"
Oct 30 11:35:30.329: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 get pods update-demo-nautilus-6s6lz -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-334'
Oct 30 11:35:30.393: INFO: stderr: ""
Oct 30 11:35:30.393: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Oct 30 11:35:30.393: INFO: validating pod update-demo-nautilus-6s6lz
Oct 30 11:35:30.396: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct 30 11:35:30.396: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct 30 11:35:30.396: INFO: update-demo-nautilus-6s6lz is verified up and running
STEP: scaling up the replication controller
Oct 30 11:35:30.398: INFO: scanned /root for discovery docs: <nil>
Oct 30 11:35:30.398: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=kubectl-334'
Oct 30 11:35:31.484: INFO: stderr: ""
Oct 30 11:35:31.484: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Oct 30 11:35:31.484: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-334'
Oct 30 11:35:31.553: INFO: stderr: ""
Oct 30 11:35:31.553: INFO: stdout: "update-demo-nautilus-6s6lz update-demo-nautilus-qp5lf "
Oct 30 11:35:31.553: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 get pods update-demo-nautilus-6s6lz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-334'
Oct 30 11:35:31.619: INFO: stderr: ""
Oct 30 11:35:31.619: INFO: stdout: "true"
Oct 30 11:35:31.619: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 get pods update-demo-nautilus-6s6lz -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-334'
Oct 30 11:35:31.686: INFO: stderr: ""
Oct 30 11:35:31.686: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Oct 30 11:35:31.686: INFO: validating pod update-demo-nautilus-6s6lz
Oct 30 11:35:31.688: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct 30 11:35:31.688: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct 30 11:35:31.688: INFO: update-demo-nautilus-6s6lz is verified up and running
Oct 30 11:35:31.688: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 get pods update-demo-nautilus-qp5lf -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-334'
Oct 30 11:35:31.757: INFO: stderr: ""
Oct 30 11:35:31.757: INFO: stdout: ""
Oct 30 11:35:31.757: INFO: update-demo-nautilus-qp5lf is created but not running
Oct 30 11:35:36.758: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-334'
Oct 30 11:35:36.825: INFO: stderr: ""
Oct 30 11:35:36.825: INFO: stdout: "update-demo-nautilus-6s6lz update-demo-nautilus-qp5lf "
Oct 30 11:35:36.825: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 get pods update-demo-nautilus-6s6lz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-334'
Oct 30 11:35:36.888: INFO: stderr: ""
Oct 30 11:35:36.888: INFO: stdout: "true"
Oct 30 11:35:36.888: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 get pods update-demo-nautilus-6s6lz -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-334'
Oct 30 11:35:36.952: INFO: stderr: ""
Oct 30 11:35:36.952: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Oct 30 11:35:36.952: INFO: validating pod update-demo-nautilus-6s6lz
Oct 30 11:35:36.954: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct 30 11:35:36.954: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct 30 11:35:36.954: INFO: update-demo-nautilus-6s6lz is verified up and running
Oct 30 11:35:36.954: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 get pods update-demo-nautilus-qp5lf -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-334'
Oct 30 11:35:37.018: INFO: stderr: ""
Oct 30 11:35:37.018: INFO: stdout: "true"
Oct 30 11:35:37.018: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 get pods update-demo-nautilus-qp5lf -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-334'
Oct 30 11:35:37.087: INFO: stderr: ""
Oct 30 11:35:37.087: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Oct 30 11:35:37.087: INFO: validating pod update-demo-nautilus-qp5lf
Oct 30 11:35:37.090: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct 30 11:35:37.090: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct 30 11:35:37.090: INFO: update-demo-nautilus-qp5lf is verified up and running
STEP: using delete to clean up resources
Oct 30 11:35:37.091: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 delete --grace-period=0 --force -f - --namespace=kubectl-334'
Oct 30 11:35:37.154: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct 30 11:35:37.154: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Oct 30 11:35:37.154: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-334'
Oct 30 11:35:37.252: INFO: stderr: "No resources found.\n"
Oct 30 11:35:37.252: INFO: stdout: ""
Oct 30 11:35:37.252: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 get pods -l name=update-demo --namespace=kubectl-334 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Oct 30 11:35:37.346: INFO: stderr: ""
Oct 30 11:35:37.346: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 11:35:37.346: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-334" for this suite.
Oct 30 11:35:59.356: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:35:59.422: INFO: namespace kubectl-334 deletion completed in 22.072856106s

• [SLOW TEST:46.210 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] version v1
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 11:35:59.422: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-8623
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-vkvnp in namespace proxy-8623
I1030 11:35:59.567001      18 runners.go:180] Created replication controller with name: proxy-service-vkvnp, namespace: proxy-8623, replica count: 1
I1030 11:36:00.617447      18 runners.go:180] proxy-service-vkvnp Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1030 11:36:01.617669      18 runners.go:180] proxy-service-vkvnp Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1030 11:36:02.618417      18 runners.go:180] proxy-service-vkvnp Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1030 11:36:03.618741      18 runners.go:180] proxy-service-vkvnp Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1030 11:36:04.618992      18 runners.go:180] proxy-service-vkvnp Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1030 11:36:05.619236      18 runners.go:180] proxy-service-vkvnp Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Oct 30 11:36:05.621: INFO: setup took 6.066295619s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Oct 30 11:36:05.628: INFO: (0) /api/v1/namespaces/proxy-8623/pods/http:proxy-service-vkvnp-46vrr:1080/proxy/: <a href="/api/v1/namespaces/proxy-8623/pods/http:proxy-service-vkvnp-46vrr:1080/proxy/rewriteme">... (200; 6.732887ms)
Oct 30 11:36:05.628: INFO: (0) /api/v1/namespaces/proxy-8623/pods/proxy-service-vkvnp-46vrr/proxy/: <a href="/api/v1/namespaces/proxy-8623/pods/proxy-service-vkvnp-46vrr/proxy/rewriteme">test</a> (200; 6.905035ms)
Oct 30 11:36:05.629: INFO: (0) /api/v1/namespaces/proxy-8623/pods/http:proxy-service-vkvnp-46vrr:160/proxy/: foo (200; 7.834086ms)
Oct 30 11:36:05.629: INFO: (0) /api/v1/namespaces/proxy-8623/pods/proxy-service-vkvnp-46vrr:162/proxy/: bar (200; 7.797217ms)
Oct 30 11:36:05.629: INFO: (0) /api/v1/namespaces/proxy-8623/pods/proxy-service-vkvnp-46vrr:1080/proxy/: <a href="/api/v1/namespaces/proxy-8623/pods/proxy-service-vkvnp-46vrr:1080/proxy/rewriteme">test<... (200; 7.897812ms)
Oct 30 11:36:05.630: INFO: (0) /api/v1/namespaces/proxy-8623/pods/http:proxy-service-vkvnp-46vrr:162/proxy/: bar (200; 8.540644ms)
Oct 30 11:36:05.630: INFO: (0) /api/v1/namespaces/proxy-8623/pods/proxy-service-vkvnp-46vrr:160/proxy/: foo (200; 8.42728ms)
Oct 30 11:36:05.631: INFO: (0) /api/v1/namespaces/proxy-8623/services/proxy-service-vkvnp:portname1/proxy/: foo (200; 9.08135ms)
Oct 30 11:36:05.631: INFO: (0) /api/v1/namespaces/proxy-8623/services/http:proxy-service-vkvnp:portname1/proxy/: foo (200; 9.418479ms)
Oct 30 11:36:05.634: INFO: (0) /api/v1/namespaces/proxy-8623/services/proxy-service-vkvnp:portname2/proxy/: bar (200; 11.918387ms)
Oct 30 11:36:05.634: INFO: (0) /api/v1/namespaces/proxy-8623/services/http:proxy-service-vkvnp:portname2/proxy/: bar (200; 12.253879ms)
Oct 30 11:36:05.636: INFO: (0) /api/v1/namespaces/proxy-8623/pods/https:proxy-service-vkvnp-46vrr:462/proxy/: tls qux (200; 14.218855ms)
Oct 30 11:36:05.636: INFO: (0) /api/v1/namespaces/proxy-8623/pods/https:proxy-service-vkvnp-46vrr:460/proxy/: tls baz (200; 14.591494ms)
Oct 30 11:36:05.637: INFO: (0) /api/v1/namespaces/proxy-8623/pods/https:proxy-service-vkvnp-46vrr:443/proxy/: <a href="/api/v1/namespaces/proxy-8623/pods/https:proxy-service-vkvnp-46vrr:443/proxy/tlsrewritem... (200; 15.35084ms)
Oct 30 11:36:05.640: INFO: (0) /api/v1/namespaces/proxy-8623/services/https:proxy-service-vkvnp:tlsportname2/proxy/: tls qux (200; 18.540117ms)
Oct 30 11:36:05.640: INFO: (0) /api/v1/namespaces/proxy-8623/services/https:proxy-service-vkvnp:tlsportname1/proxy/: tls baz (200; 18.653029ms)
Oct 30 11:36:05.643: INFO: (1) /api/v1/namespaces/proxy-8623/pods/http:proxy-service-vkvnp-46vrr:1080/proxy/: <a href="/api/v1/namespaces/proxy-8623/pods/http:proxy-service-vkvnp-46vrr:1080/proxy/rewriteme">... (200; 2.747073ms)
Oct 30 11:36:05.644: INFO: (1) /api/v1/namespaces/proxy-8623/pods/https:proxy-service-vkvnp-46vrr:460/proxy/: tls baz (200; 3.544358ms)
Oct 30 11:36:05.646: INFO: (1) /api/v1/namespaces/proxy-8623/pods/proxy-service-vkvnp-46vrr:1080/proxy/: <a href="/api/v1/namespaces/proxy-8623/pods/proxy-service-vkvnp-46vrr:1080/proxy/rewriteme">test<... (200; 5.331917ms)
Oct 30 11:36:05.646: INFO: (1) /api/v1/namespaces/proxy-8623/services/http:proxy-service-vkvnp:portname1/proxy/: foo (200; 5.891778ms)
Oct 30 11:36:05.646: INFO: (1) /api/v1/namespaces/proxy-8623/pods/https:proxy-service-vkvnp-46vrr:443/proxy/: <a href="/api/v1/namespaces/proxy-8623/pods/https:proxy-service-vkvnp-46vrr:443/proxy/tlsrewritem... (200; 5.660765ms)
Oct 30 11:36:05.646: INFO: (1) /api/v1/namespaces/proxy-8623/pods/proxy-service-vkvnp-46vrr/proxy/: <a href="/api/v1/namespaces/proxy-8623/pods/proxy-service-vkvnp-46vrr/proxy/rewriteme">test</a> (200; 5.91074ms)
Oct 30 11:36:05.646: INFO: (1) /api/v1/namespaces/proxy-8623/pods/http:proxy-service-vkvnp-46vrr:162/proxy/: bar (200; 6.063829ms)
Oct 30 11:36:05.647: INFO: (1) /api/v1/namespaces/proxy-8623/pods/https:proxy-service-vkvnp-46vrr:462/proxy/: tls qux (200; 6.491214ms)
Oct 30 11:36:05.647: INFO: (1) /api/v1/namespaces/proxy-8623/pods/proxy-service-vkvnp-46vrr:160/proxy/: foo (200; 6.396855ms)
Oct 30 11:36:05.647: INFO: (1) /api/v1/namespaces/proxy-8623/services/https:proxy-service-vkvnp:tlsportname1/proxy/: tls baz (200; 6.718016ms)
Oct 30 11:36:05.647: INFO: (1) /api/v1/namespaces/proxy-8623/pods/proxy-service-vkvnp-46vrr:162/proxy/: bar (200; 7.056782ms)
Oct 30 11:36:05.649: INFO: (1) /api/v1/namespaces/proxy-8623/services/proxy-service-vkvnp:portname1/proxy/: foo (200; 8.866593ms)
Oct 30 11:36:05.650: INFO: (1) /api/v1/namespaces/proxy-8623/services/https:proxy-service-vkvnp:tlsportname2/proxy/: tls qux (200; 9.189927ms)
Oct 30 11:36:05.650: INFO: (1) /api/v1/namespaces/proxy-8623/services/proxy-service-vkvnp:portname2/proxy/: bar (200; 9.661639ms)
Oct 30 11:36:05.650: INFO: (1) /api/v1/namespaces/proxy-8623/pods/http:proxy-service-vkvnp-46vrr:160/proxy/: foo (200; 9.886441ms)
Oct 30 11:36:05.650: INFO: (1) /api/v1/namespaces/proxy-8623/services/http:proxy-service-vkvnp:portname2/proxy/: bar (200; 10.047772ms)
Oct 30 11:36:05.657: INFO: (2) /api/v1/namespaces/proxy-8623/pods/proxy-service-vkvnp-46vrr/proxy/: <a href="/api/v1/namespaces/proxy-8623/pods/proxy-service-vkvnp-46vrr/proxy/rewriteme">test</a> (200; 6.114524ms)
Oct 30 11:36:05.657: INFO: (2) /api/v1/namespaces/proxy-8623/pods/proxy-service-vkvnp-46vrr:160/proxy/: foo (200; 6.595664ms)
Oct 30 11:36:05.658: INFO: (2) /api/v1/namespaces/proxy-8623/pods/proxy-service-vkvnp-46vrr:162/proxy/: bar (200; 6.846491ms)
Oct 30 11:36:05.658: INFO: (2) /api/v1/namespaces/proxy-8623/pods/http:proxy-service-vkvnp-46vrr:162/proxy/: bar (200; 7.502888ms)
Oct 30 11:36:05.658: INFO: (2) /api/v1/namespaces/proxy-8623/pods/https:proxy-service-vkvnp-46vrr:462/proxy/: tls qux (200; 7.819956ms)
Oct 30 11:36:05.658: INFO: (2) /api/v1/namespaces/proxy-8623/services/https:proxy-service-vkvnp:tlsportname1/proxy/: tls baz (200; 7.546191ms)
Oct 30 11:36:05.658: INFO: (2) /api/v1/namespaces/proxy-8623/services/proxy-service-vkvnp:portname1/proxy/: foo (200; 8.037306ms)
Oct 30 11:36:05.659: INFO: (2) /api/v1/namespaces/proxy-8623/services/http:proxy-service-vkvnp:portname1/proxy/: foo (200; 8.266347ms)
Oct 30 11:36:05.659: INFO: (2) /api/v1/namespaces/proxy-8623/pods/proxy-service-vkvnp-46vrr:1080/proxy/: <a href="/api/v1/namespaces/proxy-8623/pods/proxy-service-vkvnp-46vrr:1080/proxy/rewriteme">test<... (200; 8.407447ms)
Oct 30 11:36:05.659: INFO: (2) /api/v1/namespaces/proxy-8623/pods/https:proxy-service-vkvnp-46vrr:443/proxy/: <a href="/api/v1/namespaces/proxy-8623/pods/https:proxy-service-vkvnp-46vrr:443/proxy/tlsrewritem... (200; 8.387865ms)
Oct 30 11:36:05.660: INFO: (2) /api/v1/namespaces/proxy-8623/pods/https:proxy-service-vkvnp-46vrr:460/proxy/: tls baz (200; 8.648654ms)
Oct 30 11:36:05.660: INFO: (2) /api/v1/namespaces/proxy-8623/pods/http:proxy-service-vkvnp-46vrr:1080/proxy/: <a href="/api/v1/namespaces/proxy-8623/pods/http:proxy-service-vkvnp-46vrr:1080/proxy/rewriteme">... (200; 8.765485ms)
Oct 30 11:36:05.660: INFO: (2) /api/v1/namespaces/proxy-8623/pods/http:proxy-service-vkvnp-46vrr:160/proxy/: foo (200; 9.187313ms)
Oct 30 11:36:05.660: INFO: (2) /api/v1/namespaces/proxy-8623/services/https:proxy-service-vkvnp:tlsportname2/proxy/: tls qux (200; 8.991177ms)
Oct 30 11:36:05.660: INFO: (2) /api/v1/namespaces/proxy-8623/services/proxy-service-vkvnp:portname2/proxy/: bar (200; 9.163852ms)
Oct 30 11:36:05.660: INFO: (2) /api/v1/namespaces/proxy-8623/services/http:proxy-service-vkvnp:portname2/proxy/: bar (200; 9.191685ms)
Oct 30 11:36:05.664: INFO: (3) /api/v1/namespaces/proxy-8623/pods/http:proxy-service-vkvnp-46vrr:160/proxy/: foo (200; 3.596507ms)
Oct 30 11:36:05.665: INFO: (3) /api/v1/namespaces/proxy-8623/pods/proxy-service-vkvnp-46vrr/proxy/: <a href="/api/v1/namespaces/proxy-8623/pods/proxy-service-vkvnp-46vrr/proxy/rewriteme">test</a> (200; 4.770194ms)
Oct 30 11:36:05.665: INFO: (3) /api/v1/namespaces/proxy-8623/pods/proxy-service-vkvnp-46vrr:1080/proxy/: <a href="/api/v1/namespaces/proxy-8623/pods/proxy-service-vkvnp-46vrr:1080/proxy/rewriteme">test<... (200; 4.765795ms)
Oct 30 11:36:05.665: INFO: (3) /api/v1/namespaces/proxy-8623/pods/https:proxy-service-vkvnp-46vrr:443/proxy/: <a href="/api/v1/namespaces/proxy-8623/pods/https:proxy-service-vkvnp-46vrr:443/proxy/tlsrewritem... (200; 4.601375ms)
Oct 30 11:36:05.666: INFO: (3) /api/v1/namespaces/proxy-8623/pods/proxy-service-vkvnp-46vrr:162/proxy/: bar (200; 5.166532ms)
Oct 30 11:36:05.667: INFO: (3) /api/v1/namespaces/proxy-8623/pods/https:proxy-service-vkvnp-46vrr:462/proxy/: tls qux (200; 6.71221ms)
Oct 30 11:36:05.668: INFO: (3) /api/v1/namespaces/proxy-8623/pods/http:proxy-service-vkvnp-46vrr:1080/proxy/: <a href="/api/v1/namespaces/proxy-8623/pods/http:proxy-service-vkvnp-46vrr:1080/proxy/rewriteme">... (200; 6.940403ms)
Oct 30 11:36:05.668: INFO: (3) /api/v1/namespaces/proxy-8623/pods/https:proxy-service-vkvnp-46vrr:460/proxy/: tls baz (200; 7.238523ms)
Oct 30 11:36:05.668: INFO: (3) /api/v1/namespaces/proxy-8623/pods/proxy-service-vkvnp-46vrr:160/proxy/: foo (200; 7.233383ms)
Oct 30 11:36:05.668: INFO: (3) /api/v1/namespaces/proxy-8623/pods/http:proxy-service-vkvnp-46vrr:162/proxy/: bar (200; 7.566481ms)
Oct 30 11:36:05.670: INFO: (3) /api/v1/namespaces/proxy-8623/services/http:proxy-service-vkvnp:portname2/proxy/: bar (200; 9.38034ms)
Oct 30 11:36:05.670: INFO: (3) /api/v1/namespaces/proxy-8623/services/http:proxy-service-vkvnp:portname1/proxy/: foo (200; 9.863939ms)
Oct 30 11:36:05.670: INFO: (3) /api/v1/namespaces/proxy-8623/services/https:proxy-service-vkvnp:tlsportname2/proxy/: tls qux (200; 9.636014ms)
Oct 30 11:36:05.670: INFO: (3) /api/v1/namespaces/proxy-8623/services/proxy-service-vkvnp:portname2/proxy/: bar (200; 9.903758ms)
Oct 30 11:36:05.670: INFO: (3) /api/v1/namespaces/proxy-8623/services/proxy-service-vkvnp:portname1/proxy/: foo (200; 9.913053ms)
Oct 30 11:36:05.671: INFO: (3) /api/v1/namespaces/proxy-8623/services/https:proxy-service-vkvnp:tlsportname1/proxy/: tls baz (200; 10.003824ms)
Oct 30 11:36:05.676: INFO: (4) /api/v1/namespaces/proxy-8623/pods/http:proxy-service-vkvnp-46vrr:160/proxy/: foo (200; 5.406756ms)
Oct 30 11:36:05.676: INFO: (4) /api/v1/namespaces/proxy-8623/pods/https:proxy-service-vkvnp-46vrr:460/proxy/: tls baz (200; 5.301405ms)
Oct 30 11:36:05.677: INFO: (4) /api/v1/namespaces/proxy-8623/services/http:proxy-service-vkvnp:portname2/proxy/: bar (200; 5.712175ms)
Oct 30 11:36:05.677: INFO: (4) /api/v1/namespaces/proxy-8623/pods/http:proxy-service-vkvnp-46vrr:162/proxy/: bar (200; 5.791543ms)
Oct 30 11:36:05.677: INFO: (4) /api/v1/namespaces/proxy-8623/pods/http:proxy-service-vkvnp-46vrr:1080/proxy/: <a href="/api/v1/namespaces/proxy-8623/pods/http:proxy-service-vkvnp-46vrr:1080/proxy/rewriteme">... (200; 6.30485ms)
Oct 30 11:36:05.677: INFO: (4) /api/v1/namespaces/proxy-8623/services/http:proxy-service-vkvnp:portname1/proxy/: foo (200; 6.399317ms)
Oct 30 11:36:05.677: INFO: (4) /api/v1/namespaces/proxy-8623/pods/proxy-service-vkvnp-46vrr:162/proxy/: bar (200; 6.628399ms)
Oct 30 11:36:05.678: INFO: (4) /api/v1/namespaces/proxy-8623/pods/proxy-service-vkvnp-46vrr:160/proxy/: foo (200; 6.786237ms)
Oct 30 11:36:05.678: INFO: (4) /api/v1/namespaces/proxy-8623/pods/proxy-service-vkvnp-46vrr:1080/proxy/: <a href="/api/v1/namespaces/proxy-8623/pods/proxy-service-vkvnp-46vrr:1080/proxy/rewriteme">test<... (200; 7.160048ms)
Oct 30 11:36:05.679: INFO: (4) /api/v1/namespaces/proxy-8623/services/proxy-service-vkvnp:portname1/proxy/: foo (200; 7.922266ms)
Oct 30 11:36:05.679: INFO: (4) /api/v1/namespaces/proxy-8623/pods/https:proxy-service-vkvnp-46vrr:462/proxy/: tls qux (200; 8.300223ms)
Oct 30 11:36:05.679: INFO: (4) /api/v1/namespaces/proxy-8623/pods/proxy-service-vkvnp-46vrr/proxy/: <a href="/api/v1/namespaces/proxy-8623/pods/proxy-service-vkvnp-46vrr/proxy/rewriteme">test</a> (200; 8.500217ms)
Oct 30 11:36:05.679: INFO: (4) /api/v1/namespaces/proxy-8623/services/proxy-service-vkvnp:portname2/proxy/: bar (200; 8.40063ms)
Oct 30 11:36:05.680: INFO: (4) /api/v1/namespaces/proxy-8623/pods/https:proxy-service-vkvnp-46vrr:443/proxy/: <a href="/api/v1/namespaces/proxy-8623/pods/https:proxy-service-vkvnp-46vrr:443/proxy/tlsrewritem... (200; 8.243997ms)
Oct 30 11:36:05.680: INFO: (4) /api/v1/namespaces/proxy-8623/services/https:proxy-service-vkvnp:tlsportname2/proxy/: tls qux (200; 8.550011ms)
Oct 30 11:36:05.680: INFO: (4) /api/v1/namespaces/proxy-8623/services/https:proxy-service-vkvnp:tlsportname1/proxy/: tls baz (200; 8.294983ms)
Oct 30 11:36:05.686: INFO: (5) /api/v1/namespaces/proxy-8623/pods/http:proxy-service-vkvnp-46vrr:1080/proxy/: <a href="/api/v1/namespaces/proxy-8623/pods/http:proxy-service-vkvnp-46vrr:1080/proxy/rewriteme">... (200; 5.989494ms)
Oct 30 11:36:05.687: INFO: (5) /api/v1/namespaces/proxy-8623/pods/https:proxy-service-vkvnp-46vrr:460/proxy/: tls baz (200; 6.481845ms)
Oct 30 11:36:05.687: INFO: (5) /api/v1/namespaces/proxy-8623/pods/proxy-service-vkvnp-46vrr:160/proxy/: foo (200; 6.694235ms)
Oct 30 11:36:05.687: INFO: (5) /api/v1/namespaces/proxy-8623/pods/proxy-service-vkvnp-46vrr/proxy/: <a href="/api/v1/namespaces/proxy-8623/pods/proxy-service-vkvnp-46vrr/proxy/rewriteme">test</a> (200; 6.800299ms)
Oct 30 11:36:05.687: INFO: (5) /api/v1/namespaces/proxy-8623/pods/proxy-service-vkvnp-46vrr:1080/proxy/: <a href="/api/v1/namespaces/proxy-8623/pods/proxy-service-vkvnp-46vrr:1080/proxy/rewriteme">test<... (200; 6.78858ms)
Oct 30 11:36:05.687: INFO: (5) /api/v1/namespaces/proxy-8623/pods/https:proxy-service-vkvnp-46vrr:462/proxy/: tls qux (200; 6.943662ms)
Oct 30 11:36:05.687: INFO: (5) /api/v1/namespaces/proxy-8623/services/https:proxy-service-vkvnp:tlsportname1/proxy/: tls baz (200; 7.224086ms)
Oct 30 11:36:05.687: INFO: (5) /api/v1/namespaces/proxy-8623/services/http:proxy-service-vkvnp:portname2/proxy/: bar (200; 7.070103ms)
Oct 30 11:36:05.687: INFO: (5) /api/v1/namespaces/proxy-8623/pods/http:proxy-service-vkvnp-46vrr:162/proxy/: bar (200; 7.066301ms)
Oct 30 11:36:05.687: INFO: (5) /api/v1/namespaces/proxy-8623/pods/http:proxy-service-vkvnp-46vrr:160/proxy/: foo (200; 7.241029ms)
Oct 30 11:36:05.687: INFO: (5) /api/v1/namespaces/proxy-8623/pods/proxy-service-vkvnp-46vrr:162/proxy/: bar (200; 7.222296ms)
Oct 30 11:36:05.688: INFO: (5) /api/v1/namespaces/proxy-8623/pods/https:proxy-service-vkvnp-46vrr:443/proxy/: <a href="/api/v1/namespaces/proxy-8623/pods/https:proxy-service-vkvnp-46vrr:443/proxy/tlsrewritem... (200; 7.928189ms)
Oct 30 11:36:05.688: INFO: (5) /api/v1/namespaces/proxy-8623/services/proxy-service-vkvnp:portname1/proxy/: foo (200; 8.497222ms)
Oct 30 11:36:05.688: INFO: (5) /api/v1/namespaces/proxy-8623/services/https:proxy-service-vkvnp:tlsportname2/proxy/: tls qux (200; 8.468761ms)
Oct 30 11:36:05.689: INFO: (5) /api/v1/namespaces/proxy-8623/services/proxy-service-vkvnp:portname2/proxy/: bar (200; 8.669685ms)
Oct 30 11:36:05.689: INFO: (5) /api/v1/namespaces/proxy-8623/services/http:proxy-service-vkvnp:portname1/proxy/: foo (200; 8.952955ms)
Oct 30 11:36:05.694: INFO: (6) /api/v1/namespaces/proxy-8623/pods/http:proxy-service-vkvnp-46vrr:1080/proxy/: <a href="/api/v1/namespaces/proxy-8623/pods/http:proxy-service-vkvnp-46vrr:1080/proxy/rewriteme">... (200; 4.147083ms)
Oct 30 11:36:05.695: INFO: (6) /api/v1/namespaces/proxy-8623/pods/https:proxy-service-vkvnp-46vrr:462/proxy/: tls qux (200; 5.457929ms)
Oct 30 11:36:05.696: INFO: (6) /api/v1/namespaces/proxy-8623/pods/proxy-service-vkvnp-46vrr/proxy/: <a href="/api/v1/namespaces/proxy-8623/pods/proxy-service-vkvnp-46vrr/proxy/rewriteme">test</a> (200; 6.934242ms)
Oct 30 11:36:05.696: INFO: (6) /api/v1/namespaces/proxy-8623/pods/proxy-service-vkvnp-46vrr:162/proxy/: bar (200; 6.43018ms)
Oct 30 11:36:05.697: INFO: (6) /api/v1/namespaces/proxy-8623/services/http:proxy-service-vkvnp:portname2/proxy/: bar (200; 7.464276ms)
Oct 30 11:36:05.697: INFO: (6) /api/v1/namespaces/proxy-8623/pods/http:proxy-service-vkvnp-46vrr:162/proxy/: bar (200; 7.453162ms)
Oct 30 11:36:05.697: INFO: (6) /api/v1/namespaces/proxy-8623/pods/https:proxy-service-vkvnp-46vrr:443/proxy/: <a href="/api/v1/namespaces/proxy-8623/pods/https:proxy-service-vkvnp-46vrr:443/proxy/tlsrewritem... (200; 7.785877ms)
Oct 30 11:36:05.697: INFO: (6) /api/v1/namespaces/proxy-8623/pods/proxy-service-vkvnp-46vrr:1080/proxy/: <a href="/api/v1/namespaces/proxy-8623/pods/proxy-service-vkvnp-46vrr:1080/proxy/rewriteme">test<... (200; 8.18378ms)
Oct 30 11:36:05.698: INFO: (6) /api/v1/namespaces/proxy-8623/pods/proxy-service-vkvnp-46vrr:160/proxy/: foo (200; 8.270227ms)
Oct 30 11:36:05.698: INFO: (6) /api/v1/namespaces/proxy-8623/services/proxy-service-vkvnp:portname1/proxy/: foo (200; 8.349829ms)
Oct 30 11:36:05.698: INFO: (6) /api/v1/namespaces/proxy-8623/services/http:proxy-service-vkvnp:portname1/proxy/: foo (200; 9.159942ms)
Oct 30 11:36:05.698: INFO: (6) /api/v1/namespaces/proxy-8623/services/https:proxy-service-vkvnp:tlsportname1/proxy/: tls baz (200; 8.438531ms)
Oct 30 11:36:05.698: INFO: (6) /api/v1/namespaces/proxy-8623/services/proxy-service-vkvnp:portname2/proxy/: bar (200; 9.23576ms)
Oct 30 11:36:05.698: INFO: (6) /api/v1/namespaces/proxy-8623/pods/https:proxy-service-vkvnp-46vrr:460/proxy/: tls baz (200; 8.776008ms)
Oct 30 11:36:05.699: INFO: (6) /api/v1/namespaces/proxy-8623/pods/http:proxy-service-vkvnp-46vrr:160/proxy/: foo (200; 9.260819ms)
Oct 30 11:36:05.699: INFO: (6) /api/v1/namespaces/proxy-8623/services/https:proxy-service-vkvnp:tlsportname2/proxy/: tls qux (200; 8.848829ms)
Oct 30 11:36:05.707: INFO: (7) /api/v1/namespaces/proxy-8623/pods/proxy-service-vkvnp-46vrr:162/proxy/: bar (200; 8.321795ms)
Oct 30 11:36:05.708: INFO: (7) /api/v1/namespaces/proxy-8623/services/proxy-service-vkvnp:portname2/proxy/: bar (200; 9.180829ms)
Oct 30 11:36:05.709: INFO: (7) /api/v1/namespaces/proxy-8623/pods/https:proxy-service-vkvnp-46vrr:443/proxy/: <a href="/api/v1/namespaces/proxy-8623/pods/https:proxy-service-vkvnp-46vrr:443/proxy/tlsrewritem... (200; 9.692994ms)
Oct 30 11:36:05.709: INFO: (7) /api/v1/namespaces/proxy-8623/pods/http:proxy-service-vkvnp-46vrr:162/proxy/: bar (200; 10.050475ms)
Oct 30 11:36:05.709: INFO: (7) /api/v1/namespaces/proxy-8623/pods/proxy-service-vkvnp-46vrr/proxy/: <a href="/api/v1/namespaces/proxy-8623/pods/proxy-service-vkvnp-46vrr/proxy/rewriteme">test</a> (200; 10.372926ms)
Oct 30 11:36:05.709: INFO: (7) /api/v1/namespaces/proxy-8623/pods/proxy-service-vkvnp-46vrr:160/proxy/: foo (200; 10.130941ms)
Oct 30 11:36:05.709: INFO: (7) /api/v1/namespaces/proxy-8623/pods/http:proxy-service-vkvnp-46vrr:1080/proxy/: <a href="/api/v1/namespaces/proxy-8623/pods/http:proxy-service-vkvnp-46vrr:1080/proxy/rewriteme">... (200; 10.585653ms)
Oct 30 11:36:05.709: INFO: (7) /api/v1/namespaces/proxy-8623/pods/https:proxy-service-vkvnp-46vrr:460/proxy/: tls baz (200; 10.410919ms)
Oct 30 11:36:05.709: INFO: (7) /api/v1/namespaces/proxy-8623/pods/proxy-service-vkvnp-46vrr:1080/proxy/: <a href="/api/v1/namespaces/proxy-8623/pods/proxy-service-vkvnp-46vrr:1080/proxy/rewriteme">test<... (200; 10.603628ms)
Oct 30 11:36:05.709: INFO: (7) /api/v1/namespaces/proxy-8623/services/https:proxy-service-vkvnp:tlsportname2/proxy/: tls qux (200; 10.799466ms)
Oct 30 11:36:05.709: INFO: (7) /api/v1/namespaces/proxy-8623/pods/https:proxy-service-vkvnp-46vrr:462/proxy/: tls qux (200; 10.650671ms)
Oct 30 11:36:05.710: INFO: (7) /api/v1/namespaces/proxy-8623/pods/http:proxy-service-vkvnp-46vrr:160/proxy/: foo (200; 10.936058ms)
Oct 30 11:36:05.712: INFO: (7) /api/v1/namespaces/proxy-8623/services/http:proxy-service-vkvnp:portname2/proxy/: bar (200; 13.118892ms)
Oct 30 11:36:05.712: INFO: (7) /api/v1/namespaces/proxy-8623/services/http:proxy-service-vkvnp:portname1/proxy/: foo (200; 13.063156ms)
Oct 30 11:36:05.712: INFO: (7) /api/v1/namespaces/proxy-8623/services/https:proxy-service-vkvnp:tlsportname1/proxy/: tls baz (200; 13.030187ms)
Oct 30 11:36:05.712: INFO: (7) /api/v1/namespaces/proxy-8623/services/proxy-service-vkvnp:portname1/proxy/: foo (200; 13.442922ms)
Oct 30 11:36:05.719: INFO: (8) /api/v1/namespaces/proxy-8623/services/https:proxy-service-vkvnp:tlsportname2/proxy/: tls qux (200; 6.933363ms)
Oct 30 11:36:05.720: INFO: (8) /api/v1/namespaces/proxy-8623/services/http:proxy-service-vkvnp:portname2/proxy/: bar (200; 7.479716ms)
Oct 30 11:36:05.721: INFO: (8) /api/v1/namespaces/proxy-8623/services/proxy-service-vkvnp:portname2/proxy/: bar (200; 9.046968ms)
Oct 30 11:36:05.721: INFO: (8) /api/v1/namespaces/proxy-8623/services/http:proxy-service-vkvnp:portname1/proxy/: foo (200; 8.653358ms)
Oct 30 11:36:05.721: INFO: (8) /api/v1/namespaces/proxy-8623/pods/proxy-service-vkvnp-46vrr:160/proxy/: foo (200; 9.034434ms)
Oct 30 11:36:05.722: INFO: (8) /api/v1/namespaces/proxy-8623/services/proxy-service-vkvnp:portname1/proxy/: foo (200; 9.095857ms)
Oct 30 11:36:05.722: INFO: (8) /api/v1/namespaces/proxy-8623/pods/proxy-service-vkvnp-46vrr:1080/proxy/: <a href="/api/v1/namespaces/proxy-8623/pods/proxy-service-vkvnp-46vrr:1080/proxy/rewriteme">test<... (200; 10.000741ms)
Oct 30 11:36:05.723: INFO: (8) /api/v1/namespaces/proxy-8623/pods/https:proxy-service-vkvnp-46vrr:460/proxy/: tls baz (200; 10.941978ms)
Oct 30 11:36:05.723: INFO: (8) /api/v1/namespaces/proxy-8623/services/https:proxy-service-vkvnp:tlsportname1/proxy/: tls baz (200; 10.524701ms)
Oct 30 11:36:05.723: INFO: (8) /api/v1/namespaces/proxy-8623/pods/proxy-service-vkvnp-46vrr:162/proxy/: bar (200; 10.80092ms)
Oct 30 11:36:05.724: INFO: (8) /api/v1/namespaces/proxy-8623/pods/http:proxy-service-vkvnp-46vrr:1080/proxy/: <a href="/api/v1/namespaces/proxy-8623/pods/http:proxy-service-vkvnp-46vrr:1080/proxy/rewriteme">... (200; 11.186984ms)
Oct 30 11:36:05.724: INFO: (8) /api/v1/namespaces/proxy-8623/pods/https:proxy-service-vkvnp-46vrr:443/proxy/: <a href="/api/v1/namespaces/proxy-8623/pods/https:proxy-service-vkvnp-46vrr:443/proxy/tlsrewritem... (200; 11.544894ms)
Oct 30 11:36:05.724: INFO: (8) /api/v1/namespaces/proxy-8623/pods/http:proxy-service-vkvnp-46vrr:160/proxy/: foo (200; 11.828755ms)
Oct 30 11:36:05.724: INFO: (8) /api/v1/namespaces/proxy-8623/pods/proxy-service-vkvnp-46vrr/proxy/: <a href="/api/v1/namespaces/proxy-8623/pods/proxy-service-vkvnp-46vrr/proxy/rewriteme">test</a> (200; 11.585756ms)
Oct 30 11:36:05.724: INFO: (8) /api/v1/namespaces/proxy-8623/pods/http:proxy-service-vkvnp-46vrr:162/proxy/: bar (200; 11.903059ms)
Oct 30 11:36:05.725: INFO: (8) /api/v1/namespaces/proxy-8623/pods/https:proxy-service-vkvnp-46vrr:462/proxy/: tls qux (200; 11.895845ms)
Oct 30 11:36:05.729: INFO: (9) /api/v1/namespaces/proxy-8623/pods/http:proxy-service-vkvnp-46vrr:160/proxy/: foo (200; 4.294276ms)
Oct 30 11:36:05.730: INFO: (9) /api/v1/namespaces/proxy-8623/pods/proxy-service-vkvnp-46vrr:160/proxy/: foo (200; 5.609142ms)
Oct 30 11:36:05.730: INFO: (9) /api/v1/namespaces/proxy-8623/pods/https:proxy-service-vkvnp-46vrr:460/proxy/: tls baz (200; 5.483442ms)
Oct 30 11:36:05.731: INFO: (9) /api/v1/namespaces/proxy-8623/pods/https:proxy-service-vkvnp-46vrr:443/proxy/: <a href="/api/v1/namespaces/proxy-8623/pods/https:proxy-service-vkvnp-46vrr:443/proxy/tlsrewritem... (200; 5.980218ms)
Oct 30 11:36:05.731: INFO: (9) /api/v1/namespaces/proxy-8623/pods/proxy-service-vkvnp-46vrr/proxy/: <a href="/api/v1/namespaces/proxy-8623/pods/proxy-service-vkvnp-46vrr/proxy/rewriteme">test</a> (200; 6.666696ms)
Oct 30 11:36:05.732: INFO: (9) /api/v1/namespaces/proxy-8623/pods/http:proxy-service-vkvnp-46vrr:162/proxy/: bar (200; 7.154772ms)
Oct 30 11:36:05.732: INFO: (9) /api/v1/namespaces/proxy-8623/services/proxy-service-vkvnp:portname1/proxy/: foo (200; 7.306409ms)
Oct 30 11:36:05.732: INFO: (9) /api/v1/namespaces/proxy-8623/pods/http:proxy-service-vkvnp-46vrr:1080/proxy/: <a href="/api/v1/namespaces/proxy-8623/pods/http:proxy-service-vkvnp-46vrr:1080/proxy/rewriteme">... (200; 7.782677ms)
Oct 30 11:36:05.732: INFO: (9) /api/v1/namespaces/proxy-8623/services/http:proxy-service-vkvnp:portname1/proxy/: foo (200; 7.519064ms)
Oct 30 11:36:05.733: INFO: (9) /api/v1/namespaces/proxy-8623/pods/https:proxy-service-vkvnp-46vrr:462/proxy/: tls qux (200; 7.644761ms)
Oct 30 11:36:05.733: INFO: (9) /api/v1/namespaces/proxy-8623/services/proxy-service-vkvnp:portname2/proxy/: bar (200; 7.941799ms)
Oct 30 11:36:05.733: INFO: (9) /api/v1/namespaces/proxy-8623/pods/proxy-service-vkvnp-46vrr:1080/proxy/: <a href="/api/v1/namespaces/proxy-8623/pods/proxy-service-vkvnp-46vrr:1080/proxy/rewriteme">test<... (200; 8.080354ms)
Oct 30 11:36:05.733: INFO: (9) /api/v1/namespaces/proxy-8623/services/https:proxy-service-vkvnp:tlsportname2/proxy/: tls qux (200; 8.743144ms)
Oct 30 11:36:05.733: INFO: (9) /api/v1/namespaces/proxy-8623/pods/proxy-service-vkvnp-46vrr:162/proxy/: bar (200; 8.580937ms)
Oct 30 11:36:05.733: INFO: (9) /api/v1/namespaces/proxy-8623/services/https:proxy-service-vkvnp:tlsportname1/proxy/: tls baz (200; 8.663901ms)
Oct 30 11:36:05.734: INFO: (9) /api/v1/namespaces/proxy-8623/services/http:proxy-service-vkvnp:portname2/proxy/: bar (200; 8.596128ms)
Oct 30 11:36:05.740: INFO: (10) /api/v1/namespaces/proxy-8623/pods/proxy-service-vkvnp-46vrr:162/proxy/: bar (200; 6.138372ms)
Oct 30 11:36:05.740: INFO: (10) /api/v1/namespaces/proxy-8623/pods/https:proxy-service-vkvnp-46vrr:443/proxy/: <a href="/api/v1/namespaces/proxy-8623/pods/https:proxy-service-vkvnp-46vrr:443/proxy/tlsrewritem... (200; 6.06068ms)
Oct 30 11:36:05.741: INFO: (10) /api/v1/namespaces/proxy-8623/pods/proxy-service-vkvnp-46vrr:160/proxy/: foo (200; 6.669126ms)
Oct 30 11:36:05.741: INFO: (10) /api/v1/namespaces/proxy-8623/pods/https:proxy-service-vkvnp-46vrr:460/proxy/: tls baz (200; 6.524955ms)
Oct 30 11:36:05.742: INFO: (10) /api/v1/namespaces/proxy-8623/pods/http:proxy-service-vkvnp-46vrr:160/proxy/: foo (200; 7.696805ms)
Oct 30 11:36:05.742: INFO: (10) /api/v1/namespaces/proxy-8623/pods/proxy-service-vkvnp-46vrr:1080/proxy/: <a href="/api/v1/namespaces/proxy-8623/pods/proxy-service-vkvnp-46vrr:1080/proxy/rewriteme">test<... (200; 8.139147ms)
Oct 30 11:36:05.742: INFO: (10) /api/v1/namespaces/proxy-8623/pods/http:proxy-service-vkvnp-46vrr:162/proxy/: bar (200; 8.059825ms)
Oct 30 11:36:05.743: INFO: (10) /api/v1/namespaces/proxy-8623/pods/https:proxy-service-vkvnp-46vrr:462/proxy/: tls qux (200; 8.861941ms)
Oct 30 11:36:05.743: INFO: (10) /api/v1/namespaces/proxy-8623/services/proxy-service-vkvnp:portname2/proxy/: bar (200; 8.76233ms)
Oct 30 11:36:05.743: INFO: (10) /api/v1/namespaces/proxy-8623/services/http:proxy-service-vkvnp:portname1/proxy/: foo (200; 9.462384ms)
Oct 30 11:36:05.743: INFO: (10) /api/v1/namespaces/proxy-8623/pods/proxy-service-vkvnp-46vrr/proxy/: <a href="/api/v1/namespaces/proxy-8623/pods/proxy-service-vkvnp-46vrr/proxy/rewriteme">test</a> (200; 9.757205ms)
Oct 30 11:36:05.744: INFO: (10) /api/v1/namespaces/proxy-8623/pods/http:proxy-service-vkvnp-46vrr:1080/proxy/: <a href="/api/v1/namespaces/proxy-8623/pods/http:proxy-service-vkvnp-46vrr:1080/proxy/rewriteme">... (200; 9.485913ms)
Oct 30 11:36:05.744: INFO: (10) /api/v1/namespaces/proxy-8623/services/https:proxy-service-vkvnp:tlsportname1/proxy/: tls baz (200; 9.658459ms)
Oct 30 11:36:05.744: INFO: (10) /api/v1/namespaces/proxy-8623/services/proxy-service-vkvnp:portname1/proxy/: foo (200; 10.245068ms)
Oct 30 11:36:05.744: INFO: (10) /api/v1/namespaces/proxy-8623/services/http:proxy-service-vkvnp:portname2/proxy/: bar (200; 10.086801ms)
Oct 30 11:36:05.744: INFO: (10) /api/v1/namespaces/proxy-8623/services/https:proxy-service-vkvnp:tlsportname2/proxy/: tls qux (200; 10.298618ms)
Oct 30 11:36:05.748: INFO: (11) /api/v1/namespaces/proxy-8623/pods/https:proxy-service-vkvnp-46vrr:443/proxy/: <a href="/api/v1/namespaces/proxy-8623/pods/https:proxy-service-vkvnp-46vrr:443/proxy/tlsrewritem... (200; 3.508154ms)
Oct 30 11:36:05.749: INFO: (11) /api/v1/namespaces/proxy-8623/pods/http:proxy-service-vkvnp-46vrr:160/proxy/: foo (200; 4.182894ms)
Oct 30 11:36:05.749: INFO: (11) /api/v1/namespaces/proxy-8623/pods/proxy-service-vkvnp-46vrr/proxy/: <a href="/api/v1/namespaces/proxy-8623/pods/proxy-service-vkvnp-46vrr/proxy/rewriteme">test</a> (200; 4.670297ms)
Oct 30 11:36:05.749: INFO: (11) /api/v1/namespaces/proxy-8623/pods/http:proxy-service-vkvnp-46vrr:1080/proxy/: <a href="/api/v1/namespaces/proxy-8623/pods/http:proxy-service-vkvnp-46vrr:1080/proxy/rewriteme">... (200; 4.842881ms)
Oct 30 11:36:05.750: INFO: (11) /api/v1/namespaces/proxy-8623/pods/https:proxy-service-vkvnp-46vrr:462/proxy/: tls qux (200; 4.689257ms)
Oct 30 11:36:05.750: INFO: (11) /api/v1/namespaces/proxy-8623/pods/proxy-service-vkvnp-46vrr:1080/proxy/: <a href="/api/v1/namespaces/proxy-8623/pods/proxy-service-vkvnp-46vrr:1080/proxy/rewriteme">test<... (200; 4.750984ms)
Oct 30 11:36:05.751: INFO: (11) /api/v1/namespaces/proxy-8623/pods/proxy-service-vkvnp-46vrr:162/proxy/: bar (200; 6.419629ms)
Oct 30 11:36:05.751: INFO: (11) /api/v1/namespaces/proxy-8623/pods/https:proxy-service-vkvnp-46vrr:460/proxy/: tls baz (200; 5.637032ms)
Oct 30 11:36:05.752: INFO: (11) /api/v1/namespaces/proxy-8623/pods/http:proxy-service-vkvnp-46vrr:162/proxy/: bar (200; 5.422892ms)
Oct 30 11:36:05.752: INFO: (11) /api/v1/namespaces/proxy-8623/pods/proxy-service-vkvnp-46vrr:160/proxy/: foo (200; 5.615751ms)
Oct 30 11:36:05.755: INFO: (11) /api/v1/namespaces/proxy-8623/services/http:proxy-service-vkvnp:portname2/proxy/: bar (200; 9.346647ms)
Oct 30 11:36:05.755: INFO: (11) /api/v1/namespaces/proxy-8623/services/proxy-service-vkvnp:portname2/proxy/: bar (200; 9.559361ms)
Oct 30 11:36:05.755: INFO: (11) /api/v1/namespaces/proxy-8623/services/https:proxy-service-vkvnp:tlsportname2/proxy/: tls qux (200; 9.270662ms)
Oct 30 11:36:05.755: INFO: (11) /api/v1/namespaces/proxy-8623/services/http:proxy-service-vkvnp:portname1/proxy/: foo (200; 9.790552ms)
Oct 30 11:36:05.755: INFO: (11) /api/v1/namespaces/proxy-8623/services/proxy-service-vkvnp:portname1/proxy/: foo (200; 10.038487ms)
Oct 30 11:36:05.756: INFO: (11) /api/v1/namespaces/proxy-8623/services/https:proxy-service-vkvnp:tlsportname1/proxy/: tls baz (200; 11.321989ms)
Oct 30 11:36:05.759: INFO: (12) /api/v1/namespaces/proxy-8623/pods/proxy-service-vkvnp-46vrr:162/proxy/: bar (200; 3.412668ms)
Oct 30 11:36:05.762: INFO: (12) /api/v1/namespaces/proxy-8623/pods/https:proxy-service-vkvnp-46vrr:443/proxy/: <a href="/api/v1/namespaces/proxy-8623/pods/https:proxy-service-vkvnp-46vrr:443/proxy/tlsrewritem... (200; 6.468701ms)
Oct 30 11:36:05.762: INFO: (12) /api/v1/namespaces/proxy-8623/pods/https:proxy-service-vkvnp-46vrr:460/proxy/: tls baz (200; 6.276813ms)
Oct 30 11:36:05.763: INFO: (12) /api/v1/namespaces/proxy-8623/pods/http:proxy-service-vkvnp-46vrr:162/proxy/: bar (200; 6.351125ms)
Oct 30 11:36:05.764: INFO: (12) /api/v1/namespaces/proxy-8623/pods/proxy-service-vkvnp-46vrr:1080/proxy/: <a href="/api/v1/namespaces/proxy-8623/pods/proxy-service-vkvnp-46vrr:1080/proxy/rewriteme">test<... (200; 8.025125ms)
Oct 30 11:36:05.764: INFO: (12) /api/v1/namespaces/proxy-8623/services/http:proxy-service-vkvnp:portname2/proxy/: bar (200; 8.283751ms)
Oct 30 11:36:05.764: INFO: (12) /api/v1/namespaces/proxy-8623/services/http:proxy-service-vkvnp:portname1/proxy/: foo (200; 8.250005ms)
Oct 30 11:36:05.764: INFO: (12) /api/v1/namespaces/proxy-8623/services/proxy-service-vkvnp:portname2/proxy/: bar (200; 8.420146ms)
Oct 30 11:36:05.764: INFO: (12) /api/v1/namespaces/proxy-8623/pods/https:proxy-service-vkvnp-46vrr:462/proxy/: tls qux (200; 8.115114ms)
Oct 30 11:36:05.765: INFO: (12) /api/v1/namespaces/proxy-8623/pods/proxy-service-vkvnp-46vrr/proxy/: <a href="/api/v1/namespaces/proxy-8623/pods/proxy-service-vkvnp-46vrr/proxy/rewriteme">test</a> (200; 8.369898ms)
Oct 30 11:36:05.765: INFO: (12) /api/v1/namespaces/proxy-8623/pods/http:proxy-service-vkvnp-46vrr:160/proxy/: foo (200; 8.73648ms)
Oct 30 11:36:05.765: INFO: (12) /api/v1/namespaces/proxy-8623/pods/proxy-service-vkvnp-46vrr:160/proxy/: foo (200; 8.933635ms)
Oct 30 11:36:05.766: INFO: (12) /api/v1/namespaces/proxy-8623/services/https:proxy-service-vkvnp:tlsportname1/proxy/: tls baz (200; 9.525974ms)
Oct 30 11:36:05.766: INFO: (12) /api/v1/namespaces/proxy-8623/services/proxy-service-vkvnp:portname1/proxy/: foo (200; 9.733845ms)
Oct 30 11:36:05.766: INFO: (12) /api/v1/namespaces/proxy-8623/services/https:proxy-service-vkvnp:tlsportname2/proxy/: tls qux (200; 9.638952ms)
Oct 30 11:36:05.766: INFO: (12) /api/v1/namespaces/proxy-8623/pods/http:proxy-service-vkvnp-46vrr:1080/proxy/: <a href="/api/v1/namespaces/proxy-8623/pods/http:proxy-service-vkvnp-46vrr:1080/proxy/rewriteme">... (200; 9.74046ms)
Oct 30 11:36:05.772: INFO: (13) /api/v1/namespaces/proxy-8623/pods/proxy-service-vkvnp-46vrr:162/proxy/: bar (200; 5.712236ms)
Oct 30 11:36:05.772: INFO: (13) /api/v1/namespaces/proxy-8623/services/https:proxy-service-vkvnp:tlsportname2/proxy/: tls qux (200; 6.082646ms)
Oct 30 11:36:05.772: INFO: (13) /api/v1/namespaces/proxy-8623/pods/proxy-service-vkvnp-46vrr/proxy/: <a href="/api/v1/namespaces/proxy-8623/pods/proxy-service-vkvnp-46vrr/proxy/rewriteme">test</a> (200; 5.816474ms)
Oct 30 11:36:05.772: INFO: (13) /api/v1/namespaces/proxy-8623/pods/https:proxy-service-vkvnp-46vrr:462/proxy/: tls qux (200; 5.979165ms)
Oct 30 11:36:05.773: INFO: (13) /api/v1/namespaces/proxy-8623/pods/http:proxy-service-vkvnp-46vrr:162/proxy/: bar (200; 6.392808ms)
Oct 30 11:36:05.773: INFO: (13) /api/v1/namespaces/proxy-8623/pods/https:proxy-service-vkvnp-46vrr:460/proxy/: tls baz (200; 6.572092ms)
Oct 30 11:36:05.773: INFO: (13) /api/v1/namespaces/proxy-8623/pods/http:proxy-service-vkvnp-46vrr:160/proxy/: foo (200; 6.678914ms)
Oct 30 11:36:05.773: INFO: (13) /api/v1/namespaces/proxy-8623/pods/http:proxy-service-vkvnp-46vrr:1080/proxy/: <a href="/api/v1/namespaces/proxy-8623/pods/http:proxy-service-vkvnp-46vrr:1080/proxy/rewriteme">... (200; 6.867675ms)
Oct 30 11:36:05.773: INFO: (13) /api/v1/namespaces/proxy-8623/pods/proxy-service-vkvnp-46vrr:160/proxy/: foo (200; 6.671731ms)
Oct 30 11:36:05.773: INFO: (13) /api/v1/namespaces/proxy-8623/pods/proxy-service-vkvnp-46vrr:1080/proxy/: <a href="/api/v1/namespaces/proxy-8623/pods/proxy-service-vkvnp-46vrr:1080/proxy/rewriteme">test<... (200; 6.317609ms)
Oct 30 11:36:05.773: INFO: (13) /api/v1/namespaces/proxy-8623/pods/https:proxy-service-vkvnp-46vrr:443/proxy/: <a href="/api/v1/namespaces/proxy-8623/pods/https:proxy-service-vkvnp-46vrr:443/proxy/tlsrewritem... (200; 6.950897ms)
Oct 30 11:36:05.775: INFO: (13) /api/v1/namespaces/proxy-8623/services/proxy-service-vkvnp:portname1/proxy/: foo (200; 8.428589ms)
Oct 30 11:36:05.775: INFO: (13) /api/v1/namespaces/proxy-8623/services/http:proxy-service-vkvnp:portname2/proxy/: bar (200; 8.276171ms)
Oct 30 11:36:05.775: INFO: (13) /api/v1/namespaces/proxy-8623/services/http:proxy-service-vkvnp:portname1/proxy/: foo (200; 8.69235ms)
Oct 30 11:36:05.775: INFO: (13) /api/v1/namespaces/proxy-8623/services/proxy-service-vkvnp:portname2/proxy/: bar (200; 8.715734ms)
Oct 30 11:36:05.775: INFO: (13) /api/v1/namespaces/proxy-8623/services/https:proxy-service-vkvnp:tlsportname1/proxy/: tls baz (200; 8.832139ms)
Oct 30 11:36:05.781: INFO: (14) /api/v1/namespaces/proxy-8623/pods/https:proxy-service-vkvnp-46vrr:462/proxy/: tls qux (200; 5.569928ms)
Oct 30 11:36:05.782: INFO: (14) /api/v1/namespaces/proxy-8623/pods/proxy-service-vkvnp-46vrr:162/proxy/: bar (200; 6.127704ms)
Oct 30 11:36:05.783: INFO: (14) /api/v1/namespaces/proxy-8623/pods/http:proxy-service-vkvnp-46vrr:1080/proxy/: <a href="/api/v1/namespaces/proxy-8623/pods/http:proxy-service-vkvnp-46vrr:1080/proxy/rewriteme">... (200; 7.12015ms)
Oct 30 11:36:05.783: INFO: (14) /api/v1/namespaces/proxy-8623/pods/http:proxy-service-vkvnp-46vrr:162/proxy/: bar (200; 7.326362ms)
Oct 30 11:36:05.783: INFO: (14) /api/v1/namespaces/proxy-8623/pods/https:proxy-service-vkvnp-46vrr:460/proxy/: tls baz (200; 7.480884ms)
Oct 30 11:36:05.783: INFO: (14) /api/v1/namespaces/proxy-8623/pods/https:proxy-service-vkvnp-46vrr:443/proxy/: <a href="/api/v1/namespaces/proxy-8623/pods/https:proxy-service-vkvnp-46vrr:443/proxy/tlsrewritem... (200; 7.369453ms)
Oct 30 11:36:05.783: INFO: (14) /api/v1/namespaces/proxy-8623/pods/http:proxy-service-vkvnp-46vrr:160/proxy/: foo (200; 7.477451ms)
Oct 30 11:36:05.783: INFO: (14) /api/v1/namespaces/proxy-8623/services/https:proxy-service-vkvnp:tlsportname2/proxy/: tls qux (200; 8.134287ms)
Oct 30 11:36:05.783: INFO: (14) /api/v1/namespaces/proxy-8623/pods/proxy-service-vkvnp-46vrr:1080/proxy/: <a href="/api/v1/namespaces/proxy-8623/pods/proxy-service-vkvnp-46vrr:1080/proxy/rewriteme">test<... (200; 7.914776ms)
Oct 30 11:36:05.784: INFO: (14) /api/v1/namespaces/proxy-8623/services/http:proxy-service-vkvnp:portname2/proxy/: bar (200; 8.246421ms)
Oct 30 11:36:05.789: INFO: (14) /api/v1/namespaces/proxy-8623/pods/proxy-service-vkvnp-46vrr:160/proxy/: foo (200; 13.943931ms)
Oct 30 11:36:05.789: INFO: (14) /api/v1/namespaces/proxy-8623/services/http:proxy-service-vkvnp:portname1/proxy/: foo (200; 13.9494ms)
Oct 30 11:36:05.789: INFO: (14) /api/v1/namespaces/proxy-8623/services/https:proxy-service-vkvnp:tlsportname1/proxy/: tls baz (200; 13.863798ms)
Oct 30 11:36:05.789: INFO: (14) /api/v1/namespaces/proxy-8623/services/proxy-service-vkvnp:portname2/proxy/: bar (200; 13.91849ms)
Oct 30 11:36:05.789: INFO: (14) /api/v1/namespaces/proxy-8623/services/proxy-service-vkvnp:portname1/proxy/: foo (200; 13.996772ms)
Oct 30 11:36:05.790: INFO: (14) /api/v1/namespaces/proxy-8623/pods/proxy-service-vkvnp-46vrr/proxy/: <a href="/api/v1/namespaces/proxy-8623/pods/proxy-service-vkvnp-46vrr/proxy/rewriteme">test</a> (200; 13.955504ms)
Oct 30 11:36:05.793: INFO: (15) /api/v1/namespaces/proxy-8623/pods/https:proxy-service-vkvnp-46vrr:460/proxy/: tls baz (200; 3.091601ms)
Oct 30 11:36:05.793: INFO: (15) /api/v1/namespaces/proxy-8623/pods/http:proxy-service-vkvnp-46vrr:1080/proxy/: <a href="/api/v1/namespaces/proxy-8623/pods/http:proxy-service-vkvnp-46vrr:1080/proxy/rewriteme">... (200; 3.131749ms)
Oct 30 11:36:05.795: INFO: (15) /api/v1/namespaces/proxy-8623/pods/proxy-service-vkvnp-46vrr/proxy/: <a href="/api/v1/namespaces/proxy-8623/pods/proxy-service-vkvnp-46vrr/proxy/rewriteme">test</a> (200; 4.701963ms)
Oct 30 11:36:05.796: INFO: (15) /api/v1/namespaces/proxy-8623/pods/proxy-service-vkvnp-46vrr:162/proxy/: bar (200; 5.436928ms)
Oct 30 11:36:05.796: INFO: (15) /api/v1/namespaces/proxy-8623/pods/proxy-service-vkvnp-46vrr:160/proxy/: foo (200; 5.64602ms)
Oct 30 11:36:05.797: INFO: (15) /api/v1/namespaces/proxy-8623/pods/http:proxy-service-vkvnp-46vrr:162/proxy/: bar (200; 5.816488ms)
Oct 30 11:36:05.797: INFO: (15) /api/v1/namespaces/proxy-8623/pods/https:proxy-service-vkvnp-46vrr:443/proxy/: <a href="/api/v1/namespaces/proxy-8623/pods/https:proxy-service-vkvnp-46vrr:443/proxy/tlsrewritem... (200; 5.925658ms)
Oct 30 11:36:05.797: INFO: (15) /api/v1/namespaces/proxy-8623/pods/proxy-service-vkvnp-46vrr:1080/proxy/: <a href="/api/v1/namespaces/proxy-8623/pods/proxy-service-vkvnp-46vrr:1080/proxy/rewriteme">test<... (200; 6.267288ms)
Oct 30 11:36:05.797: INFO: (15) /api/v1/namespaces/proxy-8623/services/https:proxy-service-vkvnp:tlsportname1/proxy/: tls baz (200; 7.262329ms)
Oct 30 11:36:05.797: INFO: (15) /api/v1/namespaces/proxy-8623/pods/http:proxy-service-vkvnp-46vrr:160/proxy/: foo (200; 6.632473ms)
Oct 30 11:36:05.800: INFO: (15) /api/v1/namespaces/proxy-8623/services/http:proxy-service-vkvnp:portname2/proxy/: bar (200; 8.973533ms)
Oct 30 11:36:05.800: INFO: (15) /api/v1/namespaces/proxy-8623/services/proxy-service-vkvnp:portname1/proxy/: foo (200; 9.092579ms)
Oct 30 11:36:05.800: INFO: (15) /api/v1/namespaces/proxy-8623/pods/https:proxy-service-vkvnp-46vrr:462/proxy/: tls qux (200; 9.517989ms)
Oct 30 11:36:05.800: INFO: (15) /api/v1/namespaces/proxy-8623/services/proxy-service-vkvnp:portname2/proxy/: bar (200; 9.387001ms)
Oct 30 11:36:05.800: INFO: (15) /api/v1/namespaces/proxy-8623/services/https:proxy-service-vkvnp:tlsportname2/proxy/: tls qux (200; 9.619082ms)
Oct 30 11:36:05.801: INFO: (15) /api/v1/namespaces/proxy-8623/services/http:proxy-service-vkvnp:portname1/proxy/: foo (200; 9.885351ms)
Oct 30 11:36:05.808: INFO: (16) /api/v1/namespaces/proxy-8623/pods/proxy-service-vkvnp-46vrr:160/proxy/: foo (200; 6.78591ms)
Oct 30 11:36:05.809: INFO: (16) /api/v1/namespaces/proxy-8623/pods/https:proxy-service-vkvnp-46vrr:460/proxy/: tls baz (200; 8.168741ms)
Oct 30 11:36:05.809: INFO: (16) /api/v1/namespaces/proxy-8623/pods/http:proxy-service-vkvnp-46vrr:1080/proxy/: <a href="/api/v1/namespaces/proxy-8623/pods/http:proxy-service-vkvnp-46vrr:1080/proxy/rewriteme">... (200; 7.53371ms)
Oct 30 11:36:05.809: INFO: (16) /api/v1/namespaces/proxy-8623/pods/https:proxy-service-vkvnp-46vrr:443/proxy/: <a href="/api/v1/namespaces/proxy-8623/pods/https:proxy-service-vkvnp-46vrr:443/proxy/tlsrewritem... (200; 8.383897ms)
Oct 30 11:36:05.810: INFO: (16) /api/v1/namespaces/proxy-8623/pods/proxy-service-vkvnp-46vrr/proxy/: <a href="/api/v1/namespaces/proxy-8623/pods/proxy-service-vkvnp-46vrr/proxy/rewriteme">test</a> (200; 8.740299ms)
Oct 30 11:36:05.810: INFO: (16) /api/v1/namespaces/proxy-8623/pods/http:proxy-service-vkvnp-46vrr:162/proxy/: bar (200; 9.076534ms)
Oct 30 11:36:05.811: INFO: (16) /api/v1/namespaces/proxy-8623/pods/https:proxy-service-vkvnp-46vrr:462/proxy/: tls qux (200; 8.560128ms)
Oct 30 11:36:05.811: INFO: (16) /api/v1/namespaces/proxy-8623/pods/proxy-service-vkvnp-46vrr:162/proxy/: bar (200; 9.962424ms)
Oct 30 11:36:05.812: INFO: (16) /api/v1/namespaces/proxy-8623/pods/proxy-service-vkvnp-46vrr:1080/proxy/: <a href="/api/v1/namespaces/proxy-8623/pods/proxy-service-vkvnp-46vrr:1080/proxy/rewriteme">test<... (200; 9.944597ms)
Oct 30 11:36:05.812: INFO: (16) /api/v1/namespaces/proxy-8623/pods/http:proxy-service-vkvnp-46vrr:160/proxy/: foo (200; 9.821097ms)
Oct 30 11:36:05.818: INFO: (16) /api/v1/namespaces/proxy-8623/services/http:proxy-service-vkvnp:portname2/proxy/: bar (200; 16.863254ms)
Oct 30 11:36:05.819: INFO: (16) /api/v1/namespaces/proxy-8623/services/proxy-service-vkvnp:portname1/proxy/: foo (200; 16.757642ms)
Oct 30 11:36:05.819: INFO: (16) /api/v1/namespaces/proxy-8623/services/https:proxy-service-vkvnp:tlsportname2/proxy/: tls qux (200; 17.440078ms)
Oct 30 11:36:05.819: INFO: (16) /api/v1/namespaces/proxy-8623/services/proxy-service-vkvnp:portname2/proxy/: bar (200; 17.72539ms)
Oct 30 11:36:05.819: INFO: (16) /api/v1/namespaces/proxy-8623/services/http:proxy-service-vkvnp:portname1/proxy/: foo (200; 18.377288ms)
Oct 30 11:36:05.821: INFO: (16) /api/v1/namespaces/proxy-8623/services/https:proxy-service-vkvnp:tlsportname1/proxy/: tls baz (200; 19.547293ms)
Oct 30 11:36:05.828: INFO: (17) /api/v1/namespaces/proxy-8623/pods/http:proxy-service-vkvnp-46vrr:1080/proxy/: <a href="/api/v1/namespaces/proxy-8623/pods/http:proxy-service-vkvnp-46vrr:1080/proxy/rewriteme">... (200; 6.518513ms)
Oct 30 11:36:05.829: INFO: (17) /api/v1/namespaces/proxy-8623/pods/https:proxy-service-vkvnp-46vrr:460/proxy/: tls baz (200; 6.957789ms)
Oct 30 11:36:05.829: INFO: (17) /api/v1/namespaces/proxy-8623/pods/proxy-service-vkvnp-46vrr:160/proxy/: foo (200; 7.452175ms)
Oct 30 11:36:05.829: INFO: (17) /api/v1/namespaces/proxy-8623/pods/proxy-service-vkvnp-46vrr:162/proxy/: bar (200; 7.336777ms)
Oct 30 11:36:05.829: INFO: (17) /api/v1/namespaces/proxy-8623/pods/https:proxy-service-vkvnp-46vrr:462/proxy/: tls qux (200; 7.865749ms)
Oct 30 11:36:05.829: INFO: (17) /api/v1/namespaces/proxy-8623/pods/http:proxy-service-vkvnp-46vrr:160/proxy/: foo (200; 7.515845ms)
Oct 30 11:36:05.830: INFO: (17) /api/v1/namespaces/proxy-8623/pods/proxy-service-vkvnp-46vrr/proxy/: <a href="/api/v1/namespaces/proxy-8623/pods/proxy-service-vkvnp-46vrr/proxy/rewriteme">test</a> (200; 8.079137ms)
Oct 30 11:36:05.830: INFO: (17) /api/v1/namespaces/proxy-8623/pods/http:proxy-service-vkvnp-46vrr:162/proxy/: bar (200; 8.281176ms)
Oct 30 11:36:05.830: INFO: (17) /api/v1/namespaces/proxy-8623/pods/proxy-service-vkvnp-46vrr:1080/proxy/: <a href="/api/v1/namespaces/proxy-8623/pods/proxy-service-vkvnp-46vrr:1080/proxy/rewriteme">test<... (200; 8.092353ms)
Oct 30 11:36:05.830: INFO: (17) /api/v1/namespaces/proxy-8623/pods/https:proxy-service-vkvnp-46vrr:443/proxy/: <a href="/api/v1/namespaces/proxy-8623/pods/https:proxy-service-vkvnp-46vrr:443/proxy/tlsrewritem... (200; 8.576532ms)
Oct 30 11:36:05.832: INFO: (17) /api/v1/namespaces/proxy-8623/services/https:proxy-service-vkvnp:tlsportname1/proxy/: tls baz (200; 10.709954ms)
Oct 30 11:36:05.833: INFO: (17) /api/v1/namespaces/proxy-8623/services/http:proxy-service-vkvnp:portname1/proxy/: foo (200; 11.169648ms)
Oct 30 11:36:05.833: INFO: (17) /api/v1/namespaces/proxy-8623/services/proxy-service-vkvnp:portname1/proxy/: foo (200; 10.7697ms)
Oct 30 11:36:05.833: INFO: (17) /api/v1/namespaces/proxy-8623/services/proxy-service-vkvnp:portname2/proxy/: bar (200; 10.860387ms)
Oct 30 11:36:05.834: INFO: (17) /api/v1/namespaces/proxy-8623/services/http:proxy-service-vkvnp:portname2/proxy/: bar (200; 11.741568ms)
Oct 30 11:36:05.834: INFO: (17) /api/v1/namespaces/proxy-8623/services/https:proxy-service-vkvnp:tlsportname2/proxy/: tls qux (200; 12.950543ms)
Oct 30 11:36:05.841: INFO: (18) /api/v1/namespaces/proxy-8623/pods/https:proxy-service-vkvnp-46vrr:462/proxy/: tls qux (200; 6.330422ms)
Oct 30 11:36:05.841: INFO: (18) /api/v1/namespaces/proxy-8623/services/http:proxy-service-vkvnp:portname1/proxy/: foo (200; 6.384582ms)
Oct 30 11:36:05.842: INFO: (18) /api/v1/namespaces/proxy-8623/pods/proxy-service-vkvnp-46vrr:160/proxy/: foo (200; 7.131617ms)
Oct 30 11:36:05.842: INFO: (18) /api/v1/namespaces/proxy-8623/pods/proxy-service-vkvnp-46vrr/proxy/: <a href="/api/v1/namespaces/proxy-8623/pods/proxy-service-vkvnp-46vrr/proxy/rewriteme">test</a> (200; 6.690114ms)
Oct 30 11:36:05.842: INFO: (18) /api/v1/namespaces/proxy-8623/pods/http:proxy-service-vkvnp-46vrr:162/proxy/: bar (200; 7.112304ms)
Oct 30 11:36:05.842: INFO: (18) /api/v1/namespaces/proxy-8623/pods/http:proxy-service-vkvnp-46vrr:160/proxy/: foo (200; 7.592157ms)
Oct 30 11:36:05.842: INFO: (18) /api/v1/namespaces/proxy-8623/pods/https:proxy-service-vkvnp-46vrr:443/proxy/: <a href="/api/v1/namespaces/proxy-8623/pods/https:proxy-service-vkvnp-46vrr:443/proxy/tlsrewritem... (200; 7.700974ms)
Oct 30 11:36:05.842: INFO: (18) /api/v1/namespaces/proxy-8623/pods/https:proxy-service-vkvnp-46vrr:460/proxy/: tls baz (200; 7.709823ms)
Oct 30 11:36:05.843: INFO: (18) /api/v1/namespaces/proxy-8623/pods/proxy-service-vkvnp-46vrr:1080/proxy/: <a href="/api/v1/namespaces/proxy-8623/pods/proxy-service-vkvnp-46vrr:1080/proxy/rewriteme">test<... (200; 7.986304ms)
Oct 30 11:36:05.843: INFO: (18) /api/v1/namespaces/proxy-8623/services/https:proxy-service-vkvnp:tlsportname2/proxy/: tls qux (200; 7.84776ms)
Oct 30 11:36:05.843: INFO: (18) /api/v1/namespaces/proxy-8623/pods/http:proxy-service-vkvnp-46vrr:1080/proxy/: <a href="/api/v1/namespaces/proxy-8623/pods/http:proxy-service-vkvnp-46vrr:1080/proxy/rewriteme">... (200; 7.826337ms)
Oct 30 11:36:05.843: INFO: (18) /api/v1/namespaces/proxy-8623/pods/proxy-service-vkvnp-46vrr:162/proxy/: bar (200; 7.872204ms)
Oct 30 11:36:05.844: INFO: (18) /api/v1/namespaces/proxy-8623/services/http:proxy-service-vkvnp:portname2/proxy/: bar (200; 9.13158ms)
Oct 30 11:36:05.844: INFO: (18) /api/v1/namespaces/proxy-8623/services/https:proxy-service-vkvnp:tlsportname1/proxy/: tls baz (200; 9.432045ms)
Oct 30 11:36:05.844: INFO: (18) /api/v1/namespaces/proxy-8623/services/proxy-service-vkvnp:portname1/proxy/: foo (200; 9.755899ms)
Oct 30 11:36:05.845: INFO: (18) /api/v1/namespaces/proxy-8623/services/proxy-service-vkvnp:portname2/proxy/: bar (200; 10.040643ms)
Oct 30 11:36:05.852: INFO: (19) /api/v1/namespaces/proxy-8623/services/https:proxy-service-vkvnp:tlsportname1/proxy/: tls baz (200; 6.645704ms)
Oct 30 11:36:05.852: INFO: (19) /api/v1/namespaces/proxy-8623/services/https:proxy-service-vkvnp:tlsportname2/proxy/: tls qux (200; 6.94858ms)
Oct 30 11:36:05.853: INFO: (19) /api/v1/namespaces/proxy-8623/pods/proxy-service-vkvnp-46vrr:160/proxy/: foo (200; 7.332579ms)
Oct 30 11:36:05.853: INFO: (19) /api/v1/namespaces/proxy-8623/services/http:proxy-service-vkvnp:portname2/proxy/: bar (200; 7.65488ms)
Oct 30 11:36:05.853: INFO: (19) /api/v1/namespaces/proxy-8623/services/proxy-service-vkvnp:portname2/proxy/: bar (200; 7.809778ms)
Oct 30 11:36:05.853: INFO: (19) /api/v1/namespaces/proxy-8623/services/http:proxy-service-vkvnp:portname1/proxy/: foo (200; 7.872441ms)
Oct 30 11:36:05.853: INFO: (19) /api/v1/namespaces/proxy-8623/pods/http:proxy-service-vkvnp-46vrr:160/proxy/: foo (200; 8.15956ms)
Oct 30 11:36:05.854: INFO: (19) /api/v1/namespaces/proxy-8623/services/proxy-service-vkvnp:portname1/proxy/: foo (200; 8.585827ms)
Oct 30 11:36:05.854: INFO: (19) /api/v1/namespaces/proxy-8623/pods/https:proxy-service-vkvnp-46vrr:460/proxy/: tls baz (200; 8.254938ms)
Oct 30 11:36:05.854: INFO: (19) /api/v1/namespaces/proxy-8623/pods/http:proxy-service-vkvnp-46vrr:162/proxy/: bar (200; 8.342538ms)
Oct 30 11:36:05.854: INFO: (19) /api/v1/namespaces/proxy-8623/pods/proxy-service-vkvnp-46vrr/proxy/: <a href="/api/v1/namespaces/proxy-8623/pods/proxy-service-vkvnp-46vrr/proxy/rewriteme">test</a> (200; 9.222729ms)
Oct 30 11:36:05.854: INFO: (19) /api/v1/namespaces/proxy-8623/pods/proxy-service-vkvnp-46vrr:162/proxy/: bar (200; 9.317345ms)
Oct 30 11:36:05.855: INFO: (19) /api/v1/namespaces/proxy-8623/pods/http:proxy-service-vkvnp-46vrr:1080/proxy/: <a href="/api/v1/namespaces/proxy-8623/pods/http:proxy-service-vkvnp-46vrr:1080/proxy/rewriteme">... (200; 9.77456ms)
Oct 30 11:36:05.855: INFO: (19) /api/v1/namespaces/proxy-8623/pods/https:proxy-service-vkvnp-46vrr:443/proxy/: <a href="/api/v1/namespaces/proxy-8623/pods/https:proxy-service-vkvnp-46vrr:443/proxy/tlsrewritem... (200; 9.292251ms)
Oct 30 11:36:05.855: INFO: (19) /api/v1/namespaces/proxy-8623/pods/proxy-service-vkvnp-46vrr:1080/proxy/: <a href="/api/v1/namespaces/proxy-8623/pods/proxy-service-vkvnp-46vrr:1080/proxy/rewriteme">test<... (200; 9.931827ms)
Oct 30 11:36:05.855: INFO: (19) /api/v1/namespaces/proxy-8623/pods/https:proxy-service-vkvnp-46vrr:462/proxy/: tls qux (200; 9.768789ms)
STEP: deleting ReplicationController proxy-service-vkvnp in namespace proxy-8623, will wait for the garbage collector to delete the pods
Oct 30 11:36:05.911: INFO: Deleting ReplicationController proxy-service-vkvnp took: 3.764868ms
Oct 30 11:36:06.011: INFO: Terminating ReplicationController proxy-service-vkvnp pods took: 100.23141ms
[AfterEach] version v1
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 11:36:10.811: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-8623" for this suite.
Oct 30 11:36:16.821: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:36:16.953: INFO: namespace proxy-8623 deletion completed in 6.138968151s

• [SLOW TEST:17.531 seconds]
[sig-network] Proxy
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:58
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 11:36:16.954: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-8649
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Performing setup for networking test in namespace pod-network-test-8649
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Oct 30 11:36:17.084: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Oct 30 11:36:35.144: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.4.194:8080/dial?request=hostName&protocol=http&host=192.168.16.101&port=8080&tries=1'] Namespace:pod-network-test-8649 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 30 11:36:35.144: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
Oct 30 11:36:35.234: INFO: Waiting for endpoints: map[]
Oct 30 11:36:35.237: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.4.194:8080/dial?request=hostName&protocol=http&host=192.168.4.255&port=8080&tries=1'] Namespace:pod-network-test-8649 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 30 11:36:35.237: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
Oct 30 11:36:35.323: INFO: Waiting for endpoints: map[]
Oct 30 11:36:35.325: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.4.194:8080/dial?request=hostName&protocol=http&host=192.168.247.20&port=8080&tries=1'] Namespace:pod-network-test-8649 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 30 11:36:35.325: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
Oct 30 11:36:35.421: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 11:36:35.421: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-8649" for this suite.
Oct 30 11:36:57.431: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:36:57.497: INFO: namespace pod-network-test-8649 deletion completed in 22.073180687s

• [SLOW TEST:40.543 seconds]
[sig-network] Networking
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 11:36:57.497: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-7087
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1456
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Oct 30 11:36:57.627: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=kubectl-7087'
Oct 30 11:36:57.696: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Oct 30 11:36:57.696: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: verifying the pod controlled by rc e2e-test-nginx-rc was created
STEP: confirm that you can get logs from an rc
Oct 30 11:36:57.702: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-nv5hf]
Oct 30 11:36:57.702: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-nv5hf" in namespace "kubectl-7087" to be "running and ready"
Oct 30 11:36:57.705: INFO: Pod "e2e-test-nginx-rc-nv5hf": Phase="Pending", Reason="", readiness=false. Elapsed: 3.494498ms
Oct 30 11:36:59.708: INFO: Pod "e2e-test-nginx-rc-nv5hf": Phase="Running", Reason="", readiness=true. Elapsed: 2.00600252s
Oct 30 11:36:59.708: INFO: Pod "e2e-test-nginx-rc-nv5hf" satisfied condition "running and ready"
Oct 30 11:36:59.708: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-nv5hf]
Oct 30 11:36:59.708: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 logs rc/e2e-test-nginx-rc --namespace=kubectl-7087'
Oct 30 11:36:59.785: INFO: stderr: ""
Oct 30 11:36:59.785: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1461
Oct 30 11:36:59.785: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 delete rc e2e-test-nginx-rc --namespace=kubectl-7087'
Oct 30 11:36:59.868: INFO: stderr: ""
Oct 30 11:36:59.868: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 11:36:59.868: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7087" for this suite.
Oct 30 11:37:21.879: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:37:21.943: INFO: namespace kubectl-7087 deletion completed in 22.072010773s

• [SLOW TEST:24.445 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run rc
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 11:37:21.944: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-9120
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name secret-emptykey-test-44808a15-b167-473a-b877-1f554b836cee
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 11:37:22.072: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9120" for this suite.
Oct 30 11:37:28.083: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:37:28.153: INFO: namespace secrets-9120 deletion completed in 6.077698493s

• [SLOW TEST:6.209 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 11:37:28.153: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-8560
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating Redis RC
Oct 30 11:37:28.280: INFO: namespace kubectl-8560
Oct 30 11:37:28.280: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 create -f - --namespace=kubectl-8560'
Oct 30 11:37:28.430: INFO: stderr: ""
Oct 30 11:37:28.430: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Oct 30 11:37:29.433: INFO: Selector matched 1 pods for map[app:redis]
Oct 30 11:37:29.433: INFO: Found 0 / 1
Oct 30 11:37:30.434: INFO: Selector matched 1 pods for map[app:redis]
Oct 30 11:37:30.434: INFO: Found 1 / 1
Oct 30 11:37:30.434: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Oct 30 11:37:30.435: INFO: Selector matched 1 pods for map[app:redis]
Oct 30 11:37:30.435: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Oct 30 11:37:30.435: INFO: wait on redis-master startup in kubectl-8560 
Oct 30 11:37:30.436: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 logs redis-master-t4gd6 redis-master --namespace=kubectl-8560'
Oct 30 11:37:30.508: INFO: stderr: ""
Oct 30 11:37:30.508: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 30 Oct 11:37:29.216 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 30 Oct 11:37:29.216 # Server started, Redis version 3.2.12\n1:M 30 Oct 11:37:29.216 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 30 Oct 11:37:29.216 * The server is now ready to accept connections on port 6379\n"
STEP: exposing RC
Oct 30 11:37:30.508: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=kubectl-8560'
Oct 30 11:37:30.605: INFO: stderr: ""
Oct 30 11:37:30.605: INFO: stdout: "service/rm2 exposed\n"
Oct 30 11:37:30.610: INFO: Service rm2 in namespace kubectl-8560 found.
STEP: exposing service
Oct 30 11:37:32.614: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=kubectl-8560'
Oct 30 11:37:32.691: INFO: stderr: ""
Oct 30 11:37:32.691: INFO: stdout: "service/rm3 exposed\n"
Oct 30 11:37:32.693: INFO: Service rm3 in namespace kubectl-8560 found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 11:37:34.698: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8560" for this suite.
Oct 30 11:37:56.710: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:37:56.778: INFO: namespace kubectl-8560 deletion completed in 22.076801399s

• [SLOW TEST:28.625 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl expose
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create services for rc  [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 11:37:56.778: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-8897
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 11:37:56.908: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-8897" for this suite.
Oct 30 11:38:02.919: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:38:02.990: INFO: namespace services-8897 deletion completed in 6.078822405s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:92

• [SLOW TEST:6.212 seconds]
[sig-network] Services
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide secure master service  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 11:38:02.990: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-2338
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod busybox-b147b03e-d26e-402a-ad51-dd43b298efd6 in namespace container-probe-2338
Oct 30 11:38:05.128: INFO: Started pod busybox-b147b03e-d26e-402a-ad51-dd43b298efd6 in namespace container-probe-2338
STEP: checking the pod's current state and verifying that restartCount is present
Oct 30 11:38:05.129: INFO: Initial restart count of pod busybox-b147b03e-d26e-402a-ad51-dd43b298efd6 is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 11:42:05.440: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-2338" for this suite.
Oct 30 11:42:11.451: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:42:11.516: INFO: namespace container-probe-2338 deletion completed in 6.071895711s

• [SLOW TEST:248.526 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 11:42:11.517: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-7184
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Oct 30 11:42:11.650: INFO: Waiting up to 5m0s for pod "downwardapi-volume-34ba318a-ebe8-4b82-ac94-15ada048a4f5" in namespace "downward-api-7184" to be "success or failure"
Oct 30 11:42:11.653: INFO: Pod "downwardapi-volume-34ba318a-ebe8-4b82-ac94-15ada048a4f5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.902088ms
Oct 30 11:42:13.656: INFO: Pod "downwardapi-volume-34ba318a-ebe8-4b82-ac94-15ada048a4f5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005636187s
STEP: Saw pod success
Oct 30 11:42:13.656: INFO: Pod "downwardapi-volume-34ba318a-ebe8-4b82-ac94-15ada048a4f5" satisfied condition "success or failure"
Oct 30 11:42:13.658: INFO: Trying to get logs from node ip-10-1-5-63.eu-central-1.compute.internal pod downwardapi-volume-34ba318a-ebe8-4b82-ac94-15ada048a4f5 container client-container: <nil>
STEP: delete the pod
Oct 30 11:42:13.670: INFO: Waiting for pod downwardapi-volume-34ba318a-ebe8-4b82-ac94-15ada048a4f5 to disappear
Oct 30 11:42:13.672: INFO: Pod downwardapi-volume-34ba318a-ebe8-4b82-ac94-15ada048a4f5 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 11:42:13.672: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7184" for this suite.
Oct 30 11:42:19.680: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:42:19.748: INFO: namespace downward-api-7184 deletion completed in 6.074178982s

• [SLOW TEST:8.232 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 11:42:19.749: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename svc-latency
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svc-latency-553
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating replication controller svc-latency-rc in namespace svc-latency-553
I1030 11:42:19.884360      18 runners.go:180] Created replication controller with name: svc-latency-rc, namespace: svc-latency-553, replica count: 1
I1030 11:42:20.934829      18 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1030 11:42:21.935052      18 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Oct 30 11:42:22.041: INFO: Created: latency-svc-fbtvr
Oct 30 11:42:22.046: INFO: Got endpoints: latency-svc-fbtvr [10.819249ms]
Oct 30 11:42:22.054: INFO: Created: latency-svc-5gj54
Oct 30 11:42:22.058: INFO: Created: latency-svc-hvfkz
Oct 30 11:42:22.060: INFO: Got endpoints: latency-svc-5gj54 [13.945735ms]
Oct 30 11:42:22.063: INFO: Got endpoints: latency-svc-hvfkz [16.368518ms]
Oct 30 11:42:22.064: INFO: Created: latency-svc-m8rhf
Oct 30 11:42:22.067: INFO: Got endpoints: latency-svc-m8rhf [20.573517ms]
Oct 30 11:42:22.069: INFO: Created: latency-svc-8n9kd
Oct 30 11:42:22.071: INFO: Created: latency-svc-l9jkq
Oct 30 11:42:22.074: INFO: Got endpoints: latency-svc-l9jkq [28.542462ms]
Oct 30 11:42:22.075: INFO: Got endpoints: latency-svc-8n9kd [28.09502ms]
Oct 30 11:42:22.077: INFO: Created: latency-svc-rhj59
Oct 30 11:42:22.081: INFO: Created: latency-svc-8b6nj
Oct 30 11:42:22.083: INFO: Got endpoints: latency-svc-rhj59 [36.12745ms]
Oct 30 11:42:22.084: INFO: Got endpoints: latency-svc-8b6nj [38.488578ms]
Oct 30 11:42:22.087: INFO: Created: latency-svc-8kn6x
Oct 30 11:42:22.090: INFO: Got endpoints: latency-svc-8kn6x [43.317417ms]
Oct 30 11:42:22.093: INFO: Created: latency-svc-tthxw
Oct 30 11:42:22.095: INFO: Got endpoints: latency-svc-tthxw [47.811045ms]
Oct 30 11:42:22.098: INFO: Created: latency-svc-wl9sj
Oct 30 11:42:22.103: INFO: Created: latency-svc-whbsc
Oct 30 11:42:22.104: INFO: Got endpoints: latency-svc-wl9sj [56.712034ms]
Oct 30 11:42:22.109: INFO: Got endpoints: latency-svc-whbsc [61.997881ms]
Oct 30 11:42:22.110: INFO: Created: latency-svc-qkwp9
Oct 30 11:42:22.114: INFO: Got endpoints: latency-svc-qkwp9 [68.512752ms]
Oct 30 11:42:22.114: INFO: Created: latency-svc-v6fm2
Oct 30 11:42:22.120: INFO: Created: latency-svc-fwvnq
Oct 30 11:42:22.120: INFO: Got endpoints: latency-svc-v6fm2 [72.681547ms]
Oct 30 11:42:22.126: INFO: Created: latency-svc-tb95q
Oct 30 11:42:22.128: INFO: Got endpoints: latency-svc-fwvnq [80.73437ms]
Oct 30 11:42:22.129: INFO: Got endpoints: latency-svc-tb95q [83.122335ms]
Oct 30 11:42:22.131: INFO: Created: latency-svc-k8ns6
Oct 30 11:42:22.135: INFO: Got endpoints: latency-svc-k8ns6 [74.882159ms]
Oct 30 11:42:22.138: INFO: Created: latency-svc-2ncs5
Oct 30 11:42:22.142: INFO: Created: latency-svc-pd4dq
Oct 30 11:42:22.143: INFO: Got endpoints: latency-svc-2ncs5 [80.660728ms]
Oct 30 11:42:22.146: INFO: Created: latency-svc-5wlm2
Oct 30 11:42:22.147: INFO: Got endpoints: latency-svc-pd4dq [79.199814ms]
Oct 30 11:42:22.152: INFO: Created: latency-svc-4dkhd
Oct 30 11:42:22.153: INFO: Got endpoints: latency-svc-5wlm2 [78.654506ms]
Oct 30 11:42:22.157: INFO: Created: latency-svc-rxt6f
Oct 30 11:42:22.174: INFO: Got endpoints: latency-svc-4dkhd [98.922428ms]
Oct 30 11:42:22.176: INFO: Got endpoints: latency-svc-rxt6f [93.400654ms]
Oct 30 11:42:22.180: INFO: Created: latency-svc-x6zzg
Oct 30 11:42:22.185: INFO: Got endpoints: latency-svc-x6zzg [100.367021ms]
Oct 30 11:42:22.188: INFO: Created: latency-svc-pztpz
Oct 30 11:42:22.194: INFO: Got endpoints: latency-svc-pztpz [103.793616ms]
Oct 30 11:42:22.202: INFO: Created: latency-svc-mql8v
Oct 30 11:42:22.205: INFO: Got endpoints: latency-svc-mql8v [109.736797ms]
Oct 30 11:42:22.209: INFO: Created: latency-svc-29jrw
Oct 30 11:42:22.214: INFO: Got endpoints: latency-svc-29jrw [109.713463ms]
Oct 30 11:42:22.214: INFO: Created: latency-svc-c9gf4
Oct 30 11:42:22.222: INFO: Got endpoints: latency-svc-c9gf4 [112.425939ms]
Oct 30 11:42:22.224: INFO: Created: latency-svc-bjm4m
Oct 30 11:42:22.227: INFO: Created: latency-svc-mmtv2
Oct 30 11:42:22.231: INFO: Got endpoints: latency-svc-bjm4m [116.368762ms]
Oct 30 11:42:22.234: INFO: Created: latency-svc-bnkd4
Oct 30 11:42:22.236: INFO: Got endpoints: latency-svc-mmtv2 [116.016589ms]
Oct 30 11:42:22.238: INFO: Got endpoints: latency-svc-bnkd4 [110.525815ms]
Oct 30 11:42:22.241: INFO: Created: latency-svc-wfnvf
Oct 30 11:42:22.244: INFO: Created: latency-svc-xf7fz
Oct 30 11:42:22.246: INFO: Got endpoints: latency-svc-wfnvf [116.815051ms]
Oct 30 11:42:22.249: INFO: Got endpoints: latency-svc-xf7fz [113.579798ms]
Oct 30 11:42:22.251: INFO: Created: latency-svc-86h8l
Oct 30 11:42:22.255: INFO: Created: latency-svc-wx5lz
Oct 30 11:42:22.256: INFO: Got endpoints: latency-svc-86h8l [112.557479ms]
Oct 30 11:42:22.260: INFO: Got endpoints: latency-svc-wx5lz [113.03368ms]
Oct 30 11:42:22.264: INFO: Created: latency-svc-285t5
Oct 30 11:42:22.268: INFO: Created: latency-svc-ldw5t
Oct 30 11:42:22.272: INFO: Created: latency-svc-gnz72
Oct 30 11:42:22.279: INFO: Created: latency-svc-bn6hn
Oct 30 11:42:22.282: INFO: Created: latency-svc-xhwbg
Oct 30 11:42:22.287: INFO: Created: latency-svc-zh96b
Oct 30 11:42:22.291: INFO: Created: latency-svc-4m9zv
Oct 30 11:42:22.294: INFO: Got endpoints: latency-svc-285t5 [140.816619ms]
Oct 30 11:42:22.297: INFO: Created: latency-svc-2znv6
Oct 30 11:42:22.304: INFO: Created: latency-svc-q6kcz
Oct 30 11:42:22.309: INFO: Created: latency-svc-9mddn
Oct 30 11:42:22.312: INFO: Created: latency-svc-g882w
Oct 30 11:42:22.318: INFO: Created: latency-svc-k5q9q
Oct 30 11:42:22.321: INFO: Created: latency-svc-k6cqd
Oct 30 11:42:22.325: INFO: Created: latency-svc-hz6pb
Oct 30 11:42:22.330: INFO: Created: latency-svc-rc6s5
Oct 30 11:42:22.332: INFO: Created: latency-svc-sp4fx
Oct 30 11:42:22.343: INFO: Got endpoints: latency-svc-ldw5t [169.260501ms]
Oct 30 11:42:22.349: INFO: Created: latency-svc-vd6ck
Oct 30 11:42:22.393: INFO: Got endpoints: latency-svc-gnz72 [216.464318ms]
Oct 30 11:42:22.398: INFO: Created: latency-svc-dgqlb
Oct 30 11:42:22.443: INFO: Got endpoints: latency-svc-bn6hn [258.123531ms]
Oct 30 11:42:22.449: INFO: Created: latency-svc-z49jw
Oct 30 11:42:22.494: INFO: Got endpoints: latency-svc-xhwbg [299.455491ms]
Oct 30 11:42:22.500: INFO: Created: latency-svc-n66tf
Oct 30 11:42:22.543: INFO: Got endpoints: latency-svc-zh96b [338.377268ms]
Oct 30 11:42:22.548: INFO: Created: latency-svc-6nmgv
Oct 30 11:42:22.594: INFO: Got endpoints: latency-svc-4m9zv [379.937483ms]
Oct 30 11:42:22.599: INFO: Created: latency-svc-twxhx
Oct 30 11:42:22.644: INFO: Got endpoints: latency-svc-2znv6 [422.355403ms]
Oct 30 11:42:22.650: INFO: Created: latency-svc-298dt
Oct 30 11:42:22.693: INFO: Got endpoints: latency-svc-q6kcz [462.3293ms]
Oct 30 11:42:22.698: INFO: Created: latency-svc-9pdlh
Oct 30 11:42:22.744: INFO: Got endpoints: latency-svc-9mddn [508.162904ms]
Oct 30 11:42:22.749: INFO: Created: latency-svc-54fhh
Oct 30 11:42:22.793: INFO: Got endpoints: latency-svc-g882w [554.523483ms]
Oct 30 11:42:22.798: INFO: Created: latency-svc-fnc2p
Oct 30 11:42:22.843: INFO: Got endpoints: latency-svc-k5q9q [597.09623ms]
Oct 30 11:42:22.848: INFO: Created: latency-svc-v85jg
Oct 30 11:42:22.893: INFO: Got endpoints: latency-svc-k6cqd [644.445645ms]
Oct 30 11:42:22.898: INFO: Created: latency-svc-thsxh
Oct 30 11:42:22.943: INFO: Got endpoints: latency-svc-hz6pb [687.251626ms]
Oct 30 11:42:22.950: INFO: Created: latency-svc-pshff
Oct 30 11:42:22.993: INFO: Got endpoints: latency-svc-rc6s5 [733.421816ms]
Oct 30 11:42:23.000: INFO: Created: latency-svc-8czdv
Oct 30 11:42:23.043: INFO: Got endpoints: latency-svc-sp4fx [749.260293ms]
Oct 30 11:42:23.048: INFO: Created: latency-svc-pzxjx
Oct 30 11:42:23.093: INFO: Got endpoints: latency-svc-vd6ck [749.999479ms]
Oct 30 11:42:23.099: INFO: Created: latency-svc-gz74w
Oct 30 11:42:23.143: INFO: Got endpoints: latency-svc-dgqlb [750.025744ms]
Oct 30 11:42:23.150: INFO: Created: latency-svc-f8qqz
Oct 30 11:42:23.193: INFO: Got endpoints: latency-svc-z49jw [750.341313ms]
Oct 30 11:42:23.199: INFO: Created: latency-svc-bn6tj
Oct 30 11:42:23.244: INFO: Got endpoints: latency-svc-n66tf [750.175311ms]
Oct 30 11:42:23.251: INFO: Created: latency-svc-2bsfg
Oct 30 11:42:23.294: INFO: Got endpoints: latency-svc-6nmgv [750.714506ms]
Oct 30 11:42:23.300: INFO: Created: latency-svc-th2tz
Oct 30 11:42:23.343: INFO: Got endpoints: latency-svc-twxhx [749.616394ms]
Oct 30 11:42:23.349: INFO: Created: latency-svc-2zkzt
Oct 30 11:42:23.394: INFO: Got endpoints: latency-svc-298dt [749.804406ms]
Oct 30 11:42:23.400: INFO: Created: latency-svc-trdbs
Oct 30 11:42:23.443: INFO: Got endpoints: latency-svc-9pdlh [750.397216ms]
Oct 30 11:42:23.449: INFO: Created: latency-svc-jts5w
Oct 30 11:42:23.493: INFO: Got endpoints: latency-svc-54fhh [749.434867ms]
Oct 30 11:42:23.500: INFO: Created: latency-svc-z6mdm
Oct 30 11:42:23.544: INFO: Got endpoints: latency-svc-fnc2p [750.48095ms]
Oct 30 11:42:23.549: INFO: Created: latency-svc-pb84l
Oct 30 11:42:23.593: INFO: Got endpoints: latency-svc-v85jg [750.087061ms]
Oct 30 11:42:23.600: INFO: Created: latency-svc-wrjvh
Oct 30 11:42:23.644: INFO: Got endpoints: latency-svc-thsxh [750.32853ms]
Oct 30 11:42:23.649: INFO: Created: latency-svc-nsccd
Oct 30 11:42:23.693: INFO: Got endpoints: latency-svc-pshff [749.728482ms]
Oct 30 11:42:23.699: INFO: Created: latency-svc-vt2wn
Oct 30 11:42:23.743: INFO: Got endpoints: latency-svc-8czdv [749.833472ms]
Oct 30 11:42:23.753: INFO: Created: latency-svc-w2mz2
Oct 30 11:42:23.793: INFO: Got endpoints: latency-svc-pzxjx [749.923393ms]
Oct 30 11:42:23.799: INFO: Created: latency-svc-n6fqz
Oct 30 11:42:23.843: INFO: Got endpoints: latency-svc-gz74w [749.643714ms]
Oct 30 11:42:23.849: INFO: Created: latency-svc-4jl2k
Oct 30 11:42:23.893: INFO: Got endpoints: latency-svc-f8qqz [750.436144ms]
Oct 30 11:42:23.901: INFO: Created: latency-svc-t5dcx
Oct 30 11:42:23.943: INFO: Got endpoints: latency-svc-bn6tj [749.939958ms]
Oct 30 11:42:23.950: INFO: Created: latency-svc-rdk6q
Oct 30 11:42:23.994: INFO: Got endpoints: latency-svc-2bsfg [749.683991ms]
Oct 30 11:42:23.999: INFO: Created: latency-svc-km97j
Oct 30 11:42:24.045: INFO: Got endpoints: latency-svc-th2tz [750.92833ms]
Oct 30 11:42:24.051: INFO: Created: latency-svc-jsnfz
Oct 30 11:42:24.093: INFO: Got endpoints: latency-svc-2zkzt [749.933609ms]
Oct 30 11:42:24.100: INFO: Created: latency-svc-xj74p
Oct 30 11:42:24.143: INFO: Got endpoints: latency-svc-trdbs [749.312747ms]
Oct 30 11:42:24.149: INFO: Created: latency-svc-qb8fb
Oct 30 11:42:24.193: INFO: Got endpoints: latency-svc-jts5w [749.906396ms]
Oct 30 11:42:24.199: INFO: Created: latency-svc-v9zhr
Oct 30 11:42:24.244: INFO: Got endpoints: latency-svc-z6mdm [750.155693ms]
Oct 30 11:42:24.249: INFO: Created: latency-svc-tlv7f
Oct 30 11:42:24.294: INFO: Got endpoints: latency-svc-pb84l [750.746579ms]
Oct 30 11:42:24.307: INFO: Created: latency-svc-hf7mf
Oct 30 11:42:24.344: INFO: Got endpoints: latency-svc-wrjvh [750.260585ms]
Oct 30 11:42:24.351: INFO: Created: latency-svc-g65vd
Oct 30 11:42:24.393: INFO: Got endpoints: latency-svc-nsccd [749.809135ms]
Oct 30 11:42:24.399: INFO: Created: latency-svc-82g87
Oct 30 11:42:24.443: INFO: Got endpoints: latency-svc-vt2wn [749.88876ms]
Oct 30 11:42:24.449: INFO: Created: latency-svc-k5nql
Oct 30 11:42:24.493: INFO: Got endpoints: latency-svc-w2mz2 [750.33598ms]
Oct 30 11:42:24.500: INFO: Created: latency-svc-bpk2c
Oct 30 11:42:24.543: INFO: Got endpoints: latency-svc-n6fqz [749.463152ms]
Oct 30 11:42:24.548: INFO: Created: latency-svc-4zd7d
Oct 30 11:42:24.594: INFO: Got endpoints: latency-svc-4jl2k [750.766383ms]
Oct 30 11:42:24.600: INFO: Created: latency-svc-w6sjw
Oct 30 11:42:24.643: INFO: Got endpoints: latency-svc-t5dcx [749.55875ms]
Oct 30 11:42:24.652: INFO: Created: latency-svc-5db8l
Oct 30 11:42:24.695: INFO: Got endpoints: latency-svc-rdk6q [752.027185ms]
Oct 30 11:42:24.701: INFO: Created: latency-svc-rttfs
Oct 30 11:42:24.744: INFO: Got endpoints: latency-svc-km97j [750.671664ms]
Oct 30 11:42:24.753: INFO: Created: latency-svc-866ls
Oct 30 11:42:24.793: INFO: Got endpoints: latency-svc-jsnfz [747.846608ms]
Oct 30 11:42:24.799: INFO: Created: latency-svc-9dm9w
Oct 30 11:42:24.843: INFO: Got endpoints: latency-svc-xj74p [749.709854ms]
Oct 30 11:42:24.850: INFO: Created: latency-svc-ttmm5
Oct 30 11:42:24.893: INFO: Got endpoints: latency-svc-qb8fb [749.993379ms]
Oct 30 11:42:24.899: INFO: Created: latency-svc-bzdzb
Oct 30 11:42:24.943: INFO: Got endpoints: latency-svc-v9zhr [749.993221ms]
Oct 30 11:42:24.949: INFO: Created: latency-svc-blz5h
Oct 30 11:42:24.993: INFO: Got endpoints: latency-svc-tlv7f [749.680797ms]
Oct 30 11:42:24.998: INFO: Created: latency-svc-hlmjc
Oct 30 11:42:25.044: INFO: Got endpoints: latency-svc-hf7mf [749.218879ms]
Oct 30 11:42:25.049: INFO: Created: latency-svc-mwrhz
Oct 30 11:42:25.093: INFO: Got endpoints: latency-svc-g65vd [749.079681ms]
Oct 30 11:42:25.099: INFO: Created: latency-svc-hxhqx
Oct 30 11:42:25.144: INFO: Got endpoints: latency-svc-82g87 [750.232026ms]
Oct 30 11:42:25.150: INFO: Created: latency-svc-l7vqc
Oct 30 11:42:25.193: INFO: Got endpoints: latency-svc-k5nql [750.143629ms]
Oct 30 11:42:25.199: INFO: Created: latency-svc-9xxbg
Oct 30 11:42:25.243: INFO: Got endpoints: latency-svc-bpk2c [749.653483ms]
Oct 30 11:42:25.249: INFO: Created: latency-svc-ddkhr
Oct 30 11:42:25.293: INFO: Got endpoints: latency-svc-4zd7d [750.157278ms]
Oct 30 11:42:25.299: INFO: Created: latency-svc-8w84g
Oct 30 11:42:25.343: INFO: Got endpoints: latency-svc-w6sjw [749.398995ms]
Oct 30 11:42:25.350: INFO: Created: latency-svc-wcrf7
Oct 30 11:42:25.393: INFO: Got endpoints: latency-svc-5db8l [750.039553ms]
Oct 30 11:42:25.400: INFO: Created: latency-svc-vjsvf
Oct 30 11:42:25.443: INFO: Got endpoints: latency-svc-rttfs [747.609253ms]
Oct 30 11:42:25.448: INFO: Created: latency-svc-gk978
Oct 30 11:42:25.493: INFO: Got endpoints: latency-svc-866ls [748.772596ms]
Oct 30 11:42:25.500: INFO: Created: latency-svc-p9xz7
Oct 30 11:42:25.543: INFO: Got endpoints: latency-svc-9dm9w [750.217464ms]
Oct 30 11:42:25.550: INFO: Created: latency-svc-8nvt4
Oct 30 11:42:25.593: INFO: Got endpoints: latency-svc-ttmm5 [749.962551ms]
Oct 30 11:42:25.598: INFO: Created: latency-svc-nkwct
Oct 30 11:42:25.645: INFO: Got endpoints: latency-svc-bzdzb [751.642035ms]
Oct 30 11:42:25.651: INFO: Created: latency-svc-s28g6
Oct 30 11:42:25.693: INFO: Got endpoints: latency-svc-blz5h [749.435829ms]
Oct 30 11:42:25.698: INFO: Created: latency-svc-tvpv7
Oct 30 11:42:25.744: INFO: Got endpoints: latency-svc-hlmjc [750.480878ms]
Oct 30 11:42:25.750: INFO: Created: latency-svc-rx5tp
Oct 30 11:42:25.794: INFO: Got endpoints: latency-svc-mwrhz [750.038562ms]
Oct 30 11:42:25.802: INFO: Created: latency-svc-zzh65
Oct 30 11:42:25.844: INFO: Got endpoints: latency-svc-hxhqx [750.716805ms]
Oct 30 11:42:25.849: INFO: Created: latency-svc-br55z
Oct 30 11:42:25.893: INFO: Got endpoints: latency-svc-l7vqc [749.640868ms]
Oct 30 11:42:25.904: INFO: Created: latency-svc-jmn8b
Oct 30 11:42:25.944: INFO: Got endpoints: latency-svc-9xxbg [750.174369ms]
Oct 30 11:42:25.951: INFO: Created: latency-svc-6njjk
Oct 30 11:42:25.993: INFO: Got endpoints: latency-svc-ddkhr [749.981371ms]
Oct 30 11:42:25.999: INFO: Created: latency-svc-cfnwh
Oct 30 11:42:26.044: INFO: Got endpoints: latency-svc-8w84g [750.541134ms]
Oct 30 11:42:26.050: INFO: Created: latency-svc-5rtrt
Oct 30 11:42:26.094: INFO: Got endpoints: latency-svc-wcrf7 [750.284374ms]
Oct 30 11:42:26.099: INFO: Created: latency-svc-bj44d
Oct 30 11:42:26.143: INFO: Got endpoints: latency-svc-vjsvf [749.520452ms]
Oct 30 11:42:26.150: INFO: Created: latency-svc-jlhl4
Oct 30 11:42:26.193: INFO: Got endpoints: latency-svc-gk978 [750.111543ms]
Oct 30 11:42:26.199: INFO: Created: latency-svc-958wp
Oct 30 11:42:26.243: INFO: Got endpoints: latency-svc-p9xz7 [749.445374ms]
Oct 30 11:42:26.248: INFO: Created: latency-svc-fdrtl
Oct 30 11:42:26.293: INFO: Got endpoints: latency-svc-8nvt4 [750.235317ms]
Oct 30 11:42:26.299: INFO: Created: latency-svc-9cz29
Oct 30 11:42:26.343: INFO: Got endpoints: latency-svc-nkwct [750.018832ms]
Oct 30 11:42:26.350: INFO: Created: latency-svc-s6gbt
Oct 30 11:42:26.393: INFO: Got endpoints: latency-svc-s28g6 [748.363266ms]
Oct 30 11:42:26.399: INFO: Created: latency-svc-6w48m
Oct 30 11:42:26.443: INFO: Got endpoints: latency-svc-tvpv7 [749.92528ms]
Oct 30 11:42:26.449: INFO: Created: latency-svc-2nfvm
Oct 30 11:42:26.493: INFO: Got endpoints: latency-svc-rx5tp [749.070502ms]
Oct 30 11:42:26.498: INFO: Created: latency-svc-h4mxk
Oct 30 11:42:26.544: INFO: Got endpoints: latency-svc-zzh65 [750.018393ms]
Oct 30 11:42:26.550: INFO: Created: latency-svc-h4r5z
Oct 30 11:42:26.594: INFO: Got endpoints: latency-svc-br55z [749.853335ms]
Oct 30 11:42:26.601: INFO: Created: latency-svc-sgxzg
Oct 30 11:42:26.643: INFO: Got endpoints: latency-svc-jmn8b [749.913168ms]
Oct 30 11:42:26.649: INFO: Created: latency-svc-wn9z8
Oct 30 11:42:26.694: INFO: Got endpoints: latency-svc-6njjk [750.393455ms]
Oct 30 11:42:26.702: INFO: Created: latency-svc-8dq2k
Oct 30 11:42:26.743: INFO: Got endpoints: latency-svc-cfnwh [750.299388ms]
Oct 30 11:42:26.749: INFO: Created: latency-svc-8p6hf
Oct 30 11:42:26.794: INFO: Got endpoints: latency-svc-5rtrt [750.188398ms]
Oct 30 11:42:26.801: INFO: Created: latency-svc-2xd88
Oct 30 11:42:26.843: INFO: Got endpoints: latency-svc-bj44d [749.736797ms]
Oct 30 11:42:26.849: INFO: Created: latency-svc-dgh5x
Oct 30 11:42:26.894: INFO: Got endpoints: latency-svc-jlhl4 [750.820258ms]
Oct 30 11:42:26.899: INFO: Created: latency-svc-2dbzb
Oct 30 11:42:26.944: INFO: Got endpoints: latency-svc-958wp [750.692873ms]
Oct 30 11:42:26.949: INFO: Created: latency-svc-k575h
Oct 30 11:42:26.993: INFO: Got endpoints: latency-svc-fdrtl [750.557853ms]
Oct 30 11:42:27.000: INFO: Created: latency-svc-rmb2l
Oct 30 11:42:27.043: INFO: Got endpoints: latency-svc-9cz29 [750.13108ms]
Oct 30 11:42:27.049: INFO: Created: latency-svc-9vb7x
Oct 30 11:42:27.093: INFO: Got endpoints: latency-svc-s6gbt [750.296406ms]
Oct 30 11:42:27.100: INFO: Created: latency-svc-j9v8v
Oct 30 11:42:27.143: INFO: Got endpoints: latency-svc-6w48m [750.150564ms]
Oct 30 11:42:27.150: INFO: Created: latency-svc-rjngm
Oct 30 11:42:27.193: INFO: Got endpoints: latency-svc-2nfvm [750.275257ms]
Oct 30 11:42:27.199: INFO: Created: latency-svc-c5m64
Oct 30 11:42:27.243: INFO: Got endpoints: latency-svc-h4mxk [750.459493ms]
Oct 30 11:42:27.249: INFO: Created: latency-svc-78bl8
Oct 30 11:42:27.296: INFO: Got endpoints: latency-svc-h4r5z [751.512809ms]
Oct 30 11:42:27.303: INFO: Created: latency-svc-pbk9z
Oct 30 11:42:27.343: INFO: Got endpoints: latency-svc-sgxzg [749.695091ms]
Oct 30 11:42:27.349: INFO: Created: latency-svc-pkqht
Oct 30 11:42:27.393: INFO: Got endpoints: latency-svc-wn9z8 [749.360248ms]
Oct 30 11:42:27.399: INFO: Created: latency-svc-lpvgf
Oct 30 11:42:27.444: INFO: Got endpoints: latency-svc-8dq2k [749.33887ms]
Oct 30 11:42:27.449: INFO: Created: latency-svc-z9j7m
Oct 30 11:42:27.493: INFO: Got endpoints: latency-svc-8p6hf [749.618483ms]
Oct 30 11:42:27.500: INFO: Created: latency-svc-9ngts
Oct 30 11:42:27.543: INFO: Got endpoints: latency-svc-2xd88 [748.95675ms]
Oct 30 11:42:27.549: INFO: Created: latency-svc-z7bb5
Oct 30 11:42:27.594: INFO: Got endpoints: latency-svc-dgh5x [750.221231ms]
Oct 30 11:42:27.600: INFO: Created: latency-svc-vjr4l
Oct 30 11:42:27.643: INFO: Got endpoints: latency-svc-2dbzb [749.019341ms]
Oct 30 11:42:27.648: INFO: Created: latency-svc-trfgp
Oct 30 11:42:27.693: INFO: Got endpoints: latency-svc-k575h [748.911185ms]
Oct 30 11:42:27.698: INFO: Created: latency-svc-grd7k
Oct 30 11:42:27.743: INFO: Got endpoints: latency-svc-rmb2l [749.546107ms]
Oct 30 11:42:27.749: INFO: Created: latency-svc-pzw2z
Oct 30 11:42:27.797: INFO: Got endpoints: latency-svc-9vb7x [753.972931ms]
Oct 30 11:42:27.807: INFO: Created: latency-svc-p6rhk
Oct 30 11:42:27.843: INFO: Got endpoints: latency-svc-j9v8v [749.098281ms]
Oct 30 11:42:27.850: INFO: Created: latency-svc-t7x7g
Oct 30 11:42:27.893: INFO: Got endpoints: latency-svc-rjngm [749.459435ms]
Oct 30 11:42:27.900: INFO: Created: latency-svc-6sbgr
Oct 30 11:42:27.943: INFO: Got endpoints: latency-svc-c5m64 [749.611498ms]
Oct 30 11:42:27.954: INFO: Created: latency-svc-btpfp
Oct 30 11:42:27.995: INFO: Got endpoints: latency-svc-78bl8 [751.493354ms]
Oct 30 11:42:28.002: INFO: Created: latency-svc-b9z72
Oct 30 11:42:28.044: INFO: Got endpoints: latency-svc-pbk9z [748.023662ms]
Oct 30 11:42:28.051: INFO: Created: latency-svc-68s89
Oct 30 11:42:28.094: INFO: Got endpoints: latency-svc-pkqht [751.152403ms]
Oct 30 11:42:28.100: INFO: Created: latency-svc-8k7qj
Oct 30 11:42:28.143: INFO: Got endpoints: latency-svc-lpvgf [750.137731ms]
Oct 30 11:42:28.148: INFO: Created: latency-svc-pfxjw
Oct 30 11:42:28.193: INFO: Got endpoints: latency-svc-z9j7m [749.478018ms]
Oct 30 11:42:28.199: INFO: Created: latency-svc-ntjpb
Oct 30 11:42:28.243: INFO: Got endpoints: latency-svc-9ngts [750.366405ms]
Oct 30 11:42:28.249: INFO: Created: latency-svc-2wfmq
Oct 30 11:42:28.293: INFO: Got endpoints: latency-svc-z7bb5 [750.171679ms]
Oct 30 11:42:28.299: INFO: Created: latency-svc-l8vfm
Oct 30 11:42:28.343: INFO: Got endpoints: latency-svc-vjr4l [749.285603ms]
Oct 30 11:42:28.349: INFO: Created: latency-svc-gt8j9
Oct 30 11:42:28.394: INFO: Got endpoints: latency-svc-trfgp [751.326981ms]
Oct 30 11:42:28.401: INFO: Created: latency-svc-lwxjj
Oct 30 11:42:28.444: INFO: Got endpoints: latency-svc-grd7k [751.341773ms]
Oct 30 11:42:28.450: INFO: Created: latency-svc-gxh2b
Oct 30 11:42:28.494: INFO: Got endpoints: latency-svc-pzw2z [750.647973ms]
Oct 30 11:42:28.501: INFO: Created: latency-svc-98pbm
Oct 30 11:42:28.543: INFO: Got endpoints: latency-svc-p6rhk [745.796488ms]
Oct 30 11:42:28.550: INFO: Created: latency-svc-jr4rp
Oct 30 11:42:28.593: INFO: Got endpoints: latency-svc-t7x7g [750.688571ms]
Oct 30 11:42:28.600: INFO: Created: latency-svc-nf4j7
Oct 30 11:42:28.644: INFO: Got endpoints: latency-svc-6sbgr [750.620637ms]
Oct 30 11:42:28.651: INFO: Created: latency-svc-6497j
Oct 30 11:42:28.693: INFO: Got endpoints: latency-svc-btpfp [750.424481ms]
Oct 30 11:42:28.699: INFO: Created: latency-svc-t5ljh
Oct 30 11:42:28.744: INFO: Got endpoints: latency-svc-b9z72 [749.41407ms]
Oct 30 11:42:28.750: INFO: Created: latency-svc-lvlzs
Oct 30 11:42:28.793: INFO: Got endpoints: latency-svc-68s89 [748.816692ms]
Oct 30 11:42:28.799: INFO: Created: latency-svc-57n87
Oct 30 11:42:28.843: INFO: Got endpoints: latency-svc-8k7qj [748.790132ms]
Oct 30 11:42:28.851: INFO: Created: latency-svc-v4b4x
Oct 30 11:42:28.894: INFO: Got endpoints: latency-svc-pfxjw [750.42213ms]
Oct 30 11:42:28.899: INFO: Created: latency-svc-qfsxq
Oct 30 11:42:28.943: INFO: Got endpoints: latency-svc-ntjpb [750.053839ms]
Oct 30 11:42:28.950: INFO: Created: latency-svc-vlqch
Oct 30 11:42:28.993: INFO: Got endpoints: latency-svc-2wfmq [749.894404ms]
Oct 30 11:42:29.001: INFO: Created: latency-svc-sbcsj
Oct 30 11:42:29.044: INFO: Got endpoints: latency-svc-l8vfm [750.590898ms]
Oct 30 11:42:29.057: INFO: Created: latency-svc-l6tws
Oct 30 11:42:29.094: INFO: Got endpoints: latency-svc-gt8j9 [750.465401ms]
Oct 30 11:42:29.100: INFO: Created: latency-svc-78jrj
Oct 30 11:42:29.143: INFO: Got endpoints: latency-svc-lwxjj [748.575942ms]
Oct 30 11:42:29.150: INFO: Created: latency-svc-nw96m
Oct 30 11:42:29.193: INFO: Got endpoints: latency-svc-gxh2b [748.394684ms]
Oct 30 11:42:29.199: INFO: Created: latency-svc-4lkr4
Oct 30 11:42:29.243: INFO: Got endpoints: latency-svc-98pbm [749.566672ms]
Oct 30 11:42:29.249: INFO: Created: latency-svc-szlpb
Oct 30 11:42:29.293: INFO: Got endpoints: latency-svc-jr4rp [749.80509ms]
Oct 30 11:42:29.299: INFO: Created: latency-svc-7ghqg
Oct 30 11:42:29.344: INFO: Got endpoints: latency-svc-nf4j7 [750.314814ms]
Oct 30 11:42:29.350: INFO: Created: latency-svc-fzzdm
Oct 30 11:42:29.393: INFO: Got endpoints: latency-svc-6497j [748.952844ms]
Oct 30 11:42:29.399: INFO: Created: latency-svc-d5vnm
Oct 30 11:42:29.444: INFO: Got endpoints: latency-svc-t5ljh [750.120863ms]
Oct 30 11:42:29.449: INFO: Created: latency-svc-km292
Oct 30 11:42:29.494: INFO: Got endpoints: latency-svc-lvlzs [749.177736ms]
Oct 30 11:42:29.501: INFO: Created: latency-svc-fg8cg
Oct 30 11:42:29.543: INFO: Got endpoints: latency-svc-57n87 [750.077567ms]
Oct 30 11:42:29.549: INFO: Created: latency-svc-v4s7s
Oct 30 11:42:29.594: INFO: Got endpoints: latency-svc-v4b4x [750.317127ms]
Oct 30 11:42:29.602: INFO: Created: latency-svc-zqs2p
Oct 30 11:42:29.644: INFO: Got endpoints: latency-svc-qfsxq [750.687075ms]
Oct 30 11:42:29.650: INFO: Created: latency-svc-nczn6
Oct 30 11:42:29.693: INFO: Got endpoints: latency-svc-vlqch [749.535309ms]
Oct 30 11:42:29.698: INFO: Created: latency-svc-jsv9s
Oct 30 11:42:29.744: INFO: Got endpoints: latency-svc-sbcsj [750.622663ms]
Oct 30 11:42:29.750: INFO: Created: latency-svc-rnsgx
Oct 30 11:42:29.794: INFO: Got endpoints: latency-svc-l6tws [749.838395ms]
Oct 30 11:42:29.800: INFO: Created: latency-svc-9vffp
Oct 30 11:42:29.845: INFO: Got endpoints: latency-svc-78jrj [751.146775ms]
Oct 30 11:42:29.851: INFO: Created: latency-svc-wk88m
Oct 30 11:42:29.894: INFO: Got endpoints: latency-svc-nw96m [750.672378ms]
Oct 30 11:42:29.943: INFO: Got endpoints: latency-svc-4lkr4 [750.525685ms]
Oct 30 11:42:29.994: INFO: Got endpoints: latency-svc-szlpb [750.209915ms]
Oct 30 11:42:30.043: INFO: Got endpoints: latency-svc-7ghqg [749.548609ms]
Oct 30 11:42:30.094: INFO: Got endpoints: latency-svc-fzzdm [749.940055ms]
Oct 30 11:42:30.144: INFO: Got endpoints: latency-svc-d5vnm [751.085309ms]
Oct 30 11:42:30.194: INFO: Got endpoints: latency-svc-km292 [750.498135ms]
Oct 30 11:42:30.243: INFO: Got endpoints: latency-svc-fg8cg [747.866255ms]
Oct 30 11:42:30.295: INFO: Got endpoints: latency-svc-v4s7s [751.304715ms]
Oct 30 11:42:30.344: INFO: Got endpoints: latency-svc-zqs2p [750.719737ms]
Oct 30 11:42:30.393: INFO: Got endpoints: latency-svc-nczn6 [748.633453ms]
Oct 30 11:42:30.443: INFO: Got endpoints: latency-svc-jsv9s [750.52816ms]
Oct 30 11:42:30.494: INFO: Got endpoints: latency-svc-rnsgx [749.782191ms]
Oct 30 11:42:30.543: INFO: Got endpoints: latency-svc-9vffp [749.157727ms]
Oct 30 11:42:30.594: INFO: Got endpoints: latency-svc-wk88m [749.234759ms]
Oct 30 11:42:30.594: INFO: Latencies: [13.945735ms 16.368518ms 20.573517ms 28.09502ms 28.542462ms 36.12745ms 38.488578ms 43.317417ms 47.811045ms 56.712034ms 61.997881ms 68.512752ms 72.681547ms 74.882159ms 78.654506ms 79.199814ms 80.660728ms 80.73437ms 83.122335ms 93.400654ms 98.922428ms 100.367021ms 103.793616ms 109.713463ms 109.736797ms 110.525815ms 112.425939ms 112.557479ms 113.03368ms 113.579798ms 116.016589ms 116.368762ms 116.815051ms 140.816619ms 169.260501ms 216.464318ms 258.123531ms 299.455491ms 338.377268ms 379.937483ms 422.355403ms 462.3293ms 508.162904ms 554.523483ms 597.09623ms 644.445645ms 687.251626ms 733.421816ms 745.796488ms 747.609253ms 747.846608ms 747.866255ms 748.023662ms 748.363266ms 748.394684ms 748.575942ms 748.633453ms 748.772596ms 748.790132ms 748.816692ms 748.911185ms 748.952844ms 748.95675ms 749.019341ms 749.070502ms 749.079681ms 749.098281ms 749.157727ms 749.177736ms 749.218879ms 749.234759ms 749.260293ms 749.285603ms 749.312747ms 749.33887ms 749.360248ms 749.398995ms 749.41407ms 749.434867ms 749.435829ms 749.445374ms 749.459435ms 749.463152ms 749.478018ms 749.520452ms 749.535309ms 749.546107ms 749.548609ms 749.55875ms 749.566672ms 749.611498ms 749.616394ms 749.618483ms 749.640868ms 749.643714ms 749.653483ms 749.680797ms 749.683991ms 749.695091ms 749.709854ms 749.728482ms 749.736797ms 749.782191ms 749.804406ms 749.80509ms 749.809135ms 749.833472ms 749.838395ms 749.853335ms 749.88876ms 749.894404ms 749.906396ms 749.913168ms 749.923393ms 749.92528ms 749.933609ms 749.939958ms 749.940055ms 749.962551ms 749.981371ms 749.993221ms 749.993379ms 749.999479ms 750.018393ms 750.018832ms 750.025744ms 750.038562ms 750.039553ms 750.053839ms 750.077567ms 750.087061ms 750.111543ms 750.120863ms 750.13108ms 750.137731ms 750.143629ms 750.150564ms 750.155693ms 750.157278ms 750.171679ms 750.174369ms 750.175311ms 750.188398ms 750.209915ms 750.217464ms 750.221231ms 750.232026ms 750.235317ms 750.260585ms 750.275257ms 750.284374ms 750.296406ms 750.299388ms 750.314814ms 750.317127ms 750.32853ms 750.33598ms 750.341313ms 750.366405ms 750.393455ms 750.397216ms 750.42213ms 750.424481ms 750.436144ms 750.459493ms 750.465401ms 750.480878ms 750.48095ms 750.498135ms 750.525685ms 750.52816ms 750.541134ms 750.557853ms 750.590898ms 750.620637ms 750.622663ms 750.647973ms 750.671664ms 750.672378ms 750.687075ms 750.688571ms 750.692873ms 750.714506ms 750.716805ms 750.719737ms 750.746579ms 750.766383ms 750.820258ms 750.92833ms 751.085309ms 751.146775ms 751.152403ms 751.304715ms 751.326981ms 751.341773ms 751.493354ms 751.512809ms 751.642035ms 752.027185ms 753.972931ms]
Oct 30 11:42:30.594: INFO: 50 %ile: 749.728482ms
Oct 30 11:42:30.595: INFO: 90 %ile: 750.688571ms
Oct 30 11:42:30.595: INFO: 99 %ile: 752.027185ms
Oct 30 11:42:30.595: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 11:42:30.595: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svc-latency-553" for this suite.
Oct 30 11:42:50.605: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:42:50.675: INFO: namespace svc-latency-553 deletion completed in 20.07695021s

• [SLOW TEST:30.926 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should not be very high  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 11:42:50.675: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-5915
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Oct 30 11:42:50.809: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ddff63ca-dbcc-4de3-a807-487f8c2ab3f6" in namespace "downward-api-5915" to be "success or failure"
Oct 30 11:42:50.812: INFO: Pod "downwardapi-volume-ddff63ca-dbcc-4de3-a807-487f8c2ab3f6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.770461ms
Oct 30 11:42:52.814: INFO: Pod "downwardapi-volume-ddff63ca-dbcc-4de3-a807-487f8c2ab3f6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005068753s
STEP: Saw pod success
Oct 30 11:42:52.814: INFO: Pod "downwardapi-volume-ddff63ca-dbcc-4de3-a807-487f8c2ab3f6" satisfied condition "success or failure"
Oct 30 11:42:52.816: INFO: Trying to get logs from node ip-10-1-5-63.eu-central-1.compute.internal pod downwardapi-volume-ddff63ca-dbcc-4de3-a807-487f8c2ab3f6 container client-container: <nil>
STEP: delete the pod
Oct 30 11:42:52.830: INFO: Waiting for pod downwardapi-volume-ddff63ca-dbcc-4de3-a807-487f8c2ab3f6 to disappear
Oct 30 11:42:52.832: INFO: Pod downwardapi-volume-ddff63ca-dbcc-4de3-a807-487f8c2ab3f6 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 11:42:52.832: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5915" for this suite.
Oct 30 11:42:58.842: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:42:58.908: INFO: namespace downward-api-5915 deletion completed in 6.073575017s

• [SLOW TEST:8.234 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 11:42:58.909: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-5631
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-map-89e61c3c-da6f-4846-b282-2a66da6bcd04
STEP: Creating a pod to test consume configMaps
Oct 30 11:42:59.044: INFO: Waiting up to 5m0s for pod "pod-configmaps-7820d048-c634-415f-bf82-79212f5b3410" in namespace "configmap-5631" to be "success or failure"
Oct 30 11:42:59.045: INFO: Pod "pod-configmaps-7820d048-c634-415f-bf82-79212f5b3410": Phase="Pending", Reason="", readiness=false. Elapsed: 1.72704ms
Oct 30 11:43:01.048: INFO: Pod "pod-configmaps-7820d048-c634-415f-bf82-79212f5b3410": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004502701s
STEP: Saw pod success
Oct 30 11:43:01.048: INFO: Pod "pod-configmaps-7820d048-c634-415f-bf82-79212f5b3410" satisfied condition "success or failure"
Oct 30 11:43:01.050: INFO: Trying to get logs from node ip-10-1-5-84.eu-central-1.compute.internal pod pod-configmaps-7820d048-c634-415f-bf82-79212f5b3410 container configmap-volume-test: <nil>
STEP: delete the pod
Oct 30 11:43:01.066: INFO: Waiting for pod pod-configmaps-7820d048-c634-415f-bf82-79212f5b3410 to disappear
Oct 30 11:43:01.068: INFO: Pod pod-configmaps-7820d048-c634-415f-bf82-79212f5b3410 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 11:43:01.068: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5631" for this suite.
Oct 30 11:43:07.078: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:43:07.142: INFO: namespace configmap-5631 deletion completed in 6.071045848s

• [SLOW TEST:8.233 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 11:43:07.142: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-8356
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Oct 30 11:43:07.270: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 version'
Oct 30 11:43:07.328: INFO: stderr: ""
Oct 30 11:43:07.328: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"15\", GitVersion:\"v1.15.5\", GitCommit:\"20c265fef0741dd71a66480e35bd69f18351daea\", GitTreeState:\"clean\", BuildDate:\"2019-10-15T19:16:51Z\", GoVersion:\"go1.12.10\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"15\", GitVersion:\"v1.15.5\", GitCommit:\"20c265fef0741dd71a66480e35bd69f18351daea\", GitTreeState:\"clean\", BuildDate:\"2019-10-15T19:07:57Z\", GoVersion:\"go1.12.10\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 11:43:07.329: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8356" for this suite.
Oct 30 11:43:13.341: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:43:13.408: INFO: namespace kubectl-8356 deletion completed in 6.076502046s

• [SLOW TEST:6.266 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl version
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 11:43:13.408: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replicaset-6978
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Oct 30 11:43:16.566: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 11:43:17.578: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-6978" for this suite.
Oct 30 11:43:39.587: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:43:39.657: INFO: namespace replicaset-6978 deletion completed in 22.076146061s

• [SLOW TEST:26.248 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 11:43:39.657: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-7323
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0666 on tmpfs
Oct 30 11:43:39.789: INFO: Waiting up to 5m0s for pod "pod-71b1a463-6653-4601-92b7-54e3791fdcdc" in namespace "emptydir-7323" to be "success or failure"
Oct 30 11:43:39.791: INFO: Pod "pod-71b1a463-6653-4601-92b7-54e3791fdcdc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.061857ms
Oct 30 11:43:41.794: INFO: Pod "pod-71b1a463-6653-4601-92b7-54e3791fdcdc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004626699s
STEP: Saw pod success
Oct 30 11:43:41.794: INFO: Pod "pod-71b1a463-6653-4601-92b7-54e3791fdcdc" satisfied condition "success or failure"
Oct 30 11:43:41.795: INFO: Trying to get logs from node ip-10-1-5-63.eu-central-1.compute.internal pod pod-71b1a463-6653-4601-92b7-54e3791fdcdc container test-container: <nil>
STEP: delete the pod
Oct 30 11:43:41.815: INFO: Waiting for pod pod-71b1a463-6653-4601-92b7-54e3791fdcdc to disappear
Oct 30 11:43:41.817: INFO: Pod pod-71b1a463-6653-4601-92b7-54e3791fdcdc no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 11:43:41.817: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7323" for this suite.
Oct 30 11:43:47.826: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:43:47.892: INFO: namespace emptydir-7323 deletion completed in 6.072303906s

• [SLOW TEST:8.235 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 11:43:47.892: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-8629
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Oct 30 11:43:48.037: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:watch-8629,SelfLink:/api/v1/namespaces/watch-8629/configmaps/e2e-watch-test-resource-version,UID:564455c0-1ba4-4b2e-9f3d-9d2dd0ad413f,ResourceVersion:28661,Generation:0,CreationTimestamp:2019-10-30 11:43:48 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Oct 30 11:43:48.037: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:watch-8629,SelfLink:/api/v1/namespaces/watch-8629/configmaps/e2e-watch-test-resource-version,UID:564455c0-1ba4-4b2e-9f3d-9d2dd0ad413f,ResourceVersion:28662,Generation:0,CreationTimestamp:2019-10-30 11:43:48 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 11:43:48.037: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-8629" for this suite.
Oct 30 11:43:54.047: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:43:54.115: INFO: namespace watch-8629 deletion completed in 6.074935616s

• [SLOW TEST:6.222 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 11:43:54.115: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-3542
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 11:44:54.264: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-3542" for this suite.
Oct 30 11:45:16.275: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:45:16.341: INFO: namespace container-probe-3542 deletion completed in 22.073741502s

• [SLOW TEST:82.226 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 11:45:16.342: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-4503
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating secret secrets-4503/secret-test-620af1a0-bbdb-4e09-8f4e-c2c78ae73261
STEP: Creating a pod to test consume secrets
Oct 30 11:45:16.476: INFO: Waiting up to 5m0s for pod "pod-configmaps-0d51a777-e0b4-4880-a529-131ed37220bb" in namespace "secrets-4503" to be "success or failure"
Oct 30 11:45:16.479: INFO: Pod "pod-configmaps-0d51a777-e0b4-4880-a529-131ed37220bb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.396925ms
Oct 30 11:45:18.481: INFO: Pod "pod-configmaps-0d51a777-e0b4-4880-a529-131ed37220bb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005039861s
STEP: Saw pod success
Oct 30 11:45:18.481: INFO: Pod "pod-configmaps-0d51a777-e0b4-4880-a529-131ed37220bb" satisfied condition "success or failure"
Oct 30 11:45:18.483: INFO: Trying to get logs from node ip-10-1-5-63.eu-central-1.compute.internal pod pod-configmaps-0d51a777-e0b4-4880-a529-131ed37220bb container env-test: <nil>
STEP: delete the pod
Oct 30 11:45:18.496: INFO: Waiting for pod pod-configmaps-0d51a777-e0b4-4880-a529-131ed37220bb to disappear
Oct 30 11:45:18.498: INFO: Pod pod-configmaps-0d51a777-e0b4-4880-a529-131ed37220bb no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 11:45:18.498: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-4503" for this suite.
Oct 30 11:45:24.508: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:45:24.573: INFO: namespace secrets-4503 deletion completed in 6.072485752s

• [SLOW TEST:8.232 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 11:45:24.573: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5836
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-feba8281-d5a8-426d-b19e-7046fe246e69
STEP: Creating a pod to test consume configMaps
Oct 30 11:45:24.711: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-2d8f14ed-d75d-4d6e-8965-f5fd98acb440" in namespace "projected-5836" to be "success or failure"
Oct 30 11:45:24.713: INFO: Pod "pod-projected-configmaps-2d8f14ed-d75d-4d6e-8965-f5fd98acb440": Phase="Pending", Reason="", readiness=false. Elapsed: 2.050331ms
Oct 30 11:45:26.716: INFO: Pod "pod-projected-configmaps-2d8f14ed-d75d-4d6e-8965-f5fd98acb440": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004533441s
STEP: Saw pod success
Oct 30 11:45:26.716: INFO: Pod "pod-projected-configmaps-2d8f14ed-d75d-4d6e-8965-f5fd98acb440" satisfied condition "success or failure"
Oct 30 11:45:26.718: INFO: Trying to get logs from node ip-10-1-5-84.eu-central-1.compute.internal pod pod-projected-configmaps-2d8f14ed-d75d-4d6e-8965-f5fd98acb440 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Oct 30 11:45:26.731: INFO: Waiting for pod pod-projected-configmaps-2d8f14ed-d75d-4d6e-8965-f5fd98acb440 to disappear
Oct 30 11:45:26.735: INFO: Pod pod-projected-configmaps-2d8f14ed-d75d-4d6e-8965-f5fd98acb440 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 11:45:26.735: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5836" for this suite.
Oct 30 11:45:32.745: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:45:32.814: INFO: namespace projected-5836 deletion completed in 6.075934387s

• [SLOW TEST:8.241 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 11:45:32.814: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-1249
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating the pod
Oct 30 11:45:35.466: INFO: Successfully updated pod "labelsupdate406bda75-e437-432b-9a5c-b34df50dcf87"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 11:45:39.485: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1249" for this suite.
Oct 30 11:46:01.495: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:46:01.563: INFO: namespace downward-api-1249 deletion completed in 22.075336359s

• [SLOW TEST:28.749 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 11:46:01.564: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3716
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Oct 30 11:46:01.695: INFO: Waiting up to 5m0s for pod "downwardapi-volume-65530fd2-d67f-46c5-9607-ac4e7fee7479" in namespace "projected-3716" to be "success or failure"
Oct 30 11:46:01.697: INFO: Pod "downwardapi-volume-65530fd2-d67f-46c5-9607-ac4e7fee7479": Phase="Pending", Reason="", readiness=false. Elapsed: 1.985971ms
Oct 30 11:46:03.706: INFO: Pod "downwardapi-volume-65530fd2-d67f-46c5-9607-ac4e7fee7479": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010959978s
STEP: Saw pod success
Oct 30 11:46:03.706: INFO: Pod "downwardapi-volume-65530fd2-d67f-46c5-9607-ac4e7fee7479" satisfied condition "success or failure"
Oct 30 11:46:03.708: INFO: Trying to get logs from node ip-10-1-5-84.eu-central-1.compute.internal pod downwardapi-volume-65530fd2-d67f-46c5-9607-ac4e7fee7479 container client-container: <nil>
STEP: delete the pod
Oct 30 11:46:03.724: INFO: Waiting for pod downwardapi-volume-65530fd2-d67f-46c5-9607-ac4e7fee7479 to disappear
Oct 30 11:46:03.726: INFO: Pod downwardapi-volume-65530fd2-d67f-46c5-9607-ac4e7fee7479 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 11:46:03.726: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3716" for this suite.
Oct 30 11:46:09.736: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:46:09.801: INFO: namespace projected-3716 deletion completed in 6.072260319s

• [SLOW TEST:8.238 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 11:46:09.801: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-9019
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 11:46:12.952: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-9019" for this suite.
Oct 30 11:46:34.962: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:46:35.050: INFO: namespace replication-controller-9019 deletion completed in 22.095932223s

• [SLOW TEST:25.249 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 11:46:35.051: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-4767
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:81
Oct 30 11:46:35.186: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Oct 30 11:46:35.191: INFO: Waiting for terminating namespaces to be deleted...
Oct 30 11:46:35.193: INFO: 
Logging pods the kubelet thinks is on node ip-10-1-5-63.eu-central-1.compute.internal before test
Oct 30 11:46:35.197: INFO: nginx-ingress-controller-867c6c9bd-9xqzh from kube-system started at 2019-10-30 10:09:20 +0000 UTC (1 container statuses recorded)
Oct 30 11:46:35.197: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Oct 30 11:46:35.197: INFO: kube-proxy-zs4h7 from kube-system started at 2019-10-30 10:03:22 +0000 UTC (1 container statuses recorded)
Oct 30 11:46:35.197: INFO: 	Container kube-proxy ready: true, restart count 0
Oct 30 11:46:35.197: INFO: calico-node-6vhqd from kube-system started at 2019-10-30 10:03:31 +0000 UTC (1 container statuses recorded)
Oct 30 11:46:35.197: INFO: 	Container calico-node ready: true, restart count 0
Oct 30 11:46:35.197: INFO: cert-exporter-67tpq from kube-system started at 2019-10-30 10:09:15 +0000 UTC (1 container statuses recorded)
Oct 30 11:46:35.197: INFO: 	Container cert-exporter ready: true, restart count 0
Oct 30 11:46:35.197: INFO: net-exporter-t8hlz from kube-system started at 2019-10-30 10:09:19 +0000 UTC (1 container statuses recorded)
Oct 30 11:46:35.197: INFO: 	Container net-exporter ready: true, restart count 0
Oct 30 11:46:35.197: INFO: sonobuoy-systemd-logs-daemon-set-2bfde314293a499b-dvzqw from sonobuoy started at 2019-10-30 10:21:44 +0000 UTC (2 container statuses recorded)
Oct 30 11:46:35.197: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Oct 30 11:46:35.197: INFO: 	Container systemd-logs ready: true, restart count 0
Oct 30 11:46:35.197: INFO: coredns-7b76874c7b-rp58r from kube-system started at 2019-10-30 10:09:10 +0000 UTC (1 container statuses recorded)
Oct 30 11:46:35.197: INFO: 	Container coredns ready: true, restart count 0
Oct 30 11:46:35.197: INFO: node-exporter-gflqf from kube-system started at 2019-10-30 10:09:37 +0000 UTC (1 container statuses recorded)
Oct 30 11:46:35.197: INFO: 	Container node-exporter ready: true, restart count 0
Oct 30 11:46:35.197: INFO: 
Logging pods the kubelet thinks is on node ip-10-1-5-65.eu-central-1.compute.internal before test
Oct 30 11:46:35.203: INFO: calico-node-t7qtg from kube-system started at 2019-10-30 10:03:31 +0000 UTC (1 container statuses recorded)
Oct 30 11:46:35.203: INFO: 	Container calico-node ready: true, restart count 0
Oct 30 11:46:35.203: INFO: coredns-7b76874c7b-g8w49 from kube-system started at 2019-10-30 10:09:10 +0000 UTC (1 container statuses recorded)
Oct 30 11:46:35.203: INFO: 	Container coredns ready: true, restart count 0
Oct 30 11:46:35.203: INFO: cert-exporter-nvkcc from kube-system started at 2019-10-30 10:09:15 +0000 UTC (1 container statuses recorded)
Oct 30 11:46:35.203: INFO: 	Container cert-exporter ready: true, restart count 0
Oct 30 11:46:35.203: INFO: metrics-server-586d4684b4-gg69x from kube-system started at 2019-10-30 10:09:35 +0000 UTC (1 container statuses recorded)
Oct 30 11:46:35.203: INFO: 	Container metrics-server ready: true, restart count 0
Oct 30 11:46:35.203: INFO: node-exporter-chfs6 from kube-system started at 2019-10-30 10:09:37 +0000 UTC (1 container statuses recorded)
Oct 30 11:46:35.203: INFO: 	Container node-exporter ready: true, restart count 0
Oct 30 11:46:35.203: INFO: nginx-ingress-controller-867c6c9bd-zvrzn from kube-system started at 2019-10-30 10:09:51 +0000 UTC (1 container statuses recorded)
Oct 30 11:46:35.203: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Oct 30 11:46:35.203: INFO: sonobuoy-systemd-logs-daemon-set-2bfde314293a499b-vdwzq from sonobuoy started at 2019-10-30 10:21:44 +0000 UTC (2 container statuses recorded)
Oct 30 11:46:35.203: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Oct 30 11:46:35.203: INFO: 	Container systemd-logs ready: true, restart count 0
Oct 30 11:46:35.203: INFO: kube-proxy-kfnkf from kube-system started at 2019-10-30 10:03:22 +0000 UTC (1 container statuses recorded)
Oct 30 11:46:35.203: INFO: 	Container kube-proxy ready: true, restart count 0
Oct 30 11:46:35.203: INFO: kube-state-metrics-586fbd9595-zhpcd from kube-system started at 2019-10-30 10:10:02 +0000 UTC (2 container statuses recorded)
Oct 30 11:46:35.203: INFO: 	Container addon-resizer ready: true, restart count 0
Oct 30 11:46:35.203: INFO: 	Container kube-state-metrics ready: true, restart count 0
Oct 30 11:46:35.203: INFO: net-exporter-tjtcq from kube-system started at 2019-10-30 10:09:20 +0000 UTC (1 container statuses recorded)
Oct 30 11:46:35.203: INFO: 	Container net-exporter ready: true, restart count 0
Oct 30 11:46:35.203: INFO: 
Logging pods the kubelet thinks is on node ip-10-1-5-84.eu-central-1.compute.internal before test
Oct 30 11:46:35.208: INFO: kube-proxy-rvmrx from kube-system started at 2019-10-30 10:04:08 +0000 UTC (1 container statuses recorded)
Oct 30 11:46:35.208: INFO: 	Container kube-proxy ready: true, restart count 0
Oct 30 11:46:35.208: INFO: sonobuoy-systemd-logs-daemon-set-2bfde314293a499b-5db6l from sonobuoy started at 2019-10-30 10:21:44 +0000 UTC (2 container statuses recorded)
Oct 30 11:46:35.208: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Oct 30 11:46:35.208: INFO: 	Container systemd-logs ready: true, restart count 0
Oct 30 11:46:35.208: INFO: node-exporter-d55hm from kube-system started at 2019-10-30 10:09:37 +0000 UTC (1 container statuses recorded)
Oct 30 11:46:35.208: INFO: 	Container node-exporter ready: true, restart count 0
Oct 30 11:46:35.208: INFO: calico-node-qhcm8 from kube-system started at 2019-10-30 10:04:08 +0000 UTC (1 container statuses recorded)
Oct 30 11:46:35.208: INFO: 	Container calico-node ready: true, restart count 0
Oct 30 11:46:35.209: INFO: tiller-deploy-5db95cf576-vw4c4 from giantswarm started at 2019-10-30 10:08:12 +0000 UTC (1 container statuses recorded)
Oct 30 11:46:35.209: INFO: 	Container tiller ready: true, restart count 0
Oct 30 11:46:35.209: INFO: net-exporter-dvjrr from kube-system started at 2019-10-30 10:09:18 +0000 UTC (1 container statuses recorded)
Oct 30 11:46:35.209: INFO: 	Container net-exporter ready: true, restart count 0
Oct 30 11:46:35.209: INFO: nginx-ingress-controller-867c6c9bd-797qw from kube-system started at 2019-10-30 10:09:20 +0000 UTC (1 container statuses recorded)
Oct 30 11:46:35.209: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Oct 30 11:46:35.209: INFO: sonobuoy from sonobuoy started at 2019-10-30 10:21:39 +0000 UTC (1 container statuses recorded)
Oct 30 11:46:35.209: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Oct 30 11:46:35.209: INFO: sonobuoy-e2e-job-43cf25cf09454f64 from sonobuoy started at 2019-10-30 10:21:44 +0000 UTC (2 container statuses recorded)
Oct 30 11:46:35.209: INFO: 	Container e2e ready: true, restart count 0
Oct 30 11:46:35.209: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct 30 11:46:35.209: INFO: cert-exporter-r65jk from kube-system started at 2019-10-30 10:09:16 +0000 UTC (1 container statuses recorded)
Oct 30 11:46:35.209: INFO: 	Container cert-exporter ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.15d26a34df846867], Reason = [FailedScheduling], Message = [0/4 nodes are available: 4 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 11:46:36.225: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-4767" for this suite.
Oct 30 11:46:42.234: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:46:42.299: INFO: namespace sched-pred-4767 deletion completed in 6.071096477s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:72

• [SLOW TEST:7.248 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 11:46:42.299: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-2988
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test use defaults
Oct 30 11:46:42.431: INFO: Waiting up to 5m0s for pod "client-containers-185ad74c-7d87-4206-bab6-2507523bb9c7" in namespace "containers-2988" to be "success or failure"
Oct 30 11:46:42.433: INFO: Pod "client-containers-185ad74c-7d87-4206-bab6-2507523bb9c7": Phase="Pending", Reason="", readiness=false. Elapsed: 1.81947ms
Oct 30 11:46:44.435: INFO: Pod "client-containers-185ad74c-7d87-4206-bab6-2507523bb9c7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003938185s
STEP: Saw pod success
Oct 30 11:46:44.435: INFO: Pod "client-containers-185ad74c-7d87-4206-bab6-2507523bb9c7" satisfied condition "success or failure"
Oct 30 11:46:44.436: INFO: Trying to get logs from node ip-10-1-5-84.eu-central-1.compute.internal pod client-containers-185ad74c-7d87-4206-bab6-2507523bb9c7 container test-container: <nil>
STEP: delete the pod
Oct 30 11:46:44.455: INFO: Waiting for pod client-containers-185ad74c-7d87-4206-bab6-2507523bb9c7 to disappear
Oct 30 11:46:44.457: INFO: Pod client-containers-185ad74c-7d87-4206-bab6-2507523bb9c7 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 11:46:44.457: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-2988" for this suite.
Oct 30 11:46:50.467: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:46:50.531: INFO: namespace containers-2988 deletion completed in 6.071462505s

• [SLOW TEST:8.232 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-network] DNS 
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 11:46:50.531: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-7862
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-7862.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-7862.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-7862.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-7862.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-7862.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-7862.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe /etc/hosts
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Oct 30 11:46:52.679: INFO: Unable to read wheezy_udp@PodARecord from pod dns-7862/dns-test-50136e4d-7316-4027-b4b2-6b98daecbf6b: the server could not find the requested resource (get pods dns-test-50136e4d-7316-4027-b4b2-6b98daecbf6b)
Oct 30 11:46:52.681: INFO: Unable to read wheezy_tcp@PodARecord from pod dns-7862/dns-test-50136e4d-7316-4027-b4b2-6b98daecbf6b: the server could not find the requested resource (get pods dns-test-50136e4d-7316-4027-b4b2-6b98daecbf6b)
Oct 30 11:46:52.688: INFO: Unable to read jessie_udp@PodARecord from pod dns-7862/dns-test-50136e4d-7316-4027-b4b2-6b98daecbf6b: the server could not find the requested resource (get pods dns-test-50136e4d-7316-4027-b4b2-6b98daecbf6b)
Oct 30 11:46:52.690: INFO: Unable to read jessie_tcp@PodARecord from pod dns-7862/dns-test-50136e4d-7316-4027-b4b2-6b98daecbf6b: the server could not find the requested resource (get pods dns-test-50136e4d-7316-4027-b4b2-6b98daecbf6b)
Oct 30 11:46:52.690: INFO: Lookups using dns-7862/dns-test-50136e4d-7316-4027-b4b2-6b98daecbf6b failed for: [wheezy_udp@PodARecord wheezy_tcp@PodARecord jessie_udp@PodARecord jessie_tcp@PodARecord]

Oct 30 11:46:57.707: INFO: DNS probes using dns-7862/dns-test-50136e4d-7316-4027-b4b2-6b98daecbf6b succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 11:46:57.714: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-7862" for this suite.
Oct 30 11:47:03.726: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:47:03.794: INFO: namespace dns-7862 deletion completed in 6.075933463s

• [SLOW TEST:13.263 seconds]
[sig-network] DNS
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 11:47:03.794: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-6295
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-893d0a76-d778-4b7a-beb9-cfa3ec65c669
STEP: Creating a pod to test consume configMaps
Oct 30 11:47:03.937: INFO: Waiting up to 5m0s for pod "pod-configmaps-9f8ce19e-0443-4d03-8927-84bd08169e04" in namespace "configmap-6295" to be "success or failure"
Oct 30 11:47:03.940: INFO: Pod "pod-configmaps-9f8ce19e-0443-4d03-8927-84bd08169e04": Phase="Pending", Reason="", readiness=false. Elapsed: 3.259432ms
Oct 30 11:47:05.942: INFO: Pod "pod-configmaps-9f8ce19e-0443-4d03-8927-84bd08169e04": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005825027s
STEP: Saw pod success
Oct 30 11:47:05.942: INFO: Pod "pod-configmaps-9f8ce19e-0443-4d03-8927-84bd08169e04" satisfied condition "success or failure"
Oct 30 11:47:05.944: INFO: Trying to get logs from node ip-10-1-5-84.eu-central-1.compute.internal pod pod-configmaps-9f8ce19e-0443-4d03-8927-84bd08169e04 container configmap-volume-test: <nil>
STEP: delete the pod
Oct 30 11:47:05.957: INFO: Waiting for pod pod-configmaps-9f8ce19e-0443-4d03-8927-84bd08169e04 to disappear
Oct 30 11:47:05.958: INFO: Pod pod-configmaps-9f8ce19e-0443-4d03-8927-84bd08169e04 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 11:47:05.959: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6295" for this suite.
Oct 30 11:47:11.967: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:47:12.032: INFO: namespace configmap-6295 deletion completed in 6.070624734s

• [SLOW TEST:8.237 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 11:47:12.032: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-5695
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Oct 30 11:47:12.159: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Oct 30 11:47:12.165: INFO: Pod name sample-pod: Found 0 pods out of 1
Oct 30 11:47:17.167: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Oct 30 11:47:17.167: INFO: Creating deployment "test-rolling-update-deployment"
Oct 30 11:47:17.170: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Oct 30 11:47:17.175: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Oct 30 11:47:19.179: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Oct 30 11:47:19.181: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
Oct 30 11:47:19.186: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment,GenerateName:,Namespace:deployment-5695,SelfLink:/apis/apps/v1/namespaces/deployment-5695/deployments/test-rolling-update-deployment,UID:b762c6b3-d93b-49d0-8cd7-5a97272d38ab,ResourceVersion:29583,Generation:1,CreationTimestamp:2019-10-30 11:47:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-10-30 11:47:17 +0000 UTC 2019-10-30 11:47:17 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-10-30 11:47:18 +0000 UTC 2019-10-30 11:47:17 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rolling-update-deployment-79f6b9d75c" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Oct 30 11:47:19.188: INFO: New ReplicaSet "test-rolling-update-deployment-79f6b9d75c" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-79f6b9d75c,GenerateName:,Namespace:deployment-5695,SelfLink:/apis/apps/v1/namespaces/deployment-5695/replicasets/test-rolling-update-deployment-79f6b9d75c,UID:68f3f1e1-0388-469e-8110-d67e28e9f9b8,ResourceVersion:29573,Generation:1,CreationTimestamp:2019-10-30 11:47:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 79f6b9d75c,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment b762c6b3-d93b-49d0-8cd7-5a97272d38ab 0xc003d92117 0xc003d92118}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 79f6b9d75c,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 79f6b9d75c,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Oct 30 11:47:19.189: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Oct 30 11:47:19.189: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-controller,GenerateName:,Namespace:deployment-5695,SelfLink:/apis/apps/v1/namespaces/deployment-5695/replicasets/test-rolling-update-controller,UID:79e21953-842f-48f5-819e-6bdc9278f094,ResourceVersion:29582,Generation:2,CreationTimestamp:2019-10-30 11:47:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305832,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment b762c6b3-d93b-49d0-8cd7-5a97272d38ab 0xc003d92047 0xc003d92048}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Oct 30 11:47:19.191: INFO: Pod "test-rolling-update-deployment-79f6b9d75c-78l2t" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-79f6b9d75c-78l2t,GenerateName:test-rolling-update-deployment-79f6b9d75c-,Namespace:deployment-5695,SelfLink:/api/v1/namespaces/deployment-5695/pods/test-rolling-update-deployment-79f6b9d75c-78l2t,UID:277e42cf-457d-4d36-afde-bcd28e3c4993,ResourceVersion:29572,Generation:0,CreationTimestamp:2019-10-30 11:47:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 79f6b9d75c,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-rolling-update-deployment-79f6b9d75c 68f3f1e1-0388-469e-8110-d67e28e9f9b8 0xc003d92a17 0xc003d92a18}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-hv7d2 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-hv7d2,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-hv7d2 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-1-5-84.eu-central-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003d92a80} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003d92aa0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:47:17 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:47:18 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:47:18 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:47:17 +0000 UTC  }],Message:,Reason:,HostIP:10.1.5.84,PodIP:192.168.4.209,StartTime:2019-10-30 11:47:17 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-10-30 11:47:18 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://52c37537e69984f9872913b99b20b9cf50b4bd9d94e90a4f5f8fa10d06af580d}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 11:47:19.191: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-5695" for this suite.
Oct 30 11:47:25.200: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:47:25.266: INFO: namespace deployment-5695 deletion completed in 6.072785947s

• [SLOW TEST:13.234 seconds]
[sig-apps] Deployment
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 11:47:25.267: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6463
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name cm-test-opt-del-35f2e696-8381-4e98-883e-1519f3dbf464
STEP: Creating configMap with name cm-test-opt-upd-abac05a2-4486-4f6c-959c-c9743d87374d
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-35f2e696-8381-4e98-883e-1519f3dbf464
STEP: Updating configmap cm-test-opt-upd-abac05a2-4486-4f6c-959c-c9743d87374d
STEP: Creating configMap with name cm-test-opt-create-e2a48581-a6f6-493e-81ae-a89fab69c8a5
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 11:47:29.473: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6463" for this suite.
Oct 30 11:47:51.482: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:47:51.546: INFO: namespace projected-6463 deletion completed in 22.070241066s

• [SLOW TEST:26.279 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 11:47:51.546: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-6177
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test env composition
Oct 30 11:47:51.677: INFO: Waiting up to 5m0s for pod "var-expansion-ba8ca75f-8af4-49d9-bb7c-baf941c39f42" in namespace "var-expansion-6177" to be "success or failure"
Oct 30 11:47:51.679: INFO: Pod "var-expansion-ba8ca75f-8af4-49d9-bb7c-baf941c39f42": Phase="Pending", Reason="", readiness=false. Elapsed: 1.891198ms
Oct 30 11:47:53.681: INFO: Pod "var-expansion-ba8ca75f-8af4-49d9-bb7c-baf941c39f42": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004140481s
STEP: Saw pod success
Oct 30 11:47:53.681: INFO: Pod "var-expansion-ba8ca75f-8af4-49d9-bb7c-baf941c39f42" satisfied condition "success or failure"
Oct 30 11:47:53.683: INFO: Trying to get logs from node ip-10-1-5-84.eu-central-1.compute.internal pod var-expansion-ba8ca75f-8af4-49d9-bb7c-baf941c39f42 container dapi-container: <nil>
STEP: delete the pod
Oct 30 11:47:53.695: INFO: Waiting for pod var-expansion-ba8ca75f-8af4-49d9-bb7c-baf941c39f42 to disappear
Oct 30 11:47:53.697: INFO: Pod var-expansion-ba8ca75f-8af4-49d9-bb7c-baf941c39f42 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 11:47:53.697: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-6177" for this suite.
Oct 30 11:47:59.706: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:47:59.771: INFO: namespace var-expansion-6177 deletion completed in 6.071486359s

• [SLOW TEST:8.225 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 11:47:59.771: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-1277
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Oct 30 11:47:59.906: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-1277,SelfLink:/api/v1/namespaces/watch-1277/configmaps/e2e-watch-test-watch-closed,UID:73d59639-5a4f-4996-ab6e-76c71c268a2f,ResourceVersion:29810,Generation:0,CreationTimestamp:2019-10-30 11:47:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Oct 30 11:47:59.906: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-1277,SelfLink:/api/v1/namespaces/watch-1277/configmaps/e2e-watch-test-watch-closed,UID:73d59639-5a4f-4996-ab6e-76c71c268a2f,ResourceVersion:29811,Generation:0,CreationTimestamp:2019-10-30 11:47:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Oct 30 11:47:59.914: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-1277,SelfLink:/api/v1/namespaces/watch-1277/configmaps/e2e-watch-test-watch-closed,UID:73d59639-5a4f-4996-ab6e-76c71c268a2f,ResourceVersion:29812,Generation:0,CreationTimestamp:2019-10-30 11:47:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Oct 30 11:47:59.914: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-1277,SelfLink:/api/v1/namespaces/watch-1277/configmaps/e2e-watch-test-watch-closed,UID:73d59639-5a4f-4996-ab6e-76c71c268a2f,ResourceVersion:29813,Generation:0,CreationTimestamp:2019-10-30 11:47:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 11:47:59.915: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-1277" for this suite.
Oct 30 11:48:05.925: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:48:05.994: INFO: namespace watch-1277 deletion completed in 6.076638908s

• [SLOW TEST:6.223 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 11:48:05.994: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-6834
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 11:48:28.239: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-6834" for this suite.
Oct 30 11:48:34.249: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:48:34.352: INFO: namespace container-runtime-6834 deletion completed in 6.110286238s

• [SLOW TEST:28.357 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  blackbox test
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
    when starting a container that exits
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 11:48:34.352: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-5699
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-map-365fd122-da24-4eb3-a46a-dd3bf680c749
STEP: Creating a pod to test consume secrets
Oct 30 11:48:34.497: INFO: Waiting up to 5m0s for pod "pod-secrets-9b9ddf1d-5e31-4f9f-8181-5c4fb73bc0d3" in namespace "secrets-5699" to be "success or failure"
Oct 30 11:48:34.499: INFO: Pod "pod-secrets-9b9ddf1d-5e31-4f9f-8181-5c4fb73bc0d3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.045772ms
Oct 30 11:48:36.501: INFO: Pod "pod-secrets-9b9ddf1d-5e31-4f9f-8181-5c4fb73bc0d3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004421508s
STEP: Saw pod success
Oct 30 11:48:36.501: INFO: Pod "pod-secrets-9b9ddf1d-5e31-4f9f-8181-5c4fb73bc0d3" satisfied condition "success or failure"
Oct 30 11:48:36.503: INFO: Trying to get logs from node ip-10-1-5-84.eu-central-1.compute.internal pod pod-secrets-9b9ddf1d-5e31-4f9f-8181-5c4fb73bc0d3 container secret-volume-test: <nil>
STEP: delete the pod
Oct 30 11:48:36.515: INFO: Waiting for pod pod-secrets-9b9ddf1d-5e31-4f9f-8181-5c4fb73bc0d3 to disappear
Oct 30 11:48:36.516: INFO: Pod pod-secrets-9b9ddf1d-5e31-4f9f-8181-5c4fb73bc0d3 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 11:48:36.517: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5699" for this suite.
Oct 30 11:48:42.525: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:48:42.591: INFO: namespace secrets-5699 deletion completed in 6.071839531s

• [SLOW TEST:8.239 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 11:48:42.591: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svcaccounts-1255
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: getting the auto-created API token
Oct 30 11:48:43.236: INFO: created pod pod-service-account-defaultsa
Oct 30 11:48:43.236: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Oct 30 11:48:43.240: INFO: created pod pod-service-account-mountsa
Oct 30 11:48:43.240: INFO: pod pod-service-account-mountsa service account token volume mount: true
Oct 30 11:48:43.249: INFO: created pod pod-service-account-nomountsa
Oct 30 11:48:43.249: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Oct 30 11:48:43.253: INFO: created pod pod-service-account-defaultsa-mountspec
Oct 30 11:48:43.253: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Oct 30 11:48:43.265: INFO: created pod pod-service-account-mountsa-mountspec
Oct 30 11:48:43.265: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Oct 30 11:48:43.274: INFO: created pod pod-service-account-nomountsa-mountspec
Oct 30 11:48:43.274: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Oct 30 11:48:43.278: INFO: created pod pod-service-account-defaultsa-nomountspec
Oct 30 11:48:43.278: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Oct 30 11:48:43.285: INFO: created pod pod-service-account-mountsa-nomountspec
Oct 30 11:48:43.285: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Oct 30 11:48:43.290: INFO: created pod pod-service-account-nomountsa-nomountspec
Oct 30 11:48:43.290: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 11:48:43.290: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-1255" for this suite.
Oct 30 11:48:49.307: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:48:49.374: INFO: namespace svcaccounts-1255 deletion completed in 6.080253034s

• [SLOW TEST:6.783 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:23
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 11:48:49.375: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-1348
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1420
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Oct 30 11:48:49.503: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-1348'
Oct 30 11:48:49.697: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Oct 30 11:48:49.698: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1426
Oct 30 11:48:51.705: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 delete deployment e2e-test-nginx-deployment --namespace=kubectl-1348'
Oct 30 11:48:51.778: INFO: stderr: ""
Oct 30 11:48:51.778: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 11:48:51.778: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1348" for this suite.
Oct 30 11:49:13.791: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:49:13.862: INFO: namespace kubectl-1348 deletion completed in 22.081208471s

• [SLOW TEST:24.487 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run default
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 11:49:13.863: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-6184
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Oct 30 11:49:13.996: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6238950c-5c4c-471b-8a9a-744ce6b2a2a0" in namespace "downward-api-6184" to be "success or failure"
Oct 30 11:49:13.999: INFO: Pod "downwardapi-volume-6238950c-5c4c-471b-8a9a-744ce6b2a2a0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.283459ms
Oct 30 11:49:16.002: INFO: Pod "downwardapi-volume-6238950c-5c4c-471b-8a9a-744ce6b2a2a0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005060091s
STEP: Saw pod success
Oct 30 11:49:16.002: INFO: Pod "downwardapi-volume-6238950c-5c4c-471b-8a9a-744ce6b2a2a0" satisfied condition "success or failure"
Oct 30 11:49:16.003: INFO: Trying to get logs from node ip-10-1-5-63.eu-central-1.compute.internal pod downwardapi-volume-6238950c-5c4c-471b-8a9a-744ce6b2a2a0 container client-container: <nil>
STEP: delete the pod
Oct 30 11:49:16.016: INFO: Waiting for pod downwardapi-volume-6238950c-5c4c-471b-8a9a-744ce6b2a2a0 to disappear
Oct 30 11:49:16.018: INFO: Pod downwardapi-volume-6238950c-5c4c-471b-8a9a-744ce6b2a2a0 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 11:49:16.019: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6184" for this suite.
Oct 30 11:49:22.027: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:49:22.093: INFO: namespace downward-api-6184 deletion completed in 6.071899058s

• [SLOW TEST:8.230 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 11:49:22.093: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-7422
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Oct 30 11:49:22.225: INFO: Waiting up to 5m0s for pod "downwardapi-volume-096e5c96-d94c-4251-a187-20701e8537d5" in namespace "downward-api-7422" to be "success or failure"
Oct 30 11:49:22.228: INFO: Pod "downwardapi-volume-096e5c96-d94c-4251-a187-20701e8537d5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.604011ms
Oct 30 11:49:24.231: INFO: Pod "downwardapi-volume-096e5c96-d94c-4251-a187-20701e8537d5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005256857s
STEP: Saw pod success
Oct 30 11:49:24.231: INFO: Pod "downwardapi-volume-096e5c96-d94c-4251-a187-20701e8537d5" satisfied condition "success or failure"
Oct 30 11:49:24.232: INFO: Trying to get logs from node ip-10-1-5-84.eu-central-1.compute.internal pod downwardapi-volume-096e5c96-d94c-4251-a187-20701e8537d5 container client-container: <nil>
STEP: delete the pod
Oct 30 11:49:24.245: INFO: Waiting for pod downwardapi-volume-096e5c96-d94c-4251-a187-20701e8537d5 to disappear
Oct 30 11:49:24.248: INFO: Pod downwardapi-volume-096e5c96-d94c-4251-a187-20701e8537d5 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 11:49:24.248: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7422" for this suite.
Oct 30 11:49:30.258: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:49:30.324: INFO: namespace downward-api-7422 deletion completed in 6.073364s

• [SLOW TEST:8.231 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 11:49:30.324: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-2751
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-map-229fa264-3454-4968-99f2-37353319bd3e
STEP: Creating a pod to test consume configMaps
Oct 30 11:49:30.459: INFO: Waiting up to 5m0s for pod "pod-configmaps-a667816d-3091-45ff-a7c1-15d473dd6c59" in namespace "configmap-2751" to be "success or failure"
Oct 30 11:49:30.460: INFO: Pod "pod-configmaps-a667816d-3091-45ff-a7c1-15d473dd6c59": Phase="Pending", Reason="", readiness=false. Elapsed: 1.716077ms
Oct 30 11:49:32.463: INFO: Pod "pod-configmaps-a667816d-3091-45ff-a7c1-15d473dd6c59": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003947609s
STEP: Saw pod success
Oct 30 11:49:32.463: INFO: Pod "pod-configmaps-a667816d-3091-45ff-a7c1-15d473dd6c59" satisfied condition "success or failure"
Oct 30 11:49:32.464: INFO: Trying to get logs from node ip-10-1-5-63.eu-central-1.compute.internal pod pod-configmaps-a667816d-3091-45ff-a7c1-15d473dd6c59 container configmap-volume-test: <nil>
STEP: delete the pod
Oct 30 11:49:32.477: INFO: Waiting for pod pod-configmaps-a667816d-3091-45ff-a7c1-15d473dd6c59 to disappear
Oct 30 11:49:32.479: INFO: Pod pod-configmaps-a667816d-3091-45ff-a7c1-15d473dd6c59 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 11:49:32.479: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2751" for this suite.
Oct 30 11:49:38.489: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:49:38.556: INFO: namespace configmap-2751 deletion completed in 6.073834647s

• [SLOW TEST:8.233 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 11:49:38.557: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-5059
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0777 on node default medium
Oct 30 11:49:38.693: INFO: Waiting up to 5m0s for pod "pod-1a8ecf98-648e-47e8-a6e2-7f388a95a4f6" in namespace "emptydir-5059" to be "success or failure"
Oct 30 11:49:38.695: INFO: Pod "pod-1a8ecf98-648e-47e8-a6e2-7f388a95a4f6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.667757ms
Oct 30 11:49:40.697: INFO: Pod "pod-1a8ecf98-648e-47e8-a6e2-7f388a95a4f6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004812458s
STEP: Saw pod success
Oct 30 11:49:40.697: INFO: Pod "pod-1a8ecf98-648e-47e8-a6e2-7f388a95a4f6" satisfied condition "success or failure"
Oct 30 11:49:40.699: INFO: Trying to get logs from node ip-10-1-5-84.eu-central-1.compute.internal pod pod-1a8ecf98-648e-47e8-a6e2-7f388a95a4f6 container test-container: <nil>
STEP: delete the pod
Oct 30 11:49:40.710: INFO: Waiting for pod pod-1a8ecf98-648e-47e8-a6e2-7f388a95a4f6 to disappear
Oct 30 11:49:40.712: INFO: Pod pod-1a8ecf98-648e-47e8-a6e2-7f388a95a4f6 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 11:49:40.712: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5059" for this suite.
Oct 30 11:49:46.722: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:49:46.788: INFO: namespace emptydir-5059 deletion completed in 6.072900244s

• [SLOW TEST:8.231 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 11:49:46.788: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-2533
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-2533.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-2533.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Oct 30 11:49:48.934: INFO: Unable to read wheezy_udp@PodARecord from pod dns-2533/dns-test-2302899e-71ed-44c8-bc93-4327eef9409a: the server could not find the requested resource (get pods dns-test-2302899e-71ed-44c8-bc93-4327eef9409a)
Oct 30 11:49:48.936: INFO: Unable to read wheezy_tcp@PodARecord from pod dns-2533/dns-test-2302899e-71ed-44c8-bc93-4327eef9409a: the server could not find the requested resource (get pods dns-test-2302899e-71ed-44c8-bc93-4327eef9409a)
Oct 30 11:49:48.942: INFO: Unable to read jessie_udp@PodARecord from pod dns-2533/dns-test-2302899e-71ed-44c8-bc93-4327eef9409a: the server could not find the requested resource (get pods dns-test-2302899e-71ed-44c8-bc93-4327eef9409a)
Oct 30 11:49:48.944: INFO: Unable to read jessie_tcp@PodARecord from pod dns-2533/dns-test-2302899e-71ed-44c8-bc93-4327eef9409a: the server could not find the requested resource (get pods dns-test-2302899e-71ed-44c8-bc93-4327eef9409a)
Oct 30 11:49:48.944: INFO: Lookups using dns-2533/dns-test-2302899e-71ed-44c8-bc93-4327eef9409a failed for: [wheezy_udp@PodARecord wheezy_tcp@PodARecord jessie_udp@PodARecord jessie_tcp@PodARecord]

Oct 30 11:49:53.963: INFO: DNS probes using dns-2533/dns-test-2302899e-71ed-44c8-bc93-4327eef9409a succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 11:49:53.972: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-2533" for this suite.
Oct 30 11:49:59.986: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:50:00.051: INFO: namespace dns-2533 deletion completed in 6.075530204s

• [SLOW TEST:13.264 seconds]
[sig-network] DNS
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 11:50:00.052: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-2955
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W1030 11:50:06.200465      18 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Oct 30 11:50:06.200: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 11:50:06.200: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-2955" for this suite.
Oct 30 11:50:12.210: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:50:12.277: INFO: namespace gc-2955 deletion completed in 6.073787871s

• [SLOW TEST:12.225 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 11:50:12.277: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-9179
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Oct 30 11:50:12.425: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"1759fa45-f580-4e6c-922d-a87300ca81eb", Controller:(*bool)(0xc003dd4e0e), BlockOwnerDeletion:(*bool)(0xc003dd4e0f)}}
Oct 30 11:50:12.432: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"fbbcd4ed-93fd-4432-98c1-79480af00844", Controller:(*bool)(0xc00307cfc6), BlockOwnerDeletion:(*bool)(0xc00307cfc7)}}
Oct 30 11:50:12.437: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"18e929c1-f1a5-44df-bc20-0c2acab2a89e", Controller:(*bool)(0xc003dd4fde), BlockOwnerDeletion:(*bool)(0xc003dd4fdf)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 11:50:17.445: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-9179" for this suite.
Oct 30 11:50:23.459: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:50:23.530: INFO: namespace gc-9179 deletion completed in 6.083182466s

• [SLOW TEST:11.253 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 11:50:23.531: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-1616
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test override all
Oct 30 11:50:23.661: INFO: Waiting up to 5m0s for pod "client-containers-2cfaed4b-ba28-4824-9bc8-46d0b218916d" in namespace "containers-1616" to be "success or failure"
Oct 30 11:50:23.664: INFO: Pod "client-containers-2cfaed4b-ba28-4824-9bc8-46d0b218916d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.353785ms
Oct 30 11:50:25.666: INFO: Pod "client-containers-2cfaed4b-ba28-4824-9bc8-46d0b218916d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004506606s
STEP: Saw pod success
Oct 30 11:50:25.666: INFO: Pod "client-containers-2cfaed4b-ba28-4824-9bc8-46d0b218916d" satisfied condition "success or failure"
Oct 30 11:50:25.668: INFO: Trying to get logs from node ip-10-1-5-63.eu-central-1.compute.internal pod client-containers-2cfaed4b-ba28-4824-9bc8-46d0b218916d container test-container: <nil>
STEP: delete the pod
Oct 30 11:50:25.682: INFO: Waiting for pod client-containers-2cfaed4b-ba28-4824-9bc8-46d0b218916d to disappear
Oct 30 11:50:25.683: INFO: Pod client-containers-2cfaed4b-ba28-4824-9bc8-46d0b218916d no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 11:50:25.683: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-1616" for this suite.
Oct 30 11:50:31.692: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:50:31.758: INFO: namespace containers-1616 deletion completed in 6.072009193s

• [SLOW TEST:8.227 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 11:50:31.758: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2554
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Oct 30 11:50:31.891: INFO: Waiting up to 5m0s for pod "downwardapi-volume-26aa2913-b686-4b53-ba82-8c296e66f1e1" in namespace "projected-2554" to be "success or failure"
Oct 30 11:50:31.893: INFO: Pod "downwardapi-volume-26aa2913-b686-4b53-ba82-8c296e66f1e1": Phase="Pending", Reason="", readiness=false. Elapsed: 1.785588ms
Oct 30 11:50:33.895: INFO: Pod "downwardapi-volume-26aa2913-b686-4b53-ba82-8c296e66f1e1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004590501s
STEP: Saw pod success
Oct 30 11:50:33.895: INFO: Pod "downwardapi-volume-26aa2913-b686-4b53-ba82-8c296e66f1e1" satisfied condition "success or failure"
Oct 30 11:50:33.897: INFO: Trying to get logs from node ip-10-1-5-84.eu-central-1.compute.internal pod downwardapi-volume-26aa2913-b686-4b53-ba82-8c296e66f1e1 container client-container: <nil>
STEP: delete the pod
Oct 30 11:50:33.910: INFO: Waiting for pod downwardapi-volume-26aa2913-b686-4b53-ba82-8c296e66f1e1 to disappear
Oct 30 11:50:33.911: INFO: Pod downwardapi-volume-26aa2913-b686-4b53-ba82-8c296e66f1e1 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 11:50:33.911: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2554" for this suite.
Oct 30 11:50:39.921: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:50:39.987: INFO: namespace projected-2554 deletion completed in 6.072539869s

• [SLOW TEST:8.228 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 11:50:39.987: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename prestop
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in prestop-2893
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pre_stop.go:167
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating server pod server in namespace prestop-2893
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace prestop-2893
STEP: Deleting pre-stop pod
Oct 30 11:50:53.160: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 11:50:53.164: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "prestop-2893" for this suite.
Oct 30 11:51:31.173: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:51:31.238: INFO: namespace prestop-2893 deletion completed in 38.071367959s

• [SLOW TEST:51.251 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 11:51:31.239: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-7232
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
Oct 30 11:51:31.366: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 11:51:34.059: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-7232" for this suite.
Oct 30 11:51:40.069: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:51:40.134: INFO: namespace init-container-7232 deletion completed in 6.072660635s

• [SLOW TEST:8.896 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 11:51:40.135: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-7595
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-1065a9a8-d9d9-4276-8946-980d6beb5bc8
STEP: Creating a pod to test consume configMaps
Oct 30 11:51:40.268: INFO: Waiting up to 5m0s for pod "pod-configmaps-fae4ffc9-e7bd-4800-9abc-15563f7b479f" in namespace "configmap-7595" to be "success or failure"
Oct 30 11:51:40.270: INFO: Pod "pod-configmaps-fae4ffc9-e7bd-4800-9abc-15563f7b479f": Phase="Pending", Reason="", readiness=false. Elapsed: 1.998559ms
Oct 30 11:51:42.273: INFO: Pod "pod-configmaps-fae4ffc9-e7bd-4800-9abc-15563f7b479f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004505651s
STEP: Saw pod success
Oct 30 11:51:42.273: INFO: Pod "pod-configmaps-fae4ffc9-e7bd-4800-9abc-15563f7b479f" satisfied condition "success or failure"
Oct 30 11:51:42.274: INFO: Trying to get logs from node ip-10-1-5-84.eu-central-1.compute.internal pod pod-configmaps-fae4ffc9-e7bd-4800-9abc-15563f7b479f container configmap-volume-test: <nil>
STEP: delete the pod
Oct 30 11:51:42.290: INFO: Waiting for pod pod-configmaps-fae4ffc9-e7bd-4800-9abc-15563f7b479f to disappear
Oct 30 11:51:42.292: INFO: Pod pod-configmaps-fae4ffc9-e7bd-4800-9abc-15563f7b479f no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 11:51:42.292: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7595" for this suite.
Oct 30 11:51:48.301: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:51:48.366: INFO: namespace configmap-7595 deletion completed in 6.071422677s

• [SLOW TEST:8.231 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 11:51:48.366: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-7203
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:273
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the initial replication controller
Oct 30 11:51:48.494: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 create -f - --namespace=kubectl-7203'
Oct 30 11:51:48.639: INFO: stderr: ""
Oct 30 11:51:48.639: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Oct 30 11:51:48.639: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7203'
Oct 30 11:51:48.722: INFO: stderr: ""
Oct 30 11:51:48.722: INFO: stdout: "update-demo-nautilus-hb5nk update-demo-nautilus-kds9d "
Oct 30 11:51:48.722: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 get pods update-demo-nautilus-hb5nk -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7203'
Oct 30 11:51:48.784: INFO: stderr: ""
Oct 30 11:51:48.784: INFO: stdout: ""
Oct 30 11:51:48.784: INFO: update-demo-nautilus-hb5nk is created but not running
Oct 30 11:51:53.785: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7203'
Oct 30 11:51:53.857: INFO: stderr: ""
Oct 30 11:51:53.857: INFO: stdout: "update-demo-nautilus-hb5nk update-demo-nautilus-kds9d "
Oct 30 11:51:53.857: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 get pods update-demo-nautilus-hb5nk -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7203'
Oct 30 11:51:53.919: INFO: stderr: ""
Oct 30 11:51:53.919: INFO: stdout: "true"
Oct 30 11:51:53.920: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 get pods update-demo-nautilus-hb5nk -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7203'
Oct 30 11:51:53.998: INFO: stderr: ""
Oct 30 11:51:53.998: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Oct 30 11:51:53.998: INFO: validating pod update-demo-nautilus-hb5nk
Oct 30 11:51:54.001: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct 30 11:51:54.001: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct 30 11:51:54.001: INFO: update-demo-nautilus-hb5nk is verified up and running
Oct 30 11:51:54.001: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 get pods update-demo-nautilus-kds9d -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7203'
Oct 30 11:51:54.065: INFO: stderr: ""
Oct 30 11:51:54.065: INFO: stdout: "true"
Oct 30 11:51:54.065: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 get pods update-demo-nautilus-kds9d -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7203'
Oct 30 11:51:54.126: INFO: stderr: ""
Oct 30 11:51:54.126: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Oct 30 11:51:54.126: INFO: validating pod update-demo-nautilus-kds9d
Oct 30 11:51:54.129: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct 30 11:51:54.129: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct 30 11:51:54.129: INFO: update-demo-nautilus-kds9d is verified up and running
STEP: rolling-update to new replication controller
Oct 30 11:51:54.131: INFO: scanned /root for discovery docs: <nil>
Oct 30 11:51:54.131: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=kubectl-7203'
Oct 30 11:52:16.418: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Oct 30 11:52:16.418: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Oct 30 11:52:16.418: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7203'
Oct 30 11:52:16.485: INFO: stderr: ""
Oct 30 11:52:16.485: INFO: stdout: "update-demo-kitten-knf5g update-demo-kitten-lckd8 "
Oct 30 11:52:16.485: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 get pods update-demo-kitten-knf5g -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7203'
Oct 30 11:52:16.545: INFO: stderr: ""
Oct 30 11:52:16.545: INFO: stdout: "true"
Oct 30 11:52:16.545: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 get pods update-demo-kitten-knf5g -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7203'
Oct 30 11:52:16.609: INFO: stderr: ""
Oct 30 11:52:16.609: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Oct 30 11:52:16.609: INFO: validating pod update-demo-kitten-knf5g
Oct 30 11:52:16.612: INFO: got data: {
  "image": "kitten.jpg"
}

Oct 30 11:52:16.612: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Oct 30 11:52:16.612: INFO: update-demo-kitten-knf5g is verified up and running
Oct 30 11:52:16.612: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 get pods update-demo-kitten-lckd8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7203'
Oct 30 11:52:16.675: INFO: stderr: ""
Oct 30 11:52:16.675: INFO: stdout: "true"
Oct 30 11:52:16.675: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779704590 get pods update-demo-kitten-lckd8 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7203'
Oct 30 11:52:16.737: INFO: stderr: ""
Oct 30 11:52:16.737: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Oct 30 11:52:16.737: INFO: validating pod update-demo-kitten-lckd8
Oct 30 11:52:16.740: INFO: got data: {
  "image": "kitten.jpg"
}

Oct 30 11:52:16.740: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Oct 30 11:52:16.740: INFO: update-demo-kitten-lckd8 is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 11:52:16.741: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7203" for this suite.
Oct 30 11:52:38.750: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:52:38.822: INFO: namespace kubectl-7203 deletion completed in 22.079258726s

• [SLOW TEST:50.456 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 11:52:38.823: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-5394
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Oct 30 11:52:38.955: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f8a4755f-4da1-4b95-a88a-1653bf7dac03" in namespace "downward-api-5394" to be "success or failure"
Oct 30 11:52:38.957: INFO: Pod "downwardapi-volume-f8a4755f-4da1-4b95-a88a-1653bf7dac03": Phase="Pending", Reason="", readiness=false. Elapsed: 2.772356ms
Oct 30 11:52:40.960: INFO: Pod "downwardapi-volume-f8a4755f-4da1-4b95-a88a-1653bf7dac03": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005194113s
STEP: Saw pod success
Oct 30 11:52:40.960: INFO: Pod "downwardapi-volume-f8a4755f-4da1-4b95-a88a-1653bf7dac03" satisfied condition "success or failure"
Oct 30 11:52:40.962: INFO: Trying to get logs from node ip-10-1-5-63.eu-central-1.compute.internal pod downwardapi-volume-f8a4755f-4da1-4b95-a88a-1653bf7dac03 container client-container: <nil>
STEP: delete the pod
Oct 30 11:52:40.975: INFO: Waiting for pod downwardapi-volume-f8a4755f-4da1-4b95-a88a-1653bf7dac03 to disappear
Oct 30 11:52:40.977: INFO: Pod downwardapi-volume-f8a4755f-4da1-4b95-a88a-1653bf7dac03 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 11:52:40.977: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5394" for this suite.
Oct 30 11:52:46.987: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:52:47.051: INFO: namespace downward-api-5394 deletion completed in 6.07096337s

• [SLOW TEST:8.229 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 11:52:47.052: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-943
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-62c60f50-76a9-474f-b00e-2c0f00ba4dc8
STEP: Creating a pod to test consume secrets
Oct 30 11:52:47.187: INFO: Waiting up to 5m0s for pod "pod-secrets-7287aeba-0ac7-4f5a-a594-4779e9d90047" in namespace "secrets-943" to be "success or failure"
Oct 30 11:52:47.189: INFO: Pod "pod-secrets-7287aeba-0ac7-4f5a-a594-4779e9d90047": Phase="Pending", Reason="", readiness=false. Elapsed: 1.956521ms
Oct 30 11:52:49.191: INFO: Pod "pod-secrets-7287aeba-0ac7-4f5a-a594-4779e9d90047": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00456491s
STEP: Saw pod success
Oct 30 11:52:49.191: INFO: Pod "pod-secrets-7287aeba-0ac7-4f5a-a594-4779e9d90047" satisfied condition "success or failure"
Oct 30 11:52:49.193: INFO: Trying to get logs from node ip-10-1-5-84.eu-central-1.compute.internal pod pod-secrets-7287aeba-0ac7-4f5a-a594-4779e9d90047 container secret-volume-test: <nil>
STEP: delete the pod
Oct 30 11:52:49.205: INFO: Waiting for pod pod-secrets-7287aeba-0ac7-4f5a-a594-4779e9d90047 to disappear
Oct 30 11:52:49.208: INFO: Pod pod-secrets-7287aeba-0ac7-4f5a-a594-4779e9d90047 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 11:52:49.208: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-943" for this suite.
Oct 30 11:52:55.218: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:52:55.287: INFO: namespace secrets-943 deletion completed in 6.076356567s

• [SLOW TEST:8.235 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 30 11:52:55.287: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-kubelet-etc-hosts-5256
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Oct 30 11:52:59.438: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-5256 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 30 11:52:59.438: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
Oct 30 11:52:59.532: INFO: Exec stderr: ""
Oct 30 11:52:59.532: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-5256 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 30 11:52:59.533: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
Oct 30 11:52:59.636: INFO: Exec stderr: ""
Oct 30 11:52:59.636: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-5256 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 30 11:52:59.636: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
Oct 30 11:52:59.719: INFO: Exec stderr: ""
Oct 30 11:52:59.719: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-5256 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 30 11:52:59.719: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
Oct 30 11:52:59.803: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Oct 30 11:52:59.803: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-5256 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 30 11:52:59.803: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
Oct 30 11:52:59.889: INFO: Exec stderr: ""
Oct 30 11:52:59.889: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-5256 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 30 11:52:59.889: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
Oct 30 11:52:59.970: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Oct 30 11:52:59.970: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-5256 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 30 11:52:59.970: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
Oct 30 11:53:00.063: INFO: Exec stderr: ""
Oct 30 11:53:00.063: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-5256 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 30 11:53:00.063: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
Oct 30 11:53:00.154: INFO: Exec stderr: ""
Oct 30 11:53:00.154: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-5256 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 30 11:53:00.154: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
Oct 30 11:53:00.244: INFO: Exec stderr: ""
Oct 30 11:53:00.244: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-5256 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 30 11:53:00.244: INFO: >>> kubeConfig: /tmp/kubeconfig-779704590
Oct 30 11:53:00.332: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 30 11:53:00.332: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-kubelet-etc-hosts-5256" for this suite.
Oct 30 11:53:50.343: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:53:50.410: INFO: namespace e2e-kubelet-etc-hosts-5256 deletion completed in 50.075158037s

• [SLOW TEST:55.124 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSOct 30 11:53:50.411: INFO: Running AfterSuite actions on all nodes
Oct 30 11:53:50.411: INFO: Running AfterSuite actions on node 1
Oct 30 11:53:50.411: INFO: Skipping dumping logs from cluster

Ran 215 of 4413 Specs in 5507.262 seconds
SUCCESS! -- 215 Passed | 0 Failed | 0 Pending | 4198 Skipped
PASS

Ginkgo ran 1 suite in 1h31m48.533030175s
Test Suite Passed
