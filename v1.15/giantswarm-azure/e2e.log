I1028 16:32:23.172427      19 test_context.go:406] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-124947935
I1028 16:32:23.172563      19 e2e.go:243] Starting e2e run "6d4a3416-8f32-44a1-803c-eef1ef53e116" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1572280341 - Will randomize all specs
Will run 215 of 4413 specs

Oct 28 16:32:23.272: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
Oct 28 16:32:23.274: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Oct 28 16:32:23.300: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Oct 28 16:32:23.348: INFO: 32 / 32 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Oct 28 16:32:23.348: INFO: expected 8 pod replicas in namespace 'kube-system', 8 are Running and Ready.
Oct 28 16:32:23.348: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Oct 28 16:32:23.358: INFO: 4 / 4 pods ready in namespace 'kube-system' in daemonset 'calico-node' (0 seconds elapsed)
Oct 28 16:32:23.358: INFO: 4 / 4 pods ready in namespace 'kube-system' in daemonset 'cert-exporter' (0 seconds elapsed)
Oct 28 16:32:23.358: INFO: 4 / 4 pods ready in namespace 'kube-system' in daemonset 'kube-proxy' (0 seconds elapsed)
Oct 28 16:32:23.358: INFO: 4 / 4 pods ready in namespace 'kube-system' in daemonset 'net-exporter' (0 seconds elapsed)
Oct 28 16:32:23.358: INFO: 4 / 4 pods ready in namespace 'kube-system' in daemonset 'node-exporter' (0 seconds elapsed)
Oct 28 16:32:23.358: INFO: e2e test version: v1.15.5
Oct 28 16:32:23.360: INFO: kube-apiserver version: v1.15.5
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 16:32:23.360: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename deployment
Oct 28 16:32:23.424: INFO: Found PodSecurityPolicies; assuming PodSecurityPolicy is enabled.
Oct 28 16:32:23.441: INFO: Found ClusterRoles; assuming RBAC is enabled.
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-6638
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Oct 28 16:32:23.561: INFO: Creating deployment "nginx-deployment"
Oct 28 16:32:23.567: INFO: Waiting for observed generation 1
Oct 28 16:32:25.590: INFO: Waiting for all required pods to come up
Oct 28 16:32:25.596: INFO: Pod name nginx: Found 10 pods out of 10
STEP: ensuring each pod is running
Oct 28 16:32:33.610: INFO: Waiting for deployment "nginx-deployment" to complete
Oct 28 16:32:33.618: INFO: Updating deployment "nginx-deployment" with a non-existent image
Oct 28 16:32:33.628: INFO: Updating deployment nginx-deployment
Oct 28 16:32:33.628: INFO: Waiting for observed generation 2
Oct 28 16:32:35.644: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Oct 28 16:32:35.648: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Oct 28 16:32:35.651: INFO: Waiting for the first rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Oct 28 16:32:35.662: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Oct 28 16:32:35.662: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Oct 28 16:32:35.666: INFO: Waiting for the second rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Oct 28 16:32:35.673: INFO: Verifying that deployment "nginx-deployment" has minimum required number of available replicas
Oct 28 16:32:35.673: INFO: Scaling up the deployment "nginx-deployment" from 10 to 30
Oct 28 16:32:35.682: INFO: Updating deployment nginx-deployment
Oct 28 16:32:35.682: INFO: Waiting for the replicasets of deployment "nginx-deployment" to have desired number of replicas
Oct 28 16:32:35.714: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Oct 28 16:32:35.719: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
Oct 28 16:32:37.760: INFO: Deployment "nginx-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment,GenerateName:,Namespace:deployment-6638,SelfLink:/apis/apps/v1/namespaces/deployment-6638/deployments/nginx-deployment,UID:80f3bffc-407c-4192-add8-6b60c3aca7e5,ResourceVersion:2935,Generation:3,CreationTimestamp:2019-10-28 16:32:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*30,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:33,UpdatedReplicas:13,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[{Available False 2019-10-28 16:32:35 +0000 UTC 2019-10-28 16:32:35 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-10-28 16:32:35 +0000 UTC 2019-10-28 16:32:23 +0000 UTC ReplicaSetUpdated ReplicaSet "nginx-deployment-55fb7cb77f" is progressing.}],ReadyReplicas:8,CollisionCount:nil,},}

Oct 28 16:32:37.765: INFO: New ReplicaSet "nginx-deployment-55fb7cb77f" of Deployment "nginx-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f,GenerateName:,Namespace:deployment-6638,SelfLink:/apis/apps/v1/namespaces/deployment-6638/replicasets/nginx-deployment-55fb7cb77f,UID:66563a18-630d-4079-8890-b1838afe79a2,ResourceVersion:2931,Generation:3,CreationTimestamp:2019-10-28 16:32:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 80f3bffc-407c-4192-add8-6b60c3aca7e5 0xc00197e067 0xc00197e068}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*13,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:13,FullyLabeledReplicas:13,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Oct 28 16:32:37.765: INFO: All old ReplicaSets of Deployment "nginx-deployment":
Oct 28 16:32:37.765: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498,GenerateName:,Namespace:deployment-6638,SelfLink:/apis/apps/v1/namespaces/deployment-6638/replicasets/nginx-deployment-7b8c6f4498,UID:ec2e1d06-abf7-494f-8c10-e07d177bd866,ResourceVersion:2920,Generation:3,CreationTimestamp:2019-10-28 16:32:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 80f3bffc-407c-4192-add8-6b60c3aca7e5 0xc00197e137 0xc00197e138}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*20,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:20,FullyLabeledReplicas:20,ObservedGeneration:3,ReadyReplicas:8,AvailableReplicas:8,Conditions:[],},}
Oct 28 16:32:37.774: INFO: Pod "nginx-deployment-55fb7cb77f-68j2h" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-68j2h,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-6638,SelfLink:/api/v1/namespaces/deployment-6638/pods/nginx-deployment-55fb7cb77f-68j2h,UID:80d2a952-c589-4f67-b752-00f3725575f9,ResourceVersion:2923,Generation:0,CreationTimestamp:2019-10-28 16:32:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 66563a18-630d-4079-8890-b1838afe79a2 0xc00197ea90 0xc00197ea91}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-fr5f4 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-fr5f4,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-fr5f4 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kh4ga-worker-000000,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00197eb00} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00197eb20}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-28 16:32:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-28 16:32:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-28 16:32:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-28 16:32:35 +0000 UTC  }],Message:,Reason:,HostIP:10.2.1.4,PodIP:,StartTime:2019-10-28 16:32:35 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 28 16:32:37.775: INFO: Pod "nginx-deployment-55fb7cb77f-7ms88" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-7ms88,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-6638,SelfLink:/api/v1/namespaces/deployment-6638/pods/nginx-deployment-55fb7cb77f-7ms88,UID:deb699e8-9d2f-4fb9-a87c-9f3110cb70cf,ResourceVersion:2987,Generation:0,CreationTimestamp:2019-10-28 16:32:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.2.129.11/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 66563a18-630d-4079-8890-b1838afe79a2 0xc00197ec00 0xc00197ec01}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-fr5f4 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-fr5f4,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-fr5f4 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kh4ga-worker-000002,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00197ec70} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00197ec90}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-28 16:32:33 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-28 16:32:33 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-28 16:32:33 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-28 16:32:33 +0000 UTC  }],Message:,Reason:,HostIP:10.2.1.6,PodIP:10.2.129.11,StartTime:2019-10-28 16:32:33 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: manifest for nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 28 16:32:37.775: INFO: Pod "nginx-deployment-55fb7cb77f-blghh" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-blghh,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-6638,SelfLink:/api/v1/namespaces/deployment-6638/pods/nginx-deployment-55fb7cb77f-blghh,UID:0e2ce87e-98c7-437b-9b78-aa810d4ed9e0,ResourceVersion:2978,Generation:0,CreationTimestamp:2019-10-28 16:32:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.2.130.12/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 66563a18-630d-4079-8890-b1838afe79a2 0xc00197ed90 0xc00197ed91}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-fr5f4 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-fr5f4,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-fr5f4 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kh4ga-worker-000000,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00197ee00} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00197ee20}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-28 16:32:33 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-28 16:32:33 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-28 16:32:33 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-28 16:32:33 +0000 UTC  }],Message:,Reason:,HostIP:10.2.1.4,PodIP:10.2.130.12,StartTime:2019-10-28 16:32:33 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: manifest for nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 28 16:32:37.775: INFO: Pod "nginx-deployment-55fb7cb77f-d8wpv" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-d8wpv,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-6638,SelfLink:/api/v1/namespaces/deployment-6638/pods/nginx-deployment-55fb7cb77f-d8wpv,UID:4368d095-6258-4aee-addc-628ac31515bd,ResourceVersion:2989,Generation:0,CreationTimestamp:2019-10-28 16:32:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.2.131.12/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 66563a18-630d-4079-8890-b1838afe79a2 0xc00197ef20 0xc00197ef21}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-fr5f4 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-fr5f4,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-fr5f4 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kh4ga-worker-000003,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00197ef90} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00197efb0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-28 16:32:33 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-28 16:32:33 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-28 16:32:33 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-28 16:32:33 +0000 UTC  }],Message:,Reason:,HostIP:10.2.1.7,PodIP:10.2.131.12,StartTime:2019-10-28 16:32:33 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: manifest for nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 28 16:32:37.775: INFO: Pod "nginx-deployment-55fb7cb77f-drnzq" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-drnzq,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-6638,SelfLink:/api/v1/namespaces/deployment-6638/pods/nginx-deployment-55fb7cb77f-drnzq,UID:da5811d4-c88d-48bd-b7e4-d276afdead80,ResourceVersion:2980,Generation:0,CreationTimestamp:2019-10-28 16:32:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 66563a18-630d-4079-8890-b1838afe79a2 0xc00197f0a0 0xc00197f0a1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-fr5f4 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-fr5f4,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-fr5f4 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kh4ga-worker-000003,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00197f110} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00197f130}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-28 16:32:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-28 16:32:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-28 16:32:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-28 16:32:35 +0000 UTC  }],Message:,Reason:,HostIP:10.2.1.7,PodIP:,StartTime:2019-10-28 16:32:35 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 28 16:32:37.776: INFO: Pod "nginx-deployment-55fb7cb77f-fxzdr" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-fxzdr,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-6638,SelfLink:/api/v1/namespaces/deployment-6638/pods/nginx-deployment-55fb7cb77f-fxzdr,UID:f2efe7ba-8f82-4e9b-9497-8e7a9d0a7b0c,ResourceVersion:2944,Generation:0,CreationTimestamp:2019-10-28 16:32:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 66563a18-630d-4079-8890-b1838afe79a2 0xc00197f200 0xc00197f201}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-fr5f4 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-fr5f4,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-fr5f4 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kh4ga-worker-000002,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00197f270} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00197f290}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-28 16:32:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-28 16:32:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-28 16:32:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-28 16:32:35 +0000 UTC  }],Message:,Reason:,HostIP:10.2.1.6,PodIP:,StartTime:2019-10-28 16:32:35 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 28 16:32:37.776: INFO: Pod "nginx-deployment-55fb7cb77f-hr7g9" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-hr7g9,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-6638,SelfLink:/api/v1/namespaces/deployment-6638/pods/nginx-deployment-55fb7cb77f-hr7g9,UID:0e732159-5920-4fbf-a7c9-f5c3278802ec,ResourceVersion:2848,Generation:0,CreationTimestamp:2019-10-28 16:32:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.2.130.13/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 66563a18-630d-4079-8890-b1838afe79a2 0xc00197f370 0xc00197f371}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-fr5f4 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-fr5f4,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-fr5f4 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kh4ga-worker-000000,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00197f3e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00197f400}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-28 16:32:33 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-28 16:32:33 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-28 16:32:33 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-28 16:32:33 +0000 UTC  }],Message:,Reason:,HostIP:10.2.1.4,PodIP:,StartTime:2019-10-28 16:32:33 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 28 16:32:37.776: INFO: Pod "nginx-deployment-55fb7cb77f-lcp45" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-lcp45,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-6638,SelfLink:/api/v1/namespaces/deployment-6638/pods/nginx-deployment-55fb7cb77f-lcp45,UID:269d0b68-c308-4c1b-b783-589368244505,ResourceVersion:2960,Generation:0,CreationTimestamp:2019-10-28 16:32:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 66563a18-630d-4079-8890-b1838afe79a2 0xc00197f4d0 0xc00197f4d1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-fr5f4 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-fr5f4,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-fr5f4 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kh4ga-worker-000002,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00197f540} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00197f560}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-28 16:32:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-28 16:32:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-28 16:32:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-28 16:32:35 +0000 UTC  }],Message:,Reason:,HostIP:10.2.1.6,PodIP:,StartTime:2019-10-28 16:32:35 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 28 16:32:37.777: INFO: Pod "nginx-deployment-55fb7cb77f-mbnl5" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-mbnl5,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-6638,SelfLink:/api/v1/namespaces/deployment-6638/pods/nginx-deployment-55fb7cb77f-mbnl5,UID:15a1f6f6-4921-464c-919a-1537295849ac,ResourceVersion:2918,Generation:0,CreationTimestamp:2019-10-28 16:32:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 66563a18-630d-4079-8890-b1838afe79a2 0xc00197f630 0xc00197f631}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-fr5f4 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-fr5f4,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-fr5f4 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kh4ga-worker-000002,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00197f6a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00197f6c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-28 16:32:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-28 16:32:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-28 16:32:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-28 16:32:35 +0000 UTC  }],Message:,Reason:,HostIP:10.2.1.6,PodIP:,StartTime:2019-10-28 16:32:35 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 28 16:32:37.777: INFO: Pod "nginx-deployment-55fb7cb77f-p9vtf" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-p9vtf,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-6638,SelfLink:/api/v1/namespaces/deployment-6638/pods/nginx-deployment-55fb7cb77f-p9vtf,UID:1a5fe3e0-c45f-4fd1-ae5c-43e6cbb4183d,ResourceVersion:2939,Generation:0,CreationTimestamp:2019-10-28 16:32:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 66563a18-630d-4079-8890-b1838afe79a2 0xc00197f790 0xc00197f791}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-fr5f4 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-fr5f4,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-fr5f4 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kh4ga-worker-000003,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00197f800} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00197f820}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-28 16:32:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-28 16:32:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-28 16:32:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-28 16:32:35 +0000 UTC  }],Message:,Reason:,HostIP:10.2.1.7,PodIP:,StartTime:2019-10-28 16:32:35 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 28 16:32:37.777: INFO: Pod "nginx-deployment-55fb7cb77f-vcd78" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-vcd78,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-6638,SelfLink:/api/v1/namespaces/deployment-6638/pods/nginx-deployment-55fb7cb77f-vcd78,UID:84783e2a-df2f-4471-b5ff-cd6c1e242859,ResourceVersion:2911,Generation:0,CreationTimestamp:2019-10-28 16:32:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 66563a18-630d-4079-8890-b1838afe79a2 0xc00197f8f0 0xc00197f8f1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-fr5f4 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-fr5f4,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-fr5f4 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kh4ga-worker-000000,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00197f960} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00197f980}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-28 16:32:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-28 16:32:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-28 16:32:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-28 16:32:35 +0000 UTC  }],Message:,Reason:,HostIP:10.2.1.4,PodIP:,StartTime:2019-10-28 16:32:35 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 28 16:32:37.778: INFO: Pod "nginx-deployment-55fb7cb77f-ww55w" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-ww55w,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-6638,SelfLink:/api/v1/namespaces/deployment-6638/pods/nginx-deployment-55fb7cb77f-ww55w,UID:6e33428f-3d51-4ff5-b115-f2e18ba621b4,ResourceVersion:2922,Generation:0,CreationTimestamp:2019-10-28 16:32:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 66563a18-630d-4079-8890-b1838afe79a2 0xc00197fa50 0xc00197fa51}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-fr5f4 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-fr5f4,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-fr5f4 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kh4ga-worker-000003,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00197fac0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00197fae0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-28 16:32:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-28 16:32:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-28 16:32:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-28 16:32:35 +0000 UTC  }],Message:,Reason:,HostIP:10.2.1.7,PodIP:,StartTime:2019-10-28 16:32:35 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 28 16:32:37.778: INFO: Pod "nginx-deployment-55fb7cb77f-wzvqq" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-wzvqq,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-6638,SelfLink:/api/v1/namespaces/deployment-6638/pods/nginx-deployment-55fb7cb77f-wzvqq,UID:e70c4129-2537-4fd6-9213-8ae5547ab7c6,ResourceVersion:2853,Generation:0,CreationTimestamp:2019-10-28 16:32:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.2.131.13/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 66563a18-630d-4079-8890-b1838afe79a2 0xc00197fbc0 0xc00197fbc1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-fr5f4 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-fr5f4,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-fr5f4 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kh4ga-worker-000003,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00197fc30} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00197fc50}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-28 16:32:33 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-28 16:32:33 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-28 16:32:33 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-28 16:32:33 +0000 UTC  }],Message:,Reason:,HostIP:10.2.1.7,PodIP:,StartTime:2019-10-28 16:32:33 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 28 16:32:37.778: INFO: Pod "nginx-deployment-7b8c6f4498-4wdrm" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-4wdrm,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-6638,SelfLink:/api/v1/namespaces/deployment-6638/pods/nginx-deployment-7b8c6f4498-4wdrm,UID:a3816fc6-212e-49ac-a0df-090cd5f8900b,ResourceVersion:2773,Generation:0,CreationTimestamp:2019-10-28 16:32:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.2.131.10/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 ec2e1d06-abf7-494f-8c10-e07d177bd866 0xc00197fd30 0xc00197fd31}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-fr5f4 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-fr5f4,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-fr5f4 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kh4ga-worker-000003,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00197fd90} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00197fdb0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-28 16:32:23 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-10-28 16:32:31 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-10-28 16:32:31 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-28 16:32:23 +0000 UTC  }],Message:,Reason:,HostIP:10.2.1.7,PodIP:10.2.131.10,StartTime:2019-10-28 16:32:23 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-10-28 16:32:30 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://a67150314c6334e39a90b6e0e50e10de4cfde57d489f6f5fb5dd2703f3bbcb08}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 28 16:32:37.778: INFO: Pod "nginx-deployment-7b8c6f4498-7llgq" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-7llgq,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-6638,SelfLink:/api/v1/namespaces/deployment-6638/pods/nginx-deployment-7b8c6f4498-7llgq,UID:da0eb81b-34e3-468c-8bcf-93ca1b2f4ce0,ResourceVersion:2930,Generation:0,CreationTimestamp:2019-10-28 16:32:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 ec2e1d06-abf7-494f-8c10-e07d177bd866 0xc00197fe80 0xc00197fe81}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-fr5f4 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-fr5f4,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-fr5f4 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kh4ga-worker-000003,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00197fee0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00197ff00}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-28 16:32:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-28 16:32:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-28 16:32:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-28 16:32:35 +0000 UTC  }],Message:,Reason:,HostIP:10.2.1.7,PodIP:,StartTime:2019-10-28 16:32:35 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 28 16:32:37.778: INFO: Pod "nginx-deployment-7b8c6f4498-b4rc6" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-b4rc6,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-6638,SelfLink:/api/v1/namespaces/deployment-6638/pods/nginx-deployment-7b8c6f4498-b4rc6,UID:0d2d0dff-4d06-420c-a946-4896f95f6ff4,ResourceVersion:2732,Generation:0,CreationTimestamp:2019-10-28 16:32:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.2.129.8/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 ec2e1d06-abf7-494f-8c10-e07d177bd866 0xc00197ffd0 0xc00197ffd1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-fr5f4 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-fr5f4,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-fr5f4 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kh4ga-worker-000002,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001a8a030} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001a8a050}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-28 16:32:23 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-10-28 16:32:28 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-10-28 16:32:28 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-28 16:32:23 +0000 UTC  }],Message:,Reason:,HostIP:10.2.1.6,PodIP:10.2.129.8,StartTime:2019-10-28 16:32:23 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-10-28 16:32:28 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://bf73c344c6cd2a7da57ae87f6635a21d68c447ea06b48ba332de4fd000bc9b68}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 28 16:32:37.779: INFO: Pod "nginx-deployment-7b8c6f4498-glhtt" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-glhtt,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-6638,SelfLink:/api/v1/namespaces/deployment-6638/pods/nginx-deployment-7b8c6f4498-glhtt,UID:2590957b-6ba6-41db-9229-7fb31caac8f5,ResourceVersion:2743,Generation:0,CreationTimestamp:2019-10-28 16:32:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.2.130.9/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 ec2e1d06-abf7-494f-8c10-e07d177bd866 0xc001a8a130 0xc001a8a131}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-fr5f4 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-fr5f4,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-fr5f4 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kh4ga-worker-000000,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001a8a190} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001a8a1b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-28 16:32:23 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-10-28 16:32:29 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-10-28 16:32:29 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-28 16:32:23 +0000 UTC  }],Message:,Reason:,HostIP:10.2.1.4,PodIP:10.2.130.9,StartTime:2019-10-28 16:32:23 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-10-28 16:32:29 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://25eddfeb648b26d22b96024489c7df842f4dc7a6e9f43926279285629d4bff41}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 28 16:32:37.779: INFO: Pod "nginx-deployment-7b8c6f4498-gqwlx" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-gqwlx,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-6638,SelfLink:/api/v1/namespaces/deployment-6638/pods/nginx-deployment-7b8c6f4498-gqwlx,UID:a5fbc112-f6f8-4424-85b7-e6179012ab12,ResourceVersion:2946,Generation:0,CreationTimestamp:2019-10-28 16:32:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 ec2e1d06-abf7-494f-8c10-e07d177bd866 0xc001a8a280 0xc001a8a281}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-fr5f4 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-fr5f4,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-fr5f4 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kh4ga-worker-000003,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001a8a2e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001a8a300}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-28 16:32:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-28 16:32:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-28 16:32:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-28 16:32:35 +0000 UTC  }],Message:,Reason:,HostIP:10.2.1.7,PodIP:,StartTime:2019-10-28 16:32:35 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 28 16:32:37.779: INFO: Pod "nginx-deployment-7b8c6f4498-j9cmw" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-j9cmw,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-6638,SelfLink:/api/v1/namespaces/deployment-6638/pods/nginx-deployment-7b8c6f4498-j9cmw,UID:3fa7db39-0f67-41b4-a3cf-95f5ff47b544,ResourceVersion:2759,Generation:0,CreationTimestamp:2019-10-28 16:32:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.2.130.11/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 ec2e1d06-abf7-494f-8c10-e07d177bd866 0xc001a8a3d0 0xc001a8a3d1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-fr5f4 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-fr5f4,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-fr5f4 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kh4ga-worker-000000,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001a8a430} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001a8a450}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-28 16:32:23 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-10-28 16:32:30 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-10-28 16:32:30 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-28 16:32:23 +0000 UTC  }],Message:,Reason:,HostIP:10.2.1.4,PodIP:10.2.130.11,StartTime:2019-10-28 16:32:23 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-10-28 16:32:29 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://5f4967dce62d9a566fcd6988e5b646172f79bcf80644dccc04f1fd8dba900fed}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 28 16:32:37.779: INFO: Pod "nginx-deployment-7b8c6f4498-kd949" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-kd949,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-6638,SelfLink:/api/v1/namespaces/deployment-6638/pods/nginx-deployment-7b8c6f4498-kd949,UID:1c079823-8921-44a3-96ad-caace4a7e3df,ResourceVersion:2740,Generation:0,CreationTimestamp:2019-10-28 16:32:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.2.131.8/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 ec2e1d06-abf7-494f-8c10-e07d177bd866 0xc001a8a530 0xc001a8a531}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-fr5f4 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-fr5f4,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-fr5f4 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kh4ga-worker-000003,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001a8a590} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001a8a5b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-28 16:32:23 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-10-28 16:32:29 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-10-28 16:32:29 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-28 16:32:23 +0000 UTC  }],Message:,Reason:,HostIP:10.2.1.7,PodIP:10.2.131.8,StartTime:2019-10-28 16:32:23 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-10-28 16:32:28 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://a68222c95dc61b92494e648b97d70b7232b8a6348e9b56e0f3db0558d2d07ec6}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 28 16:32:37.782: INFO: Pod "nginx-deployment-7b8c6f4498-kn9p9" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-kn9p9,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-6638,SelfLink:/api/v1/namespaces/deployment-6638/pods/nginx-deployment-7b8c6f4498-kn9p9,UID:7fc1f96b-1577-4fd5-9cc0-3c986e1e6505,ResourceVersion:2995,Generation:0,CreationTimestamp:2019-10-28 16:32:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.2.129.12/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 ec2e1d06-abf7-494f-8c10-e07d177bd866 0xc001a8a690 0xc001a8a691}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-fr5f4 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-fr5f4,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-fr5f4 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kh4ga-worker-000002,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001a8a6f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001a8a710}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-28 16:32:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-28 16:32:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-28 16:32:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-28 16:32:35 +0000 UTC  }],Message:,Reason:,HostIP:10.2.1.6,PodIP:,StartTime:2019-10-28 16:32:35 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 28 16:32:37.783: INFO: Pod "nginx-deployment-7b8c6f4498-lxpqx" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-lxpqx,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-6638,SelfLink:/api/v1/namespaces/deployment-6638/pods/nginx-deployment-7b8c6f4498-lxpqx,UID:b928a680-20df-451b-a914-2cf277b7fac1,ResourceVersion:2907,Generation:0,CreationTimestamp:2019-10-28 16:32:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 ec2e1d06-abf7-494f-8c10-e07d177bd866 0xc001a8a7d0 0xc001a8a7d1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-fr5f4 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-fr5f4,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-fr5f4 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kh4ga-worker-000003,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001a8a830} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001a8a850}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-28 16:32:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-28 16:32:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-28 16:32:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-28 16:32:35 +0000 UTC  }],Message:,Reason:,HostIP:10.2.1.7,PodIP:,StartTime:2019-10-28 16:32:35 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 28 16:32:37.783: INFO: Pod "nginx-deployment-7b8c6f4498-mb5pf" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-mb5pf,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-6638,SelfLink:/api/v1/namespaces/deployment-6638/pods/nginx-deployment-7b8c6f4498-mb5pf,UID:d8af9300-801d-4030-8d61-d66b4f839fa1,ResourceVersion:2936,Generation:0,CreationTimestamp:2019-10-28 16:32:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 ec2e1d06-abf7-494f-8c10-e07d177bd866 0xc001a8a910 0xc001a8a911}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-fr5f4 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-fr5f4,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-fr5f4 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kh4ga-worker-000002,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001a8a970} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001a8a990}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-28 16:32:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-28 16:32:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-28 16:32:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-28 16:32:35 +0000 UTC  }],Message:,Reason:,HostIP:10.2.1.6,PodIP:,StartTime:2019-10-28 16:32:35 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 28 16:32:37.783: INFO: Pod "nginx-deployment-7b8c6f4498-ppzwr" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-ppzwr,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-6638,SelfLink:/api/v1/namespaces/deployment-6638/pods/nginx-deployment-7b8c6f4498-ppzwr,UID:7b3f85b7-4f92-4645-a89f-65a341680b67,ResourceVersion:2940,Generation:0,CreationTimestamp:2019-10-28 16:32:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 ec2e1d06-abf7-494f-8c10-e07d177bd866 0xc001a8aa50 0xc001a8aa51}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-fr5f4 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-fr5f4,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-fr5f4 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kh4ga-worker-000000,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001a8aab0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001a8aad0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-28 16:32:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-28 16:32:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-28 16:32:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-28 16:32:35 +0000 UTC  }],Message:,Reason:,HostIP:10.2.1.4,PodIP:,StartTime:2019-10-28 16:32:35 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 28 16:32:37.784: INFO: Pod "nginx-deployment-7b8c6f4498-rzlrb" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-rzlrb,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-6638,SelfLink:/api/v1/namespaces/deployment-6638/pods/nginx-deployment-7b8c6f4498-rzlrb,UID:b8c23ce1-3f09-409b-b732-ac8e3552a41f,ResourceVersion:2926,Generation:0,CreationTimestamp:2019-10-28 16:32:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 ec2e1d06-abf7-494f-8c10-e07d177bd866 0xc001a8ab90 0xc001a8ab91}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-fr5f4 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-fr5f4,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-fr5f4 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kh4ga-worker-000002,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001a8abf0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001a8ac10}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-28 16:32:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-28 16:32:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-28 16:32:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-28 16:32:35 +0000 UTC  }],Message:,Reason:,HostIP:10.2.1.6,PodIP:,StartTime:2019-10-28 16:32:35 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 28 16:32:37.784: INFO: Pod "nginx-deployment-7b8c6f4498-s5mkg" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-s5mkg,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-6638,SelfLink:/api/v1/namespaces/deployment-6638/pods/nginx-deployment-7b8c6f4498-s5mkg,UID:7a702dee-e9b4-4ab9-b50c-b0fb509570e3,ResourceVersion:2963,Generation:0,CreationTimestamp:2019-10-28 16:32:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 ec2e1d06-abf7-494f-8c10-e07d177bd866 0xc001a8acd0 0xc001a8acd1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-fr5f4 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-fr5f4,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-fr5f4 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kh4ga-worker-000003,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001a8ad30} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001a8ad50}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-28 16:32:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-28 16:32:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-28 16:32:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-28 16:32:35 +0000 UTC  }],Message:,Reason:,HostIP:10.2.1.7,PodIP:,StartTime:2019-10-28 16:32:35 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 28 16:32:37.784: INFO: Pod "nginx-deployment-7b8c6f4498-tp9zk" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-tp9zk,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-6638,SelfLink:/api/v1/namespaces/deployment-6638/pods/nginx-deployment-7b8c6f4498-tp9zk,UID:ad7babf5-8a04-4c8a-a559-3212c66b2e18,ResourceVersion:2977,Generation:0,CreationTimestamp:2019-10-28 16:32:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 ec2e1d06-abf7-494f-8c10-e07d177bd866 0xc001a8ae10 0xc001a8ae11}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-fr5f4 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-fr5f4,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-fr5f4 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kh4ga-worker-000002,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001a8ae70} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001a8ae90}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-28 16:32:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-28 16:32:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-28 16:32:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-28 16:32:35 +0000 UTC  }],Message:,Reason:,HostIP:10.2.1.6,PodIP:,StartTime:2019-10-28 16:32:35 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 28 16:32:37.784: INFO: Pod "nginx-deployment-7b8c6f4498-tv5ww" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-tv5ww,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-6638,SelfLink:/api/v1/namespaces/deployment-6638/pods/nginx-deployment-7b8c6f4498-tv5ww,UID:893fc8e2-7100-4b3a-9393-514bbd9e4109,ResourceVersion:2756,Generation:0,CreationTimestamp:2019-10-28 16:32:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.2.131.9/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 ec2e1d06-abf7-494f-8c10-e07d177bd866 0xc001a8af60 0xc001a8af61}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-fr5f4 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-fr5f4,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-fr5f4 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kh4ga-worker-000003,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001a8afc0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001a8afe0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-28 16:32:23 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-10-28 16:32:30 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-10-28 16:32:30 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-28 16:32:23 +0000 UTC  }],Message:,Reason:,HostIP:10.2.1.7,PodIP:10.2.131.9,StartTime:2019-10-28 16:32:23 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-10-28 16:32:29 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://bde0661680905b2ad785e8565eaaca2d31c8fed272f55520f2b4b52b48d775d0}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 28 16:32:37.785: INFO: Pod "nginx-deployment-7b8c6f4498-vcmgv" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-vcmgv,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-6638,SelfLink:/api/v1/namespaces/deployment-6638/pods/nginx-deployment-7b8c6f4498-vcmgv,UID:68a754d2-3d20-4b9f-8e5f-5ba70324538e,ResourceVersion:2994,Generation:0,CreationTimestamp:2019-10-28 16:32:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.2.130.14/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 ec2e1d06-abf7-494f-8c10-e07d177bd866 0xc001a8b0c0 0xc001a8b0c1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-fr5f4 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-fr5f4,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-fr5f4 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kh4ga-worker-000000,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001a8b120} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001a8b140}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-28 16:32:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-28 16:32:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-28 16:32:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-28 16:32:35 +0000 UTC  }],Message:,Reason:,HostIP:10.2.1.4,PodIP:,StartTime:2019-10-28 16:32:35 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 28 16:32:37.785: INFO: Pod "nginx-deployment-7b8c6f4498-wh4m4" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-wh4m4,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-6638,SelfLink:/api/v1/namespaces/deployment-6638/pods/nginx-deployment-7b8c6f4498-wh4m4,UID:9e33a52e-cabc-4d18-9732-7fe170caa0a5,ResourceVersion:2933,Generation:0,CreationTimestamp:2019-10-28 16:32:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 ec2e1d06-abf7-494f-8c10-e07d177bd866 0xc001a8b200 0xc001a8b201}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-fr5f4 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-fr5f4,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-fr5f4 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kh4ga-worker-000000,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001a8b260} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001a8b280}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-28 16:32:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-28 16:32:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-28 16:32:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-28 16:32:35 +0000 UTC  }],Message:,Reason:,HostIP:10.2.1.4,PodIP:,StartTime:2019-10-28 16:32:35 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 28 16:32:37.785: INFO: Pod "nginx-deployment-7b8c6f4498-xf2fk" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-xf2fk,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-6638,SelfLink:/api/v1/namespaces/deployment-6638/pods/nginx-deployment-7b8c6f4498-xf2fk,UID:feaea850-06fc-44eb-98be-0d527eac7ee2,ResourceVersion:2753,Generation:0,CreationTimestamp:2019-10-28 16:32:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.2.129.9/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 ec2e1d06-abf7-494f-8c10-e07d177bd866 0xc001a8b350 0xc001a8b351}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-fr5f4 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-fr5f4,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-fr5f4 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kh4ga-worker-000002,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001a8b3b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001a8b3d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-28 16:32:23 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-10-28 16:32:30 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-10-28 16:32:30 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-28 16:32:23 +0000 UTC  }],Message:,Reason:,HostIP:10.2.1.6,PodIP:10.2.129.9,StartTime:2019-10-28 16:32:23 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-10-28 16:32:29 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://73b2244e09ec6d35821b5b83dcc046f6d103173656809d9d4dbc6700d0bf3d66}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 28 16:32:37.785: INFO: Pod "nginx-deployment-7b8c6f4498-z2d6d" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-z2d6d,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-6638,SelfLink:/api/v1/namespaces/deployment-6638/pods/nginx-deployment-7b8c6f4498-z2d6d,UID:51e4ad08-746d-4e88-82e0-1469d0245cab,ResourceVersion:2961,Generation:0,CreationTimestamp:2019-10-28 16:32:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 ec2e1d06-abf7-494f-8c10-e07d177bd866 0xc001a8b4a0 0xc001a8b4a1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-fr5f4 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-fr5f4,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-fr5f4 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kh4ga-worker-000000,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001a8b500} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001a8b520}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-28 16:32:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-28 16:32:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-28 16:32:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-28 16:32:35 +0000 UTC  }],Message:,Reason:,HostIP:10.2.1.4,PodIP:,StartTime:2019-10-28 16:32:35 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 28 16:32:37.785: INFO: Pod "nginx-deployment-7b8c6f4498-zbfbh" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-zbfbh,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-6638,SelfLink:/api/v1/namespaces/deployment-6638/pods/nginx-deployment-7b8c6f4498-zbfbh,UID:4fbf2f3d-02a1-492c-9019-4cdabf4c4ccf,ResourceVersion:2776,Generation:0,CreationTimestamp:2019-10-28 16:32:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.2.130.10/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 ec2e1d06-abf7-494f-8c10-e07d177bd866 0xc001a8b5f0 0xc001a8b5f1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-fr5f4 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-fr5f4,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-fr5f4 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kh4ga-worker-000000,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001a8b650} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001a8b670}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-28 16:32:23 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-10-28 16:32:31 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-10-28 16:32:31 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-28 16:32:23 +0000 UTC  }],Message:,Reason:,HostIP:10.2.1.4,PodIP:10.2.130.10,StartTime:2019-10-28 16:32:23 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-10-28 16:32:31 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://6ca80cde8a216977b5f2c8c1d8207eb97e929ffd833d0fc7e9abeea106ba87a8}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 16:32:37.786: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-6638" for this suite.
Oct 28 16:32:45.805: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 16:32:45.971: INFO: namespace deployment-6638 deletion completed in 8.181036627s

• [SLOW TEST:22.611 seconds]
[sig-apps] Deployment
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 16:32:45.972: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-216
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:273
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a replication controller
Oct 28 16:32:46.125: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-124947935 create -f - --namespace=kubectl-216'
Oct 28 16:32:47.460: INFO: stderr: ""
Oct 28 16:32:47.460: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Oct 28 16:32:47.460: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-124947935 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-216'
Oct 28 16:32:47.544: INFO: stderr: ""
Oct 28 16:32:47.545: INFO: stdout: "update-demo-nautilus-z8d4l update-demo-nautilus-zc6xq "
Oct 28 16:32:47.545: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-124947935 get pods update-demo-nautilus-z8d4l -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-216'
Oct 28 16:32:47.614: INFO: stderr: ""
Oct 28 16:32:47.614: INFO: stdout: ""
Oct 28 16:32:47.614: INFO: update-demo-nautilus-z8d4l is created but not running
Oct 28 16:32:52.614: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-124947935 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-216'
Oct 28 16:32:52.695: INFO: stderr: ""
Oct 28 16:32:52.695: INFO: stdout: "update-demo-nautilus-z8d4l update-demo-nautilus-zc6xq "
Oct 28 16:32:52.695: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-124947935 get pods update-demo-nautilus-z8d4l -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-216'
Oct 28 16:32:52.770: INFO: stderr: ""
Oct 28 16:32:52.770: INFO: stdout: "true"
Oct 28 16:32:52.770: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-124947935 get pods update-demo-nautilus-z8d4l -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-216'
Oct 28 16:32:52.841: INFO: stderr: ""
Oct 28 16:32:52.841: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Oct 28 16:32:52.841: INFO: validating pod update-demo-nautilus-z8d4l
Oct 28 16:32:52.850: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct 28 16:32:52.850: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct 28 16:32:52.850: INFO: update-demo-nautilus-z8d4l is verified up and running
Oct 28 16:32:52.850: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-124947935 get pods update-demo-nautilus-zc6xq -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-216'
Oct 28 16:32:52.928: INFO: stderr: ""
Oct 28 16:32:52.928: INFO: stdout: "true"
Oct 28 16:32:52.929: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-124947935 get pods update-demo-nautilus-zc6xq -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-216'
Oct 28 16:32:52.997: INFO: stderr: ""
Oct 28 16:32:52.997: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Oct 28 16:32:52.997: INFO: validating pod update-demo-nautilus-zc6xq
Oct 28 16:32:53.006: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct 28 16:32:53.006: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct 28 16:32:53.006: INFO: update-demo-nautilus-zc6xq is verified up and running
STEP: using delete to clean up resources
Oct 28 16:32:53.006: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-124947935 delete --grace-period=0 --force -f - --namespace=kubectl-216'
Oct 28 16:32:53.084: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct 28 16:32:53.084: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Oct 28 16:32:53.084: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-124947935 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-216'
Oct 28 16:32:53.163: INFO: stderr: "No resources found.\n"
Oct 28 16:32:53.163: INFO: stdout: ""
Oct 28 16:32:53.163: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-124947935 get pods -l name=update-demo --namespace=kubectl-216 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Oct 28 16:32:53.246: INFO: stderr: ""
Oct 28 16:32:53.246: INFO: stdout: "update-demo-nautilus-z8d4l\nupdate-demo-nautilus-zc6xq\n"
Oct 28 16:32:53.746: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-124947935 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-216'
Oct 28 16:32:53.825: INFO: stderr: "No resources found.\n"
Oct 28 16:32:53.825: INFO: stdout: ""
Oct 28 16:32:53.825: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-124947935 get pods -l name=update-demo --namespace=kubectl-216 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Oct 28 16:32:53.916: INFO: stderr: ""
Oct 28 16:32:53.916: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 16:32:53.916: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-216" for this suite.
Oct 28 16:33:15.937: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 16:33:16.092: INFO: namespace kubectl-216 deletion completed in 22.169638651s

• [SLOW TEST:30.120 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 16:33:16.092: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-2760
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Oct 28 16:33:16.282: INFO: Waiting up to 5m0s for pod "downwardapi-volume-2691023d-284b-47bd-9c67-00c4457938dc" in namespace "downward-api-2760" to be "success or failure"
Oct 28 16:33:16.287: INFO: Pod "downwardapi-volume-2691023d-284b-47bd-9c67-00c4457938dc": Phase="Pending", Reason="", readiness=false. Elapsed: 5.714308ms
Oct 28 16:33:18.292: INFO: Pod "downwardapi-volume-2691023d-284b-47bd-9c67-00c4457938dc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009968578s
Oct 28 16:33:20.297: INFO: Pod "downwardapi-volume-2691023d-284b-47bd-9c67-00c4457938dc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014885539s
STEP: Saw pod success
Oct 28 16:33:20.297: INFO: Pod "downwardapi-volume-2691023d-284b-47bd-9c67-00c4457938dc" satisfied condition "success or failure"
Oct 28 16:33:20.301: INFO: Trying to get logs from node kh4ga-worker-000000 pod downwardapi-volume-2691023d-284b-47bd-9c67-00c4457938dc container client-container: <nil>
STEP: delete the pod
Oct 28 16:33:20.330: INFO: Waiting for pod downwardapi-volume-2691023d-284b-47bd-9c67-00c4457938dc to disappear
Oct 28 16:33:20.343: INFO: Pod downwardapi-volume-2691023d-284b-47bd-9c67-00c4457938dc no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 16:33:20.343: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2760" for this suite.
Oct 28 16:33:26.367: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 16:33:26.519: INFO: namespace downward-api-2760 deletion completed in 6.169620727s

• [SLOW TEST:10.426 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 16:33:26.519: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5564
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Oct 28 16:33:26.686: INFO: Waiting up to 5m0s for pod "downwardapi-volume-71dfeffa-356f-4ee6-a54b-97527d0dbb56" in namespace "projected-5564" to be "success or failure"
Oct 28 16:33:26.697: INFO: Pod "downwardapi-volume-71dfeffa-356f-4ee6-a54b-97527d0dbb56": Phase="Pending", Reason="", readiness=false. Elapsed: 11.475015ms
Oct 28 16:33:28.702: INFO: Pod "downwardapi-volume-71dfeffa-356f-4ee6-a54b-97527d0dbb56": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016208636s
Oct 28 16:33:30.707: INFO: Pod "downwardapi-volume-71dfeffa-356f-4ee6-a54b-97527d0dbb56": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021218548s
STEP: Saw pod success
Oct 28 16:33:30.707: INFO: Pod "downwardapi-volume-71dfeffa-356f-4ee6-a54b-97527d0dbb56" satisfied condition "success or failure"
Oct 28 16:33:30.711: INFO: Trying to get logs from node kh4ga-worker-000003 pod downwardapi-volume-71dfeffa-356f-4ee6-a54b-97527d0dbb56 container client-container: <nil>
STEP: delete the pod
Oct 28 16:33:30.748: INFO: Waiting for pod downwardapi-volume-71dfeffa-356f-4ee6-a54b-97527d0dbb56 to disappear
Oct 28 16:33:30.759: INFO: Pod downwardapi-volume-71dfeffa-356f-4ee6-a54b-97527d0dbb56 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 16:33:30.759: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5564" for this suite.
Oct 28 16:33:36.808: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 16:33:37.015: INFO: namespace projected-5564 deletion completed in 6.237474768s

• [SLOW TEST:10.497 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 16:33:37.016: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-4728
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
Oct 28 16:33:37.183: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 16:33:43.147: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-4728" for this suite.
Oct 28 16:33:49.169: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 16:33:49.343: INFO: namespace init-container-4728 deletion completed in 6.188799446s

• [SLOW TEST:12.328 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 16:33:49.344: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-8560
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
Oct 28 16:33:59.528: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 16:33:59.528: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
W1028 16:33:59.528583      19 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
STEP: Destroying namespace "gc-8560" for this suite.
Oct 28 16:34:05.548: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 16:34:05.709: INFO: namespace gc-8560 deletion completed in 6.177039044s

• [SLOW TEST:16.366 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 16:34:05.709: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-3008
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 16:34:07.897: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-3008" for this suite.
Oct 28 16:34:59.930: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 16:35:00.098: INFO: namespace kubelet-test-3008 deletion completed in 52.1855927s

• [SLOW TEST:54.389 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when scheduling a busybox command in a pod
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:40
    should print the output to logs [NodeConformance] [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 16:35:00.098: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-9563
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 16:35:35.630: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-9563" for this suite.
Oct 28 16:35:41.653: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 16:35:41.815: INFO: namespace container-runtime-9563 deletion completed in 6.178222479s

• [SLOW TEST:41.717 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  blackbox test
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
    when starting a container that exits
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 16:35:41.816: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-7688
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:63
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Oct 28 16:35:52.085: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Oct 28 16:35:52.091: INFO: Pod pod-with-poststart-http-hook still exists
Oct 28 16:35:54.092: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Oct 28 16:35:54.096: INFO: Pod pod-with-poststart-http-hook still exists
Oct 28 16:35:56.092: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Oct 28 16:35:56.096: INFO: Pod pod-with-poststart-http-hook still exists
Oct 28 16:35:58.092: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Oct 28 16:35:58.096: INFO: Pod pod-with-poststart-http-hook still exists
Oct 28 16:36:00.092: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Oct 28 16:36:00.096: INFO: Pod pod-with-poststart-http-hook still exists
Oct 28 16:36:02.092: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Oct 28 16:36:02.098: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 16:36:02.098: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-7688" for this suite.
Oct 28 16:36:24.118: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 16:36:24.279: INFO: namespace container-lifecycle-hook-7688 deletion completed in 22.174747649s

• [SLOW TEST:42.463 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when create a pod with lifecycle hook
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 16:36:24.279: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-103
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Oct 28 16:36:24.438: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Oct 28 16:36:29.443: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Oct 28 16:36:29.443: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
Oct 28 16:36:37.485: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment,GenerateName:,Namespace:deployment-103,SelfLink:/apis/apps/v1/namespaces/deployment-103/deployments/test-cleanup-deployment,UID:82339b16-496f-4bea-85ae-1bdcd5ba78ee,ResourceVersion:4091,Generation:1,CreationTimestamp:2019-10-28 16:36:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 1,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-10-28 16:36:29 +0000 UTC 2019-10-28 16:36:29 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-10-28 16:36:36 +0000 UTC 2019-10-28 16:36:29 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-cleanup-deployment-55bbcbc84c" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Oct 28 16:36:37.489: INFO: New ReplicaSet "test-cleanup-deployment-55bbcbc84c" of Deployment "test-cleanup-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-55bbcbc84c,GenerateName:,Namespace:deployment-103,SelfLink:/apis/apps/v1/namespaces/deployment-103/replicasets/test-cleanup-deployment-55bbcbc84c,UID:63aed9f7-101a-4748-8796-326d922f5a6d,ResourceVersion:4080,Generation:1,CreationTimestamp:2019-10-28 16:36:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 55bbcbc84c,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment 82339b16-496f-4bea-85ae-1bdcd5ba78ee 0xc0005b7167 0xc0005b7168}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: 55bbcbc84c,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 55bbcbc84c,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Oct 28 16:36:37.493: INFO: Pod "test-cleanup-deployment-55bbcbc84c-x9j6r" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-55bbcbc84c-x9j6r,GenerateName:test-cleanup-deployment-55bbcbc84c-,Namespace:deployment-103,SelfLink:/api/v1/namespaces/deployment-103/pods/test-cleanup-deployment-55bbcbc84c-x9j6r,UID:4c3a08e4-3811-48cc-92a0-807580b03e4f,ResourceVersion:4079,Generation:0,CreationTimestamp:2019-10-28 16:36:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 55bbcbc84c,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.2.130.26/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-deployment-55bbcbc84c 63aed9f7-101a-4748-8796-326d922f5a6d 0xc0005b7af7 0xc0005b7af8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-vnptq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vnptq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-vnptq true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kh4ga-worker-000000,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0005b7b80} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0005b7ba0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-28 16:36:29 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-10-28 16:36:36 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-10-28 16:36:36 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-28 16:36:29 +0000 UTC  }],Message:,Reason:,HostIP:10.2.1.4,PodIP:10.2.130.26,StartTime:2019-10-28 16:36:29 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-10-28 16:36:35 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://2a7cd3ae413a44bb72e8cfc227af4dfb71712a9123d1cb78e1780f5b3caec63a}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 16:36:37.493: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-103" for this suite.
Oct 28 16:36:43.520: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 16:36:43.685: INFO: namespace deployment-103 deletion completed in 6.186265563s

• [SLOW TEST:19.406 seconds]
[sig-apps] Deployment
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 16:36:43.686: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-3972
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0777 on node default medium
Oct 28 16:36:43.848: INFO: Waiting up to 5m0s for pod "pod-a119ecce-484a-4eec-afa7-edfd54ae72cb" in namespace "emptydir-3972" to be "success or failure"
Oct 28 16:36:43.872: INFO: Pod "pod-a119ecce-484a-4eec-afa7-edfd54ae72cb": Phase="Pending", Reason="", readiness=false. Elapsed: 23.406221ms
Oct 28 16:36:45.876: INFO: Pod "pod-a119ecce-484a-4eec-afa7-edfd54ae72cb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.027860425s
Oct 28 16:36:47.881: INFO: Pod "pod-a119ecce-484a-4eec-afa7-edfd54ae72cb": Phase="Pending", Reason="", readiness=false. Elapsed: 4.032795077s
Oct 28 16:36:49.886: INFO: Pod "pod-a119ecce-484a-4eec-afa7-edfd54ae72cb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.037581474s
STEP: Saw pod success
Oct 28 16:36:49.886: INFO: Pod "pod-a119ecce-484a-4eec-afa7-edfd54ae72cb" satisfied condition "success or failure"
Oct 28 16:36:49.890: INFO: Trying to get logs from node kh4ga-worker-000003 pod pod-a119ecce-484a-4eec-afa7-edfd54ae72cb container test-container: <nil>
STEP: delete the pod
Oct 28 16:36:49.911: INFO: Waiting for pod pod-a119ecce-484a-4eec-afa7-edfd54ae72cb to disappear
Oct 28 16:36:49.915: INFO: Pod pod-a119ecce-484a-4eec-afa7-edfd54ae72cb no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 16:36:49.916: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3972" for this suite.
Oct 28 16:36:55.936: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 16:36:56.081: INFO: namespace emptydir-3972 deletion completed in 6.159851598s

• [SLOW TEST:12.396 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 16:36:56.082: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-6555
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating secret secrets-6555/secret-test-c3288326-350e-446d-9868-f4b37566466a
STEP: Creating a pod to test consume secrets
Oct 28 16:36:56.243: INFO: Waiting up to 5m0s for pod "pod-configmaps-667face3-b727-4039-a3fd-730a9967a16b" in namespace "secrets-6555" to be "success or failure"
Oct 28 16:36:56.251: INFO: Pod "pod-configmaps-667face3-b727-4039-a3fd-730a9967a16b": Phase="Pending", Reason="", readiness=false. Elapsed: 8.434742ms
Oct 28 16:36:58.255: INFO: Pod "pod-configmaps-667face3-b727-4039-a3fd-730a9967a16b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012445116s
Oct 28 16:37:00.260: INFO: Pod "pod-configmaps-667face3-b727-4039-a3fd-730a9967a16b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016594939s
STEP: Saw pod success
Oct 28 16:37:00.260: INFO: Pod "pod-configmaps-667face3-b727-4039-a3fd-730a9967a16b" satisfied condition "success or failure"
Oct 28 16:37:00.263: INFO: Trying to get logs from node kh4ga-worker-000000 pod pod-configmaps-667face3-b727-4039-a3fd-730a9967a16b container env-test: <nil>
STEP: delete the pod
Oct 28 16:37:00.290: INFO: Waiting for pod pod-configmaps-667face3-b727-4039-a3fd-730a9967a16b to disappear
Oct 28 16:37:00.303: INFO: Pod pod-configmaps-667face3-b727-4039-a3fd-730a9967a16b no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 16:37:00.303: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6555" for this suite.
Oct 28 16:37:06.322: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 16:37:06.492: INFO: namespace secrets-6555 deletion completed in 6.184262393s

• [SLOW TEST:10.411 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 16:37:06.493: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-4543
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1456
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Oct 28 16:37:06.663: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-124947935 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=kubectl-4543'
Oct 28 16:37:06.738: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Oct 28 16:37:06.738: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: verifying the pod controlled by rc e2e-test-nginx-rc was created
STEP: confirm that you can get logs from an rc
Oct 28 16:37:06.774: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-5x5f8]
Oct 28 16:37:06.774: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-5x5f8" in namespace "kubectl-4543" to be "running and ready"
Oct 28 16:37:06.782: INFO: Pod "e2e-test-nginx-rc-5x5f8": Phase="Pending", Reason="", readiness=false. Elapsed: 7.581137ms
Oct 28 16:37:08.787: INFO: Pod "e2e-test-nginx-rc-5x5f8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013106351s
Oct 28 16:37:10.792: INFO: Pod "e2e-test-nginx-rc-5x5f8": Phase="Running", Reason="", readiness=true. Elapsed: 4.018019713s
Oct 28 16:37:10.792: INFO: Pod "e2e-test-nginx-rc-5x5f8" satisfied condition "running and ready"
Oct 28 16:37:10.792: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-5x5f8]
Oct 28 16:37:10.792: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-124947935 logs rc/e2e-test-nginx-rc --namespace=kubectl-4543'
Oct 28 16:37:10.891: INFO: stderr: ""
Oct 28 16:37:10.891: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1461
Oct 28 16:37:10.891: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-124947935 delete rc e2e-test-nginx-rc --namespace=kubectl-4543'
Oct 28 16:37:10.979: INFO: stderr: ""
Oct 28 16:37:10.979: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 16:37:10.979: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4543" for this suite.
Oct 28 16:37:33.007: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 16:37:33.203: INFO: namespace kubectl-4543 deletion completed in 22.217666407s

• [SLOW TEST:26.710 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run rc
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 16:37:33.203: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-8786
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating all guestbook components
Oct 28 16:37:33.415: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Oct 28 16:37:33.415: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-124947935 create -f - --namespace=kubectl-8786'
Oct 28 16:37:34.412: INFO: stderr: ""
Oct 28 16:37:34.412: INFO: stdout: "service/redis-slave created\n"
Oct 28 16:37:34.412: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Oct 28 16:37:34.412: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-124947935 create -f - --namespace=kubectl-8786'
Oct 28 16:37:34.978: INFO: stderr: ""
Oct 28 16:37:34.978: INFO: stdout: "service/redis-master created\n"
Oct 28 16:37:34.978: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Oct 28 16:37:34.978: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-124947935 create -f - --namespace=kubectl-8786'
Oct 28 16:37:35.510: INFO: stderr: ""
Oct 28 16:37:35.510: INFO: stdout: "service/frontend created\n"
Oct 28 16:37:35.510: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: guestbook
      tier: frontend
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Oct 28 16:37:35.510: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-124947935 create -f - --namespace=kubectl-8786'
Oct 28 16:37:36.054: INFO: stderr: ""
Oct 28 16:37:36.054: INFO: stdout: "deployment.apps/frontend created\n"
Oct 28 16:37:36.054: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  selector:
    matchLabels:
      app: redis
      role: master
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Oct 28 16:37:36.054: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-124947935 create -f - --namespace=kubectl-8786'
Oct 28 16:37:36.613: INFO: stderr: ""
Oct 28 16:37:36.613: INFO: stdout: "deployment.apps/redis-master created\n"
Oct 28 16:37:36.613: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  selector:
    matchLabels:
      app: redis
      role: slave
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave:v3
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Oct 28 16:37:36.613: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-124947935 create -f - --namespace=kubectl-8786'
Oct 28 16:37:37.544: INFO: stderr: ""
Oct 28 16:37:37.544: INFO: stdout: "deployment.apps/redis-slave created\n"
STEP: validating guestbook app
Oct 28 16:37:37.544: INFO: Waiting for all frontend pods to be Running.
Oct 28 16:38:22.596: INFO: Waiting for frontend to serve content.
Oct 28 16:38:27.621: INFO: Failed to get response from guestbook. err: <nil>, response: <br />
<b>Fatal error</b>:  Uncaught exception 'Predis\Connection\ConnectionException' with message 'Connection timed out [tcp://redis-slave:6379]' in /usr/local/lib/php/Predis/Connection/AbstractConnection.php:155
Stack trace:
#0 /usr/local/lib/php/Predis/Connection/StreamConnection.php(128): Predis\Connection\AbstractConnection-&gt;onConnectionError('Connection time...', 110)
#1 /usr/local/lib/php/Predis/Connection/StreamConnection.php(178): Predis\Connection\StreamConnection-&gt;createStreamSocket(Object(Predis\Connection\Parameters), 'tcp://redis-sla...', 4)
#2 /usr/local/lib/php/Predis/Connection/StreamConnection.php(100): Predis\Connection\StreamConnection-&gt;tcpStreamInitializer(Object(Predis\Connection\Parameters))
#3 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(81): Predis\Connection\StreamConnection-&gt;createResource()
#4 /usr/local/lib/php/Predis/Connection/StreamConnection.php(258): Predis\Connection\AbstractConnection-&gt;connect()
#5 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(180): Predis\Connection\Stre in <b>/usr/local/lib/php/Predis/Connection/AbstractConnection.php</b> on line <b>155</b><br />

Oct 28 16:38:32.640: INFO: Trying to add a new entry to the guestbook.
Oct 28 16:38:32.654: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Oct 28 16:38:32.668: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-124947935 delete --grace-period=0 --force -f - --namespace=kubectl-8786'
Oct 28 16:38:32.768: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct 28 16:38:32.768: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Oct 28 16:38:32.768: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-124947935 delete --grace-period=0 --force -f - --namespace=kubectl-8786'
Oct 28 16:38:32.877: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct 28 16:38:32.877: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Oct 28 16:38:32.878: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-124947935 delete --grace-period=0 --force -f - --namespace=kubectl-8786'
Oct 28 16:38:33.058: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct 28 16:38:33.058: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Oct 28 16:38:33.058: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-124947935 delete --grace-period=0 --force -f - --namespace=kubectl-8786'
Oct 28 16:38:33.145: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct 28 16:38:33.145: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Oct 28 16:38:33.145: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-124947935 delete --grace-period=0 --force -f - --namespace=kubectl-8786'
Oct 28 16:38:33.257: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct 28 16:38:33.257: INFO: stdout: "deployment.apps \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Oct 28 16:38:33.257: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-124947935 delete --grace-period=0 --force -f - --namespace=kubectl-8786'
Oct 28 16:38:33.360: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct 28 16:38:33.360: INFO: stdout: "deployment.apps \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 16:38:33.360: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8786" for this suite.
Oct 28 16:39:19.400: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 16:39:19.553: INFO: namespace kubectl-8786 deletion completed in 46.17896958s

• [SLOW TEST:106.349 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Guestbook application
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 16:39:19.553: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-334
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Oct 28 16:39:19.754: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Oct 28 16:39:19.768: INFO: Pod name sample-pod: Found 0 pods out of 1
Oct 28 16:39:24.780: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Oct 28 16:39:24.781: INFO: Creating deployment "test-rolling-update-deployment"
Oct 28 16:39:24.786: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Oct 28 16:39:24.810: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Oct 28 16:39:26.819: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Oct 28 16:39:26.823: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707877564, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707877564, loc:(*time.Location)(0x7ed0a20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707877564, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707877564, loc:(*time.Location)(0x7ed0a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-79f6b9d75c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 28 16:39:28.828: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707877564, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707877564, loc:(*time.Location)(0x7ed0a20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707877564, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707877564, loc:(*time.Location)(0x7ed0a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-79f6b9d75c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 28 16:39:30.828: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
Oct 28 16:39:30.840: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment,GenerateName:,Namespace:deployment-334,SelfLink:/apis/apps/v1/namespaces/deployment-334/deployments/test-rolling-update-deployment,UID:9708638b-d617-489b-9105-a95e6ab90f5c,ResourceVersion:4767,Generation:1,CreationTimestamp:2019-10-28 16:39:24 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-10-28 16:39:24 +0000 UTC 2019-10-28 16:39:24 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-10-28 16:39:28 +0000 UTC 2019-10-28 16:39:24 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rolling-update-deployment-79f6b9d75c" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Oct 28 16:39:30.845: INFO: New ReplicaSet "test-rolling-update-deployment-79f6b9d75c" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-79f6b9d75c,GenerateName:,Namespace:deployment-334,SelfLink:/apis/apps/v1/namespaces/deployment-334/replicasets/test-rolling-update-deployment-79f6b9d75c,UID:1952ca6b-afc3-4aed-bd75-2c761610be17,ResourceVersion:4757,Generation:1,CreationTimestamp:2019-10-28 16:39:24 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 79f6b9d75c,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 9708638b-d617-489b-9105-a95e6ab90f5c 0xc003b13897 0xc003b13898}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 79f6b9d75c,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 79f6b9d75c,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Oct 28 16:39:30.845: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Oct 28 16:39:30.845: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-controller,GenerateName:,Namespace:deployment-334,SelfLink:/apis/apps/v1/namespaces/deployment-334/replicasets/test-rolling-update-controller,UID:0069050a-9c75-4641-b4d5-cd2ad46d0070,ResourceVersion:4766,Generation:2,CreationTimestamp:2019-10-28 16:39:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305832,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 9708638b-d617-489b-9105-a95e6ab90f5c 0xc003b137bf 0xc003b137d0}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Oct 28 16:39:30.850: INFO: Pod "test-rolling-update-deployment-79f6b9d75c-x4tj9" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-79f6b9d75c-x4tj9,GenerateName:test-rolling-update-deployment-79f6b9d75c-,Namespace:deployment-334,SelfLink:/api/v1/namespaces/deployment-334/pods/test-rolling-update-deployment-79f6b9d75c-x4tj9,UID:ec9a9651-576b-438a-a19c-4c355a24cd92,ResourceVersion:4756,Generation:0,CreationTimestamp:2019-10-28 16:39:24 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 79f6b9d75c,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.2.131.34/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-rolling-update-deployment-79f6b9d75c 1952ca6b-afc3-4aed-bd75-2c761610be17 0xc002a54867 0xc002a54868}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-hpj6c {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-hpj6c,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-hpj6c true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kh4ga-worker-000003,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002a548d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002a548f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-28 16:39:24 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-10-28 16:39:28 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-10-28 16:39:28 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-28 16:39:24 +0000 UTC  }],Message:,Reason:,HostIP:10.2.1.7,PodIP:10.2.131.34,StartTime:2019-10-28 16:39:24 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-10-28 16:39:28 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://e07a4a30a3555a8315529643d9dafd0a920a32561a05b8fbc341bb776a0dd636}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 16:39:30.850: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-334" for this suite.
Oct 28 16:39:36.879: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 16:39:37.048: INFO: namespace deployment-334 deletion completed in 6.191577456s

• [SLOW TEST:17.495 seconds]
[sig-apps] Deployment
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 16:39:37.049: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-462
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:63
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Oct 28 16:39:49.269: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct 28 16:39:49.274: INFO: Pod pod-with-prestop-exec-hook still exists
Oct 28 16:39:51.274: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct 28 16:39:51.278: INFO: Pod pod-with-prestop-exec-hook still exists
Oct 28 16:39:53.274: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct 28 16:39:53.280: INFO: Pod pod-with-prestop-exec-hook still exists
Oct 28 16:39:55.274: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct 28 16:39:55.279: INFO: Pod pod-with-prestop-exec-hook still exists
Oct 28 16:39:57.274: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct 28 16:39:57.278: INFO: Pod pod-with-prestop-exec-hook still exists
Oct 28 16:39:59.274: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct 28 16:39:59.279: INFO: Pod pod-with-prestop-exec-hook still exists
Oct 28 16:40:01.274: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct 28 16:40:01.279: INFO: Pod pod-with-prestop-exec-hook still exists
Oct 28 16:40:03.274: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct 28 16:40:03.279: INFO: Pod pod-with-prestop-exec-hook still exists
Oct 28 16:40:05.274: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct 28 16:40:05.279: INFO: Pod pod-with-prestop-exec-hook still exists
Oct 28 16:40:07.274: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct 28 16:40:07.281: INFO: Pod pod-with-prestop-exec-hook still exists
Oct 28 16:40:09.274: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct 28 16:40:09.278: INFO: Pod pod-with-prestop-exec-hook still exists
Oct 28 16:40:11.274: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct 28 16:40:11.280: INFO: Pod pod-with-prestop-exec-hook still exists
Oct 28 16:40:13.274: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct 28 16:40:13.279: INFO: Pod pod-with-prestop-exec-hook still exists
Oct 28 16:40:15.274: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct 28 16:40:15.279: INFO: Pod pod-with-prestop-exec-hook still exists
Oct 28 16:40:17.274: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct 28 16:40:17.279: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 16:40:17.296: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-462" for this suite.
Oct 28 16:40:39.340: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 16:40:39.510: INFO: namespace container-lifecycle-hook-462 deletion completed in 22.20749905s

• [SLOW TEST:62.461 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when create a pod with lifecycle hook
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 16:40:39.510: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-2917
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
Oct 28 16:41:19.705: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W1028 16:41:19.705928      19 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 16:41:19.706: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-2917" for this suite.
Oct 28 16:41:25.724: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 16:41:25.880: INFO: namespace gc-2917 deletion completed in 6.17062776s

• [SLOW TEST:46.370 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 16:41:25.881: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-4368
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0644 on tmpfs
Oct 28 16:41:26.088: INFO: Waiting up to 5m0s for pod "pod-38879533-6221-4891-85d5-0be5e42eb087" in namespace "emptydir-4368" to be "success or failure"
Oct 28 16:41:26.097: INFO: Pod "pod-38879533-6221-4891-85d5-0be5e42eb087": Phase="Pending", Reason="", readiness=false. Elapsed: 8.855325ms
Oct 28 16:41:28.102: INFO: Pod "pod-38879533-6221-4891-85d5-0be5e42eb087": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013595091s
Oct 28 16:41:30.107: INFO: Pod "pod-38879533-6221-4891-85d5-0be5e42eb087": Phase="Pending", Reason="", readiness=false. Elapsed: 4.01879994s
Oct 28 16:41:32.112: INFO: Pod "pod-38879533-6221-4891-85d5-0be5e42eb087": Phase="Pending", Reason="", readiness=false. Elapsed: 6.023667671s
Oct 28 16:41:34.117: INFO: Pod "pod-38879533-6221-4891-85d5-0be5e42eb087": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.028545283s
STEP: Saw pod success
Oct 28 16:41:34.117: INFO: Pod "pod-38879533-6221-4891-85d5-0be5e42eb087" satisfied condition "success or failure"
Oct 28 16:41:34.121: INFO: Trying to get logs from node kh4ga-worker-000000 pod pod-38879533-6221-4891-85d5-0be5e42eb087 container test-container: <nil>
STEP: delete the pod
Oct 28 16:41:34.148: INFO: Waiting for pod pod-38879533-6221-4891-85d5-0be5e42eb087 to disappear
Oct 28 16:41:34.151: INFO: Pod pod-38879533-6221-4891-85d5-0be5e42eb087 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 16:41:34.151: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4368" for this suite.
Oct 28 16:41:40.173: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 16:41:40.326: INFO: namespace emptydir-4368 deletion completed in 6.166434952s

• [SLOW TEST:14.445 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 16:41:40.326: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-4447
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a test externalName service
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-4447.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-4447.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-4447.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-4447.svc.cluster.local; sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Oct 28 16:42:12.540: INFO: DNS probes using dns-test-e5a35427-a722-48f2-83c6-640af6f4362b succeeded

STEP: deleting the pod
STEP: changing the externalName to bar.example.com
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-4447.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-4447.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-4447.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-4447.svc.cluster.local; sleep 1; done

STEP: creating a second pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Oct 28 16:42:22.639: INFO: DNS probes using dns-test-3ec5ca1c-a6df-40bd-a6d0-687528b8fea1 succeeded

STEP: deleting the pod
STEP: changing the service to type=ClusterIP
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-4447.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-4447.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-4447.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-4447.svc.cluster.local; sleep 1; done

STEP: creating a third pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Oct 28 16:42:32.758: INFO: DNS probes using dns-test-694c3f52-8278-44e3-9db0-ce9bcd323104 succeeded

STEP: deleting the pod
STEP: deleting the test externalName service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 16:42:32.810: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-4447" for this suite.
Oct 28 16:42:38.891: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 16:42:39.044: INFO: namespace dns-4447 deletion completed in 6.199497243s

• [SLOW TEST:58.718 seconds]
[sig-network] DNS
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 16:42:39.045: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-1918
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Oct 28 16:42:43.739: INFO: Successfully updated pod "pod-update-579eac7d-d342-4661-878e-2abffb399745"
STEP: verifying the updated pod is in kubernetes
Oct 28 16:42:43.750: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 16:42:43.750: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-1918" for this suite.
Oct 28 16:43:05.780: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 16:43:05.938: INFO: namespace pods-1918 deletion completed in 22.181469902s

• [SLOW TEST:26.892 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 16:43:05.938: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-4688
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-40d3f1f7-3d1d-4516-9d22-382d4df219b2
STEP: Creating a pod to test consume configMaps
Oct 28 16:43:06.115: INFO: Waiting up to 5m0s for pod "pod-configmaps-22a3abbc-3dfe-444b-bb01-df5bf9e508d9" in namespace "configmap-4688" to be "success or failure"
Oct 28 16:43:06.136: INFO: Pod "pod-configmaps-22a3abbc-3dfe-444b-bb01-df5bf9e508d9": Phase="Pending", Reason="", readiness=false. Elapsed: 21.805353ms
Oct 28 16:43:08.141: INFO: Pod "pod-configmaps-22a3abbc-3dfe-444b-bb01-df5bf9e508d9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026566874s
Oct 28 16:43:10.145: INFO: Pod "pod-configmaps-22a3abbc-3dfe-444b-bb01-df5bf9e508d9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.030716382s
STEP: Saw pod success
Oct 28 16:43:10.145: INFO: Pod "pod-configmaps-22a3abbc-3dfe-444b-bb01-df5bf9e508d9" satisfied condition "success or failure"
Oct 28 16:43:10.149: INFO: Trying to get logs from node kh4ga-worker-000003 pod pod-configmaps-22a3abbc-3dfe-444b-bb01-df5bf9e508d9 container configmap-volume-test: <nil>
STEP: delete the pod
Oct 28 16:43:10.172: INFO: Waiting for pod pod-configmaps-22a3abbc-3dfe-444b-bb01-df5bf9e508d9 to disappear
Oct 28 16:43:10.176: INFO: Pod pod-configmaps-22a3abbc-3dfe-444b-bb01-df5bf9e508d9 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 16:43:10.176: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4688" for this suite.
Oct 28 16:43:16.209: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 16:43:16.380: INFO: namespace configmap-4688 deletion completed in 6.1982038s

• [SLOW TEST:10.442 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 16:43:16.381: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-8958
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Oct 28 16:43:46.563: INFO: Container started at 2019-10-28 16:43:20 +0000 UTC, pod became ready at 2019-10-28 16:43:44 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 16:43:46.563: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-8958" for this suite.
Oct 28 16:44:08.585: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 16:44:08.748: INFO: namespace container-probe-8958 deletion completed in 22.178754761s

• [SLOW TEST:52.367 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 16:44:08.748: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-7769
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 16:44:08.956: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-7769" for this suite.
Oct 28 16:44:30.983: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 16:44:31.134: INFO: namespace kubelet-test-7769 deletion completed in 22.170757658s

• [SLOW TEST:22.385 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should be possible to delete [NodeConformance] [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 16:44:31.134: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5265
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Oct 28 16:44:31.318: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a4e1b143-b645-4daf-a171-1fa81eacb460" in namespace "projected-5265" to be "success or failure"
Oct 28 16:44:31.343: INFO: Pod "downwardapi-volume-a4e1b143-b645-4daf-a171-1fa81eacb460": Phase="Pending", Reason="", readiness=false. Elapsed: 24.964756ms
Oct 28 16:44:33.352: INFO: Pod "downwardapi-volume-a4e1b143-b645-4daf-a171-1fa81eacb460": Phase="Pending", Reason="", readiness=false. Elapsed: 2.034462047s
Oct 28 16:44:35.357: INFO: Pod "downwardapi-volume-a4e1b143-b645-4daf-a171-1fa81eacb460": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.03968782s
STEP: Saw pod success
Oct 28 16:44:35.357: INFO: Pod "downwardapi-volume-a4e1b143-b645-4daf-a171-1fa81eacb460" satisfied condition "success or failure"
Oct 28 16:44:35.366: INFO: Trying to get logs from node kh4ga-worker-000000 pod downwardapi-volume-a4e1b143-b645-4daf-a171-1fa81eacb460 container client-container: <nil>
STEP: delete the pod
Oct 28 16:44:35.399: INFO: Waiting for pod downwardapi-volume-a4e1b143-b645-4daf-a171-1fa81eacb460 to disappear
Oct 28 16:44:35.403: INFO: Pod downwardapi-volume-a4e1b143-b645-4daf-a171-1fa81eacb460 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 16:44:35.403: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5265" for this suite.
Oct 28 16:44:41.424: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 16:44:41.580: INFO: namespace projected-5265 deletion completed in 6.17137451s

• [SLOW TEST:10.446 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 16:44:41.581: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-1582
STEP: Waiting for a default service account to be provisioned in namespace
[It] should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: starting a background goroutine to produce watch events
STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 16:44:47.242: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-1582" for this suite.
Oct 28 16:44:53.394: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 16:44:53.551: INFO: namespace watch-1582 deletion completed in 6.259469451s

• [SLOW TEST:11.970 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 16:44:53.552: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-3434
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Oct 28 16:44:53.710: INFO: Waiting up to 5m0s for pod "downward-api-12b3b327-c29f-4c4c-ac11-400fc1402af6" in namespace "downward-api-3434" to be "success or failure"
Oct 28 16:44:53.759: INFO: Pod "downward-api-12b3b327-c29f-4c4c-ac11-400fc1402af6": Phase="Pending", Reason="", readiness=false. Elapsed: 49.650809ms
Oct 28 16:44:55.764: INFO: Pod "downward-api-12b3b327-c29f-4c4c-ac11-400fc1402af6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.054421596s
Oct 28 16:44:57.769: INFO: Pod "downward-api-12b3b327-c29f-4c4c-ac11-400fc1402af6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.059614976s
STEP: Saw pod success
Oct 28 16:44:57.769: INFO: Pod "downward-api-12b3b327-c29f-4c4c-ac11-400fc1402af6" satisfied condition "success or failure"
Oct 28 16:44:57.773: INFO: Trying to get logs from node kh4ga-worker-000003 pod downward-api-12b3b327-c29f-4c4c-ac11-400fc1402af6 container dapi-container: <nil>
STEP: delete the pod
Oct 28 16:44:57.800: INFO: Waiting for pod downward-api-12b3b327-c29f-4c4c-ac11-400fc1402af6 to disappear
Oct 28 16:44:57.817: INFO: Pod downward-api-12b3b327-c29f-4c4c-ac11-400fc1402af6 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 16:44:57.817: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3434" for this suite.
Oct 28 16:45:03.844: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 16:45:03.991: INFO: namespace downward-api-3434 deletion completed in 6.167308721s

• [SLOW TEST:10.440 seconds]
[sig-node] Downward API
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 16:45:03.992: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5708
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Oct 28 16:45:04.184: INFO: Waiting up to 5m0s for pod "downwardapi-volume-4c1b99a5-234f-4885-ba65-b5bb4593ad45" in namespace "projected-5708" to be "success or failure"
Oct 28 16:45:04.193: INFO: Pod "downwardapi-volume-4c1b99a5-234f-4885-ba65-b5bb4593ad45": Phase="Pending", Reason="", readiness=false. Elapsed: 8.85602ms
Oct 28 16:45:06.218: INFO: Pod "downwardapi-volume-4c1b99a5-234f-4885-ba65-b5bb4593ad45": Phase="Pending", Reason="", readiness=false. Elapsed: 2.033725609s
Oct 28 16:45:08.223: INFO: Pod "downwardapi-volume-4c1b99a5-234f-4885-ba65-b5bb4593ad45": Phase="Pending", Reason="", readiness=false. Elapsed: 4.038755648s
Oct 28 16:45:10.228: INFO: Pod "downwardapi-volume-4c1b99a5-234f-4885-ba65-b5bb4593ad45": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.043774579s
STEP: Saw pod success
Oct 28 16:45:10.228: INFO: Pod "downwardapi-volume-4c1b99a5-234f-4885-ba65-b5bb4593ad45" satisfied condition "success or failure"
Oct 28 16:45:10.231: INFO: Trying to get logs from node kh4ga-worker-000000 pod downwardapi-volume-4c1b99a5-234f-4885-ba65-b5bb4593ad45 container client-container: <nil>
STEP: delete the pod
Oct 28 16:45:10.257: INFO: Waiting for pod downwardapi-volume-4c1b99a5-234f-4885-ba65-b5bb4593ad45 to disappear
Oct 28 16:45:10.265: INFO: Pod downwardapi-volume-4c1b99a5-234f-4885-ba65-b5bb4593ad45 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 16:45:10.265: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5708" for this suite.
Oct 28 16:45:16.292: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 16:45:16.447: INFO: namespace projected-5708 deletion completed in 6.171630784s

• [SLOW TEST:12.455 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 16:45:16.448: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-7435
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-map-3cf74982-3296-4c26-aa9f-5379f96a548b
STEP: Creating a pod to test consume secrets
Oct 28 16:45:16.627: INFO: Waiting up to 5m0s for pod "pod-secrets-c4b76187-2deb-4af4-b07f-fac1f31a61fb" in namespace "secrets-7435" to be "success or failure"
Oct 28 16:45:16.639: INFO: Pod "pod-secrets-c4b76187-2deb-4af4-b07f-fac1f31a61fb": Phase="Pending", Reason="", readiness=false. Elapsed: 11.939125ms
Oct 28 16:45:18.644: INFO: Pod "pod-secrets-c4b76187-2deb-4af4-b07f-fac1f31a61fb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016607225s
Oct 28 16:45:20.658: INFO: Pod "pod-secrets-c4b76187-2deb-4af4-b07f-fac1f31a61fb": Phase="Pending", Reason="", readiness=false. Elapsed: 4.030240936s
Oct 28 16:45:22.662: INFO: Pod "pod-secrets-c4b76187-2deb-4af4-b07f-fac1f31a61fb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.035051321s
STEP: Saw pod success
Oct 28 16:45:22.663: INFO: Pod "pod-secrets-c4b76187-2deb-4af4-b07f-fac1f31a61fb" satisfied condition "success or failure"
Oct 28 16:45:22.666: INFO: Trying to get logs from node kh4ga-worker-000003 pod pod-secrets-c4b76187-2deb-4af4-b07f-fac1f31a61fb container secret-volume-test: <nil>
STEP: delete the pod
Oct 28 16:45:22.713: INFO: Waiting for pod pod-secrets-c4b76187-2deb-4af4-b07f-fac1f31a61fb to disappear
Oct 28 16:45:22.717: INFO: Pod pod-secrets-c4b76187-2deb-4af4-b07f-fac1f31a61fb no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 16:45:22.717: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7435" for this suite.
Oct 28 16:45:28.745: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 16:45:28.933: INFO: namespace secrets-7435 deletion completed in 6.210682829s

• [SLOW TEST:12.486 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 16:45:28.934: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-1076
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-1076.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-1076.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Oct 28 16:45:37.154: INFO: Unable to read wheezy_udp@PodARecord from pod dns-1076/dns-test-5b9fcf33-ffe0-4cbf-8ba9-746849853e86: the server could not find the requested resource (get pods dns-test-5b9fcf33-ffe0-4cbf-8ba9-746849853e86)
Oct 28 16:45:37.161: INFO: Unable to read wheezy_tcp@PodARecord from pod dns-1076/dns-test-5b9fcf33-ffe0-4cbf-8ba9-746849853e86: the server could not find the requested resource (get pods dns-test-5b9fcf33-ffe0-4cbf-8ba9-746849853e86)
Oct 28 16:45:37.180: INFO: Unable to read jessie_udp@PodARecord from pod dns-1076/dns-test-5b9fcf33-ffe0-4cbf-8ba9-746849853e86: the server could not find the requested resource (get pods dns-test-5b9fcf33-ffe0-4cbf-8ba9-746849853e86)
Oct 28 16:45:37.186: INFO: Unable to read jessie_tcp@PodARecord from pod dns-1076/dns-test-5b9fcf33-ffe0-4cbf-8ba9-746849853e86: the server could not find the requested resource (get pods dns-test-5b9fcf33-ffe0-4cbf-8ba9-746849853e86)
Oct 28 16:45:37.186: INFO: Lookups using dns-1076/dns-test-5b9fcf33-ffe0-4cbf-8ba9-746849853e86 failed for: [wheezy_udp@PodARecord wheezy_tcp@PodARecord jessie_udp@PodARecord jessie_tcp@PodARecord]

Oct 28 16:45:42.235: INFO: DNS probes using dns-1076/dns-test-5b9fcf33-ffe0-4cbf-8ba9-746849853e86 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 16:45:42.257: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-1076" for this suite.
Oct 28 16:45:48.301: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 16:45:48.463: INFO: namespace dns-1076 deletion completed in 6.194963889s

• [SLOW TEST:19.530 seconds]
[sig-network] DNS
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 16:45:48.463: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2288
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-map-86d09b2c-416a-4a72-9555-2f23865bb8e4
STEP: Creating a pod to test consume configMaps
Oct 28 16:45:48.633: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-eb0ab520-2b8a-4640-a452-54a0b7d12c58" in namespace "projected-2288" to be "success or failure"
Oct 28 16:45:48.647: INFO: Pod "pod-projected-configmaps-eb0ab520-2b8a-4640-a452-54a0b7d12c58": Phase="Pending", Reason="", readiness=false. Elapsed: 13.755629ms
Oct 28 16:45:50.652: INFO: Pod "pod-projected-configmaps-eb0ab520-2b8a-4640-a452-54a0b7d12c58": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018545219s
Oct 28 16:45:52.656: INFO: Pod "pod-projected-configmaps-eb0ab520-2b8a-4640-a452-54a0b7d12c58": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023301602s
STEP: Saw pod success
Oct 28 16:45:52.656: INFO: Pod "pod-projected-configmaps-eb0ab520-2b8a-4640-a452-54a0b7d12c58" satisfied condition "success or failure"
Oct 28 16:45:52.660: INFO: Trying to get logs from node kh4ga-worker-000000 pod pod-projected-configmaps-eb0ab520-2b8a-4640-a452-54a0b7d12c58 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Oct 28 16:45:52.690: INFO: Waiting for pod pod-projected-configmaps-eb0ab520-2b8a-4640-a452-54a0b7d12c58 to disappear
Oct 28 16:45:52.696: INFO: Pod pod-projected-configmaps-eb0ab520-2b8a-4640-a452-54a0b7d12c58 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 16:45:52.696: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2288" for this suite.
Oct 28 16:45:58.717: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 16:45:58.930: INFO: namespace projected-2288 deletion completed in 6.228007955s

• [SLOW TEST:10.467 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 16:45:58.931: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-9740
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
Oct 28 16:45:59.749: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W1028 16:45:59.749399      19 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 16:45:59.749: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-9740" for this suite.
Oct 28 16:46:05.768: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 16:46:05.938: INFO: namespace gc-9740 deletion completed in 6.184832297s

• [SLOW TEST:7.008 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 16:46:05.939: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-kubelet-etc-hosts-4542
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Oct 28 16:46:18.170: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-4542 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 28 16:46:18.170: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
Oct 28 16:46:18.296: INFO: Exec stderr: ""
Oct 28 16:46:18.296: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-4542 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 28 16:46:18.296: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
Oct 28 16:46:18.430: INFO: Exec stderr: ""
Oct 28 16:46:18.430: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-4542 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 28 16:46:18.430: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
Oct 28 16:46:18.547: INFO: Exec stderr: ""
Oct 28 16:46:18.547: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-4542 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 28 16:46:18.547: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
Oct 28 16:46:18.670: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Oct 28 16:46:18.670: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-4542 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 28 16:46:18.670: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
Oct 28 16:46:18.800: INFO: Exec stderr: ""
Oct 28 16:46:18.801: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-4542 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 28 16:46:18.801: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
Oct 28 16:46:18.928: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Oct 28 16:46:18.928: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-4542 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 28 16:46:18.928: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
Oct 28 16:46:19.045: INFO: Exec stderr: ""
Oct 28 16:46:19.045: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-4542 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 28 16:46:19.045: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
Oct 28 16:46:19.158: INFO: Exec stderr: ""
Oct 28 16:46:19.158: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-4542 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 28 16:46:19.158: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
Oct 28 16:46:19.281: INFO: Exec stderr: ""
Oct 28 16:46:19.281: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-4542 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 28 16:46:19.281: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
Oct 28 16:46:19.403: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 16:46:19.403: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-kubelet-etc-hosts-4542" for this suite.
Oct 28 16:47:07.432: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 16:47:07.580: INFO: namespace e2e-kubelet-etc-hosts-4542 deletion completed in 48.168943831s

• [SLOW TEST:61.640 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 16:47:07.580: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-7242
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Oct 28 16:47:07.753: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-7242,SelfLink:/api/v1/namespaces/watch-7242/configmaps/e2e-watch-test-watch-closed,UID:0bcb5a42-722d-4973-bde6-0bbf4ff3e10d,ResourceVersion:6499,Generation:0,CreationTimestamp:2019-10-28 16:47:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Oct 28 16:47:07.754: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-7242,SelfLink:/api/v1/namespaces/watch-7242/configmaps/e2e-watch-test-watch-closed,UID:0bcb5a42-722d-4973-bde6-0bbf4ff3e10d,ResourceVersion:6500,Generation:0,CreationTimestamp:2019-10-28 16:47:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Oct 28 16:47:07.776: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-7242,SelfLink:/api/v1/namespaces/watch-7242/configmaps/e2e-watch-test-watch-closed,UID:0bcb5a42-722d-4973-bde6-0bbf4ff3e10d,ResourceVersion:6501,Generation:0,CreationTimestamp:2019-10-28 16:47:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Oct 28 16:47:07.777: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-7242,SelfLink:/api/v1/namespaces/watch-7242/configmaps/e2e-watch-test-watch-closed,UID:0bcb5a42-722d-4973-bde6-0bbf4ff3e10d,ResourceVersion:6502,Generation:0,CreationTimestamp:2019-10-28 16:47:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 16:47:07.777: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-7242" for this suite.
Oct 28 16:47:13.812: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 16:47:13.973: INFO: namespace watch-7242 deletion completed in 6.185823436s

• [SLOW TEST:6.394 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 16:47:13.975: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-9626
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
Oct 28 16:47:14.126: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 16:47:23.626: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-9626" for this suite.
Oct 28 16:47:45.649: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 16:47:45.805: INFO: namespace init-container-9626 deletion completed in 22.170702367s

• [SLOW TEST:31.830 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 16:47:45.805: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in namespaces-8178
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-5353
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-3363
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 16:48:14.382: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-8178" for this suite.
Oct 28 16:48:20.403: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 16:48:20.570: INFO: namespace namespaces-8178 deletion completed in 6.180769302s
STEP: Destroying namespace "nsdeletetest-5353" for this suite.
Oct 28 16:48:20.573: INFO: Namespace nsdeletetest-5353 was already deleted
STEP: Destroying namespace "nsdeletetest-3363" for this suite.
Oct 28 16:48:26.588: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 16:48:26.752: INFO: namespace nsdeletetest-3363 deletion completed in 6.178657864s

• [SLOW TEST:40.947 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 16:48:26.752: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-2035
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1516
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Oct 28 16:48:26.903: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-124947935 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=kubectl-2035'
Oct 28 16:48:29.424: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Oct 28 16:48:29.424: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
Oct 28 16:48:29.441: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 1 spec.replicas 1 status.replicas 0
STEP: rolling-update to same image controller
Oct 28 16:48:29.448: INFO: scanned /root for discovery docs: <nil>
Oct 28 16:48:29.448: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-124947935 rolling-update e2e-test-nginx-rc --update-period=1s --image=docker.io/library/nginx:1.14-alpine --image-pull-policy=IfNotPresent --namespace=kubectl-2035'
Oct 28 16:48:46.269: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Oct 28 16:48:46.269: INFO: stdout: "Created e2e-test-nginx-rc-f891652844fbc32264d2c96085d4ffc4\nScaling up e2e-test-nginx-rc-f891652844fbc32264d2c96085d4ffc4 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-f891652844fbc32264d2c96085d4ffc4 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-f891652844fbc32264d2c96085d4ffc4 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
Oct 28 16:48:46.269: INFO: stdout: "Created e2e-test-nginx-rc-f891652844fbc32264d2c96085d4ffc4\nScaling up e2e-test-nginx-rc-f891652844fbc32264d2c96085d4ffc4 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-f891652844fbc32264d2c96085d4ffc4 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-f891652844fbc32264d2c96085d4ffc4 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
Oct 28 16:48:46.269: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-124947935 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=kubectl-2035'
Oct 28 16:48:46.343: INFO: stderr: ""
Oct 28 16:48:46.343: INFO: stdout: "e2e-test-nginx-rc-f891652844fbc32264d2c96085d4ffc4-c2hr9 "
Oct 28 16:48:46.343: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-124947935 get pods e2e-test-nginx-rc-f891652844fbc32264d2c96085d4ffc4-c2hr9 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2035'
Oct 28 16:48:46.408: INFO: stderr: ""
Oct 28 16:48:46.408: INFO: stdout: "true"
Oct 28 16:48:46.408: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-124947935 get pods e2e-test-nginx-rc-f891652844fbc32264d2c96085d4ffc4-c2hr9 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-2035'
Oct 28 16:48:46.477: INFO: stderr: ""
Oct 28 16:48:46.477: INFO: stdout: "docker.io/library/nginx:1.14-alpine"
Oct 28 16:48:46.477: INFO: e2e-test-nginx-rc-f891652844fbc32264d2c96085d4ffc4-c2hr9 is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1522
Oct 28 16:48:46.477: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-124947935 delete rc e2e-test-nginx-rc --namespace=kubectl-2035'
Oct 28 16:48:46.551: INFO: stderr: ""
Oct 28 16:48:46.551: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 16:48:46.551: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2035" for this suite.
Oct 28 16:49:08.573: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 16:49:08.734: INFO: namespace kubectl-2035 deletion completed in 22.177019307s

• [SLOW TEST:41.982 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 16:49:08.734: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-3120
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0666 on node default medium
Oct 28 16:49:08.918: INFO: Waiting up to 5m0s for pod "pod-2ce7f8ae-9563-415b-bb99-3a69e4f9a281" in namespace "emptydir-3120" to be "success or failure"
Oct 28 16:49:08.928: INFO: Pod "pod-2ce7f8ae-9563-415b-bb99-3a69e4f9a281": Phase="Pending", Reason="", readiness=false. Elapsed: 9.475118ms
Oct 28 16:49:10.933: INFO: Pod "pod-2ce7f8ae-9563-415b-bb99-3a69e4f9a281": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014655761s
Oct 28 16:49:12.938: INFO: Pod "pod-2ce7f8ae-9563-415b-bb99-3a69e4f9a281": Phase="Pending", Reason="", readiness=false. Elapsed: 4.0193545s
Oct 28 16:49:14.942: INFO: Pod "pod-2ce7f8ae-9563-415b-bb99-3a69e4f9a281": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.023945237s
STEP: Saw pod success
Oct 28 16:49:14.942: INFO: Pod "pod-2ce7f8ae-9563-415b-bb99-3a69e4f9a281" satisfied condition "success or failure"
Oct 28 16:49:14.946: INFO: Trying to get logs from node kh4ga-worker-000000 pod pod-2ce7f8ae-9563-415b-bb99-3a69e4f9a281 container test-container: <nil>
STEP: delete the pod
Oct 28 16:49:14.971: INFO: Waiting for pod pod-2ce7f8ae-9563-415b-bb99-3a69e4f9a281 to disappear
Oct 28 16:49:14.977: INFO: Pod pod-2ce7f8ae-9563-415b-bb99-3a69e4f9a281 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 16:49:14.977: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3120" for this suite.
Oct 28 16:49:21.006: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 16:49:21.166: INFO: namespace emptydir-3120 deletion completed in 6.182749006s

• [SLOW TEST:12.432 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 16:49:21.167: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-4372
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-map-b7380f1b-8595-4926-b50f-ff630a9df4f5
STEP: Creating a pod to test consume configMaps
Oct 28 16:49:21.342: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-38fdf214-5ff0-406d-af5c-4c8c688d9422" in namespace "projected-4372" to be "success or failure"
Oct 28 16:49:21.349: INFO: Pod "pod-projected-configmaps-38fdf214-5ff0-406d-af5c-4c8c688d9422": Phase="Pending", Reason="", readiness=false. Elapsed: 6.367712ms
Oct 28 16:49:23.354: INFO: Pod "pod-projected-configmaps-38fdf214-5ff0-406d-af5c-4c8c688d9422": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011191237s
Oct 28 16:49:25.358: INFO: Pod "pod-projected-configmaps-38fdf214-5ff0-406d-af5c-4c8c688d9422": Phase="Pending", Reason="", readiness=false. Elapsed: 4.016007159s
Oct 28 16:49:27.363: INFO: Pod "pod-projected-configmaps-38fdf214-5ff0-406d-af5c-4c8c688d9422": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.020878578s
STEP: Saw pod success
Oct 28 16:49:27.363: INFO: Pod "pod-projected-configmaps-38fdf214-5ff0-406d-af5c-4c8c688d9422" satisfied condition "success or failure"
Oct 28 16:49:27.367: INFO: Trying to get logs from node kh4ga-worker-000003 pod pod-projected-configmaps-38fdf214-5ff0-406d-af5c-4c8c688d9422 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Oct 28 16:49:27.392: INFO: Waiting for pod pod-projected-configmaps-38fdf214-5ff0-406d-af5c-4c8c688d9422 to disappear
Oct 28 16:49:27.403: INFO: Pod pod-projected-configmaps-38fdf214-5ff0-406d-af5c-4c8c688d9422 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 16:49:27.403: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4372" for this suite.
Oct 28 16:49:33.422: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 16:49:33.573: INFO: namespace projected-4372 deletion completed in 6.164558619s

• [SLOW TEST:12.406 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 16:49:33.574: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename hostpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in hostpath-2414
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test hostPath mode
Oct 28 16:49:33.741: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "hostpath-2414" to be "success or failure"
Oct 28 16:49:33.753: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 11.392521ms
Oct 28 16:49:35.758: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016280029s
Oct 28 16:49:37.762: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 4.020743534s
Oct 28 16:49:39.767: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.025927537s
STEP: Saw pod success
Oct 28 16:49:39.767: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Oct 28 16:49:39.775: INFO: Trying to get logs from node kh4ga-worker-000003 pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Oct 28 16:49:39.802: INFO: Waiting for pod pod-host-path-test to disappear
Oct 28 16:49:39.808: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 16:49:39.808: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "hostpath-2414" for this suite.
Oct 28 16:49:45.831: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 16:49:46.018: INFO: namespace hostpath-2414 deletion completed in 6.203381839s

• [SLOW TEST:12.444 seconds]
[sig-storage] HostPath
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 16:49:46.018: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-3310
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-3310.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-3310.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-3310.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-3310.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-3310.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-3310.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe /etc/hosts
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Oct 28 16:49:52.232: INFO: Unable to read wheezy_udp@PodARecord from pod dns-3310/dns-test-629bbc7c-b4fa-4cd7-8190-345eb855c78e: the server could not find the requested resource (get pods dns-test-629bbc7c-b4fa-4cd7-8190-345eb855c78e)
Oct 28 16:49:52.238: INFO: Unable to read wheezy_tcp@PodARecord from pod dns-3310/dns-test-629bbc7c-b4fa-4cd7-8190-345eb855c78e: the server could not find the requested resource (get pods dns-test-629bbc7c-b4fa-4cd7-8190-345eb855c78e)
Oct 28 16:49:52.256: INFO: Unable to read jessie_udp@PodARecord from pod dns-3310/dns-test-629bbc7c-b4fa-4cd7-8190-345eb855c78e: the server could not find the requested resource (get pods dns-test-629bbc7c-b4fa-4cd7-8190-345eb855c78e)
Oct 28 16:49:52.262: INFO: Unable to read jessie_tcp@PodARecord from pod dns-3310/dns-test-629bbc7c-b4fa-4cd7-8190-345eb855c78e: the server could not find the requested resource (get pods dns-test-629bbc7c-b4fa-4cd7-8190-345eb855c78e)
Oct 28 16:49:52.262: INFO: Lookups using dns-3310/dns-test-629bbc7c-b4fa-4cd7-8190-345eb855c78e failed for: [wheezy_udp@PodARecord wheezy_tcp@PodARecord jessie_udp@PodARecord jessie_tcp@PodARecord]

Oct 28 16:49:57.310: INFO: DNS probes using dns-3310/dns-test-629bbc7c-b4fa-4cd7-8190-345eb855c78e succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 16:49:57.348: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-3310" for this suite.
Oct 28 16:50:03.378: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 16:50:03.549: INFO: namespace dns-3310 deletion completed in 6.193915754s

• [SLOW TEST:17.531 seconds]
[sig-network] DNS
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 16:50:03.550: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1227
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-map-55c8385c-8c0d-4268-8425-da30a451a98b
STEP: Creating a pod to test consume configMaps
Oct 28 16:50:03.759: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-992c1985-a097-435e-9962-ebfcab823193" in namespace "projected-1227" to be "success or failure"
Oct 28 16:50:03.776: INFO: Pod "pod-projected-configmaps-992c1985-a097-435e-9962-ebfcab823193": Phase="Pending", Reason="", readiness=false. Elapsed: 17.205432ms
Oct 28 16:50:05.781: INFO: Pod "pod-projected-configmaps-992c1985-a097-435e-9962-ebfcab823193": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021672501s
Oct 28 16:50:07.785: INFO: Pod "pod-projected-configmaps-992c1985-a097-435e-9962-ebfcab823193": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.025759767s
STEP: Saw pod success
Oct 28 16:50:07.785: INFO: Pod "pod-projected-configmaps-992c1985-a097-435e-9962-ebfcab823193" satisfied condition "success or failure"
Oct 28 16:50:07.789: INFO: Trying to get logs from node kh4ga-worker-000000 pod pod-projected-configmaps-992c1985-a097-435e-9962-ebfcab823193 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Oct 28 16:50:07.812: INFO: Waiting for pod pod-projected-configmaps-992c1985-a097-435e-9962-ebfcab823193 to disappear
Oct 28 16:50:07.818: INFO: Pod pod-projected-configmaps-992c1985-a097-435e-9962-ebfcab823193 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 16:50:07.818: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1227" for this suite.
Oct 28 16:50:13.856: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 16:50:14.034: INFO: namespace projected-1227 deletion completed in 6.210044146s

• [SLOW TEST:10.484 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 16:50:14.034: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-986
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1685
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Oct 28 16:50:14.192: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-124947935 run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-986'
Oct 28 16:50:14.283: INFO: stderr: ""
Oct 28 16:50:14.283: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1690
Oct 28 16:50:14.291: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-124947935 delete pods e2e-test-nginx-pod --namespace=kubectl-986'
Oct 28 16:50:20.634: INFO: stderr: ""
Oct 28 16:50:20.634: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 16:50:20.635: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-986" for this suite.
Oct 28 16:50:26.664: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 16:50:26.814: INFO: namespace kubectl-986 deletion completed in 6.172473332s

• [SLOW TEST:12.780 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run pod
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 16:50:26.815: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-6217
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
Oct 28 16:50:26.968: INFO: observed the pod list
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 16:50:40.928: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-6217" for this suite.
Oct 28 16:50:46.950: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 16:50:47.133: INFO: namespace pods-6217 deletion completed in 6.198962015s

• [SLOW TEST:20.319 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 16:50:47.133: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-7937
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-2d92ed5c-34e6-4cd5-959d-ddb5ab425491
STEP: Creating a pod to test consume secrets
Oct 28 16:50:47.301: INFO: Waiting up to 5m0s for pod "pod-secrets-6d56b4f7-74f7-40f2-bfb9-f631fea6b751" in namespace "secrets-7937" to be "success or failure"
Oct 28 16:50:47.306: INFO: Pod "pod-secrets-6d56b4f7-74f7-40f2-bfb9-f631fea6b751": Phase="Pending", Reason="", readiness=false. Elapsed: 4.847609ms
Oct 28 16:50:49.311: INFO: Pod "pod-secrets-6d56b4f7-74f7-40f2-bfb9-f631fea6b751": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010327632s
Oct 28 16:50:51.316: INFO: Pod "pod-secrets-6d56b4f7-74f7-40f2-bfb9-f631fea6b751": Phase="Pending", Reason="", readiness=false. Elapsed: 4.015202153s
Oct 28 16:50:53.321: INFO: Pod "pod-secrets-6d56b4f7-74f7-40f2-bfb9-f631fea6b751": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.020539973s
STEP: Saw pod success
Oct 28 16:50:53.321: INFO: Pod "pod-secrets-6d56b4f7-74f7-40f2-bfb9-f631fea6b751" satisfied condition "success or failure"
Oct 28 16:50:53.325: INFO: Trying to get logs from node kh4ga-worker-000000 pod pod-secrets-6d56b4f7-74f7-40f2-bfb9-f631fea6b751 container secret-env-test: <nil>
STEP: delete the pod
Oct 28 16:50:53.353: INFO: Waiting for pod pod-secrets-6d56b4f7-74f7-40f2-bfb9-f631fea6b751 to disappear
Oct 28 16:50:53.356: INFO: Pod pod-secrets-6d56b4f7-74f7-40f2-bfb9-f631fea6b751 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 16:50:53.357: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7937" for this suite.
Oct 28 16:50:59.377: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 16:50:59.532: INFO: namespace secrets-7937 deletion completed in 6.169184923s

• [SLOW TEST:12.398 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 16:50:59.532: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-7716
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-map-67d9cbd1-33c1-495a-b681-d317f2b7efb9
STEP: Creating a pod to test consume configMaps
Oct 28 16:50:59.698: INFO: Waiting up to 5m0s for pod "pod-configmaps-377fc125-5bea-49b9-b3e0-c8fe281f3e17" in namespace "configmap-7716" to be "success or failure"
Oct 28 16:50:59.703: INFO: Pod "pod-configmaps-377fc125-5bea-49b9-b3e0-c8fe281f3e17": Phase="Pending", Reason="", readiness=false. Elapsed: 5.003709ms
Oct 28 16:51:01.708: INFO: Pod "pod-configmaps-377fc125-5bea-49b9-b3e0-c8fe281f3e17": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009638019s
Oct 28 16:51:03.713: INFO: Pod "pod-configmaps-377fc125-5bea-49b9-b3e0-c8fe281f3e17": Phase="Pending", Reason="", readiness=false. Elapsed: 4.014875428s
Oct 28 16:51:05.718: INFO: Pod "pod-configmaps-377fc125-5bea-49b9-b3e0-c8fe281f3e17": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.019758135s
STEP: Saw pod success
Oct 28 16:51:05.718: INFO: Pod "pod-configmaps-377fc125-5bea-49b9-b3e0-c8fe281f3e17" satisfied condition "success or failure"
Oct 28 16:51:05.722: INFO: Trying to get logs from node kh4ga-worker-000000 pod pod-configmaps-377fc125-5bea-49b9-b3e0-c8fe281f3e17 container configmap-volume-test: <nil>
STEP: delete the pod
Oct 28 16:51:05.753: INFO: Waiting for pod pod-configmaps-377fc125-5bea-49b9-b3e0-c8fe281f3e17 to disappear
Oct 28 16:51:05.757: INFO: Pod pod-configmaps-377fc125-5bea-49b9-b3e0-c8fe281f3e17 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 16:51:05.757: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7716" for this suite.
Oct 28 16:51:11.778: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 16:51:11.942: INFO: namespace configmap-7716 deletion completed in 6.179660605s

• [SLOW TEST:12.410 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 16:51:11.943: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-9108
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod liveness-68dc29f1-d1fe-4d06-bf52-0ef3ffa58c6a in namespace container-probe-9108
Oct 28 16:51:20.112: INFO: Started pod liveness-68dc29f1-d1fe-4d06-bf52-0ef3ffa58c6a in namespace container-probe-9108
STEP: checking the pod's current state and verifying that restartCount is present
Oct 28 16:51:20.115: INFO: Initial restart count of pod liveness-68dc29f1-d1fe-4d06-bf52-0ef3ffa58c6a is 0
Oct 28 16:51:32.147: INFO: Restart count of pod container-probe-9108/liveness-68dc29f1-d1fe-4d06-bf52-0ef3ffa58c6a is now 1 (12.03167303s elapsed)
Oct 28 16:51:52.210: INFO: Restart count of pod container-probe-9108/liveness-68dc29f1-d1fe-4d06-bf52-0ef3ffa58c6a is now 2 (32.095404797s elapsed)
Oct 28 16:52:12.267: INFO: Restart count of pod container-probe-9108/liveness-68dc29f1-d1fe-4d06-bf52-0ef3ffa58c6a is now 3 (52.152338972s elapsed)
Oct 28 16:52:32.317: INFO: Restart count of pod container-probe-9108/liveness-68dc29f1-d1fe-4d06-bf52-0ef3ffa58c6a is now 4 (1m12.201757203s elapsed)
Oct 28 16:53:40.488: INFO: Restart count of pod container-probe-9108/liveness-68dc29f1-d1fe-4d06-bf52-0ef3ffa58c6a is now 5 (2m20.373208343s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 16:53:40.500: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-9108" for this suite.
Oct 28 16:53:46.523: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 16:53:46.669: INFO: namespace container-probe-9108 deletion completed in 6.161634736s

• [SLOW TEST:154.726 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 16:53:46.670: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-2901
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Oct 28 16:53:46.872: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-124947935 create -f - --namespace=kubectl-2901'
Oct 28 16:53:47.414: INFO: stderr: ""
Oct 28 16:53:47.414: INFO: stdout: "replicationcontroller/redis-master created\n"
Oct 28 16:53:47.414: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-124947935 create -f - --namespace=kubectl-2901'
Oct 28 16:53:47.994: INFO: stderr: ""
Oct 28 16:53:47.994: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Oct 28 16:53:48.999: INFO: Selector matched 1 pods for map[app:redis]
Oct 28 16:53:48.999: INFO: Found 0 / 1
Oct 28 16:53:49.999: INFO: Selector matched 1 pods for map[app:redis]
Oct 28 16:53:49.999: INFO: Found 0 / 1
Oct 28 16:53:51.001: INFO: Selector matched 1 pods for map[app:redis]
Oct 28 16:53:51.001: INFO: Found 0 / 1
Oct 28 16:53:52.000: INFO: Selector matched 1 pods for map[app:redis]
Oct 28 16:53:52.000: INFO: Found 1 / 1
Oct 28 16:53:52.000: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Oct 28 16:53:52.004: INFO: Selector matched 1 pods for map[app:redis]
Oct 28 16:53:52.004: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Oct 28 16:53:52.004: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-124947935 describe pod redis-master-7hqds --namespace=kubectl-2901'
Oct 28 16:53:52.098: INFO: stderr: ""
Oct 28 16:53:52.098: INFO: stdout: "Name:           redis-master-7hqds\nNamespace:      kubectl-2901\nPriority:       0\nNode:           kh4ga-worker-000000/10.2.1.4\nStart Time:     Mon, 28 Oct 2019 16:53:47 +0000\nLabels:         app=redis\n                role=master\nAnnotations:    cni.projectcalico.org/podIP: 10.2.130.47/32\n                kubernetes.io/psp: e2e-test-privileged-psp\nStatus:         Running\nIP:             10.2.130.47\nControlled By:  ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   docker://040c664ebe7493a3393a1d31c4a5bf9ecafeeabd39f0b0639c4922d8eb0130f9\n    Image:          gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Image ID:       docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Mon, 28 Oct 2019 16:53:51 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-nf679 (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-nf679:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-nf679\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age   From                          Message\n  ----    ------     ----  ----                          -------\n  Normal  Scheduled  5s    default-scheduler             Successfully assigned kubectl-2901/redis-master-7hqds to kh4ga-worker-000000\n  Normal  Pulled     3s    kubelet, kh4ga-worker-000000  Container image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\" already present on machine\n  Normal  Created    1s    kubelet, kh4ga-worker-000000  Created container redis-master\n  Normal  Started    1s    kubelet, kh4ga-worker-000000  Started container redis-master\n"
Oct 28 16:53:52.098: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-124947935 describe rc redis-master --namespace=kubectl-2901'
Oct 28 16:53:52.186: INFO: stderr: ""
Oct 28 16:53:52.186: INFO: stdout: "Name:         redis-master\nNamespace:    kubectl-2901\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  5s    replication-controller  Created pod: redis-master-7hqds\n"
Oct 28 16:53:52.187: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-124947935 describe service redis-master --namespace=kubectl-2901'
Oct 28 16:53:52.269: INFO: stderr: ""
Oct 28 16:53:52.269: INFO: stdout: "Name:              redis-master\nNamespace:         kubectl-2901\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                172.31.185.134\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         10.2.130.47:6379\nSession Affinity:  None\nEvents:            <none>\n"
Oct 28 16:53:52.277: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-124947935 describe node kh4ga-master-000000'
Oct 28 16:53:52.380: INFO: stderr: ""
Oct 28 16:53:52.380: INFO: stdout: "Name:               kh4ga-master-000000\nRoles:              master\nLabels:             azure-operator.giantswarm.io/version=2.7.0\n                    beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/instance-type=Standard_D2s_v3\n                    beta.kubernetes.io/os=linux\n                    failure-domain.beta.kubernetes.io/region=westeurope\n                    failure-domain.beta.kubernetes.io/zone=0\n                    giantswarm.io/provider=azure\n                    ip=10.2.0.5\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=kh4ga-master-000000\n                    kubernetes.io/os=linux\n                    kubernetes.io/role=master\n                    node-role.kubernetes.io/master=\n                    node.kubernetes.io/master=\n                    role=master\nAnnotations:        node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Mon, 28 Oct 2019 16:21:12 +0000\nTaints:             node-role.kubernetes.io/master:NoSchedule\nUnschedulable:      false\nConditions:\n  Type                 Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----                 ------  -----------------                 ------------------                ------                       -------\n  NetworkUnavailable   False   Mon, 28 Oct 2019 16:21:37 +0000   Mon, 28 Oct 2019 16:21:37 +0000   RouteCreated                 RouteController created a route\n  MemoryPressure       False   Mon, 28 Oct 2019 16:53:48 +0000   Mon, 28 Oct 2019 16:21:00 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure         False   Mon, 28 Oct 2019 16:53:48 +0000   Mon, 28 Oct 2019 16:21:00 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure          False   Mon, 28 Oct 2019 16:53:48 +0000   Mon, 28 Oct 2019 16:21:00 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready                True    Mon, 28 Oct 2019 16:53:48 +0000   Mon, 28 Oct 2019 16:22:42 +0000   KubeletReady                 kubelet is posting ready status\nAddresses:\n  InternalIP:  10.2.0.5\n  Hostname:    kh4ga-master-000000\nCapacity:\n attachable-volumes-azure-disk:  4\n cpu:                            2\n ephemeral-storage:              28454196Ki\n hugepages-1Gi:                  0\n hugepages-2Mi:                  0\n memory:                         7955Mi\n pods:                           110\nAllocatable:\n attachable-volumes-azure-disk:  4\n cpu:                            1400m\n ephemeral-storage:              27405620Ki\n hugepages-1Gi:                  0\n hugepages-2Mi:                  0\n memory:                         6091Mi\n pods:                           110\nSystem Info:\n Machine ID:                 d1b688501e1f4419ba8f3ab38a913502\n System UUID:                9ca6a85d-8386-1e46-b253-c80fcc09d675\n Boot ID:                    94981986-17bd-4718-8b1b-9141933fb529\n Kernel Version:             4.19.68-coreos\n OS Image:                   Container Linux by CoreOS 2191.5.0 (Rhyolite)\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  docker://18.6.3\n Kubelet Version:            v1.15.5\n Kube-Proxy Version:         v1.15.5\nPodCIDR:                     10.2.128.0/24\nProviderID:                  azure:///subscriptions/1be3b2e6-497b-45b9-915f-eb35cae23c6a/resourceGroups/kh4ga/providers/Microsoft.Compute/virtualMachineScaleSets/kh4ga-master/virtualMachines/0\nNon-terminated Pods:         (10 in total)\n  Namespace                  Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                  ----                                                       ------------  ----------  ---------------  -------------  ---\n  kube-system                calico-node-q5b7t                                          250m (17%)    250m (17%)  150Mi (2%)       150Mi (2%)     31m\n  kube-system                cert-exporter-59sr6                                        50m (3%)      50m (3%)    50Mi (0%)        50Mi (0%)      27m\n  kube-system                k8s-api-healthz-kh4ga-master-000000                        50m (3%)      0 (0%)      20Mi (0%)        0 (0%)         31m\n  kube-system                k8s-api-server-kh4ga-master-000000                         300m (21%)    0 (0%)      300Mi (4%)       0 (0%)         31m\n  kube-system                k8s-controller-manager-kh4ga-master-000000                 200m (14%)    0 (0%)      200Mi (3%)       0 (0%)         31m\n  kube-system                k8s-scheduler-kh4ga-master-000000                          100m (7%)     0 (0%)      100Mi (1%)       0 (0%)         31m\n  kube-system                kube-proxy-k276k                                           75m (5%)      0 (0%)      80Mi (1%)        0 (0%)         32m\n  kube-system                net-exporter-944vn                                         0 (0%)        0 (0%)      75Mi (1%)        75Mi (1%)      27m\n  kube-system                node-exporter-hr5xf                                        75m (5%)      0 (0%)      50Mi (0%)        50Mi (0%)      28m\n  sonobuoy                   sonobuoy-systemd-logs-daemon-set-80aafb278b8f4e15-tdcp4    0 (0%)        0 (0%)      0 (0%)           0 (0%)         22m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource                       Requests      Limits\n  --------                       --------      ------\n  cpu                            1100m (78%)   300m (21%)\n  memory                         1025Mi (16%)  325Mi (5%)\n  ephemeral-storage              0 (0%)        0 (0%)\n  attachable-volumes-azure-disk  0             0\nEvents:\n  Type    Reason                   Age                From                             Message\n  ----    ------                   ----               ----                             -------\n  Normal  Starting                 32m                kubelet, kh4ga-master-000000     Starting kubelet.\n  Normal  NodeHasSufficientMemory  32m (x8 over 32m)  kubelet, kh4ga-master-000000     Node kh4ga-master-000000 status is now: NodeHasSufficientMemory\n  Normal  NodeHasNoDiskPressure    32m (x8 over 32m)  kubelet, kh4ga-master-000000     Node kh4ga-master-000000 status is now: NodeHasNoDiskPressure\n  Normal  NodeHasSufficientPID     32m (x7 over 32m)  kubelet, kh4ga-master-000000     Node kh4ga-master-000000 status is now: NodeHasSufficientPID\n  Normal  NodeAllocatableEnforced  32m                kubelet, kh4ga-master-000000     Updated Node Allocatable limit across pods\n  Normal  Starting                 32m                kube-proxy, kh4ga-master-000000  Starting kube-proxy.\n  Normal  Starting                 32m                kube-proxy, kh4ga-master-000000  Starting kube-proxy.\n  Normal  Starting                 31m                kubelet, kh4ga-master-000000     Starting kubelet.\n  Normal  NodeAllocatableEnforced  31m                kubelet, kh4ga-master-000000     Updated Node Allocatable limit across pods\n  Normal  NodeHasSufficientMemory  31m                kubelet, kh4ga-master-000000     Node kh4ga-master-000000 status is now: NodeHasSufficientMemory\n  Normal  NodeHasNoDiskPressure    31m                kubelet, kh4ga-master-000000     Node kh4ga-master-000000 status is now: NodeHasNoDiskPressure\n  Normal  NodeHasSufficientPID     31m                kubelet, kh4ga-master-000000     Node kh4ga-master-000000 status is now: NodeHasSufficientPID\n  Normal  NodeReady                31m                kubelet, kh4ga-master-000000     Node kh4ga-master-000000 status is now: NodeReady\n"
Oct 28 16:53:52.380: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-124947935 describe namespace kubectl-2901'
Oct 28 16:53:52.463: INFO: stderr: ""
Oct 28 16:53:52.463: INFO: stdout: "Name:         kubectl-2901\nLabels:       e2e-framework=kubectl\n              e2e-run=6d4a3416-8f32-44a1-803c-eef1ef53e116\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 16:53:52.463: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2901" for this suite.
Oct 28 16:54:14.482: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 16:54:14.642: INFO: namespace kubectl-2901 deletion completed in 22.174662889s

• [SLOW TEST:27.973 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl describe
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 16:54:14.643: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-1094
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Oct 28 16:54:14.840: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Oct 28 16:54:14.862: INFO: Number of nodes with available pods: 0
Oct 28 16:54:14.862: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Oct 28 16:54:14.886: INFO: Number of nodes with available pods: 0
Oct 28 16:54:14.886: INFO: Node kh4ga-worker-000000 is running more than one daemon pod
Oct 28 16:54:15.892: INFO: Number of nodes with available pods: 0
Oct 28 16:54:15.892: INFO: Node kh4ga-worker-000000 is running more than one daemon pod
Oct 28 16:54:16.891: INFO: Number of nodes with available pods: 0
Oct 28 16:54:16.891: INFO: Node kh4ga-worker-000000 is running more than one daemon pod
Oct 28 16:54:17.892: INFO: Number of nodes with available pods: 0
Oct 28 16:54:17.892: INFO: Node kh4ga-worker-000000 is running more than one daemon pod
Oct 28 16:54:18.891: INFO: Number of nodes with available pods: 0
Oct 28 16:54:18.891: INFO: Node kh4ga-worker-000000 is running more than one daemon pod
Oct 28 16:54:19.894: INFO: Number of nodes with available pods: 1
Oct 28 16:54:19.894: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Oct 28 16:54:19.920: INFO: Number of nodes with available pods: 1
Oct 28 16:54:19.920: INFO: Number of running nodes: 0, number of available pods: 1
Oct 28 16:54:20.924: INFO: Number of nodes with available pods: 0
Oct 28 16:54:20.924: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Oct 28 16:54:20.935: INFO: Number of nodes with available pods: 0
Oct 28 16:54:20.935: INFO: Node kh4ga-worker-000000 is running more than one daemon pod
Oct 28 16:54:21.939: INFO: Number of nodes with available pods: 0
Oct 28 16:54:21.939: INFO: Node kh4ga-worker-000000 is running more than one daemon pod
Oct 28 16:54:22.951: INFO: Number of nodes with available pods: 0
Oct 28 16:54:22.951: INFO: Node kh4ga-worker-000000 is running more than one daemon pod
Oct 28 16:54:23.943: INFO: Number of nodes with available pods: 0
Oct 28 16:54:23.943: INFO: Node kh4ga-worker-000000 is running more than one daemon pod
Oct 28 16:54:24.940: INFO: Number of nodes with available pods: 0
Oct 28 16:54:24.940: INFO: Node kh4ga-worker-000000 is running more than one daemon pod
Oct 28 16:54:25.941: INFO: Number of nodes with available pods: 0
Oct 28 16:54:25.941: INFO: Node kh4ga-worker-000000 is running more than one daemon pod
Oct 28 16:54:26.941: INFO: Number of nodes with available pods: 0
Oct 28 16:54:26.941: INFO: Node kh4ga-worker-000000 is running more than one daemon pod
Oct 28 16:54:27.940: INFO: Number of nodes with available pods: 0
Oct 28 16:54:27.940: INFO: Node kh4ga-worker-000000 is running more than one daemon pod
Oct 28 16:54:28.941: INFO: Number of nodes with available pods: 0
Oct 28 16:54:28.941: INFO: Node kh4ga-worker-000000 is running more than one daemon pod
Oct 28 16:54:29.940: INFO: Number of nodes with available pods: 0
Oct 28 16:54:29.940: INFO: Node kh4ga-worker-000000 is running more than one daemon pod
Oct 28 16:54:30.951: INFO: Number of nodes with available pods: 0
Oct 28 16:54:30.951: INFO: Node kh4ga-worker-000000 is running more than one daemon pod
Oct 28 16:54:31.941: INFO: Number of nodes with available pods: 0
Oct 28 16:54:31.941: INFO: Node kh4ga-worker-000000 is running more than one daemon pod
Oct 28 16:54:32.940: INFO: Number of nodes with available pods: 0
Oct 28 16:54:32.940: INFO: Node kh4ga-worker-000000 is running more than one daemon pod
Oct 28 16:54:33.941: INFO: Number of nodes with available pods: 0
Oct 28 16:54:33.941: INFO: Node kh4ga-worker-000000 is running more than one daemon pod
Oct 28 16:54:34.945: INFO: Number of nodes with available pods: 0
Oct 28 16:54:34.945: INFO: Node kh4ga-worker-000000 is running more than one daemon pod
Oct 28 16:54:35.940: INFO: Number of nodes with available pods: 1
Oct 28 16:54:35.940: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-1094, will wait for the garbage collector to delete the pods
Oct 28 16:54:36.009: INFO: Deleting DaemonSet.extensions daemon-set took: 8.191547ms
Oct 28 16:54:36.110: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.244475ms
Oct 28 16:54:41.214: INFO: Number of nodes with available pods: 0
Oct 28 16:54:41.214: INFO: Number of running nodes: 0, number of available pods: 0
Oct 28 16:54:41.219: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-1094/daemonsets","resourceVersion":"7886"},"items":null}

Oct 28 16:54:41.223: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-1094/pods","resourceVersion":"7886"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 16:54:41.251: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-1094" for this suite.
Oct 28 16:54:47.270: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 16:54:47.429: INFO: namespace daemonsets-1094 deletion completed in 6.172294545s

• [SLOW TEST:32.787 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 16:54:47.429: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-7755
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-projected-zls6
STEP: Creating a pod to test atomic-volume-subpath
Oct 28 16:54:47.606: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-zls6" in namespace "subpath-7755" to be "success or failure"
Oct 28 16:54:47.612: INFO: Pod "pod-subpath-test-projected-zls6": Phase="Pending", Reason="", readiness=false. Elapsed: 6.558437ms
Oct 28 16:54:49.617: INFO: Pod "pod-subpath-test-projected-zls6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01075486s
Oct 28 16:54:51.621: INFO: Pod "pod-subpath-test-projected-zls6": Phase="Pending", Reason="", readiness=false. Elapsed: 4.015284258s
Oct 28 16:54:53.627: INFO: Pod "pod-subpath-test-projected-zls6": Phase="Running", Reason="", readiness=true. Elapsed: 6.021168037s
Oct 28 16:54:55.632: INFO: Pod "pod-subpath-test-projected-zls6": Phase="Running", Reason="", readiness=true. Elapsed: 8.026059385s
Oct 28 16:54:57.636: INFO: Pod "pod-subpath-test-projected-zls6": Phase="Running", Reason="", readiness=true. Elapsed: 10.030651504s
Oct 28 16:54:59.641: INFO: Pod "pod-subpath-test-projected-zls6": Phase="Running", Reason="", readiness=true. Elapsed: 12.035370498s
Oct 28 16:55:01.646: INFO: Pod "pod-subpath-test-projected-zls6": Phase="Running", Reason="", readiness=true. Elapsed: 14.040315168s
Oct 28 16:55:03.651: INFO: Pod "pod-subpath-test-projected-zls6": Phase="Running", Reason="", readiness=true. Elapsed: 16.045671914s
Oct 28 16:55:05.656: INFO: Pod "pod-subpath-test-projected-zls6": Phase="Running", Reason="", readiness=true. Elapsed: 18.050588531s
Oct 28 16:55:07.661: INFO: Pod "pod-subpath-test-projected-zls6": Phase="Running", Reason="", readiness=true. Elapsed: 20.055488423s
Oct 28 16:55:09.666: INFO: Pod "pod-subpath-test-projected-zls6": Phase="Running", Reason="", readiness=true. Elapsed: 22.06057339s
Oct 28 16:55:11.672: INFO: Pod "pod-subpath-test-projected-zls6": Phase="Running", Reason="", readiness=true. Elapsed: 24.066496036s
Oct 28 16:55:13.676: INFO: Pod "pod-subpath-test-projected-zls6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 26.070657348s
STEP: Saw pod success
Oct 28 16:55:13.676: INFO: Pod "pod-subpath-test-projected-zls6" satisfied condition "success or failure"
Oct 28 16:55:13.680: INFO: Trying to get logs from node kh4ga-worker-000003 pod pod-subpath-test-projected-zls6 container test-container-subpath-projected-zls6: <nil>
STEP: delete the pod
Oct 28 16:55:13.708: INFO: Waiting for pod pod-subpath-test-projected-zls6 to disappear
Oct 28 16:55:13.712: INFO: Pod pod-subpath-test-projected-zls6 no longer exists
STEP: Deleting pod pod-subpath-test-projected-zls6
Oct 28 16:55:13.712: INFO: Deleting pod "pod-subpath-test-projected-zls6" in namespace "subpath-7755"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 16:55:13.716: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-7755" for this suite.
Oct 28 16:55:19.736: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 16:55:19.895: INFO: namespace subpath-7755 deletion completed in 6.173429858s

• [SLOW TEST:32.466 seconds]
[sig-storage] Subpath
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with projected pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 16:55:19.895: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-325
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-map-4883f04a-c156-4844-9483-222b4a21061a
STEP: Creating a pod to test consume secrets
Oct 28 16:55:20.076: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-996f7322-edd8-4b8b-9172-0912e2590511" in namespace "projected-325" to be "success or failure"
Oct 28 16:55:20.085: INFO: Pod "pod-projected-secrets-996f7322-edd8-4b8b-9172-0912e2590511": Phase="Pending", Reason="", readiness=false. Elapsed: 8.962149ms
Oct 28 16:55:22.089: INFO: Pod "pod-projected-secrets-996f7322-edd8-4b8b-9172-0912e2590511": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013369756s
Oct 28 16:55:24.094: INFO: Pod "pod-projected-secrets-996f7322-edd8-4b8b-9172-0912e2590511": Phase="Pending", Reason="", readiness=false. Elapsed: 4.017961339s
Oct 28 16:55:26.098: INFO: Pod "pod-projected-secrets-996f7322-edd8-4b8b-9172-0912e2590511": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.022367297s
STEP: Saw pod success
Oct 28 16:55:26.098: INFO: Pod "pod-projected-secrets-996f7322-edd8-4b8b-9172-0912e2590511" satisfied condition "success or failure"
Oct 28 16:55:26.102: INFO: Trying to get logs from node kh4ga-worker-000000 pod pod-projected-secrets-996f7322-edd8-4b8b-9172-0912e2590511 container projected-secret-volume-test: <nil>
STEP: delete the pod
Oct 28 16:55:26.138: INFO: Waiting for pod pod-projected-secrets-996f7322-edd8-4b8b-9172-0912e2590511 to disappear
Oct 28 16:55:26.144: INFO: Pod pod-projected-secrets-996f7322-edd8-4b8b-9172-0912e2590511 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 16:55:26.144: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-325" for this suite.
Oct 28 16:55:32.164: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 16:55:32.315: INFO: namespace projected-325 deletion completed in 6.166001443s

• [SLOW TEST:12.420 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 16:55:32.316: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8299
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-68d18579-0d98-495d-b148-f923b546fdaa
STEP: Creating a pod to test consume configMaps
Oct 28 16:55:32.502: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-d607175f-b9e5-4e48-a27b-4da22bd535df" in namespace "projected-8299" to be "success or failure"
Oct 28 16:55:32.515: INFO: Pod "pod-projected-configmaps-d607175f-b9e5-4e48-a27b-4da22bd535df": Phase="Pending", Reason="", readiness=false. Elapsed: 13.402572ms
Oct 28 16:55:34.522: INFO: Pod "pod-projected-configmaps-d607175f-b9e5-4e48-a27b-4da22bd535df": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020679442s
Oct 28 16:55:36.527: INFO: Pod "pod-projected-configmaps-d607175f-b9e5-4e48-a27b-4da22bd535df": Phase="Pending", Reason="", readiness=false. Elapsed: 4.025669175s
Oct 28 16:55:38.537: INFO: Pod "pod-projected-configmaps-d607175f-b9e5-4e48-a27b-4da22bd535df": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.035150208s
STEP: Saw pod success
Oct 28 16:55:38.537: INFO: Pod "pod-projected-configmaps-d607175f-b9e5-4e48-a27b-4da22bd535df" satisfied condition "success or failure"
Oct 28 16:55:38.541: INFO: Trying to get logs from node kh4ga-worker-000003 pod pod-projected-configmaps-d607175f-b9e5-4e48-a27b-4da22bd535df container projected-configmap-volume-test: <nil>
STEP: delete the pod
Oct 28 16:55:38.564: INFO: Waiting for pod pod-projected-configmaps-d607175f-b9e5-4e48-a27b-4da22bd535df to disappear
Oct 28 16:55:38.573: INFO: Pod pod-projected-configmaps-d607175f-b9e5-4e48-a27b-4da22bd535df no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 16:55:38.573: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8299" for this suite.
Oct 28 16:55:44.593: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 16:55:44.758: INFO: namespace projected-8299 deletion completed in 6.179324552s

• [SLOW TEST:12.442 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 16:55:44.759: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-3210
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: starting the proxy server
Oct 28 16:55:44.921: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-124947935 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 16:55:44.986: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3210" for this suite.
Oct 28 16:55:51.006: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 16:55:51.155: INFO: namespace kubectl-3210 deletion completed in 6.164431939s

• [SLOW TEST:6.397 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Proxy server
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 16:55:51.156: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-1356
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Oct 28 16:55:51.324: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 16:55:52.397: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-1356" for this suite.
Oct 28 16:55:58.434: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 16:55:58.649: INFO: namespace custom-resource-definition-1356 deletion completed in 6.245075792s

• [SLOW TEST:7.493 seconds]
[sig-api-machinery] CustomResourceDefinition resources
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:35
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 16:55:58.649: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8754
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Oct 28 16:55:58.808: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f5eedcb4-2caa-4073-8cd2-74a5b4c099e7" in namespace "projected-8754" to be "success or failure"
Oct 28 16:55:58.818: INFO: Pod "downwardapi-volume-f5eedcb4-2caa-4073-8cd2-74a5b4c099e7": Phase="Pending", Reason="", readiness=false. Elapsed: 9.411049ms
Oct 28 16:56:00.822: INFO: Pod "downwardapi-volume-f5eedcb4-2caa-4073-8cd2-74a5b4c099e7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014067093s
Oct 28 16:56:02.827: INFO: Pod "downwardapi-volume-f5eedcb4-2caa-4073-8cd2-74a5b4c099e7": Phase="Pending", Reason="", readiness=false. Elapsed: 4.018977816s
Oct 28 16:56:04.832: INFO: Pod "downwardapi-volume-f5eedcb4-2caa-4073-8cd2-74a5b4c099e7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.023668514s
STEP: Saw pod success
Oct 28 16:56:04.832: INFO: Pod "downwardapi-volume-f5eedcb4-2caa-4073-8cd2-74a5b4c099e7" satisfied condition "success or failure"
Oct 28 16:56:04.836: INFO: Trying to get logs from node kh4ga-worker-000000 pod downwardapi-volume-f5eedcb4-2caa-4073-8cd2-74a5b4c099e7 container client-container: <nil>
STEP: delete the pod
Oct 28 16:56:04.864: INFO: Waiting for pod downwardapi-volume-f5eedcb4-2caa-4073-8cd2-74a5b4c099e7 to disappear
Oct 28 16:56:04.876: INFO: Pod downwardapi-volume-f5eedcb4-2caa-4073-8cd2-74a5b4c099e7 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 16:56:04.876: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8754" for this suite.
Oct 28 16:56:10.897: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 16:56:11.054: INFO: namespace projected-8754 deletion completed in 6.172447772s

• [SLOW TEST:12.406 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 16:56:11.055: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-4923
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-a69ff716-f947-4627-a620-eea33eb73035
STEP: Creating a pod to test consume secrets
Oct 28 16:56:11.224: INFO: Waiting up to 5m0s for pod "pod-secrets-145dc0db-89dd-4780-8361-b15db65399c5" in namespace "secrets-4923" to be "success or failure"
Oct 28 16:56:11.228: INFO: Pod "pod-secrets-145dc0db-89dd-4780-8361-b15db65399c5": Phase="Pending", Reason="", readiness=false. Elapsed: 4.026321ms
Oct 28 16:56:13.233: INFO: Pod "pod-secrets-145dc0db-89dd-4780-8361-b15db65399c5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009560128s
Oct 28 16:56:15.238: INFO: Pod "pod-secrets-145dc0db-89dd-4780-8361-b15db65399c5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014268109s
STEP: Saw pod success
Oct 28 16:56:15.238: INFO: Pod "pod-secrets-145dc0db-89dd-4780-8361-b15db65399c5" satisfied condition "success or failure"
Oct 28 16:56:15.241: INFO: Trying to get logs from node kh4ga-worker-000003 pod pod-secrets-145dc0db-89dd-4780-8361-b15db65399c5 container secret-volume-test: <nil>
STEP: delete the pod
Oct 28 16:56:15.273: INFO: Waiting for pod pod-secrets-145dc0db-89dd-4780-8361-b15db65399c5 to disappear
Oct 28 16:56:15.287: INFO: Pod pod-secrets-145dc0db-89dd-4780-8361-b15db65399c5 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 16:56:15.287: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-4923" for this suite.
Oct 28 16:56:21.319: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 16:56:21.489: INFO: namespace secrets-4923 deletion completed in 6.194140722s

• [SLOW TEST:10.435 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 16:56:21.490: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-3843
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name s-test-opt-del-077b8180-024b-4d4f-a964-7b400988a2ce
STEP: Creating secret with name s-test-opt-upd-724c0250-ee58-470c-b76a-7bc348e8290b
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-077b8180-024b-4d4f-a964-7b400988a2ce
STEP: Updating secret s-test-opt-upd-724c0250-ee58-470c-b76a-7bc348e8290b
STEP: Creating secret with name s-test-opt-create-553fb545-0042-4ccb-a3f4-586053b8e3fc
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 16:56:33.832: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3843" for this suite.
Oct 28 16:56:55.857: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 16:56:56.015: INFO: namespace secrets-3843 deletion completed in 22.172610819s

• [SLOW TEST:34.525 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 16:56:56.015: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-832
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 16:57:03.198: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-832" for this suite.
Oct 28 16:57:25.219: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 16:57:25.386: INFO: namespace replication-controller-832 deletion completed in 22.182112831s

• [SLOW TEST:29.371 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 16:57:25.387: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-7325
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Oct 28 16:57:25.578: INFO: Waiting up to 5m0s for pod "downward-api-8f67e01e-77d5-431f-9eeb-d6c4ead08682" in namespace "downward-api-7325" to be "success or failure"
Oct 28 16:57:25.592: INFO: Pod "downward-api-8f67e01e-77d5-431f-9eeb-d6c4ead08682": Phase="Pending", Reason="", readiness=false. Elapsed: 14.026666ms
Oct 28 16:57:27.606: INFO: Pod "downward-api-8f67e01e-77d5-431f-9eeb-d6c4ead08682": Phase="Pending", Reason="", readiness=false. Elapsed: 2.028323136s
Oct 28 16:57:29.611: INFO: Pod "downward-api-8f67e01e-77d5-431f-9eeb-d6c4ead08682": Phase="Pending", Reason="", readiness=false. Elapsed: 4.033351642s
Oct 28 16:57:31.616: INFO: Pod "downward-api-8f67e01e-77d5-431f-9eeb-d6c4ead08682": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.038048928s
STEP: Saw pod success
Oct 28 16:57:31.616: INFO: Pod "downward-api-8f67e01e-77d5-431f-9eeb-d6c4ead08682" satisfied condition "success or failure"
Oct 28 16:57:31.620: INFO: Trying to get logs from node kh4ga-worker-000000 pod downward-api-8f67e01e-77d5-431f-9eeb-d6c4ead08682 container dapi-container: <nil>
STEP: delete the pod
Oct 28 16:57:31.658: INFO: Waiting for pod downward-api-8f67e01e-77d5-431f-9eeb-d6c4ead08682 to disappear
Oct 28 16:57:31.662: INFO: Pod downward-api-8f67e01e-77d5-431f-9eeb-d6c4ead08682 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 16:57:31.662: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7325" for this suite.
Oct 28 16:57:37.694: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 16:57:37.870: INFO: namespace downward-api-7325 deletion completed in 6.198134904s

• [SLOW TEST:12.484 seconds]
[sig-node] Downward API
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 16:57:37.871: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-7648
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1721
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Oct 28 16:57:38.020: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-124947935 run e2e-test-nginx-pod --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --labels=run=e2e-test-nginx-pod --namespace=kubectl-7648'
Oct 28 16:57:38.105: INFO: stderr: ""
Oct 28 16:57:38.105: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod is running
STEP: verifying the pod e2e-test-nginx-pod was created
Oct 28 16:57:43.155: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-124947935 get pod e2e-test-nginx-pod --namespace=kubectl-7648 -o json'
Oct 28 16:57:43.228: INFO: stderr: ""
Oct 28 16:57:43.228: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"annotations\": {\n            \"cni.projectcalico.org/podIP\": \"10.2.131.61/32\",\n            \"kubernetes.io/psp\": \"cert-exporter-psp\"\n        },\n        \"creationTimestamp\": \"2019-10-28T16:57:38Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"kubectl-7648\",\n        \"resourceVersion\": \"8503\",\n        \"selfLink\": \"/api/v1/namespaces/kubectl-7648/pods/e2e-test-nginx-pod\",\n        \"uid\": \"c66cb1e6-ec92-4ee8-89af-676c6ebeb1c8\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-gchg7\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"kh4ga-worker-000003\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-gchg7\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-gchg7\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-10-28T16:57:38Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-10-28T16:57:42Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-10-28T16:57:42Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-10-28T16:57:38Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://ce89286b334ecdc9e3b9692aa324770773b99b6d60bcfdcefec49a57e3e3b203\",\n                \"image\": \"nginx:1.14-alpine\",\n                \"imageID\": \"docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2019-10-28T16:57:41Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.2.1.7\",\n        \"phase\": \"Running\",\n        \"podIP\": \"10.2.131.61\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2019-10-28T16:57:38Z\"\n    }\n}\n"
STEP: replace the image in the pod
Oct 28 16:57:43.229: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-124947935 replace -f - --namespace=kubectl-7648'
Oct 28 16:57:43.755: INFO: stderr: ""
Oct 28 16:57:43.755: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
STEP: verifying the pod e2e-test-nginx-pod has the right image docker.io/library/busybox:1.29
[AfterEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1726
Oct 28 16:57:43.759: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-124947935 delete pods e2e-test-nginx-pod --namespace=kubectl-7648'
Oct 28 16:57:56.336: INFO: stderr: ""
Oct 28 16:57:56.336: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 16:57:56.336: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7648" for this suite.
Oct 28 16:58:02.360: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 16:58:02.513: INFO: namespace kubectl-7648 deletion completed in 6.166256843s

• [SLOW TEST:24.641 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl replace
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 16:58:02.513: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6314
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Oct 28 16:58:02.681: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9ac4b9ae-9ab3-4bc6-9767-9519a416d60f" in namespace "projected-6314" to be "success or failure"
Oct 28 16:58:02.692: INFO: Pod "downwardapi-volume-9ac4b9ae-9ab3-4bc6-9767-9519a416d60f": Phase="Pending", Reason="", readiness=false. Elapsed: 11.02185ms
Oct 28 16:58:04.698: INFO: Pod "downwardapi-volume-9ac4b9ae-9ab3-4bc6-9767-9519a416d60f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016416629s
Oct 28 16:58:06.703: INFO: Pod "downwardapi-volume-9ac4b9ae-9ab3-4bc6-9767-9519a416d60f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02180349s
STEP: Saw pod success
Oct 28 16:58:06.703: INFO: Pod "downwardapi-volume-9ac4b9ae-9ab3-4bc6-9767-9519a416d60f" satisfied condition "success or failure"
Oct 28 16:58:06.707: INFO: Trying to get logs from node kh4ga-worker-000000 pod downwardapi-volume-9ac4b9ae-9ab3-4bc6-9767-9519a416d60f container client-container: <nil>
STEP: delete the pod
Oct 28 16:58:06.736: INFO: Waiting for pod downwardapi-volume-9ac4b9ae-9ab3-4bc6-9767-9519a416d60f to disappear
Oct 28 16:58:06.741: INFO: Pod downwardapi-volume-9ac4b9ae-9ab3-4bc6-9767-9519a416d60f no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 16:58:06.741: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6314" for this suite.
Oct 28 16:58:12.779: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 16:58:12.940: INFO: namespace projected-6314 deletion completed in 6.190696066s

• [SLOW TEST:10.427 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 16:58:12.940: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6677
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Oct 28 16:58:13.120: INFO: Waiting up to 5m0s for pod "downwardapi-volume-3acfb5d1-fd91-4de2-a8ca-8987dc8c6726" in namespace "projected-6677" to be "success or failure"
Oct 28 16:58:13.132: INFO: Pod "downwardapi-volume-3acfb5d1-fd91-4de2-a8ca-8987dc8c6726": Phase="Pending", Reason="", readiness=false. Elapsed: 11.668353ms
Oct 28 16:58:15.137: INFO: Pod "downwardapi-volume-3acfb5d1-fd91-4de2-a8ca-8987dc8c6726": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016382136s
Oct 28 16:58:17.141: INFO: Pod "downwardapi-volume-3acfb5d1-fd91-4de2-a8ca-8987dc8c6726": Phase="Pending", Reason="", readiness=false. Elapsed: 4.0208868s
Oct 28 16:58:19.147: INFO: Pod "downwardapi-volume-3acfb5d1-fd91-4de2-a8ca-8987dc8c6726": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.02640375s
STEP: Saw pod success
Oct 28 16:58:19.147: INFO: Pod "downwardapi-volume-3acfb5d1-fd91-4de2-a8ca-8987dc8c6726" satisfied condition "success or failure"
Oct 28 16:58:19.150: INFO: Trying to get logs from node kh4ga-worker-000003 pod downwardapi-volume-3acfb5d1-fd91-4de2-a8ca-8987dc8c6726 container client-container: <nil>
STEP: delete the pod
Oct 28 16:58:19.180: INFO: Waiting for pod downwardapi-volume-3acfb5d1-fd91-4de2-a8ca-8987dc8c6726 to disappear
Oct 28 16:58:19.183: INFO: Pod downwardapi-volume-3acfb5d1-fd91-4de2-a8ca-8987dc8c6726 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 16:58:19.183: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6677" for this suite.
Oct 28 16:58:25.203: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 16:58:25.374: INFO: namespace projected-6677 deletion completed in 6.184867399s

• [SLOW TEST:12.434 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 16:58:25.374: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-7941
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Oct 28 16:58:25.555: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-7941,SelfLink:/api/v1/namespaces/watch-7941/configmaps/e2e-watch-test-configmap-a,UID:c5a38544-a368-4b90-a220-e8d55b8e23ab,ResourceVersion:8653,Generation:0,CreationTimestamp:2019-10-28 16:58:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Oct 28 16:58:25.556: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-7941,SelfLink:/api/v1/namespaces/watch-7941/configmaps/e2e-watch-test-configmap-a,UID:c5a38544-a368-4b90-a220-e8d55b8e23ab,ResourceVersion:8653,Generation:0,CreationTimestamp:2019-10-28 16:58:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Oct 28 16:58:35.566: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-7941,SelfLink:/api/v1/namespaces/watch-7941/configmaps/e2e-watch-test-configmap-a,UID:c5a38544-a368-4b90-a220-e8d55b8e23ab,ResourceVersion:8671,Generation:0,CreationTimestamp:2019-10-28 16:58:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Oct 28 16:58:35.566: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-7941,SelfLink:/api/v1/namespaces/watch-7941/configmaps/e2e-watch-test-configmap-a,UID:c5a38544-a368-4b90-a220-e8d55b8e23ab,ResourceVersion:8671,Generation:0,CreationTimestamp:2019-10-28 16:58:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Oct 28 16:58:45.575: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-7941,SelfLink:/api/v1/namespaces/watch-7941/configmaps/e2e-watch-test-configmap-a,UID:c5a38544-a368-4b90-a220-e8d55b8e23ab,ResourceVersion:8690,Generation:0,CreationTimestamp:2019-10-28 16:58:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Oct 28 16:58:45.575: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-7941,SelfLink:/api/v1/namespaces/watch-7941/configmaps/e2e-watch-test-configmap-a,UID:c5a38544-a368-4b90-a220-e8d55b8e23ab,ResourceVersion:8690,Generation:0,CreationTimestamp:2019-10-28 16:58:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Oct 28 16:58:55.582: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-7941,SelfLink:/api/v1/namespaces/watch-7941/configmaps/e2e-watch-test-configmap-a,UID:c5a38544-a368-4b90-a220-e8d55b8e23ab,ResourceVersion:8708,Generation:0,CreationTimestamp:2019-10-28 16:58:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Oct 28 16:58:55.583: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-7941,SelfLink:/api/v1/namespaces/watch-7941/configmaps/e2e-watch-test-configmap-a,UID:c5a38544-a368-4b90-a220-e8d55b8e23ab,ResourceVersion:8708,Generation:0,CreationTimestamp:2019-10-28 16:58:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Oct 28 16:59:05.591: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-7941,SelfLink:/api/v1/namespaces/watch-7941/configmaps/e2e-watch-test-configmap-b,UID:95f69b86-0736-4847-860c-a3edb56775a1,ResourceVersion:8727,Generation:0,CreationTimestamp:2019-10-28 16:59:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Oct 28 16:59:05.591: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-7941,SelfLink:/api/v1/namespaces/watch-7941/configmaps/e2e-watch-test-configmap-b,UID:95f69b86-0736-4847-860c-a3edb56775a1,ResourceVersion:8727,Generation:0,CreationTimestamp:2019-10-28 16:59:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Oct 28 16:59:15.599: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-7941,SelfLink:/api/v1/namespaces/watch-7941/configmaps/e2e-watch-test-configmap-b,UID:95f69b86-0736-4847-860c-a3edb56775a1,ResourceVersion:8745,Generation:0,CreationTimestamp:2019-10-28 16:59:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Oct 28 16:59:15.599: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-7941,SelfLink:/api/v1/namespaces/watch-7941/configmaps/e2e-watch-test-configmap-b,UID:95f69b86-0736-4847-860c-a3edb56775a1,ResourceVersion:8745,Generation:0,CreationTimestamp:2019-10-28 16:59:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 16:59:25.600: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-7941" for this suite.
Oct 28 16:59:31.624: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 16:59:31.778: INFO: namespace watch-7941 deletion completed in 6.170980565s

• [SLOW TEST:66.404 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 16:59:31.779: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-7975
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Performing setup for networking test in namespace pod-network-test-7975
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Oct 28 16:59:31.927: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Oct 28 17:00:02.057: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.2.129.23 8081 | grep -v '^\s*$'] Namespace:pod-network-test-7975 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 28 17:00:02.057: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
Oct 28 17:00:03.181: INFO: Found all expected endpoints: [netserver-0]
Oct 28 17:00:03.185: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.2.131.63 8081 | grep -v '^\s*$'] Namespace:pod-network-test-7975 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 28 17:00:03.185: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
Oct 28 17:00:04.309: INFO: Found all expected endpoints: [netserver-1]
Oct 28 17:00:04.313: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.2.130.54 8081 | grep -v '^\s*$'] Namespace:pod-network-test-7975 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 28 17:00:04.313: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
Oct 28 17:00:05.442: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 17:00:05.442: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-7975" for this suite.
Oct 28 17:00:27.465: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 17:00:27.628: INFO: namespace pod-network-test-7975 deletion completed in 22.178610204s

• [SLOW TEST:55.849 seconds]
[sig-network] Networking
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 17:00:27.628: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-9983
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:273
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a replication controller
Oct 28 17:00:27.778: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-124947935 create -f - --namespace=kubectl-9983'
Oct 28 17:00:30.724: INFO: stderr: ""
Oct 28 17:00:30.724: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Oct 28 17:00:30.725: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-124947935 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9983'
Oct 28 17:00:30.822: INFO: stderr: ""
Oct 28 17:00:30.822: INFO: stdout: "update-demo-nautilus-tcxgm update-demo-nautilus-zjgp2 "
Oct 28 17:00:30.822: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-124947935 get pods update-demo-nautilus-tcxgm -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9983'
Oct 28 17:00:30.895: INFO: stderr: ""
Oct 28 17:00:30.895: INFO: stdout: ""
Oct 28 17:00:30.895: INFO: update-demo-nautilus-tcxgm is created but not running
Oct 28 17:00:35.896: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-124947935 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9983'
Oct 28 17:00:35.971: INFO: stderr: ""
Oct 28 17:00:35.971: INFO: stdout: "update-demo-nautilus-tcxgm update-demo-nautilus-zjgp2 "
Oct 28 17:00:35.971: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-124947935 get pods update-demo-nautilus-tcxgm -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9983'
Oct 28 17:00:36.038: INFO: stderr: ""
Oct 28 17:00:36.038: INFO: stdout: "true"
Oct 28 17:00:36.038: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-124947935 get pods update-demo-nautilus-tcxgm -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9983'
Oct 28 17:00:36.106: INFO: stderr: ""
Oct 28 17:00:36.106: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Oct 28 17:00:36.106: INFO: validating pod update-demo-nautilus-tcxgm
Oct 28 17:00:36.115: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct 28 17:00:36.115: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct 28 17:00:36.115: INFO: update-demo-nautilus-tcxgm is verified up and running
Oct 28 17:00:36.115: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-124947935 get pods update-demo-nautilus-zjgp2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9983'
Oct 28 17:00:36.198: INFO: stderr: ""
Oct 28 17:00:36.198: INFO: stdout: "true"
Oct 28 17:00:36.198: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-124947935 get pods update-demo-nautilus-zjgp2 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9983'
Oct 28 17:00:36.275: INFO: stderr: ""
Oct 28 17:00:36.275: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Oct 28 17:00:36.275: INFO: validating pod update-demo-nautilus-zjgp2
Oct 28 17:00:36.285: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct 28 17:00:36.285: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct 28 17:00:36.285: INFO: update-demo-nautilus-zjgp2 is verified up and running
STEP: scaling down the replication controller
Oct 28 17:00:36.288: INFO: scanned /root for discovery docs: <nil>
Oct 28 17:00:36.288: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-124947935 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=kubectl-9983'
Oct 28 17:00:37.388: INFO: stderr: ""
Oct 28 17:00:37.388: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Oct 28 17:00:37.388: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-124947935 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9983'
Oct 28 17:00:37.462: INFO: stderr: ""
Oct 28 17:00:37.462: INFO: stdout: "update-demo-nautilus-tcxgm update-demo-nautilus-zjgp2 "
STEP: Replicas for name=update-demo: expected=1 actual=2
Oct 28 17:00:42.462: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-124947935 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9983'
Oct 28 17:00:42.535: INFO: stderr: ""
Oct 28 17:00:42.535: INFO: stdout: "update-demo-nautilus-zjgp2 "
Oct 28 17:00:42.535: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-124947935 get pods update-demo-nautilus-zjgp2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9983'
Oct 28 17:00:42.603: INFO: stderr: ""
Oct 28 17:00:42.603: INFO: stdout: "true"
Oct 28 17:00:42.603: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-124947935 get pods update-demo-nautilus-zjgp2 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9983'
Oct 28 17:00:42.677: INFO: stderr: ""
Oct 28 17:00:42.677: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Oct 28 17:00:42.677: INFO: validating pod update-demo-nautilus-zjgp2
Oct 28 17:00:42.683: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct 28 17:00:42.683: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct 28 17:00:42.683: INFO: update-demo-nautilus-zjgp2 is verified up and running
STEP: scaling up the replication controller
Oct 28 17:00:42.686: INFO: scanned /root for discovery docs: <nil>
Oct 28 17:00:42.686: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-124947935 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=kubectl-9983'
Oct 28 17:00:43.789: INFO: stderr: ""
Oct 28 17:00:43.789: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Oct 28 17:00:43.789: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-124947935 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9983'
Oct 28 17:00:43.861: INFO: stderr: ""
Oct 28 17:00:43.861: INFO: stdout: "update-demo-nautilus-hbmtr update-demo-nautilus-zjgp2 "
Oct 28 17:00:43.861: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-124947935 get pods update-demo-nautilus-hbmtr -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9983'
Oct 28 17:00:43.928: INFO: stderr: ""
Oct 28 17:00:43.928: INFO: stdout: ""
Oct 28 17:00:43.928: INFO: update-demo-nautilus-hbmtr is created but not running
Oct 28 17:00:48.928: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-124947935 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9983'
Oct 28 17:00:49.005: INFO: stderr: ""
Oct 28 17:00:49.005: INFO: stdout: "update-demo-nautilus-hbmtr update-demo-nautilus-zjgp2 "
Oct 28 17:00:49.005: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-124947935 get pods update-demo-nautilus-hbmtr -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9983'
Oct 28 17:00:49.073: INFO: stderr: ""
Oct 28 17:00:49.073: INFO: stdout: "true"
Oct 28 17:00:49.073: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-124947935 get pods update-demo-nautilus-hbmtr -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9983'
Oct 28 17:00:49.139: INFO: stderr: ""
Oct 28 17:00:49.139: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Oct 28 17:00:49.139: INFO: validating pod update-demo-nautilus-hbmtr
Oct 28 17:00:49.148: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct 28 17:00:49.148: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct 28 17:00:49.148: INFO: update-demo-nautilus-hbmtr is verified up and running
Oct 28 17:00:49.148: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-124947935 get pods update-demo-nautilus-zjgp2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9983'
Oct 28 17:00:49.229: INFO: stderr: ""
Oct 28 17:00:49.229: INFO: stdout: "true"
Oct 28 17:00:49.229: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-124947935 get pods update-demo-nautilus-zjgp2 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9983'
Oct 28 17:00:49.306: INFO: stderr: ""
Oct 28 17:00:49.306: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Oct 28 17:00:49.306: INFO: validating pod update-demo-nautilus-zjgp2
Oct 28 17:00:49.319: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct 28 17:00:49.319: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct 28 17:00:49.319: INFO: update-demo-nautilus-zjgp2 is verified up and running
STEP: using delete to clean up resources
Oct 28 17:00:49.319: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-124947935 delete --grace-period=0 --force -f - --namespace=kubectl-9983'
Oct 28 17:00:49.393: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct 28 17:00:49.393: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Oct 28 17:00:49.393: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-124947935 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-9983'
Oct 28 17:00:49.467: INFO: stderr: "No resources found.\n"
Oct 28 17:00:49.467: INFO: stdout: ""
Oct 28 17:00:49.467: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-124947935 get pods -l name=update-demo --namespace=kubectl-9983 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Oct 28 17:00:49.542: INFO: stderr: ""
Oct 28 17:00:49.542: INFO: stdout: "update-demo-nautilus-hbmtr\nupdate-demo-nautilus-zjgp2\n"
Oct 28 17:00:50.043: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-124947935 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-9983'
Oct 28 17:00:50.123: INFO: stderr: "No resources found.\n"
Oct 28 17:00:50.123: INFO: stdout: ""
Oct 28 17:00:50.123: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-124947935 get pods -l name=update-demo --namespace=kubectl-9983 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Oct 28 17:00:50.233: INFO: stderr: ""
Oct 28 17:00:50.233: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 17:00:50.233: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9983" for this suite.
Oct 28 17:01:12.253: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 17:01:12.413: INFO: namespace kubectl-9983 deletion completed in 22.173560072s

• [SLOW TEST:44.784 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 17:01:12.413: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-6168
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test override arguments
Oct 28 17:01:12.593: INFO: Waiting up to 5m0s for pod "client-containers-67c55007-00e6-46ad-b2bb-0fd82287cf37" in namespace "containers-6168" to be "success or failure"
Oct 28 17:01:12.612: INFO: Pod "client-containers-67c55007-00e6-46ad-b2bb-0fd82287cf37": Phase="Pending", Reason="", readiness=false. Elapsed: 18.549572ms
Oct 28 17:01:14.620: INFO: Pod "client-containers-67c55007-00e6-46ad-b2bb-0fd82287cf37": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026549124s
Oct 28 17:01:16.626: INFO: Pod "client-containers-67c55007-00e6-46ad-b2bb-0fd82287cf37": Phase="Pending", Reason="", readiness=false. Elapsed: 4.032385056s
Oct 28 17:01:18.631: INFO: Pod "client-containers-67c55007-00e6-46ad-b2bb-0fd82287cf37": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.037291672s
STEP: Saw pod success
Oct 28 17:01:18.631: INFO: Pod "client-containers-67c55007-00e6-46ad-b2bb-0fd82287cf37" satisfied condition "success or failure"
Oct 28 17:01:18.635: INFO: Trying to get logs from node kh4ga-worker-000003 pod client-containers-67c55007-00e6-46ad-b2bb-0fd82287cf37 container test-container: <nil>
STEP: delete the pod
Oct 28 17:01:18.660: INFO: Waiting for pod client-containers-67c55007-00e6-46ad-b2bb-0fd82287cf37 to disappear
Oct 28 17:01:18.686: INFO: Pod client-containers-67c55007-00e6-46ad-b2bb-0fd82287cf37 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 17:01:18.686: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-6168" for this suite.
Oct 28 17:01:24.707: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 17:01:24.884: INFO: namespace containers-6168 deletion completed in 6.191575849s

• [SLOW TEST:12.471 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 17:01:24.884: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-4254
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test override command
Oct 28 17:01:25.062: INFO: Waiting up to 5m0s for pod "client-containers-4ea01dcd-e39d-4717-aac5-010a8bb190ca" in namespace "containers-4254" to be "success or failure"
Oct 28 17:01:25.071: INFO: Pod "client-containers-4ea01dcd-e39d-4717-aac5-010a8bb190ca": Phase="Pending", Reason="", readiness=false. Elapsed: 8.900334ms
Oct 28 17:01:27.076: INFO: Pod "client-containers-4ea01dcd-e39d-4717-aac5-010a8bb190ca": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013351397s
Oct 28 17:01:29.081: INFO: Pod "client-containers-4ea01dcd-e39d-4717-aac5-010a8bb190ca": Phase="Pending", Reason="", readiness=false. Elapsed: 4.018507349s
Oct 28 17:01:31.085: INFO: Pod "client-containers-4ea01dcd-e39d-4717-aac5-010a8bb190ca": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.023012587s
STEP: Saw pod success
Oct 28 17:01:31.085: INFO: Pod "client-containers-4ea01dcd-e39d-4717-aac5-010a8bb190ca" satisfied condition "success or failure"
Oct 28 17:01:31.088: INFO: Trying to get logs from node kh4ga-worker-000000 pod client-containers-4ea01dcd-e39d-4717-aac5-010a8bb190ca container test-container: <nil>
STEP: delete the pod
Oct 28 17:01:31.137: INFO: Waiting for pod client-containers-4ea01dcd-e39d-4717-aac5-010a8bb190ca to disappear
Oct 28 17:01:31.142: INFO: Pod client-containers-4ea01dcd-e39d-4717-aac5-010a8bb190ca no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 17:01:31.142: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-4254" for this suite.
Oct 28 17:01:37.166: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 17:01:37.328: INFO: namespace containers-4254 deletion completed in 6.180295473s

• [SLOW TEST:12.444 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 17:01:37.329: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-5964
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test use defaults
Oct 28 17:01:37.488: INFO: Waiting up to 5m0s for pod "client-containers-5b9561ff-1ecf-4429-bd1e-5ab84b0f5a75" in namespace "containers-5964" to be "success or failure"
Oct 28 17:01:37.509: INFO: Pod "client-containers-5b9561ff-1ecf-4429-bd1e-5ab84b0f5a75": Phase="Pending", Reason="", readiness=false. Elapsed: 21.588682ms
Oct 28 17:01:39.514: INFO: Pod "client-containers-5b9561ff-1ecf-4429-bd1e-5ab84b0f5a75": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026424871s
Oct 28 17:01:41.519: INFO: Pod "client-containers-5b9561ff-1ecf-4429-bd1e-5ab84b0f5a75": Phase="Pending", Reason="", readiness=false. Elapsed: 4.031344548s
Oct 28 17:01:43.524: INFO: Pod "client-containers-5b9561ff-1ecf-4429-bd1e-5ab84b0f5a75": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.036609515s
STEP: Saw pod success
Oct 28 17:01:43.524: INFO: Pod "client-containers-5b9561ff-1ecf-4429-bd1e-5ab84b0f5a75" satisfied condition "success or failure"
Oct 28 17:01:43.528: INFO: Trying to get logs from node kh4ga-worker-000003 pod client-containers-5b9561ff-1ecf-4429-bd1e-5ab84b0f5a75 container test-container: <nil>
STEP: delete the pod
Oct 28 17:01:43.556: INFO: Waiting for pod client-containers-5b9561ff-1ecf-4429-bd1e-5ab84b0f5a75 to disappear
Oct 28 17:01:43.564: INFO: Pod client-containers-5b9561ff-1ecf-4429-bd1e-5ab84b0f5a75 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 17:01:43.564: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-5964" for this suite.
Oct 28 17:01:49.587: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 17:01:49.741: INFO: namespace containers-5964 deletion completed in 6.169961307s

• [SLOW TEST:12.412 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 17:01:49.741: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-2727
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0666 on tmpfs
Oct 28 17:01:49.920: INFO: Waiting up to 5m0s for pod "pod-eba653b8-de49-42a5-a012-966bd6058a44" in namespace "emptydir-2727" to be "success or failure"
Oct 28 17:01:49.934: INFO: Pod "pod-eba653b8-de49-42a5-a012-966bd6058a44": Phase="Pending", Reason="", readiness=false. Elapsed: 13.167349ms
Oct 28 17:01:51.938: INFO: Pod "pod-eba653b8-de49-42a5-a012-966bd6058a44": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017660164s
Oct 28 17:01:53.943: INFO: Pod "pod-eba653b8-de49-42a5-a012-966bd6058a44": Phase="Pending", Reason="", readiness=false. Elapsed: 4.022729669s
Oct 28 17:01:55.947: INFO: Pod "pod-eba653b8-de49-42a5-a012-966bd6058a44": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.027070659s
STEP: Saw pod success
Oct 28 17:01:55.947: INFO: Pod "pod-eba653b8-de49-42a5-a012-966bd6058a44" satisfied condition "success or failure"
Oct 28 17:01:55.951: INFO: Trying to get logs from node kh4ga-worker-000000 pod pod-eba653b8-de49-42a5-a012-966bd6058a44 container test-container: <nil>
STEP: delete the pod
Oct 28 17:01:55.975: INFO: Waiting for pod pod-eba653b8-de49-42a5-a012-966bd6058a44 to disappear
Oct 28 17:01:55.979: INFO: Pod pod-eba653b8-de49-42a5-a012-966bd6058a44 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 17:01:55.979: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2727" for this suite.
Oct 28 17:02:02.003: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 17:02:02.154: INFO: namespace emptydir-2727 deletion completed in 6.168786781s

• [SLOW TEST:12.413 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 17:02:02.154: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-6025
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0666 on node default medium
Oct 28 17:02:02.325: INFO: Waiting up to 5m0s for pod "pod-17664851-6445-4c86-8911-d8aa9a216308" in namespace "emptydir-6025" to be "success or failure"
Oct 28 17:02:02.331: INFO: Pod "pod-17664851-6445-4c86-8911-d8aa9a216308": Phase="Pending", Reason="", readiness=false. Elapsed: 6.663425ms
Oct 28 17:02:04.341: INFO: Pod "pod-17664851-6445-4c86-8911-d8aa9a216308": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016232287s
Oct 28 17:02:06.346: INFO: Pod "pod-17664851-6445-4c86-8911-d8aa9a216308": Phase="Pending", Reason="", readiness=false. Elapsed: 4.021279221s
Oct 28 17:02:08.353: INFO: Pod "pod-17664851-6445-4c86-8911-d8aa9a216308": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.028395351s
STEP: Saw pod success
Oct 28 17:02:08.353: INFO: Pod "pod-17664851-6445-4c86-8911-d8aa9a216308" satisfied condition "success or failure"
Oct 28 17:02:08.357: INFO: Trying to get logs from node kh4ga-worker-000003 pod pod-17664851-6445-4c86-8911-d8aa9a216308 container test-container: <nil>
STEP: delete the pod
Oct 28 17:02:08.404: INFO: Waiting for pod pod-17664851-6445-4c86-8911-d8aa9a216308 to disappear
Oct 28 17:02:08.408: INFO: Pod pod-17664851-6445-4c86-8911-d8aa9a216308 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 17:02:08.408: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6025" for this suite.
Oct 28 17:02:14.433: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 17:02:14.591: INFO: namespace emptydir-6025 deletion completed in 6.176960196s

• [SLOW TEST:12.437 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 17:02:14.591: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-8716
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Performing setup for networking test in namespace pod-network-test-8716
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Oct 28 17:02:14.739: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Oct 28 17:02:44.886: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.2.131.70:8080/dial?request=hostName&protocol=udp&host=10.2.129.24&port=8081&tries=1'] Namespace:pod-network-test-8716 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 28 17:02:44.886: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
Oct 28 17:02:45.025: INFO: Waiting for endpoints: map[]
Oct 28 17:02:45.029: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.2.131.70:8080/dial?request=hostName&protocol=udp&host=10.2.130.59&port=8081&tries=1'] Namespace:pod-network-test-8716 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 28 17:02:45.029: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
Oct 28 17:02:45.158: INFO: Waiting for endpoints: map[]
Oct 28 17:02:45.162: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.2.131.70:8080/dial?request=hostName&protocol=udp&host=10.2.131.69&port=8081&tries=1'] Namespace:pod-network-test-8716 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 28 17:02:45.162: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
Oct 28 17:02:45.300: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 17:02:45.300: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-8716" for this suite.
Oct 28 17:03:07.326: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 17:03:07.484: INFO: namespace pod-network-test-8716 deletion completed in 22.176735493s

• [SLOW TEST:52.893 seconds]
[sig-network] Networking
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 17:03:07.484: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-6362
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secret-namespace-6206
STEP: Creating secret with name secret-test-eb0c084b-c187-4837-8ff2-1cce831a0fd1
STEP: Creating a pod to test consume secrets
Oct 28 17:03:07.798: INFO: Waiting up to 5m0s for pod "pod-secrets-9e4c9a90-6d43-4830-9947-b4d1e2133c85" in namespace "secrets-6362" to be "success or failure"
Oct 28 17:03:07.803: INFO: Pod "pod-secrets-9e4c9a90-6d43-4830-9947-b4d1e2133c85": Phase="Pending", Reason="", readiness=false. Elapsed: 4.878317ms
Oct 28 17:03:09.807: INFO: Pod "pod-secrets-9e4c9a90-6d43-4830-9947-b4d1e2133c85": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009262612s
Oct 28 17:03:11.812: INFO: Pod "pod-secrets-9e4c9a90-6d43-4830-9947-b4d1e2133c85": Phase="Pending", Reason="", readiness=false. Elapsed: 4.013800397s
Oct 28 17:03:13.817: INFO: Pod "pod-secrets-9e4c9a90-6d43-4830-9947-b4d1e2133c85": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.019467977s
STEP: Saw pod success
Oct 28 17:03:13.817: INFO: Pod "pod-secrets-9e4c9a90-6d43-4830-9947-b4d1e2133c85" satisfied condition "success or failure"
Oct 28 17:03:13.824: INFO: Trying to get logs from node kh4ga-worker-000000 pod pod-secrets-9e4c9a90-6d43-4830-9947-b4d1e2133c85 container secret-volume-test: <nil>
STEP: delete the pod
Oct 28 17:03:13.862: INFO: Waiting for pod pod-secrets-9e4c9a90-6d43-4830-9947-b4d1e2133c85 to disappear
Oct 28 17:03:13.865: INFO: Pod pod-secrets-9e4c9a90-6d43-4830-9947-b4d1e2133c85 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 17:03:13.865: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6362" for this suite.
Oct 28 17:03:19.888: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 17:03:20.056: INFO: namespace secrets-6362 deletion completed in 6.18261086s
STEP: Destroying namespace "secret-namespace-6206" for this suite.
Oct 28 17:03:26.070: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 17:03:26.222: INFO: namespace secret-namespace-6206 deletion completed in 6.165792808s

• [SLOW TEST:18.738 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 17:03:26.222: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-1103
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Oct 28 17:03:34.448: INFO: Waiting up to 5m0s for pod "client-envvars-5fd53c36-4bcc-464f-acaa-5d832fc34d98" in namespace "pods-1103" to be "success or failure"
Oct 28 17:03:34.460: INFO: Pod "client-envvars-5fd53c36-4bcc-464f-acaa-5d832fc34d98": Phase="Pending", Reason="", readiness=false. Elapsed: 12.367643ms
Oct 28 17:03:36.465: INFO: Pod "client-envvars-5fd53c36-4bcc-464f-acaa-5d832fc34d98": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017693612s
Oct 28 17:03:38.470: INFO: Pod "client-envvars-5fd53c36-4bcc-464f-acaa-5d832fc34d98": Phase="Pending", Reason="", readiness=false. Elapsed: 4.022263368s
Oct 28 17:03:40.475: INFO: Pod "client-envvars-5fd53c36-4bcc-464f-acaa-5d832fc34d98": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.027034916s
STEP: Saw pod success
Oct 28 17:03:40.475: INFO: Pod "client-envvars-5fd53c36-4bcc-464f-acaa-5d832fc34d98" satisfied condition "success or failure"
Oct 28 17:03:40.478: INFO: Trying to get logs from node kh4ga-worker-000000 pod client-envvars-5fd53c36-4bcc-464f-acaa-5d832fc34d98 container env3cont: <nil>
STEP: delete the pod
Oct 28 17:03:40.504: INFO: Waiting for pod client-envvars-5fd53c36-4bcc-464f-acaa-5d832fc34d98 to disappear
Oct 28 17:03:40.509: INFO: Pod client-envvars-5fd53c36-4bcc-464f-acaa-5d832fc34d98 no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 17:03:40.509: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-1103" for this suite.
Oct 28 17:04:32.529: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 17:04:32.693: INFO: namespace pods-1103 deletion completed in 52.177949327s

• [SLOW TEST:66.471 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 17:04:32.694: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-2228
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:63
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Oct 28 17:04:44.910: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct 28 17:04:44.914: INFO: Pod pod-with-poststart-exec-hook still exists
Oct 28 17:04:46.914: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct 28 17:04:46.919: INFO: Pod pod-with-poststart-exec-hook still exists
Oct 28 17:04:48.914: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct 28 17:04:48.919: INFO: Pod pod-with-poststart-exec-hook still exists
Oct 28 17:04:50.914: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct 28 17:04:50.920: INFO: Pod pod-with-poststart-exec-hook still exists
Oct 28 17:04:52.914: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct 28 17:04:52.919: INFO: Pod pod-with-poststart-exec-hook still exists
Oct 28 17:04:54.914: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct 28 17:04:54.919: INFO: Pod pod-with-poststart-exec-hook still exists
Oct 28 17:04:56.914: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct 28 17:04:56.919: INFO: Pod pod-with-poststart-exec-hook still exists
Oct 28 17:04:58.914: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct 28 17:04:58.919: INFO: Pod pod-with-poststart-exec-hook still exists
Oct 28 17:05:00.914: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct 28 17:05:00.919: INFO: Pod pod-with-poststart-exec-hook still exists
Oct 28 17:05:02.914: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct 28 17:05:02.919: INFO: Pod pod-with-poststart-exec-hook still exists
Oct 28 17:05:04.914: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct 28 17:05:04.919: INFO: Pod pod-with-poststart-exec-hook still exists
Oct 28 17:05:06.915: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct 28 17:05:06.919: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 17:05:06.919: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-2228" for this suite.
Oct 28 17:05:28.956: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 17:05:29.129: INFO: namespace container-lifecycle-hook-2228 deletion completed in 22.20346369s

• [SLOW TEST:56.435 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when create a pod with lifecycle hook
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 17:05:29.130: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-4692
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-projected-all-test-volume-48c6ca62-7581-45dc-8a80-6710345e7165
STEP: Creating secret with name secret-projected-all-test-volume-730f838f-0f46-4087-b665-5bbb27842284
STEP: Creating a pod to test Check all projections for projected volume plugin
Oct 28 17:05:29.328: INFO: Waiting up to 5m0s for pod "projected-volume-a81665d5-1601-442d-b730-45fd9124f3b8" in namespace "projected-4692" to be "success or failure"
Oct 28 17:05:29.338: INFO: Pod "projected-volume-a81665d5-1601-442d-b730-45fd9124f3b8": Phase="Pending", Reason="", readiness=false. Elapsed: 9.899932ms
Oct 28 17:05:31.349: INFO: Pod "projected-volume-a81665d5-1601-442d-b730-45fd9124f3b8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021140932s
Oct 28 17:05:33.353: INFO: Pod "projected-volume-a81665d5-1601-442d-b730-45fd9124f3b8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.025143602s
STEP: Saw pod success
Oct 28 17:05:33.353: INFO: Pod "projected-volume-a81665d5-1601-442d-b730-45fd9124f3b8" satisfied condition "success or failure"
Oct 28 17:05:33.356: INFO: Trying to get logs from node kh4ga-worker-000003 pod projected-volume-a81665d5-1601-442d-b730-45fd9124f3b8 container projected-all-volume-test: <nil>
STEP: delete the pod
Oct 28 17:05:33.384: INFO: Waiting for pod projected-volume-a81665d5-1601-442d-b730-45fd9124f3b8 to disappear
Oct 28 17:05:33.390: INFO: Pod projected-volume-a81665d5-1601-442d-b730-45fd9124f3b8 no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 17:05:33.390: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4692" for this suite.
Oct 28 17:05:39.411: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 17:05:39.572: INFO: namespace projected-4692 deletion completed in 6.176067491s

• [SLOW TEST:10.443 seconds]
[sig-storage] Projected combined
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_combined.go:31
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 17:05:39.573: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-886
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Oct 28 17:05:39.764: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:watch-886,SelfLink:/api/v1/namespaces/watch-886/configmaps/e2e-watch-test-resource-version,UID:27a4d2ec-ebca-4e98-b35c-55ceb757fd5f,ResourceVersion:9977,Generation:0,CreationTimestamp:2019-10-28 17:05:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Oct 28 17:05:39.764: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:watch-886,SelfLink:/api/v1/namespaces/watch-886/configmaps/e2e-watch-test-resource-version,UID:27a4d2ec-ebca-4e98-b35c-55ceb757fd5f,ResourceVersion:9978,Generation:0,CreationTimestamp:2019-10-28 17:05:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 17:05:39.764: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-886" for this suite.
Oct 28 17:05:45.790: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 17:05:45.971: INFO: namespace watch-886 deletion completed in 6.199541294s

• [SLOW TEST:6.398 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 17:05:45.971: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-2261
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1612
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Oct 28 17:05:46.137: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-124947935 run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-2261'
Oct 28 17:05:46.229: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Oct 28 17:05:46.229: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
STEP: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1617
Oct 28 17:05:46.234: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-124947935 delete jobs e2e-test-nginx-job --namespace=kubectl-2261'
Oct 28 17:05:46.345: INFO: stderr: ""
Oct 28 17:05:46.345: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 17:05:46.345: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2261" for this suite.
Oct 28 17:05:52.367: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 17:05:52.527: INFO: namespace kubectl-2261 deletion completed in 6.176369345s

• [SLOW TEST:6.556 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run job
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 17:05:52.527: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-1673
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod test-webserver-dfda0d89-a144-42d9-8398-0f9a4848d824 in namespace container-probe-1673
Oct 28 17:05:56.762: INFO: Started pod test-webserver-dfda0d89-a144-42d9-8398-0f9a4848d824 in namespace container-probe-1673
STEP: checking the pod's current state and verifying that restartCount is present
Oct 28 17:05:56.765: INFO: Initial restart count of pod test-webserver-dfda0d89-a144-42d9-8398-0f9a4848d824 is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 17:09:57.402: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-1673" for this suite.
Oct 28 17:10:03.430: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 17:10:03.584: INFO: namespace container-probe-1673 deletion completed in 6.173636511s

• [SLOW TEST:251.057 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 17:10:03.585: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6629
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name cm-test-opt-del-9ce5b33f-476c-4129-84fe-bc04e4a1d240
STEP: Creating configMap with name cm-test-opt-upd-ba68f020-305c-4d10-9e53-cf8205bc3275
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-9ce5b33f-476c-4129-84fe-bc04e4a1d240
STEP: Updating configmap cm-test-opt-upd-ba68f020-305c-4d10-9e53-cf8205bc3275
STEP: Creating configMap with name cm-test-opt-create-aeb49b18-830c-4513-8a82-daa8a8141f08
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 17:11:32.325: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6629" for this suite.
Oct 28 17:11:54.346: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 17:11:54.498: INFO: namespace projected-6629 deletion completed in 22.166598178s

• [SLOW TEST:110.913 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 17:11:54.498: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-5615
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Oct 28 17:11:59.713: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 17:11:59.736: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-5615" for this suite.
Oct 28 17:12:05.756: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 17:12:05.907: INFO: namespace container-runtime-5615 deletion completed in 6.165886843s

• [SLOW TEST:11.409 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  blackbox test
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
    on terminated container
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:129
      should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
      /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 17:12:05.907: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-5536
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: executing a command with run --rm and attach with stdin
Oct 28 17:12:06.059: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-124947935 --namespace=kubectl-5536 run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Oct 28 17:12:14.139: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Oct 28 17:12:14.139: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 17:12:16.147: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5536" for this suite.
Oct 28 17:12:22.180: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 17:12:22.335: INFO: namespace kubectl-5536 deletion completed in 6.1821832s

• [SLOW TEST:16.428 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run --rm job
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 17:12:22.336: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-244
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1292
STEP: creating an rc
Oct 28 17:12:22.494: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-124947935 create -f - --namespace=kubectl-244'
Oct 28 17:12:23.010: INFO: stderr: ""
Oct 28 17:12:23.010: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Waiting for Redis master to start.
Oct 28 17:12:24.015: INFO: Selector matched 1 pods for map[app:redis]
Oct 28 17:12:24.015: INFO: Found 0 / 1
Oct 28 17:12:25.015: INFO: Selector matched 1 pods for map[app:redis]
Oct 28 17:12:25.015: INFO: Found 0 / 1
Oct 28 17:12:26.019: INFO: Selector matched 1 pods for map[app:redis]
Oct 28 17:12:26.019: INFO: Found 0 / 1
Oct 28 17:12:27.015: INFO: Selector matched 1 pods for map[app:redis]
Oct 28 17:12:27.015: INFO: Found 0 / 1
Oct 28 17:12:28.015: INFO: Selector matched 1 pods for map[app:redis]
Oct 28 17:12:28.015: INFO: Found 1 / 1
Oct 28 17:12:28.015: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Oct 28 17:12:28.019: INFO: Selector matched 1 pods for map[app:redis]
Oct 28 17:12:28.019: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
STEP: checking for a matching strings
Oct 28 17:12:28.019: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-124947935 logs redis-master-hrgml redis-master --namespace=kubectl-244'
Oct 28 17:12:28.099: INFO: stderr: ""
Oct 28 17:12:28.099: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 28 Oct 17:12:26.933 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 28 Oct 17:12:26.933 # Server started, Redis version 3.2.12\n1:M 28 Oct 17:12:26.933 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 28 Oct 17:12:26.934 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log lines
Oct 28 17:12:28.099: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-124947935 logs redis-master-hrgml redis-master --namespace=kubectl-244 --tail=1'
Oct 28 17:12:28.178: INFO: stderr: ""
Oct 28 17:12:28.178: INFO: stdout: "1:M 28 Oct 17:12:26.934 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log bytes
Oct 28 17:12:28.178: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-124947935 logs redis-master-hrgml redis-master --namespace=kubectl-244 --limit-bytes=1'
Oct 28 17:12:28.259: INFO: stderr: ""
Oct 28 17:12:28.259: INFO: stdout: " "
STEP: exposing timestamps
Oct 28 17:12:28.259: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-124947935 logs redis-master-hrgml redis-master --namespace=kubectl-244 --tail=1 --timestamps'
Oct 28 17:12:28.341: INFO: stderr: ""
Oct 28 17:12:28.341: INFO: stdout: "2019-10-28T17:12:26.93415598Z 1:M 28 Oct 17:12:26.934 * The server is now ready to accept connections on port 6379\n"
STEP: restricting to a time range
Oct 28 17:12:30.842: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-124947935 logs redis-master-hrgml redis-master --namespace=kubectl-244 --since=1s'
Oct 28 17:12:30.929: INFO: stderr: ""
Oct 28 17:12:30.929: INFO: stdout: ""
Oct 28 17:12:30.929: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-124947935 logs redis-master-hrgml redis-master --namespace=kubectl-244 --since=24h'
Oct 28 17:12:31.014: INFO: stderr: ""
Oct 28 17:12:31.014: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 28 Oct 17:12:26.933 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 28 Oct 17:12:26.933 # Server started, Redis version 3.2.12\n1:M 28 Oct 17:12:26.933 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 28 Oct 17:12:26.934 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1298
STEP: using delete to clean up resources
Oct 28 17:12:31.014: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-124947935 delete --grace-period=0 --force -f - --namespace=kubectl-244'
Oct 28 17:12:31.090: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct 28 17:12:31.090: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
Oct 28 17:12:31.090: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-124947935 get rc,svc -l name=nginx --no-headers --namespace=kubectl-244'
Oct 28 17:12:31.173: INFO: stderr: "No resources found.\n"
Oct 28 17:12:31.173: INFO: stdout: ""
Oct 28 17:12:31.173: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-124947935 get pods -l name=nginx --namespace=kubectl-244 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Oct 28 17:12:31.239: INFO: stderr: ""
Oct 28 17:12:31.239: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 17:12:31.239: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-244" for this suite.
Oct 28 17:12:37.263: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 17:12:37.419: INFO: namespace kubectl-244 deletion completed in 6.172551896s

• [SLOW TEST:15.084 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl logs
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 17:12:37.420: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-4807
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with configMap that has name projected-configmap-test-upd-c5822929-9b8c-4855-aca7-f22ef04cf99e
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-c5822929-9b8c-4855-aca7-f22ef04cf99e
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 17:13:56.047: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4807" for this suite.
Oct 28 17:14:18.068: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 17:14:18.219: INFO: namespace projected-4807 deletion completed in 22.165247749s

• [SLOW TEST:100.799 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 17:14:18.220: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-1845
STEP: Waiting for a default service account to be provisioned in namespace
[It] should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Oct 28 17:14:18.370: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
STEP: Creating rc "condition-test" that asks for more than the allowed pod quota
STEP: Checking rc "condition-test" has the desired failure condition set
STEP: Scaling down rc "condition-test" to satisfy pod quota
Oct 28 17:14:20.445: INFO: Updating replication controller "condition-test"
STEP: Checking rc "condition-test" has no failure condition set
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 17:14:20.454: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-1845" for this suite.
Oct 28 17:14:26.475: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 17:14:26.633: INFO: namespace replication-controller-1845 deletion completed in 6.172742698s

• [SLOW TEST:8.413 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 17:14:26.633: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-384
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-map-ad16cba2-2dca-48e7-be72-d7d1863f9019
STEP: Creating a pod to test consume configMaps
Oct 28 17:14:26.811: INFO: Waiting up to 5m0s for pod "pod-configmaps-ce5d8afa-cea3-4733-80b3-6c45d0f22f7a" in namespace "configmap-384" to be "success or failure"
Oct 28 17:14:26.816: INFO: Pod "pod-configmaps-ce5d8afa-cea3-4733-80b3-6c45d0f22f7a": Phase="Pending", Reason="", readiness=false. Elapsed: 5.208513ms
Oct 28 17:14:28.822: INFO: Pod "pod-configmaps-ce5d8afa-cea3-4733-80b3-6c45d0f22f7a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010943438s
Oct 28 17:14:30.826: INFO: Pod "pod-configmaps-ce5d8afa-cea3-4733-80b3-6c45d0f22f7a": Phase="Pending", Reason="", readiness=false. Elapsed: 4.015754458s
Oct 28 17:14:32.832: INFO: Pod "pod-configmaps-ce5d8afa-cea3-4733-80b3-6c45d0f22f7a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.021067877s
STEP: Saw pod success
Oct 28 17:14:32.832: INFO: Pod "pod-configmaps-ce5d8afa-cea3-4733-80b3-6c45d0f22f7a" satisfied condition "success or failure"
Oct 28 17:14:32.835: INFO: Trying to get logs from node kh4ga-worker-000003 pod pod-configmaps-ce5d8afa-cea3-4733-80b3-6c45d0f22f7a container configmap-volume-test: <nil>
STEP: delete the pod
Oct 28 17:14:32.858: INFO: Waiting for pod pod-configmaps-ce5d8afa-cea3-4733-80b3-6c45d0f22f7a to disappear
Oct 28 17:14:32.862: INFO: Pod pod-configmaps-ce5d8afa-cea3-4733-80b3-6c45d0f22f7a no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 17:14:32.862: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-384" for this suite.
Oct 28 17:14:38.884: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 17:14:39.046: INFO: namespace configmap-384 deletion completed in 6.177317759s

• [SLOW TEST:12.413 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 17:14:39.046: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-1237
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl label
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1210
STEP: creating the pod
Oct 28 17:14:39.202: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-124947935 create -f - --namespace=kubectl-1237'
Oct 28 17:14:39.705: INFO: stderr: ""
Oct 28 17:14:39.705: INFO: stdout: "pod/pause created\n"
Oct 28 17:14:39.705: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Oct 28 17:14:39.705: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-1237" to be "running and ready"
Oct 28 17:14:39.722: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 17.184245ms
Oct 28 17:14:41.727: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022084651s
Oct 28 17:14:43.737: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 4.031726166s
Oct 28 17:14:43.737: INFO: Pod "pause" satisfied condition "running and ready"
Oct 28 17:14:43.737: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: adding the label testing-label with value testing-label-value to a pod
Oct 28 17:14:43.737: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-124947935 label pods pause testing-label=testing-label-value --namespace=kubectl-1237'
Oct 28 17:14:43.831: INFO: stderr: ""
Oct 28 17:14:43.831: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Oct 28 17:14:43.832: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-124947935 get pod pause -L testing-label --namespace=kubectl-1237'
Oct 28 17:14:43.916: INFO: stderr: ""
Oct 28 17:14:43.916: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          4s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Oct 28 17:14:43.916: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-124947935 label pods pause testing-label- --namespace=kubectl-1237'
Oct 28 17:14:43.994: INFO: stderr: ""
Oct 28 17:14:43.994: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Oct 28 17:14:43.994: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-124947935 get pod pause -L testing-label --namespace=kubectl-1237'
Oct 28 17:14:44.066: INFO: stderr: ""
Oct 28 17:14:44.066: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          5s    \n"
[AfterEach] [k8s.io] Kubectl label
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1217
STEP: using delete to clean up resources
Oct 28 17:14:44.066: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-124947935 delete --grace-period=0 --force -f - --namespace=kubectl-1237'
Oct 28 17:14:44.157: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct 28 17:14:44.157: INFO: stdout: "pod \"pause\" force deleted\n"
Oct 28 17:14:44.157: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-124947935 get rc,svc -l name=pause --no-headers --namespace=kubectl-1237'
Oct 28 17:14:44.273: INFO: stderr: "No resources found.\n"
Oct 28 17:14:44.273: INFO: stdout: ""
Oct 28 17:14:44.273: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-124947935 get pods -l name=pause --namespace=kubectl-1237 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Oct 28 17:14:44.370: INFO: stderr: ""
Oct 28 17:14:44.370: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 17:14:44.370: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1237" for this suite.
Oct 28 17:14:50.401: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 17:14:50.591: INFO: namespace kubectl-1237 deletion completed in 6.215440112s

• [SLOW TEST:11.545 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl label
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 17:14:50.592: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-3055
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Oct 28 17:14:50.756: INFO: Waiting up to 5m0s for pod "downwardapi-volume-bac0759a-44bf-45a9-9444-9c1b847a39e8" in namespace "downward-api-3055" to be "success or failure"
Oct 28 17:14:50.764: INFO: Pod "downwardapi-volume-bac0759a-44bf-45a9-9444-9c1b847a39e8": Phase="Pending", Reason="", readiness=false. Elapsed: 7.516819ms
Oct 28 17:14:52.768: INFO: Pod "downwardapi-volume-bac0759a-44bf-45a9-9444-9c1b847a39e8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01187651s
Oct 28 17:14:54.774: INFO: Pod "downwardapi-volume-bac0759a-44bf-45a9-9444-9c1b847a39e8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.0172211s
Oct 28 17:14:56.778: INFO: Pod "downwardapi-volume-bac0759a-44bf-45a9-9444-9c1b847a39e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.022020387s
STEP: Saw pod success
Oct 28 17:14:56.778: INFO: Pod "downwardapi-volume-bac0759a-44bf-45a9-9444-9c1b847a39e8" satisfied condition "success or failure"
Oct 28 17:14:56.782: INFO: Trying to get logs from node kh4ga-worker-000003 pod downwardapi-volume-bac0759a-44bf-45a9-9444-9c1b847a39e8 container client-container: <nil>
STEP: delete the pod
Oct 28 17:14:56.813: INFO: Waiting for pod downwardapi-volume-bac0759a-44bf-45a9-9444-9c1b847a39e8 to disappear
Oct 28 17:14:56.816: INFO: Pod downwardapi-volume-bac0759a-44bf-45a9-9444-9c1b847a39e8 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 17:14:56.817: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3055" for this suite.
Oct 28 17:15:02.836: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 17:15:03.009: INFO: namespace downward-api-3055 deletion completed in 6.186477589s

• [SLOW TEST:12.417 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 17:15:03.009: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-1607
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-1607
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace statefulset-1607
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-1607
Oct 28 17:15:03.197: INFO: Found 0 stateful pods, waiting for 1
Oct 28 17:15:13.202: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Oct 28 17:15:13.206: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-124947935 exec --namespace=statefulset-1607 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Oct 28 17:15:13.415: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Oct 28 17:15:13.415: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Oct 28 17:15:13.416: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Oct 28 17:15:13.420: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Oct 28 17:15:23.426: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Oct 28 17:15:23.426: INFO: Waiting for statefulset status.replicas updated to 0
Oct 28 17:15:23.444: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.9999997s
Oct 28 17:15:24.448: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.994903317s
Oct 28 17:15:25.453: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.990192636s
Oct 28 17:15:26.459: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.985245854s
Oct 28 17:15:27.465: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.97899927s
Oct 28 17:15:28.473: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.973326388s
Oct 28 17:15:29.478: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.9653265s
Oct 28 17:15:30.483: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.960287721s
Oct 28 17:15:31.488: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.955413843s
Oct 28 17:15:32.492: INFO: Verifying statefulset ss doesn't scale past 1 for another 950.216364ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-1607
Oct 28 17:15:33.498: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-124947935 exec --namespace=statefulset-1607 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 28 17:15:33.708: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Oct 28 17:15:33.708: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Oct 28 17:15:33.708: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Oct 28 17:15:33.713: INFO: Found 1 stateful pods, waiting for 3
Oct 28 17:15:43.718: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Oct 28 17:15:43.718: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Oct 28 17:15:43.718: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Oct 28 17:15:43.726: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-124947935 exec --namespace=statefulset-1607 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Oct 28 17:15:43.917: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Oct 28 17:15:43.917: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Oct 28 17:15:43.917: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Oct 28 17:15:43.917: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-124947935 exec --namespace=statefulset-1607 ss-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Oct 28 17:15:44.132: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Oct 28 17:15:44.132: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Oct 28 17:15:44.132: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Oct 28 17:15:44.132: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-124947935 exec --namespace=statefulset-1607 ss-2 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Oct 28 17:15:44.340: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Oct 28 17:15:44.340: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Oct 28 17:15:44.340: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Oct 28 17:15:44.340: INFO: Waiting for statefulset status.replicas updated to 0
Oct 28 17:15:44.344: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Oct 28 17:15:54.358: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Oct 28 17:15:54.358: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Oct 28 17:15:54.358: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Oct 28 17:15:54.372: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.9999998s
Oct 28 17:15:55.377: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.995592237s
Oct 28 17:15:56.382: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.990810373s
Oct 28 17:15:57.387: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.985926409s
Oct 28 17:15:58.392: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.980531445s
Oct 28 17:15:59.397: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.975211482s
Oct 28 17:16:00.403: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.97048802s
Oct 28 17:16:01.408: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.964984057s
Oct 28 17:16:02.417: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.959777396s
Oct 28 17:16:03.423: INFO: Verifying statefulset ss doesn't scale past 3 for another 950.421424ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-1607
Oct 28 17:16:04.429: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-124947935 exec --namespace=statefulset-1607 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 28 17:16:04.634: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Oct 28 17:16:04.634: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Oct 28 17:16:04.634: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Oct 28 17:16:04.634: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-124947935 exec --namespace=statefulset-1607 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 28 17:16:04.843: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Oct 28 17:16:04.843: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Oct 28 17:16:04.843: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Oct 28 17:16:04.843: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-124947935 exec --namespace=statefulset-1607 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 28 17:16:05.084: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Oct 28 17:16:05.084: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Oct 28 17:16:05.084: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Oct 28 17:16:05.084: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Oct 28 17:16:35.103: INFO: Deleting all statefulset in ns statefulset-1607
Oct 28 17:16:35.108: INFO: Scaling statefulset ss to 0
Oct 28 17:16:35.119: INFO: Waiting for statefulset status.replicas updated to 0
Oct 28 17:16:35.122: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 17:16:35.139: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-1607" for this suite.
Oct 28 17:16:41.162: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 17:16:41.330: INFO: namespace statefulset-1607 deletion completed in 6.182948037s

• [SLOW TEST:98.321 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 17:16:41.331: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7069
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-d66d6044-862d-4acb-97e1-fe8cca10058b
STEP: Creating a pod to test consume secrets
Oct 28 17:16:41.534: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-24d3f41d-af4f-4019-a1fc-c5476dad0abe" in namespace "projected-7069" to be "success or failure"
Oct 28 17:16:41.547: INFO: Pod "pod-projected-secrets-24d3f41d-af4f-4019-a1fc-c5476dad0abe": Phase="Pending", Reason="", readiness=false. Elapsed: 12.585331ms
Oct 28 17:16:43.552: INFO: Pod "pod-projected-secrets-24d3f41d-af4f-4019-a1fc-c5476dad0abe": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017371697s
Oct 28 17:16:45.558: INFO: Pod "pod-projected-secrets-24d3f41d-af4f-4019-a1fc-c5476dad0abe": Phase="Pending", Reason="", readiness=false. Elapsed: 4.024034466s
Oct 28 17:16:47.563: INFO: Pod "pod-projected-secrets-24d3f41d-af4f-4019-a1fc-c5476dad0abe": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.028778928s
STEP: Saw pod success
Oct 28 17:16:47.563: INFO: Pod "pod-projected-secrets-24d3f41d-af4f-4019-a1fc-c5476dad0abe" satisfied condition "success or failure"
Oct 28 17:16:47.567: INFO: Trying to get logs from node kh4ga-worker-000003 pod pod-projected-secrets-24d3f41d-af4f-4019-a1fc-c5476dad0abe container projected-secret-volume-test: <nil>
STEP: delete the pod
Oct 28 17:16:47.592: INFO: Waiting for pod pod-projected-secrets-24d3f41d-af4f-4019-a1fc-c5476dad0abe to disappear
Oct 28 17:16:47.596: INFO: Pod pod-projected-secrets-24d3f41d-af4f-4019-a1fc-c5476dad0abe no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 17:16:47.596: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7069" for this suite.
Oct 28 17:16:53.617: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 17:16:53.788: INFO: namespace projected-7069 deletion completed in 6.186018806s

• [SLOW TEST:12.457 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 17:16:53.788: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-6734
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Starting the proxy
Oct 28 17:16:53.938: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-124947935 proxy --unix-socket=/tmp/kubectl-proxy-unix148069810/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 17:16:53.988: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6734" for this suite.
Oct 28 17:17:00.007: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 17:17:00.180: INFO: namespace kubectl-6734 deletion completed in 6.187077689s

• [SLOW TEST:6.392 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Proxy server
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 17:17:00.180: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-2131
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-43ef2d98-a3d0-46ca-a05e-7a1c476778dd
STEP: Creating a pod to test consume configMaps
Oct 28 17:17:00.344: INFO: Waiting up to 5m0s for pod "pod-configmaps-759d6dc6-0bf1-4b4d-9d1e-6019c8f9be5c" in namespace "configmap-2131" to be "success or failure"
Oct 28 17:17:00.352: INFO: Pod "pod-configmaps-759d6dc6-0bf1-4b4d-9d1e-6019c8f9be5c": Phase="Pending", Reason="", readiness=false. Elapsed: 8.17002ms
Oct 28 17:17:02.356: INFO: Pod "pod-configmaps-759d6dc6-0bf1-4b4d-9d1e-6019c8f9be5c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012285666s
Oct 28 17:17:04.362: INFO: Pod "pod-configmaps-759d6dc6-0bf1-4b4d-9d1e-6019c8f9be5c": Phase="Pending", Reason="", readiness=false. Elapsed: 4.017779713s
Oct 28 17:17:06.366: INFO: Pod "pod-configmaps-759d6dc6-0bf1-4b4d-9d1e-6019c8f9be5c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.022430456s
STEP: Saw pod success
Oct 28 17:17:06.366: INFO: Pod "pod-configmaps-759d6dc6-0bf1-4b4d-9d1e-6019c8f9be5c" satisfied condition "success or failure"
Oct 28 17:17:06.370: INFO: Trying to get logs from node kh4ga-worker-000000 pod pod-configmaps-759d6dc6-0bf1-4b4d-9d1e-6019c8f9be5c container configmap-volume-test: <nil>
STEP: delete the pod
Oct 28 17:17:06.400: INFO: Waiting for pod pod-configmaps-759d6dc6-0bf1-4b4d-9d1e-6019c8f9be5c to disappear
Oct 28 17:17:06.404: INFO: Pod pod-configmaps-759d6dc6-0bf1-4b4d-9d1e-6019c8f9be5c no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 17:17:06.404: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2131" for this suite.
Oct 28 17:17:12.437: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 17:17:12.586: INFO: namespace configmap-2131 deletion completed in 6.175728824s

• [SLOW TEST:12.406 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 17:17:12.586: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-5182
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-88f6e3be-d614-484a-9083-857ad40bd84d
STEP: Creating a pod to test consume secrets
Oct 28 17:17:12.775: INFO: Waiting up to 5m0s for pod "pod-secrets-965efd1e-1be0-49ce-badb-256b3e771cff" in namespace "secrets-5182" to be "success or failure"
Oct 28 17:17:12.791: INFO: Pod "pod-secrets-965efd1e-1be0-49ce-badb-256b3e771cff": Phase="Pending", Reason="", readiness=false. Elapsed: 15.90844ms
Oct 28 17:17:14.795: INFO: Pod "pod-secrets-965efd1e-1be0-49ce-badb-256b3e771cff": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020019473s
Oct 28 17:17:16.799: INFO: Pod "pod-secrets-965efd1e-1be0-49ce-badb-256b3e771cff": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023863104s
STEP: Saw pod success
Oct 28 17:17:16.799: INFO: Pod "pod-secrets-965efd1e-1be0-49ce-badb-256b3e771cff" satisfied condition "success or failure"
Oct 28 17:17:16.803: INFO: Trying to get logs from node kh4ga-worker-000003 pod pod-secrets-965efd1e-1be0-49ce-badb-256b3e771cff container secret-volume-test: <nil>
STEP: delete the pod
Oct 28 17:17:16.826: INFO: Waiting for pod pod-secrets-965efd1e-1be0-49ce-badb-256b3e771cff to disappear
Oct 28 17:17:16.830: INFO: Pod pod-secrets-965efd1e-1be0-49ce-badb-256b3e771cff no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 17:17:16.830: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5182" for this suite.
Oct 28 17:17:22.855: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 17:17:23.019: INFO: namespace secrets-5182 deletion completed in 6.183050711s

• [SLOW TEST:10.433 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 17:17:23.019: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2247
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-4ab0dde1-00d0-492e-85d7-38612c0141a7
STEP: Creating a pod to test consume configMaps
Oct 28 17:17:23.217: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-86bde780-5438-419c-b958-c7045d9f7feb" in namespace "projected-2247" to be "success or failure"
Oct 28 17:17:23.225: INFO: Pod "pod-projected-configmaps-86bde780-5438-419c-b958-c7045d9f7feb": Phase="Pending", Reason="", readiness=false. Elapsed: 8.485921ms
Oct 28 17:17:25.229: INFO: Pod "pod-projected-configmaps-86bde780-5438-419c-b958-c7045d9f7feb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012677745s
Oct 28 17:17:27.234: INFO: Pod "pod-projected-configmaps-86bde780-5438-419c-b958-c7045d9f7feb": Phase="Pending", Reason="", readiness=false. Elapsed: 4.017271568s
Oct 28 17:17:29.240: INFO: Pod "pod-projected-configmaps-86bde780-5438-419c-b958-c7045d9f7feb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.022931692s
STEP: Saw pod success
Oct 28 17:17:29.240: INFO: Pod "pod-projected-configmaps-86bde780-5438-419c-b958-c7045d9f7feb" satisfied condition "success or failure"
Oct 28 17:17:29.244: INFO: Trying to get logs from node kh4ga-worker-000000 pod pod-projected-configmaps-86bde780-5438-419c-b958-c7045d9f7feb container projected-configmap-volume-test: <nil>
STEP: delete the pod
Oct 28 17:17:29.269: INFO: Waiting for pod pod-projected-configmaps-86bde780-5438-419c-b958-c7045d9f7feb to disappear
Oct 28 17:17:29.272: INFO: Pod pod-projected-configmaps-86bde780-5438-419c-b958-c7045d9f7feb no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 17:17:29.272: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2247" for this suite.
Oct 28 17:17:35.314: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 17:17:35.475: INFO: namespace projected-2247 deletion completed in 6.196639309s

• [SLOW TEST:12.456 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 17:17:35.476: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svcaccounts-4720
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: getting the auto-created API token
Oct 28 17:17:36.162: INFO: created pod pod-service-account-defaultsa
Oct 28 17:17:36.162: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Oct 28 17:17:36.172: INFO: created pod pod-service-account-mountsa
Oct 28 17:17:36.172: INFO: pod pod-service-account-mountsa service account token volume mount: true
Oct 28 17:17:36.181: INFO: created pod pod-service-account-nomountsa
Oct 28 17:17:36.181: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Oct 28 17:17:36.194: INFO: created pod pod-service-account-defaultsa-mountspec
Oct 28 17:17:36.194: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Oct 28 17:17:36.207: INFO: created pod pod-service-account-mountsa-mountspec
Oct 28 17:17:36.207: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Oct 28 17:17:36.222: INFO: created pod pod-service-account-nomountsa-mountspec
Oct 28 17:17:36.222: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Oct 28 17:17:36.238: INFO: created pod pod-service-account-defaultsa-nomountspec
Oct 28 17:17:36.238: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Oct 28 17:17:36.257: INFO: created pod pod-service-account-mountsa-nomountspec
Oct 28 17:17:36.257: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Oct 28 17:17:36.267: INFO: created pod pod-service-account-nomountsa-nomountspec
Oct 28 17:17:36.267: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 17:17:36.268: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-4720" for this suite.
Oct 28 17:17:58.320: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 17:17:58.512: INFO: namespace svcaccounts-4720 deletion completed in 22.230325689s

• [SLOW TEST:23.036 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:23
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 17:17:58.512: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-2925
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0644 on node default medium
Oct 28 17:17:58.714: INFO: Waiting up to 5m0s for pod "pod-52dcd270-0704-4743-85a5-e0db7ed4f55b" in namespace "emptydir-2925" to be "success or failure"
Oct 28 17:17:58.726: INFO: Pod "pod-52dcd270-0704-4743-85a5-e0db7ed4f55b": Phase="Pending", Reason="", readiness=false. Elapsed: 11.70103ms
Oct 28 17:18:00.730: INFO: Pod "pod-52dcd270-0704-4743-85a5-e0db7ed4f55b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016069922s
Oct 28 17:18:02.736: INFO: Pod "pod-52dcd270-0704-4743-85a5-e0db7ed4f55b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.021564215s
Oct 28 17:18:04.741: INFO: Pod "pod-52dcd270-0704-4743-85a5-e0db7ed4f55b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.026402705s
STEP: Saw pod success
Oct 28 17:18:04.741: INFO: Pod "pod-52dcd270-0704-4743-85a5-e0db7ed4f55b" satisfied condition "success or failure"
Oct 28 17:18:04.744: INFO: Trying to get logs from node kh4ga-worker-000000 pod pod-52dcd270-0704-4743-85a5-e0db7ed4f55b container test-container: <nil>
STEP: delete the pod
Oct 28 17:18:04.776: INFO: Waiting for pod pod-52dcd270-0704-4743-85a5-e0db7ed4f55b to disappear
Oct 28 17:18:04.780: INFO: Pod pod-52dcd270-0704-4743-85a5-e0db7ed4f55b no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 17:18:04.781: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2925" for this suite.
Oct 28 17:18:10.804: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 17:18:10.976: INFO: namespace emptydir-2925 deletion completed in 6.187161688s

• [SLOW TEST:12.464 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 17:18:10.977: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-9601
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Oct 28 17:18:11.186: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"fe7a52e5-5a0b-458b-a49c-c085dfd7eb7b", Controller:(*bool)(0xc003b6c296), BlockOwnerDeletion:(*bool)(0xc003b6c297)}}
Oct 28 17:18:11.195: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"dfc38c50-830c-415b-b5e1-597e8f792519", Controller:(*bool)(0xc003b26f2e), BlockOwnerDeletion:(*bool)(0xc003b26f2f)}}
Oct 28 17:18:11.221: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"bc28f828-7f42-41e9-b96b-2fc77dbc59bc", Controller:(*bool)(0xc002871a86), BlockOwnerDeletion:(*bool)(0xc002871a87)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 17:18:16.232: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-9601" for this suite.
Oct 28 17:18:22.255: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 17:18:22.414: INFO: namespace gc-9601 deletion completed in 6.17590183s

• [SLOW TEST:11.437 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 17:18:22.414: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-4626
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name projected-secret-test-31360f2d-f929-4357-8fb2-0d313a437ab4
STEP: Creating a pod to test consume secrets
Oct 28 17:18:22.600: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-46330af8-cd07-44cf-9065-4192c86751ef" in namespace "projected-4626" to be "success or failure"
Oct 28 17:18:22.632: INFO: Pod "pod-projected-secrets-46330af8-cd07-44cf-9065-4192c86751ef": Phase="Pending", Reason="", readiness=false. Elapsed: 32.52098ms
Oct 28 17:18:24.637: INFO: Pod "pod-projected-secrets-46330af8-cd07-44cf-9065-4192c86751ef": Phase="Pending", Reason="", readiness=false. Elapsed: 2.037233853s
Oct 28 17:18:26.641: INFO: Pod "pod-projected-secrets-46330af8-cd07-44cf-9065-4192c86751ef": Phase="Pending", Reason="", readiness=false. Elapsed: 4.041681323s
Oct 28 17:18:28.646: INFO: Pod "pod-projected-secrets-46330af8-cd07-44cf-9065-4192c86751ef": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.046742793s
STEP: Saw pod success
Oct 28 17:18:28.646: INFO: Pod "pod-projected-secrets-46330af8-cd07-44cf-9065-4192c86751ef" satisfied condition "success or failure"
Oct 28 17:18:28.660: INFO: Trying to get logs from node kh4ga-worker-000000 pod pod-projected-secrets-46330af8-cd07-44cf-9065-4192c86751ef container secret-volume-test: <nil>
STEP: delete the pod
Oct 28 17:18:28.683: INFO: Waiting for pod pod-projected-secrets-46330af8-cd07-44cf-9065-4192c86751ef to disappear
Oct 28 17:18:28.687: INFO: Pod pod-projected-secrets-46330af8-cd07-44cf-9065-4192c86751ef no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 17:18:28.687: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4626" for this suite.
Oct 28 17:18:34.716: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 17:18:34.881: INFO: namespace projected-4626 deletion completed in 6.187556527s

• [SLOW TEST:12.467 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 17:18:34.881: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8409
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-8f711e54-acda-4f25-b0a1-921c58a249dc
STEP: Creating a pod to test consume configMaps
Oct 28 17:18:35.063: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-77c4f8e5-f416-48bf-8008-2157225211dd" in namespace "projected-8409" to be "success or failure"
Oct 28 17:18:35.070: INFO: Pod "pod-projected-configmaps-77c4f8e5-f416-48bf-8008-2157225211dd": Phase="Pending", Reason="", readiness=false. Elapsed: 7.436818ms
Oct 28 17:18:37.075: INFO: Pod "pod-projected-configmaps-77c4f8e5-f416-48bf-8008-2157225211dd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012217681s
Oct 28 17:18:39.080: INFO: Pod "pod-projected-configmaps-77c4f8e5-f416-48bf-8008-2157225211dd": Phase="Pending", Reason="", readiness=false. Elapsed: 4.017239942s
Oct 28 17:18:41.085: INFO: Pod "pod-projected-configmaps-77c4f8e5-f416-48bf-8008-2157225211dd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.022726103s
STEP: Saw pod success
Oct 28 17:18:41.085: INFO: Pod "pod-projected-configmaps-77c4f8e5-f416-48bf-8008-2157225211dd" satisfied condition "success or failure"
Oct 28 17:18:41.089: INFO: Trying to get logs from node kh4ga-worker-000003 pod pod-projected-configmaps-77c4f8e5-f416-48bf-8008-2157225211dd container projected-configmap-volume-test: <nil>
STEP: delete the pod
Oct 28 17:18:41.128: INFO: Waiting for pod pod-projected-configmaps-77c4f8e5-f416-48bf-8008-2157225211dd to disappear
Oct 28 17:18:41.132: INFO: Pod pod-projected-configmaps-77c4f8e5-f416-48bf-8008-2157225211dd no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 17:18:41.132: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8409" for this suite.
Oct 28 17:18:47.152: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 17:18:47.317: INFO: namespace projected-8409 deletion completed in 6.178991475s

• [SLOW TEST:12.436 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 17:18:47.317: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-4983
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod busybox-b2382705-2b29-44e5-8f8c-3cae423659d2 in namespace container-probe-4983
Oct 28 17:18:53.494: INFO: Started pod busybox-b2382705-2b29-44e5-8f8c-3cae423659d2 in namespace container-probe-4983
STEP: checking the pod's current state and verifying that restartCount is present
Oct 28 17:18:53.497: INFO: Initial restart count of pod busybox-b2382705-2b29-44e5-8f8c-3cae423659d2 is 0
Oct 28 17:19:47.636: INFO: Restart count of pod container-probe-4983/busybox-b2382705-2b29-44e5-8f8c-3cae423659d2 is now 1 (54.139258381s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 17:19:47.654: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-4983" for this suite.
Oct 28 17:19:53.675: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 17:19:53.823: INFO: namespace container-probe-4983 deletion completed in 6.162772481s

• [SLOW TEST:66.506 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 17:19:53.824: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replicaset-1860
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Oct 28 17:20:01.033: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 17:20:02.071: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-1860" for this suite.
Oct 28 17:20:24.094: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 17:20:24.248: INFO: namespace replicaset-1860 deletion completed in 22.168468279s

• [SLOW TEST:30.424 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 17:20:24.248: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-5518
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-5518
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a new StatefulSet
Oct 28 17:20:24.451: INFO: Found 0 stateful pods, waiting for 3
Oct 28 17:20:34.456: INFO: Found 2 stateful pods, waiting for 3
Oct 28 17:20:44.456: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Oct 28 17:20:44.456: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Oct 28 17:20:44.456: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Oct 28 17:20:44.487: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Oct 28 17:20:54.526: INFO: Updating stateful set ss2
Oct 28 17:20:54.545: INFO: Waiting for Pod statefulset-5518/ss2-2 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Oct 28 17:21:04.555: INFO: Waiting for Pod statefulset-5518/ss2-2 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
STEP: Restoring Pods to the correct revision when they are deleted
Oct 28 17:21:14.697: INFO: Found 2 stateful pods, waiting for 3
Oct 28 17:21:24.702: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Oct 28 17:21:24.702: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Oct 28 17:21:24.702: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Oct 28 17:21:24.733: INFO: Updating stateful set ss2
Oct 28 17:21:24.749: INFO: Waiting for Pod statefulset-5518/ss2-1 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Oct 28 17:21:34.779: INFO: Updating stateful set ss2
Oct 28 17:21:34.790: INFO: Waiting for StatefulSet statefulset-5518/ss2 to complete update
Oct 28 17:21:34.790: INFO: Waiting for Pod statefulset-5518/ss2-0 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Oct 28 17:21:44.799: INFO: Waiting for StatefulSet statefulset-5518/ss2 to complete update
Oct 28 17:21:44.799: INFO: Waiting for Pod statefulset-5518/ss2-0 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Oct 28 17:21:54.804: INFO: Waiting for StatefulSet statefulset-5518/ss2 to complete update
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Oct 28 17:22:04.799: INFO: Deleting all statefulset in ns statefulset-5518
Oct 28 17:22:04.803: INFO: Scaling statefulset ss2 to 0
Oct 28 17:22:34.824: INFO: Waiting for statefulset status.replicas updated to 0
Oct 28 17:22:34.827: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 17:22:34.843: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-5518" for this suite.
Oct 28 17:22:40.879: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 17:22:41.044: INFO: namespace statefulset-5518 deletion completed in 6.190585139s

• [SLOW TEST:136.796 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 17:22:41.044: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-7080
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0777 on tmpfs
Oct 28 17:22:41.219: INFO: Waiting up to 5m0s for pod "pod-ecc70146-fd20-45ee-bd5e-daaa0982279a" in namespace "emptydir-7080" to be "success or failure"
Oct 28 17:22:41.228: INFO: Pod "pod-ecc70146-fd20-45ee-bd5e-daaa0982279a": Phase="Pending", Reason="", readiness=false. Elapsed: 8.628321ms
Oct 28 17:22:43.232: INFO: Pod "pod-ecc70146-fd20-45ee-bd5e-daaa0982279a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013412824s
Oct 28 17:22:45.237: INFO: Pod "pod-ecc70146-fd20-45ee-bd5e-daaa0982279a": Phase="Pending", Reason="", readiness=false. Elapsed: 4.018508228s
Oct 28 17:22:47.246: INFO: Pod "pod-ecc70146-fd20-45ee-bd5e-daaa0982279a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.027431739s
STEP: Saw pod success
Oct 28 17:22:47.246: INFO: Pod "pod-ecc70146-fd20-45ee-bd5e-daaa0982279a" satisfied condition "success or failure"
Oct 28 17:22:47.250: INFO: Trying to get logs from node kh4ga-worker-000003 pod pod-ecc70146-fd20-45ee-bd5e-daaa0982279a container test-container: <nil>
STEP: delete the pod
Oct 28 17:22:47.293: INFO: Waiting for pod pod-ecc70146-fd20-45ee-bd5e-daaa0982279a to disappear
Oct 28 17:22:47.310: INFO: Pod pod-ecc70146-fd20-45ee-bd5e-daaa0982279a no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 17:22:47.310: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7080" for this suite.
Oct 28 17:22:53.355: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 17:22:53.512: INFO: namespace emptydir-7080 deletion completed in 6.193071226s

• [SLOW TEST:12.468 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 17:22:53.513: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-1318
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Oct 28 17:22:53.672: INFO: Waiting up to 5m0s for pod "downward-api-be6fdac1-b42f-4df8-887b-8ecb7c414e5b" in namespace "downward-api-1318" to be "success or failure"
Oct 28 17:22:53.685: INFO: Pod "downward-api-be6fdac1-b42f-4df8-887b-8ecb7c414e5b": Phase="Pending", Reason="", readiness=false. Elapsed: 12.73633ms
Oct 28 17:22:55.692: INFO: Pod "downward-api-be6fdac1-b42f-4df8-887b-8ecb7c414e5b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020036033s
Oct 28 17:22:57.696: INFO: Pod "downward-api-be6fdac1-b42f-4df8-887b-8ecb7c414e5b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023934928s
STEP: Saw pod success
Oct 28 17:22:57.696: INFO: Pod "downward-api-be6fdac1-b42f-4df8-887b-8ecb7c414e5b" satisfied condition "success or failure"
Oct 28 17:22:57.700: INFO: Trying to get logs from node kh4ga-worker-000000 pod downward-api-be6fdac1-b42f-4df8-887b-8ecb7c414e5b container dapi-container: <nil>
STEP: delete the pod
Oct 28 17:22:57.723: INFO: Waiting for pod downward-api-be6fdac1-b42f-4df8-887b-8ecb7c414e5b to disappear
Oct 28 17:22:57.728: INFO: Pod downward-api-be6fdac1-b42f-4df8-887b-8ecb7c414e5b no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 17:22:57.728: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1318" for this suite.
Oct 28 17:23:03.777: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 17:23:03.941: INFO: namespace downward-api-1318 deletion completed in 6.199911527s

• [SLOW TEST:10.428 seconds]
[sig-node] Downward API
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 17:23:03.941: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-1252
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Oct 28 17:23:10.652: INFO: Successfully updated pod "pod-update-activedeadlineseconds-4049044a-d0c4-4e57-aa30-b53a57d45b24"
Oct 28 17:23:10.652: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-4049044a-d0c4-4e57-aa30-b53a57d45b24" in namespace "pods-1252" to be "terminated due to deadline exceeded"
Oct 28 17:23:10.662: INFO: Pod "pod-update-activedeadlineseconds-4049044a-d0c4-4e57-aa30-b53a57d45b24": Phase="Running", Reason="", readiness=true. Elapsed: 9.085921ms
Oct 28 17:23:12.666: INFO: Pod "pod-update-activedeadlineseconds-4049044a-d0c4-4e57-aa30-b53a57d45b24": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 2.013997911s
Oct 28 17:23:12.667: INFO: Pod "pod-update-activedeadlineseconds-4049044a-d0c4-4e57-aa30-b53a57d45b24" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 17:23:12.667: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-1252" for this suite.
Oct 28 17:23:18.704: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 17:23:18.883: INFO: namespace pods-1252 deletion completed in 6.210167529s

• [SLOW TEST:14.942 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 17:23:18.884: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-9964
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Oct 28 17:23:19.033: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 17:23:25.172: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-9964" for this suite.
Oct 28 17:24:17.194: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 17:24:17.350: INFO: namespace pods-9964 deletion completed in 52.171313862s

• [SLOW TEST:58.467 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-apps] Job 
  should delete a job [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 17:24:17.350: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename job
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in job-5172
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete a job [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: delete a job
STEP: deleting Job.batch foo in namespace job-5172, will wait for the garbage collector to delete the pods
Oct 28 17:24:23.579: INFO: Deleting Job.batch foo took: 6.959316ms
Oct 28 17:24:24.379: INFO: Terminating Job.batch foo pods took: 800.239099ms
STEP: Ensuring job was deleted
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 17:25:06.389: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-5172" for this suite.
Oct 28 17:25:12.411: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 17:25:12.590: INFO: namespace job-5172 deletion completed in 6.194929145s

• [SLOW TEST:55.240 seconds]
[sig-apps] Job
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should delete a job [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 17:25:12.590: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-9653
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Performing setup for networking test in namespace pod-network-test-9653
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Oct 28 17:25:12.749: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Oct 28 17:25:42.907: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.2.131.95:8080/dial?request=hostName&protocol=http&host=10.2.129.29&port=8080&tries=1'] Namespace:pod-network-test-9653 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 28 17:25:42.907: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
Oct 28 17:25:43.034: INFO: Waiting for endpoints: map[]
Oct 28 17:25:43.038: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.2.131.95:8080/dial?request=hostName&protocol=http&host=10.2.130.82&port=8080&tries=1'] Namespace:pod-network-test-9653 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 28 17:25:43.038: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
Oct 28 17:25:43.164: INFO: Waiting for endpoints: map[]
Oct 28 17:25:43.169: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.2.131.95:8080/dial?request=hostName&protocol=http&host=10.2.131.94&port=8080&tries=1'] Namespace:pod-network-test-9653 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 28 17:25:43.169: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
Oct 28 17:25:43.299: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 17:25:43.299: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-9653" for this suite.
Oct 28 17:26:05.327: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 17:26:05.488: INFO: namespace pod-network-test-9653 deletion completed in 22.181721358s

• [SLOW TEST:52.898 seconds]
[sig-network] Networking
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 17:26:05.488: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-7961
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating Redis RC
Oct 28 17:26:05.638: INFO: namespace kubectl-7961
Oct 28 17:26:05.638: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-124947935 create -f - --namespace=kubectl-7961'
Oct 28 17:26:08.980: INFO: stderr: ""
Oct 28 17:26:08.980: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Oct 28 17:26:09.986: INFO: Selector matched 1 pods for map[app:redis]
Oct 28 17:26:09.986: INFO: Found 0 / 1
Oct 28 17:26:10.986: INFO: Selector matched 1 pods for map[app:redis]
Oct 28 17:26:10.986: INFO: Found 0 / 1
Oct 28 17:26:11.986: INFO: Selector matched 1 pods for map[app:redis]
Oct 28 17:26:11.986: INFO: Found 0 / 1
Oct 28 17:26:12.986: INFO: Selector matched 1 pods for map[app:redis]
Oct 28 17:26:12.986: INFO: Found 0 / 1
Oct 28 17:26:13.985: INFO: Selector matched 1 pods for map[app:redis]
Oct 28 17:26:13.986: INFO: Found 1 / 1
Oct 28 17:26:13.986: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Oct 28 17:26:13.989: INFO: Selector matched 1 pods for map[app:redis]
Oct 28 17:26:13.989: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Oct 28 17:26:13.989: INFO: wait on redis-master startup in kubectl-7961 
Oct 28 17:26:13.989: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-124947935 logs redis-master-6tbfn redis-master --namespace=kubectl-7961'
Oct 28 17:26:14.076: INFO: stderr: ""
Oct 28 17:26:14.076: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 28 Oct 17:26:12.618 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 28 Oct 17:26:12.618 # Server started, Redis version 3.2.12\n1:M 28 Oct 17:26:12.618 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 28 Oct 17:26:12.618 * The server is now ready to accept connections on port 6379\n"
STEP: exposing RC
Oct 28 17:26:14.076: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-124947935 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=kubectl-7961'
Oct 28 17:26:14.185: INFO: stderr: ""
Oct 28 17:26:14.185: INFO: stdout: "service/rm2 exposed\n"
Oct 28 17:26:14.191: INFO: Service rm2 in namespace kubectl-7961 found.
STEP: exposing service
Oct 28 17:26:16.200: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-124947935 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=kubectl-7961'
Oct 28 17:26:16.293: INFO: stderr: ""
Oct 28 17:26:16.293: INFO: stdout: "service/rm3 exposed\n"
Oct 28 17:26:16.301: INFO: Service rm3 in namespace kubectl-7961 found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 17:26:18.309: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7961" for this suite.
Oct 28 17:26:38.330: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 17:26:38.493: INFO: namespace kubectl-7961 deletion completed in 20.177733087s

• [SLOW TEST:33.005 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl expose
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create services for rc  [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 17:26:38.494: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-1213
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Oct 28 17:26:38.689: INFO: DaemonSet pods can't tolerate node kh4ga-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 28 17:26:38.693: INFO: Number of nodes with available pods: 0
Oct 28 17:26:38.693: INFO: Node kh4ga-worker-000000 is running more than one daemon pod
Oct 28 17:26:39.700: INFO: DaemonSet pods can't tolerate node kh4ga-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 28 17:26:39.704: INFO: Number of nodes with available pods: 0
Oct 28 17:26:39.704: INFO: Node kh4ga-worker-000000 is running more than one daemon pod
Oct 28 17:26:40.700: INFO: DaemonSet pods can't tolerate node kh4ga-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 28 17:26:40.704: INFO: Number of nodes with available pods: 0
Oct 28 17:26:40.704: INFO: Node kh4ga-worker-000000 is running more than one daemon pod
Oct 28 17:26:41.702: INFO: DaemonSet pods can't tolerate node kh4ga-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 28 17:26:41.706: INFO: Number of nodes with available pods: 0
Oct 28 17:26:41.706: INFO: Node kh4ga-worker-000000 is running more than one daemon pod
Oct 28 17:26:42.702: INFO: DaemonSet pods can't tolerate node kh4ga-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 28 17:26:42.706: INFO: Number of nodes with available pods: 0
Oct 28 17:26:42.706: INFO: Node kh4ga-worker-000000 is running more than one daemon pod
Oct 28 17:26:43.701: INFO: DaemonSet pods can't tolerate node kh4ga-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 28 17:26:43.705: INFO: Number of nodes with available pods: 3
Oct 28 17:26:43.705: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Oct 28 17:26:43.728: INFO: DaemonSet pods can't tolerate node kh4ga-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 28 17:26:43.732: INFO: Number of nodes with available pods: 3
Oct 28 17:26:43.732: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-1213, will wait for the garbage collector to delete the pods
Oct 28 17:26:44.808: INFO: Deleting DaemonSet.extensions daemon-set took: 7.169575ms
Oct 28 17:26:44.909: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.206343ms
Oct 28 17:26:57.314: INFO: Number of nodes with available pods: 0
Oct 28 17:26:57.314: INFO: Number of running nodes: 0, number of available pods: 0
Oct 28 17:26:57.318: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-1213/daemonsets","resourceVersion":"13826"},"items":null}

Oct 28 17:26:57.321: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-1213/pods","resourceVersion":"13826"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 17:26:57.338: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-1213" for this suite.
Oct 28 17:27:03.359: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 17:27:03.595: INFO: namespace daemonsets-1213 deletion completed in 6.251401091s

• [SLOW TEST:25.101 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 17:27:03.595: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-2519
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:81
Oct 28 17:27:03.815: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Oct 28 17:27:03.828: INFO: Waiting for terminating namespaces to be deleted...
Oct 28 17:27:03.832: INFO: 
Logging pods the kubelet thinks is on node kh4ga-worker-000000 before test
Oct 28 17:27:03.844: INFO: sonobuoy-e2e-job-2b01bf00cc914c5a from sonobuoy started at 2019-10-28 16:31:37 +0000 UTC (2 container statuses recorded)
Oct 28 17:27:03.844: INFO: 	Container e2e ready: true, restart count 0
Oct 28 17:27:03.844: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct 28 17:27:03.844: INFO: calico-node-bqrms from kube-system started at 2019-10-28 16:23:02 +0000 UTC (1 container statuses recorded)
Oct 28 17:27:03.844: INFO: 	Container calico-node ready: true, restart count 0
Oct 28 17:27:03.844: INFO: kube-proxy-5r5g9 from kube-system started at 2019-10-28 16:23:02 +0000 UTC (1 container statuses recorded)
Oct 28 17:27:03.844: INFO: 	Container kube-proxy ready: true, restart count 0
Oct 28 17:27:03.844: INFO: net-exporter-v94hf from kube-system started at 2019-10-28 16:26:19 +0000 UTC (1 container statuses recorded)
Oct 28 17:27:03.844: INFO: 	Container net-exporter ready: true, restart count 0
Oct 28 17:27:03.844: INFO: nginx-ingress-controller-6b49fc4779-46b6j from kube-system started at 2019-10-28 16:26:20 +0000 UTC (1 container statuses recorded)
Oct 28 17:27:03.844: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Oct 28 17:27:03.844: INFO: sonobuoy from sonobuoy started at 2019-10-28 16:31:26 +0000 UTC (1 container statuses recorded)
Oct 28 17:27:03.844: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Oct 28 17:27:03.844: INFO: node-exporter-94ffd from kube-system started at 2019-10-28 16:25:51 +0000 UTC (1 container statuses recorded)
Oct 28 17:27:03.844: INFO: 	Container node-exporter ready: true, restart count 0
Oct 28 17:27:03.844: INFO: external-dns-769446d578-7lh6n from kube-system started at 2019-10-28 16:26:07 +0000 UTC (1 container statuses recorded)
Oct 28 17:27:03.844: INFO: 	Container external-dns ready: true, restart count 0
Oct 28 17:27:03.844: INFO: sonobuoy-systemd-logs-daemon-set-80aafb278b8f4e15-fhxc7 from sonobuoy started at 2019-10-28 16:31:37 +0000 UTC (2 container statuses recorded)
Oct 28 17:27:03.844: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct 28 17:27:03.844: INFO: 	Container systemd-logs ready: true, restart count 0
Oct 28 17:27:03.844: INFO: coredns-7b76874c7b-hnw8g from kube-system started at 2019-10-28 16:25:57 +0000 UTC (1 container statuses recorded)
Oct 28 17:27:03.844: INFO: 	Container coredns ready: true, restart count 0
Oct 28 17:27:03.844: INFO: cert-exporter-7zznl from kube-system started at 2019-10-28 16:26:11 +0000 UTC (1 container statuses recorded)
Oct 28 17:27:03.844: INFO: 	Container cert-exporter ready: true, restart count 0
Oct 28 17:27:03.844: INFO: 
Logging pods the kubelet thinks is on node kh4ga-worker-000002 before test
Oct 28 17:27:03.857: INFO: tiller-deploy-5db95cf576-tbgkz from giantswarm started at 2019-10-28 16:23:58 +0000 UTC (1 container statuses recorded)
Oct 28 17:27:03.857: INFO: 	Container tiller ready: true, restart count 0
Oct 28 17:27:03.857: INFO: net-exporter-rb7qj from kube-system started at 2019-10-28 16:26:20 +0000 UTC (1 container statuses recorded)
Oct 28 17:27:03.857: INFO: 	Container net-exporter ready: true, restart count 0
Oct 28 17:27:03.857: INFO: node-exporter-b29jz from kube-system started at 2019-10-28 16:25:51 +0000 UTC (1 container statuses recorded)
Oct 28 17:27:03.857: INFO: 	Container node-exporter ready: true, restart count 0
Oct 28 17:27:03.857: INFO: kube-proxy-hcbz2 from kube-system started at 2019-10-28 16:22:57 +0000 UTC (1 container statuses recorded)
Oct 28 17:27:03.857: INFO: 	Container kube-proxy ready: true, restart count 0
Oct 28 17:27:03.857: INFO: calico-node-wzq68 from kube-system started at 2019-10-28 16:22:57 +0000 UTC (1 container statuses recorded)
Oct 28 17:27:03.857: INFO: 	Container calico-node ready: true, restart count 0
Oct 28 17:27:03.857: INFO: chart-operator-7dcfd7559b-4xhkx from giantswarm started at 2019-10-28 16:25:53 +0000 UTC (1 container statuses recorded)
Oct 28 17:27:03.857: INFO: 	Container chart-operator ready: true, restart count 0
Oct 28 17:27:03.857: INFO: cert-exporter-shzc7 from kube-system started at 2019-10-28 16:26:17 +0000 UTC (1 container statuses recorded)
Oct 28 17:27:03.857: INFO: 	Container cert-exporter ready: true, restart count 0
Oct 28 17:27:03.857: INFO: kube-state-metrics-586fbd9595-r5656 from kube-system started at 2019-10-28 16:26:10 +0000 UTC (2 container statuses recorded)
Oct 28 17:27:03.857: INFO: 	Container addon-resizer ready: true, restart count 0
Oct 28 17:27:03.857: INFO: 	Container kube-state-metrics ready: true, restart count 0
Oct 28 17:27:03.857: INFO: nginx-ingress-controller-6b49fc4779-t5skf from kube-system started at 2019-10-28 16:26:20 +0000 UTC (1 container statuses recorded)
Oct 28 17:27:03.857: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Oct 28 17:27:03.857: INFO: sonobuoy-systemd-logs-daemon-set-80aafb278b8f4e15-wqcmm from sonobuoy started at 2019-10-28 16:31:37 +0000 UTC (2 container statuses recorded)
Oct 28 17:27:03.857: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct 28 17:27:03.857: INFO: 	Container systemd-logs ready: true, restart count 0
Oct 28 17:27:03.857: INFO: 
Logging pods the kubelet thinks is on node kh4ga-worker-000003 before test
Oct 28 17:27:03.868: INFO: metrics-server-586d4684b4-qh7rw from kube-system started at 2019-10-28 16:25:49 +0000 UTC (1 container statuses recorded)
Oct 28 17:27:03.868: INFO: 	Container metrics-server ready: true, restart count 0
Oct 28 17:27:03.868: INFO: coredns-7b76874c7b-654r4 from kube-system started at 2019-10-28 16:25:59 +0000 UTC (1 container statuses recorded)
Oct 28 17:27:03.868: INFO: 	Container coredns ready: true, restart count 0
Oct 28 17:27:03.868: INFO: cert-exporter-cjdz5 from kube-system started at 2019-10-28 16:26:16 +0000 UTC (1 container statuses recorded)
Oct 28 17:27:03.868: INFO: 	Container cert-exporter ready: true, restart count 0
Oct 28 17:27:03.868: INFO: nginx-ingress-controller-6b49fc4779-ddjkh from kube-system started at 2019-10-28 16:26:20 +0000 UTC (1 container statuses recorded)
Oct 28 17:27:03.868: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Oct 28 17:27:03.868: INFO: kube-proxy-lc8jd from kube-system started at 2019-10-28 16:23:07 +0000 UTC (1 container statuses recorded)
Oct 28 17:27:03.868: INFO: 	Container kube-proxy ready: true, restart count 0
Oct 28 17:27:03.868: INFO: net-exporter-vhl5t from kube-system started at 2019-10-28 16:26:19 +0000 UTC (1 container statuses recorded)
Oct 28 17:27:03.868: INFO: 	Container net-exporter ready: true, restart count 0
Oct 28 17:27:03.868: INFO: node-exporter-4q9vs from kube-system started at 2019-10-28 16:25:51 +0000 UTC (1 container statuses recorded)
Oct 28 17:27:03.868: INFO: 	Container node-exporter ready: true, restart count 0
Oct 28 17:27:03.868: INFO: calico-node-sxmff from kube-system started at 2019-10-28 16:23:07 +0000 UTC (1 container statuses recorded)
Oct 28 17:27:03.868: INFO: 	Container calico-node ready: true, restart count 0
Oct 28 17:27:03.868: INFO: sonobuoy-systemd-logs-daemon-set-80aafb278b8f4e15-rvx7d from sonobuoy started at 2019-10-28 16:31:37 +0000 UTC (2 container statuses recorded)
Oct 28 17:27:03.868: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct 28 17:27:03.868: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: verifying the node has the label node kh4ga-worker-000000
STEP: verifying the node has the label node kh4ga-worker-000002
STEP: verifying the node has the label node kh4ga-worker-000003
Oct 28 17:27:03.950: INFO: Pod chart-operator-7dcfd7559b-4xhkx requesting resource cpu=250m on Node kh4ga-worker-000002
Oct 28 17:27:03.950: INFO: Pod tiller-deploy-5db95cf576-tbgkz requesting resource cpu=0m on Node kh4ga-worker-000002
Oct 28 17:27:03.950: INFO: Pod calico-node-bqrms requesting resource cpu=250m on Node kh4ga-worker-000000
Oct 28 17:27:03.950: INFO: Pod calico-node-sxmff requesting resource cpu=250m on Node kh4ga-worker-000003
Oct 28 17:27:03.950: INFO: Pod calico-node-wzq68 requesting resource cpu=250m on Node kh4ga-worker-000002
Oct 28 17:27:03.950: INFO: Pod cert-exporter-7zznl requesting resource cpu=50m on Node kh4ga-worker-000000
Oct 28 17:27:03.950: INFO: Pod cert-exporter-cjdz5 requesting resource cpu=50m on Node kh4ga-worker-000003
Oct 28 17:27:03.950: INFO: Pod cert-exporter-shzc7 requesting resource cpu=50m on Node kh4ga-worker-000002
Oct 28 17:27:03.950: INFO: Pod coredns-7b76874c7b-654r4 requesting resource cpu=250m on Node kh4ga-worker-000003
Oct 28 17:27:03.950: INFO: Pod coredns-7b76874c7b-hnw8g requesting resource cpu=250m on Node kh4ga-worker-000000
Oct 28 17:27:03.950: INFO: Pod external-dns-769446d578-7lh6n requesting resource cpu=50m on Node kh4ga-worker-000000
Oct 28 17:27:03.950: INFO: Pod kube-proxy-5r5g9 requesting resource cpu=75m on Node kh4ga-worker-000000
Oct 28 17:27:03.950: INFO: Pod kube-proxy-hcbz2 requesting resource cpu=75m on Node kh4ga-worker-000002
Oct 28 17:27:03.950: INFO: Pod kube-proxy-lc8jd requesting resource cpu=75m on Node kh4ga-worker-000003
Oct 28 17:27:03.950: INFO: Pod kube-state-metrics-586fbd9595-r5656 requesting resource cpu=490m on Node kh4ga-worker-000002
Oct 28 17:27:03.950: INFO: Pod metrics-server-586d4684b4-qh7rw requesting resource cpu=0m on Node kh4ga-worker-000003
Oct 28 17:27:03.950: INFO: Pod net-exporter-rb7qj requesting resource cpu=0m on Node kh4ga-worker-000002
Oct 28 17:27:03.950: INFO: Pod net-exporter-v94hf requesting resource cpu=0m on Node kh4ga-worker-000000
Oct 28 17:27:03.950: INFO: Pod net-exporter-vhl5t requesting resource cpu=0m on Node kh4ga-worker-000003
Oct 28 17:27:03.950: INFO: Pod nginx-ingress-controller-6b49fc4779-46b6j requesting resource cpu=500m on Node kh4ga-worker-000000
Oct 28 17:27:03.950: INFO: Pod nginx-ingress-controller-6b49fc4779-ddjkh requesting resource cpu=500m on Node kh4ga-worker-000003
Oct 28 17:27:03.950: INFO: Pod nginx-ingress-controller-6b49fc4779-t5skf requesting resource cpu=500m on Node kh4ga-worker-000002
Oct 28 17:27:03.950: INFO: Pod node-exporter-4q9vs requesting resource cpu=75m on Node kh4ga-worker-000003
Oct 28 17:27:03.950: INFO: Pod node-exporter-94ffd requesting resource cpu=75m on Node kh4ga-worker-000000
Oct 28 17:27:03.950: INFO: Pod node-exporter-b29jz requesting resource cpu=75m on Node kh4ga-worker-000002
Oct 28 17:27:03.950: INFO: Pod sonobuoy requesting resource cpu=0m on Node kh4ga-worker-000000
Oct 28 17:27:03.950: INFO: Pod sonobuoy-e2e-job-2b01bf00cc914c5a requesting resource cpu=0m on Node kh4ga-worker-000000
Oct 28 17:27:03.950: INFO: Pod sonobuoy-systemd-logs-daemon-set-80aafb278b8f4e15-fhxc7 requesting resource cpu=0m on Node kh4ga-worker-000000
Oct 28 17:27:03.950: INFO: Pod sonobuoy-systemd-logs-daemon-set-80aafb278b8f4e15-rvx7d requesting resource cpu=0m on Node kh4ga-worker-000003
Oct 28 17:27:03.950: INFO: Pod sonobuoy-systemd-logs-daemon-set-80aafb278b8f4e15-wqcmm requesting resource cpu=0m on Node kh4ga-worker-000002
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-10aa27be-8c0c-4c7c-ba23-0cdaf9638dc9.15d1dfa02eae47b3], Reason = [Scheduled], Message = [Successfully assigned sched-pred-2519/filler-pod-10aa27be-8c0c-4c7c-ba23-0cdaf9638dc9 to kh4ga-worker-000003]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-10aa27be-8c0c-4c7c-ba23-0cdaf9638dc9.15d1dfa09ffe5f28], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-10aa27be-8c0c-4c7c-ba23-0cdaf9638dc9.15d1dfa0e6b0c113], Reason = [Created], Message = [Created container filler-pod-10aa27be-8c0c-4c7c-ba23-0cdaf9638dc9]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-10aa27be-8c0c-4c7c-ba23-0cdaf9638dc9.15d1dfa0f40526e9], Reason = [Started], Message = [Started container filler-pod-10aa27be-8c0c-4c7c-ba23-0cdaf9638dc9]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-805ff83d-cb64-4c7a-85c8-07057b67b553.15d1dfa02dfa925f], Reason = [Scheduled], Message = [Successfully assigned sched-pred-2519/filler-pod-805ff83d-cb64-4c7a-85c8-07057b67b553 to kh4ga-worker-000002]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-805ff83d-cb64-4c7a-85c8-07057b67b553.15d1dfa0a19ca586], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-805ff83d-cb64-4c7a-85c8-07057b67b553.15d1dfa0efc0b894], Reason = [Created], Message = [Created container filler-pod-805ff83d-cb64-4c7a-85c8-07057b67b553]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-805ff83d-cb64-4c7a-85c8-07057b67b553.15d1dfa0fb4b1608], Reason = [Started], Message = [Started container filler-pod-805ff83d-cb64-4c7a-85c8-07057b67b553]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-a8c4b3b6-d65f-477d-9fb8-d6728ecc50ba.15d1dfa02cfca680], Reason = [Scheduled], Message = [Successfully assigned sched-pred-2519/filler-pod-a8c4b3b6-d65f-477d-9fb8-d6728ecc50ba to kh4ga-worker-000000]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-a8c4b3b6-d65f-477d-9fb8-d6728ecc50ba.15d1dfa0a710ae15], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-a8c4b3b6-d65f-477d-9fb8-d6728ecc50ba.15d1dfa0f6e7b4f2], Reason = [Created], Message = [Created container filler-pod-a8c4b3b6-d65f-477d-9fb8-d6728ecc50ba]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-a8c4b3b6-d65f-477d-9fb8-d6728ecc50ba.15d1dfa101f859e4], Reason = [Started], Message = [Started container filler-pod-a8c4b3b6-d65f-477d-9fb8-d6728ecc50ba]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.15d1dfa11e8f5e7d], Reason = [FailedScheduling], Message = [0/4 nodes are available: 4 Insufficient cpu.]
STEP: removing the label node off the node kh4ga-worker-000000
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node kh4ga-worker-000002
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node kh4ga-worker-000003
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 17:27:09.174: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-2519" for this suite.
Oct 28 17:27:15.194: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 17:27:15.389: INFO: namespace sched-pred-2519 deletion completed in 6.209107727s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:72

• [SLOW TEST:11.794 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 17:27:15.389: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-9401
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-9401
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating stateful set ss in namespace statefulset-9401
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-9401
Oct 28 17:27:15.568: INFO: Found 0 stateful pods, waiting for 1
Oct 28 17:27:25.576: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Oct 28 17:27:25.580: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-124947935 exec --namespace=statefulset-9401 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Oct 28 17:27:25.777: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Oct 28 17:27:25.777: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Oct 28 17:27:25.777: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Oct 28 17:27:25.782: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Oct 28 17:27:35.786: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Oct 28 17:27:35.786: INFO: Waiting for statefulset status.replicas updated to 0
Oct 28 17:27:35.808: INFO: POD   NODE                 PHASE    GRACE  CONDITIONS
Oct 28 17:27:35.808: INFO: ss-0  kh4ga-worker-000000  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-28 17:27:15 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-28 17:27:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-28 17:27:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-28 17:27:15 +0000 UTC  }]
Oct 28 17:27:35.808: INFO: 
Oct 28 17:27:35.808: INFO: StatefulSet ss has not reached scale 3, at 1
Oct 28 17:27:36.812: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.99073635s
Oct 28 17:27:37.817: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.98640756s
Oct 28 17:27:38.823: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.981334275s
Oct 28 17:27:39.830: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.975512395s
Oct 28 17:27:40.835: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.968873219s
Oct 28 17:27:41.839: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.964139174s
Oct 28 17:27:42.844: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.959449541s
Oct 28 17:27:43.849: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.954402116s
Oct 28 17:27:44.867: INFO: Verifying statefulset ss doesn't scale past 3 for another 949.597906ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-9401
Oct 28 17:27:45.875: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-124947935 exec --namespace=statefulset-9401 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 28 17:27:46.080: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Oct 28 17:27:46.081: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Oct 28 17:27:46.081: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Oct 28 17:27:46.081: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-124947935 exec --namespace=statefulset-9401 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 28 17:27:46.285: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Oct 28 17:27:46.285: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Oct 28 17:27:46.285: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Oct 28 17:27:46.285: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-124947935 exec --namespace=statefulset-9401 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 28 17:27:46.487: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Oct 28 17:27:46.487: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Oct 28 17:27:46.487: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Oct 28 17:27:46.493: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=false
Oct 28 17:27:56.498: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Oct 28 17:27:56.498: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Oct 28 17:27:56.498: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Oct 28 17:27:56.503: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-124947935 exec --namespace=statefulset-9401 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Oct 28 17:27:56.703: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Oct 28 17:27:56.703: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Oct 28 17:27:56.703: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Oct 28 17:27:56.703: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-124947935 exec --namespace=statefulset-9401 ss-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Oct 28 17:27:56.927: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Oct 28 17:27:56.927: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Oct 28 17:27:56.927: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Oct 28 17:27:56.927: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-124947935 exec --namespace=statefulset-9401 ss-2 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Oct 28 17:27:57.132: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Oct 28 17:27:57.132: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Oct 28 17:27:57.132: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Oct 28 17:27:57.132: INFO: Waiting for statefulset status.replicas updated to 0
Oct 28 17:27:57.137: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Oct 28 17:28:07.147: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Oct 28 17:28:07.147: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Oct 28 17:28:07.147: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Oct 28 17:28:07.172: INFO: POD   NODE                 PHASE    GRACE  CONDITIONS
Oct 28 17:28:07.172: INFO: ss-0  kh4ga-worker-000000  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-28 17:27:15 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-28 17:27:56 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-28 17:27:56 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-28 17:27:15 +0000 UTC  }]
Oct 28 17:28:07.172: INFO: ss-1  kh4ga-worker-000003  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-28 17:27:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-28 17:27:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-28 17:27:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-28 17:27:35 +0000 UTC  }]
Oct 28 17:28:07.172: INFO: ss-2  kh4ga-worker-000002  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-28 17:27:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-28 17:27:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-28 17:27:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-28 17:27:35 +0000 UTC  }]
Oct 28 17:28:07.172: INFO: 
Oct 28 17:28:07.172: INFO: StatefulSet ss has not reached scale 0, at 3
Oct 28 17:28:08.177: INFO: POD   NODE                 PHASE    GRACE  CONDITIONS
Oct 28 17:28:08.177: INFO: ss-0  kh4ga-worker-000000  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-28 17:27:15 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-28 17:27:56 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-28 17:27:56 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-28 17:27:15 +0000 UTC  }]
Oct 28 17:28:08.177: INFO: ss-1  kh4ga-worker-000003  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-28 17:27:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-28 17:27:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-28 17:27:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-28 17:27:35 +0000 UTC  }]
Oct 28 17:28:08.177: INFO: ss-2  kh4ga-worker-000002  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-28 17:27:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-28 17:27:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-28 17:27:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-28 17:27:35 +0000 UTC  }]
Oct 28 17:28:08.177: INFO: 
Oct 28 17:28:08.177: INFO: StatefulSet ss has not reached scale 0, at 3
Oct 28 17:28:09.183: INFO: POD   NODE                 PHASE    GRACE  CONDITIONS
Oct 28 17:28:09.183: INFO: ss-0  kh4ga-worker-000000  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-28 17:27:15 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-28 17:27:56 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-28 17:27:56 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-28 17:27:15 +0000 UTC  }]
Oct 28 17:28:09.183: INFO: ss-1  kh4ga-worker-000003  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-28 17:27:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-28 17:27:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-28 17:27:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-28 17:27:35 +0000 UTC  }]
Oct 28 17:28:09.183: INFO: ss-2  kh4ga-worker-000002  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-28 17:27:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-28 17:27:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-28 17:27:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-28 17:27:35 +0000 UTC  }]
Oct 28 17:28:09.183: INFO: 
Oct 28 17:28:09.183: INFO: StatefulSet ss has not reached scale 0, at 3
Oct 28 17:28:10.188: INFO: POD   NODE                 PHASE    GRACE  CONDITIONS
Oct 28 17:28:10.188: INFO: ss-0  kh4ga-worker-000000  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-28 17:27:15 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-28 17:27:56 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-28 17:27:56 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-28 17:27:15 +0000 UTC  }]
Oct 28 17:28:10.188: INFO: ss-1  kh4ga-worker-000003  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-28 17:27:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-28 17:27:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-28 17:27:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-28 17:27:35 +0000 UTC  }]
Oct 28 17:28:10.188: INFO: 
Oct 28 17:28:10.188: INFO: StatefulSet ss has not reached scale 0, at 2
Oct 28 17:28:11.194: INFO: Verifying statefulset ss doesn't scale past 0 for another 5.975377256s
Oct 28 17:28:12.198: INFO: Verifying statefulset ss doesn't scale past 0 for another 4.969858555s
Oct 28 17:28:13.203: INFO: Verifying statefulset ss doesn't scale past 0 for another 3.965683477s
Oct 28 17:28:14.208: INFO: Verifying statefulset ss doesn't scale past 0 for another 2.960548602s
Oct 28 17:28:15.212: INFO: Verifying statefulset ss doesn't scale past 0 for another 1.955492038s
Oct 28 17:28:16.217: INFO: Verifying statefulset ss doesn't scale past 0 for another 951.078292ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-9401
Oct 28 17:28:17.222: INFO: Scaling statefulset ss to 0
Oct 28 17:28:17.234: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Oct 28 17:28:17.238: INFO: Deleting all statefulset in ns statefulset-9401
Oct 28 17:28:17.241: INFO: Scaling statefulset ss to 0
Oct 28 17:28:17.256: INFO: Waiting for statefulset status.replicas updated to 0
Oct 28 17:28:17.261: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 17:28:17.289: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-9401" for this suite.
Oct 28 17:28:23.331: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 17:28:23.496: INFO: namespace statefulset-9401 deletion completed in 6.190923987s

• [SLOW TEST:68.107 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 17:28:23.496: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-3778
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1420
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Oct 28 17:28:23.655: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-124947935 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-3778'
Oct 28 17:28:23.734: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Oct 28 17:28:23.734: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1426
Oct 28 17:28:25.750: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-124947935 delete deployment e2e-test-nginx-deployment --namespace=kubectl-3778'
Oct 28 17:28:25.829: INFO: stderr: ""
Oct 28 17:28:25.829: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 17:28:25.829: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3778" for this suite.
Oct 28 17:28:31.875: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 17:28:32.029: INFO: namespace kubectl-3778 deletion completed in 6.1896214s

• [SLOW TEST:8.533 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run default
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 17:28:32.029: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-5007
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0777 on node default medium
Oct 28 17:28:32.205: INFO: Waiting up to 5m0s for pod "pod-5ab0d961-9c8c-4cc7-a965-484ff71c0a16" in namespace "emptydir-5007" to be "success or failure"
Oct 28 17:28:32.220: INFO: Pod "pod-5ab0d961-9c8c-4cc7-a965-484ff71c0a16": Phase="Pending", Reason="", readiness=false. Elapsed: 14.919036ms
Oct 28 17:28:34.226: INFO: Pod "pod-5ab0d961-9c8c-4cc7-a965-484ff71c0a16": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020533716s
Oct 28 17:28:36.232: INFO: Pod "pod-5ab0d961-9c8c-4cc7-a965-484ff71c0a16": Phase="Pending", Reason="", readiness=false. Elapsed: 4.027059861s
Oct 28 17:28:38.237: INFO: Pod "pod-5ab0d961-9c8c-4cc7-a965-484ff71c0a16": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.031404443s
STEP: Saw pod success
Oct 28 17:28:38.237: INFO: Pod "pod-5ab0d961-9c8c-4cc7-a965-484ff71c0a16" satisfied condition "success or failure"
Oct 28 17:28:38.240: INFO: Trying to get logs from node kh4ga-worker-000000 pod pod-5ab0d961-9c8c-4cc7-a965-484ff71c0a16 container test-container: <nil>
STEP: delete the pod
Oct 28 17:28:38.267: INFO: Waiting for pod pod-5ab0d961-9c8c-4cc7-a965-484ff71c0a16 to disappear
Oct 28 17:28:38.287: INFO: Pod pod-5ab0d961-9c8c-4cc7-a965-484ff71c0a16 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 17:28:38.287: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5007" for this suite.
Oct 28 17:28:44.312: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 17:28:44.466: INFO: namespace emptydir-5007 deletion completed in 6.170327002s

• [SLOW TEST:12.437 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 17:28:44.467: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svcaccounts-7634
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: getting the auto-created API token
STEP: reading a file in the container
Oct 28 17:28:51.177: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-7634 pod-service-account-8c69e8c1-c4e4-42c0-831e-e525edbe9d0a -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
STEP: reading a file in the container
Oct 28 17:28:51.370: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-7634 pod-service-account-8c69e8c1-c4e4-42c0-831e-e525edbe9d0a -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
STEP: reading a file in the container
Oct 28 17:28:51.569: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-7634 pod-service-account-8c69e8c1-c4e4-42c0-831e-e525edbe9d0a -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 17:28:51.770: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-7634" for this suite.
Oct 28 17:28:57.791: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 17:28:57.939: INFO: namespace svcaccounts-7634 deletion completed in 6.162445667s

• [SLOW TEST:13.472 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:23
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 17:28:57.940: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-9433
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating the pod
Oct 28 17:29:04.661: INFO: Successfully updated pod "annotationupdate4bedf13d-2e5e-4251-869f-ffd2e509f718"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 17:29:06.697: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9433" for this suite.
Oct 28 17:29:28.742: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 17:29:28.927: INFO: namespace downward-api-9433 deletion completed in 22.22277428s

• [SLOW TEST:30.987 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 17:29:28.927: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-1535
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Oct 28 17:29:29.068: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 17:29:35.114: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-1535" for this suite.
Oct 28 17:30:19.137: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 17:30:19.291: INFO: namespace pods-1535 deletion completed in 44.169908469s

• [SLOW TEST:50.364 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 17:30:19.292: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-wrapper-5895
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 17:30:25.536: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-5895" for this suite.
Oct 28 17:30:31.562: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 17:30:31.724: INFO: namespace emptydir-wrapper-5895 deletion completed in 6.18094189s

• [SLOW TEST:12.432 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not conflict [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 17:30:31.724: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-6663
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap that has name configmap-test-emptyKey-8dbc875c-2bc0-4838-b476-285ac43ae083
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 17:30:31.879: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6663" for this suite.
Oct 28 17:30:37.902: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 17:30:38.076: INFO: namespace configmap-6663 deletion completed in 6.193023653s

• [SLOW TEST:6.352 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 17:30:38.077: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-40
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 17:30:44.279: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-40" for this suite.
Oct 28 17:31:24.304: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 17:31:24.455: INFO: namespace kubelet-test-40 deletion completed in 40.169805114s

• [SLOW TEST:46.378 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when scheduling a read only busybox container
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:187
    should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 17:31:24.456: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-7701
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap configmap-7701/configmap-test-37451c1c-3784-4d51-83d2-4fac5ccda537
STEP: Creating a pod to test consume configMaps
Oct 28 17:31:24.623: INFO: Waiting up to 5m0s for pod "pod-configmaps-d5a576fe-9115-4a2a-b56e-0918115c560a" in namespace "configmap-7701" to be "success or failure"
Oct 28 17:31:24.644: INFO: Pod "pod-configmaps-d5a576fe-9115-4a2a-b56e-0918115c560a": Phase="Pending", Reason="", readiness=false. Elapsed: 20.231253ms
Oct 28 17:31:26.648: INFO: Pod "pod-configmaps-d5a576fe-9115-4a2a-b56e-0918115c560a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024969279s
Oct 28 17:31:28.653: INFO: Pod "pod-configmaps-d5a576fe-9115-4a2a-b56e-0918115c560a": Phase="Pending", Reason="", readiness=false. Elapsed: 4.029743775s
Oct 28 17:31:30.658: INFO: Pod "pod-configmaps-d5a576fe-9115-4a2a-b56e-0918115c560a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.034605941s
STEP: Saw pod success
Oct 28 17:31:30.658: INFO: Pod "pod-configmaps-d5a576fe-9115-4a2a-b56e-0918115c560a" satisfied condition "success or failure"
Oct 28 17:31:30.661: INFO: Trying to get logs from node kh4ga-worker-000000 pod pod-configmaps-d5a576fe-9115-4a2a-b56e-0918115c560a container env-test: <nil>
STEP: delete the pod
Oct 28 17:31:30.693: INFO: Waiting for pod pod-configmaps-d5a576fe-9115-4a2a-b56e-0918115c560a to disappear
Oct 28 17:31:30.696: INFO: Pod pod-configmaps-d5a576fe-9115-4a2a-b56e-0918115c560a no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 17:31:30.696: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7701" for this suite.
Oct 28 17:31:36.730: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 17:31:36.886: INFO: namespace configmap-7701 deletion completed in 6.183293573s

• [SLOW TEST:12.430 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 17:31:36.887: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-1417
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
Oct 28 17:31:47.184: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W1028 17:31:47.184439      19 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 17:31:47.184: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-1417" for this suite.
Oct 28 17:31:53.203: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 17:31:53.387: INFO: namespace gc-1417 deletion completed in 6.198215427s

• [SLOW TEST:16.500 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 17:31:53.387: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-1574
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Oct 28 17:31:53.548: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a7bcb42f-7551-4d1b-bf55-ea135b8668a6" in namespace "downward-api-1574" to be "success or failure"
Oct 28 17:31:53.568: INFO: Pod "downwardapi-volume-a7bcb42f-7551-4d1b-bf55-ea135b8668a6": Phase="Pending", Reason="", readiness=false. Elapsed: 20.154548ms
Oct 28 17:31:55.573: INFO: Pod "downwardapi-volume-a7bcb42f-7551-4d1b-bf55-ea135b8668a6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025054144s
Oct 28 17:31:57.578: INFO: Pod "downwardapi-volume-a7bcb42f-7551-4d1b-bf55-ea135b8668a6": Phase="Pending", Reason="", readiness=false. Elapsed: 4.030090012s
Oct 28 17:31:59.584: INFO: Pod "downwardapi-volume-a7bcb42f-7551-4d1b-bf55-ea135b8668a6": Phase="Pending", Reason="", readiness=false. Elapsed: 6.035949157s
Oct 28 17:32:01.589: INFO: Pod "downwardapi-volume-a7bcb42f-7551-4d1b-bf55-ea135b8668a6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.040616665s
STEP: Saw pod success
Oct 28 17:32:01.589: INFO: Pod "downwardapi-volume-a7bcb42f-7551-4d1b-bf55-ea135b8668a6" satisfied condition "success or failure"
Oct 28 17:32:01.592: INFO: Trying to get logs from node kh4ga-worker-000003 pod downwardapi-volume-a7bcb42f-7551-4d1b-bf55-ea135b8668a6 container client-container: <nil>
STEP: delete the pod
Oct 28 17:32:01.625: INFO: Waiting for pod downwardapi-volume-a7bcb42f-7551-4d1b-bf55-ea135b8668a6 to disappear
Oct 28 17:32:01.628: INFO: Pod downwardapi-volume-a7bcb42f-7551-4d1b-bf55-ea135b8668a6 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 17:32:01.628: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1574" for this suite.
Oct 28 17:32:07.648: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 17:32:07.831: INFO: namespace downward-api-1574 deletion completed in 6.197063875s

• [SLOW TEST:14.444 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 17:32:07.832: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-2260
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating service multi-endpoint-test in namespace services-2260
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-2260 to expose endpoints map[]
Oct 28 17:32:08.033: INFO: Get endpoints failed (4.904935ms elapsed, ignoring for 5s): endpoints "multi-endpoint-test" not found
Oct 28 17:32:09.038: INFO: successfully validated that service multi-endpoint-test in namespace services-2260 exposes endpoints map[] (1.009516099s elapsed)
STEP: Creating pod pod1 in namespace services-2260
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-2260 to expose endpoints map[pod1:[100]]
Oct 28 17:32:13.122: INFO: Unexpected endpoints: found map[], expected map[pod1:[100]] (4.074095685s elapsed, will retry)
Oct 28 17:32:17.157: INFO: successfully validated that service multi-endpoint-test in namespace services-2260 exposes endpoints map[pod1:[100]] (8.109277575s elapsed)
STEP: Creating pod pod2 in namespace services-2260
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-2260 to expose endpoints map[pod1:[100] pod2:[101]]
Oct 28 17:32:21.241: INFO: Unexpected endpoints: found map[00733ad0-5d32-42e9-9e2d-44c372efbadd:[100]], expected map[pod1:[100] pod2:[101]] (4.079173892s elapsed, will retry)
Oct 28 17:32:23.266: INFO: successfully validated that service multi-endpoint-test in namespace services-2260 exposes endpoints map[pod1:[100] pod2:[101]] (6.103772038s elapsed)
STEP: Deleting pod pod1 in namespace services-2260
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-2260 to expose endpoints map[pod2:[101]]
Oct 28 17:32:23.302: INFO: successfully validated that service multi-endpoint-test in namespace services-2260 exposes endpoints map[pod2:[101]] (27.380395ms elapsed)
STEP: Deleting pod pod2 in namespace services-2260
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-2260 to expose endpoints map[]
Oct 28 17:32:24.337: INFO: successfully validated that service multi-endpoint-test in namespace services-2260 exposes endpoints map[] (1.018504756s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 17:32:24.356: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-2260" for this suite.
Oct 28 17:32:46.385: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 17:32:46.540: INFO: namespace services-2260 deletion completed in 22.170170918s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:92

• [SLOW TEST:38.708 seconds]
[sig-network] Services
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 17:32:46.541: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-6869
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Oct 28 17:32:46.725: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Oct 28 17:32:46.740: INFO: DaemonSet pods can't tolerate node kh4ga-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 28 17:32:46.743: INFO: Number of nodes with available pods: 0
Oct 28 17:32:46.743: INFO: Node kh4ga-worker-000000 is running more than one daemon pod
Oct 28 17:32:47.751: INFO: DaemonSet pods can't tolerate node kh4ga-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 28 17:32:47.755: INFO: Number of nodes with available pods: 0
Oct 28 17:32:47.755: INFO: Node kh4ga-worker-000000 is running more than one daemon pod
Oct 28 17:32:48.757: INFO: DaemonSet pods can't tolerate node kh4ga-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 28 17:32:48.764: INFO: Number of nodes with available pods: 0
Oct 28 17:32:48.764: INFO: Node kh4ga-worker-000000 is running more than one daemon pod
Oct 28 17:32:49.750: INFO: DaemonSet pods can't tolerate node kh4ga-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 28 17:32:49.754: INFO: Number of nodes with available pods: 0
Oct 28 17:32:49.754: INFO: Node kh4ga-worker-000000 is running more than one daemon pod
Oct 28 17:32:50.751: INFO: DaemonSet pods can't tolerate node kh4ga-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 28 17:32:50.756: INFO: Number of nodes with available pods: 0
Oct 28 17:32:50.756: INFO: Node kh4ga-worker-000000 is running more than one daemon pod
Oct 28 17:32:51.750: INFO: DaemonSet pods can't tolerate node kh4ga-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 28 17:32:51.774: INFO: Number of nodes with available pods: 3
Oct 28 17:32:51.774: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Oct 28 17:32:51.808: INFO: Wrong image for pod: daemon-set-4p96b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 28 17:32:51.808: INFO: Wrong image for pod: daemon-set-8wvpl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 28 17:32:51.808: INFO: Wrong image for pod: daemon-set-s8jc7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 28 17:32:51.818: INFO: DaemonSet pods can't tolerate node kh4ga-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 28 17:32:52.823: INFO: Wrong image for pod: daemon-set-4p96b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 28 17:32:52.823: INFO: Wrong image for pod: daemon-set-8wvpl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 28 17:32:52.823: INFO: Wrong image for pod: daemon-set-s8jc7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 28 17:32:52.829: INFO: DaemonSet pods can't tolerate node kh4ga-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 28 17:32:53.823: INFO: Wrong image for pod: daemon-set-4p96b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 28 17:32:53.823: INFO: Wrong image for pod: daemon-set-8wvpl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 28 17:32:53.823: INFO: Wrong image for pod: daemon-set-s8jc7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 28 17:32:53.829: INFO: DaemonSet pods can't tolerate node kh4ga-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 28 17:32:54.823: INFO: Wrong image for pod: daemon-set-4p96b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 28 17:32:54.823: INFO: Wrong image for pod: daemon-set-8wvpl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 28 17:32:54.823: INFO: Wrong image for pod: daemon-set-s8jc7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 28 17:32:54.839: INFO: DaemonSet pods can't tolerate node kh4ga-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 28 17:32:55.824: INFO: Wrong image for pod: daemon-set-4p96b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 28 17:32:55.824: INFO: Wrong image for pod: daemon-set-8wvpl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 28 17:32:55.824: INFO: Wrong image for pod: daemon-set-s8jc7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 28 17:32:55.831: INFO: DaemonSet pods can't tolerate node kh4ga-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 28 17:32:56.824: INFO: Wrong image for pod: daemon-set-4p96b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 28 17:32:56.824: INFO: Wrong image for pod: daemon-set-8wvpl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 28 17:32:56.824: INFO: Wrong image for pod: daemon-set-s8jc7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 28 17:32:56.824: INFO: Pod daemon-set-s8jc7 is not available
Oct 28 17:32:56.830: INFO: DaemonSet pods can't tolerate node kh4ga-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 28 17:32:57.823: INFO: Wrong image for pod: daemon-set-4p96b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 28 17:32:57.823: INFO: Wrong image for pod: daemon-set-8wvpl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 28 17:32:57.823: INFO: Wrong image for pod: daemon-set-s8jc7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 28 17:32:57.823: INFO: Pod daemon-set-s8jc7 is not available
Oct 28 17:32:57.829: INFO: DaemonSet pods can't tolerate node kh4ga-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 28 17:32:58.826: INFO: Wrong image for pod: daemon-set-4p96b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 28 17:32:58.826: INFO: Wrong image for pod: daemon-set-8wvpl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 28 17:32:58.826: INFO: Wrong image for pod: daemon-set-s8jc7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 28 17:32:58.826: INFO: Pod daemon-set-s8jc7 is not available
Oct 28 17:32:58.833: INFO: DaemonSet pods can't tolerate node kh4ga-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 28 17:32:59.826: INFO: Wrong image for pod: daemon-set-4p96b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 28 17:32:59.826: INFO: Wrong image for pod: daemon-set-8wvpl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 28 17:32:59.826: INFO: Wrong image for pod: daemon-set-s8jc7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 28 17:32:59.826: INFO: Pod daemon-set-s8jc7 is not available
Oct 28 17:32:59.832: INFO: DaemonSet pods can't tolerate node kh4ga-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 28 17:33:00.823: INFO: Wrong image for pod: daemon-set-4p96b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 28 17:33:00.823: INFO: Wrong image for pod: daemon-set-8wvpl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 28 17:33:00.823: INFO: Wrong image for pod: daemon-set-s8jc7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 28 17:33:00.823: INFO: Pod daemon-set-s8jc7 is not available
Oct 28 17:33:00.829: INFO: DaemonSet pods can't tolerate node kh4ga-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 28 17:33:01.824: INFO: Wrong image for pod: daemon-set-4p96b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 28 17:33:01.824: INFO: Wrong image for pod: daemon-set-8wvpl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 28 17:33:01.824: INFO: Wrong image for pod: daemon-set-s8jc7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 28 17:33:01.824: INFO: Pod daemon-set-s8jc7 is not available
Oct 28 17:33:01.830: INFO: DaemonSet pods can't tolerate node kh4ga-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 28 17:33:02.824: INFO: Wrong image for pod: daemon-set-4p96b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 28 17:33:02.824: INFO: Wrong image for pod: daemon-set-8wvpl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 28 17:33:02.824: INFO: Wrong image for pod: daemon-set-s8jc7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 28 17:33:02.824: INFO: Pod daemon-set-s8jc7 is not available
Oct 28 17:33:02.830: INFO: DaemonSet pods can't tolerate node kh4ga-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 28 17:33:03.824: INFO: Wrong image for pod: daemon-set-4p96b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 28 17:33:03.824: INFO: Wrong image for pod: daemon-set-8wvpl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 28 17:33:03.824: INFO: Wrong image for pod: daemon-set-s8jc7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 28 17:33:03.824: INFO: Pod daemon-set-s8jc7 is not available
Oct 28 17:33:03.831: INFO: DaemonSet pods can't tolerate node kh4ga-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 28 17:33:04.823: INFO: Wrong image for pod: daemon-set-4p96b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 28 17:33:04.823: INFO: Wrong image for pod: daemon-set-8wvpl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 28 17:33:04.823: INFO: Wrong image for pod: daemon-set-s8jc7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 28 17:33:04.823: INFO: Pod daemon-set-s8jc7 is not available
Oct 28 17:33:04.828: INFO: DaemonSet pods can't tolerate node kh4ga-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 28 17:33:05.823: INFO: Wrong image for pod: daemon-set-4p96b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 28 17:33:05.823: INFO: Wrong image for pod: daemon-set-8wvpl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 28 17:33:05.823: INFO: Wrong image for pod: daemon-set-s8jc7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 28 17:33:05.823: INFO: Pod daemon-set-s8jc7 is not available
Oct 28 17:33:05.829: INFO: DaemonSet pods can't tolerate node kh4ga-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 28 17:33:06.823: INFO: Wrong image for pod: daemon-set-4p96b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 28 17:33:06.823: INFO: Wrong image for pod: daemon-set-8wvpl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 28 17:33:06.823: INFO: Wrong image for pod: daemon-set-s8jc7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 28 17:33:06.823: INFO: Pod daemon-set-s8jc7 is not available
Oct 28 17:33:06.829: INFO: DaemonSet pods can't tolerate node kh4ga-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 28 17:33:07.823: INFO: Wrong image for pod: daemon-set-4p96b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 28 17:33:07.823: INFO: Wrong image for pod: daemon-set-8wvpl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 28 17:33:07.823: INFO: Pod daemon-set-x2cgg is not available
Oct 28 17:33:07.833: INFO: DaemonSet pods can't tolerate node kh4ga-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 28 17:33:08.825: INFO: Wrong image for pod: daemon-set-4p96b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 28 17:33:08.825: INFO: Wrong image for pod: daemon-set-8wvpl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 28 17:33:08.825: INFO: Pod daemon-set-x2cgg is not available
Oct 28 17:33:08.844: INFO: DaemonSet pods can't tolerate node kh4ga-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 28 17:33:09.824: INFO: Wrong image for pod: daemon-set-4p96b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 28 17:33:09.824: INFO: Wrong image for pod: daemon-set-8wvpl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 28 17:33:09.824: INFO: Pod daemon-set-x2cgg is not available
Oct 28 17:33:09.829: INFO: DaemonSet pods can't tolerate node kh4ga-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 28 17:33:10.828: INFO: Wrong image for pod: daemon-set-4p96b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 28 17:33:10.828: INFO: Wrong image for pod: daemon-set-8wvpl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 28 17:33:10.828: INFO: Pod daemon-set-x2cgg is not available
Oct 28 17:33:10.835: INFO: DaemonSet pods can't tolerate node kh4ga-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 28 17:33:11.823: INFO: Wrong image for pod: daemon-set-4p96b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 28 17:33:11.823: INFO: Wrong image for pod: daemon-set-8wvpl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 28 17:33:11.823: INFO: Pod daemon-set-x2cgg is not available
Oct 28 17:33:11.829: INFO: DaemonSet pods can't tolerate node kh4ga-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 28 17:33:12.823: INFO: Wrong image for pod: daemon-set-4p96b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 28 17:33:12.823: INFO: Wrong image for pod: daemon-set-8wvpl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 28 17:33:12.823: INFO: Pod daemon-set-x2cgg is not available
Oct 28 17:33:12.829: INFO: DaemonSet pods can't tolerate node kh4ga-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 28 17:33:13.823: INFO: Wrong image for pod: daemon-set-4p96b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 28 17:33:13.824: INFO: Wrong image for pod: daemon-set-8wvpl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 28 17:33:13.830: INFO: DaemonSet pods can't tolerate node kh4ga-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 28 17:33:14.823: INFO: Wrong image for pod: daemon-set-4p96b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 28 17:33:14.823: INFO: Wrong image for pod: daemon-set-8wvpl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 28 17:33:14.829: INFO: DaemonSet pods can't tolerate node kh4ga-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 28 17:33:15.835: INFO: Wrong image for pod: daemon-set-4p96b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 28 17:33:15.835: INFO: Wrong image for pod: daemon-set-8wvpl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 28 17:33:15.843: INFO: DaemonSet pods can't tolerate node kh4ga-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 28 17:33:16.824: INFO: Wrong image for pod: daemon-set-4p96b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 28 17:33:16.824: INFO: Pod daemon-set-4p96b is not available
Oct 28 17:33:16.824: INFO: Wrong image for pod: daemon-set-8wvpl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 28 17:33:16.832: INFO: DaemonSet pods can't tolerate node kh4ga-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 28 17:33:17.824: INFO: Wrong image for pod: daemon-set-8wvpl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 28 17:33:17.824: INFO: Pod daemon-set-j9dfv is not available
Oct 28 17:33:17.830: INFO: DaemonSet pods can't tolerate node kh4ga-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 28 17:33:18.825: INFO: Wrong image for pod: daemon-set-8wvpl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 28 17:33:18.825: INFO: Pod daemon-set-j9dfv is not available
Oct 28 17:33:18.833: INFO: DaemonSet pods can't tolerate node kh4ga-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 28 17:33:19.823: INFO: Wrong image for pod: daemon-set-8wvpl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 28 17:33:19.823: INFO: Pod daemon-set-j9dfv is not available
Oct 28 17:33:19.829: INFO: DaemonSet pods can't tolerate node kh4ga-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 28 17:33:20.823: INFO: Wrong image for pod: daemon-set-8wvpl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 28 17:33:20.823: INFO: Pod daemon-set-j9dfv is not available
Oct 28 17:33:20.829: INFO: DaemonSet pods can't tolerate node kh4ga-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 28 17:33:21.823: INFO: Wrong image for pod: daemon-set-8wvpl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 28 17:33:21.841: INFO: DaemonSet pods can't tolerate node kh4ga-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 28 17:33:22.823: INFO: Wrong image for pod: daemon-set-8wvpl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 28 17:33:22.829: INFO: DaemonSet pods can't tolerate node kh4ga-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 28 17:33:23.824: INFO: Wrong image for pod: daemon-set-8wvpl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 28 17:33:23.824: INFO: Pod daemon-set-8wvpl is not available
Oct 28 17:33:23.830: INFO: DaemonSet pods can't tolerate node kh4ga-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 28 17:33:24.823: INFO: Wrong image for pod: daemon-set-8wvpl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 28 17:33:24.823: INFO: Pod daemon-set-8wvpl is not available
Oct 28 17:33:24.829: INFO: DaemonSet pods can't tolerate node kh4ga-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 28 17:33:25.824: INFO: Wrong image for pod: daemon-set-8wvpl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 28 17:33:25.824: INFO: Pod daemon-set-8wvpl is not available
Oct 28 17:33:25.830: INFO: DaemonSet pods can't tolerate node kh4ga-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 28 17:33:26.826: INFO: Pod daemon-set-jg52w is not available
Oct 28 17:33:26.832: INFO: DaemonSet pods can't tolerate node kh4ga-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
STEP: Check that daemon pods are still running on every node of the cluster.
Oct 28 17:33:26.837: INFO: DaemonSet pods can't tolerate node kh4ga-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 28 17:33:26.840: INFO: Number of nodes with available pods: 2
Oct 28 17:33:26.840: INFO: Node kh4ga-worker-000003 is running more than one daemon pod
Oct 28 17:33:27.852: INFO: DaemonSet pods can't tolerate node kh4ga-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 28 17:33:27.857: INFO: Number of nodes with available pods: 2
Oct 28 17:33:27.857: INFO: Node kh4ga-worker-000003 is running more than one daemon pod
Oct 28 17:33:28.852: INFO: DaemonSet pods can't tolerate node kh4ga-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 28 17:33:28.857: INFO: Number of nodes with available pods: 2
Oct 28 17:33:28.857: INFO: Node kh4ga-worker-000003 is running more than one daemon pod
Oct 28 17:33:29.847: INFO: DaemonSet pods can't tolerate node kh4ga-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 28 17:33:29.851: INFO: Number of nodes with available pods: 2
Oct 28 17:33:29.851: INFO: Node kh4ga-worker-000003 is running more than one daemon pod
Oct 28 17:33:30.852: INFO: DaemonSet pods can't tolerate node kh4ga-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 28 17:33:30.856: INFO: Number of nodes with available pods: 3
Oct 28 17:33:30.856: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-6869, will wait for the garbage collector to delete the pods
Oct 28 17:33:30.959: INFO: Deleting DaemonSet.extensions daemon-set took: 8.167655ms
Oct 28 17:33:31.059: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.298771ms
Oct 28 17:33:46.412: INFO: Number of nodes with available pods: 0
Oct 28 17:33:46.412: INFO: Number of running nodes: 0, number of available pods: 0
Oct 28 17:33:46.416: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-6869/daemonsets","resourceVersion":"15495"},"items":null}

Oct 28 17:33:46.419: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-6869/pods","resourceVersion":"15495"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 17:33:46.437: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-6869" for this suite.
Oct 28 17:33:52.458: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 17:33:52.613: INFO: namespace daemonsets-6869 deletion completed in 6.171445044s

• [SLOW TEST:66.073 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 17:33:52.614: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-5386
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating replication controller my-hostname-basic-34d416dd-e47c-4204-9e6b-e2e47229bc31
Oct 28 17:33:52.785: INFO: Pod name my-hostname-basic-34d416dd-e47c-4204-9e6b-e2e47229bc31: Found 0 pods out of 1
Oct 28 17:33:57.791: INFO: Pod name my-hostname-basic-34d416dd-e47c-4204-9e6b-e2e47229bc31: Found 1 pods out of 1
Oct 28 17:33:57.791: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-34d416dd-e47c-4204-9e6b-e2e47229bc31" are running
Oct 28 17:33:59.805: INFO: Pod "my-hostname-basic-34d416dd-e47c-4204-9e6b-e2e47229bc31-9dnkv" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-10-28 17:33:52 +0000 UTC Reason: Message:} {Type:Ready Status:False LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-10-28 17:33:52 +0000 UTC Reason:ContainersNotReady Message:containers with unready status: [my-hostname-basic-34d416dd-e47c-4204-9e6b-e2e47229bc31]} {Type:ContainersReady Status:False LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-10-28 17:33:52 +0000 UTC Reason:ContainersNotReady Message:containers with unready status: [my-hostname-basic-34d416dd-e47c-4204-9e6b-e2e47229bc31]} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-10-28 17:33:52 +0000 UTC Reason: Message:}])
Oct 28 17:33:59.805: INFO: Trying to dial the pod
Oct 28 17:34:04.836: INFO: Controller my-hostname-basic-34d416dd-e47c-4204-9e6b-e2e47229bc31: Got expected result from replica 1 [my-hostname-basic-34d416dd-e47c-4204-9e6b-e2e47229bc31-9dnkv]: "my-hostname-basic-34d416dd-e47c-4204-9e6b-e2e47229bc31-9dnkv", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 17:34:04.836: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-5386" for this suite.
Oct 28 17:34:10.861: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 17:34:11.024: INFO: namespace replication-controller-5386 deletion completed in 6.182067769s

• [SLOW TEST:18.410 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 17:34:11.024: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-3180
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-map-21c93b8d-0aae-4066-9f3c-91e2380b55df
STEP: Creating a pod to test consume secrets
Oct 28 17:34:11.199: INFO: Waiting up to 5m0s for pod "pod-secrets-61854517-ef40-4a1f-8d37-a95af0a80050" in namespace "secrets-3180" to be "success or failure"
Oct 28 17:34:11.203: INFO: Pod "pod-secrets-61854517-ef40-4a1f-8d37-a95af0a80050": Phase="Pending", Reason="", readiness=false. Elapsed: 4.294328ms
Oct 28 17:34:13.209: INFO: Pod "pod-secrets-61854517-ef40-4a1f-8d37-a95af0a80050": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010402483s
Oct 28 17:34:15.214: INFO: Pod "pod-secrets-61854517-ef40-4a1f-8d37-a95af0a80050": Phase="Pending", Reason="", readiness=false. Elapsed: 4.015018506s
Oct 28 17:34:17.218: INFO: Pod "pod-secrets-61854517-ef40-4a1f-8d37-a95af0a80050": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.019820408s
STEP: Saw pod success
Oct 28 17:34:17.219: INFO: Pod "pod-secrets-61854517-ef40-4a1f-8d37-a95af0a80050" satisfied condition "success or failure"
Oct 28 17:34:17.226: INFO: Trying to get logs from node kh4ga-worker-000003 pod pod-secrets-61854517-ef40-4a1f-8d37-a95af0a80050 container secret-volume-test: <nil>
STEP: delete the pod
Oct 28 17:34:17.252: INFO: Waiting for pod pod-secrets-61854517-ef40-4a1f-8d37-a95af0a80050 to disappear
Oct 28 17:34:17.275: INFO: Pod pod-secrets-61854517-ef40-4a1f-8d37-a95af0a80050 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 17:34:17.275: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3180" for this suite.
Oct 28 17:34:23.310: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 17:34:23.461: INFO: namespace secrets-3180 deletion completed in 6.17970413s

• [SLOW TEST:12.437 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 17:34:23.462: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5294
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-60b9c7e1-b40b-4e20-ad3e-201d8f9dc44e
STEP: Creating a pod to test consume configMaps
Oct 28 17:34:23.632: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-5d17f34c-050f-4e6c-8e94-25288a222760" in namespace "projected-5294" to be "success or failure"
Oct 28 17:34:23.636: INFO: Pod "pod-projected-configmaps-5d17f34c-050f-4e6c-8e94-25288a222760": Phase="Pending", Reason="", readiness=false. Elapsed: 3.744624ms
Oct 28 17:34:25.648: INFO: Pod "pod-projected-configmaps-5d17f34c-050f-4e6c-8e94-25288a222760": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016327584s
Oct 28 17:34:27.652: INFO: Pod "pod-projected-configmaps-5d17f34c-050f-4e6c-8e94-25288a222760": Phase="Pending", Reason="", readiness=false. Elapsed: 4.020326367s
Oct 28 17:34:29.657: INFO: Pod "pod-projected-configmaps-5d17f34c-050f-4e6c-8e94-25288a222760": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.025364436s
STEP: Saw pod success
Oct 28 17:34:29.657: INFO: Pod "pod-projected-configmaps-5d17f34c-050f-4e6c-8e94-25288a222760" satisfied condition "success or failure"
Oct 28 17:34:29.661: INFO: Trying to get logs from node kh4ga-worker-000003 pod pod-projected-configmaps-5d17f34c-050f-4e6c-8e94-25288a222760 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Oct 28 17:34:29.692: INFO: Waiting for pod pod-projected-configmaps-5d17f34c-050f-4e6c-8e94-25288a222760 to disappear
Oct 28 17:34:29.695: INFO: Pod pod-projected-configmaps-5d17f34c-050f-4e6c-8e94-25288a222760 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 17:34:29.695: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5294" for this suite.
Oct 28 17:34:35.715: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 17:34:35.865: INFO: namespace projected-5294 deletion completed in 6.16432162s

• [SLOW TEST:12.404 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 17:34:35.866: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-1431
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
Oct 28 17:34:36.032: INFO: PodSpec: initContainers in spec.initContainers
Oct 28 17:35:33.247: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-e2b2a802-530c-4a4d-92ea-dbc4050cbe05", GenerateName:"", Namespace:"init-container-1431", SelfLink:"/api/v1/namespaces/init-container-1431/pods/pod-init-e2b2a802-530c-4a4d-92ea-dbc4050cbe05", UID:"a512350a-4344-42b3-b88b-fa505d2d2766", ResourceVersion:"15844", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63707880876, loc:(*time.Location)(0x7ed0a20)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"32714285"}, Annotations:map[string]string{"cni.projectcalico.org/podIP":"10.2.131.113/32", "kubernetes.io/psp":"cert-exporter-psp"}, OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-k9xxq", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc00240b000), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-k9xxq", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-k9xxq", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-k9xxq", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc001d56098), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"kh4ga-worker-000003", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc002c44000), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc001d56110)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc001d56140)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc001d56148), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc001d5614c), PreemptionPolicy:(*v1.PreemptionPolicy)(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707880876, loc:(*time.Location)(0x7ed0a20)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707880876, loc:(*time.Location)(0x7ed0a20)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707880876, loc:(*time.Location)(0x7ed0a20)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707880876, loc:(*time.Location)(0x7ed0a20)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.2.1.7", PodIP:"10.2.131.113", StartTime:(*v1.Time)(0xc0030b8220), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc00235cee0)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc00235cf50)}, Ready:false, RestartCount:3, Image:"busybox:1.29", ImageID:"docker-pullable://busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"docker://f047eb5bd7d8bcc6b9d0c923eea013ab3fb5dbe4a02e17188f817f50a0c8bc11"}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0030b8360), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:""}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0030b82c0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:""}}, QOSClass:"Guaranteed"}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 17:35:33.247: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-1431" for this suite.
Oct 28 17:35:55.272: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 17:35:55.439: INFO: namespace init-container-1431 deletion completed in 22.182621617s

• [SLOW TEST:79.574 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 17:35:55.440: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9750
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-9b1a335b-df1c-401f-9fbe-f46d61f54c41
STEP: Creating a pod to test consume secrets
Oct 28 17:35:55.608: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-f232dba8-0a5f-448c-8d0c-861ce12c9e47" in namespace "projected-9750" to be "success or failure"
Oct 28 17:35:55.613: INFO: Pod "pod-projected-secrets-f232dba8-0a5f-448c-8d0c-861ce12c9e47": Phase="Pending", Reason="", readiness=false. Elapsed: 4.861929ms
Oct 28 17:35:57.617: INFO: Pod "pod-projected-secrets-f232dba8-0a5f-448c-8d0c-861ce12c9e47": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009193826s
Oct 28 17:35:59.622: INFO: Pod "pod-projected-secrets-f232dba8-0a5f-448c-8d0c-861ce12c9e47": Phase="Pending", Reason="", readiness=false. Elapsed: 4.013706207s
Oct 28 17:36:01.627: INFO: Pod "pod-projected-secrets-f232dba8-0a5f-448c-8d0c-861ce12c9e47": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.018821373s
STEP: Saw pod success
Oct 28 17:36:01.627: INFO: Pod "pod-projected-secrets-f232dba8-0a5f-448c-8d0c-861ce12c9e47" satisfied condition "success or failure"
Oct 28 17:36:01.630: INFO: Trying to get logs from node kh4ga-worker-000000 pod pod-projected-secrets-f232dba8-0a5f-448c-8d0c-861ce12c9e47 container projected-secret-volume-test: <nil>
STEP: delete the pod
Oct 28 17:36:01.651: INFO: Waiting for pod pod-projected-secrets-f232dba8-0a5f-448c-8d0c-861ce12c9e47 to disappear
Oct 28 17:36:01.658: INFO: Pod pod-projected-secrets-f232dba8-0a5f-448c-8d0c-861ce12c9e47 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 17:36:01.658: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9750" for this suite.
Oct 28 17:36:07.685: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 17:36:07.874: INFO: namespace projected-9750 deletion completed in 6.209858635s

• [SLOW TEST:12.435 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 17:36:07.875: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-4294
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Oct 28 17:36:08.034: INFO: Waiting up to 5m0s for pod "downwardapi-volume-50933f11-3d4b-4bd7-897d-9f9f308d4478" in namespace "downward-api-4294" to be "success or failure"
Oct 28 17:36:08.042: INFO: Pod "downwardapi-volume-50933f11-3d4b-4bd7-897d-9f9f308d4478": Phase="Pending", Reason="", readiness=false. Elapsed: 8.070048ms
Oct 28 17:36:10.048: INFO: Pod "downwardapi-volume-50933f11-3d4b-4bd7-897d-9f9f308d4478": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013877943s
Oct 28 17:36:12.053: INFO: Pod "downwardapi-volume-50933f11-3d4b-4bd7-897d-9f9f308d4478": Phase="Pending", Reason="", readiness=false. Elapsed: 4.018201912s
Oct 28 17:36:14.057: INFO: Pod "downwardapi-volume-50933f11-3d4b-4bd7-897d-9f9f308d4478": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.022948266s
STEP: Saw pod success
Oct 28 17:36:14.057: INFO: Pod "downwardapi-volume-50933f11-3d4b-4bd7-897d-9f9f308d4478" satisfied condition "success or failure"
Oct 28 17:36:14.061: INFO: Trying to get logs from node kh4ga-worker-000003 pod downwardapi-volume-50933f11-3d4b-4bd7-897d-9f9f308d4478 container client-container: <nil>
STEP: delete the pod
Oct 28 17:36:14.091: INFO: Waiting for pod downwardapi-volume-50933f11-3d4b-4bd7-897d-9f9f308d4478 to disappear
Oct 28 17:36:14.094: INFO: Pod downwardapi-volume-50933f11-3d4b-4bd7-897d-9f9f308d4478 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 17:36:14.094: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4294" for this suite.
Oct 28 17:36:20.119: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 17:36:20.278: INFO: namespace downward-api-4294 deletion completed in 6.177101005s

• [SLOW TEST:12.404 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 17:36:20.278: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-8289
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir volume type on tmpfs
Oct 28 17:36:20.454: INFO: Waiting up to 5m0s for pod "pod-ca80e86d-71e6-4e19-ad57-2a498511407d" in namespace "emptydir-8289" to be "success or failure"
Oct 28 17:36:20.463: INFO: Pod "pod-ca80e86d-71e6-4e19-ad57-2a498511407d": Phase="Pending", Reason="", readiness=false. Elapsed: 8.968852ms
Oct 28 17:36:22.470: INFO: Pod "pod-ca80e86d-71e6-4e19-ad57-2a498511407d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015592944s
Oct 28 17:36:24.475: INFO: Pod "pod-ca80e86d-71e6-4e19-ad57-2a498511407d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.020646509s
Oct 28 17:36:26.479: INFO: Pod "pod-ca80e86d-71e6-4e19-ad57-2a498511407d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.025237155s
STEP: Saw pod success
Oct 28 17:36:26.479: INFO: Pod "pod-ca80e86d-71e6-4e19-ad57-2a498511407d" satisfied condition "success or failure"
Oct 28 17:36:26.487: INFO: Trying to get logs from node kh4ga-worker-000000 pod pod-ca80e86d-71e6-4e19-ad57-2a498511407d container test-container: <nil>
STEP: delete the pod
Oct 28 17:36:26.522: INFO: Waiting for pod pod-ca80e86d-71e6-4e19-ad57-2a498511407d to disappear
Oct 28 17:36:26.528: INFO: Pod pod-ca80e86d-71e6-4e19-ad57-2a498511407d no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 17:36:26.529: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8289" for this suite.
Oct 28 17:36:32.548: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 17:36:32.712: INFO: namespace emptydir-8289 deletion completed in 6.177790681s

• [SLOW TEST:12.434 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 17:36:32.713: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-wrapper-4251
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Oct 28 17:36:33.255: INFO: Pod name wrapped-volume-race-fdba98da-f19b-411b-8699-c3b084b50e53: Found 0 pods out of 5
Oct 28 17:36:38.263: INFO: Pod name wrapped-volume-race-fdba98da-f19b-411b-8699-c3b084b50e53: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-fdba98da-f19b-411b-8699-c3b084b50e53 in namespace emptydir-wrapper-4251, will wait for the garbage collector to delete the pods
Oct 28 17:36:56.357: INFO: Deleting ReplicationController wrapped-volume-race-fdba98da-f19b-411b-8699-c3b084b50e53 took: 8.078546ms
Oct 28 17:36:56.557: INFO: Terminating ReplicationController wrapped-volume-race-fdba98da-f19b-411b-8699-c3b084b50e53 pods took: 200.240738ms
STEP: Creating RC which spawns configmap-volume pods
Oct 28 17:37:41.982: INFO: Pod name wrapped-volume-race-2e2996e3-d25c-495a-8c8a-bb59afc14cf9: Found 0 pods out of 5
Oct 28 17:37:46.995: INFO: Pod name wrapped-volume-race-2e2996e3-d25c-495a-8c8a-bb59afc14cf9: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-2e2996e3-d25c-495a-8c8a-bb59afc14cf9 in namespace emptydir-wrapper-4251, will wait for the garbage collector to delete the pods
Oct 28 17:38:09.084: INFO: Deleting ReplicationController wrapped-volume-race-2e2996e3-d25c-495a-8c8a-bb59afc14cf9 took: 9.560251ms
Oct 28 17:38:09.184: INFO: Terminating ReplicationController wrapped-volume-race-2e2996e3-d25c-495a-8c8a-bb59afc14cf9 pods took: 100.198442ms
STEP: Creating RC which spawns configmap-volume pods
Oct 28 17:38:52.022: INFO: Pod name wrapped-volume-race-083786b9-92cb-4e70-8250-44eecb351f15: Found 0 pods out of 5
Oct 28 17:38:57.030: INFO: Pod name wrapped-volume-race-083786b9-92cb-4e70-8250-44eecb351f15: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-083786b9-92cb-4e70-8250-44eecb351f15 in namespace emptydir-wrapper-4251, will wait for the garbage collector to delete the pods
Oct 28 17:39:19.120: INFO: Deleting ReplicationController wrapped-volume-race-083786b9-92cb-4e70-8250-44eecb351f15 took: 8.648244ms
Oct 28 17:39:20.020: INFO: Terminating ReplicationController wrapped-volume-race-083786b9-92cb-4e70-8250-44eecb351f15 pods took: 900.352665ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 17:40:02.437: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-4251" for this suite.
Oct 28 17:40:10.465: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 17:40:10.623: INFO: namespace emptydir-wrapper-4251 deletion completed in 8.174995546s

• [SLOW TEST:217.910 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 17:40:10.623: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-5613
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: validating api versions
Oct 28 17:40:10.792: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-124947935 api-versions'
Oct 28 17:40:12.126: INFO: stderr: ""
Oct 28 17:40:12.126: INFO: stdout: "admissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napplication.giantswarm.io/v1alpha1\napps/v1\napps/v1beta1\napps/v1beta2\nauditregistration.k8s.io/v1alpha1\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\nbatch/v2alpha1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1\ncoordination.k8s.io/v1beta1\ncore.giantswarm.io/v1alpha1\ncrd.projectcalico.org/v1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nmetrics.k8s.io/v1beta1\nnetworking.k8s.io/v1\nnetworking.k8s.io/v1beta1\nnode.k8s.io/v1alpha1\nnode.k8s.io/v1beta1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1alpha1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1\nscheduling.k8s.io/v1alpha1\nscheduling.k8s.io/v1beta1\nsettings.k8s.io/v1alpha1\nstorage.k8s.io/v1\nstorage.k8s.io/v1alpha1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 17:40:12.126: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5613" for this suite.
Oct 28 17:40:18.150: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 17:40:18.317: INFO: namespace kubectl-5613 deletion completed in 6.18358145s

• [SLOW TEST:7.694 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl api-versions
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 17:40:18.317: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-7804
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Oct 28 17:40:18.507: INFO: DaemonSet pods can't tolerate node kh4ga-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 28 17:40:18.513: INFO: Number of nodes with available pods: 0
Oct 28 17:40:18.513: INFO: Node kh4ga-worker-000000 is running more than one daemon pod
Oct 28 17:40:19.521: INFO: DaemonSet pods can't tolerate node kh4ga-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 28 17:40:19.526: INFO: Number of nodes with available pods: 0
Oct 28 17:40:19.526: INFO: Node kh4ga-worker-000000 is running more than one daemon pod
Oct 28 17:40:20.520: INFO: DaemonSet pods can't tolerate node kh4ga-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 28 17:40:20.524: INFO: Number of nodes with available pods: 0
Oct 28 17:40:20.524: INFO: Node kh4ga-worker-000000 is running more than one daemon pod
Oct 28 17:40:21.520: INFO: DaemonSet pods can't tolerate node kh4ga-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 28 17:40:21.525: INFO: Number of nodes with available pods: 0
Oct 28 17:40:21.525: INFO: Node kh4ga-worker-000000 is running more than one daemon pod
Oct 28 17:40:22.520: INFO: DaemonSet pods can't tolerate node kh4ga-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 28 17:40:22.525: INFO: Number of nodes with available pods: 1
Oct 28 17:40:22.525: INFO: Node kh4ga-worker-000000 is running more than one daemon pod
Oct 28 17:40:23.520: INFO: DaemonSet pods can't tolerate node kh4ga-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 28 17:40:23.524: INFO: Number of nodes with available pods: 3
Oct 28 17:40:23.524: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Stop a daemon pod, check that the daemon pod is revived.
Oct 28 17:40:23.546: INFO: DaemonSet pods can't tolerate node kh4ga-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 28 17:40:23.550: INFO: Number of nodes with available pods: 2
Oct 28 17:40:23.550: INFO: Node kh4ga-worker-000000 is running more than one daemon pod
Oct 28 17:40:24.558: INFO: DaemonSet pods can't tolerate node kh4ga-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 28 17:40:24.562: INFO: Number of nodes with available pods: 2
Oct 28 17:40:24.562: INFO: Node kh4ga-worker-000000 is running more than one daemon pod
Oct 28 17:40:25.557: INFO: DaemonSet pods can't tolerate node kh4ga-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 28 17:40:25.561: INFO: Number of nodes with available pods: 2
Oct 28 17:40:25.561: INFO: Node kh4ga-worker-000000 is running more than one daemon pod
Oct 28 17:40:26.557: INFO: DaemonSet pods can't tolerate node kh4ga-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 28 17:40:26.561: INFO: Number of nodes with available pods: 2
Oct 28 17:40:26.561: INFO: Node kh4ga-worker-000000 is running more than one daemon pod
Oct 28 17:40:27.563: INFO: DaemonSet pods can't tolerate node kh4ga-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 28 17:40:27.574: INFO: Number of nodes with available pods: 2
Oct 28 17:40:27.574: INFO: Node kh4ga-worker-000000 is running more than one daemon pod
Oct 28 17:40:28.557: INFO: DaemonSet pods can't tolerate node kh4ga-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 28 17:40:28.561: INFO: Number of nodes with available pods: 2
Oct 28 17:40:28.561: INFO: Node kh4ga-worker-000000 is running more than one daemon pod
Oct 28 17:40:29.557: INFO: DaemonSet pods can't tolerate node kh4ga-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 28 17:40:29.561: INFO: Number of nodes with available pods: 2
Oct 28 17:40:29.561: INFO: Node kh4ga-worker-000000 is running more than one daemon pod
Oct 28 17:40:30.557: INFO: DaemonSet pods can't tolerate node kh4ga-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 28 17:40:30.564: INFO: Number of nodes with available pods: 2
Oct 28 17:40:30.564: INFO: Node kh4ga-worker-000000 is running more than one daemon pod
Oct 28 17:40:31.562: INFO: DaemonSet pods can't tolerate node kh4ga-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 28 17:40:31.565: INFO: Number of nodes with available pods: 2
Oct 28 17:40:31.565: INFO: Node kh4ga-worker-000000 is running more than one daemon pod
Oct 28 17:40:32.557: INFO: DaemonSet pods can't tolerate node kh4ga-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 28 17:40:32.561: INFO: Number of nodes with available pods: 2
Oct 28 17:40:32.561: INFO: Node kh4ga-worker-000000 is running more than one daemon pod
Oct 28 17:40:33.557: INFO: DaemonSet pods can't tolerate node kh4ga-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 28 17:40:33.563: INFO: Number of nodes with available pods: 2
Oct 28 17:40:33.563: INFO: Node kh4ga-worker-000000 is running more than one daemon pod
Oct 28 17:40:34.557: INFO: DaemonSet pods can't tolerate node kh4ga-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 28 17:40:34.562: INFO: Number of nodes with available pods: 2
Oct 28 17:40:34.562: INFO: Node kh4ga-worker-000000 is running more than one daemon pod
Oct 28 17:40:35.557: INFO: DaemonSet pods can't tolerate node kh4ga-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 28 17:40:35.561: INFO: Number of nodes with available pods: 3
Oct 28 17:40:35.561: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-7804, will wait for the garbage collector to delete the pods
Oct 28 17:40:35.627: INFO: Deleting DaemonSet.extensions daemon-set took: 7.530437ms
Oct 28 17:40:35.727: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.217198ms
Oct 28 17:40:46.432: INFO: Number of nodes with available pods: 0
Oct 28 17:40:46.432: INFO: Number of running nodes: 0, number of available pods: 0
Oct 28 17:40:46.435: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-7804/daemonsets","resourceVersion":"17430"},"items":null}

Oct 28 17:40:46.438: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-7804/pods","resourceVersion":"17430"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 17:40:46.454: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-7804" for this suite.
Oct 28 17:40:52.473: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 17:40:52.625: INFO: namespace daemonsets-7804 deletion completed in 6.167000411s

• [SLOW TEST:34.308 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 17:40:52.626: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-1670
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Oct 28 17:40:52.830: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-1670,SelfLink:/api/v1/namespaces/watch-1670/configmaps/e2e-watch-test-label-changed,UID:fd42e504-04d7-4e8b-8700-fa0ca132901b,ResourceVersion:17478,Generation:0,CreationTimestamp:2019-10-28 17:40:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Oct 28 17:40:52.830: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-1670,SelfLink:/api/v1/namespaces/watch-1670/configmaps/e2e-watch-test-label-changed,UID:fd42e504-04d7-4e8b-8700-fa0ca132901b,ResourceVersion:17479,Generation:0,CreationTimestamp:2019-10-28 17:40:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Oct 28 17:40:52.830: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-1670,SelfLink:/api/v1/namespaces/watch-1670/configmaps/e2e-watch-test-label-changed,UID:fd42e504-04d7-4e8b-8700-fa0ca132901b,ResourceVersion:17480,Generation:0,CreationTimestamp:2019-10-28 17:40:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Oct 28 17:41:02.865: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-1670,SelfLink:/api/v1/namespaces/watch-1670/configmaps/e2e-watch-test-label-changed,UID:fd42e504-04d7-4e8b-8700-fa0ca132901b,ResourceVersion:17500,Generation:0,CreationTimestamp:2019-10-28 17:40:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Oct 28 17:41:02.865: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-1670,SelfLink:/api/v1/namespaces/watch-1670/configmaps/e2e-watch-test-label-changed,UID:fd42e504-04d7-4e8b-8700-fa0ca132901b,ResourceVersion:17501,Generation:0,CreationTimestamp:2019-10-28 17:40:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Oct 28 17:41:02.865: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-1670,SelfLink:/api/v1/namespaces/watch-1670/configmaps/e2e-watch-test-label-changed,UID:fd42e504-04d7-4e8b-8700-fa0ca132901b,ResourceVersion:17502,Generation:0,CreationTimestamp:2019-10-28 17:40:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 17:41:02.865: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-1670" for this suite.
Oct 28 17:41:08.888: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 17:41:09.040: INFO: namespace watch-1670 deletion completed in 6.16749126s

• [SLOW TEST:16.415 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 17:41:09.041: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in namespaces-7056
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-1215
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-1921
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 17:41:15.539: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-7056" for this suite.
Oct 28 17:41:21.561: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 17:41:21.732: INFO: namespace namespaces-7056 deletion completed in 6.187399367s
STEP: Destroying namespace "nsdeletetest-1215" for this suite.
Oct 28 17:41:21.735: INFO: Namespace nsdeletetest-1215 was already deleted
STEP: Destroying namespace "nsdeletetest-1921" for this suite.
Oct 28 17:41:27.763: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 17:41:27.917: INFO: namespace nsdeletetest-1921 deletion completed in 6.181658048s

• [SLOW TEST:18.876 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 17:41:27.918: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-8093
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Oct 28 17:41:34.119: INFO: Expected: &{} to match Container's Termination Message:  --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 17:41:34.148: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-8093" for this suite.
Oct 28 17:41:40.169: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 17:41:40.325: INFO: namespace container-runtime-8093 deletion completed in 6.170984917s

• [SLOW TEST:12.407 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  blackbox test
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
    on terminated container
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:129
      should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 17:41:40.325: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-4319
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:179
[It] should be submitted and removed  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 17:41:40.502: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-4319" for this suite.
Oct 28 17:42:02.532: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 17:42:02.685: INFO: namespace pods-4319 deletion completed in 22.169073232s

• [SLOW TEST:22.360 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should be submitted and removed  [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 17:42:02.686: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-6036
STEP: Waiting for a default service account to be provisioned in namespace
[It] pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating Pod
STEP: Waiting for the pod running
STEP: Geting the pod
STEP: Reading file content from the nginx-container
Oct 28 17:42:08.884: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-124947935 exec pod-sharedvolume-ad29b9f3-8390-4ba3-af1e-b395950e0ebf -c busybox-main-container --namespace=emptydir-6036 -- cat /usr/share/volumeshare/shareddata.txt'
Oct 28 17:42:11.469: INFO: stderr: ""
Oct 28 17:42:11.469: INFO: stdout: "Hello from the busy-box sub-container\n"
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 17:42:11.469: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6036" for this suite.
Oct 28 17:42:17.503: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 17:42:17.710: INFO: namespace emptydir-6036 deletion completed in 6.231527989s

• [SLOW TEST:15.024 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 17:42:17.710: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-4267
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:63
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Oct 28 17:42:29.917: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Oct 28 17:42:29.922: INFO: Pod pod-with-prestop-http-hook still exists
Oct 28 17:42:31.922: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Oct 28 17:42:31.928: INFO: Pod pod-with-prestop-http-hook still exists
Oct 28 17:42:33.922: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Oct 28 17:42:33.926: INFO: Pod pod-with-prestop-http-hook still exists
Oct 28 17:42:35.922: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Oct 28 17:42:35.927: INFO: Pod pod-with-prestop-http-hook still exists
Oct 28 17:42:37.922: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Oct 28 17:42:37.927: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 17:42:37.936: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-4267" for this suite.
Oct 28 17:42:59.957: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 17:43:00.131: INFO: namespace container-lifecycle-hook-4267 deletion completed in 22.188332511s

• [SLOW TEST:42.421 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when create a pod with lifecycle hook
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 17:43:00.131: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-314
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 17:43:00.334: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-314" for this suite.
Oct 28 17:43:06.355: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 17:43:06.506: INFO: namespace services-314 deletion completed in 6.166824865s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:92

• [SLOW TEST:6.375 seconds]
[sig-network] Services
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide secure master service  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 17:43:06.507: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-6237
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating Redis RC
Oct 28 17:43:06.658: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-124947935 create -f - --namespace=kubectl-6237'
Oct 28 17:43:07.160: INFO: stderr: ""
Oct 28 17:43:07.160: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Oct 28 17:43:08.165: INFO: Selector matched 1 pods for map[app:redis]
Oct 28 17:43:08.165: INFO: Found 0 / 1
Oct 28 17:43:09.166: INFO: Selector matched 1 pods for map[app:redis]
Oct 28 17:43:09.166: INFO: Found 0 / 1
Oct 28 17:43:10.164: INFO: Selector matched 1 pods for map[app:redis]
Oct 28 17:43:10.164: INFO: Found 0 / 1
Oct 28 17:43:11.167: INFO: Selector matched 1 pods for map[app:redis]
Oct 28 17:43:11.167: INFO: Found 0 / 1
Oct 28 17:43:12.165: INFO: Selector matched 1 pods for map[app:redis]
Oct 28 17:43:12.165: INFO: Found 1 / 1
Oct 28 17:43:12.165: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Oct 28 17:43:12.169: INFO: Selector matched 1 pods for map[app:redis]
Oct 28 17:43:12.169: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Oct 28 17:43:12.169: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-124947935 patch pod redis-master-qqzj6 --namespace=kubectl-6237 -p {"metadata":{"annotations":{"x":"y"}}}'
Oct 28 17:43:12.252: INFO: stderr: ""
Oct 28 17:43:12.252: INFO: stdout: "pod/redis-master-qqzj6 patched\n"
STEP: checking annotations
Oct 28 17:43:12.258: INFO: Selector matched 1 pods for map[app:redis]
Oct 28 17:43:12.258: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 17:43:12.258: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6237" for this suite.
Oct 28 17:43:34.277: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 17:43:34.447: INFO: namespace kubectl-6237 deletion completed in 22.182859704s

• [SLOW TEST:27.940 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl patch
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 17:43:34.447: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-3367
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-3367
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace statefulset-3367
STEP: Creating statefulset with conflicting port in namespace statefulset-3367
STEP: Waiting until pod test-pod will start running in namespace statefulset-3367
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-3367
Oct 28 17:43:42.652: INFO: Observed stateful pod in namespace: statefulset-3367, name: ss-0, uid: 6fc33b2e-28af-463c-adea-02a704f13c37, status phase: Pending. Waiting for statefulset controller to delete.
Oct 28 17:43:42.832: INFO: Observed stateful pod in namespace: statefulset-3367, name: ss-0, uid: 6fc33b2e-28af-463c-adea-02a704f13c37, status phase: Failed. Waiting for statefulset controller to delete.
Oct 28 17:43:42.840: INFO: Observed stateful pod in namespace: statefulset-3367, name: ss-0, uid: 6fc33b2e-28af-463c-adea-02a704f13c37, status phase: Failed. Waiting for statefulset controller to delete.
Oct 28 17:43:42.845: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-3367
STEP: Removing pod with conflicting port in namespace statefulset-3367
STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-3367 and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Oct 28 17:43:50.941: INFO: Deleting all statefulset in ns statefulset-3367
Oct 28 17:43:50.945: INFO: Scaling statefulset ss to 0
Oct 28 17:44:00.964: INFO: Waiting for statefulset status.replicas updated to 0
Oct 28 17:44:00.967: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 17:44:00.994: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-3367" for this suite.
Oct 28 17:44:07.023: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 17:44:07.185: INFO: namespace statefulset-3367 deletion completed in 6.176508419s

• [SLOW TEST:32.738 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 17:44:07.186: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-4498
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name s-test-opt-del-23051e6f-6942-463e-892f-b051e053fb18
STEP: Creating secret with name s-test-opt-upd-1aa6dc22-f962-4418-a0dc-5b88d985a560
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-23051e6f-6942-463e-892f-b051e053fb18
STEP: Updating secret s-test-opt-upd-1aa6dc22-f962-4418-a0dc-5b88d985a560
STEP: Creating secret with name s-test-opt-create-93863202-6e46-40be-91ff-e163c37ab842
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 17:44:17.478: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4498" for this suite.
Oct 28 17:44:39.498: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 17:44:39.663: INFO: namespace projected-4498 deletion completed in 22.179329134s

• [SLOW TEST:32.477 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 17:44:39.663: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-2330
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-0d18d589-cd52-4e5b-891a-c5b7184887a5
STEP: Creating a pod to test consume secrets
Oct 28 17:44:39.823: INFO: Waiting up to 5m0s for pod "pod-secrets-ce602ee1-751e-47d4-9d0f-29e905cdcd8a" in namespace "secrets-2330" to be "success or failure"
Oct 28 17:44:39.827: INFO: Pod "pod-secrets-ce602ee1-751e-47d4-9d0f-29e905cdcd8a": Phase="Pending", Reason="", readiness=false. Elapsed: 4.203818ms
Oct 28 17:44:41.832: INFO: Pod "pod-secrets-ce602ee1-751e-47d4-9d0f-29e905cdcd8a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009387659s
Oct 28 17:44:43.837: INFO: Pod "pod-secrets-ce602ee1-751e-47d4-9d0f-29e905cdcd8a": Phase="Pending", Reason="", readiness=false. Elapsed: 4.013929989s
Oct 28 17:44:45.842: INFO: Pod "pod-secrets-ce602ee1-751e-47d4-9d0f-29e905cdcd8a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.019179417s
STEP: Saw pod success
Oct 28 17:44:45.842: INFO: Pod "pod-secrets-ce602ee1-751e-47d4-9d0f-29e905cdcd8a" satisfied condition "success or failure"
Oct 28 17:44:45.845: INFO: Trying to get logs from node kh4ga-worker-000000 pod pod-secrets-ce602ee1-751e-47d4-9d0f-29e905cdcd8a container secret-volume-test: <nil>
STEP: delete the pod
Oct 28 17:44:45.895: INFO: Waiting for pod pod-secrets-ce602ee1-751e-47d4-9d0f-29e905cdcd8a to disappear
Oct 28 17:44:45.899: INFO: Pod pod-secrets-ce602ee1-751e-47d4-9d0f-29e905cdcd8a no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 17:44:45.899: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-2330" for this suite.
Oct 28 17:44:51.918: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 17:44:52.091: INFO: namespace secrets-2330 deletion completed in 6.185784498s

• [SLOW TEST:12.427 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 17:44:52.091: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-6481
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test substitution in container's command
Oct 28 17:44:52.246: INFO: Waiting up to 5m0s for pod "var-expansion-0c6fc79d-b562-443d-9d99-9373c3d2a3f3" in namespace "var-expansion-6481" to be "success or failure"
Oct 28 17:44:52.271: INFO: Pod "var-expansion-0c6fc79d-b562-443d-9d99-9373c3d2a3f3": Phase="Pending", Reason="", readiness=false. Elapsed: 24.805211ms
Oct 28 17:44:54.275: INFO: Pod "var-expansion-0c6fc79d-b562-443d-9d99-9373c3d2a3f3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.029356108s
Oct 28 17:44:56.280: INFO: Pod "var-expansion-0c6fc79d-b562-443d-9d99-9373c3d2a3f3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.033652198s
Oct 28 17:44:58.284: INFO: Pod "var-expansion-0c6fc79d-b562-443d-9d99-9373c3d2a3f3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.037950682s
STEP: Saw pod success
Oct 28 17:44:58.284: INFO: Pod "var-expansion-0c6fc79d-b562-443d-9d99-9373c3d2a3f3" satisfied condition "success or failure"
Oct 28 17:44:58.287: INFO: Trying to get logs from node kh4ga-worker-000003 pod var-expansion-0c6fc79d-b562-443d-9d99-9373c3d2a3f3 container dapi-container: <nil>
STEP: delete the pod
Oct 28 17:44:58.309: INFO: Waiting for pod var-expansion-0c6fc79d-b562-443d-9d99-9373c3d2a3f3 to disappear
Oct 28 17:44:58.315: INFO: Pod var-expansion-0c6fc79d-b562-443d-9d99-9373c3d2a3f3 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 17:44:58.315: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-6481" for this suite.
Oct 28 17:45:04.340: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 17:45:04.507: INFO: namespace var-expansion-6481 deletion completed in 6.183177067s

• [SLOW TEST:12.416 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 17:45:04.508: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-3785
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-secret-87rl
STEP: Creating a pod to test atomic-volume-subpath
Oct 28 17:45:04.691: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-87rl" in namespace "subpath-3785" to be "success or failure"
Oct 28 17:45:04.699: INFO: Pod "pod-subpath-test-secret-87rl": Phase="Pending", Reason="", readiness=false. Elapsed: 8.154336ms
Oct 28 17:45:06.703: INFO: Pod "pod-subpath-test-secret-87rl": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012283993s
Oct 28 17:45:08.709: INFO: Pod "pod-subpath-test-secret-87rl": Phase="Pending", Reason="", readiness=false. Elapsed: 4.018425153s
Oct 28 17:45:10.714: INFO: Pod "pod-subpath-test-secret-87rl": Phase="Running", Reason="", readiness=true. Elapsed: 6.023357101s
Oct 28 17:45:12.719: INFO: Pod "pod-subpath-test-secret-87rl": Phase="Running", Reason="", readiness=true. Elapsed: 8.028153942s
Oct 28 17:45:14.724: INFO: Pod "pod-subpath-test-secret-87rl": Phase="Running", Reason="", readiness=true. Elapsed: 10.032961478s
Oct 28 17:45:16.728: INFO: Pod "pod-subpath-test-secret-87rl": Phase="Running", Reason="", readiness=true. Elapsed: 12.037369105s
Oct 28 17:45:18.733: INFO: Pod "pod-subpath-test-secret-87rl": Phase="Running", Reason="", readiness=true. Elapsed: 14.042832231s
Oct 28 17:45:20.740: INFO: Pod "pod-subpath-test-secret-87rl": Phase="Running", Reason="", readiness=true. Elapsed: 16.049443256s
Oct 28 17:45:22.745: INFO: Pod "pod-subpath-test-secret-87rl": Phase="Running", Reason="", readiness=true. Elapsed: 18.054342567s
Oct 28 17:45:24.750: INFO: Pod "pod-subpath-test-secret-87rl": Phase="Running", Reason="", readiness=true. Elapsed: 20.059270473s
Oct 28 17:45:26.755: INFO: Pod "pod-subpath-test-secret-87rl": Phase="Running", Reason="", readiness=true. Elapsed: 22.063987872s
Oct 28 17:45:28.761: INFO: Pod "pod-subpath-test-secret-87rl": Phase="Running", Reason="", readiness=true. Elapsed: 24.070149471s
Oct 28 17:45:30.766: INFO: Pod "pod-subpath-test-secret-87rl": Phase="Succeeded", Reason="", readiness=false. Elapsed: 26.075812662s
STEP: Saw pod success
Oct 28 17:45:30.767: INFO: Pod "pod-subpath-test-secret-87rl" satisfied condition "success or failure"
Oct 28 17:45:30.772: INFO: Trying to get logs from node kh4ga-worker-000000 pod pod-subpath-test-secret-87rl container test-container-subpath-secret-87rl: <nil>
STEP: delete the pod
Oct 28 17:45:30.806: INFO: Waiting for pod pod-subpath-test-secret-87rl to disappear
Oct 28 17:45:30.819: INFO: Pod pod-subpath-test-secret-87rl no longer exists
STEP: Deleting pod pod-subpath-test-secret-87rl
Oct 28 17:45:30.819: INFO: Deleting pod "pod-subpath-test-secret-87rl" in namespace "subpath-3785"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 17:45:30.823: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-3785" for this suite.
Oct 28 17:45:36.846: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 17:45:36.997: INFO: namespace subpath-3785 deletion completed in 6.167399195s

• [SLOW TEST:32.489 seconds]
[sig-storage] Subpath
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with secret pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 17:45:36.997: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-4510
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-upd-0bdc890f-e0e6-4b54-93d8-16ca5922c8b7
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 17:45:43.224: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4510" for this suite.
Oct 28 17:46:05.248: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 17:46:05.422: INFO: namespace configmap-4510 deletion completed in 22.189919781s

• [SLOW TEST:28.425 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 17:46:05.422: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename svc-latency
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svc-latency-5457
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating replication controller svc-latency-rc in namespace svc-latency-5457
I1028 17:46:05.601353      19 runners.go:180] Created replication controller with name: svc-latency-rc, namespace: svc-latency-5457, replica count: 1
I1028 17:46:06.651817      19 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1028 17:46:07.652099      19 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1028 17:46:08.652289      19 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1028 17:46:09.652588      19 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1028 17:46:10.652843      19 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Oct 28 17:46:10.776: INFO: Created: latency-svc-qkwq6
Oct 28 17:46:10.781: INFO: Got endpoints: latency-svc-qkwq6 [28.871325ms]
Oct 28 17:46:10.811: INFO: Created: latency-svc-sbwfn
Oct 28 17:46:10.823: INFO: Created: latency-svc-gdv78
Oct 28 17:46:10.826: INFO: Got endpoints: latency-svc-sbwfn [44.245092ms]
Oct 28 17:46:10.850: INFO: Got endpoints: latency-svc-gdv78 [68.088195ms]
Oct 28 17:46:10.865: INFO: Created: latency-svc-87hh4
Oct 28 17:46:10.879: INFO: Created: latency-svc-gwrt9
Oct 28 17:46:10.884: INFO: Created: latency-svc-bb2q7
Oct 28 17:46:10.891: INFO: Got endpoints: latency-svc-87hh4 [108.752271ms]
Oct 28 17:46:10.899: INFO: Got endpoints: latency-svc-gwrt9 [115.981802ms]
Oct 28 17:46:10.907: INFO: Created: latency-svc-q8hrj
Oct 28 17:46:10.908: INFO: Got endpoints: latency-svc-bb2q7 [124.951741ms]
Oct 28 17:46:10.923: INFO: Got endpoints: latency-svc-q8hrj [140.766809ms]
Oct 28 17:46:10.927: INFO: Created: latency-svc-nqwfj
Oct 28 17:46:10.940: INFO: Created: latency-svc-7xcnc
Oct 28 17:46:10.945: INFO: Got endpoints: latency-svc-nqwfj [162.161301ms]
Oct 28 17:46:10.971: INFO: Got endpoints: latency-svc-7xcnc [188.223914ms]
Oct 28 17:46:10.977: INFO: Created: latency-svc-b79nq
Oct 28 17:46:10.986: INFO: Got endpoints: latency-svc-b79nq [203.33168ms]
Oct 28 17:46:10.990: INFO: Created: latency-svc-klgz4
Oct 28 17:46:11.004: INFO: Created: latency-svc-9l4xx
Oct 28 17:46:11.006: INFO: Got endpoints: latency-svc-klgz4 [222.869964ms]
Oct 28 17:46:11.015: INFO: Got endpoints: latency-svc-9l4xx [232.147804ms]
Oct 28 17:46:11.027: INFO: Created: latency-svc-rdx9j
Oct 28 17:46:11.040: INFO: Created: latency-svc-sntpk
Oct 28 17:46:11.044: INFO: Got endpoints: latency-svc-rdx9j [260.990128ms]
Oct 28 17:46:11.051: INFO: Got endpoints: latency-svc-sntpk [268.11766ms]
Oct 28 17:46:11.062: INFO: Created: latency-svc-gmgcz
Oct 28 17:46:11.097: INFO: Created: latency-svc-f5255
Oct 28 17:46:11.102: INFO: Got endpoints: latency-svc-gmgcz [318.800779ms]
Oct 28 17:46:11.110: INFO: Created: latency-svc-fk74m
Oct 28 17:46:11.113: INFO: Got endpoints: latency-svc-f5255 [330.260928ms]
Oct 28 17:46:11.124: INFO: Created: latency-svc-tv58n
Oct 28 17:46:11.125: INFO: Got endpoints: latency-svc-fk74m [299.311194ms]
Oct 28 17:46:11.133: INFO: Got endpoints: latency-svc-tv58n [283.023624ms]
Oct 28 17:46:11.144: INFO: Created: latency-svc-w9q6s
Oct 28 17:46:11.156: INFO: Got endpoints: latency-svc-w9q6s [264.361043ms]
Oct 28 17:46:11.156: INFO: Created: latency-svc-n78p5
Oct 28 17:46:11.175: INFO: Got endpoints: latency-svc-n78p5 [276.197695ms]
Oct 28 17:46:11.175: INFO: Created: latency-svc-wj8lh
Oct 28 17:46:11.181: INFO: Got endpoints: latency-svc-wj8lh [272.972881ms]
Oct 28 17:46:11.192: INFO: Created: latency-svc-c5zfh
Oct 28 17:46:11.217: INFO: Got endpoints: latency-svc-c5zfh [294.078572ms]
Oct 28 17:46:11.227: INFO: Created: latency-svc-9pwbj
Oct 28 17:46:11.243: INFO: Got endpoints: latency-svc-9pwbj [298.053189ms]
Oct 28 17:46:11.243: INFO: Created: latency-svc-bcj8q
Oct 28 17:46:11.258: INFO: Got endpoints: latency-svc-bcj8q [287.322342ms]
Oct 28 17:46:11.260: INFO: Created: latency-svc-lc9kk
Oct 28 17:46:11.278: INFO: Got endpoints: latency-svc-lc9kk [291.886362ms]
Oct 28 17:46:11.279: INFO: Created: latency-svc-jqvzx
Oct 28 17:46:11.288: INFO: Created: latency-svc-tzk95
Oct 28 17:46:11.298: INFO: Got endpoints: latency-svc-tzk95 [39.565072ms]
Oct 28 17:46:11.298: INFO: Got endpoints: latency-svc-jqvzx [292.202064ms]
Oct 28 17:46:11.307: INFO: Created: latency-svc-h9bcr
Oct 28 17:46:11.313: INFO: Got endpoints: latency-svc-h9bcr [297.524286ms]
Oct 28 17:46:11.349: INFO: Created: latency-svc-tg6hb
Oct 28 17:46:11.363: INFO: Got endpoints: latency-svc-tg6hb [318.655977ms]
Oct 28 17:46:11.364: INFO: Created: latency-svc-k2nhq
Oct 28 17:46:11.376: INFO: Got endpoints: latency-svc-k2nhq [325.162906ms]
Oct 28 17:46:11.394: INFO: Created: latency-svc-kgjkv
Oct 28 17:46:11.407: INFO: Got endpoints: latency-svc-kgjkv [305.386221ms]
Oct 28 17:46:11.407: INFO: Created: latency-svc-4jm7p
Oct 28 17:46:11.422: INFO: Created: latency-svc-cvs5z
Oct 28 17:46:11.423: INFO: Got endpoints: latency-svc-4jm7p [310.198141ms]
Oct 28 17:46:11.441: INFO: Created: latency-svc-qj67q
Oct 28 17:46:11.444: INFO: Got endpoints: latency-svc-cvs5z [318.864879ms]
Oct 28 17:46:11.470: INFO: Created: latency-svc-9l5mr
Oct 28 17:46:11.472: INFO: Got endpoints: latency-svc-qj67q [338.575064ms]
Oct 28 17:46:11.485: INFO: Got endpoints: latency-svc-9l5mr [329.857927ms]
Oct 28 17:46:11.487: INFO: Created: latency-svc-5prpx
Oct 28 17:46:11.496: INFO: Got endpoints: latency-svc-5prpx [320.574886ms]
Oct 28 17:46:11.510: INFO: Created: latency-svc-4zfn9
Oct 28 17:46:11.520: INFO: Got endpoints: latency-svc-4zfn9 [339.655469ms]
Oct 28 17:46:11.535: INFO: Created: latency-svc-2gvfw
Oct 28 17:46:11.548: INFO: Created: latency-svc-s62tp
Oct 28 17:46:11.550: INFO: Got endpoints: latency-svc-2gvfw [333.10184ms]
Oct 28 17:46:11.569: INFO: Got endpoints: latency-svc-s62tp [325.730109ms]
Oct 28 17:46:11.572: INFO: Created: latency-svc-6wfgx
Oct 28 17:46:11.607: INFO: Got endpoints: latency-svc-6wfgx [329.228124ms]
Oct 28 17:46:11.619: INFO: Created: latency-svc-7w6cm
Oct 28 17:46:11.641: INFO: Got endpoints: latency-svc-7w6cm [343.413985ms]
Oct 28 17:46:11.648: INFO: Created: latency-svc-h9db6
Oct 28 17:46:11.663: INFO: Created: latency-svc-x9wkg
Oct 28 17:46:11.664: INFO: Got endpoints: latency-svc-h9db6 [366.067083ms]
Oct 28 17:46:11.674: INFO: Got endpoints: latency-svc-x9wkg [360.86416ms]
Oct 28 17:46:11.681: INFO: Created: latency-svc-5p29d
Oct 28 17:46:11.693: INFO: Got endpoints: latency-svc-5p29d [330.060227ms]
Oct 28 17:46:11.700: INFO: Created: latency-svc-qg8xh
Oct 28 17:46:11.736: INFO: Got endpoints: latency-svc-qg8xh [359.814856ms]
Oct 28 17:46:11.743: INFO: Created: latency-svc-9hx5x
Oct 28 17:46:11.749: INFO: Created: latency-svc-prv5h
Oct 28 17:46:11.769: INFO: Created: latency-svc-2rjvr
Oct 28 17:46:11.770: INFO: Got endpoints: latency-svc-prv5h [346.095197ms]
Oct 28 17:46:11.770: INFO: Got endpoints: latency-svc-9hx5x [362.510268ms]
Oct 28 17:46:11.775: INFO: Created: latency-svc-vns9b
Oct 28 17:46:11.780: INFO: Got endpoints: latency-svc-2rjvr [336.038053ms]
Oct 28 17:46:11.795: INFO: Created: latency-svc-gl7kn
Oct 28 17:46:11.796: INFO: Got endpoints: latency-svc-vns9b [324.383903ms]
Oct 28 17:46:11.810: INFO: Got endpoints: latency-svc-gl7kn [324.782004ms]
Oct 28 17:46:11.814: INFO: Created: latency-svc-29cf5
Oct 28 17:46:11.826: INFO: Created: latency-svc-8zjvm
Oct 28 17:46:11.836: INFO: Got endpoints: latency-svc-29cf5 [340.179671ms]
Oct 28 17:46:11.862: INFO: Created: latency-svc-k9mtk
Oct 28 17:46:11.871: INFO: Created: latency-svc-qxcr5
Oct 28 17:46:11.886: INFO: Created: latency-svc-xdvpr
Oct 28 17:46:11.890: INFO: Got endpoints: latency-svc-8zjvm [369.320897ms]
Oct 28 17:46:11.911: INFO: Created: latency-svc-mrp5k
Oct 28 17:46:11.925: INFO: Created: latency-svc-hw6s7
Oct 28 17:46:11.941: INFO: Got endpoints: latency-svc-k9mtk [390.556089ms]
Oct 28 17:46:11.941: INFO: Created: latency-svc-gjww8
Oct 28 17:46:11.958: INFO: Created: latency-svc-9lmkd
Oct 28 17:46:11.991: INFO: Got endpoints: latency-svc-qxcr5 [422.047525ms]
Oct 28 17:46:11.995: INFO: Created: latency-svc-2ljjx
Oct 28 17:46:11.995: INFO: Created: latency-svc-frrrh
Oct 28 17:46:12.004: INFO: Created: latency-svc-2mwsb
Oct 28 17:46:12.019: INFO: Created: latency-svc-z78dr
Oct 28 17:46:12.036: INFO: Got endpoints: latency-svc-xdvpr [428.932554ms]
Oct 28 17:46:12.042: INFO: Created: latency-svc-64452
Oct 28 17:46:12.057: INFO: Created: latency-svc-n9dp5
Oct 28 17:46:12.073: INFO: Created: latency-svc-8v6g9
Oct 28 17:46:12.117: INFO: Created: latency-svc-w5xbb
Oct 28 17:46:12.120: INFO: Got endpoints: latency-svc-mrp5k [478.187168ms]
Oct 28 17:46:12.133: INFO: Created: latency-svc-mkw4f
Oct 28 17:46:12.138: INFO: Got endpoints: latency-svc-hw6s7 [473.808748ms]
Oct 28 17:46:12.149: INFO: Created: latency-svc-xk694
Oct 28 17:46:12.166: INFO: Created: latency-svc-55hk7
Oct 28 17:46:12.185: INFO: Created: latency-svc-l27kf
Oct 28 17:46:12.189: INFO: Got endpoints: latency-svc-gjww8 [515.062927ms]
Oct 28 17:46:12.198: INFO: Created: latency-svc-bmcxr
Oct 28 17:46:12.214: INFO: Created: latency-svc-7q5pc
Oct 28 17:46:12.240: INFO: Got endpoints: latency-svc-9lmkd [547.537767ms]
Oct 28 17:46:12.259: INFO: Created: latency-svc-fwhmx
Oct 28 17:46:12.281: INFO: Got endpoints: latency-svc-frrrh [511.292511ms]
Oct 28 17:46:12.298: INFO: Created: latency-svc-c6xqt
Oct 28 17:46:12.331: INFO: Got endpoints: latency-svc-2ljjx [594.894172ms]
Oct 28 17:46:12.367: INFO: Created: latency-svc-f86tp
Oct 28 17:46:12.383: INFO: Got endpoints: latency-svc-2mwsb [612.717249ms]
Oct 28 17:46:12.406: INFO: Created: latency-svc-h87kx
Oct 28 17:46:12.431: INFO: Got endpoints: latency-svc-z78dr [650.591713ms]
Oct 28 17:46:12.451: INFO: Created: latency-svc-cmk6d
Oct 28 17:46:12.482: INFO: Got endpoints: latency-svc-64452 [685.384663ms]
Oct 28 17:46:12.500: INFO: Created: latency-svc-wptpz
Oct 28 17:46:12.530: INFO: Got endpoints: latency-svc-n9dp5 [719.648411ms]
Oct 28 17:46:12.552: INFO: Created: latency-svc-hcfg7
Oct 28 17:46:12.595: INFO: Got endpoints: latency-svc-8v6g9 [759.257783ms]
Oct 28 17:46:12.617: INFO: Created: latency-svc-rwvbs
Oct 28 17:46:12.633: INFO: Got endpoints: latency-svc-w5xbb [742.867611ms]
Oct 28 17:46:12.674: INFO: Created: latency-svc-t6dw6
Oct 28 17:46:12.686: INFO: Got endpoints: latency-svc-mkw4f [744.926321ms]
Oct 28 17:46:12.717: INFO: Created: latency-svc-qnfwq
Oct 28 17:46:12.731: INFO: Got endpoints: latency-svc-xk694 [739.948999ms]
Oct 28 17:46:12.748: INFO: Created: latency-svc-ghjv8
Oct 28 17:46:12.783: INFO: Got endpoints: latency-svc-55hk7 [746.815328ms]
Oct 28 17:46:12.805: INFO: Created: latency-svc-ztzbj
Oct 28 17:46:12.831: INFO: Got endpoints: latency-svc-l27kf [710.967973ms]
Oct 28 17:46:12.851: INFO: Created: latency-svc-c4wjn
Oct 28 17:46:12.882: INFO: Got endpoints: latency-svc-bmcxr [744.004116ms]
Oct 28 17:46:12.901: INFO: Created: latency-svc-9cm28
Oct 28 17:46:12.948: INFO: Got endpoints: latency-svc-7q5pc [759.574984ms]
Oct 28 17:46:12.966: INFO: Created: latency-svc-8lp9x
Oct 28 17:46:12.984: INFO: Got endpoints: latency-svc-fwhmx [743.530014ms]
Oct 28 17:46:13.004: INFO: Created: latency-svc-sn96z
Oct 28 17:46:13.032: INFO: Got endpoints: latency-svc-c6xqt [750.775745ms]
Oct 28 17:46:13.071: INFO: Created: latency-svc-mxpld
Oct 28 17:46:13.082: INFO: Got endpoints: latency-svc-f86tp [750.869146ms]
Oct 28 17:46:13.100: INFO: Created: latency-svc-7vpfp
Oct 28 17:46:13.133: INFO: Got endpoints: latency-svc-h87kx [750.097343ms]
Oct 28 17:46:13.158: INFO: Created: latency-svc-r2dfh
Oct 28 17:46:13.184: INFO: Got endpoints: latency-svc-cmk6d [752.767054ms]
Oct 28 17:46:13.209: INFO: Created: latency-svc-zhljh
Oct 28 17:46:13.231: INFO: Got endpoints: latency-svc-wptpz [749.086338ms]
Oct 28 17:46:13.257: INFO: Created: latency-svc-j64nn
Oct 28 17:46:13.284: INFO: Got endpoints: latency-svc-hcfg7 [753.666857ms]
Oct 28 17:46:13.318: INFO: Created: latency-svc-h9rgg
Oct 28 17:46:13.331: INFO: Got endpoints: latency-svc-rwvbs [735.81268ms]
Oct 28 17:46:13.362: INFO: Created: latency-svc-cr7hs
Oct 28 17:46:13.382: INFO: Got endpoints: latency-svc-t6dw6 [749.505039ms]
Oct 28 17:46:13.403: INFO: Created: latency-svc-2gjk4
Oct 28 17:46:13.431: INFO: Got endpoints: latency-svc-qnfwq [745.05462ms]
Oct 28 17:46:13.452: INFO: Created: latency-svc-gqbbq
Oct 28 17:46:13.483: INFO: Got endpoints: latency-svc-ghjv8 [751.98665ms]
Oct 28 17:46:13.502: INFO: Created: latency-svc-vgqjl
Oct 28 17:46:13.535: INFO: Got endpoints: latency-svc-ztzbj [751.96685ms]
Oct 28 17:46:13.555: INFO: Created: latency-svc-9xchb
Oct 28 17:46:13.582: INFO: Got endpoints: latency-svc-c4wjn [751.281247ms]
Oct 28 17:46:13.607: INFO: Created: latency-svc-w8254
Oct 28 17:46:13.635: INFO: Got endpoints: latency-svc-9cm28 [753.184055ms]
Oct 28 17:46:13.675: INFO: Created: latency-svc-jwgts
Oct 28 17:46:13.687: INFO: Got endpoints: latency-svc-8lp9x [738.638292ms]
Oct 28 17:46:13.712: INFO: Created: latency-svc-zf7m9
Oct 28 17:46:13.733: INFO: Got endpoints: latency-svc-sn96z [749.332338ms]
Oct 28 17:46:13.780: INFO: Created: latency-svc-75fl7
Oct 28 17:46:13.783: INFO: Got endpoints: latency-svc-mxpld [751.128146ms]
Oct 28 17:46:13.800: INFO: Created: latency-svc-jgg49
Oct 28 17:46:13.833: INFO: Got endpoints: latency-svc-7vpfp [751.569648ms]
Oct 28 17:46:13.861: INFO: Created: latency-svc-7mlzs
Oct 28 17:46:13.905: INFO: Got endpoints: latency-svc-r2dfh [771.819135ms]
Oct 28 17:46:13.927: INFO: Created: latency-svc-sx98b
Oct 28 17:46:13.933: INFO: Got endpoints: latency-svc-zhljh [749.57684ms]
Oct 28 17:46:13.951: INFO: Created: latency-svc-4s5np
Oct 28 17:46:13.982: INFO: Got endpoints: latency-svc-j64nn [751.303747ms]
Oct 28 17:46:14.003: INFO: Created: latency-svc-fddp9
Oct 28 17:46:14.031: INFO: Got endpoints: latency-svc-h9rgg [747.673131ms]
Oct 28 17:46:14.051: INFO: Created: latency-svc-hnrww
Oct 28 17:46:14.082: INFO: Got endpoints: latency-svc-cr7hs [750.571644ms]
Oct 28 17:46:14.103: INFO: Created: latency-svc-6hf6d
Oct 28 17:46:14.142: INFO: Got endpoints: latency-svc-2gjk4 [759.09988ms]
Oct 28 17:46:14.161: INFO: Created: latency-svc-6456s
Oct 28 17:46:14.183: INFO: Got endpoints: latency-svc-gqbbq [752.02975ms]
Oct 28 17:46:14.201: INFO: Created: latency-svc-m78cw
Oct 28 17:46:14.233: INFO: Got endpoints: latency-svc-vgqjl [750.364243ms]
Oct 28 17:46:14.271: INFO: Created: latency-svc-kxz4n
Oct 28 17:46:14.282: INFO: Got endpoints: latency-svc-9xchb [746.607226ms]
Oct 28 17:46:14.302: INFO: Created: latency-svc-xqkdp
Oct 28 17:46:14.333: INFO: Got endpoints: latency-svc-w8254 [751.236846ms]
Oct 28 17:46:14.358: INFO: Created: latency-svc-qdlxp
Oct 28 17:46:14.386: INFO: Got endpoints: latency-svc-jwgts [750.854945ms]
Oct 28 17:46:14.407: INFO: Created: latency-svc-dhmzx
Oct 28 17:46:14.431: INFO: Got endpoints: latency-svc-zf7m9 [744.437217ms]
Oct 28 17:46:14.451: INFO: Created: latency-svc-rdqhx
Oct 28 17:46:14.481: INFO: Got endpoints: latency-svc-75fl7 [747.427329ms]
Oct 28 17:46:14.516: INFO: Created: latency-svc-cclzp
Oct 28 17:46:14.532: INFO: Got endpoints: latency-svc-jgg49 [748.736335ms]
Oct 28 17:46:14.550: INFO: Created: latency-svc-mk78l
Oct 28 17:46:14.581: INFO: Got endpoints: latency-svc-7mlzs [747.431629ms]
Oct 28 17:46:14.606: INFO: Created: latency-svc-6k4mg
Oct 28 17:46:14.631: INFO: Got endpoints: latency-svc-sx98b [726.67114ms]
Oct 28 17:46:14.659: INFO: Created: latency-svc-86zjn
Oct 28 17:46:14.686: INFO: Got endpoints: latency-svc-4s5np [752.902653ms]
Oct 28 17:46:14.707: INFO: Created: latency-svc-jk7xs
Oct 28 17:46:14.754: INFO: Got endpoints: latency-svc-fddp9 [771.345233ms]
Oct 28 17:46:14.771: INFO: Created: latency-svc-nr6x6
Oct 28 17:46:14.781: INFO: Got endpoints: latency-svc-hnrww [749.474538ms]
Oct 28 17:46:14.801: INFO: Created: latency-svc-z9dwz
Oct 28 17:46:14.831: INFO: Got endpoints: latency-svc-6hf6d [749.530838ms]
Oct 28 17:46:14.852: INFO: Created: latency-svc-ccknw
Oct 28 17:46:14.881: INFO: Got endpoints: latency-svc-6456s [738.971393ms]
Oct 28 17:46:14.902: INFO: Created: latency-svc-d6l92
Oct 28 17:46:14.932: INFO: Got endpoints: latency-svc-m78cw [749.435238ms]
Oct 28 17:46:14.956: INFO: Created: latency-svc-2gzsf
Oct 28 17:46:14.984: INFO: Got endpoints: latency-svc-kxz4n [750.712443ms]
Oct 28 17:46:15.002: INFO: Created: latency-svc-zks9j
Oct 28 17:46:15.029: INFO: Got endpoints: latency-svc-xqkdp [747.58973ms]
Oct 28 17:46:15.049: INFO: Created: latency-svc-w5b6z
Oct 28 17:46:15.095: INFO: Got endpoints: latency-svc-qdlxp [761.772891ms]
Oct 28 17:46:15.111: INFO: Created: latency-svc-2x6zf
Oct 28 17:46:15.135: INFO: Got endpoints: latency-svc-dhmzx [748.700034ms]
Oct 28 17:46:15.157: INFO: Created: latency-svc-ssqwx
Oct 28 17:46:15.183: INFO: Got endpoints: latency-svc-rdqhx [751.137545ms]
Oct 28 17:46:15.211: INFO: Created: latency-svc-xgc4f
Oct 28 17:46:15.231: INFO: Got endpoints: latency-svc-cclzp [750.08044ms]
Oct 28 17:46:15.250: INFO: Created: latency-svc-mpm95
Oct 28 17:46:15.283: INFO: Got endpoints: latency-svc-mk78l [751.083144ms]
Oct 28 17:46:15.304: INFO: Created: latency-svc-hmzl9
Oct 28 17:46:15.334: INFO: Got endpoints: latency-svc-6k4mg [753.142153ms]
Oct 28 17:46:15.353: INFO: Created: latency-svc-2gdd5
Oct 28 17:46:15.382: INFO: Got endpoints: latency-svc-86zjn [750.723643ms]
Oct 28 17:46:15.399: INFO: Created: latency-svc-p5kfw
Oct 28 17:46:15.431: INFO: Got endpoints: latency-svc-jk7xs [744.612116ms]
Oct 28 17:46:15.470: INFO: Created: latency-svc-kff9l
Oct 28 17:46:15.483: INFO: Got endpoints: latency-svc-nr6x6 [728.902948ms]
Oct 28 17:46:15.503: INFO: Created: latency-svc-b84wr
Oct 28 17:46:15.532: INFO: Got endpoints: latency-svc-z9dwz [750.694643ms]
Oct 28 17:46:15.550: INFO: Created: latency-svc-zkpp7
Oct 28 17:46:15.581: INFO: Got endpoints: latency-svc-ccknw [749.303636ms]
Oct 28 17:46:15.598: INFO: Created: latency-svc-dzpwb
Oct 28 17:46:15.641: INFO: Got endpoints: latency-svc-d6l92 [759.943182ms]
Oct 28 17:46:15.662: INFO: Created: latency-svc-vqbkh
Oct 28 17:46:15.691: INFO: Got endpoints: latency-svc-2gzsf [758.819277ms]
Oct 28 17:46:15.709: INFO: Created: latency-svc-8f8kc
Oct 28 17:46:15.732: INFO: Got endpoints: latency-svc-zks9j [748.388832ms]
Oct 28 17:46:15.753: INFO: Created: latency-svc-q6wbt
Oct 28 17:46:15.784: INFO: Got endpoints: latency-svc-w5b6z [754.490659ms]
Oct 28 17:46:15.812: INFO: Created: latency-svc-vrhcx
Oct 28 17:46:15.836: INFO: Got endpoints: latency-svc-2x6zf [740.796299ms]
Oct 28 17:46:15.858: INFO: Created: latency-svc-h567j
Oct 28 17:46:15.883: INFO: Got endpoints: latency-svc-ssqwx [748.395832ms]
Oct 28 17:46:15.901: INFO: Created: latency-svc-nxgwd
Oct 28 17:46:15.935: INFO: Got endpoints: latency-svc-xgc4f [752.136548ms]
Oct 28 17:46:15.955: INFO: Created: latency-svc-4wvhx
Oct 28 17:46:15.983: INFO: Got endpoints: latency-svc-mpm95 [752.215449ms]
Oct 28 17:46:16.001: INFO: Created: latency-svc-nn7zd
Oct 28 17:46:16.044: INFO: Got endpoints: latency-svc-hmzl9 [760.962387ms]
Oct 28 17:46:16.067: INFO: Created: latency-svc-n5zkt
Oct 28 17:46:16.082: INFO: Got endpoints: latency-svc-2gdd5 [747.846829ms]
Oct 28 17:46:16.098: INFO: Created: latency-svc-cg4b8
Oct 28 17:46:16.133: INFO: Got endpoints: latency-svc-p5kfw [751.152244ms]
Oct 28 17:46:16.206: INFO: Got endpoints: latency-svc-kff9l [774.960446ms]
Oct 28 17:46:16.215: INFO: Created: latency-svc-vlrpl
Oct 28 17:46:16.229: INFO: Created: latency-svc-kb772
Oct 28 17:46:16.235: INFO: Got endpoints: latency-svc-b84wr [752.340849ms]
Oct 28 17:46:16.251: INFO: Created: latency-svc-6wcpj
Oct 28 17:46:16.285: INFO: Got endpoints: latency-svc-zkpp7 [753.365553ms]
Oct 28 17:46:16.304: INFO: Created: latency-svc-rdkdv
Oct 28 17:46:16.332: INFO: Got endpoints: latency-svc-dzpwb [751.171443ms]
Oct 28 17:46:16.361: INFO: Created: latency-svc-frhxf
Oct 28 17:46:16.385: INFO: Got endpoints: latency-svc-vqbkh [744.065013ms]
Oct 28 17:46:16.401: INFO: Created: latency-svc-9bng7
Oct 28 17:46:16.435: INFO: Got endpoints: latency-svc-8f8kc [744.114213ms]
Oct 28 17:46:16.451: INFO: Created: latency-svc-bnj9r
Oct 28 17:46:16.482: INFO: Got endpoints: latency-svc-q6wbt [749.402935ms]
Oct 28 17:46:16.499: INFO: Created: latency-svc-dl4xd
Oct 28 17:46:16.533: INFO: Got endpoints: latency-svc-vrhcx [749.038634ms]
Oct 28 17:46:16.575: INFO: Created: latency-svc-thcdz
Oct 28 17:46:16.585: INFO: Got endpoints: latency-svc-h567j [748.722633ms]
Oct 28 17:46:16.605: INFO: Created: latency-svc-zwdg2
Oct 28 17:46:16.631: INFO: Got endpoints: latency-svc-nxgwd [747.525528ms]
Oct 28 17:46:16.653: INFO: Created: latency-svc-hwn6v
Oct 28 17:46:16.689: INFO: Got endpoints: latency-svc-4wvhx [754.346657ms]
Oct 28 17:46:16.709: INFO: Created: latency-svc-7b7dn
Oct 28 17:46:16.731: INFO: Got endpoints: latency-svc-nn7zd [748.15683ms]
Oct 28 17:46:16.757: INFO: Created: latency-svc-zq42n
Oct 28 17:46:16.805: INFO: Got endpoints: latency-svc-n5zkt [760.961285ms]
Oct 28 17:46:16.825: INFO: Created: latency-svc-wvclj
Oct 28 17:46:16.831: INFO: Got endpoints: latency-svc-cg4b8 [748.998933ms]
Oct 28 17:46:16.846: INFO: Created: latency-svc-474vk
Oct 28 17:46:16.881: INFO: Got endpoints: latency-svc-vlrpl [747.338727ms]
Oct 28 17:46:16.899: INFO: Created: latency-svc-h9tzq
Oct 28 17:46:16.933: INFO: Got endpoints: latency-svc-kb772 [727.195239ms]
Oct 28 17:46:16.949: INFO: Created: latency-svc-tmcns
Oct 28 17:46:16.981: INFO: Got endpoints: latency-svc-6wcpj [745.878721ms]
Oct 28 17:46:17.001: INFO: Created: latency-svc-rl2bp
Oct 28 17:46:17.049: INFO: Got endpoints: latency-svc-rdkdv [764.1595ms]
Oct 28 17:46:17.066: INFO: Created: latency-svc-fnwc9
Oct 28 17:46:17.080: INFO: Got endpoints: latency-svc-frhxf [748.29723ms]
Oct 28 17:46:17.102: INFO: Created: latency-svc-8pcl2
Oct 28 17:46:17.133: INFO: Got endpoints: latency-svc-9bng7 [748.08323ms]
Oct 28 17:46:17.171: INFO: Created: latency-svc-b7czv
Oct 28 17:46:17.182: INFO: Got endpoints: latency-svc-bnj9r [747.129825ms]
Oct 28 17:46:17.201: INFO: Created: latency-svc-2d6jw
Oct 28 17:46:17.234: INFO: Got endpoints: latency-svc-dl4xd [752.205947ms]
Oct 28 17:46:17.256: INFO: Created: latency-svc-68l56
Oct 28 17:46:17.286: INFO: Got endpoints: latency-svc-thcdz [752.548249ms]
Oct 28 17:46:17.302: INFO: Created: latency-svc-5fpwt
Oct 28 17:46:17.331: INFO: Got endpoints: latency-svc-zwdg2 [745.99942ms]
Oct 28 17:46:17.347: INFO: Created: latency-svc-qrqns
Oct 28 17:46:17.381: INFO: Got endpoints: latency-svc-hwn6v [750.57374ms]
Oct 28 17:46:17.414: INFO: Created: latency-svc-kjgfr
Oct 28 17:46:17.432: INFO: Got endpoints: latency-svc-7b7dn [742.398205ms]
Oct 28 17:46:17.453: INFO: Created: latency-svc-rhbsg
Oct 28 17:46:17.489: INFO: Got endpoints: latency-svc-zq42n [757.229469ms]
Oct 28 17:46:17.525: INFO: Created: latency-svc-fxhnk
Oct 28 17:46:17.531: INFO: Got endpoints: latency-svc-wvclj [725.797032ms]
Oct 28 17:46:17.550: INFO: Created: latency-svc-fpgfb
Oct 28 17:46:17.582: INFO: Got endpoints: latency-svc-474vk [750.50944ms]
Oct 28 17:46:17.601: INFO: Created: latency-svc-xg54l
Oct 28 17:46:17.643: INFO: Got endpoints: latency-svc-h9tzq [762.494491ms]
Oct 28 17:46:17.667: INFO: Created: latency-svc-27h56
Oct 28 17:46:17.682: INFO: Got endpoints: latency-svc-tmcns [748.922733ms]
Oct 28 17:46:17.732: INFO: Created: latency-svc-2hdzk
Oct 28 17:46:17.735: INFO: Got endpoints: latency-svc-rl2bp [753.728853ms]
Oct 28 17:46:17.780: INFO: Created: latency-svc-hcmlv
Oct 28 17:46:17.787: INFO: Got endpoints: latency-svc-fnwc9 [737.492683ms]
Oct 28 17:46:17.808: INFO: Created: latency-svc-s6p2s
Oct 28 17:46:17.833: INFO: Got endpoints: latency-svc-8pcl2 [752.755049ms]
Oct 28 17:46:17.849: INFO: Created: latency-svc-n9v8s
Oct 28 17:46:17.880: INFO: Got endpoints: latency-svc-b7czv [747.201925ms]
Oct 28 17:46:17.902: INFO: Created: latency-svc-sjfj2
Oct 28 17:46:17.935: INFO: Got endpoints: latency-svc-2d6jw [752.670949ms]
Oct 28 17:46:17.955: INFO: Created: latency-svc-ldstq
Oct 28 17:46:18.005: INFO: Got endpoints: latency-svc-68l56 [770.892728ms]
Oct 28 17:46:18.025: INFO: Created: latency-svc-bqzzs
Oct 28 17:46:18.032: INFO: Got endpoints: latency-svc-5fpwt [745.800619ms]
Oct 28 17:46:18.052: INFO: Created: latency-svc-xkzc7
Oct 28 17:46:18.083: INFO: Got endpoints: latency-svc-qrqns [752.139946ms]
Oct 28 17:46:18.100: INFO: Created: latency-svc-zxnzd
Oct 28 17:46:18.131: INFO: Got endpoints: latency-svc-kjgfr [749.081933ms]
Oct 28 17:46:18.157: INFO: Created: latency-svc-cnfq6
Oct 28 17:46:18.181: INFO: Got endpoints: latency-svc-rhbsg [749.736936ms]
Oct 28 17:46:18.199: INFO: Created: latency-svc-2wzqv
Oct 28 17:46:18.238: INFO: Got endpoints: latency-svc-fxhnk [748.822632ms]
Oct 28 17:46:18.256: INFO: Created: latency-svc-hwb2b
Oct 28 17:46:18.281: INFO: Got endpoints: latency-svc-fpgfb [750.589139ms]
Oct 28 17:46:18.298: INFO: Created: latency-svc-7bwjs
Oct 28 17:46:18.332: INFO: Got endpoints: latency-svc-xg54l [749.983337ms]
Oct 28 17:46:18.370: INFO: Created: latency-svc-pc4xf
Oct 28 17:46:18.401: INFO: Got endpoints: latency-svc-27h56 [757.832771ms]
Oct 28 17:46:18.426: INFO: Created: latency-svc-m5n4k
Oct 28 17:46:18.436: INFO: Got endpoints: latency-svc-2hdzk [753.888253ms]
Oct 28 17:46:18.480: INFO: Created: latency-svc-d7glv
Oct 28 17:46:18.489: INFO: Got endpoints: latency-svc-hcmlv [754.307655ms]
Oct 28 17:46:18.517: INFO: Created: latency-svc-4lqtp
Oct 28 17:46:18.532: INFO: Got endpoints: latency-svc-s6p2s [744.767514ms]
Oct 28 17:46:18.586: INFO: Created: latency-svc-9fqqw
Oct 28 17:46:18.587: INFO: Got endpoints: latency-svc-n9v8s [753.789553ms]
Oct 28 17:46:18.605: INFO: Created: latency-svc-8gx6w
Oct 28 17:46:18.637: INFO: Got endpoints: latency-svc-sjfj2 [756.921767ms]
Oct 28 17:46:18.703: INFO: Got endpoints: latency-svc-ldstq [768.113714ms]
Oct 28 17:46:18.740: INFO: Got endpoints: latency-svc-bqzzs [734.67177ms]
Oct 28 17:46:18.796: INFO: Got endpoints: latency-svc-xkzc7 [764.751ms]
Oct 28 17:46:18.835: INFO: Got endpoints: latency-svc-zxnzd [751.551543ms]
Oct 28 17:46:18.883: INFO: Got endpoints: latency-svc-cnfq6 [752.022545ms]
Oct 28 17:46:18.943: INFO: Got endpoints: latency-svc-2wzqv [761.845987ms]
Oct 28 17:46:18.985: INFO: Got endpoints: latency-svc-hwb2b [747.375225ms]
Oct 28 17:46:19.033: INFO: Got endpoints: latency-svc-7bwjs [751.975945ms]
Oct 28 17:46:19.081: INFO: Got endpoints: latency-svc-pc4xf [748.769331ms]
Oct 28 17:46:19.133: INFO: Got endpoints: latency-svc-m5n4k [731.933458ms]
Oct 28 17:46:19.185: INFO: Got endpoints: latency-svc-d7glv [749.298733ms]
Oct 28 17:46:19.232: INFO: Got endpoints: latency-svc-4lqtp [742.911206ms]
Oct 28 17:46:19.284: INFO: Got endpoints: latency-svc-9fqqw [752.655847ms]
Oct 28 17:46:19.334: INFO: Got endpoints: latency-svc-8gx6w [747.531925ms]
Oct 28 17:46:19.335: INFO: Latencies: [39.565072ms 44.245092ms 68.088195ms 108.752271ms 115.981802ms 124.951741ms 140.766809ms 162.161301ms 188.223914ms 203.33168ms 222.869964ms 232.147804ms 260.990128ms 264.361043ms 268.11766ms 272.972881ms 276.197695ms 283.023624ms 287.322342ms 291.886362ms 292.202064ms 294.078572ms 297.524286ms 298.053189ms 299.311194ms 305.386221ms 310.198141ms 318.655977ms 318.800779ms 318.864879ms 320.574886ms 324.383903ms 324.782004ms 325.162906ms 325.730109ms 329.228124ms 329.857927ms 330.060227ms 330.260928ms 333.10184ms 336.038053ms 338.575064ms 339.655469ms 340.179671ms 343.413985ms 346.095197ms 359.814856ms 360.86416ms 362.510268ms 366.067083ms 369.320897ms 390.556089ms 422.047525ms 428.932554ms 473.808748ms 478.187168ms 511.292511ms 515.062927ms 547.537767ms 594.894172ms 612.717249ms 650.591713ms 685.384663ms 710.967973ms 719.648411ms 725.797032ms 726.67114ms 727.195239ms 728.902948ms 731.933458ms 734.67177ms 735.81268ms 737.492683ms 738.638292ms 738.971393ms 739.948999ms 740.796299ms 742.398205ms 742.867611ms 742.911206ms 743.530014ms 744.004116ms 744.065013ms 744.114213ms 744.437217ms 744.612116ms 744.767514ms 744.926321ms 745.05462ms 745.800619ms 745.878721ms 745.99942ms 746.607226ms 746.815328ms 747.129825ms 747.201925ms 747.338727ms 747.375225ms 747.427329ms 747.431629ms 747.525528ms 747.531925ms 747.58973ms 747.673131ms 747.846829ms 748.08323ms 748.15683ms 748.29723ms 748.388832ms 748.395832ms 748.700034ms 748.722633ms 748.736335ms 748.769331ms 748.822632ms 748.922733ms 748.998933ms 749.038634ms 749.081933ms 749.086338ms 749.298733ms 749.303636ms 749.332338ms 749.402935ms 749.435238ms 749.474538ms 749.505039ms 749.530838ms 749.57684ms 749.736936ms 749.983337ms 750.08044ms 750.097343ms 750.364243ms 750.50944ms 750.571644ms 750.57374ms 750.589139ms 750.694643ms 750.712443ms 750.723643ms 750.775745ms 750.854945ms 750.869146ms 751.083144ms 751.128146ms 751.137545ms 751.152244ms 751.171443ms 751.236846ms 751.281247ms 751.303747ms 751.551543ms 751.569648ms 751.96685ms 751.975945ms 751.98665ms 752.022545ms 752.02975ms 752.136548ms 752.139946ms 752.205947ms 752.215449ms 752.340849ms 752.548249ms 752.655847ms 752.670949ms 752.755049ms 752.767054ms 752.902653ms 753.142153ms 753.184055ms 753.365553ms 753.666857ms 753.728853ms 753.789553ms 753.888253ms 754.307655ms 754.346657ms 754.490659ms 756.921767ms 757.229469ms 757.832771ms 758.819277ms 759.09988ms 759.257783ms 759.574984ms 759.943182ms 760.961285ms 760.962387ms 761.772891ms 761.845987ms 762.494491ms 764.1595ms 764.751ms 768.113714ms 770.892728ms 771.345233ms 771.819135ms 774.960446ms]
Oct 28 17:46:19.335: INFO: 50 %ile: 747.525528ms
Oct 28 17:46:19.335: INFO: 90 %ile: 756.921767ms
Oct 28 17:46:19.335: INFO: 99 %ile: 771.819135ms
Oct 28 17:46:19.335: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 17:46:19.335: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svc-latency-5457" for this suite.
Oct 28 17:46:45.374: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 17:46:45.539: INFO: namespace svc-latency-5457 deletion completed in 26.196393153s

• [SLOW TEST:40.117 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should not be very high  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 17:46:45.540: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-5057
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Oct 28 17:46:45.716: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b9d8fd30-454d-47ce-8e11-752a80b62914" in namespace "downward-api-5057" to be "success or failure"
Oct 28 17:46:45.729: INFO: Pod "downwardapi-volume-b9d8fd30-454d-47ce-8e11-752a80b62914": Phase="Pending", Reason="", readiness=false. Elapsed: 12.488753ms
Oct 28 17:46:47.741: INFO: Pod "downwardapi-volume-b9d8fd30-454d-47ce-8e11-752a80b62914": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025435265s
Oct 28 17:46:49.746: INFO: Pod "downwardapi-volume-b9d8fd30-454d-47ce-8e11-752a80b62914": Phase="Pending", Reason="", readiness=false. Elapsed: 4.030327737s
Oct 28 17:46:51.751: INFO: Pod "downwardapi-volume-b9d8fd30-454d-47ce-8e11-752a80b62914": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.034782502s
STEP: Saw pod success
Oct 28 17:46:51.751: INFO: Pod "downwardapi-volume-b9d8fd30-454d-47ce-8e11-752a80b62914" satisfied condition "success or failure"
Oct 28 17:46:51.754: INFO: Trying to get logs from node kh4ga-worker-000003 pod downwardapi-volume-b9d8fd30-454d-47ce-8e11-752a80b62914 container client-container: <nil>
STEP: delete the pod
Oct 28 17:46:51.791: INFO: Waiting for pod downwardapi-volume-b9d8fd30-454d-47ce-8e11-752a80b62914 to disappear
Oct 28 17:46:51.805: INFO: Pod downwardapi-volume-b9d8fd30-454d-47ce-8e11-752a80b62914 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 17:46:51.805: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5057" for this suite.
Oct 28 17:46:57.846: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 17:46:57.996: INFO: namespace downward-api-5057 deletion completed in 6.171200338s

• [SLOW TEST:12.456 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 17:46:57.996: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-962
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 17:47:06.181: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-962" for this suite.
Oct 28 17:47:12.244: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 17:47:12.397: INFO: namespace kubelet-test-962 deletion completed in 6.208867789s

• [SLOW TEST:14.401 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should have an terminated reason [NodeConformance] [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 17:47:12.397: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-4054
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test substitution in container's args
Oct 28 17:47:12.596: INFO: Waiting up to 5m0s for pod "var-expansion-a72b8390-690c-4e8f-bfa7-7889426e4168" in namespace "var-expansion-4054" to be "success or failure"
Oct 28 17:47:12.604: INFO: Pod "var-expansion-a72b8390-690c-4e8f-bfa7-7889426e4168": Phase="Pending", Reason="", readiness=false. Elapsed: 7.838134ms
Oct 28 17:47:14.608: INFO: Pod "var-expansion-a72b8390-690c-4e8f-bfa7-7889426e4168": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012069942s
Oct 28 17:47:16.613: INFO: Pod "var-expansion-a72b8390-690c-4e8f-bfa7-7889426e4168": Phase="Pending", Reason="", readiness=false. Elapsed: 4.017262849s
Oct 28 17:47:18.618: INFO: Pod "var-expansion-a72b8390-690c-4e8f-bfa7-7889426e4168": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.021828049s
STEP: Saw pod success
Oct 28 17:47:18.618: INFO: Pod "var-expansion-a72b8390-690c-4e8f-bfa7-7889426e4168" satisfied condition "success or failure"
Oct 28 17:47:18.621: INFO: Trying to get logs from node kh4ga-worker-000003 pod var-expansion-a72b8390-690c-4e8f-bfa7-7889426e4168 container dapi-container: <nil>
STEP: delete the pod
Oct 28 17:47:18.642: INFO: Waiting for pod var-expansion-a72b8390-690c-4e8f-bfa7-7889426e4168 to disappear
Oct 28 17:47:18.648: INFO: Pod var-expansion-a72b8390-690c-4e8f-bfa7-7889426e4168 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 17:47:18.648: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-4054" for this suite.
Oct 28 17:47:24.673: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 17:47:24.858: INFO: namespace var-expansion-4054 deletion completed in 6.204712379s

• [SLOW TEST:12.462 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 17:47:24.859: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-8416
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating pod
Oct 28 17:47:31.039: INFO: Pod pod-hostip-9c07ebf8-2eee-4382-8827-95f4013b81e4 has hostIP: 10.2.1.7
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 17:47:31.039: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-8416" for this suite.
Oct 28 17:47:53.063: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 17:47:53.243: INFO: namespace pods-8416 deletion completed in 22.197775292s

• [SLOW TEST:28.384 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 17:47:53.243: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-3073
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0644 on node default medium
Oct 28 17:47:53.430: INFO: Waiting up to 5m0s for pod "pod-c6e98080-af8e-4c9d-8609-bfb2c8c57655" in namespace "emptydir-3073" to be "success or failure"
Oct 28 17:47:53.438: INFO: Pod "pod-c6e98080-af8e-4c9d-8609-bfb2c8c57655": Phase="Pending", Reason="", readiness=false. Elapsed: 7.545932ms
Oct 28 17:47:55.442: INFO: Pod "pod-c6e98080-af8e-4c9d-8609-bfb2c8c57655": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012126147s
Oct 28 17:47:57.447: INFO: Pod "pod-c6e98080-af8e-4c9d-8609-bfb2c8c57655": Phase="Pending", Reason="", readiness=false. Elapsed: 4.016732358s
Oct 28 17:47:59.455: INFO: Pod "pod-c6e98080-af8e-4c9d-8609-bfb2c8c57655": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.024914179s
STEP: Saw pod success
Oct 28 17:47:59.455: INFO: Pod "pod-c6e98080-af8e-4c9d-8609-bfb2c8c57655" satisfied condition "success or failure"
Oct 28 17:47:59.459: INFO: Trying to get logs from node kh4ga-worker-000003 pod pod-c6e98080-af8e-4c9d-8609-bfb2c8c57655 container test-container: <nil>
STEP: delete the pod
Oct 28 17:47:59.486: INFO: Waiting for pod pod-c6e98080-af8e-4c9d-8609-bfb2c8c57655 to disappear
Oct 28 17:47:59.490: INFO: Pod pod-c6e98080-af8e-4c9d-8609-bfb2c8c57655 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 17:47:59.490: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3073" for this suite.
Oct 28 17:48:05.511: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 17:48:05.668: INFO: namespace emptydir-3073 deletion completed in 6.171449552s

• [SLOW TEST:12.425 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 17:48:05.668: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-8997
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod busybox-5019159f-f0e0-4d25-845f-d47390ff14ed in namespace container-probe-8997
Oct 28 17:48:11.837: INFO: Started pod busybox-5019159f-f0e0-4d25-845f-d47390ff14ed in namespace container-probe-8997
STEP: checking the pod's current state and verifying that restartCount is present
Oct 28 17:48:11.841: INFO: Initial restart count of pod busybox-5019159f-f0e0-4d25-845f-d47390ff14ed is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 17:52:12.467: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-8997" for this suite.
Oct 28 17:52:18.516: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 17:52:18.690: INFO: namespace container-probe-8997 deletion completed in 6.211264468s

• [SLOW TEST:253.023 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 17:52:18.691: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-5887
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 17:53:18.872: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-5887" for this suite.
Oct 28 17:53:40.892: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 17:53:41.069: INFO: namespace container-probe-5887 deletion completed in 22.190008809s

• [SLOW TEST:82.378 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 17:53:41.069: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-9604
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating service endpoint-test2 in namespace services-9604
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-9604 to expose endpoints map[]
Oct 28 17:53:41.244: INFO: Get endpoints failed (5.759322ms elapsed, ignoring for 5s): endpoints "endpoint-test2" not found
Oct 28 17:53:42.247: INFO: successfully validated that service endpoint-test2 in namespace services-9604 exposes endpoints map[] (1.009357955s elapsed)
STEP: Creating pod pod1 in namespace services-9604
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-9604 to expose endpoints map[pod1:[80]]
Oct 28 17:53:46.317: INFO: Unexpected endpoints: found map[], expected map[pod1:[80]] (4.062830116s elapsed, will retry)
Oct 28 17:53:47.325: INFO: successfully validated that service endpoint-test2 in namespace services-9604 exposes endpoints map[pod1:[80]] (5.070584363s elapsed)
STEP: Creating pod pod2 in namespace services-9604
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-9604 to expose endpoints map[pod1:[80] pod2:[80]]
Oct 28 17:53:51.401: INFO: Unexpected endpoints: found map[d6a75d70-3314-40f5-b406-238814bd496b:[80]], expected map[pod1:[80] pod2:[80]] (4.070001633s elapsed, will retry)
Oct 28 17:53:52.422: INFO: successfully validated that service endpoint-test2 in namespace services-9604 exposes endpoints map[pod1:[80] pod2:[80]] (5.09150653s elapsed)
STEP: Deleting pod pod1 in namespace services-9604
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-9604 to expose endpoints map[pod2:[80]]
Oct 28 17:53:52.444: INFO: successfully validated that service endpoint-test2 in namespace services-9604 exposes endpoints map[pod2:[80]] (12.706749ms elapsed)
STEP: Deleting pod pod2 in namespace services-9604
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-9604 to expose endpoints map[]
Oct 28 17:53:52.462: INFO: successfully validated that service endpoint-test2 in namespace services-9604 exposes endpoints map[] (8.071131ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 17:53:52.492: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-9604" for this suite.
Oct 28 17:54:14.535: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 17:54:14.682: INFO: namespace services-9604 deletion completed in 22.177106643s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:92

• [SLOW TEST:33.613 seconds]
[sig-network] Services
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 17:54:14.682: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-5920
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-4af997c9-df18-4a47-ae0a-993897e35d2c
STEP: Creating a pod to test consume configMaps
Oct 28 17:54:14.863: INFO: Waiting up to 5m0s for pod "pod-configmaps-6dfb5dd4-0bed-407b-8e91-b1e83a815f5b" in namespace "configmap-5920" to be "success or failure"
Oct 28 17:54:14.874: INFO: Pod "pod-configmaps-6dfb5dd4-0bed-407b-8e91-b1e83a815f5b": Phase="Pending", Reason="", readiness=false. Elapsed: 10.983843ms
Oct 28 17:54:16.879: INFO: Pod "pod-configmaps-6dfb5dd4-0bed-407b-8e91-b1e83a815f5b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015831863s
Oct 28 17:54:18.883: INFO: Pod "pod-configmaps-6dfb5dd4-0bed-407b-8e91-b1e83a815f5b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.020300779s
Oct 28 17:54:20.888: INFO: Pod "pod-configmaps-6dfb5dd4-0bed-407b-8e91-b1e83a815f5b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.024594892s
STEP: Saw pod success
Oct 28 17:54:20.888: INFO: Pod "pod-configmaps-6dfb5dd4-0bed-407b-8e91-b1e83a815f5b" satisfied condition "success or failure"
Oct 28 17:54:20.891: INFO: Trying to get logs from node kh4ga-worker-000000 pod pod-configmaps-6dfb5dd4-0bed-407b-8e91-b1e83a815f5b container configmap-volume-test: <nil>
STEP: delete the pod
Oct 28 17:54:20.918: INFO: Waiting for pod pod-configmaps-6dfb5dd4-0bed-407b-8e91-b1e83a815f5b to disappear
Oct 28 17:54:20.925: INFO: Pod pod-configmaps-6dfb5dd4-0bed-407b-8e91-b1e83a815f5b no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 17:54:20.925: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5920" for this suite.
Oct 28 17:54:26.956: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 17:54:27.131: INFO: namespace configmap-5920 deletion completed in 6.200406257s

• [SLOW TEST:12.449 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 17:54:27.132: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7431
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Oct 28 17:54:27.319: INFO: Waiting up to 5m0s for pod "downwardapi-volume-031396c9-6ca1-4214-b7f8-8f066b267dde" in namespace "projected-7431" to be "success or failure"
Oct 28 17:54:27.335: INFO: Pod "downwardapi-volume-031396c9-6ca1-4214-b7f8-8f066b267dde": Phase="Pending", Reason="", readiness=false. Elapsed: 16.000063ms
Oct 28 17:54:29.342: INFO: Pod "downwardapi-volume-031396c9-6ca1-4214-b7f8-8f066b267dde": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023206178s
Oct 28 17:54:31.346: INFO: Pod "downwardapi-volume-031396c9-6ca1-4214-b7f8-8f066b267dde": Phase="Pending", Reason="", readiness=false. Elapsed: 4.02727398s
Oct 28 17:54:33.359: INFO: Pod "downwardapi-volume-031396c9-6ca1-4214-b7f8-8f066b267dde": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.039579911s
STEP: Saw pod success
Oct 28 17:54:33.359: INFO: Pod "downwardapi-volume-031396c9-6ca1-4214-b7f8-8f066b267dde" satisfied condition "success or failure"
Oct 28 17:54:33.363: INFO: Trying to get logs from node kh4ga-worker-000003 pod downwardapi-volume-031396c9-6ca1-4214-b7f8-8f066b267dde container client-container: <nil>
STEP: delete the pod
Oct 28 17:54:33.400: INFO: Waiting for pod downwardapi-volume-031396c9-6ca1-4214-b7f8-8f066b267dde to disappear
Oct 28 17:54:33.405: INFO: Pod downwardapi-volume-031396c9-6ca1-4214-b7f8-8f066b267dde no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 17:54:33.405: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7431" for this suite.
Oct 28 17:54:39.426: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 17:54:39.575: INFO: namespace projected-7431 deletion completed in 6.163822376s

• [SLOW TEST:12.443 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 17:54:39.575: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-2525
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1557
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Oct 28 17:54:39.729: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-124947935 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --generator=deployment/apps.v1 --namespace=kubectl-2525'
Oct 28 17:54:42.238: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Oct 28 17:54:42.238: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the deployment e2e-test-nginx-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1562
Oct 28 17:54:46.278: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-124947935 delete deployment e2e-test-nginx-deployment --namespace=kubectl-2525'
Oct 28 17:54:46.369: INFO: stderr: ""
Oct 28 17:54:46.370: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 17:54:46.370: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2525" for this suite.
Oct 28 17:55:08.396: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 17:55:08.551: INFO: namespace kubectl-2525 deletion completed in 22.174562623s

• [SLOW TEST:28.976 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run deployment
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 17:55:08.552: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7312
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating the pod
Oct 28 17:55:15.254: INFO: Successfully updated pod "annotationupdatef7f0a29d-bb76-4312-b162-552c48fae92d"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 17:55:17.284: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7312" for this suite.
Oct 28 17:55:39.304: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 17:55:39.471: INFO: namespace projected-7312 deletion completed in 22.181674629s

• [SLOW TEST:30.919 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 17:55:39.471: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-1255
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Oct 28 17:55:44.685: INFO: Expected: &{OK} to match Container's Termination Message: OK --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 17:55:44.707: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-1255" for this suite.
Oct 28 17:55:50.726: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 17:55:50.880: INFO: namespace container-runtime-1255 deletion completed in 6.166489279s

• [SLOW TEST:11.409 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  blackbox test
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
    on terminated container
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:129
      should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 17:55:50.881: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-3254
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap configmap-3254/configmap-test-3288de08-0a76-4a66-9245-0df4bf0628f7
STEP: Creating a pod to test consume configMaps
Oct 28 17:55:51.060: INFO: Waiting up to 5m0s for pod "pod-configmaps-83ff05f5-cf90-49f5-8f79-cc51f16932ae" in namespace "configmap-3254" to be "success or failure"
Oct 28 17:55:51.068: INFO: Pod "pod-configmaps-83ff05f5-cf90-49f5-8f79-cc51f16932ae": Phase="Pending", Reason="", readiness=false. Elapsed: 7.817731ms
Oct 28 17:55:53.072: INFO: Pod "pod-configmaps-83ff05f5-cf90-49f5-8f79-cc51f16932ae": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012135556s
Oct 28 17:55:55.077: INFO: Pod "pod-configmaps-83ff05f5-cf90-49f5-8f79-cc51f16932ae": Phase="Pending", Reason="", readiness=false. Elapsed: 4.01670508s
Oct 28 17:55:57.082: INFO: Pod "pod-configmaps-83ff05f5-cf90-49f5-8f79-cc51f16932ae": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.021494004s
STEP: Saw pod success
Oct 28 17:55:57.082: INFO: Pod "pod-configmaps-83ff05f5-cf90-49f5-8f79-cc51f16932ae" satisfied condition "success or failure"
Oct 28 17:55:57.085: INFO: Trying to get logs from node kh4ga-worker-000003 pod pod-configmaps-83ff05f5-cf90-49f5-8f79-cc51f16932ae container env-test: <nil>
STEP: delete the pod
Oct 28 17:55:57.106: INFO: Waiting for pod pod-configmaps-83ff05f5-cf90-49f5-8f79-cc51f16932ae to disappear
Oct 28 17:55:57.111: INFO: Pod pod-configmaps-83ff05f5-cf90-49f5-8f79-cc51f16932ae no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 17:55:57.111: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3254" for this suite.
Oct 28 17:56:03.135: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 17:56:03.296: INFO: namespace configmap-3254 deletion completed in 6.179461395s

• [SLOW TEST:12.416 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 17:56:03.297: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-4383
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0644 on tmpfs
Oct 28 17:56:03.460: INFO: Waiting up to 5m0s for pod "pod-51f9dfa8-6903-4442-9325-45cf91cc7b2f" in namespace "emptydir-4383" to be "success or failure"
Oct 28 17:56:03.475: INFO: Pod "pod-51f9dfa8-6903-4442-9325-45cf91cc7b2f": Phase="Pending", Reason="", readiness=false. Elapsed: 14.530955ms
Oct 28 17:56:05.481: INFO: Pod "pod-51f9dfa8-6903-4442-9325-45cf91cc7b2f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020377376s
Oct 28 17:56:07.486: INFO: Pod "pod-51f9dfa8-6903-4442-9325-45cf91cc7b2f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.025566892s
Oct 28 17:56:09.491: INFO: Pod "pod-51f9dfa8-6903-4442-9325-45cf91cc7b2f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.030119304s
STEP: Saw pod success
Oct 28 17:56:09.491: INFO: Pod "pod-51f9dfa8-6903-4442-9325-45cf91cc7b2f" satisfied condition "success or failure"
Oct 28 17:56:09.494: INFO: Trying to get logs from node kh4ga-worker-000000 pod pod-51f9dfa8-6903-4442-9325-45cf91cc7b2f container test-container: <nil>
STEP: delete the pod
Oct 28 17:56:09.521: INFO: Waiting for pod pod-51f9dfa8-6903-4442-9325-45cf91cc7b2f to disappear
Oct 28 17:56:09.526: INFO: Pod pod-51f9dfa8-6903-4442-9325-45cf91cc7b2f no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 17:56:09.526: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4383" for this suite.
Oct 28 17:56:15.567: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 17:56:15.769: INFO: namespace emptydir-4383 deletion completed in 6.233057669s

• [SLOW TEST:12.473 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 17:56:15.770: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-9272
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-33fc0e2a-d3a6-4692-8eec-fc068806c0d7
STEP: Creating a pod to test consume configMaps
Oct 28 17:56:15.952: INFO: Waiting up to 5m0s for pod "pod-configmaps-610d0895-650a-4e31-b583-86363d4f65e0" in namespace "configmap-9272" to be "success or failure"
Oct 28 17:56:15.964: INFO: Pod "pod-configmaps-610d0895-650a-4e31-b583-86363d4f65e0": Phase="Pending", Reason="", readiness=false. Elapsed: 11.711445ms
Oct 28 17:56:17.968: INFO: Pod "pod-configmaps-610d0895-650a-4e31-b583-86363d4f65e0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016407651s
Oct 28 17:56:19.973: INFO: Pod "pod-configmaps-610d0895-650a-4e31-b583-86363d4f65e0": Phase="Pending", Reason="", readiness=false. Elapsed: 4.021149855s
Oct 28 17:56:21.977: INFO: Pod "pod-configmaps-610d0895-650a-4e31-b583-86363d4f65e0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.025453155s
STEP: Saw pod success
Oct 28 17:56:21.977: INFO: Pod "pod-configmaps-610d0895-650a-4e31-b583-86363d4f65e0" satisfied condition "success or failure"
Oct 28 17:56:21.980: INFO: Trying to get logs from node kh4ga-worker-000003 pod pod-configmaps-610d0895-650a-4e31-b583-86363d4f65e0 container configmap-volume-test: <nil>
STEP: delete the pod
Oct 28 17:56:22.013: INFO: Waiting for pod pod-configmaps-610d0895-650a-4e31-b583-86363d4f65e0 to disappear
Oct 28 17:56:22.020: INFO: Pod pod-configmaps-610d0895-650a-4e31-b583-86363d4f65e0 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 17:56:22.020: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9272" for this suite.
Oct 28 17:56:28.040: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 17:56:28.194: INFO: namespace configmap-9272 deletion completed in 6.167138384s

• [SLOW TEST:12.424 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 17:56:28.194: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-1327
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-03eb902a-fc78-4266-b646-ca76c26e8790
STEP: Creating a pod to test consume secrets
Oct 28 17:56:28.364: INFO: Waiting up to 5m0s for pod "pod-secrets-3386ffa5-d82a-4091-b165-caefd5f99f56" in namespace "secrets-1327" to be "success or failure"
Oct 28 17:56:28.376: INFO: Pod "pod-secrets-3386ffa5-d82a-4091-b165-caefd5f99f56": Phase="Pending", Reason="", readiness=false. Elapsed: 11.109442ms
Oct 28 17:56:30.380: INFO: Pod "pod-secrets-3386ffa5-d82a-4091-b165-caefd5f99f56": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015850038s
Oct 28 17:56:32.385: INFO: Pod "pod-secrets-3386ffa5-d82a-4091-b165-caefd5f99f56": Phase="Pending", Reason="", readiness=false. Elapsed: 4.020832332s
Oct 28 17:56:34.390: INFO: Pod "pod-secrets-3386ffa5-d82a-4091-b165-caefd5f99f56": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.025806025s
STEP: Saw pod success
Oct 28 17:56:34.390: INFO: Pod "pod-secrets-3386ffa5-d82a-4091-b165-caefd5f99f56" satisfied condition "success or failure"
Oct 28 17:56:34.394: INFO: Trying to get logs from node kh4ga-worker-000000 pod pod-secrets-3386ffa5-d82a-4091-b165-caefd5f99f56 container secret-volume-test: <nil>
STEP: delete the pod
Oct 28 17:56:34.422: INFO: Waiting for pod pod-secrets-3386ffa5-d82a-4091-b165-caefd5f99f56 to disappear
Oct 28 17:56:34.442: INFO: Pod pod-secrets-3386ffa5-d82a-4091-b165-caefd5f99f56 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 17:56:34.442: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-1327" for this suite.
Oct 28 17:56:40.463: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 17:56:40.635: INFO: namespace secrets-1327 deletion completed in 6.186826728s

• [SLOW TEST:12.441 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 17:56:40.636: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-8694
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-configmap-5n8d
STEP: Creating a pod to test atomic-volume-subpath
Oct 28 17:56:40.828: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-5n8d" in namespace "subpath-8694" to be "success or failure"
Oct 28 17:56:40.836: INFO: Pod "pod-subpath-test-configmap-5n8d": Phase="Pending", Reason="", readiness=false. Elapsed: 8.610633ms
Oct 28 17:56:42.847: INFO: Pod "pod-subpath-test-configmap-5n8d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019746743s
Oct 28 17:56:44.852: INFO: Pod "pod-subpath-test-configmap-5n8d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.024222126s
Oct 28 17:56:46.857: INFO: Pod "pod-subpath-test-configmap-5n8d": Phase="Running", Reason="", readiness=true. Elapsed: 6.02941541s
Oct 28 17:56:48.863: INFO: Pod "pod-subpath-test-configmap-5n8d": Phase="Running", Reason="", readiness=true. Elapsed: 8.035778797s
Oct 28 17:56:50.868: INFO: Pod "pod-subpath-test-configmap-5n8d": Phase="Running", Reason="", readiness=true. Elapsed: 10.040613676s
Oct 28 17:56:52.873: INFO: Pod "pod-subpath-test-configmap-5n8d": Phase="Running", Reason="", readiness=true. Elapsed: 12.045846856s
Oct 28 17:56:54.879: INFO: Pod "pod-subpath-test-configmap-5n8d": Phase="Running", Reason="", readiness=true. Elapsed: 14.050899933s
Oct 28 17:56:56.884: INFO: Pod "pod-subpath-test-configmap-5n8d": Phase="Running", Reason="", readiness=true. Elapsed: 16.055905309s
Oct 28 17:56:58.888: INFO: Pod "pod-subpath-test-configmap-5n8d": Phase="Running", Reason="", readiness=true. Elapsed: 18.060754482s
Oct 28 17:57:00.893: INFO: Pod "pod-subpath-test-configmap-5n8d": Phase="Running", Reason="", readiness=true. Elapsed: 20.065517253s
Oct 28 17:57:02.898: INFO: Pod "pod-subpath-test-configmap-5n8d": Phase="Running", Reason="", readiness=true. Elapsed: 22.069958922s
Oct 28 17:57:04.903: INFO: Pod "pod-subpath-test-configmap-5n8d": Phase="Running", Reason="", readiness=true. Elapsed: 24.075123292s
Oct 28 17:57:06.908: INFO: Pod "pod-subpath-test-configmap-5n8d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 26.08016566s
STEP: Saw pod success
Oct 28 17:57:06.908: INFO: Pod "pod-subpath-test-configmap-5n8d" satisfied condition "success or failure"
Oct 28 17:57:06.911: INFO: Trying to get logs from node kh4ga-worker-000003 pod pod-subpath-test-configmap-5n8d container test-container-subpath-configmap-5n8d: <nil>
STEP: delete the pod
Oct 28 17:57:06.944: INFO: Waiting for pod pod-subpath-test-configmap-5n8d to disappear
Oct 28 17:57:06.949: INFO: Pod pod-subpath-test-configmap-5n8d no longer exists
STEP: Deleting pod pod-subpath-test-configmap-5n8d
Oct 28 17:57:06.949: INFO: Deleting pod "pod-subpath-test-configmap-5n8d" in namespace "subpath-8694"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 17:57:06.952: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-8694" for this suite.
Oct 28 17:57:12.996: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 17:57:13.202: INFO: namespace subpath-8694 deletion completed in 6.243541168s

• [SLOW TEST:32.566 seconds]
[sig-storage] Subpath
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 17:57:13.202: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-1041
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Oct 28 17:57:13.365: INFO: Pod name rollover-pod: Found 0 pods out of 1
Oct 28 17:57:18.370: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Oct 28 17:57:18.370: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Oct 28 17:57:20.375: INFO: Creating deployment "test-rollover-deployment"
Oct 28 17:57:20.387: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Oct 28 17:57:22.399: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Oct 28 17:57:22.406: INFO: Ensure that both replica sets have 1 created replica
Oct 28 17:57:22.413: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Oct 28 17:57:22.422: INFO: Updating deployment test-rollover-deployment
Oct 28 17:57:22.422: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Oct 28 17:57:24.434: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Oct 28 17:57:24.442: INFO: Make sure deployment "test-rollover-deployment" is complete
Oct 28 17:57:24.449: INFO: all replica sets need to contain the pod-template-hash label
Oct 28 17:57:24.449: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707882240, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707882240, loc:(*time.Location)(0x7ed0a20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707882242, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707882240, loc:(*time.Location)(0x7ed0a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 28 17:57:26.459: INFO: all replica sets need to contain the pod-template-hash label
Oct 28 17:57:26.459: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707882240, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707882240, loc:(*time.Location)(0x7ed0a20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707882242, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707882240, loc:(*time.Location)(0x7ed0a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 28 17:57:28.458: INFO: all replica sets need to contain the pod-template-hash label
Oct 28 17:57:28.458: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707882240, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707882240, loc:(*time.Location)(0x7ed0a20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707882247, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707882240, loc:(*time.Location)(0x7ed0a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 28 17:57:30.457: INFO: all replica sets need to contain the pod-template-hash label
Oct 28 17:57:30.457: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707882240, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707882240, loc:(*time.Location)(0x7ed0a20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707882247, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707882240, loc:(*time.Location)(0x7ed0a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 28 17:57:32.461: INFO: all replica sets need to contain the pod-template-hash label
Oct 28 17:57:32.461: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707882240, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707882240, loc:(*time.Location)(0x7ed0a20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707882247, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707882240, loc:(*time.Location)(0x7ed0a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 28 17:57:34.459: INFO: all replica sets need to contain the pod-template-hash label
Oct 28 17:57:34.459: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707882240, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707882240, loc:(*time.Location)(0x7ed0a20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707882247, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707882240, loc:(*time.Location)(0x7ed0a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 28 17:57:36.458: INFO: all replica sets need to contain the pod-template-hash label
Oct 28 17:57:36.458: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707882240, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707882240, loc:(*time.Location)(0x7ed0a20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707882247, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707882240, loc:(*time.Location)(0x7ed0a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 28 17:57:38.459: INFO: 
Oct 28 17:57:38.459: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
Oct 28 17:57:38.475: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment,GenerateName:,Namespace:deployment-1041,SelfLink:/apis/apps/v1/namespaces/deployment-1041/deployments/test-rollover-deployment,UID:c378f3e8-3d9b-40fa-946d-bafbaed99875,ResourceVersion:21697,Generation:2,CreationTimestamp:2019-10-28 17:57:20 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-10-28 17:57:20 +0000 UTC 2019-10-28 17:57:20 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-10-28 17:57:37 +0000 UTC 2019-10-28 17:57:20 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rollover-deployment-854595fc44" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Oct 28 17:57:38.481: INFO: New ReplicaSet "test-rollover-deployment-854595fc44" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-854595fc44,GenerateName:,Namespace:deployment-1041,SelfLink:/apis/apps/v1/namespaces/deployment-1041/replicasets/test-rollover-deployment-854595fc44,UID:9bc144ef-8ddb-44a3-820d-9b588c7000cf,ResourceVersion:21686,Generation:2,CreationTimestamp:2019-10-28 17:57:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 854595fc44,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment c378f3e8-3d9b-40fa-946d-bafbaed99875 0xc003b27617 0xc003b27618}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 854595fc44,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 854595fc44,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Oct 28 17:57:38.481: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Oct 28 17:57:38.481: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-controller,GenerateName:,Namespace:deployment-1041,SelfLink:/apis/apps/v1/namespaces/deployment-1041/replicasets/test-rollover-controller,UID:03ae7bfc-acd7-46ac-9c43-e6b33fdc4a8e,ResourceVersion:21696,Generation:2,CreationTimestamp:2019-10-28 17:57:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment c378f3e8-3d9b-40fa-946d-bafbaed99875 0xc003b27547 0xc003b27548}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Oct 28 17:57:38.481: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-9b8b997cf,GenerateName:,Namespace:deployment-1041,SelfLink:/apis/apps/v1/namespaces/deployment-1041/replicasets/test-rollover-deployment-9b8b997cf,UID:cca27d65-9bb7-4f54-9039-d2c2d185b4f1,ResourceVersion:21641,Generation:2,CreationTimestamp:2019-10-28 17:57:20 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 9b8b997cf,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment c378f3e8-3d9b-40fa-946d-bafbaed99875 0xc003b276e0 0xc003b276e1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 9b8b997cf,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 9b8b997cf,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Oct 28 17:57:38.485: INFO: Pod "test-rollover-deployment-854595fc44-twrpk" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-854595fc44-twrpk,GenerateName:test-rollover-deployment-854595fc44-,Namespace:deployment-1041,SelfLink:/api/v1/namespaces/deployment-1041/pods/test-rollover-deployment-854595fc44-twrpk,UID:3385a03a-16fd-4f7f-a6a6-d413f4c45111,ResourceVersion:21667,Generation:0,CreationTimestamp:2019-10-28 17:57:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 854595fc44,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.2.131.133/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-rollover-deployment-854595fc44 9bc144ef-8ddb-44a3-820d-9b588c7000cf 0xc000d30347 0xc000d30348}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-w7tzg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-w7tzg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-w7tzg true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kh4ga-worker-000003,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000d303b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000d303d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-28 17:57:22 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-10-28 17:57:27 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-10-28 17:57:27 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-28 17:57:22 +0000 UTC  }],Message:,Reason:,HostIP:10.2.1.7,PodIP:10.2.131.133,StartTime:2019-10-28 17:57:22 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-10-28 17:57:27 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://c614082213e0c4aa9216bb07b110619d5ac203534b3cc208c03f4e59f8117001}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 17:57:38.485: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-1041" for this suite.
Oct 28 17:57:44.514: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 17:57:44.675: INFO: namespace deployment-1041 deletion completed in 6.182773865s

• [SLOW TEST:31.473 seconds]
[sig-apps] Deployment
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support rollover [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 17:57:44.675: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-6302
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
Oct 28 17:57:50.924: INFO: 0 pods remaining
Oct 28 17:57:50.924: INFO: 0 pods has nil DeletionTimestamp
Oct 28 17:57:50.924: INFO: 
STEP: Gathering metrics
Oct 28 17:57:51.871: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W1028 17:57:51.871691      19 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 17:57:51.871: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-6302" for this suite.
Oct 28 17:57:57.895: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 17:57:58.056: INFO: namespace gc-6302 deletion completed in 6.180320127s

• [SLOW TEST:13.382 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 17:57:58.057: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-5196
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0666 on tmpfs
Oct 28 17:57:58.227: INFO: Waiting up to 5m0s for pod "pod-71787821-67d0-4c07-9501-7a924123b399" in namespace "emptydir-5196" to be "success or failure"
Oct 28 17:57:58.232: INFO: Pod "pod-71787821-67d0-4c07-9501-7a924123b399": Phase="Pending", Reason="", readiness=false. Elapsed: 4.907519ms
Oct 28 17:58:00.236: INFO: Pod "pod-71787821-67d0-4c07-9501-7a924123b399": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009101445s
Oct 28 17:58:02.252: INFO: Pod "pod-71787821-67d0-4c07-9501-7a924123b399": Phase="Pending", Reason="", readiness=false. Elapsed: 4.025341616s
Oct 28 17:58:04.257: INFO: Pod "pod-71787821-67d0-4c07-9501-7a924123b399": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.029959442s
STEP: Saw pod success
Oct 28 17:58:04.257: INFO: Pod "pod-71787821-67d0-4c07-9501-7a924123b399" satisfied condition "success or failure"
Oct 28 17:58:04.261: INFO: Trying to get logs from node kh4ga-worker-000003 pod pod-71787821-67d0-4c07-9501-7a924123b399 container test-container: <nil>
STEP: delete the pod
Oct 28 17:58:04.287: INFO: Waiting for pod pod-71787821-67d0-4c07-9501-7a924123b399 to disappear
Oct 28 17:58:04.294: INFO: Pod pod-71787821-67d0-4c07-9501-7a924123b399 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 17:58:04.294: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5196" for this suite.
Oct 28 17:58:10.313: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 17:58:10.474: INFO: namespace emptydir-5196 deletion completed in 6.174060077s

• [SLOW TEST:12.417 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Delete Grace Period 
  should be submitted and removed [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 17:58:10.474: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-2201
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Delete Grace Period
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:47
[It] should be submitted and removed [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: setting up selector
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
Oct 28 17:58:14.673: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-124947935 proxy -p 0'
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
Oct 28 17:58:34.759: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 17:58:34.763: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-2201" for this suite.
Oct 28 17:58:40.785: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 17:58:40.949: INFO: namespace pods-2201 deletion completed in 6.182128246s

• [SLOW TEST:30.475 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  [k8s.io] Delete Grace Period
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should be submitted and removed [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 17:58:40.949: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-7572
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating the pod
Oct 28 17:58:47.654: INFO: Successfully updated pod "labelsupdateecf86ab8-084b-45ff-a3b7-25992ccef610"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 17:58:49.674: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7572" for this suite.
Oct 28 17:59:11.694: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 17:59:11.851: INFO: namespace downward-api-7572 deletion completed in 22.171054931s

• [SLOW TEST:30.902 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 17:59:11.851: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-5899
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-5899
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a new StatefulSet
Oct 28 17:59:12.031: INFO: Found 0 stateful pods, waiting for 3
Oct 28 17:59:22.037: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Oct 28 17:59:22.037: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Oct 28 17:59:22.037: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Pending - Ready=false
Oct 28 17:59:32.037: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Oct 28 17:59:32.037: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Oct 28 17:59:32.037: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Oct 28 17:59:32.048: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-124947935 exec --namespace=statefulset-5899 ss2-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Oct 28 17:59:32.250: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Oct 28 17:59:32.250: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Oct 28 17:59:32.250: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Oct 28 17:59:42.287: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Oct 28 17:59:52.314: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-124947935 exec --namespace=statefulset-5899 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 28 17:59:52.518: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Oct 28 17:59:52.518: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Oct 28 17:59:52.518: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Oct 28 18:00:02.550: INFO: Waiting for StatefulSet statefulset-5899/ss2 to complete update
Oct 28 18:00:02.550: INFO: Waiting for Pod statefulset-5899/ss2-0 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Oct 28 18:00:02.550: INFO: Waiting for Pod statefulset-5899/ss2-1 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Oct 28 18:00:02.550: INFO: Waiting for Pod statefulset-5899/ss2-2 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Oct 28 18:00:12.559: INFO: Waiting for StatefulSet statefulset-5899/ss2 to complete update
Oct 28 18:00:12.559: INFO: Waiting for Pod statefulset-5899/ss2-0 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Oct 28 18:00:12.559: INFO: Waiting for Pod statefulset-5899/ss2-1 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Oct 28 18:00:22.559: INFO: Waiting for StatefulSet statefulset-5899/ss2 to complete update
Oct 28 18:00:22.559: INFO: Waiting for Pod statefulset-5899/ss2-0 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Oct 28 18:00:22.559: INFO: Waiting for Pod statefulset-5899/ss2-1 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Oct 28 18:00:32.559: INFO: Waiting for StatefulSet statefulset-5899/ss2 to complete update
Oct 28 18:00:32.559: INFO: Waiting for Pod statefulset-5899/ss2-0 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
STEP: Rolling back to a previous revision
Oct 28 18:00:42.559: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-124947935 exec --namespace=statefulset-5899 ss2-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Oct 28 18:00:43.461: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Oct 28 18:00:43.461: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Oct 28 18:00:43.461: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Oct 28 18:00:53.498: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Oct 28 18:01:03.530: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-124947935 exec --namespace=statefulset-5899 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 28 18:01:03.730: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Oct 28 18:01:03.730: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Oct 28 18:01:03.730: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Oct 28 18:01:13.756: INFO: Waiting for StatefulSet statefulset-5899/ss2 to complete update
Oct 28 18:01:13.756: INFO: Waiting for Pod statefulset-5899/ss2-0 to have revision ss2-7c9b54fd4c update revision ss2-6c5cd755cd
Oct 28 18:01:13.756: INFO: Waiting for Pod statefulset-5899/ss2-1 to have revision ss2-7c9b54fd4c update revision ss2-6c5cd755cd
Oct 28 18:01:13.756: INFO: Waiting for Pod statefulset-5899/ss2-2 to have revision ss2-7c9b54fd4c update revision ss2-6c5cd755cd
Oct 28 18:01:23.765: INFO: Waiting for StatefulSet statefulset-5899/ss2 to complete update
Oct 28 18:01:23.765: INFO: Waiting for Pod statefulset-5899/ss2-0 to have revision ss2-7c9b54fd4c update revision ss2-6c5cd755cd
Oct 28 18:01:23.765: INFO: Waiting for Pod statefulset-5899/ss2-1 to have revision ss2-7c9b54fd4c update revision ss2-6c5cd755cd
Oct 28 18:01:33.765: INFO: Waiting for StatefulSet statefulset-5899/ss2 to complete update
Oct 28 18:01:33.765: INFO: Waiting for Pod statefulset-5899/ss2-0 to have revision ss2-7c9b54fd4c update revision ss2-6c5cd755cd
Oct 28 18:01:33.765: INFO: Waiting for Pod statefulset-5899/ss2-1 to have revision ss2-7c9b54fd4c update revision ss2-6c5cd755cd
Oct 28 18:01:43.764: INFO: Waiting for StatefulSet statefulset-5899/ss2 to complete update
Oct 28 18:01:43.764: INFO: Waiting for Pod statefulset-5899/ss2-0 to have revision ss2-7c9b54fd4c update revision ss2-6c5cd755cd
Oct 28 18:01:53.766: INFO: Waiting for StatefulSet statefulset-5899/ss2 to complete update
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Oct 28 18:02:03.765: INFO: Deleting all statefulset in ns statefulset-5899
Oct 28 18:02:03.768: INFO: Scaling statefulset ss2 to 0
Oct 28 18:02:33.792: INFO: Waiting for statefulset status.replicas updated to 0
Oct 28 18:02:33.796: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 18:02:33.824: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-5899" for this suite.
Oct 28 18:02:39.855: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 18:02:40.010: INFO: namespace statefulset-5899 deletion completed in 6.174460365s

• [SLOW TEST:208.159 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] version v1
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 18:02:40.010: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-33
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Oct 28 18:02:40.170: INFO: (0) /api/v1/nodes/kh4ga-worker-000000:10250/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 6.465731ms)
Oct 28 18:02:40.176: INFO: (1) /api/v1/nodes/kh4ga-worker-000000:10250/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 5.543427ms)
Oct 28 18:02:40.181: INFO: (2) /api/v1/nodes/kh4ga-worker-000000:10250/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 5.736627ms)
Oct 28 18:02:40.188: INFO: (3) /api/v1/nodes/kh4ga-worker-000000:10250/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 6.625132ms)
Oct 28 18:02:40.205: INFO: (4) /api/v1/nodes/kh4ga-worker-000000:10250/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 16.599679ms)
Oct 28 18:02:40.211: INFO: (5) /api/v1/nodes/kh4ga-worker-000000:10250/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 5.847627ms)
Oct 28 18:02:40.216: INFO: (6) /api/v1/nodes/kh4ga-worker-000000:10250/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 5.497427ms)
Oct 28 18:02:40.222: INFO: (7) /api/v1/nodes/kh4ga-worker-000000:10250/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 5.787527ms)
Oct 28 18:02:40.227: INFO: (8) /api/v1/nodes/kh4ga-worker-000000:10250/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 5.609027ms)
Oct 28 18:02:40.233: INFO: (9) /api/v1/nodes/kh4ga-worker-000000:10250/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 5.870028ms)
Oct 28 18:02:40.239: INFO: (10) /api/v1/nodes/kh4ga-worker-000000:10250/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 6.005228ms)
Oct 28 18:02:40.245: INFO: (11) /api/v1/nodes/kh4ga-worker-000000:10250/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 5.668027ms)
Oct 28 18:02:40.251: INFO: (12) /api/v1/nodes/kh4ga-worker-000000:10250/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 6.009928ms)
Oct 28 18:02:40.258: INFO: (13) /api/v1/nodes/kh4ga-worker-000000:10250/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 6.716432ms)
Oct 28 18:02:40.264: INFO: (14) /api/v1/nodes/kh4ga-worker-000000:10250/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 6.088528ms)
Oct 28 18:02:40.270: INFO: (15) /api/v1/nodes/kh4ga-worker-000000:10250/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 5.913128ms)
Oct 28 18:02:40.276: INFO: (16) /api/v1/nodes/kh4ga-worker-000000:10250/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 6.041128ms)
Oct 28 18:02:40.282: INFO: (17) /api/v1/nodes/kh4ga-worker-000000:10250/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 5.814927ms)
Oct 28 18:02:40.288: INFO: (18) /api/v1/nodes/kh4ga-worker-000000:10250/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 6.450431ms)
Oct 28 18:02:40.294: INFO: (19) /api/v1/nodes/kh4ga-worker-000000:10250/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 5.684427ms)
[AfterEach] version v1
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 18:02:40.294: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-33" for this suite.
Oct 28 18:02:46.314: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 18:02:46.481: INFO: namespace proxy-33 deletion completed in 6.182401127s

• [SLOW TEST:6.471 seconds]
[sig-network] Proxy
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:58
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 18:02:46.481: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-7246
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Oct 28 18:02:46.683: INFO: Creating deployment "test-recreate-deployment"
Oct 28 18:02:46.688: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Oct 28 18:02:46.701: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
Oct 28 18:02:48.716: INFO: Waiting deployment "test-recreate-deployment" to complete
Oct 28 18:02:48.720: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707882566, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707882566, loc:(*time.Location)(0x7ed0a20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707882566, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707882566, loc:(*time.Location)(0x7ed0a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-6df85df6b9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 28 18:02:50.725: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707882566, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707882566, loc:(*time.Location)(0x7ed0a20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707882566, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707882566, loc:(*time.Location)(0x7ed0a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-6df85df6b9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 28 18:02:52.726: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Oct 28 18:02:52.736: INFO: Updating deployment test-recreate-deployment
Oct 28 18:02:52.736: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
Oct 28 18:02:52.867: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment,GenerateName:,Namespace:deployment-7246,SelfLink:/apis/apps/v1/namespaces/deployment-7246/deployments/test-recreate-deployment,UID:dbba955d-f407-4e84-8b16-2c7e2903f5d8,ResourceVersion:22911,Generation:2,CreationTimestamp:2019-10-28 18:02:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[{Available False 2019-10-28 18:02:52 +0000 UTC 2019-10-28 18:02:52 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-10-28 18:02:52 +0000 UTC 2019-10-28 18:02:46 +0000 UTC ReplicaSetUpdated ReplicaSet "test-recreate-deployment-5c8c9cc69d" is progressing.}],ReadyReplicas:0,CollisionCount:nil,},}

Oct 28 18:02:52.871: INFO: New ReplicaSet "test-recreate-deployment-5c8c9cc69d" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-5c8c9cc69d,GenerateName:,Namespace:deployment-7246,SelfLink:/apis/apps/v1/namespaces/deployment-7246/replicasets/test-recreate-deployment-5c8c9cc69d,UID:0aa877e3-e3c6-465a-8d3a-b8aa2af804ab,ResourceVersion:22910,Generation:1,CreationTimestamp:2019-10-28 18:02:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5c8c9cc69d,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment dbba955d-f407-4e84-8b16-2c7e2903f5d8 0xc000d37d07 0xc000d37d08}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 5c8c9cc69d,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5c8c9cc69d,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Oct 28 18:02:52.871: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Oct 28 18:02:52.871: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-6df85df6b9,GenerateName:,Namespace:deployment-7246,SelfLink:/apis/apps/v1/namespaces/deployment-7246/replicasets/test-recreate-deployment-6df85df6b9,UID:9f0c695a-3dce-408a-83bb-2439362f5c3b,ResourceVersion:22899,Generation:2,CreationTimestamp:2019-10-28 18:02:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 6df85df6b9,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment dbba955d-f407-4e84-8b16-2c7e2903f5d8 0xc000d37e37 0xc000d37e38}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 6df85df6b9,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 6df85df6b9,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Oct 28 18:02:52.875: INFO: Pod "test-recreate-deployment-5c8c9cc69d-vd55m" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-5c8c9cc69d-vd55m,GenerateName:test-recreate-deployment-5c8c9cc69d-,Namespace:deployment-7246,SelfLink:/api/v1/namespaces/deployment-7246/pods/test-recreate-deployment-5c8c9cc69d-vd55m,UID:8035821c-2a1b-4589-a042-1acfbf4d134b,ResourceVersion:22909,Generation:0,CreationTimestamp:2019-10-28 18:02:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5c8c9cc69d,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-recreate-deployment-5c8c9cc69d 0aa877e3-e3c6-465a-8d3a-b8aa2af804ab 0xc000586227 0xc000586228}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-9ztrk {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9ztrk,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-9ztrk true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kh4ga-worker-000000,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0005862d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000586330}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-28 18:02:52 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-28 18:02:52 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-28 18:02:52 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-28 18:02:52 +0000 UTC  }],Message:,Reason:,HostIP:10.2.1.4,PodIP:,StartTime:2019-10-28 18:02:52 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 18:02:52.875: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-7246" for this suite.
Oct 28 18:02:58.900: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 18:02:59.061: INFO: namespace deployment-7246 deletion completed in 6.176294556s

• [SLOW TEST:12.580 seconds]
[sig-apps] Deployment
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 18:02:59.062: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7641
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Oct 28 18:02:59.227: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0c25fcb3-dfae-42c0-8182-6dae63778772" in namespace "projected-7641" to be "success or failure"
Oct 28 18:02:59.232: INFO: Pod "downwardapi-volume-0c25fcb3-dfae-42c0-8182-6dae63778772": Phase="Pending", Reason="", readiness=false. Elapsed: 4.487922ms
Oct 28 18:03:01.236: INFO: Pod "downwardapi-volume-0c25fcb3-dfae-42c0-8182-6dae63778772": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009160969s
Oct 28 18:03:03.291: INFO: Pod "downwardapi-volume-0c25fcb3-dfae-42c0-8182-6dae63778772": Phase="Pending", Reason="", readiness=false. Elapsed: 4.064156446s
Oct 28 18:03:05.303: INFO: Pod "downwardapi-volume-0c25fcb3-dfae-42c0-8182-6dae63778772": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.075744312s
STEP: Saw pod success
Oct 28 18:03:05.303: INFO: Pod "downwardapi-volume-0c25fcb3-dfae-42c0-8182-6dae63778772" satisfied condition "success or failure"
Oct 28 18:03:05.308: INFO: Trying to get logs from node kh4ga-worker-000003 pod downwardapi-volume-0c25fcb3-dfae-42c0-8182-6dae63778772 container client-container: <nil>
STEP: delete the pod
Oct 28 18:03:05.358: INFO: Waiting for pod downwardapi-volume-0c25fcb3-dfae-42c0-8182-6dae63778772 to disappear
Oct 28 18:03:05.361: INFO: Pod downwardapi-volume-0c25fcb3-dfae-42c0-8182-6dae63778772 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 18:03:05.361: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7641" for this suite.
Oct 28 18:03:11.383: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 18:03:11.547: INFO: namespace projected-7641 deletion completed in 6.179995834s

• [SLOW TEST:12.485 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 18:03:11.548: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-9189
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:81
Oct 28 18:03:11.704: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Oct 28 18:03:11.728: INFO: Waiting for terminating namespaces to be deleted...
Oct 28 18:03:11.732: INFO: 
Logging pods the kubelet thinks is on node kh4ga-worker-000000 before test
Oct 28 18:03:11.745: INFO: node-exporter-94ffd from kube-system started at 2019-10-28 16:25:51 +0000 UTC (1 container statuses recorded)
Oct 28 18:03:11.745: INFO: 	Container node-exporter ready: true, restart count 0
Oct 28 18:03:11.745: INFO: external-dns-769446d578-7lh6n from kube-system started at 2019-10-28 16:26:07 +0000 UTC (1 container statuses recorded)
Oct 28 18:03:11.745: INFO: 	Container external-dns ready: true, restart count 0
Oct 28 18:03:11.745: INFO: sonobuoy-systemd-logs-daemon-set-80aafb278b8f4e15-fhxc7 from sonobuoy started at 2019-10-28 16:31:37 +0000 UTC (2 container statuses recorded)
Oct 28 18:03:11.745: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Oct 28 18:03:11.745: INFO: 	Container systemd-logs ready: true, restart count 1
Oct 28 18:03:11.745: INFO: coredns-7b76874c7b-hnw8g from kube-system started at 2019-10-28 16:25:57 +0000 UTC (1 container statuses recorded)
Oct 28 18:03:11.745: INFO: 	Container coredns ready: true, restart count 0
Oct 28 18:03:11.745: INFO: cert-exporter-7zznl from kube-system started at 2019-10-28 16:26:11 +0000 UTC (1 container statuses recorded)
Oct 28 18:03:11.745: INFO: 	Container cert-exporter ready: true, restart count 0
Oct 28 18:03:11.745: INFO: sonobuoy-e2e-job-2b01bf00cc914c5a from sonobuoy started at 2019-10-28 16:31:37 +0000 UTC (2 container statuses recorded)
Oct 28 18:03:11.745: INFO: 	Container e2e ready: true, restart count 0
Oct 28 18:03:11.745: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct 28 18:03:11.745: INFO: calico-node-bqrms from kube-system started at 2019-10-28 16:23:02 +0000 UTC (1 container statuses recorded)
Oct 28 18:03:11.745: INFO: 	Container calico-node ready: true, restart count 0
Oct 28 18:03:11.745: INFO: kube-proxy-5r5g9 from kube-system started at 2019-10-28 16:23:02 +0000 UTC (1 container statuses recorded)
Oct 28 18:03:11.745: INFO: 	Container kube-proxy ready: true, restart count 0
Oct 28 18:03:11.745: INFO: net-exporter-v94hf from kube-system started at 2019-10-28 16:26:19 +0000 UTC (1 container statuses recorded)
Oct 28 18:03:11.745: INFO: 	Container net-exporter ready: true, restart count 0
Oct 28 18:03:11.745: INFO: nginx-ingress-controller-6b49fc4779-46b6j from kube-system started at 2019-10-28 16:26:20 +0000 UTC (1 container statuses recorded)
Oct 28 18:03:11.745: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Oct 28 18:03:11.745: INFO: sonobuoy from sonobuoy started at 2019-10-28 16:31:26 +0000 UTC (1 container statuses recorded)
Oct 28 18:03:11.745: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Oct 28 18:03:11.745: INFO: 
Logging pods the kubelet thinks is on node kh4ga-worker-000002 before test
Oct 28 18:03:11.756: INFO: net-exporter-rb7qj from kube-system started at 2019-10-28 16:26:20 +0000 UTC (1 container statuses recorded)
Oct 28 18:03:11.756: INFO: 	Container net-exporter ready: true, restart count 0
Oct 28 18:03:11.756: INFO: tiller-deploy-5db95cf576-tbgkz from giantswarm started at 2019-10-28 16:23:58 +0000 UTC (1 container statuses recorded)
Oct 28 18:03:11.756: INFO: 	Container tiller ready: true, restart count 0
Oct 28 18:03:11.756: INFO: node-exporter-b29jz from kube-system started at 2019-10-28 16:25:51 +0000 UTC (1 container statuses recorded)
Oct 28 18:03:11.756: INFO: 	Container node-exporter ready: true, restart count 0
Oct 28 18:03:11.756: INFO: calico-node-wzq68 from kube-system started at 2019-10-28 16:22:57 +0000 UTC (1 container statuses recorded)
Oct 28 18:03:11.756: INFO: 	Container calico-node ready: true, restart count 0
Oct 28 18:03:11.756: INFO: chart-operator-7dcfd7559b-4xhkx from giantswarm started at 2019-10-28 16:25:53 +0000 UTC (1 container statuses recorded)
Oct 28 18:03:11.756: INFO: 	Container chart-operator ready: true, restart count 0
Oct 28 18:03:11.756: INFO: cert-exporter-shzc7 from kube-system started at 2019-10-28 16:26:17 +0000 UTC (1 container statuses recorded)
Oct 28 18:03:11.756: INFO: 	Container cert-exporter ready: true, restart count 0
Oct 28 18:03:11.756: INFO: kube-proxy-hcbz2 from kube-system started at 2019-10-28 16:22:57 +0000 UTC (1 container statuses recorded)
Oct 28 18:03:11.756: INFO: 	Container kube-proxy ready: true, restart count 0
Oct 28 18:03:11.756: INFO: nginx-ingress-controller-6b49fc4779-t5skf from kube-system started at 2019-10-28 16:26:20 +0000 UTC (1 container statuses recorded)
Oct 28 18:03:11.756: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Oct 28 18:03:11.756: INFO: sonobuoy-systemd-logs-daemon-set-80aafb278b8f4e15-wqcmm from sonobuoy started at 2019-10-28 16:31:37 +0000 UTC (2 container statuses recorded)
Oct 28 18:03:11.756: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Oct 28 18:03:11.756: INFO: 	Container systemd-logs ready: true, restart count 1
Oct 28 18:03:11.756: INFO: kube-state-metrics-586fbd9595-r5656 from kube-system started at 2019-10-28 16:26:10 +0000 UTC (2 container statuses recorded)
Oct 28 18:03:11.756: INFO: 	Container addon-resizer ready: true, restart count 0
Oct 28 18:03:11.756: INFO: 	Container kube-state-metrics ready: true, restart count 0
Oct 28 18:03:11.756: INFO: 
Logging pods the kubelet thinks is on node kh4ga-worker-000003 before test
Oct 28 18:03:11.767: INFO: node-exporter-4q9vs from kube-system started at 2019-10-28 16:25:51 +0000 UTC (1 container statuses recorded)
Oct 28 18:03:11.767: INFO: 	Container node-exporter ready: true, restart count 0
Oct 28 18:03:11.767: INFO: calico-node-sxmff from kube-system started at 2019-10-28 16:23:07 +0000 UTC (1 container statuses recorded)
Oct 28 18:03:11.767: INFO: 	Container calico-node ready: true, restart count 0
Oct 28 18:03:11.767: INFO: sonobuoy-systemd-logs-daemon-set-80aafb278b8f4e15-rvx7d from sonobuoy started at 2019-10-28 16:31:37 +0000 UTC (2 container statuses recorded)
Oct 28 18:03:11.767: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Oct 28 18:03:11.767: INFO: 	Container systemd-logs ready: true, restart count 1
Oct 28 18:03:11.767: INFO: cert-exporter-cjdz5 from kube-system started at 2019-10-28 16:26:16 +0000 UTC (1 container statuses recorded)
Oct 28 18:03:11.767: INFO: 	Container cert-exporter ready: true, restart count 0
Oct 28 18:03:11.767: INFO: nginx-ingress-controller-6b49fc4779-ddjkh from kube-system started at 2019-10-28 16:26:20 +0000 UTC (1 container statuses recorded)
Oct 28 18:03:11.767: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Oct 28 18:03:11.767: INFO: metrics-server-586d4684b4-qh7rw from kube-system started at 2019-10-28 16:25:49 +0000 UTC (1 container statuses recorded)
Oct 28 18:03:11.767: INFO: 	Container metrics-server ready: true, restart count 0
Oct 28 18:03:11.767: INFO: coredns-7b76874c7b-654r4 from kube-system started at 2019-10-28 16:25:59 +0000 UTC (1 container statuses recorded)
Oct 28 18:03:11.767: INFO: 	Container coredns ready: true, restart count 0
Oct 28 18:03:11.767: INFO: kube-proxy-lc8jd from kube-system started at 2019-10-28 16:23:07 +0000 UTC (1 container statuses recorded)
Oct 28 18:03:11.767: INFO: 	Container kube-proxy ready: true, restart count 0
Oct 28 18:03:11.767: INFO: net-exporter-vhl5t from kube-system started at 2019-10-28 16:26:19 +0000 UTC (1 container statuses recorded)
Oct 28 18:03:11.767: INFO: 	Container net-exporter ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-d3dd04e9-8cad-4877-a981-c3b087a8f91a 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-d3dd04e9-8cad-4877-a981-c3b087a8f91a off the node kh4ga-worker-000000
STEP: verifying the node doesn't have the label kubernetes.io/e2e-d3dd04e9-8cad-4877-a981-c3b087a8f91a
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 18:03:23.889: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-9189" for this suite.
Oct 28 18:03:33.920: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 18:03:34.098: INFO: namespace sched-pred-9189 deletion completed in 10.200481958s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:72

• [SLOW TEST:22.550 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] version v1
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 18:03:34.098: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-7037
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Oct 28 18:03:34.329: INFO: (0) /api/v1/nodes/kh4ga-worker-000000/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 7.025833ms)
Oct 28 18:03:34.335: INFO: (1) /api/v1/nodes/kh4ga-worker-000000/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 5.611327ms)
Oct 28 18:03:34.341: INFO: (2) /api/v1/nodes/kh4ga-worker-000000/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 5.922627ms)
Oct 28 18:03:34.348: INFO: (3) /api/v1/nodes/kh4ga-worker-000000/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 7.419135ms)
Oct 28 18:03:34.354: INFO: (4) /api/v1/nodes/kh4ga-worker-000000/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 5.903628ms)
Oct 28 18:03:34.360: INFO: (5) /api/v1/nodes/kh4ga-worker-000000/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 6.189129ms)
Oct 28 18:03:34.366: INFO: (6) /api/v1/nodes/kh4ga-worker-000000/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 5.966927ms)
Oct 28 18:03:34.373: INFO: (7) /api/v1/nodes/kh4ga-worker-000000/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 6.379029ms)
Oct 28 18:03:34.379: INFO: (8) /api/v1/nodes/kh4ga-worker-000000/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 5.944428ms)
Oct 28 18:03:34.386: INFO: (9) /api/v1/nodes/kh4ga-worker-000000/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 6.744632ms)
Oct 28 18:03:34.391: INFO: (10) /api/v1/nodes/kh4ga-worker-000000/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 5.563426ms)
Oct 28 18:03:34.397: INFO: (11) /api/v1/nodes/kh4ga-worker-000000/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 5.711327ms)
Oct 28 18:03:34.404: INFO: (12) /api/v1/nodes/kh4ga-worker-000000/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 6.659931ms)
Oct 28 18:03:34.409: INFO: (13) /api/v1/nodes/kh4ga-worker-000000/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 5.428025ms)
Oct 28 18:03:34.418: INFO: (14) /api/v1/nodes/kh4ga-worker-000000/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 8.67724ms)
Oct 28 18:03:34.424: INFO: (15) /api/v1/nodes/kh4ga-worker-000000/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 6.309629ms)
Oct 28 18:03:34.430: INFO: (16) /api/v1/nodes/kh4ga-worker-000000/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 5.523926ms)
Oct 28 18:03:34.436: INFO: (17) /api/v1/nodes/kh4ga-worker-000000/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 6.44433ms)
Oct 28 18:03:34.442: INFO: (18) /api/v1/nodes/kh4ga-worker-000000/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 6.021828ms)
Oct 28 18:03:34.448: INFO: (19) /api/v1/nodes/kh4ga-worker-000000/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 5.879828ms)
[AfterEach] version v1
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 18:03:34.448: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-7037" for this suite.
Oct 28 18:03:40.470: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 18:03:40.623: INFO: namespace proxy-7037 deletion completed in 6.170080178s

• [SLOW TEST:6.525 seconds]
[sig-network] Proxy
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:58
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 18:03:40.623: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-9091
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Oct 28 18:03:40.782: INFO: Waiting up to 5m0s for pod "downwardapi-volume-31dc4cca-bfb9-4137-80e2-1befcbfe300e" in namespace "downward-api-9091" to be "success or failure"
Oct 28 18:03:40.789: INFO: Pod "downwardapi-volume-31dc4cca-bfb9-4137-80e2-1befcbfe300e": Phase="Pending", Reason="", readiness=false. Elapsed: 7.664936ms
Oct 28 18:03:42.793: INFO: Pod "downwardapi-volume-31dc4cca-bfb9-4137-80e2-1befcbfe300e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011704636s
Oct 28 18:03:44.799: INFO: Pod "downwardapi-volume-31dc4cca-bfb9-4137-80e2-1befcbfe300e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.017154937s
Oct 28 18:03:46.820: INFO: Pod "downwardapi-volume-31dc4cca-bfb9-4137-80e2-1befcbfe300e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.038346803s
STEP: Saw pod success
Oct 28 18:03:46.820: INFO: Pod "downwardapi-volume-31dc4cca-bfb9-4137-80e2-1befcbfe300e" satisfied condition "success or failure"
Oct 28 18:03:46.823: INFO: Trying to get logs from node kh4ga-worker-000000 pod downwardapi-volume-31dc4cca-bfb9-4137-80e2-1befcbfe300e container client-container: <nil>
STEP: delete the pod
Oct 28 18:03:46.854: INFO: Waiting for pod downwardapi-volume-31dc4cca-bfb9-4137-80e2-1befcbfe300e to disappear
Oct 28 18:03:46.861: INFO: Pod downwardapi-volume-31dc4cca-bfb9-4137-80e2-1befcbfe300e no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 18:03:46.861: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9091" for this suite.
Oct 28 18:03:52.883: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 18:03:53.054: INFO: namespace downward-api-9091 deletion completed in 6.185913324s

• [SLOW TEST:12.431 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 18:03:53.055: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-8679
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir volume type on node default medium
Oct 28 18:03:53.231: INFO: Waiting up to 5m0s for pod "pod-c141d360-d18e-44df-bb76-3e9360d53fb0" in namespace "emptydir-8679" to be "success or failure"
Oct 28 18:03:53.239: INFO: Pod "pod-c141d360-d18e-44df-bb76-3e9360d53fb0": Phase="Pending", Reason="", readiness=false. Elapsed: 7.461534ms
Oct 28 18:03:55.252: INFO: Pod "pod-c141d360-d18e-44df-bb76-3e9360d53fb0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021210938s
Oct 28 18:03:57.258: INFO: Pod "pod-c141d360-d18e-44df-bb76-3e9360d53fb0": Phase="Pending", Reason="", readiness=false. Elapsed: 4.026462797s
Oct 28 18:03:59.263: INFO: Pod "pod-c141d360-d18e-44df-bb76-3e9360d53fb0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.031671649s
STEP: Saw pod success
Oct 28 18:03:59.263: INFO: Pod "pod-c141d360-d18e-44df-bb76-3e9360d53fb0" satisfied condition "success or failure"
Oct 28 18:03:59.266: INFO: Trying to get logs from node kh4ga-worker-000000 pod pod-c141d360-d18e-44df-bb76-3e9360d53fb0 container test-container: <nil>
STEP: delete the pod
Oct 28 18:03:59.291: INFO: Waiting for pod pod-c141d360-d18e-44df-bb76-3e9360d53fb0 to disappear
Oct 28 18:03:59.307: INFO: Pod pod-c141d360-d18e-44df-bb76-3e9360d53fb0 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 18:03:59.307: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8679" for this suite.
Oct 28 18:04:05.338: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 18:04:05.504: INFO: namespace emptydir-8679 deletion completed in 6.19017322s

• [SLOW TEST:12.450 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 18:04:05.505: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-5333
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Performing setup for networking test in namespace pod-network-test-5333
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Oct 28 18:04:05.651: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Oct 28 18:04:37.773: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.2.129.45:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-5333 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 28 18:04:37.773: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
Oct 28 18:04:37.907: INFO: Found all expected endpoints: [netserver-0]
Oct 28 18:04:37.910: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.2.130.145:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-5333 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 28 18:04:37.910: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
Oct 28 18:04:38.034: INFO: Found all expected endpoints: [netserver-1]
Oct 28 18:04:38.038: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.2.131.143:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-5333 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 28 18:04:38.038: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
Oct 28 18:04:38.168: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 18:04:38.168: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-5333" for this suite.
Oct 28 18:05:00.192: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 18:05:00.364: INFO: namespace pod-network-test-5333 deletion completed in 22.188850044s

• [SLOW TEST:54.859 seconds]
[sig-network] Networking
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 18:05:00.365: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2633
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-a3fce646-594a-4f52-abbf-02d6d2ae2b6e
STEP: Creating a pod to test consume secrets
Oct 28 18:05:00.542: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-26252b30-0d7a-4f8b-8e0c-ce443272e796" in namespace "projected-2633" to be "success or failure"
Oct 28 18:05:00.547: INFO: Pod "pod-projected-secrets-26252b30-0d7a-4f8b-8e0c-ce443272e796": Phase="Pending", Reason="", readiness=false. Elapsed: 4.808022ms
Oct 28 18:05:02.552: INFO: Pod "pod-projected-secrets-26252b30-0d7a-4f8b-8e0c-ce443272e796": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00966248s
Oct 28 18:05:04.556: INFO: Pod "pod-projected-secrets-26252b30-0d7a-4f8b-8e0c-ce443272e796": Phase="Pending", Reason="", readiness=false. Elapsed: 4.01397023s
Oct 28 18:05:06.562: INFO: Pod "pod-projected-secrets-26252b30-0d7a-4f8b-8e0c-ce443272e796": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.020463884s
STEP: Saw pod success
Oct 28 18:05:06.562: INFO: Pod "pod-projected-secrets-26252b30-0d7a-4f8b-8e0c-ce443272e796" satisfied condition "success or failure"
Oct 28 18:05:06.566: INFO: Trying to get logs from node kh4ga-worker-000003 pod pod-projected-secrets-26252b30-0d7a-4f8b-8e0c-ce443272e796 container projected-secret-volume-test: <nil>
STEP: delete the pod
Oct 28 18:05:06.596: INFO: Waiting for pod pod-projected-secrets-26252b30-0d7a-4f8b-8e0c-ce443272e796 to disappear
Oct 28 18:05:06.599: INFO: Pod pod-projected-secrets-26252b30-0d7a-4f8b-8e0c-ce443272e796 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 18:05:06.599: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2633" for this suite.
Oct 28 18:05:12.619: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 18:05:12.819: INFO: namespace projected-2633 deletion completed in 6.213648002s

• [SLOW TEST:12.454 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 18:05:12.819: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-7624
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Oct 28 18:05:12.995: INFO: Waiting up to 5m0s for pod "downwardapi-volume-02b70aa7-a95d-45f4-89ab-0f71c73a692e" in namespace "downward-api-7624" to be "success or failure"
Oct 28 18:05:13.006: INFO: Pod "downwardapi-volume-02b70aa7-a95d-45f4-89ab-0f71c73a692e": Phase="Pending", Reason="", readiness=false. Elapsed: 10.577947ms
Oct 28 18:05:15.010: INFO: Pod "downwardapi-volume-02b70aa7-a95d-45f4-89ab-0f71c73a692e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015126569s
Oct 28 18:05:17.015: INFO: Pod "downwardapi-volume-02b70aa7-a95d-45f4-89ab-0f71c73a692e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.020123287s
Oct 28 18:05:19.020: INFO: Pod "downwardapi-volume-02b70aa7-a95d-45f4-89ab-0f71c73a692e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.0251336s
STEP: Saw pod success
Oct 28 18:05:19.021: INFO: Pod "downwardapi-volume-02b70aa7-a95d-45f4-89ab-0f71c73a692e" satisfied condition "success or failure"
Oct 28 18:05:19.024: INFO: Trying to get logs from node kh4ga-worker-000000 pod downwardapi-volume-02b70aa7-a95d-45f4-89ab-0f71c73a692e container client-container: <nil>
STEP: delete the pod
Oct 28 18:05:19.045: INFO: Waiting for pod downwardapi-volume-02b70aa7-a95d-45f4-89ab-0f71c73a692e to disappear
Oct 28 18:05:19.052: INFO: Pod downwardapi-volume-02b70aa7-a95d-45f4-89ab-0f71c73a692e no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 18:05:19.052: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7624" for this suite.
Oct 28 18:05:25.072: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 18:05:25.228: INFO: namespace downward-api-7624 deletion completed in 6.170262601s

• [SLOW TEST:12.409 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 18:05:25.228: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-4103
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Oct 28 18:05:25.392: INFO: Pod name pod-release: Found 0 pods out of 1
Oct 28 18:05:30.396: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 18:05:31.420: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-4103" for this suite.
Oct 28 18:05:37.442: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 18:05:37.599: INFO: namespace replication-controller-4103 deletion completed in 6.172729309s

• [SLOW TEST:12.370 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 18:05:37.599: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-9835
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-downwardapi-ddhc
STEP: Creating a pod to test atomic-volume-subpath
Oct 28 18:05:37.793: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-ddhc" in namespace "subpath-9835" to be "success or failure"
Oct 28 18:05:37.802: INFO: Pod "pod-subpath-test-downwardapi-ddhc": Phase="Pending", Reason="", readiness=false. Elapsed: 9.083241ms
Oct 28 18:05:39.807: INFO: Pod "pod-subpath-test-downwardapi-ddhc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014187098s
Oct 28 18:05:41.812: INFO: Pod "pod-subpath-test-downwardapi-ddhc": Phase="Pending", Reason="", readiness=false. Elapsed: 4.019083848s
Oct 28 18:05:43.816: INFO: Pod "pod-subpath-test-downwardapi-ddhc": Phase="Running", Reason="", readiness=true. Elapsed: 6.023464591s
Oct 28 18:05:45.821: INFO: Pod "pod-subpath-test-downwardapi-ddhc": Phase="Running", Reason="", readiness=true. Elapsed: 8.027872129s
Oct 28 18:05:47.826: INFO: Pod "pod-subpath-test-downwardapi-ddhc": Phase="Running", Reason="", readiness=true. Elapsed: 10.032663363s
Oct 28 18:05:49.830: INFO: Pod "pod-subpath-test-downwardapi-ddhc": Phase="Running", Reason="", readiness=true. Elapsed: 12.037443292s
Oct 28 18:05:51.836: INFO: Pod "pod-subpath-test-downwardapi-ddhc": Phase="Running", Reason="", readiness=true. Elapsed: 14.042724018s
Oct 28 18:05:53.840: INFO: Pod "pod-subpath-test-downwardapi-ddhc": Phase="Running", Reason="", readiness=true. Elapsed: 16.047621837s
Oct 28 18:05:55.845: INFO: Pod "pod-subpath-test-downwardapi-ddhc": Phase="Running", Reason="", readiness=true. Elapsed: 18.052534551s
Oct 28 18:05:57.851: INFO: Pod "pod-subpath-test-downwardapi-ddhc": Phase="Running", Reason="", readiness=true. Elapsed: 20.057885562s
Oct 28 18:05:59.856: INFO: Pod "pod-subpath-test-downwardapi-ddhc": Phase="Running", Reason="", readiness=true. Elapsed: 22.063141667s
Oct 28 18:06:01.862: INFO: Pod "pod-subpath-test-downwardapi-ddhc": Phase="Running", Reason="", readiness=true. Elapsed: 24.069340572s
Oct 28 18:06:03.867: INFO: Pod "pod-subpath-test-downwardapi-ddhc": Phase="Running", Reason="", readiness=true. Elapsed: 26.074468566s
Oct 28 18:06:05.872: INFO: Pod "pod-subpath-test-downwardapi-ddhc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 28.079241254s
STEP: Saw pod success
Oct 28 18:06:05.872: INFO: Pod "pod-subpath-test-downwardapi-ddhc" satisfied condition "success or failure"
Oct 28 18:06:05.883: INFO: Trying to get logs from node kh4ga-worker-000003 pod pod-subpath-test-downwardapi-ddhc container test-container-subpath-downwardapi-ddhc: <nil>
STEP: delete the pod
Oct 28 18:06:05.921: INFO: Waiting for pod pod-subpath-test-downwardapi-ddhc to disappear
Oct 28 18:06:05.929: INFO: Pod pod-subpath-test-downwardapi-ddhc no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-ddhc
Oct 28 18:06:05.929: INFO: Deleting pod "pod-subpath-test-downwardapi-ddhc" in namespace "subpath-9835"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 18:06:05.933: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-9835" for this suite.
Oct 28 18:06:11.955: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 18:06:12.131: INFO: namespace subpath-9835 deletion completed in 6.190834313s

• [SLOW TEST:34.532 seconds]
[sig-storage] Subpath
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with downward pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 18:06:12.131: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-22
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Oct 28 18:06:12.338: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-124947935 version'
Oct 28 18:06:12.421: INFO: stderr: ""
Oct 28 18:06:12.422: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"15\", GitVersion:\"v1.15.5\", GitCommit:\"20c265fef0741dd71a66480e35bd69f18351daea\", GitTreeState:\"clean\", BuildDate:\"2019-10-15T19:16:51Z\", GoVersion:\"go1.12.10\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"15\", GitVersion:\"v1.15.5\", GitCommit:\"20c265fef0741dd71a66480e35bd69f18351daea\", GitTreeState:\"clean\", BuildDate:\"2019-10-15T19:07:57Z\", GoVersion:\"go1.12.10\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 18:06:12.422: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-22" for this suite.
Oct 28 18:06:18.447: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 18:06:18.617: INFO: namespace kubectl-22 deletion completed in 6.183586032s

• [SLOW TEST:6.485 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl version
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 18:06:18.617: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-1133
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-configmap-dlnp
STEP: Creating a pod to test atomic-volume-subpath
Oct 28 18:06:18.801: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-dlnp" in namespace "subpath-1133" to be "success or failure"
Oct 28 18:06:18.825: INFO: Pod "pod-subpath-test-configmap-dlnp": Phase="Pending", Reason="", readiness=false. Elapsed: 24.582309ms
Oct 28 18:06:20.829: INFO: Pod "pod-subpath-test-configmap-dlnp": Phase="Pending", Reason="", readiness=false. Elapsed: 2.028532156s
Oct 28 18:06:22.833: INFO: Pod "pod-subpath-test-configmap-dlnp": Phase="Pending", Reason="", readiness=false. Elapsed: 4.0328388s
Oct 28 18:06:24.839: INFO: Pod "pod-subpath-test-configmap-dlnp": Phase="Running", Reason="", readiness=true. Elapsed: 6.038014342s
Oct 28 18:06:26.844: INFO: Pod "pod-subpath-test-configmap-dlnp": Phase="Running", Reason="", readiness=true. Elapsed: 8.043674882s
Oct 28 18:06:28.850: INFO: Pod "pod-subpath-test-configmap-dlnp": Phase="Running", Reason="", readiness=true. Elapsed: 10.049232517s
Oct 28 18:06:30.855: INFO: Pod "pod-subpath-test-configmap-dlnp": Phase="Running", Reason="", readiness=true. Elapsed: 12.054200044s
Oct 28 18:06:32.860: INFO: Pod "pod-subpath-test-configmap-dlnp": Phase="Running", Reason="", readiness=true. Elapsed: 14.059442268s
Oct 28 18:06:34.864: INFO: Pod "pod-subpath-test-configmap-dlnp": Phase="Running", Reason="", readiness=true. Elapsed: 16.063609082s
Oct 28 18:06:36.869: INFO: Pod "pod-subpath-test-configmap-dlnp": Phase="Running", Reason="", readiness=true. Elapsed: 18.068376594s
Oct 28 18:06:38.874: INFO: Pod "pod-subpath-test-configmap-dlnp": Phase="Running", Reason="", readiness=true. Elapsed: 20.073453003s
Oct 28 18:06:40.879: INFO: Pod "pod-subpath-test-configmap-dlnp": Phase="Running", Reason="", readiness=true. Elapsed: 22.078332706s
Oct 28 18:06:42.884: INFO: Pod "pod-subpath-test-configmap-dlnp": Phase="Running", Reason="", readiness=true. Elapsed: 24.083373505s
Oct 28 18:06:44.889: INFO: Pod "pod-subpath-test-configmap-dlnp": Phase="Succeeded", Reason="", readiness=false. Elapsed: 26.088386499s
STEP: Saw pod success
Oct 28 18:06:44.889: INFO: Pod "pod-subpath-test-configmap-dlnp" satisfied condition "success or failure"
Oct 28 18:06:44.892: INFO: Trying to get logs from node kh4ga-worker-000000 pod pod-subpath-test-configmap-dlnp container test-container-subpath-configmap-dlnp: <nil>
STEP: delete the pod
Oct 28 18:06:44.942: INFO: Waiting for pod pod-subpath-test-configmap-dlnp to disappear
Oct 28 18:06:44.952: INFO: Pod pod-subpath-test-configmap-dlnp no longer exists
STEP: Deleting pod pod-subpath-test-configmap-dlnp
Oct 28 18:06:44.952: INFO: Deleting pod "pod-subpath-test-configmap-dlnp" in namespace "subpath-1133"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 18:06:44.955: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-1133" for this suite.
Oct 28 18:06:50.977: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 18:06:51.131: INFO: namespace subpath-1133 deletion completed in 6.170238434s

• [SLOW TEST:32.515 seconds]
[sig-storage] Subpath
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with configmap pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 18:06:51.132: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-4314
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:81
Oct 28 18:06:51.346: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Oct 28 18:06:51.355: INFO: Waiting for terminating namespaces to be deleted...
Oct 28 18:06:51.359: INFO: 
Logging pods the kubelet thinks is on node kh4ga-worker-000000 before test
Oct 28 18:06:51.372: INFO: coredns-7b76874c7b-hnw8g from kube-system started at 2019-10-28 16:25:57 +0000 UTC (1 container statuses recorded)
Oct 28 18:06:51.372: INFO: 	Container coredns ready: true, restart count 0
Oct 28 18:06:51.372: INFO: cert-exporter-7zznl from kube-system started at 2019-10-28 16:26:11 +0000 UTC (1 container statuses recorded)
Oct 28 18:06:51.372: INFO: 	Container cert-exporter ready: true, restart count 0
Oct 28 18:06:51.372: INFO: sonobuoy-e2e-job-2b01bf00cc914c5a from sonobuoy started at 2019-10-28 16:31:37 +0000 UTC (2 container statuses recorded)
Oct 28 18:06:51.372: INFO: 	Container e2e ready: true, restart count 0
Oct 28 18:06:51.372: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct 28 18:06:51.372: INFO: calico-node-bqrms from kube-system started at 2019-10-28 16:23:02 +0000 UTC (1 container statuses recorded)
Oct 28 18:06:51.372: INFO: 	Container calico-node ready: true, restart count 0
Oct 28 18:06:51.372: INFO: kube-proxy-5r5g9 from kube-system started at 2019-10-28 16:23:02 +0000 UTC (1 container statuses recorded)
Oct 28 18:06:51.372: INFO: 	Container kube-proxy ready: true, restart count 0
Oct 28 18:06:51.372: INFO: net-exporter-v94hf from kube-system started at 2019-10-28 16:26:19 +0000 UTC (1 container statuses recorded)
Oct 28 18:06:51.372: INFO: 	Container net-exporter ready: true, restart count 0
Oct 28 18:06:51.372: INFO: nginx-ingress-controller-6b49fc4779-46b6j from kube-system started at 2019-10-28 16:26:20 +0000 UTC (1 container statuses recorded)
Oct 28 18:06:51.372: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Oct 28 18:06:51.372: INFO: sonobuoy from sonobuoy started at 2019-10-28 16:31:26 +0000 UTC (1 container statuses recorded)
Oct 28 18:06:51.372: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Oct 28 18:06:51.372: INFO: node-exporter-94ffd from kube-system started at 2019-10-28 16:25:51 +0000 UTC (1 container statuses recorded)
Oct 28 18:06:51.372: INFO: 	Container node-exporter ready: true, restart count 0
Oct 28 18:06:51.372: INFO: external-dns-769446d578-7lh6n from kube-system started at 2019-10-28 16:26:07 +0000 UTC (1 container statuses recorded)
Oct 28 18:06:51.372: INFO: 	Container external-dns ready: true, restart count 0
Oct 28 18:06:51.372: INFO: sonobuoy-systemd-logs-daemon-set-80aafb278b8f4e15-fhxc7 from sonobuoy started at 2019-10-28 16:31:37 +0000 UTC (2 container statuses recorded)
Oct 28 18:06:51.372: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Oct 28 18:06:51.372: INFO: 	Container systemd-logs ready: true, restart count 1
Oct 28 18:06:51.372: INFO: 
Logging pods the kubelet thinks is on node kh4ga-worker-000002 before test
Oct 28 18:06:51.384: INFO: node-exporter-b29jz from kube-system started at 2019-10-28 16:25:51 +0000 UTC (1 container statuses recorded)
Oct 28 18:06:51.384: INFO: 	Container node-exporter ready: true, restart count 0
Oct 28 18:06:51.384: INFO: chart-operator-7dcfd7559b-4xhkx from giantswarm started at 2019-10-28 16:25:53 +0000 UTC (1 container statuses recorded)
Oct 28 18:06:51.384: INFO: 	Container chart-operator ready: true, restart count 0
Oct 28 18:06:51.384: INFO: cert-exporter-shzc7 from kube-system started at 2019-10-28 16:26:17 +0000 UTC (1 container statuses recorded)
Oct 28 18:06:51.384: INFO: 	Container cert-exporter ready: true, restart count 0
Oct 28 18:06:51.384: INFO: kube-proxy-hcbz2 from kube-system started at 2019-10-28 16:22:57 +0000 UTC (1 container statuses recorded)
Oct 28 18:06:51.384: INFO: 	Container kube-proxy ready: true, restart count 0
Oct 28 18:06:51.384: INFO: calico-node-wzq68 from kube-system started at 2019-10-28 16:22:57 +0000 UTC (1 container statuses recorded)
Oct 28 18:06:51.384: INFO: 	Container calico-node ready: true, restart count 0
Oct 28 18:06:51.384: INFO: sonobuoy-systemd-logs-daemon-set-80aafb278b8f4e15-wqcmm from sonobuoy started at 2019-10-28 16:31:37 +0000 UTC (2 container statuses recorded)
Oct 28 18:06:51.384: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Oct 28 18:06:51.384: INFO: 	Container systemd-logs ready: true, restart count 1
Oct 28 18:06:51.384: INFO: kube-state-metrics-586fbd9595-r5656 from kube-system started at 2019-10-28 16:26:10 +0000 UTC (2 container statuses recorded)
Oct 28 18:06:51.384: INFO: 	Container addon-resizer ready: true, restart count 0
Oct 28 18:06:51.384: INFO: 	Container kube-state-metrics ready: true, restart count 0
Oct 28 18:06:51.384: INFO: nginx-ingress-controller-6b49fc4779-t5skf from kube-system started at 2019-10-28 16:26:20 +0000 UTC (1 container statuses recorded)
Oct 28 18:06:51.384: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Oct 28 18:06:51.384: INFO: tiller-deploy-5db95cf576-tbgkz from giantswarm started at 2019-10-28 16:23:58 +0000 UTC (1 container statuses recorded)
Oct 28 18:06:51.384: INFO: 	Container tiller ready: true, restart count 0
Oct 28 18:06:51.384: INFO: net-exporter-rb7qj from kube-system started at 2019-10-28 16:26:20 +0000 UTC (1 container statuses recorded)
Oct 28 18:06:51.384: INFO: 	Container net-exporter ready: true, restart count 0
Oct 28 18:06:51.384: INFO: 
Logging pods the kubelet thinks is on node kh4ga-worker-000003 before test
Oct 28 18:06:51.396: INFO: calico-node-sxmff from kube-system started at 2019-10-28 16:23:07 +0000 UTC (1 container statuses recorded)
Oct 28 18:06:51.396: INFO: 	Container calico-node ready: true, restart count 0
Oct 28 18:06:51.396: INFO: sonobuoy-systemd-logs-daemon-set-80aafb278b8f4e15-rvx7d from sonobuoy started at 2019-10-28 16:31:37 +0000 UTC (2 container statuses recorded)
Oct 28 18:06:51.396: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Oct 28 18:06:51.396: INFO: 	Container systemd-logs ready: true, restart count 1
Oct 28 18:06:51.396: INFO: metrics-server-586d4684b4-qh7rw from kube-system started at 2019-10-28 16:25:49 +0000 UTC (1 container statuses recorded)
Oct 28 18:06:51.396: INFO: 	Container metrics-server ready: true, restart count 0
Oct 28 18:06:51.396: INFO: coredns-7b76874c7b-654r4 from kube-system started at 2019-10-28 16:25:59 +0000 UTC (1 container statuses recorded)
Oct 28 18:06:51.396: INFO: 	Container coredns ready: true, restart count 0
Oct 28 18:06:51.396: INFO: cert-exporter-cjdz5 from kube-system started at 2019-10-28 16:26:16 +0000 UTC (1 container statuses recorded)
Oct 28 18:06:51.396: INFO: 	Container cert-exporter ready: true, restart count 0
Oct 28 18:06:51.396: INFO: nginx-ingress-controller-6b49fc4779-ddjkh from kube-system started at 2019-10-28 16:26:20 +0000 UTC (1 container statuses recorded)
Oct 28 18:06:51.396: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Oct 28 18:06:51.396: INFO: kube-proxy-lc8jd from kube-system started at 2019-10-28 16:23:07 +0000 UTC (1 container statuses recorded)
Oct 28 18:06:51.396: INFO: 	Container kube-proxy ready: true, restart count 0
Oct 28 18:06:51.396: INFO: net-exporter-vhl5t from kube-system started at 2019-10-28 16:26:19 +0000 UTC (1 container statuses recorded)
Oct 28 18:06:51.396: INFO: 	Container net-exporter ready: true, restart count 0
Oct 28 18:06:51.397: INFO: node-exporter-4q9vs from kube-system started at 2019-10-28 16:25:51 +0000 UTC (1 container statuses recorded)
Oct 28 18:06:51.397: INFO: 	Container node-exporter ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.15d1e1cc0c405d35], Reason = [FailedScheduling], Message = [0/4 nodes are available: 4 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 18:06:52.428: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-4314" for this suite.
Oct 28 18:06:58.452: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 18:06:58.621: INFO: namespace sched-pred-4314 deletion completed in 6.186340151s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:72

• [SLOW TEST:7.489 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 18:06:58.621: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-4069
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Oct 28 18:06:58.830: INFO: Create a RollingUpdate DaemonSet
Oct 28 18:06:58.840: INFO: Check that daemon pods launch on every node of the cluster
Oct 28 18:06:58.845: INFO: DaemonSet pods can't tolerate node kh4ga-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 28 18:06:58.853: INFO: Number of nodes with available pods: 0
Oct 28 18:06:58.853: INFO: Node kh4ga-worker-000000 is running more than one daemon pod
Oct 28 18:06:59.861: INFO: DaemonSet pods can't tolerate node kh4ga-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 28 18:06:59.865: INFO: Number of nodes with available pods: 0
Oct 28 18:06:59.865: INFO: Node kh4ga-worker-000000 is running more than one daemon pod
Oct 28 18:07:00.861: INFO: DaemonSet pods can't tolerate node kh4ga-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 28 18:07:00.866: INFO: Number of nodes with available pods: 0
Oct 28 18:07:00.866: INFO: Node kh4ga-worker-000000 is running more than one daemon pod
Oct 28 18:07:01.861: INFO: DaemonSet pods can't tolerate node kh4ga-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 28 18:07:01.866: INFO: Number of nodes with available pods: 0
Oct 28 18:07:01.866: INFO: Node kh4ga-worker-000000 is running more than one daemon pod
Oct 28 18:07:02.862: INFO: DaemonSet pods can't tolerate node kh4ga-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 28 18:07:02.866: INFO: Number of nodes with available pods: 1
Oct 28 18:07:02.866: INFO: Node kh4ga-worker-000000 is running more than one daemon pod
Oct 28 18:07:03.862: INFO: DaemonSet pods can't tolerate node kh4ga-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 28 18:07:03.866: INFO: Number of nodes with available pods: 3
Oct 28 18:07:03.866: INFO: Number of running nodes: 3, number of available pods: 3
Oct 28 18:07:03.866: INFO: Update the DaemonSet to trigger a rollout
Oct 28 18:07:03.875: INFO: Updating DaemonSet daemon-set
Oct 28 18:07:17.897: INFO: Roll back the DaemonSet before rollout is complete
Oct 28 18:07:17.906: INFO: Updating DaemonSet daemon-set
Oct 28 18:07:17.906: INFO: Make sure DaemonSet rollback is complete
Oct 28 18:07:17.917: INFO: Wrong image for pod: daemon-set-9p4ft. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Oct 28 18:07:17.917: INFO: Pod daemon-set-9p4ft is not available
Oct 28 18:07:17.928: INFO: DaemonSet pods can't tolerate node kh4ga-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 28 18:07:18.933: INFO: Wrong image for pod: daemon-set-9p4ft. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Oct 28 18:07:18.933: INFO: Pod daemon-set-9p4ft is not available
Oct 28 18:07:18.940: INFO: DaemonSet pods can't tolerate node kh4ga-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 28 18:07:19.933: INFO: Wrong image for pod: daemon-set-9p4ft. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Oct 28 18:07:19.933: INFO: Pod daemon-set-9p4ft is not available
Oct 28 18:07:19.940: INFO: DaemonSet pods can't tolerate node kh4ga-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 28 18:07:20.933: INFO: Pod daemon-set-4f5xm is not available
Oct 28 18:07:20.940: INFO: DaemonSet pods can't tolerate node kh4ga-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-4069, will wait for the garbage collector to delete the pods
Oct 28 18:07:21.010: INFO: Deleting DaemonSet.extensions daemon-set took: 8.815938ms
Oct 28 18:07:21.110: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.195435ms
Oct 28 18:07:25.318: INFO: Number of nodes with available pods: 0
Oct 28 18:07:25.318: INFO: Number of running nodes: 0, number of available pods: 0
Oct 28 18:07:25.323: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-4069/daemonsets","resourceVersion":"23914"},"items":null}

Oct 28 18:07:25.327: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-4069/pods","resourceVersion":"23914"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 18:07:25.350: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-4069" for this suite.
Oct 28 18:07:31.369: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 18:07:31.512: INFO: namespace daemonsets-4069 deletion completed in 6.158058804s

• [SLOW TEST:32.891 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 18:07:31.513: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6988
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-map-380c0330-f4d8-43f5-aed6-eaee83df9883
STEP: Creating a pod to test consume secrets
Oct 28 18:07:31.675: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-fe8f2cc2-47ae-40b1-b722-4943deb639c8" in namespace "projected-6988" to be "success or failure"
Oct 28 18:07:31.685: INFO: Pod "pod-projected-secrets-fe8f2cc2-47ae-40b1-b722-4943deb639c8": Phase="Pending", Reason="", readiness=false. Elapsed: 9.473541ms
Oct 28 18:07:33.690: INFO: Pod "pod-projected-secrets-fe8f2cc2-47ae-40b1-b722-4943deb639c8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014057224s
Oct 28 18:07:35.694: INFO: Pod "pod-projected-secrets-fe8f2cc2-47ae-40b1-b722-4943deb639c8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.018800705s
Oct 28 18:07:37.699: INFO: Pod "pod-projected-secrets-fe8f2cc2-47ae-40b1-b722-4943deb639c8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.023803782s
STEP: Saw pod success
Oct 28 18:07:37.699: INFO: Pod "pod-projected-secrets-fe8f2cc2-47ae-40b1-b722-4943deb639c8" satisfied condition "success or failure"
Oct 28 18:07:37.703: INFO: Trying to get logs from node kh4ga-worker-000003 pod pod-projected-secrets-fe8f2cc2-47ae-40b1-b722-4943deb639c8 container projected-secret-volume-test: <nil>
STEP: delete the pod
Oct 28 18:07:37.729: INFO: Waiting for pod pod-projected-secrets-fe8f2cc2-47ae-40b1-b722-4943deb639c8 to disappear
Oct 28 18:07:37.734: INFO: Pod pod-projected-secrets-fe8f2cc2-47ae-40b1-b722-4943deb639c8 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 18:07:37.734: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6988" for this suite.
Oct 28 18:07:43.764: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 18:07:43.914: INFO: namespace projected-6988 deletion completed in 6.17099298s

• [SLOW TEST:12.402 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 18:07:43.915: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-2718
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Oct 28 18:07:44.119: INFO: Waiting up to 5m0s for pod "downward-api-928daa27-b5c5-454c-b5f2-6b5d3082df3b" in namespace "downward-api-2718" to be "success or failure"
Oct 28 18:07:44.133: INFO: Pod "downward-api-928daa27-b5c5-454c-b5f2-6b5d3082df3b": Phase="Pending", Reason="", readiness=false. Elapsed: 13.787059ms
Oct 28 18:07:46.138: INFO: Pod "downward-api-928daa27-b5c5-454c-b5f2-6b5d3082df3b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01916032s
Oct 28 18:07:48.144: INFO: Pod "downward-api-928daa27-b5c5-454c-b5f2-6b5d3082df3b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.024621378s
Oct 28 18:07:50.149: INFO: Pod "downward-api-928daa27-b5c5-454c-b5f2-6b5d3082df3b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.029528928s
STEP: Saw pod success
Oct 28 18:07:50.149: INFO: Pod "downward-api-928daa27-b5c5-454c-b5f2-6b5d3082df3b" satisfied condition "success or failure"
Oct 28 18:07:50.152: INFO: Trying to get logs from node kh4ga-worker-000000 pod downward-api-928daa27-b5c5-454c-b5f2-6b5d3082df3b container dapi-container: <nil>
STEP: delete the pod
Oct 28 18:07:50.188: INFO: Waiting for pod downward-api-928daa27-b5c5-454c-b5f2-6b5d3082df3b to disappear
Oct 28 18:07:50.193: INFO: Pod downward-api-928daa27-b5c5-454c-b5f2-6b5d3082df3b no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 18:07:50.193: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2718" for this suite.
Oct 28 18:07:56.218: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 18:07:56.378: INFO: namespace downward-api-2718 deletion completed in 6.178996535s

• [SLOW TEST:12.464 seconds]
[sig-node] Downward API
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 18:07:56.379: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename events
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in events-7724
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Oct 28 18:08:02.554: INFO: &Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-b438bd8e-7579-49cd-b1ae-e21935c93709,GenerateName:,Namespace:events-7724,SelfLink:/api/v1/namespaces/events-7724/pods/send-events-b438bd8e-7579-49cd-b1ae-e21935c93709,UID:86406e4b-2971-4de2-b312-45e87a08578e,ResourceVersion:24070,Generation:0,CreationTimestamp:2019-10-28 18:07:56 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 529826065,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.2.131.150/32,kubernetes.io/psp: cert-exporter-psp,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-xhv45 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-xhv45,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-xhv45 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kh4ga-worker-000003,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001fee470} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001fee4b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-28 18:07:56 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-10-28 18:08:00 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-10-28 18:08:00 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-28 18:07:56 +0000 UTC  }],Message:,Reason:,HostIP:10.2.1.7,PodIP:10.2.131.150,StartTime:2019-10-28 18:07:56 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2019-10-28 18:08:00 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 docker-pullable://gcr.io/kubernetes-e2e-test-images/serve-hostname@sha256:bab70473a6d8ef65a22625dc9a1b0f0452e811530fdbe77e4408523460177ff1 docker://71615bc18b6da8eac466baeca9b4ee77d4d7ad399882d523e722246f1267feee}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}

STEP: checking for scheduler event about the pod
Oct 28 18:08:04.560: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Oct 28 18:08:06.564: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 18:08:06.570: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-7724" for this suite.
Oct 28 18:08:44.597: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 18:08:44.754: INFO: namespace events-7724 deletion completed in 38.171633127s

• [SLOW TEST:48.375 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 18:08:44.755: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-5454
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
Oct 28 18:08:44.903: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 18:08:53.676: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-5454" for this suite.
Oct 28 18:08:59.709: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 18:08:59.857: INFO: namespace init-container-5454 deletion completed in 6.169721821s

• [SLOW TEST:15.102 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 18:08:59.858: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-157
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod liveness-3a3900f8-1a9c-42dc-8dcc-0461b75c2487 in namespace container-probe-157
Oct 28 18:09:06.044: INFO: Started pod liveness-3a3900f8-1a9c-42dc-8dcc-0461b75c2487 in namespace container-probe-157
STEP: checking the pod's current state and verifying that restartCount is present
Oct 28 18:09:06.047: INFO: Initial restart count of pod liveness-3a3900f8-1a9c-42dc-8dcc-0461b75c2487 is 0
Oct 28 18:09:30.114: INFO: Restart count of pod container-probe-157/liveness-3a3900f8-1a9c-42dc-8dcc-0461b75c2487 is now 1 (24.066493029s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 18:09:30.132: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-157" for this suite.
Oct 28 18:09:36.153: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 18:09:36.318: INFO: namespace container-probe-157 deletion completed in 6.178867064s

• [SLOW TEST:36.460 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Aggregator 
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 18:09:36.318: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename aggregator
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in aggregator-7370
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:76
Oct 28 18:09:36.473: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
[It] Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Registering the sample API server.
Oct 28 18:09:37.043: INFO: deployment "sample-apiserver-deployment" doesn't have the required revision set
Oct 28 18:09:39.124: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707882977, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707882977, loc:(*time.Location)(0x7ed0a20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707882977, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707882977, loc:(*time.Location)(0x7ed0a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 28 18:09:41.129: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707882977, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707882977, loc:(*time.Location)(0x7ed0a20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707882977, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707882977, loc:(*time.Location)(0x7ed0a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 28 18:09:43.130: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707882977, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707882977, loc:(*time.Location)(0x7ed0a20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707882977, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707882977, loc:(*time.Location)(0x7ed0a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 28 18:09:45.129: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707882977, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707882977, loc:(*time.Location)(0x7ed0a20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707882977, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707882977, loc:(*time.Location)(0x7ed0a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 28 18:09:47.129: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707882977, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707882977, loc:(*time.Location)(0x7ed0a20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707882977, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707882977, loc:(*time.Location)(0x7ed0a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 28 18:09:49.129: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707882977, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707882977, loc:(*time.Location)(0x7ed0a20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707882977, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707882977, loc:(*time.Location)(0x7ed0a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 28 18:09:51.129: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707882977, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707882977, loc:(*time.Location)(0x7ed0a20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707882977, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707882977, loc:(*time.Location)(0x7ed0a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 28 18:09:53.130: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707882977, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707882977, loc:(*time.Location)(0x7ed0a20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707882977, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707882977, loc:(*time.Location)(0x7ed0a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 28 18:09:55.129: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707882977, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707882977, loc:(*time.Location)(0x7ed0a20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707882977, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707882977, loc:(*time.Location)(0x7ed0a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 28 18:09:57.129: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707882977, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707882977, loc:(*time.Location)(0x7ed0a20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707882977, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707882977, loc:(*time.Location)(0x7ed0a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 28 18:09:59.128: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707882977, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707882977, loc:(*time.Location)(0x7ed0a20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707882977, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707882977, loc:(*time.Location)(0x7ed0a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 28 18:10:01.129: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707882977, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707882977, loc:(*time.Location)(0x7ed0a20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707882977, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707882977, loc:(*time.Location)(0x7ed0a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 28 18:10:03.129: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707882977, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707882977, loc:(*time.Location)(0x7ed0a20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707882977, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707882977, loc:(*time.Location)(0x7ed0a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 28 18:10:05.129: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707882977, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707882977, loc:(*time.Location)(0x7ed0a20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707882977, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707882977, loc:(*time.Location)(0x7ed0a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 28 18:10:07.129: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707882977, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707882977, loc:(*time.Location)(0x7ed0a20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707882977, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707882977, loc:(*time.Location)(0x7ed0a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 28 18:10:09.133: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707882977, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707882977, loc:(*time.Location)(0x7ed0a20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707882977, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707882977, loc:(*time.Location)(0x7ed0a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 28 18:10:11.129: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707882977, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707882977, loc:(*time.Location)(0x7ed0a20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707882977, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707882977, loc:(*time.Location)(0x7ed0a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 28 18:10:13.129: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707882977, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707882977, loc:(*time.Location)(0x7ed0a20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707882977, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707882977, loc:(*time.Location)(0x7ed0a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 28 18:10:16.474: INFO: Waited 1.334927586s for the sample-apiserver to be ready to handle requests.
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:67
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 18:10:17.412: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "aggregator-7370" for this suite.
Oct 28 18:10:23.580: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 18:10:23.763: INFO: namespace aggregator-7370 deletion completed in 6.297367526s

• [SLOW TEST:47.445 seconds]
[sig-api-machinery] Aggregator
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 18:10:23.764: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-1672
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 18:10:29.961: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-1672" for this suite.
Oct 28 18:11:21.983: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 18:11:22.144: INFO: namespace kubelet-test-1672 deletion completed in 52.176308764s

• [SLOW TEST:58.381 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when scheduling a busybox Pod with hostAliases
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:136
    should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 18:11:22.145: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-6125
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
W1028 18:11:52.852096      19 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Oct 28 18:11:52.852: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 18:11:52.852: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-6125" for this suite.
Oct 28 18:11:58.871: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 18:11:59.026: INFO: namespace gc-6125 deletion completed in 6.170003984s

• [SLOW TEST:36.882 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 18:11:59.027: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-3890
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: validating cluster-info
Oct 28 18:11:59.175: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-124947935 cluster-info'
Oct 28 18:12:02.741: INFO: stderr: ""
Oct 28 18:12:02.741: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://172.31.0.1:443\x1b[0m\n\x1b[0;32mCoreDNS\x1b[0m is running at \x1b[0;33mhttps://172.31.0.1:443/api/v1/namespaces/kube-system/services/coredns:dns/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 18:12:02.741: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3890" for this suite.
Oct 28 18:12:08.762: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 18:12:08.929: INFO: namespace kubectl-3890 deletion completed in 6.182224596s

• [SLOW TEST:9.902 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl cluster-info
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 18:12:08.930: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-3638
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-3638.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-3638.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-3638.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-3638.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-3638.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-3638.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-3638.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-3638.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-3638.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-3638.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-3638.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-3638.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-3638.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 190.209.31.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.31.209.190_udp@PTR;check="$$(dig +tcp +noall +answer +search 190.209.31.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.31.209.190_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-3638.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-3638.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-3638.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-3638.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-3638.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-3638.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-3638.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-3638.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-3638.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-3638.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-3638.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-3638.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-3638.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 190.209.31.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.31.209.190_udp@PTR;check="$$(dig +tcp +noall +answer +search 190.209.31.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.31.209.190_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Oct 28 18:12:17.180: INFO: Unable to read wheezy_udp@dns-test-service.dns-3638.svc.cluster.local from pod dns-3638/dns-test-17106982-d1e6-4c9d-82e4-6c6c5b7d5ce3: the server could not find the requested resource (get pods dns-test-17106982-d1e6-4c9d-82e4-6c6c5b7d5ce3)
Oct 28 18:12:17.186: INFO: Unable to read wheezy_tcp@dns-test-service.dns-3638.svc.cluster.local from pod dns-3638/dns-test-17106982-d1e6-4c9d-82e4-6c6c5b7d5ce3: the server could not find the requested resource (get pods dns-test-17106982-d1e6-4c9d-82e4-6c6c5b7d5ce3)
Oct 28 18:12:17.192: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-3638.svc.cluster.local from pod dns-3638/dns-test-17106982-d1e6-4c9d-82e4-6c6c5b7d5ce3: the server could not find the requested resource (get pods dns-test-17106982-d1e6-4c9d-82e4-6c6c5b7d5ce3)
Oct 28 18:12:17.197: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-3638.svc.cluster.local from pod dns-3638/dns-test-17106982-d1e6-4c9d-82e4-6c6c5b7d5ce3: the server could not find the requested resource (get pods dns-test-17106982-d1e6-4c9d-82e4-6c6c5b7d5ce3)
Oct 28 18:12:17.216: INFO: Unable to read wheezy_udp@PodARecord from pod dns-3638/dns-test-17106982-d1e6-4c9d-82e4-6c6c5b7d5ce3: the server could not find the requested resource (get pods dns-test-17106982-d1e6-4c9d-82e4-6c6c5b7d5ce3)
Oct 28 18:12:17.221: INFO: Unable to read wheezy_tcp@PodARecord from pod dns-3638/dns-test-17106982-d1e6-4c9d-82e4-6c6c5b7d5ce3: the server could not find the requested resource (get pods dns-test-17106982-d1e6-4c9d-82e4-6c6c5b7d5ce3)
Oct 28 18:12:17.239: INFO: Unable to read jessie_udp@dns-test-service.dns-3638.svc.cluster.local from pod dns-3638/dns-test-17106982-d1e6-4c9d-82e4-6c6c5b7d5ce3: the server could not find the requested resource (get pods dns-test-17106982-d1e6-4c9d-82e4-6c6c5b7d5ce3)
Oct 28 18:12:17.244: INFO: Unable to read jessie_tcp@dns-test-service.dns-3638.svc.cluster.local from pod dns-3638/dns-test-17106982-d1e6-4c9d-82e4-6c6c5b7d5ce3: the server could not find the requested resource (get pods dns-test-17106982-d1e6-4c9d-82e4-6c6c5b7d5ce3)
Oct 28 18:12:17.250: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-3638.svc.cluster.local from pod dns-3638/dns-test-17106982-d1e6-4c9d-82e4-6c6c5b7d5ce3: the server could not find the requested resource (get pods dns-test-17106982-d1e6-4c9d-82e4-6c6c5b7d5ce3)
Oct 28 18:12:17.256: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-3638.svc.cluster.local from pod dns-3638/dns-test-17106982-d1e6-4c9d-82e4-6c6c5b7d5ce3: the server could not find the requested resource (get pods dns-test-17106982-d1e6-4c9d-82e4-6c6c5b7d5ce3)
Oct 28 18:12:17.274: INFO: Unable to read jessie_udp@PodARecord from pod dns-3638/dns-test-17106982-d1e6-4c9d-82e4-6c6c5b7d5ce3: the server could not find the requested resource (get pods dns-test-17106982-d1e6-4c9d-82e4-6c6c5b7d5ce3)
Oct 28 18:12:17.280: INFO: Unable to read jessie_tcp@PodARecord from pod dns-3638/dns-test-17106982-d1e6-4c9d-82e4-6c6c5b7d5ce3: the server could not find the requested resource (get pods dns-test-17106982-d1e6-4c9d-82e4-6c6c5b7d5ce3)
Oct 28 18:12:17.292: INFO: Lookups using dns-3638/dns-test-17106982-d1e6-4c9d-82e4-6c6c5b7d5ce3 failed for: [wheezy_udp@dns-test-service.dns-3638.svc.cluster.local wheezy_tcp@dns-test-service.dns-3638.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-3638.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-3638.svc.cluster.local wheezy_udp@PodARecord wheezy_tcp@PodARecord jessie_udp@dns-test-service.dns-3638.svc.cluster.local jessie_tcp@dns-test-service.dns-3638.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-3638.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-3638.svc.cluster.local jessie_udp@PodARecord jessie_tcp@PodARecord]

Oct 28 18:12:22.450: INFO: DNS probes using dns-3638/dns-test-17106982-d1e6-4c9d-82e4-6c6c5b7d5ce3 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 18:12:22.585: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-3638" for this suite.
Oct 28 18:12:28.616: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 18:12:28.800: INFO: namespace dns-3638 deletion completed in 6.205667217s

• [SLOW TEST:19.870 seconds]
[sig-network] DNS
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 18:12:28.801: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-9819
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Oct 28 18:12:28.969: INFO: Waiting up to 5m0s for pod "downwardapi-volume-46fe988c-8ef8-437d-bec3-353d1555d24c" in namespace "downward-api-9819" to be "success or failure"
Oct 28 18:12:28.980: INFO: Pod "downwardapi-volume-46fe988c-8ef8-437d-bec3-353d1555d24c": Phase="Pending", Reason="", readiness=false. Elapsed: 10.810844ms
Oct 28 18:12:30.983: INFO: Pod "downwardapi-volume-46fe988c-8ef8-437d-bec3-353d1555d24c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014493246s
Oct 28 18:12:32.988: INFO: Pod "downwardapi-volume-46fe988c-8ef8-437d-bec3-353d1555d24c": Phase="Pending", Reason="", readiness=false. Elapsed: 4.018968248s
Oct 28 18:12:34.993: INFO: Pod "downwardapi-volume-46fe988c-8ef8-437d-bec3-353d1555d24c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.02391355s
STEP: Saw pod success
Oct 28 18:12:34.993: INFO: Pod "downwardapi-volume-46fe988c-8ef8-437d-bec3-353d1555d24c" satisfied condition "success or failure"
Oct 28 18:12:34.997: INFO: Trying to get logs from node kh4ga-worker-000003 pod downwardapi-volume-46fe988c-8ef8-437d-bec3-353d1555d24c container client-container: <nil>
STEP: delete the pod
Oct 28 18:12:35.026: INFO: Waiting for pod downwardapi-volume-46fe988c-8ef8-437d-bec3-353d1555d24c to disappear
Oct 28 18:12:35.029: INFO: Pod downwardapi-volume-46fe988c-8ef8-437d-bec3-353d1555d24c no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 18:12:35.029: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9819" for this suite.
Oct 28 18:12:41.062: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 18:12:41.214: INFO: namespace downward-api-9819 deletion completed in 6.179958767s

• [SLOW TEST:12.413 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 18:12:41.215: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3210
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Oct 28 18:12:41.386: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9a56f42d-e162-43b5-9f7f-d62671f8723e" in namespace "projected-3210" to be "success or failure"
Oct 28 18:12:41.393: INFO: Pod "downwardapi-volume-9a56f42d-e162-43b5-9f7f-d62671f8723e": Phase="Pending", Reason="", readiness=false. Elapsed: 7.019928ms
Oct 28 18:12:43.398: INFO: Pod "downwardapi-volume-9a56f42d-e162-43b5-9f7f-d62671f8723e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011510519s
Oct 28 18:12:45.402: INFO: Pod "downwardapi-volume-9a56f42d-e162-43b5-9f7f-d62671f8723e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.016225008s
Oct 28 18:12:47.407: INFO: Pod "downwardapi-volume-9a56f42d-e162-43b5-9f7f-d62671f8723e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.021336296s
STEP: Saw pod success
Oct 28 18:12:47.408: INFO: Pod "downwardapi-volume-9a56f42d-e162-43b5-9f7f-d62671f8723e" satisfied condition "success or failure"
Oct 28 18:12:47.411: INFO: Trying to get logs from node kh4ga-worker-000000 pod downwardapi-volume-9a56f42d-e162-43b5-9f7f-d62671f8723e container client-container: <nil>
STEP: delete the pod
Oct 28 18:12:47.449: INFO: Waiting for pod downwardapi-volume-9a56f42d-e162-43b5-9f7f-d62671f8723e to disappear
Oct 28 18:12:47.454: INFO: Pod downwardapi-volume-9a56f42d-e162-43b5-9f7f-d62671f8723e no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 18:12:47.454: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3210" for this suite.
Oct 28 18:12:53.473: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 18:12:53.637: INFO: namespace projected-3210 deletion completed in 6.177562712s

• [SLOW TEST:12.423 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 18:12:53.638: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-4464
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0777 on tmpfs
Oct 28 18:12:53.801: INFO: Waiting up to 5m0s for pod "pod-77ed3572-09df-4a3a-ab51-f7a42d4eb3b4" in namespace "emptydir-4464" to be "success or failure"
Oct 28 18:12:53.814: INFO: Pod "pod-77ed3572-09df-4a3a-ab51-f7a42d4eb3b4": Phase="Pending", Reason="", readiness=false. Elapsed: 13.509155ms
Oct 28 18:12:55.819: INFO: Pod "pod-77ed3572-09df-4a3a-ab51-f7a42d4eb3b4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018103031s
Oct 28 18:12:57.826: INFO: Pod "pod-77ed3572-09df-4a3a-ab51-f7a42d4eb3b4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.025069115s
Oct 28 18:12:59.831: INFO: Pod "pod-77ed3572-09df-4a3a-ab51-f7a42d4eb3b4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.029962289s
STEP: Saw pod success
Oct 28 18:12:59.831: INFO: Pod "pod-77ed3572-09df-4a3a-ab51-f7a42d4eb3b4" satisfied condition "success or failure"
Oct 28 18:12:59.834: INFO: Trying to get logs from node kh4ga-worker-000003 pod pod-77ed3572-09df-4a3a-ab51-f7a42d4eb3b4 container test-container: <nil>
STEP: delete the pod
Oct 28 18:12:59.862: INFO: Waiting for pod pod-77ed3572-09df-4a3a-ab51-f7a42d4eb3b4 to disappear
Oct 28 18:12:59.867: INFO: Pod pod-77ed3572-09df-4a3a-ab51-f7a42d4eb3b4 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 18:12:59.867: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4464" for this suite.
Oct 28 18:13:05.891: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 18:13:06.041: INFO: namespace emptydir-4464 deletion completed in 6.165239819s

• [SLOW TEST:12.403 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 18:13:06.042: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-3910
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name cm-test-opt-del-79bfc836-20ae-4243-b74d-18826d3b2494
STEP: Creating configMap with name cm-test-opt-upd-a69a5d9b-24b0-43d3-a569-80f5ac893df4
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-79bfc836-20ae-4243-b74d-18826d3b2494
STEP: Updating configmap cm-test-opt-upd-a69a5d9b-24b0-43d3-a569-80f5ac893df4
STEP: Creating configMap with name cm-test-opt-create-72afabcb-3edf-457d-bdad-1ee9ea14a341
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 18:13:16.333: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3910" for this suite.
Oct 28 18:13:38.355: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 18:13:38.526: INFO: namespace configmap-3910 deletion completed in 22.185952099s

• [SLOW TEST:32.484 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 18:13:38.527: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-2152
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test env composition
Oct 28 18:13:38.687: INFO: Waiting up to 5m0s for pod "var-expansion-de4d275b-86fb-488f-86c9-494a7a475e2b" in namespace "var-expansion-2152" to be "success or failure"
Oct 28 18:13:38.692: INFO: Pod "var-expansion-de4d275b-86fb-488f-86c9-494a7a475e2b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.595118ms
Oct 28 18:13:40.699: INFO: Pod "var-expansion-de4d275b-86fb-488f-86c9-494a7a475e2b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012275259s
Oct 28 18:13:42.704: INFO: Pod "var-expansion-de4d275b-86fb-488f-86c9-494a7a475e2b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.017184886s
Oct 28 18:13:44.709: INFO: Pod "var-expansion-de4d275b-86fb-488f-86c9-494a7a475e2b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.022142911s
STEP: Saw pod success
Oct 28 18:13:44.709: INFO: Pod "var-expansion-de4d275b-86fb-488f-86c9-494a7a475e2b" satisfied condition "success or failure"
Oct 28 18:13:44.713: INFO: Trying to get logs from node kh4ga-worker-000003 pod var-expansion-de4d275b-86fb-488f-86c9-494a7a475e2b container dapi-container: <nil>
STEP: delete the pod
Oct 28 18:13:44.737: INFO: Waiting for pod var-expansion-de4d275b-86fb-488f-86c9-494a7a475e2b to disappear
Oct 28 18:13:44.741: INFO: Pod var-expansion-de4d275b-86fb-488f-86c9-494a7a475e2b no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 18:13:44.741: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-2152" for this suite.
Oct 28 18:13:50.776: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 18:13:50.940: INFO: namespace var-expansion-2152 deletion completed in 6.181092436s

• [SLOW TEST:12.414 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 18:13:50.942: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-8871
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-upd-41818a7f-71fb-4971-8480-62344720ad8c
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-41818a7f-71fb-4971-8480-62344720ad8c
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 18:15:01.520: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8871" for this suite.
Oct 28 18:15:23.545: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 18:15:23.707: INFO: namespace configmap-8871 deletion completed in 22.180301161s

• [SLOW TEST:92.765 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 18:15:23.707: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-7176
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the container
STEP: wait for the container to reach Failed
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Oct 28 18:15:29.904: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 18:15:29.934: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-7176" for this suite.
Oct 28 18:15:35.963: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 18:15:36.135: INFO: namespace container-runtime-7176 deletion completed in 6.191035177s

• [SLOW TEST:12.428 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  blackbox test
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
    on terminated container
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:129
      should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-api-machinery] Secrets 
  should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 18:15:36.135: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-558
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name secret-emptykey-test-28620c1a-1bc4-4c2a-89ce-a1b38d2c22bc
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 18:15:36.291: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-558" for this suite.
Oct 28 18:15:42.310: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 18:15:42.483: INFO: namespace secrets-558 deletion completed in 6.187111346s

• [SLOW TEST:6.348 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 18:15:42.484: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-5372
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-map-b69fab21-a4c9-4172-aded-62c4a3ab972f
STEP: Creating a pod to test consume configMaps
Oct 28 18:15:42.659: INFO: Waiting up to 5m0s for pod "pod-configmaps-20b3b8ab-3189-487f-927e-a07d07ab5082" in namespace "configmap-5372" to be "success or failure"
Oct 28 18:15:42.668: INFO: Pod "pod-configmaps-20b3b8ab-3189-487f-927e-a07d07ab5082": Phase="Pending", Reason="", readiness=false. Elapsed: 9.103136ms
Oct 28 18:15:44.673: INFO: Pod "pod-configmaps-20b3b8ab-3189-487f-927e-a07d07ab5082": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014167052s
Oct 28 18:15:46.678: INFO: Pod "pod-configmaps-20b3b8ab-3189-487f-927e-a07d07ab5082": Phase="Pending", Reason="", readiness=false. Elapsed: 4.018816265s
Oct 28 18:15:48.683: INFO: Pod "pod-configmaps-20b3b8ab-3189-487f-927e-a07d07ab5082": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.023700677s
STEP: Saw pod success
Oct 28 18:15:48.683: INFO: Pod "pod-configmaps-20b3b8ab-3189-487f-927e-a07d07ab5082" satisfied condition "success or failure"
Oct 28 18:15:48.687: INFO: Trying to get logs from node kh4ga-worker-000000 pod pod-configmaps-20b3b8ab-3189-487f-927e-a07d07ab5082 container configmap-volume-test: <nil>
STEP: delete the pod
Oct 28 18:15:48.730: INFO: Waiting for pod pod-configmaps-20b3b8ab-3189-487f-927e-a07d07ab5082 to disappear
Oct 28 18:15:48.742: INFO: Pod pod-configmaps-20b3b8ab-3189-487f-927e-a07d07ab5082 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 18:15:48.743: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5372" for this suite.
Oct 28 18:15:54.768: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 18:15:54.939: INFO: namespace configmap-5372 deletion completed in 6.189639725s

• [SLOW TEST:12.455 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] version v1
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 18:15:54.939: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-1448
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-kdhrj in namespace proxy-1448
I1028 18:15:55.110250      19 runners.go:180] Created replication controller with name: proxy-service-kdhrj, namespace: proxy-1448, replica count: 1
I1028 18:15:56.160740      19 runners.go:180] proxy-service-kdhrj Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1028 18:15:57.160994      19 runners.go:180] proxy-service-kdhrj Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1028 18:15:58.161291      19 runners.go:180] proxy-service-kdhrj Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1028 18:15:59.161646      19 runners.go:180] proxy-service-kdhrj Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1028 18:16:00.161948      19 runners.go:180] proxy-service-kdhrj Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1028 18:16:01.162252      19 runners.go:180] proxy-service-kdhrj Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1028 18:16:02.162552      19 runners.go:180] proxy-service-kdhrj Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1028 18:16:03.162753      19 runners.go:180] proxy-service-kdhrj Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1028 18:16:04.163096      19 runners.go:180] proxy-service-kdhrj Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1028 18:16:05.163452      19 runners.go:180] proxy-service-kdhrj Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1028 18:16:06.163819      19 runners.go:180] proxy-service-kdhrj Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Oct 28 18:16:06.168: INFO: setup took 11.081228225s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Oct 28 18:16:06.181: INFO: (0) /api/v1/namespaces/proxy-1448/pods/proxy-service-kdhrj-l2czr:1080/proxy/: <a href="/api/v1/namespaces/proxy-1448/pods/proxy-service-kdhrj-l2czr:1080/proxy/rewriteme">test<... (200; 13.286553ms)
Oct 28 18:16:06.182: INFO: (0) /api/v1/namespaces/proxy-1448/pods/proxy-service-kdhrj-l2czr/proxy/: <a href="/api/v1/namespaces/proxy-1448/pods/proxy-service-kdhrj-l2czr/proxy/rewriteme">test</a> (200; 13.435054ms)
Oct 28 18:16:06.183: INFO: (0) /api/v1/namespaces/proxy-1448/pods/http:proxy-service-kdhrj-l2czr:162/proxy/: bar (200; 14.712459ms)
Oct 28 18:16:06.183: INFO: (0) /api/v1/namespaces/proxy-1448/pods/proxy-service-kdhrj-l2czr:160/proxy/: foo (200; 15.260561ms)
Oct 28 18:16:06.185: INFO: (0) /api/v1/namespaces/proxy-1448/pods/http:proxy-service-kdhrj-l2czr:1080/proxy/: <a href="/api/v1/namespaces/proxy-1448/pods/http:proxy-service-kdhrj-l2czr:1080/proxy/rewriteme">... (200; 16.926967ms)
Oct 28 18:16:06.185: INFO: (0) /api/v1/namespaces/proxy-1448/pods/proxy-service-kdhrj-l2czr:162/proxy/: bar (200; 17.005567ms)
Oct 28 18:16:06.185: INFO: (0) /api/v1/namespaces/proxy-1448/pods/http:proxy-service-kdhrj-l2czr:160/proxy/: foo (200; 17.396969ms)
Oct 28 18:16:06.189: INFO: (0) /api/v1/namespaces/proxy-1448/services/proxy-service-kdhrj:portname1/proxy/: foo (200; 21.031884ms)
Oct 28 18:16:06.189: INFO: (0) /api/v1/namespaces/proxy-1448/services/http:proxy-service-kdhrj:portname1/proxy/: foo (200; 21.241985ms)
Oct 28 18:16:06.189: INFO: (0) /api/v1/namespaces/proxy-1448/services/http:proxy-service-kdhrj:portname2/proxy/: bar (200; 21.259785ms)
Oct 28 18:16:06.190: INFO: (0) /api/v1/namespaces/proxy-1448/services/proxy-service-kdhrj:portname2/proxy/: bar (200; 21.690286ms)
Oct 28 18:16:06.192: INFO: (0) /api/v1/namespaces/proxy-1448/services/https:proxy-service-kdhrj:tlsportname2/proxy/: tls qux (200; 23.805795ms)
Oct 28 18:16:06.193: INFO: (0) /api/v1/namespaces/proxy-1448/pods/https:proxy-service-kdhrj-l2czr:460/proxy/: tls baz (200; 25.232501ms)
Oct 28 18:16:06.194: INFO: (0) /api/v1/namespaces/proxy-1448/pods/https:proxy-service-kdhrj-l2czr:462/proxy/: tls qux (200; 25.641103ms)
Oct 28 18:16:06.196: INFO: (0) /api/v1/namespaces/proxy-1448/services/https:proxy-service-kdhrj:tlsportname1/proxy/: tls baz (200; 27.59481ms)
Oct 28 18:16:06.199: INFO: (0) /api/v1/namespaces/proxy-1448/pods/https:proxy-service-kdhrj-l2czr:443/proxy/: <a href="/api/v1/namespaces/proxy-1448/pods/https:proxy-service-kdhrj-l2czr:443/proxy/tlsrewritem... (200; 31.275925ms)
Oct 28 18:16:06.209: INFO: (1) /api/v1/namespaces/proxy-1448/pods/proxy-service-kdhrj-l2czr:162/proxy/: bar (200; 9.765938ms)
Oct 28 18:16:06.212: INFO: (1) /api/v1/namespaces/proxy-1448/pods/https:proxy-service-kdhrj-l2czr:443/proxy/: <a href="/api/v1/namespaces/proxy-1448/pods/https:proxy-service-kdhrj-l2czr:443/proxy/tlsrewritem... (200; 11.979847ms)
Oct 28 18:16:06.212: INFO: (1) /api/v1/namespaces/proxy-1448/pods/http:proxy-service-kdhrj-l2czr:162/proxy/: bar (200; 11.924648ms)
Oct 28 18:16:06.212: INFO: (1) /api/v1/namespaces/proxy-1448/pods/http:proxy-service-kdhrj-l2czr:1080/proxy/: <a href="/api/v1/namespaces/proxy-1448/pods/http:proxy-service-kdhrj-l2czr:1080/proxy/rewriteme">... (200; 12.158149ms)
Oct 28 18:16:06.213: INFO: (1) /api/v1/namespaces/proxy-1448/pods/proxy-service-kdhrj-l2czr/proxy/: <a href="/api/v1/namespaces/proxy-1448/pods/proxy-service-kdhrj-l2czr/proxy/rewriteme">test</a> (200; 13.616354ms)
Oct 28 18:16:06.213: INFO: (1) /api/v1/namespaces/proxy-1448/pods/http:proxy-service-kdhrj-l2czr:160/proxy/: foo (200; 13.748354ms)
Oct 28 18:16:06.214: INFO: (1) /api/v1/namespaces/proxy-1448/pods/https:proxy-service-kdhrj-l2czr:460/proxy/: tls baz (200; 14.440457ms)
Oct 28 18:16:06.214: INFO: (1) /api/v1/namespaces/proxy-1448/pods/proxy-service-kdhrj-l2czr:160/proxy/: foo (200; 14.111557ms)
Oct 28 18:16:06.214: INFO: (1) /api/v1/namespaces/proxy-1448/services/proxy-service-kdhrj:portname2/proxy/: bar (200; 14.450458ms)
Oct 28 18:16:06.214: INFO: (1) /api/v1/namespaces/proxy-1448/pods/https:proxy-service-kdhrj-l2czr:462/proxy/: tls qux (200; 14.895359ms)
Oct 28 18:16:06.216: INFO: (1) /api/v1/namespaces/proxy-1448/services/proxy-service-kdhrj:portname1/proxy/: foo (200; 16.036264ms)
Oct 28 18:16:06.216: INFO: (1) /api/v1/namespaces/proxy-1448/pods/proxy-service-kdhrj-l2czr:1080/proxy/: <a href="/api/v1/namespaces/proxy-1448/pods/proxy-service-kdhrj-l2czr:1080/proxy/rewriteme">test<... (200; 16.345466ms)
Oct 28 18:16:06.217: INFO: (1) /api/v1/namespaces/proxy-1448/services/http:proxy-service-kdhrj:portname1/proxy/: foo (200; 17.170368ms)
Oct 28 18:16:06.217: INFO: (1) /api/v1/namespaces/proxy-1448/services/http:proxy-service-kdhrj:portname2/proxy/: bar (200; 17.111368ms)
Oct 28 18:16:06.218: INFO: (1) /api/v1/namespaces/proxy-1448/services/https:proxy-service-kdhrj:tlsportname2/proxy/: tls qux (200; 18.410974ms)
Oct 28 18:16:06.218: INFO: (1) /api/v1/namespaces/proxy-1448/services/https:proxy-service-kdhrj:tlsportname1/proxy/: tls baz (200; 18.240273ms)
Oct 28 18:16:06.230: INFO: (2) /api/v1/namespaces/proxy-1448/pods/http:proxy-service-kdhrj-l2czr:1080/proxy/: <a href="/api/v1/namespaces/proxy-1448/pods/http:proxy-service-kdhrj-l2czr:1080/proxy/rewriteme">... (200; 11.474445ms)
Oct 28 18:16:06.231: INFO: (2) /api/v1/namespaces/proxy-1448/pods/proxy-service-kdhrj-l2czr:1080/proxy/: <a href="/api/v1/namespaces/proxy-1448/pods/proxy-service-kdhrj-l2czr:1080/proxy/rewriteme">test<... (200; 13.345153ms)
Oct 28 18:16:06.232: INFO: (2) /api/v1/namespaces/proxy-1448/pods/http:proxy-service-kdhrj-l2czr:162/proxy/: bar (200; 13.907956ms)
Oct 28 18:16:06.232: INFO: (2) /api/v1/namespaces/proxy-1448/pods/proxy-service-kdhrj-l2czr/proxy/: <a href="/api/v1/namespaces/proxy-1448/pods/proxy-service-kdhrj-l2czr/proxy/rewriteme">test</a> (200; 13.639955ms)
Oct 28 18:16:06.233: INFO: (2) /api/v1/namespaces/proxy-1448/services/http:proxy-service-kdhrj:portname1/proxy/: foo (200; 14.900259ms)
Oct 28 18:16:06.234: INFO: (2) /api/v1/namespaces/proxy-1448/pods/proxy-service-kdhrj-l2czr:162/proxy/: bar (200; 16.365265ms)
Oct 28 18:16:06.235: INFO: (2) /api/v1/namespaces/proxy-1448/pods/proxy-service-kdhrj-l2czr:160/proxy/: foo (200; 16.407366ms)
Oct 28 18:16:06.235: INFO: (2) /api/v1/namespaces/proxy-1448/pods/https:proxy-service-kdhrj-l2czr:462/proxy/: tls qux (200; 16.642166ms)
Oct 28 18:16:06.235: INFO: (2) /api/v1/namespaces/proxy-1448/services/https:proxy-service-kdhrj:tlsportname2/proxy/: tls qux (200; 16.705467ms)
Oct 28 18:16:06.235: INFO: (2) /api/v1/namespaces/proxy-1448/pods/https:proxy-service-kdhrj-l2czr:460/proxy/: tls baz (200; 16.867767ms)
Oct 28 18:16:06.235: INFO: (2) /api/v1/namespaces/proxy-1448/services/proxy-service-kdhrj:portname2/proxy/: bar (200; 17.39887ms)
Oct 28 18:16:06.235: INFO: (2) /api/v1/namespaces/proxy-1448/pods/http:proxy-service-kdhrj-l2czr:160/proxy/: foo (200; 17.146868ms)
Oct 28 18:16:06.236: INFO: (2) /api/v1/namespaces/proxy-1448/services/https:proxy-service-kdhrj:tlsportname1/proxy/: tls baz (200; 18.090472ms)
Oct 28 18:16:06.236: INFO: (2) /api/v1/namespaces/proxy-1448/services/http:proxy-service-kdhrj:portname2/proxy/: bar (200; 18.480474ms)
Oct 28 18:16:06.237: INFO: (2) /api/v1/namespaces/proxy-1448/services/proxy-service-kdhrj:portname1/proxy/: foo (200; 18.537174ms)
Oct 28 18:16:06.237: INFO: (2) /api/v1/namespaces/proxy-1448/pods/https:proxy-service-kdhrj-l2czr:443/proxy/: <a href="/api/v1/namespaces/proxy-1448/pods/https:proxy-service-kdhrj-l2czr:443/proxy/tlsrewritem... (200; 18.824475ms)
Oct 28 18:16:06.247: INFO: (3) /api/v1/namespaces/proxy-1448/pods/http:proxy-service-kdhrj-l2czr:160/proxy/: foo (200; 10.00804ms)
Oct 28 18:16:06.247: INFO: (3) /api/v1/namespaces/proxy-1448/pods/proxy-service-kdhrj-l2czr:1080/proxy/: <a href="/api/v1/namespaces/proxy-1448/pods/proxy-service-kdhrj-l2czr:1080/proxy/rewriteme">test<... (200; 9.93694ms)
Oct 28 18:16:06.248: INFO: (3) /api/v1/namespaces/proxy-1448/pods/http:proxy-service-kdhrj-l2czr:162/proxy/: bar (200; 11.098344ms)
Oct 28 18:16:06.250: INFO: (3) /api/v1/namespaces/proxy-1448/pods/proxy-service-kdhrj-l2czr:160/proxy/: foo (200; 13.244653ms)
Oct 28 18:16:06.250: INFO: (3) /api/v1/namespaces/proxy-1448/pods/http:proxy-service-kdhrj-l2czr:1080/proxy/: <a href="/api/v1/namespaces/proxy-1448/pods/http:proxy-service-kdhrj-l2czr:1080/proxy/rewriteme">... (200; 13.282553ms)
Oct 28 18:16:06.250: INFO: (3) /api/v1/namespaces/proxy-1448/pods/https:proxy-service-kdhrj-l2czr:460/proxy/: tls baz (200; 13.094653ms)
Oct 28 18:16:06.251: INFO: (3) /api/v1/namespaces/proxy-1448/pods/proxy-service-kdhrj-l2czr:162/proxy/: bar (200; 13.376753ms)
Oct 28 18:16:06.252: INFO: (3) /api/v1/namespaces/proxy-1448/pods/https:proxy-service-kdhrj-l2czr:443/proxy/: <a href="/api/v1/namespaces/proxy-1448/pods/https:proxy-service-kdhrj-l2czr:443/proxy/tlsrewritem... (200; 14.562458ms)
Oct 28 18:16:06.252: INFO: (3) /api/v1/namespaces/proxy-1448/pods/https:proxy-service-kdhrj-l2czr:462/proxy/: tls qux (200; 14.652959ms)
Oct 28 18:16:06.252: INFO: (3) /api/v1/namespaces/proxy-1448/services/https:proxy-service-kdhrj:tlsportname1/proxy/: tls baz (200; 14.94216ms)
Oct 28 18:16:06.253: INFO: (3) /api/v1/namespaces/proxy-1448/services/http:proxy-service-kdhrj:portname1/proxy/: foo (200; 16.265465ms)
Oct 28 18:16:06.254: INFO: (3) /api/v1/namespaces/proxy-1448/services/http:proxy-service-kdhrj:portname2/proxy/: bar (200; 16.740067ms)
Oct 28 18:16:06.254: INFO: (3) /api/v1/namespaces/proxy-1448/services/https:proxy-service-kdhrj:tlsportname2/proxy/: tls qux (200; 17.176669ms)
Oct 28 18:16:06.256: INFO: (3) /api/v1/namespaces/proxy-1448/pods/proxy-service-kdhrj-l2czr/proxy/: <a href="/api/v1/namespaces/proxy-1448/pods/proxy-service-kdhrj-l2czr/proxy/rewriteme">test</a> (200; 18.994876ms)
Oct 28 18:16:06.257: INFO: (3) /api/v1/namespaces/proxy-1448/services/proxy-service-kdhrj:portname2/proxy/: bar (200; 19.92268ms)
Oct 28 18:16:06.257: INFO: (3) /api/v1/namespaces/proxy-1448/services/proxy-service-kdhrj:portname1/proxy/: foo (200; 20.220181ms)
Oct 28 18:16:06.263: INFO: (4) /api/v1/namespaces/proxy-1448/pods/https:proxy-service-kdhrj-l2czr:460/proxy/: tls baz (200; 6.056324ms)
Oct 28 18:16:06.267: INFO: (4) /api/v1/namespaces/proxy-1448/pods/http:proxy-service-kdhrj-l2czr:160/proxy/: foo (200; 9.449638ms)
Oct 28 18:16:06.267: INFO: (4) /api/v1/namespaces/proxy-1448/pods/proxy-service-kdhrj-l2czr:1080/proxy/: <a href="/api/v1/namespaces/proxy-1448/pods/proxy-service-kdhrj-l2czr:1080/proxy/rewriteme">test<... (200; 9.98964ms)
Oct 28 18:16:06.270: INFO: (4) /api/v1/namespaces/proxy-1448/services/http:proxy-service-kdhrj:portname1/proxy/: foo (200; 12.755751ms)
Oct 28 18:16:06.271: INFO: (4) /api/v1/namespaces/proxy-1448/pods/https:proxy-service-kdhrj-l2czr:443/proxy/: <a href="/api/v1/namespaces/proxy-1448/pods/https:proxy-service-kdhrj-l2czr:443/proxy/tlsrewritem... (200; 13.357454ms)
Oct 28 18:16:06.272: INFO: (4) /api/v1/namespaces/proxy-1448/pods/proxy-service-kdhrj-l2czr:160/proxy/: foo (200; 14.852559ms)
Oct 28 18:16:06.272: INFO: (4) /api/v1/namespaces/proxy-1448/pods/proxy-service-kdhrj-l2czr/proxy/: <a href="/api/v1/namespaces/proxy-1448/pods/proxy-service-kdhrj-l2czr/proxy/rewriteme">test</a> (200; 14.796259ms)
Oct 28 18:16:06.275: INFO: (4) /api/v1/namespaces/proxy-1448/pods/proxy-service-kdhrj-l2czr:162/proxy/: bar (200; 17.218169ms)
Oct 28 18:16:06.275: INFO: (4) /api/v1/namespaces/proxy-1448/services/proxy-service-kdhrj:portname1/proxy/: foo (200; 17.312369ms)
Oct 28 18:16:06.275: INFO: (4) /api/v1/namespaces/proxy-1448/services/http:proxy-service-kdhrj:portname2/proxy/: bar (200; 17.301969ms)
Oct 28 18:16:06.275: INFO: (4) /api/v1/namespaces/proxy-1448/services/https:proxy-service-kdhrj:tlsportname2/proxy/: tls qux (200; 17.242169ms)
Oct 28 18:16:06.275: INFO: (4) /api/v1/namespaces/proxy-1448/services/https:proxy-service-kdhrj:tlsportname1/proxy/: tls baz (200; 17.313469ms)
Oct 28 18:16:06.275: INFO: (4) /api/v1/namespaces/proxy-1448/pods/https:proxy-service-kdhrj-l2czr:462/proxy/: tls qux (200; 17.588571ms)
Oct 28 18:16:06.278: INFO: (4) /api/v1/namespaces/proxy-1448/services/proxy-service-kdhrj:portname2/proxy/: bar (200; 20.463382ms)
Oct 28 18:16:06.278: INFO: (4) /api/v1/namespaces/proxy-1448/pods/http:proxy-service-kdhrj-l2czr:162/proxy/: bar (200; 20.658582ms)
Oct 28 18:16:06.278: INFO: (4) /api/v1/namespaces/proxy-1448/pods/http:proxy-service-kdhrj-l2czr:1080/proxy/: <a href="/api/v1/namespaces/proxy-1448/pods/http:proxy-service-kdhrj-l2czr:1080/proxy/rewriteme">... (200; 20.437382ms)
Oct 28 18:16:06.291: INFO: (5) /api/v1/namespaces/proxy-1448/pods/proxy-service-kdhrj-l2czr:162/proxy/: bar (200; 12.880951ms)
Oct 28 18:16:06.291: INFO: (5) /api/v1/namespaces/proxy-1448/pods/proxy-service-kdhrj-l2czr/proxy/: <a href="/api/v1/namespaces/proxy-1448/pods/proxy-service-kdhrj-l2czr/proxy/rewriteme">test</a> (200; 12.976151ms)
Oct 28 18:16:06.291: INFO: (5) /api/v1/namespaces/proxy-1448/pods/http:proxy-service-kdhrj-l2czr:160/proxy/: foo (200; 13.030452ms)
Oct 28 18:16:06.293: INFO: (5) /api/v1/namespaces/proxy-1448/pods/https:proxy-service-kdhrj-l2czr:462/proxy/: tls qux (200; 14.166656ms)
Oct 28 18:16:06.293: INFO: (5) /api/v1/namespaces/proxy-1448/pods/proxy-service-kdhrj-l2czr:1080/proxy/: <a href="/api/v1/namespaces/proxy-1448/pods/proxy-service-kdhrj-l2czr:1080/proxy/rewriteme">test<... (200; 14.360357ms)
Oct 28 18:16:06.293: INFO: (5) /api/v1/namespaces/proxy-1448/pods/https:proxy-service-kdhrj-l2czr:460/proxy/: tls baz (200; 14.391058ms)
Oct 28 18:16:06.293: INFO: (5) /api/v1/namespaces/proxy-1448/pods/http:proxy-service-kdhrj-l2czr:162/proxy/: bar (200; 14.705259ms)
Oct 28 18:16:06.294: INFO: (5) /api/v1/namespaces/proxy-1448/pods/proxy-service-kdhrj-l2czr:160/proxy/: foo (200; 15.302761ms)
Oct 28 18:16:06.294: INFO: (5) /api/v1/namespaces/proxy-1448/pods/http:proxy-service-kdhrj-l2czr:1080/proxy/: <a href="/api/v1/namespaces/proxy-1448/pods/http:proxy-service-kdhrj-l2czr:1080/proxy/rewriteme">... (200; 15.635663ms)
Oct 28 18:16:06.295: INFO: (5) /api/v1/namespaces/proxy-1448/services/http:proxy-service-kdhrj:portname2/proxy/: bar (200; 16.501566ms)
Oct 28 18:16:06.295: INFO: (5) /api/v1/namespaces/proxy-1448/pods/https:proxy-service-kdhrj-l2czr:443/proxy/: <a href="/api/v1/namespaces/proxy-1448/pods/https:proxy-service-kdhrj-l2czr:443/proxy/tlsrewritem... (200; 16.287165ms)
Oct 28 18:16:06.295: INFO: (5) /api/v1/namespaces/proxy-1448/services/proxy-service-kdhrj:portname1/proxy/: foo (200; 16.631567ms)
Oct 28 18:16:06.295: INFO: (5) /api/v1/namespaces/proxy-1448/services/https:proxy-service-kdhrj:tlsportname2/proxy/: tls qux (200; 16.715267ms)
Oct 28 18:16:06.296: INFO: (5) /api/v1/namespaces/proxy-1448/services/proxy-service-kdhrj:portname2/proxy/: bar (200; 17.53317ms)
Oct 28 18:16:06.296: INFO: (5) /api/v1/namespaces/proxy-1448/services/https:proxy-service-kdhrj:tlsportname1/proxy/: tls baz (200; 17.47057ms)
Oct 28 18:16:06.297: INFO: (5) /api/v1/namespaces/proxy-1448/services/http:proxy-service-kdhrj:portname1/proxy/: foo (200; 19.087676ms)
Oct 28 18:16:06.308: INFO: (6) /api/v1/namespaces/proxy-1448/pods/http:proxy-service-kdhrj-l2czr:162/proxy/: bar (200; 10.471542ms)
Oct 28 18:16:06.308: INFO: (6) /api/v1/namespaces/proxy-1448/pods/http:proxy-service-kdhrj-l2czr:1080/proxy/: <a href="/api/v1/namespaces/proxy-1448/pods/http:proxy-service-kdhrj-l2czr:1080/proxy/rewriteme">... (200; 10.683243ms)
Oct 28 18:16:06.311: INFO: (6) /api/v1/namespaces/proxy-1448/pods/http:proxy-service-kdhrj-l2czr:160/proxy/: foo (200; 13.276153ms)
Oct 28 18:16:06.311: INFO: (6) /api/v1/namespaces/proxy-1448/services/proxy-service-kdhrj:portname2/proxy/: bar (200; 13.887956ms)
Oct 28 18:16:06.313: INFO: (6) /api/v1/namespaces/proxy-1448/pods/proxy-service-kdhrj-l2czr:162/proxy/: bar (200; 15.380161ms)
Oct 28 18:16:06.313: INFO: (6) /api/v1/namespaces/proxy-1448/pods/https:proxy-service-kdhrj-l2czr:443/proxy/: <a href="/api/v1/namespaces/proxy-1448/pods/https:proxy-service-kdhrj-l2czr:443/proxy/tlsrewritem... (200; 15.408261ms)
Oct 28 18:16:06.315: INFO: (6) /api/v1/namespaces/proxy-1448/services/https:proxy-service-kdhrj:tlsportname2/proxy/: tls qux (200; 17.042368ms)
Oct 28 18:16:06.315: INFO: (6) /api/v1/namespaces/proxy-1448/pods/proxy-service-kdhrj-l2czr:1080/proxy/: <a href="/api/v1/namespaces/proxy-1448/pods/proxy-service-kdhrj-l2czr:1080/proxy/rewriteme">test<... (200; 16.978667ms)
Oct 28 18:16:06.315: INFO: (6) /api/v1/namespaces/proxy-1448/pods/https:proxy-service-kdhrj-l2czr:462/proxy/: tls qux (200; 17.40077ms)
Oct 28 18:16:06.315: INFO: (6) /api/v1/namespaces/proxy-1448/pods/https:proxy-service-kdhrj-l2czr:460/proxy/: tls baz (200; 17.415669ms)
Oct 28 18:16:06.315: INFO: (6) /api/v1/namespaces/proxy-1448/pods/proxy-service-kdhrj-l2czr/proxy/: <a href="/api/v1/namespaces/proxy-1448/pods/proxy-service-kdhrj-l2czr/proxy/rewriteme">test</a> (200; 17.47737ms)
Oct 28 18:16:06.316: INFO: (6) /api/v1/namespaces/proxy-1448/pods/proxy-service-kdhrj-l2czr:160/proxy/: foo (200; 17.853971ms)
Oct 28 18:16:06.318: INFO: (6) /api/v1/namespaces/proxy-1448/services/http:proxy-service-kdhrj:portname1/proxy/: foo (200; 19.995479ms)
Oct 28 18:16:06.318: INFO: (6) /api/v1/namespaces/proxy-1448/services/proxy-service-kdhrj:portname1/proxy/: foo (200; 19.902179ms)
Oct 28 18:16:06.318: INFO: (6) /api/v1/namespaces/proxy-1448/services/https:proxy-service-kdhrj:tlsportname1/proxy/: tls baz (200; 19.92348ms)
Oct 28 18:16:06.318: INFO: (6) /api/v1/namespaces/proxy-1448/services/http:proxy-service-kdhrj:portname2/proxy/: bar (200; 20.434281ms)
Oct 28 18:16:06.331: INFO: (7) /api/v1/namespaces/proxy-1448/pods/https:proxy-service-kdhrj-l2czr:460/proxy/: tls baz (200; 12.638951ms)
Oct 28 18:16:06.331: INFO: (7) /api/v1/namespaces/proxy-1448/pods/proxy-service-kdhrj-l2czr:1080/proxy/: <a href="/api/v1/namespaces/proxy-1448/pods/proxy-service-kdhrj-l2czr:1080/proxy/rewriteme">test<... (200; 12.658751ms)
Oct 28 18:16:06.331: INFO: (7) /api/v1/namespaces/proxy-1448/pods/proxy-service-kdhrj-l2czr:162/proxy/: bar (200; 12.832551ms)
Oct 28 18:16:06.331: INFO: (7) /api/v1/namespaces/proxy-1448/pods/https:proxy-service-kdhrj-l2czr:443/proxy/: <a href="/api/v1/namespaces/proxy-1448/pods/https:proxy-service-kdhrj-l2czr:443/proxy/tlsrewritem... (200; 12.782651ms)
Oct 28 18:16:06.333: INFO: (7) /api/v1/namespaces/proxy-1448/services/http:proxy-service-kdhrj:portname1/proxy/: foo (200; 14.530958ms)
Oct 28 18:16:06.335: INFO: (7) /api/v1/namespaces/proxy-1448/pods/http:proxy-service-kdhrj-l2czr:1080/proxy/: <a href="/api/v1/namespaces/proxy-1448/pods/http:proxy-service-kdhrj-l2czr:1080/proxy/rewriteme">... (200; 17.148268ms)
Oct 28 18:16:06.336: INFO: (7) /api/v1/namespaces/proxy-1448/pods/http:proxy-service-kdhrj-l2czr:160/proxy/: foo (200; 17.410569ms)
Oct 28 18:16:06.336: INFO: (7) /api/v1/namespaces/proxy-1448/pods/proxy-service-kdhrj-l2czr:160/proxy/: foo (200; 17.69807ms)
Oct 28 18:16:06.336: INFO: (7) /api/v1/namespaces/proxy-1448/pods/https:proxy-service-kdhrj-l2czr:462/proxy/: tls qux (200; 17.423669ms)
Oct 28 18:16:06.336: INFO: (7) /api/v1/namespaces/proxy-1448/pods/proxy-service-kdhrj-l2czr/proxy/: <a href="/api/v1/namespaces/proxy-1448/pods/proxy-service-kdhrj-l2czr/proxy/rewriteme">test</a> (200; 17.348969ms)
Oct 28 18:16:06.336: INFO: (7) /api/v1/namespaces/proxy-1448/pods/http:proxy-service-kdhrj-l2czr:162/proxy/: bar (200; 17.63657ms)
Oct 28 18:16:06.336: INFO: (7) /api/v1/namespaces/proxy-1448/services/http:proxy-service-kdhrj:portname2/proxy/: bar (200; 17.914071ms)
Oct 28 18:16:06.336: INFO: (7) /api/v1/namespaces/proxy-1448/services/https:proxy-service-kdhrj:tlsportname1/proxy/: tls baz (200; 17.872172ms)
Oct 28 18:16:06.336: INFO: (7) /api/v1/namespaces/proxy-1448/services/https:proxy-service-kdhrj:tlsportname2/proxy/: tls qux (200; 18.307973ms)
Oct 28 18:16:06.337: INFO: (7) /api/v1/namespaces/proxy-1448/services/proxy-service-kdhrj:portname1/proxy/: foo (200; 18.431574ms)
Oct 28 18:16:06.338: INFO: (7) /api/v1/namespaces/proxy-1448/services/proxy-service-kdhrj:portname2/proxy/: bar (200; 19.84368ms)
Oct 28 18:16:06.349: INFO: (8) /api/v1/namespaces/proxy-1448/pods/http:proxy-service-kdhrj-l2czr:162/proxy/: bar (200; 10.26544ms)
Oct 28 18:16:06.350: INFO: (8) /api/v1/namespaces/proxy-1448/pods/proxy-service-kdhrj-l2czr:160/proxy/: foo (200; 11.013244ms)
Oct 28 18:16:06.351: INFO: (8) /api/v1/namespaces/proxy-1448/pods/https:proxy-service-kdhrj-l2czr:443/proxy/: <a href="/api/v1/namespaces/proxy-1448/pods/https:proxy-service-kdhrj-l2czr:443/proxy/tlsrewritem... (200; 12.46155ms)
Oct 28 18:16:06.351: INFO: (8) /api/v1/namespaces/proxy-1448/pods/https:proxy-service-kdhrj-l2czr:462/proxy/: tls qux (200; 12.55625ms)
Oct 28 18:16:06.352: INFO: (8) /api/v1/namespaces/proxy-1448/pods/proxy-service-kdhrj-l2czr/proxy/: <a href="/api/v1/namespaces/proxy-1448/pods/proxy-service-kdhrj-l2czr/proxy/rewriteme">test</a> (200; 13.221452ms)
Oct 28 18:16:06.355: INFO: (8) /api/v1/namespaces/proxy-1448/pods/proxy-service-kdhrj-l2czr:162/proxy/: bar (200; 15.822463ms)
Oct 28 18:16:06.355: INFO: (8) /api/v1/namespaces/proxy-1448/pods/proxy-service-kdhrj-l2czr:1080/proxy/: <a href="/api/v1/namespaces/proxy-1448/pods/proxy-service-kdhrj-l2czr:1080/proxy/rewriteme">test<... (200; 16.730867ms)
Oct 28 18:16:06.357: INFO: (8) /api/v1/namespaces/proxy-1448/pods/http:proxy-service-kdhrj-l2czr:160/proxy/: foo (200; 18.168673ms)
Oct 28 18:16:06.357: INFO: (8) /api/v1/namespaces/proxy-1448/services/proxy-service-kdhrj:portname1/proxy/: foo (200; 18.385874ms)
Oct 28 18:16:06.357: INFO: (8) /api/v1/namespaces/proxy-1448/pods/http:proxy-service-kdhrj-l2czr:1080/proxy/: <a href="/api/v1/namespaces/proxy-1448/pods/http:proxy-service-kdhrj-l2czr:1080/proxy/rewriteme">... (200; 18.304073ms)
Oct 28 18:16:06.357: INFO: (8) /api/v1/namespaces/proxy-1448/pods/https:proxy-service-kdhrj-l2czr:460/proxy/: tls baz (200; 18.505874ms)
Oct 28 18:16:06.358: INFO: (8) /api/v1/namespaces/proxy-1448/services/https:proxy-service-kdhrj:tlsportname1/proxy/: tls baz (200; 19.375178ms)
Oct 28 18:16:06.358: INFO: (8) /api/v1/namespaces/proxy-1448/services/http:proxy-service-kdhrj:portname1/proxy/: foo (200; 19.698379ms)
Oct 28 18:16:06.358: INFO: (8) /api/v1/namespaces/proxy-1448/services/proxy-service-kdhrj:portname2/proxy/: bar (200; 19.576578ms)
Oct 28 18:16:06.358: INFO: (8) /api/v1/namespaces/proxy-1448/services/https:proxy-service-kdhrj:tlsportname2/proxy/: tls qux (200; 19.595778ms)
Oct 28 18:16:06.359: INFO: (8) /api/v1/namespaces/proxy-1448/services/http:proxy-service-kdhrj:portname2/proxy/: bar (200; 19.925379ms)
Oct 28 18:16:06.370: INFO: (9) /api/v1/namespaces/proxy-1448/pods/https:proxy-service-kdhrj-l2czr:462/proxy/: tls qux (200; 11.270045ms)
Oct 28 18:16:06.373: INFO: (9) /api/v1/namespaces/proxy-1448/services/proxy-service-kdhrj:portname1/proxy/: foo (200; 14.409757ms)
Oct 28 18:16:06.376: INFO: (9) /api/v1/namespaces/proxy-1448/services/https:proxy-service-kdhrj:tlsportname2/proxy/: tls qux (200; 16.660667ms)
Oct 28 18:16:06.376: INFO: (9) /api/v1/namespaces/proxy-1448/pods/proxy-service-kdhrj-l2czr:1080/proxy/: <a href="/api/v1/namespaces/proxy-1448/pods/proxy-service-kdhrj-l2czr:1080/proxy/rewriteme">test<... (200; 16.766067ms)
Oct 28 18:16:06.377: INFO: (9) /api/v1/namespaces/proxy-1448/pods/https:proxy-service-kdhrj-l2czr:443/proxy/: <a href="/api/v1/namespaces/proxy-1448/pods/https:proxy-service-kdhrj-l2czr:443/proxy/tlsrewritem... (200; 18.002971ms)
Oct 28 18:16:06.377: INFO: (9) /api/v1/namespaces/proxy-1448/services/http:proxy-service-kdhrj:portname2/proxy/: bar (200; 18.363573ms)
Oct 28 18:16:06.379: INFO: (9) /api/v1/namespaces/proxy-1448/pods/http:proxy-service-kdhrj-l2czr:160/proxy/: foo (200; 20.376281ms)
Oct 28 18:16:06.380: INFO: (9) /api/v1/namespaces/proxy-1448/pods/https:proxy-service-kdhrj-l2czr:460/proxy/: tls baz (200; 21.452785ms)
Oct 28 18:16:06.382: INFO: (9) /api/v1/namespaces/proxy-1448/pods/http:proxy-service-kdhrj-l2czr:1080/proxy/: <a href="/api/v1/namespaces/proxy-1448/pods/http:proxy-service-kdhrj-l2czr:1080/proxy/rewriteme">... (200; 22.736391ms)
Oct 28 18:16:06.382: INFO: (9) /api/v1/namespaces/proxy-1448/pods/http:proxy-service-kdhrj-l2czr:162/proxy/: bar (200; 22.900891ms)
Oct 28 18:16:06.382: INFO: (9) /api/v1/namespaces/proxy-1448/pods/proxy-service-kdhrj-l2czr:162/proxy/: bar (200; 23.250693ms)
Oct 28 18:16:06.382: INFO: (9) /api/v1/namespaces/proxy-1448/services/http:proxy-service-kdhrj:portname1/proxy/: foo (200; 23.138892ms)
Oct 28 18:16:06.382: INFO: (9) /api/v1/namespaces/proxy-1448/pods/proxy-service-kdhrj-l2czr:160/proxy/: foo (200; 23.330893ms)
Oct 28 18:16:06.382: INFO: (9) /api/v1/namespaces/proxy-1448/pods/proxy-service-kdhrj-l2czr/proxy/: <a href="/api/v1/namespaces/proxy-1448/pods/proxy-service-kdhrj-l2czr/proxy/rewriteme">test</a> (200; 23.275993ms)
Oct 28 18:16:06.383: INFO: (9) /api/v1/namespaces/proxy-1448/services/proxy-service-kdhrj:portname2/proxy/: bar (200; 23.968996ms)
Oct 28 18:16:06.384: INFO: (9) /api/v1/namespaces/proxy-1448/services/https:proxy-service-kdhrj:tlsportname1/proxy/: tls baz (200; 25.415601ms)
Oct 28 18:16:06.405: INFO: (10) /api/v1/namespaces/proxy-1448/pods/http:proxy-service-kdhrj-l2czr:1080/proxy/: <a href="/api/v1/namespaces/proxy-1448/pods/http:proxy-service-kdhrj-l2czr:1080/proxy/rewriteme">... (200; 20.312481ms)
Oct 28 18:16:06.405: INFO: (10) /api/v1/namespaces/proxy-1448/pods/https:proxy-service-kdhrj-l2czr:462/proxy/: tls qux (200; 20.485281ms)
Oct 28 18:16:06.408: INFO: (10) /api/v1/namespaces/proxy-1448/pods/proxy-service-kdhrj-l2czr/proxy/: <a href="/api/v1/namespaces/proxy-1448/pods/proxy-service-kdhrj-l2czr/proxy/rewriteme">test</a> (200; 22.951891ms)
Oct 28 18:16:06.408: INFO: (10) /api/v1/namespaces/proxy-1448/pods/https:proxy-service-kdhrj-l2czr:460/proxy/: tls baz (200; 22.766791ms)
Oct 28 18:16:06.408: INFO: (10) /api/v1/namespaces/proxy-1448/pods/proxy-service-kdhrj-l2czr:162/proxy/: bar (200; 23.314593ms)
Oct 28 18:16:06.408: INFO: (10) /api/v1/namespaces/proxy-1448/pods/proxy-service-kdhrj-l2czr:160/proxy/: foo (200; 23.168492ms)
Oct 28 18:16:06.408: INFO: (10) /api/v1/namespaces/proxy-1448/pods/http:proxy-service-kdhrj-l2czr:160/proxy/: foo (200; 23.040592ms)
Oct 28 18:16:06.408: INFO: (10) /api/v1/namespaces/proxy-1448/services/http:proxy-service-kdhrj:portname2/proxy/: bar (200; 23.696594ms)
Oct 28 18:16:06.409: INFO: (10) /api/v1/namespaces/proxy-1448/pods/https:proxy-service-kdhrj-l2czr:443/proxy/: <a href="/api/v1/namespaces/proxy-1448/pods/https:proxy-service-kdhrj-l2czr:443/proxy/tlsrewritem... (200; 23.767095ms)
Oct 28 18:16:06.409: INFO: (10) /api/v1/namespaces/proxy-1448/pods/proxy-service-kdhrj-l2czr:1080/proxy/: <a href="/api/v1/namespaces/proxy-1448/pods/proxy-service-kdhrj-l2czr:1080/proxy/rewriteme">test<... (200; 23.787495ms)
Oct 28 18:16:06.409: INFO: (10) /api/v1/namespaces/proxy-1448/pods/http:proxy-service-kdhrj-l2czr:162/proxy/: bar (200; 24.244896ms)
Oct 28 18:16:06.409: INFO: (10) /api/v1/namespaces/proxy-1448/services/proxy-service-kdhrj:portname1/proxy/: foo (200; 23.891595ms)
Oct 28 18:16:06.409: INFO: (10) /api/v1/namespaces/proxy-1448/services/https:proxy-service-kdhrj:tlsportname1/proxy/: tls baz (200; 24.655399ms)
Oct 28 18:16:06.410: INFO: (10) /api/v1/namespaces/proxy-1448/services/https:proxy-service-kdhrj:tlsportname2/proxy/: tls qux (200; 25.297301ms)
Oct 28 18:16:06.411: INFO: (10) /api/v1/namespaces/proxy-1448/services/proxy-service-kdhrj:portname2/proxy/: bar (200; 26.279705ms)
Oct 28 18:16:06.411: INFO: (10) /api/v1/namespaces/proxy-1448/services/http:proxy-service-kdhrj:portname1/proxy/: foo (200; 26.602107ms)
Oct 28 18:16:06.421: INFO: (11) /api/v1/namespaces/proxy-1448/pods/https:proxy-service-kdhrj-l2czr:462/proxy/: tls qux (200; 9.525938ms)
Oct 28 18:16:06.426: INFO: (11) /api/v1/namespaces/proxy-1448/pods/http:proxy-service-kdhrj-l2czr:1080/proxy/: <a href="/api/v1/namespaces/proxy-1448/pods/http:proxy-service-kdhrj-l2czr:1080/proxy/rewriteme">... (200; 14.082756ms)
Oct 28 18:16:06.426: INFO: (11) /api/v1/namespaces/proxy-1448/services/proxy-service-kdhrj:portname2/proxy/: bar (200; 14.342257ms)
Oct 28 18:16:06.426: INFO: (11) /api/v1/namespaces/proxy-1448/services/https:proxy-service-kdhrj:tlsportname1/proxy/: tls baz (200; 14.911259ms)
Oct 28 18:16:06.426: INFO: (11) /api/v1/namespaces/proxy-1448/pods/proxy-service-kdhrj-l2czr/proxy/: <a href="/api/v1/namespaces/proxy-1448/pods/proxy-service-kdhrj-l2czr/proxy/rewriteme">test</a> (200; 15.15796ms)
Oct 28 18:16:06.427: INFO: (11) /api/v1/namespaces/proxy-1448/services/http:proxy-service-kdhrj:portname1/proxy/: foo (200; 15.562862ms)
Oct 28 18:16:06.427: INFO: (11) /api/v1/namespaces/proxy-1448/services/https:proxy-service-kdhrj:tlsportname2/proxy/: tls qux (200; 15.566362ms)
Oct 28 18:16:06.427: INFO: (11) /api/v1/namespaces/proxy-1448/services/proxy-service-kdhrj:portname1/proxy/: foo (200; 15.734962ms)
Oct 28 18:16:06.429: INFO: (11) /api/v1/namespaces/proxy-1448/pods/http:proxy-service-kdhrj-l2czr:162/proxy/: bar (200; 17.735571ms)
Oct 28 18:16:06.429: INFO: (11) /api/v1/namespaces/proxy-1448/pods/proxy-service-kdhrj-l2czr:1080/proxy/: <a href="/api/v1/namespaces/proxy-1448/pods/proxy-service-kdhrj-l2czr:1080/proxy/rewriteme">test<... (200; 17.44817ms)
Oct 28 18:16:06.430: INFO: (11) /api/v1/namespaces/proxy-1448/pods/https:proxy-service-kdhrj-l2czr:460/proxy/: tls baz (200; 18.202973ms)
Oct 28 18:16:06.430: INFO: (11) /api/v1/namespaces/proxy-1448/pods/proxy-service-kdhrj-l2czr:162/proxy/: bar (200; 18.582675ms)
Oct 28 18:16:06.430: INFO: (11) /api/v1/namespaces/proxy-1448/pods/proxy-service-kdhrj-l2czr:160/proxy/: foo (200; 18.677575ms)
Oct 28 18:16:06.430: INFO: (11) /api/v1/namespaces/proxy-1448/pods/https:proxy-service-kdhrj-l2czr:443/proxy/: <a href="/api/v1/namespaces/proxy-1448/pods/https:proxy-service-kdhrj-l2czr:443/proxy/tlsrewritem... (200; 18.775675ms)
Oct 28 18:16:06.430: INFO: (11) /api/v1/namespaces/proxy-1448/pods/http:proxy-service-kdhrj-l2czr:160/proxy/: foo (200; 18.846575ms)
Oct 28 18:16:06.431: INFO: (11) /api/v1/namespaces/proxy-1448/services/http:proxy-service-kdhrj:portname2/proxy/: bar (200; 19.538878ms)
Oct 28 18:16:06.439: INFO: (12) /api/v1/namespaces/proxy-1448/pods/http:proxy-service-kdhrj-l2czr:162/proxy/: bar (200; 7.765331ms)
Oct 28 18:16:06.439: INFO: (12) /api/v1/namespaces/proxy-1448/pods/https:proxy-service-kdhrj-l2czr:460/proxy/: tls baz (200; 7.897832ms)
Oct 28 18:16:06.446: INFO: (12) /api/v1/namespaces/proxy-1448/pods/http:proxy-service-kdhrj-l2czr:160/proxy/: foo (200; 15.335861ms)
Oct 28 18:16:06.447: INFO: (12) /api/v1/namespaces/proxy-1448/services/http:proxy-service-kdhrj:portname1/proxy/: foo (200; 15.665363ms)
Oct 28 18:16:06.447: INFO: (12) /api/v1/namespaces/proxy-1448/pods/proxy-service-kdhrj-l2czr:1080/proxy/: <a href="/api/v1/namespaces/proxy-1448/pods/proxy-service-kdhrj-l2czr:1080/proxy/rewriteme">test<... (200; 15.649263ms)
Oct 28 18:16:06.448: INFO: (12) /api/v1/namespaces/proxy-1448/pods/proxy-service-kdhrj-l2czr:162/proxy/: bar (200; 16.295365ms)
Oct 28 18:16:06.448: INFO: (12) /api/v1/namespaces/proxy-1448/pods/https:proxy-service-kdhrj-l2czr:462/proxy/: tls qux (200; 16.905268ms)
Oct 28 18:16:06.449: INFO: (12) /api/v1/namespaces/proxy-1448/pods/proxy-service-kdhrj-l2czr/proxy/: <a href="/api/v1/namespaces/proxy-1448/pods/proxy-service-kdhrj-l2czr/proxy/rewriteme">test</a> (200; 17.65667ms)
Oct 28 18:16:06.450: INFO: (12) /api/v1/namespaces/proxy-1448/pods/https:proxy-service-kdhrj-l2czr:443/proxy/: <a href="/api/v1/namespaces/proxy-1448/pods/https:proxy-service-kdhrj-l2czr:443/proxy/tlsrewritem... (200; 18.426574ms)
Oct 28 18:16:06.450: INFO: (12) /api/v1/namespaces/proxy-1448/services/proxy-service-kdhrj:portname1/proxy/: foo (200; 18.546774ms)
Oct 28 18:16:06.450: INFO: (12) /api/v1/namespaces/proxy-1448/services/https:proxy-service-kdhrj:tlsportname2/proxy/: tls qux (200; 18.847575ms)
Oct 28 18:16:06.451: INFO: (12) /api/v1/namespaces/proxy-1448/pods/proxy-service-kdhrj-l2czr:160/proxy/: foo (200; 19.513777ms)
Oct 28 18:16:06.451: INFO: (12) /api/v1/namespaces/proxy-1448/services/https:proxy-service-kdhrj:tlsportname1/proxy/: tls baz (200; 20.421281ms)
Oct 28 18:16:06.451: INFO: (12) /api/v1/namespaces/proxy-1448/services/http:proxy-service-kdhrj:portname2/proxy/: bar (200; 20.287581ms)
Oct 28 18:16:06.451: INFO: (12) /api/v1/namespaces/proxy-1448/services/proxy-service-kdhrj:portname2/proxy/: bar (200; 20.442782ms)
Oct 28 18:16:06.452: INFO: (12) /api/v1/namespaces/proxy-1448/pods/http:proxy-service-kdhrj-l2czr:1080/proxy/: <a href="/api/v1/namespaces/proxy-1448/pods/http:proxy-service-kdhrj-l2czr:1080/proxy/rewriteme">... (200; 20.374281ms)
Oct 28 18:16:06.463: INFO: (13) /api/v1/namespaces/proxy-1448/services/proxy-service-kdhrj:portname1/proxy/: foo (200; 11.648546ms)
Oct 28 18:16:06.466: INFO: (13) /api/v1/namespaces/proxy-1448/pods/proxy-service-kdhrj-l2czr:162/proxy/: bar (200; 13.687754ms)
Oct 28 18:16:06.466: INFO: (13) /api/v1/namespaces/proxy-1448/pods/https:proxy-service-kdhrj-l2czr:460/proxy/: tls baz (200; 13.927355ms)
Oct 28 18:16:06.466: INFO: (13) /api/v1/namespaces/proxy-1448/pods/proxy-service-kdhrj-l2czr:1080/proxy/: <a href="/api/v1/namespaces/proxy-1448/pods/proxy-service-kdhrj-l2czr:1080/proxy/rewriteme">test<... (200; 13.821555ms)
Oct 28 18:16:06.466: INFO: (13) /api/v1/namespaces/proxy-1448/pods/http:proxy-service-kdhrj-l2czr:1080/proxy/: <a href="/api/v1/namespaces/proxy-1448/pods/http:proxy-service-kdhrj-l2czr:1080/proxy/rewriteme">... (200; 13.755055ms)
Oct 28 18:16:06.466: INFO: (13) /api/v1/namespaces/proxy-1448/pods/http:proxy-service-kdhrj-l2czr:160/proxy/: foo (200; 13.862855ms)
Oct 28 18:16:06.466: INFO: (13) /api/v1/namespaces/proxy-1448/pods/https:proxy-service-kdhrj-l2czr:462/proxy/: tls qux (200; 13.859356ms)
Oct 28 18:16:06.466: INFO: (13) /api/v1/namespaces/proxy-1448/services/https:proxy-service-kdhrj:tlsportname2/proxy/: tls qux (200; 13.869355ms)
Oct 28 18:16:06.467: INFO: (13) /api/v1/namespaces/proxy-1448/services/https:proxy-service-kdhrj:tlsportname1/proxy/: tls baz (200; 14.827759ms)
Oct 28 18:16:06.467: INFO: (13) /api/v1/namespaces/proxy-1448/pods/proxy-service-kdhrj-l2czr:160/proxy/: foo (200; 14.93496ms)
Oct 28 18:16:06.467: INFO: (13) /api/v1/namespaces/proxy-1448/pods/proxy-service-kdhrj-l2czr/proxy/: <a href="/api/v1/namespaces/proxy-1448/pods/proxy-service-kdhrj-l2czr/proxy/rewriteme">test</a> (200; 15.02716ms)
Oct 28 18:16:06.467: INFO: (13) /api/v1/namespaces/proxy-1448/pods/http:proxy-service-kdhrj-l2czr:162/proxy/: bar (200; 14.892959ms)
Oct 28 18:16:06.467: INFO: (13) /api/v1/namespaces/proxy-1448/pods/https:proxy-service-kdhrj-l2czr:443/proxy/: <a href="/api/v1/namespaces/proxy-1448/pods/https:proxy-service-kdhrj-l2czr:443/proxy/tlsrewritem... (200; 14.965159ms)
Oct 28 18:16:06.468: INFO: (13) /api/v1/namespaces/proxy-1448/services/proxy-service-kdhrj:portname2/proxy/: bar (200; 15.782363ms)
Oct 28 18:16:06.468: INFO: (13) /api/v1/namespaces/proxy-1448/services/http:proxy-service-kdhrj:portname1/proxy/: foo (200; 16.005364ms)
Oct 28 18:16:06.468: INFO: (13) /api/v1/namespaces/proxy-1448/services/http:proxy-service-kdhrj:portname2/proxy/: bar (200; 16.207565ms)
Oct 28 18:16:06.477: INFO: (14) /api/v1/namespaces/proxy-1448/pods/http:proxy-service-kdhrj-l2czr:162/proxy/: bar (200; 8.326433ms)
Oct 28 18:16:06.478: INFO: (14) /api/v1/namespaces/proxy-1448/pods/proxy-service-kdhrj-l2czr:1080/proxy/: <a href="/api/v1/namespaces/proxy-1448/pods/proxy-service-kdhrj-l2czr:1080/proxy/rewriteme">test<... (200; 9.118736ms)
Oct 28 18:16:06.478: INFO: (14) /api/v1/namespaces/proxy-1448/pods/proxy-service-kdhrj-l2czr:162/proxy/: bar (200; 9.428338ms)
Oct 28 18:16:06.479: INFO: (14) /api/v1/namespaces/proxy-1448/pods/https:proxy-service-kdhrj-l2czr:462/proxy/: tls qux (200; 10.672143ms)
Oct 28 18:16:06.479: INFO: (14) /api/v1/namespaces/proxy-1448/pods/http:proxy-service-kdhrj-l2czr:160/proxy/: foo (200; 10.719143ms)
Oct 28 18:16:06.480: INFO: (14) /api/v1/namespaces/proxy-1448/pods/proxy-service-kdhrj-l2czr/proxy/: <a href="/api/v1/namespaces/proxy-1448/pods/proxy-service-kdhrj-l2czr/proxy/rewriteme">test</a> (200; 11.925448ms)
Oct 28 18:16:06.484: INFO: (14) /api/v1/namespaces/proxy-1448/services/http:proxy-service-kdhrj:portname1/proxy/: foo (200; 15.648062ms)
Oct 28 18:16:06.485: INFO: (14) /api/v1/namespaces/proxy-1448/pods/https:proxy-service-kdhrj-l2czr:460/proxy/: tls baz (200; 16.542466ms)
Oct 28 18:16:06.485: INFO: (14) /api/v1/namespaces/proxy-1448/pods/proxy-service-kdhrj-l2czr:160/proxy/: foo (200; 16.403066ms)
Oct 28 18:16:06.485: INFO: (14) /api/v1/namespaces/proxy-1448/services/https:proxy-service-kdhrj:tlsportname2/proxy/: tls qux (200; 16.502666ms)
Oct 28 18:16:06.487: INFO: (14) /api/v1/namespaces/proxy-1448/pods/https:proxy-service-kdhrj-l2czr:443/proxy/: <a href="/api/v1/namespaces/proxy-1448/pods/https:proxy-service-kdhrj-l2czr:443/proxy/tlsrewritem... (200; 18.571374ms)
Oct 28 18:16:06.487: INFO: (14) /api/v1/namespaces/proxy-1448/services/proxy-service-kdhrj:portname2/proxy/: bar (200; 18.713074ms)
Oct 28 18:16:06.488: INFO: (14) /api/v1/namespaces/proxy-1448/services/https:proxy-service-kdhrj:tlsportname1/proxy/: tls baz (200; 19.368877ms)
Oct 28 18:16:06.488: INFO: (14) /api/v1/namespaces/proxy-1448/pods/http:proxy-service-kdhrj-l2czr:1080/proxy/: <a href="/api/v1/namespaces/proxy-1448/pods/http:proxy-service-kdhrj-l2czr:1080/proxy/rewriteme">... (200; 19.106076ms)
Oct 28 18:16:06.488: INFO: (14) /api/v1/namespaces/proxy-1448/services/proxy-service-kdhrj:portname1/proxy/: foo (200; 19.432977ms)
Oct 28 18:16:06.488: INFO: (14) /api/v1/namespaces/proxy-1448/services/http:proxy-service-kdhrj:portname2/proxy/: bar (200; 19.633878ms)
Oct 28 18:16:06.501: INFO: (15) /api/v1/namespaces/proxy-1448/pods/proxy-service-kdhrj-l2czr:160/proxy/: foo (200; 12.764951ms)
Oct 28 18:16:06.501: INFO: (15) /api/v1/namespaces/proxy-1448/pods/https:proxy-service-kdhrj-l2czr:460/proxy/: tls baz (200; 13.115952ms)
Oct 28 18:16:06.502: INFO: (15) /api/v1/namespaces/proxy-1448/pods/https:proxy-service-kdhrj-l2czr:462/proxy/: tls qux (200; 13.775955ms)
Oct 28 18:16:06.502: INFO: (15) /api/v1/namespaces/proxy-1448/pods/https:proxy-service-kdhrj-l2czr:443/proxy/: <a href="/api/v1/namespaces/proxy-1448/pods/https:proxy-service-kdhrj-l2czr:443/proxy/tlsrewritem... (200; 13.806255ms)
Oct 28 18:16:06.502: INFO: (15) /api/v1/namespaces/proxy-1448/pods/proxy-service-kdhrj-l2czr:1080/proxy/: <a href="/api/v1/namespaces/proxy-1448/pods/proxy-service-kdhrj-l2czr:1080/proxy/rewriteme">test<... (200; 13.691355ms)
Oct 28 18:16:06.502: INFO: (15) /api/v1/namespaces/proxy-1448/pods/http:proxy-service-kdhrj-l2czr:1080/proxy/: <a href="/api/v1/namespaces/proxy-1448/pods/http:proxy-service-kdhrj-l2czr:1080/proxy/rewriteme">... (200; 14.390957ms)
Oct 28 18:16:06.504: INFO: (15) /api/v1/namespaces/proxy-1448/pods/http:proxy-service-kdhrj-l2czr:160/proxy/: foo (200; 15.594063ms)
Oct 28 18:16:06.504: INFO: (15) /api/v1/namespaces/proxy-1448/services/proxy-service-kdhrj:portname2/proxy/: bar (200; 16.125165ms)
Oct 28 18:16:06.505: INFO: (15) /api/v1/namespaces/proxy-1448/pods/proxy-service-kdhrj-l2czr/proxy/: <a href="/api/v1/namespaces/proxy-1448/pods/proxy-service-kdhrj-l2czr/proxy/rewriteme">test</a> (200; 17.059668ms)
Oct 28 18:16:06.505: INFO: (15) /api/v1/namespaces/proxy-1448/pods/http:proxy-service-kdhrj-l2czr:162/proxy/: bar (200; 17.160069ms)
Oct 28 18:16:06.506: INFO: (15) /api/v1/namespaces/proxy-1448/services/http:proxy-service-kdhrj:portname1/proxy/: foo (200; 17.50567ms)
Oct 28 18:16:06.506: INFO: (15) /api/v1/namespaces/proxy-1448/pods/proxy-service-kdhrj-l2czr:162/proxy/: bar (200; 18.169072ms)
Oct 28 18:16:06.507: INFO: (15) /api/v1/namespaces/proxy-1448/services/https:proxy-service-kdhrj:tlsportname2/proxy/: tls qux (200; 18.674274ms)
Oct 28 18:16:06.508: INFO: (15) /api/v1/namespaces/proxy-1448/services/http:proxy-service-kdhrj:portname2/proxy/: bar (200; 19.507978ms)
Oct 28 18:16:06.508: INFO: (15) /api/v1/namespaces/proxy-1448/services/https:proxy-service-kdhrj:tlsportname1/proxy/: tls baz (200; 19.863779ms)
Oct 28 18:16:06.508: INFO: (15) /api/v1/namespaces/proxy-1448/services/proxy-service-kdhrj:portname1/proxy/: foo (200; 20.00878ms)
Oct 28 18:16:06.521: INFO: (16) /api/v1/namespaces/proxy-1448/pods/http:proxy-service-kdhrj-l2czr:162/proxy/: bar (200; 12.946552ms)
Oct 28 18:16:06.522: INFO: (16) /api/v1/namespaces/proxy-1448/pods/proxy-service-kdhrj-l2czr/proxy/: <a href="/api/v1/namespaces/proxy-1448/pods/proxy-service-kdhrj-l2czr/proxy/rewriteme">test</a> (200; 13.980356ms)
Oct 28 18:16:06.522: INFO: (16) /api/v1/namespaces/proxy-1448/pods/proxy-service-kdhrj-l2czr:1080/proxy/: <a href="/api/v1/namespaces/proxy-1448/pods/proxy-service-kdhrj-l2czr:1080/proxy/rewriteme">test<... (200; 14.158657ms)
Oct 28 18:16:06.523: INFO: (16) /api/v1/namespaces/proxy-1448/services/https:proxy-service-kdhrj:tlsportname1/proxy/: tls baz (200; 14.656958ms)
Oct 28 18:16:06.523: INFO: (16) /api/v1/namespaces/proxy-1448/pods/https:proxy-service-kdhrj-l2czr:460/proxy/: tls baz (200; 14.428258ms)
Oct 28 18:16:06.523: INFO: (16) /api/v1/namespaces/proxy-1448/pods/http:proxy-service-kdhrj-l2czr:1080/proxy/: <a href="/api/v1/namespaces/proxy-1448/pods/http:proxy-service-kdhrj-l2czr:1080/proxy/rewriteme">... (200; 15.25416ms)
Oct 28 18:16:06.525: INFO: (16) /api/v1/namespaces/proxy-1448/pods/https:proxy-service-kdhrj-l2czr:443/proxy/: <a href="/api/v1/namespaces/proxy-1448/pods/https:proxy-service-kdhrj-l2czr:443/proxy/tlsrewritem... (200; 16.291365ms)
Oct 28 18:16:06.525: INFO: (16) /api/v1/namespaces/proxy-1448/pods/proxy-service-kdhrj-l2czr:162/proxy/: bar (200; 16.337465ms)
Oct 28 18:16:06.525: INFO: (16) /api/v1/namespaces/proxy-1448/pods/http:proxy-service-kdhrj-l2czr:160/proxy/: foo (200; 16.521066ms)
Oct 28 18:16:06.525: INFO: (16) /api/v1/namespaces/proxy-1448/services/http:proxy-service-kdhrj:portname2/proxy/: bar (200; 16.484465ms)
Oct 28 18:16:06.525: INFO: (16) /api/v1/namespaces/proxy-1448/services/https:proxy-service-kdhrj:tlsportname2/proxy/: tls qux (200; 16.937167ms)
Oct 28 18:16:06.525: INFO: (16) /api/v1/namespaces/proxy-1448/pods/proxy-service-kdhrj-l2czr:160/proxy/: foo (200; 17.40837ms)
Oct 28 18:16:06.525: INFO: (16) /api/v1/namespaces/proxy-1448/pods/https:proxy-service-kdhrj-l2czr:462/proxy/: tls qux (200; 17.103569ms)
Oct 28 18:16:06.526: INFO: (16) /api/v1/namespaces/proxy-1448/services/proxy-service-kdhrj:portname2/proxy/: bar (200; 17.690171ms)
Oct 28 18:16:06.527: INFO: (16) /api/v1/namespaces/proxy-1448/services/proxy-service-kdhrj:portname1/proxy/: foo (200; 18.397773ms)
Oct 28 18:16:06.527: INFO: (16) /api/v1/namespaces/proxy-1448/services/http:proxy-service-kdhrj:portname1/proxy/: foo (200; 18.486174ms)
Oct 28 18:16:06.538: INFO: (17) /api/v1/namespaces/proxy-1448/pods/https:proxy-service-kdhrj-l2czr:443/proxy/: <a href="/api/v1/namespaces/proxy-1448/pods/https:proxy-service-kdhrj-l2czr:443/proxy/tlsrewritem... (200; 11.308945ms)
Oct 28 18:16:06.539: INFO: (17) /api/v1/namespaces/proxy-1448/pods/https:proxy-service-kdhrj-l2czr:460/proxy/: tls baz (200; 12.42465ms)
Oct 28 18:16:06.539: INFO: (17) /api/v1/namespaces/proxy-1448/pods/proxy-service-kdhrj-l2czr:162/proxy/: bar (200; 12.298449ms)
Oct 28 18:16:06.539: INFO: (17) /api/v1/namespaces/proxy-1448/pods/https:proxy-service-kdhrj-l2czr:462/proxy/: tls qux (200; 12.46935ms)
Oct 28 18:16:06.542: INFO: (17) /api/v1/namespaces/proxy-1448/services/https:proxy-service-kdhrj:tlsportname2/proxy/: tls qux (200; 14.884359ms)
Oct 28 18:16:06.542: INFO: (17) /api/v1/namespaces/proxy-1448/services/proxy-service-kdhrj:portname1/proxy/: foo (200; 15.18296ms)
Oct 28 18:16:06.543: INFO: (17) /api/v1/namespaces/proxy-1448/pods/http:proxy-service-kdhrj-l2czr:160/proxy/: foo (200; 15.478862ms)
Oct 28 18:16:06.543: INFO: (17) /api/v1/namespaces/proxy-1448/pods/proxy-service-kdhrj-l2czr:1080/proxy/: <a href="/api/v1/namespaces/proxy-1448/pods/proxy-service-kdhrj-l2czr:1080/proxy/rewriteme">test<... (200; 16.307465ms)
Oct 28 18:16:06.543: INFO: (17) /api/v1/namespaces/proxy-1448/services/http:proxy-service-kdhrj:portname2/proxy/: bar (200; 16.445565ms)
Oct 28 18:16:06.544: INFO: (17) /api/v1/namespaces/proxy-1448/pods/http:proxy-service-kdhrj-l2czr:162/proxy/: bar (200; 17.143568ms)
Oct 28 18:16:06.544: INFO: (17) /api/v1/namespaces/proxy-1448/services/https:proxy-service-kdhrj:tlsportname1/proxy/: tls baz (200; 17.181768ms)
Oct 28 18:16:06.544: INFO: (17) /api/v1/namespaces/proxy-1448/pods/proxy-service-kdhrj-l2czr/proxy/: <a href="/api/v1/namespaces/proxy-1448/pods/proxy-service-kdhrj-l2czr/proxy/rewriteme">test</a> (200; 17.186068ms)
Oct 28 18:16:06.545: INFO: (17) /api/v1/namespaces/proxy-1448/pods/http:proxy-service-kdhrj-l2czr:1080/proxy/: <a href="/api/v1/namespaces/proxy-1448/pods/http:proxy-service-kdhrj-l2czr:1080/proxy/rewriteme">... (200; 17.43747ms)
Oct 28 18:16:06.545: INFO: (17) /api/v1/namespaces/proxy-1448/pods/proxy-service-kdhrj-l2czr:160/proxy/: foo (200; 17.860772ms)
Oct 28 18:16:06.547: INFO: (17) /api/v1/namespaces/proxy-1448/services/proxy-service-kdhrj:portname2/proxy/: bar (200; 19.850379ms)
Oct 28 18:16:06.547: INFO: (17) /api/v1/namespaces/proxy-1448/services/http:proxy-service-kdhrj:portname1/proxy/: foo (200; 19.982879ms)
Oct 28 18:16:06.559: INFO: (18) /api/v1/namespaces/proxy-1448/pods/proxy-service-kdhrj-l2czr:1080/proxy/: <a href="/api/v1/namespaces/proxy-1448/pods/proxy-service-kdhrj-l2czr:1080/proxy/rewriteme">test<... (200; 12.179349ms)
Oct 28 18:16:06.560: INFO: (18) /api/v1/namespaces/proxy-1448/pods/http:proxy-service-kdhrj-l2czr:162/proxy/: bar (200; 12.710151ms)
Oct 28 18:16:06.561: INFO: (18) /api/v1/namespaces/proxy-1448/pods/https:proxy-service-kdhrj-l2czr:462/proxy/: tls qux (200; 14.017356ms)
Oct 28 18:16:06.562: INFO: (18) /api/v1/namespaces/proxy-1448/pods/proxy-service-kdhrj-l2czr/proxy/: <a href="/api/v1/namespaces/proxy-1448/pods/proxy-service-kdhrj-l2czr/proxy/rewriteme">test</a> (200; 14.641158ms)
Oct 28 18:16:06.562: INFO: (18) /api/v1/namespaces/proxy-1448/pods/http:proxy-service-kdhrj-l2czr:1080/proxy/: <a href="/api/v1/namespaces/proxy-1448/pods/http:proxy-service-kdhrj-l2czr:1080/proxy/rewriteme">... (200; 14.811859ms)
Oct 28 18:16:06.563: INFO: (18) /api/v1/namespaces/proxy-1448/services/http:proxy-service-kdhrj:portname1/proxy/: foo (200; 15.287361ms)
Oct 28 18:16:06.563: INFO: (18) /api/v1/namespaces/proxy-1448/services/https:proxy-service-kdhrj:tlsportname2/proxy/: tls qux (200; 16.001664ms)
Oct 28 18:16:06.564: INFO: (18) /api/v1/namespaces/proxy-1448/pods/https:proxy-service-kdhrj-l2czr:460/proxy/: tls baz (200; 16.532366ms)
Oct 28 18:16:06.564: INFO: (18) /api/v1/namespaces/proxy-1448/services/proxy-service-kdhrj:portname2/proxy/: bar (200; 16.950967ms)
Oct 28 18:16:06.564: INFO: (18) /api/v1/namespaces/proxy-1448/pods/proxy-service-kdhrj-l2czr:162/proxy/: bar (200; 16.735367ms)
Oct 28 18:16:06.564: INFO: (18) /api/v1/namespaces/proxy-1448/pods/proxy-service-kdhrj-l2czr:160/proxy/: foo (200; 16.895067ms)
Oct 28 18:16:06.564: INFO: (18) /api/v1/namespaces/proxy-1448/pods/https:proxy-service-kdhrj-l2czr:443/proxy/: <a href="/api/v1/namespaces/proxy-1448/pods/https:proxy-service-kdhrj-l2czr:443/proxy/tlsrewritem... (200; 17.023468ms)
Oct 28 18:16:06.566: INFO: (18) /api/v1/namespaces/proxy-1448/services/http:proxy-service-kdhrj:portname2/proxy/: bar (200; 18.511174ms)
Oct 28 18:16:06.566: INFO: (18) /api/v1/namespaces/proxy-1448/services/proxy-service-kdhrj:portname1/proxy/: foo (200; 18.396173ms)
Oct 28 18:16:06.566: INFO: (18) /api/v1/namespaces/proxy-1448/services/https:proxy-service-kdhrj:tlsportname1/proxy/: tls baz (200; 18.711674ms)
Oct 28 18:16:06.566: INFO: (18) /api/v1/namespaces/proxy-1448/pods/http:proxy-service-kdhrj-l2czr:160/proxy/: foo (200; 19.248377ms)
Oct 28 18:16:06.576: INFO: (19) /api/v1/namespaces/proxy-1448/pods/proxy-service-kdhrj-l2czr:160/proxy/: foo (200; 9.155336ms)
Oct 28 18:16:06.576: INFO: (19) /api/v1/namespaces/proxy-1448/pods/proxy-service-kdhrj-l2czr:1080/proxy/: <a href="/api/v1/namespaces/proxy-1448/pods/proxy-service-kdhrj-l2czr:1080/proxy/rewriteme">test<... (200; 9.787339ms)
Oct 28 18:16:06.579: INFO: (19) /api/v1/namespaces/proxy-1448/pods/https:proxy-service-kdhrj-l2czr:462/proxy/: tls qux (200; 12.011748ms)
Oct 28 18:16:06.579: INFO: (19) /api/v1/namespaces/proxy-1448/pods/proxy-service-kdhrj-l2czr:162/proxy/: bar (200; 12.38455ms)
Oct 28 18:16:06.580: INFO: (19) /api/v1/namespaces/proxy-1448/pods/http:proxy-service-kdhrj-l2czr:162/proxy/: bar (200; 12.866352ms)
Oct 28 18:16:06.580: INFO: (19) /api/v1/namespaces/proxy-1448/pods/proxy-service-kdhrj-l2czr/proxy/: <a href="/api/v1/namespaces/proxy-1448/pods/proxy-service-kdhrj-l2czr/proxy/rewriteme">test</a> (200; 13.368454ms)
Oct 28 18:16:06.580: INFO: (19) /api/v1/namespaces/proxy-1448/pods/https:proxy-service-kdhrj-l2czr:460/proxy/: tls baz (200; 13.075452ms)
Oct 28 18:16:06.581: INFO: (19) /api/v1/namespaces/proxy-1448/pods/http:proxy-service-kdhrj-l2czr:1080/proxy/: <a href="/api/v1/namespaces/proxy-1448/pods/http:proxy-service-kdhrj-l2czr:1080/proxy/rewriteme">... (200; 14.377958ms)
Oct 28 18:16:06.581: INFO: (19) /api/v1/namespaces/proxy-1448/pods/http:proxy-service-kdhrj-l2czr:160/proxy/: foo (200; 14.038556ms)
Oct 28 18:16:06.581: INFO: (19) /api/v1/namespaces/proxy-1448/pods/https:proxy-service-kdhrj-l2czr:443/proxy/: <a href="/api/v1/namespaces/proxy-1448/pods/https:proxy-service-kdhrj-l2czr:443/proxy/tlsrewritem... (200; 14.132556ms)
Oct 28 18:16:06.584: INFO: (19) /api/v1/namespaces/proxy-1448/services/http:proxy-service-kdhrj:portname2/proxy/: bar (200; 17.872571ms)
Oct 28 18:16:06.584: INFO: (19) /api/v1/namespaces/proxy-1448/services/https:proxy-service-kdhrj:tlsportname1/proxy/: tls baz (200; 17.735771ms)
Oct 28 18:16:06.584: INFO: (19) /api/v1/namespaces/proxy-1448/services/proxy-service-kdhrj:portname2/proxy/: bar (200; 17.56717ms)
Oct 28 18:16:06.584: INFO: (19) /api/v1/namespaces/proxy-1448/services/proxy-service-kdhrj:portname1/proxy/: foo (200; 17.634871ms)
Oct 28 18:16:06.585: INFO: (19) /api/v1/namespaces/proxy-1448/services/http:proxy-service-kdhrj:portname1/proxy/: foo (200; 18.139672ms)
Oct 28 18:16:06.585: INFO: (19) /api/v1/namespaces/proxy-1448/services/https:proxy-service-kdhrj:tlsportname2/proxy/: tls qux (200; 17.997972ms)
STEP: deleting ReplicationController proxy-service-kdhrj in namespace proxy-1448, will wait for the garbage collector to delete the pods
Oct 28 18:16:06.645: INFO: Deleting ReplicationController proxy-service-kdhrj took: 6.744327ms
Oct 28 18:16:06.745: INFO: Terminating ReplicationController proxy-service-kdhrj pods took: 100.2241ms
[AfterEach] version v1
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 18:16:10.746: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-1448" for this suite.
Oct 28 18:16:16.767: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 18:16:16.931: INFO: namespace proxy-1448 deletion completed in 6.178235026s

• [SLOW TEST:21.992 seconds]
[sig-network] Proxy
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:58
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 18:16:16.931: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-5084
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:273
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the initial replication controller
Oct 28 18:16:17.095: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-124947935 create -f - --namespace=kubectl-5084'
Oct 28 18:16:17.717: INFO: stderr: ""
Oct 28 18:16:17.717: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Oct 28 18:16:17.717: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-124947935 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-5084'
Oct 28 18:16:17.820: INFO: stderr: ""
Oct 28 18:16:17.820: INFO: stdout: "update-demo-nautilus-cr77f update-demo-nautilus-rqxwm "
Oct 28 18:16:17.820: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-124947935 get pods update-demo-nautilus-cr77f -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-5084'
Oct 28 18:16:17.888: INFO: stderr: ""
Oct 28 18:16:17.888: INFO: stdout: ""
Oct 28 18:16:17.888: INFO: update-demo-nautilus-cr77f is created but not running
Oct 28 18:16:22.888: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-124947935 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-5084'
Oct 28 18:16:22.972: INFO: stderr: ""
Oct 28 18:16:22.972: INFO: stdout: "update-demo-nautilus-cr77f update-demo-nautilus-rqxwm "
Oct 28 18:16:22.972: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-124947935 get pods update-demo-nautilus-cr77f -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-5084'
Oct 28 18:16:23.045: INFO: stderr: ""
Oct 28 18:16:23.045: INFO: stdout: "true"
Oct 28 18:16:23.045: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-124947935 get pods update-demo-nautilus-cr77f -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-5084'
Oct 28 18:16:23.116: INFO: stderr: ""
Oct 28 18:16:23.116: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Oct 28 18:16:23.116: INFO: validating pod update-demo-nautilus-cr77f
Oct 28 18:16:23.125: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct 28 18:16:23.125: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct 28 18:16:23.125: INFO: update-demo-nautilus-cr77f is verified up and running
Oct 28 18:16:23.125: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-124947935 get pods update-demo-nautilus-rqxwm -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-5084'
Oct 28 18:16:23.200: INFO: stderr: ""
Oct 28 18:16:23.200: INFO: stdout: "true"
Oct 28 18:16:23.200: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-124947935 get pods update-demo-nautilus-rqxwm -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-5084'
Oct 28 18:16:23.271: INFO: stderr: ""
Oct 28 18:16:23.271: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Oct 28 18:16:23.271: INFO: validating pod update-demo-nautilus-rqxwm
Oct 28 18:16:23.281: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct 28 18:16:23.282: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct 28 18:16:23.282: INFO: update-demo-nautilus-rqxwm is verified up and running
STEP: rolling-update to new replication controller
Oct 28 18:16:23.284: INFO: scanned /root for discovery docs: <nil>
Oct 28 18:16:23.284: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-124947935 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=kubectl-5084'
Oct 28 18:16:52.159: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Oct 28 18:16:52.159: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Oct 28 18:16:52.159: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-124947935 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-5084'
Oct 28 18:16:52.246: INFO: stderr: ""
Oct 28 18:16:52.246: INFO: stdout: "update-demo-kitten-4bmx6 update-demo-kitten-llrh6 "
Oct 28 18:16:52.246: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-124947935 get pods update-demo-kitten-4bmx6 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-5084'
Oct 28 18:16:52.312: INFO: stderr: ""
Oct 28 18:16:52.312: INFO: stdout: "true"
Oct 28 18:16:52.312: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-124947935 get pods update-demo-kitten-4bmx6 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-5084'
Oct 28 18:16:52.383: INFO: stderr: ""
Oct 28 18:16:52.383: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Oct 28 18:16:52.383: INFO: validating pod update-demo-kitten-4bmx6
Oct 28 18:16:52.392: INFO: got data: {
  "image": "kitten.jpg"
}

Oct 28 18:16:52.392: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Oct 28 18:16:52.392: INFO: update-demo-kitten-4bmx6 is verified up and running
Oct 28 18:16:52.392: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-124947935 get pods update-demo-kitten-llrh6 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-5084'
Oct 28 18:16:52.459: INFO: stderr: ""
Oct 28 18:16:52.460: INFO: stdout: "true"
Oct 28 18:16:52.460: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-124947935 get pods update-demo-kitten-llrh6 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-5084'
Oct 28 18:16:52.534: INFO: stderr: ""
Oct 28 18:16:52.534: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Oct 28 18:16:52.534: INFO: validating pod update-demo-kitten-llrh6
Oct 28 18:16:52.542: INFO: got data: {
  "image": "kitten.jpg"
}

Oct 28 18:16:52.542: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Oct 28 18:16:52.542: INFO: update-demo-kitten-llrh6 is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 18:16:52.542: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5084" for this suite.
Oct 28 18:17:14.566: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 18:17:14.753: INFO: namespace kubectl-5084 deletion completed in 22.205176206s

• [SLOW TEST:57.822 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 18:17:14.754: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-9110
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Oct 28 18:17:14.915: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c2458224-fea0-4ec9-bd6c-a89de994000d" in namespace "downward-api-9110" to be "success or failure"
Oct 28 18:17:14.920: INFO: Pod "downwardapi-volume-c2458224-fea0-4ec9-bd6c-a89de994000d": Phase="Pending", Reason="", readiness=false. Elapsed: 5.288421ms
Oct 28 18:17:16.925: INFO: Pod "downwardapi-volume-c2458224-fea0-4ec9-bd6c-a89de994000d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010356969s
Oct 28 18:17:18.931: INFO: Pod "downwardapi-volume-c2458224-fea0-4ec9-bd6c-a89de994000d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.015612615s
Oct 28 18:17:20.935: INFO: Pod "downwardapi-volume-c2458224-fea0-4ec9-bd6c-a89de994000d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.020349359s
STEP: Saw pod success
Oct 28 18:17:20.935: INFO: Pod "downwardapi-volume-c2458224-fea0-4ec9-bd6c-a89de994000d" satisfied condition "success or failure"
Oct 28 18:17:20.939: INFO: Trying to get logs from node kh4ga-worker-000000 pod downwardapi-volume-c2458224-fea0-4ec9-bd6c-a89de994000d container client-container: <nil>
STEP: delete the pod
Oct 28 18:17:20.967: INFO: Waiting for pod downwardapi-volume-c2458224-fea0-4ec9-bd6c-a89de994000d to disappear
Oct 28 18:17:20.971: INFO: Pod downwardapi-volume-c2458224-fea0-4ec9-bd6c-a89de994000d no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 18:17:20.971: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9110" for this suite.
Oct 28 18:17:27.000: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 18:17:27.154: INFO: namespace downward-api-9110 deletion completed in 6.176844165s

• [SLOW TEST:12.400 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 18:17:27.154: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6388
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating the pod
Oct 28 18:17:33.877: INFO: Successfully updated pod "labelsupdatee9bf3e89-b005-4895-afe8-2e255d4844c7"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 18:17:35.897: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6388" for this suite.
Oct 28 18:17:57.918: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 18:17:58.085: INFO: namespace projected-6388 deletion completed in 22.180654289s

• [SLOW TEST:30.930 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 18:17:58.085: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-5500
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test override all
Oct 28 18:17:58.243: INFO: Waiting up to 5m0s for pod "client-containers-aac09fe4-32a3-4788-95d0-b228123dc392" in namespace "containers-5500" to be "success or failure"
Oct 28 18:17:58.252: INFO: Pod "client-containers-aac09fe4-32a3-4788-95d0-b228123dc392": Phase="Pending", Reason="", readiness=false. Elapsed: 8.915535ms
Oct 28 18:18:00.257: INFO: Pod "client-containers-aac09fe4-32a3-4788-95d0-b228123dc392": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013599453s
Oct 28 18:18:02.261: INFO: Pod "client-containers-aac09fe4-32a3-4788-95d0-b228123dc392": Phase="Pending", Reason="", readiness=false. Elapsed: 4.017851767s
Oct 28 18:18:04.267: INFO: Pod "client-containers-aac09fe4-32a3-4788-95d0-b228123dc392": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.023753787s
STEP: Saw pod success
Oct 28 18:18:04.267: INFO: Pod "client-containers-aac09fe4-32a3-4788-95d0-b228123dc392" satisfied condition "success or failure"
Oct 28 18:18:04.272: INFO: Trying to get logs from node kh4ga-worker-000000 pod client-containers-aac09fe4-32a3-4788-95d0-b228123dc392 container test-container: <nil>
STEP: delete the pod
Oct 28 18:18:04.299: INFO: Waiting for pod client-containers-aac09fe4-32a3-4788-95d0-b228123dc392 to disappear
Oct 28 18:18:04.303: INFO: Pod client-containers-aac09fe4-32a3-4788-95d0-b228123dc392 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 18:18:04.303: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-5500" for this suite.
Oct 28 18:18:10.323: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 18:18:10.478: INFO: namespace containers-5500 deletion completed in 6.169417851s

• [SLOW TEST:12.394 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 18:18:10.479: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-149
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Oct 28 18:18:10.648: INFO: Waiting up to 5m0s for pod "downward-api-69d0a756-2818-4de5-ac9d-42a9c86a90cd" in namespace "downward-api-149" to be "success or failure"
Oct 28 18:18:10.652: INFO: Pod "downward-api-69d0a756-2818-4de5-ac9d-42a9c86a90cd": Phase="Pending", Reason="", readiness=false. Elapsed: 4.406318ms
Oct 28 18:18:12.657: INFO: Pod "downward-api-69d0a756-2818-4de5-ac9d-42a9c86a90cd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008966127s
Oct 28 18:18:14.661: INFO: Pod "downward-api-69d0a756-2818-4de5-ac9d-42a9c86a90cd": Phase="Pending", Reason="", readiness=false. Elapsed: 4.013766036s
Oct 28 18:18:16.666: INFO: Pod "downward-api-69d0a756-2818-4de5-ac9d-42a9c86a90cd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.018515344s
STEP: Saw pod success
Oct 28 18:18:16.666: INFO: Pod "downward-api-69d0a756-2818-4de5-ac9d-42a9c86a90cd" satisfied condition "success or failure"
Oct 28 18:18:16.670: INFO: Trying to get logs from node kh4ga-worker-000003 pod downward-api-69d0a756-2818-4de5-ac9d-42a9c86a90cd container dapi-container: <nil>
STEP: delete the pod
Oct 28 18:18:16.695: INFO: Waiting for pod downward-api-69d0a756-2818-4de5-ac9d-42a9c86a90cd to disappear
Oct 28 18:18:16.710: INFO: Pod downward-api-69d0a756-2818-4de5-ac9d-42a9c86a90cd no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 18:18:16.710: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-149" for this suite.
Oct 28 18:18:22.734: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 18:18:22.891: INFO: namespace downward-api-149 deletion completed in 6.17508415s

• [SLOW TEST:12.413 seconds]
[sig-node] Downward API
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 18:18:22.891: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename prestop
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in prestop-221
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pre_stop.go:167
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating server pod server in namespace prestop-221
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace prestop-221
STEP: Deleting pre-stop pod
Oct 28 18:18:44.123: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 18:18:44.145: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "prestop-221" for this suite.
Oct 28 18:19:22.179: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 18:19:22.352: INFO: namespace prestop-221 deletion completed in 38.19514554s

• [SLOW TEST:59.461 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 28 18:19:22.352: INFO: >>> kubeConfig: /tmp/kubeconfig-124947935
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replicaset-1679
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Oct 28 18:19:22.560: INFO: Creating ReplicaSet my-hostname-basic-8162f262-8d49-4a86-95fb-6f5525c2288f
Oct 28 18:19:22.581: INFO: Pod name my-hostname-basic-8162f262-8d49-4a86-95fb-6f5525c2288f: Found 0 pods out of 1
Oct 28 18:19:27.586: INFO: Pod name my-hostname-basic-8162f262-8d49-4a86-95fb-6f5525c2288f: Found 1 pods out of 1
Oct 28 18:19:27.586: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-8162f262-8d49-4a86-95fb-6f5525c2288f" is running
Oct 28 18:19:27.590: INFO: Pod "my-hostname-basic-8162f262-8d49-4a86-95fb-6f5525c2288f-fj8g4" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-10-28 18:19:22 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-10-28 18:19:27 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-10-28 18:19:27 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-10-28 18:19:22 +0000 UTC Reason: Message:}])
Oct 28 18:19:27.590: INFO: Trying to dial the pod
Oct 28 18:19:32.609: INFO: Controller my-hostname-basic-8162f262-8d49-4a86-95fb-6f5525c2288f: Got expected result from replica 1 [my-hostname-basic-8162f262-8d49-4a86-95fb-6f5525c2288f-fj8g4]: "my-hostname-basic-8162f262-8d49-4a86-95fb-6f5525c2288f-fj8g4", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 28 18:19:32.609: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-1679" for this suite.
Oct 28 18:19:38.632: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 28 18:19:38.814: INFO: namespace replicaset-1679 deletion completed in 6.199259315s

• [SLOW TEST:16.462 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSOct 28 18:19:38.815: INFO: Running AfterSuite actions on all nodes
Oct 28 18:19:38.815: INFO: Running AfterSuite actions on node 1
Oct 28 18:19:38.815: INFO: Skipping dumping logs from cluster

Ran 215 of 4413 Specs in 6435.548 seconds
SUCCESS! -- 215 Passed | 0 Failed | 0 Pending | 4198 Skipped
PASS

Ginkgo ran 1 suite in 1h47m16.845261067s
Test Suite Passed
