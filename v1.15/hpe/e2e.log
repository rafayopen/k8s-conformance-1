I1021 23:53:54.234146      18 test_context.go:406] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-172996996
I1021 23:53:54.234373      18 e2e.go:241] Starting e2e run "f78efc7c-21e8-43ed-bdf6-34bfcaef6b7b" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1571702032 - Will randomize all specs
Will run 215 of 4413 specs

Oct 21 23:53:54.629: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
Oct 21 23:53:54.637: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Oct 21 23:53:54.665: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Oct 21 23:53:54.718: INFO: 17 / 17 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Oct 21 23:53:54.718: INFO: expected 5 pod replicas in namespace 'kube-system', 5 are Running and Ready.
Oct 21 23:53:54.718: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Oct 21 23:53:54.734: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'canal' (0 seconds elapsed)
Oct 21 23:53:54.734: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'kube-proxy' (0 seconds elapsed)
Oct 21 23:53:54.734: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'kubedirector-fsmount' (0 seconds elapsed)
Oct 21 23:53:54.734: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'nvidia-device-plugin-daemonset' (0 seconds elapsed)
Oct 21 23:53:54.734: INFO: e2e test version: v1.15.3
Oct 21 23:53:54.736: INFO: kube-apiserver version: v1.15.3
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 23:53:54.736: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename subpath
Oct 21 23:53:54.792: INFO: No PodSecurityPolicies found; assuming PodSecurityPolicy is disabled.
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-projected-5gmb
STEP: Creating a pod to test atomic-volume-subpath
Oct 21 23:53:54.816: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-5gmb" in namespace "subpath-4207" to be "success or failure"
Oct 21 23:53:54.830: INFO: Pod "pod-subpath-test-projected-5gmb": Phase="Pending", Reason="", readiness=false. Elapsed: 14.874924ms
Oct 21 23:53:56.837: INFO: Pod "pod-subpath-test-projected-5gmb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021305091s
Oct 21 23:53:58.844: INFO: Pod "pod-subpath-test-projected-5gmb": Phase="Running", Reason="", readiness=true. Elapsed: 4.028050107s
Oct 21 23:54:00.851: INFO: Pod "pod-subpath-test-projected-5gmb": Phase="Running", Reason="", readiness=true. Elapsed: 6.035078462s
Oct 21 23:54:02.856: INFO: Pod "pod-subpath-test-projected-5gmb": Phase="Running", Reason="", readiness=true. Elapsed: 8.040492336s
Oct 21 23:54:04.862: INFO: Pod "pod-subpath-test-projected-5gmb": Phase="Running", Reason="", readiness=true. Elapsed: 10.0467728s
Oct 21 23:54:06.868: INFO: Pod "pod-subpath-test-projected-5gmb": Phase="Running", Reason="", readiness=true. Elapsed: 12.052197287s
Oct 21 23:54:08.873: INFO: Pod "pod-subpath-test-projected-5gmb": Phase="Running", Reason="", readiness=true. Elapsed: 14.057357692s
Oct 21 23:54:10.879: INFO: Pod "pod-subpath-test-projected-5gmb": Phase="Running", Reason="", readiness=true. Elapsed: 16.063302725s
Oct 21 23:54:12.884: INFO: Pod "pod-subpath-test-projected-5gmb": Phase="Running", Reason="", readiness=true. Elapsed: 18.068502746s
Oct 21 23:54:14.890: INFO: Pod "pod-subpath-test-projected-5gmb": Phase="Running", Reason="", readiness=true. Elapsed: 20.074222766s
Oct 21 23:54:16.895: INFO: Pod "pod-subpath-test-projected-5gmb": Phase="Running", Reason="", readiness=true. Elapsed: 22.079812478s
Oct 21 23:54:18.900: INFO: Pod "pod-subpath-test-projected-5gmb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.084802449s
STEP: Saw pod success
Oct 21 23:54:18.900: INFO: Pod "pod-subpath-test-projected-5gmb" satisfied condition "success or failure"
Oct 21 23:54:18.906: INFO: Trying to get logs from node mip-bd-vm41.mip.storage.hpecorp.net pod pod-subpath-test-projected-5gmb container test-container-subpath-projected-5gmb: <nil>
STEP: delete the pod
Oct 21 23:54:18.941: INFO: Waiting for pod pod-subpath-test-projected-5gmb to disappear
Oct 21 23:54:18.946: INFO: Pod pod-subpath-test-projected-5gmb no longer exists
STEP: Deleting pod pod-subpath-test-projected-5gmb
Oct 21 23:54:18.946: INFO: Deleting pod "pod-subpath-test-projected-5gmb" in namespace "subpath-4207"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 23:54:18.949: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-4207" for this suite.
Oct 21 23:54:24.973: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 23:54:25.136: INFO: namespace subpath-4207 deletion completed in 6.182562881s

• [SLOW TEST:30.399 seconds]
[sig-storage] Subpath
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with projected pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 23:54:25.136: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-19327c97-4230-4869-8c3f-025c163defe0
STEP: Creating a pod to test consume secrets
Oct 21 23:54:25.201: INFO: Waiting up to 5m0s for pod "pod-secrets-b3b3eb04-a115-4a50-ae31-da07db20cdf7" in namespace "secrets-134" to be "success or failure"
Oct 21 23:54:25.205: INFO: Pod "pod-secrets-b3b3eb04-a115-4a50-ae31-da07db20cdf7": Phase="Pending", Reason="", readiness=false. Elapsed: 4.183498ms
Oct 21 23:54:27.210: INFO: Pod "pod-secrets-b3b3eb04-a115-4a50-ae31-da07db20cdf7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009172644s
Oct 21 23:54:29.215: INFO: Pod "pod-secrets-b3b3eb04-a115-4a50-ae31-da07db20cdf7": Phase="Pending", Reason="", readiness=false. Elapsed: 4.014233066s
Oct 21 23:54:31.221: INFO: Pod "pod-secrets-b3b3eb04-a115-4a50-ae31-da07db20cdf7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.019854779s
STEP: Saw pod success
Oct 21 23:54:31.221: INFO: Pod "pod-secrets-b3b3eb04-a115-4a50-ae31-da07db20cdf7" satisfied condition "success or failure"
Oct 21 23:54:31.225: INFO: Trying to get logs from node mip-bd-vm40.mip.storage.hpecorp.net pod pod-secrets-b3b3eb04-a115-4a50-ae31-da07db20cdf7 container secret-env-test: <nil>
STEP: delete the pod
Oct 21 23:54:31.258: INFO: Waiting for pod pod-secrets-b3b3eb04-a115-4a50-ae31-da07db20cdf7 to disappear
Oct 21 23:54:31.261: INFO: Pod pod-secrets-b3b3eb04-a115-4a50-ae31-da07db20cdf7 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 23:54:31.262: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-134" for this suite.
Oct 21 23:54:37.284: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 23:54:37.434: INFO: namespace secrets-134 deletion completed in 6.167459622s

• [SLOW TEST:12.298 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 23:54:37.434: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
Oct 21 23:54:37.485: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 23:54:43.282: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-8158" for this suite.
Oct 21 23:54:49.306: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 23:54:49.467: INFO: namespace init-container-8158 deletion completed in 6.178991092s

• [SLOW TEST:12.033 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 23:54:49.467: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap that has name configmap-test-emptyKey-7c4fd1ae-ffbb-42c2-b88b-a406956507a0
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 23:54:49.518: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7517" for this suite.
Oct 21 23:54:55.538: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 23:54:55.688: INFO: namespace configmap-7517 deletion completed in 6.164400206s

• [SLOW TEST:6.220 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 23:54:55.688: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-map-ff655f8c-7b20-49eb-95c5-a2d313fa9e7a
STEP: Creating a pod to test consume secrets
Oct 21 23:54:55.745: INFO: Waiting up to 5m0s for pod "pod-secrets-e6607a53-433b-46a0-9869-4ce2f5cf7952" in namespace "secrets-4061" to be "success or failure"
Oct 21 23:54:55.753: INFO: Pod "pod-secrets-e6607a53-433b-46a0-9869-4ce2f5cf7952": Phase="Pending", Reason="", readiness=false. Elapsed: 8.393149ms
Oct 21 23:54:57.759: INFO: Pod "pod-secrets-e6607a53-433b-46a0-9869-4ce2f5cf7952": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013960345s
Oct 21 23:54:59.764: INFO: Pod "pod-secrets-e6607a53-433b-46a0-9869-4ce2f5cf7952": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018768665s
STEP: Saw pod success
Oct 21 23:54:59.764: INFO: Pod "pod-secrets-e6607a53-433b-46a0-9869-4ce2f5cf7952" satisfied condition "success or failure"
Oct 21 23:54:59.767: INFO: Trying to get logs from node mip-bd-vm40.mip.storage.hpecorp.net pod pod-secrets-e6607a53-433b-46a0-9869-4ce2f5cf7952 container secret-volume-test: <nil>
STEP: delete the pod
Oct 21 23:54:59.794: INFO: Waiting for pod pod-secrets-e6607a53-433b-46a0-9869-4ce2f5cf7952 to disappear
Oct 21 23:54:59.798: INFO: Pod pod-secrets-e6607a53-433b-46a0-9869-4ce2f5cf7952 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 23:54:59.798: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-4061" for this suite.
Oct 21 23:55:05.821: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 23:55:05.966: INFO: namespace secrets-4061 deletion completed in 6.163355579s

• [SLOW TEST:10.278 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 23:55:05.966: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-1497d489-f813-4e34-9a2d-9e06c8fe5e42
STEP: Creating a pod to test consume secrets
Oct 21 23:55:06.128: INFO: Waiting up to 5m0s for pod "pod-secrets-f71faec6-199c-472d-a8e8-1c26d5e6214f" in namespace "secrets-8004" to be "success or failure"
Oct 21 23:55:06.155: INFO: Pod "pod-secrets-f71faec6-199c-472d-a8e8-1c26d5e6214f": Phase="Pending", Reason="", readiness=false. Elapsed: 26.94618ms
Oct 21 23:55:08.161: INFO: Pod "pod-secrets-f71faec6-199c-472d-a8e8-1c26d5e6214f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.032898201s
STEP: Saw pod success
Oct 21 23:55:08.161: INFO: Pod "pod-secrets-f71faec6-199c-472d-a8e8-1c26d5e6214f" satisfied condition "success or failure"
Oct 21 23:55:08.164: INFO: Trying to get logs from node mip-bd-vm41.mip.storage.hpecorp.net pod pod-secrets-f71faec6-199c-472d-a8e8-1c26d5e6214f container secret-volume-test: <nil>
STEP: delete the pod
Oct 21 23:55:08.193: INFO: Waiting for pod pod-secrets-f71faec6-199c-472d-a8e8-1c26d5e6214f to disappear
Oct 21 23:55:08.196: INFO: Pod pod-secrets-f71faec6-199c-472d-a8e8-1c26d5e6214f no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 23:55:08.196: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8004" for this suite.
Oct 21 23:55:14.215: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 23:55:14.375: INFO: namespace secrets-8004 deletion completed in 6.174475844s
STEP: Destroying namespace "secret-namespace-7700" for this suite.
Oct 21 23:55:20.390: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 23:55:20.534: INFO: namespace secret-namespace-7700 deletion completed in 6.158796373s

• [SLOW TEST:14.568 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 23:55:20.534: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-e62956cc-2260-4c08-9b37-389dd46c06fb
STEP: Creating a pod to test consume secrets
Oct 21 23:55:20.596: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-54f7d339-2a87-4855-bcf6-6cb58ecdcf53" in namespace "projected-9403" to be "success or failure"
Oct 21 23:55:20.603: INFO: Pod "pod-projected-secrets-54f7d339-2a87-4855-bcf6-6cb58ecdcf53": Phase="Pending", Reason="", readiness=false. Elapsed: 6.089631ms
Oct 21 23:55:22.607: INFO: Pod "pod-projected-secrets-54f7d339-2a87-4855-bcf6-6cb58ecdcf53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010879989s
STEP: Saw pod success
Oct 21 23:55:22.608: INFO: Pod "pod-projected-secrets-54f7d339-2a87-4855-bcf6-6cb58ecdcf53" satisfied condition "success or failure"
Oct 21 23:55:22.611: INFO: Trying to get logs from node mip-bd-vm40.mip.storage.hpecorp.net pod pod-projected-secrets-54f7d339-2a87-4855-bcf6-6cb58ecdcf53 container projected-secret-volume-test: <nil>
STEP: delete the pod
Oct 21 23:55:22.645: INFO: Waiting for pod pod-projected-secrets-54f7d339-2a87-4855-bcf6-6cb58ecdcf53 to disappear
Oct 21 23:55:22.650: INFO: Pod pod-projected-secrets-54f7d339-2a87-4855-bcf6-6cb58ecdcf53 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 23:55:22.650: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9403" for this suite.
Oct 21 23:55:28.671: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 23:55:28.837: INFO: namespace projected-9403 deletion completed in 6.182961003s

• [SLOW TEST:8.303 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 23:55:28.837: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: starting the proxy server
Oct 21 23:55:28.886: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-172996996 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 23:55:29.034: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-873" for this suite.
Oct 21 23:55:35.057: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 23:55:35.205: INFO: namespace kubectl-873 deletion completed in 6.165875698s

• [SLOW TEST:6.368 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Proxy server
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 23:55:35.205: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-1853
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a new StatefulSet
Oct 21 23:55:35.278: INFO: Found 0 stateful pods, waiting for 3
Oct 21 23:55:45.287: INFO: Found 2 stateful pods, waiting for 3
Oct 21 23:55:55.284: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Oct 21 23:55:55.284: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Oct 21 23:55:55.284: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Oct 21 23:55:55.315: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Oct 21 23:56:05.354: INFO: Updating stateful set ss2
Oct 21 23:56:05.367: INFO: Waiting for Pod statefulset-1853/ss2-2 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
STEP: Restoring Pods to the correct revision when they are deleted
Oct 21 23:56:15.445: INFO: Found 2 stateful pods, waiting for 3
Oct 21 23:56:25.452: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Oct 21 23:56:25.452: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Oct 21 23:56:25.452: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Oct 21 23:56:25.483: INFO: Updating stateful set ss2
Oct 21 23:56:25.491: INFO: Waiting for Pod statefulset-1853/ss2-1 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Oct 21 23:56:35.523: INFO: Updating stateful set ss2
Oct 21 23:56:35.531: INFO: Waiting for StatefulSet statefulset-1853/ss2 to complete update
Oct 21 23:56:35.531: INFO: Waiting for Pod statefulset-1853/ss2-0 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Oct 21 23:56:45.544: INFO: Deleting all statefulset in ns statefulset-1853
Oct 21 23:56:45.548: INFO: Scaling statefulset ss2 to 0
Oct 21 23:57:15.570: INFO: Waiting for statefulset status.replicas updated to 0
Oct 21 23:57:15.574: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 23:57:15.592: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-1853" for this suite.
Oct 21 23:57:31.614: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 23:57:31.770: INFO: namespace statefulset-1853 deletion completed in 16.173413007s

• [SLOW TEST:116.565 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 23:57:31.771: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name s-test-opt-del-bb2be532-0096-4a8a-9490-0ed1b525e55d
STEP: Creating secret with name s-test-opt-upd-d9644ee9-fd14-4bdf-acfb-bcafc09fb153
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-bb2be532-0096-4a8a-9490-0ed1b525e55d
STEP: Updating secret s-test-opt-upd-d9644ee9-fd14-4bdf-acfb-bcafc09fb153
STEP: Creating secret with name s-test-opt-create-e96750e1-d10a-488a-904e-5a8c5acf8d52
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 23:59:08.708: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5994" for this suite.
Oct 21 23:59:30.733: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 23:59:30.901: INFO: namespace secrets-5994 deletion completed in 22.188376583s

• [SLOW TEST:119.131 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 23:59:30.902: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0666 on node default medium
Oct 21 23:59:30.959: INFO: Waiting up to 5m0s for pod "pod-431f5295-ec8a-4c0a-b2af-365f200cba2c" in namespace "emptydir-5776" to be "success or failure"
Oct 21 23:59:30.965: INFO: Pod "pod-431f5295-ec8a-4c0a-b2af-365f200cba2c": Phase="Pending", Reason="", readiness=false. Elapsed: 5.342938ms
Oct 21 23:59:32.971: INFO: Pod "pod-431f5295-ec8a-4c0a-b2af-365f200cba2c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011227065s
Oct 21 23:59:34.976: INFO: Pod "pod-431f5295-ec8a-4c0a-b2af-365f200cba2c": Phase="Pending", Reason="", readiness=false. Elapsed: 4.016279755s
Oct 21 23:59:36.981: INFO: Pod "pod-431f5295-ec8a-4c0a-b2af-365f200cba2c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.022028128s
STEP: Saw pod success
Oct 21 23:59:36.981: INFO: Pod "pod-431f5295-ec8a-4c0a-b2af-365f200cba2c" satisfied condition "success or failure"
Oct 21 23:59:36.985: INFO: Trying to get logs from node mip-bd-vm40.mip.storage.hpecorp.net pod pod-431f5295-ec8a-4c0a-b2af-365f200cba2c container test-container: <nil>
STEP: delete the pod
Oct 21 23:59:37.014: INFO: Waiting for pod pod-431f5295-ec8a-4c0a-b2af-365f200cba2c to disappear
Oct 21 23:59:37.019: INFO: Pod pod-431f5295-ec8a-4c0a-b2af-365f200cba2c no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 23:59:37.019: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5776" for this suite.
Oct 21 23:59:43.039: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 23:59:43.182: INFO: namespace emptydir-5776 deletion completed in 6.158344803s

• [SLOW TEST:12.280 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 23:59:43.182: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Oct 21 23:59:43.267: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:watch-4456,SelfLink:/api/v1/namespaces/watch-4456/configmaps/e2e-watch-test-resource-version,UID:cd680208-48c6-48b3-88dc-57ee6ba46bfe,ResourceVersion:11306,Generation:0,CreationTimestamp:2019-10-21 23:59:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Oct 21 23:59:43.267: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:watch-4456,SelfLink:/api/v1/namespaces/watch-4456/configmaps/e2e-watch-test-resource-version,UID:cd680208-48c6-48b3-88dc-57ee6ba46bfe,ResourceVersion:11307,Generation:0,CreationTimestamp:2019-10-21 23:59:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 23:59:43.267: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-4456" for this suite.
Oct 21 23:59:49.287: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 23:59:49.444: INFO: namespace watch-4456 deletion completed in 6.172625528s

• [SLOW TEST:6.262 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 23:59:49.445: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Oct 21 23:59:49.550: INFO: Waiting up to 5m0s for pod "downwardapi-volume-1eb78b05-e92a-4f3e-a408-77c21367fe77" in namespace "projected-4238" to be "success or failure"
Oct 21 23:59:49.555: INFO: Pod "downwardapi-volume-1eb78b05-e92a-4f3e-a408-77c21367fe77": Phase="Pending", Reason="", readiness=false. Elapsed: 4.753053ms
Oct 21 23:59:51.559: INFO: Pod "downwardapi-volume-1eb78b05-e92a-4f3e-a408-77c21367fe77": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009078987s
STEP: Saw pod success
Oct 21 23:59:51.559: INFO: Pod "downwardapi-volume-1eb78b05-e92a-4f3e-a408-77c21367fe77" satisfied condition "success or failure"
Oct 21 23:59:51.563: INFO: Trying to get logs from node mip-bd-vm41.mip.storage.hpecorp.net pod downwardapi-volume-1eb78b05-e92a-4f3e-a408-77c21367fe77 container client-container: <nil>
STEP: delete the pod
Oct 21 23:59:51.604: INFO: Waiting for pod downwardapi-volume-1eb78b05-e92a-4f3e-a408-77c21367fe77 to disappear
Oct 21 23:59:51.608: INFO: Pod downwardapi-volume-1eb78b05-e92a-4f3e-a408-77c21367fe77 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 23:59:51.608: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4238" for this suite.
Oct 21 23:59:57.632: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 23:59:57.784: INFO: namespace projected-4238 deletion completed in 6.17004157s

• [SLOW TEST:8.340 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 23:59:57.785: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:273
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the initial replication controller
Oct 21 23:59:57.836: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 create -f - --namespace=kubectl-9334'
Oct 21 23:59:58.483: INFO: stderr: ""
Oct 21 23:59:58.483: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Oct 21 23:59:58.484: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9334'
Oct 21 23:59:58.651: INFO: stderr: ""
Oct 21 23:59:58.651: INFO: stdout: "update-demo-nautilus-tbh2v update-demo-nautilus-v4kf2 "
Oct 21 23:59:58.651: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 get pods update-demo-nautilus-tbh2v -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9334'
Oct 21 23:59:58.819: INFO: stderr: ""
Oct 21 23:59:58.819: INFO: stdout: ""
Oct 21 23:59:58.819: INFO: update-demo-nautilus-tbh2v is created but not running
Oct 22 00:00:03.819: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9334'
Oct 22 00:00:03.991: INFO: stderr: ""
Oct 22 00:00:03.991: INFO: stdout: "update-demo-nautilus-tbh2v update-demo-nautilus-v4kf2 "
Oct 22 00:00:03.991: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 get pods update-demo-nautilus-tbh2v -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9334'
Oct 22 00:00:04.158: INFO: stderr: ""
Oct 22 00:00:04.158: INFO: stdout: "true"
Oct 22 00:00:04.158: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 get pods update-demo-nautilus-tbh2v -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9334'
Oct 22 00:00:04.330: INFO: stderr: ""
Oct 22 00:00:04.330: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Oct 22 00:00:04.330: INFO: validating pod update-demo-nautilus-tbh2v
Oct 22 00:00:04.338: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct 22 00:00:04.338: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct 22 00:00:04.338: INFO: update-demo-nautilus-tbh2v is verified up and running
Oct 22 00:00:04.338: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 get pods update-demo-nautilus-v4kf2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9334'
Oct 22 00:00:04.497: INFO: stderr: ""
Oct 22 00:00:04.497: INFO: stdout: "true"
Oct 22 00:00:04.497: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 get pods update-demo-nautilus-v4kf2 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9334'
Oct 22 00:00:04.658: INFO: stderr: ""
Oct 22 00:00:04.658: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Oct 22 00:00:04.658: INFO: validating pod update-demo-nautilus-v4kf2
Oct 22 00:00:04.666: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct 22 00:00:04.666: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct 22 00:00:04.666: INFO: update-demo-nautilus-v4kf2 is verified up and running
STEP: rolling-update to new replication controller
Oct 22 00:00:04.669: INFO: scanned /root for discovery docs: <nil>
Oct 22 00:00:04.669: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=kubectl-9334'
Oct 22 00:00:28.333: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Oct 22 00:00:28.333: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Oct 22 00:00:28.333: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9334'
Oct 22 00:00:28.497: INFO: stderr: ""
Oct 22 00:00:28.497: INFO: stdout: "update-demo-kitten-gg6n2 update-demo-kitten-mbc9b "
Oct 22 00:00:28.497: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 get pods update-demo-kitten-gg6n2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9334'
Oct 22 00:00:28.660: INFO: stderr: ""
Oct 22 00:00:28.660: INFO: stdout: "true"
Oct 22 00:00:28.660: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 get pods update-demo-kitten-gg6n2 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9334'
Oct 22 00:00:28.820: INFO: stderr: ""
Oct 22 00:00:28.820: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Oct 22 00:00:28.820: INFO: validating pod update-demo-kitten-gg6n2
Oct 22 00:00:28.828: INFO: got data: {
  "image": "kitten.jpg"
}

Oct 22 00:00:28.828: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Oct 22 00:00:28.828: INFO: update-demo-kitten-gg6n2 is verified up and running
Oct 22 00:00:28.828: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 get pods update-demo-kitten-mbc9b -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9334'
Oct 22 00:00:28.992: INFO: stderr: ""
Oct 22 00:00:28.993: INFO: stdout: "true"
Oct 22 00:00:28.993: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 get pods update-demo-kitten-mbc9b -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9334'
Oct 22 00:00:29.147: INFO: stderr: ""
Oct 22 00:00:29.147: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Oct 22 00:00:29.147: INFO: validating pod update-demo-kitten-mbc9b
Oct 22 00:00:29.154: INFO: got data: {
  "image": "kitten.jpg"
}

Oct 22 00:00:29.154: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Oct 22 00:00:29.154: INFO: update-demo-kitten-mbc9b is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 00:00:29.154: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9334" for this suite.
Oct 22 00:00:51.175: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 00:00:51.335: INFO: namespace kubectl-9334 deletion completed in 22.175681231s

• [SLOW TEST:53.551 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 00:00:51.336: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Oct 22 00:00:51.385: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 00:00:52.493: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-2678" for this suite.
Oct 22 00:00:58.514: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 00:00:58.669: INFO: namespace custom-resource-definition-2678 deletion completed in 6.170158908s

• [SLOW TEST:7.333 seconds]
[sig-api-machinery] CustomResourceDefinition resources
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:35
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 00:00:58.669: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-cf20a8a0-a611-4d7f-82ef-50f8ce821b3a
STEP: Creating a pod to test consume secrets
Oct 22 00:00:58.737: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-01f6a5f5-f838-46b4-bdd0-d4d022e85fe7" in namespace "projected-7073" to be "success or failure"
Oct 22 00:00:58.740: INFO: Pod "pod-projected-secrets-01f6a5f5-f838-46b4-bdd0-d4d022e85fe7": Phase="Pending", Reason="", readiness=false. Elapsed: 3.43686ms
Oct 22 00:01:00.749: INFO: Pod "pod-projected-secrets-01f6a5f5-f838-46b4-bdd0-d4d022e85fe7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011674121s
STEP: Saw pod success
Oct 22 00:01:00.749: INFO: Pod "pod-projected-secrets-01f6a5f5-f838-46b4-bdd0-d4d022e85fe7" satisfied condition "success or failure"
Oct 22 00:01:00.754: INFO: Trying to get logs from node mip-bd-vm40.mip.storage.hpecorp.net pod pod-projected-secrets-01f6a5f5-f838-46b4-bdd0-d4d022e85fe7 container projected-secret-volume-test: <nil>
STEP: delete the pod
Oct 22 00:01:00.781: INFO: Waiting for pod pod-projected-secrets-01f6a5f5-f838-46b4-bdd0-d4d022e85fe7 to disappear
Oct 22 00:01:00.785: INFO: Pod pod-projected-secrets-01f6a5f5-f838-46b4-bdd0-d4d022e85fe7 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 00:01:00.785: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7073" for this suite.
Oct 22 00:01:06.806: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 00:01:06.955: INFO: namespace projected-7073 deletion completed in 6.163758799s

• [SLOW TEST:8.286 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 00:01:06.955: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 00:01:07.029: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-6252" for this suite.
Oct 22 00:01:13.058: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 00:01:13.194: INFO: namespace kubelet-test-6252 deletion completed in 6.157643874s

• [SLOW TEST:6.239 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should be possible to delete [NodeConformance] [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 00:01:13.195: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the container
STEP: wait for the container to reach Failed
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Oct 22 00:01:15.267: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 00:01:15.287: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-7787" for this suite.
Oct 22 00:01:21.308: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 00:01:21.448: INFO: namespace container-runtime-7787 deletion completed in 6.156680616s

• [SLOW TEST:8.254 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  blackbox test
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
    on terminated container
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:129
      should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] version v1
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 00:01:21.449: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Oct 22 00:01:21.505: INFO: (0) /api/v1/nodes/mip-bd-vm40.mip.storage.hpecorp.net:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="bluedata/">bluedata/... (200; 8.794167ms)
Oct 22 00:01:21.510: INFO: (1) /api/v1/nodes/mip-bd-vm40.mip.storage.hpecorp.net:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="bluedata/">bluedata/... (200; 5.040353ms)
Oct 22 00:01:21.516: INFO: (2) /api/v1/nodes/mip-bd-vm40.mip.storage.hpecorp.net:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="bluedata/">bluedata/... (200; 6.066266ms)
Oct 22 00:01:21.521: INFO: (3) /api/v1/nodes/mip-bd-vm40.mip.storage.hpecorp.net:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="bluedata/">bluedata/... (200; 4.871314ms)
Oct 22 00:01:21.526: INFO: (4) /api/v1/nodes/mip-bd-vm40.mip.storage.hpecorp.net:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="bluedata/">bluedata/... (200; 4.869938ms)
Oct 22 00:01:21.531: INFO: (5) /api/v1/nodes/mip-bd-vm40.mip.storage.hpecorp.net:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="bluedata/">bluedata/... (200; 4.743582ms)
Oct 22 00:01:21.536: INFO: (6) /api/v1/nodes/mip-bd-vm40.mip.storage.hpecorp.net:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="bluedata/">bluedata/... (200; 4.663536ms)
Oct 22 00:01:21.541: INFO: (7) /api/v1/nodes/mip-bd-vm40.mip.storage.hpecorp.net:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="bluedata/">bluedata/... (200; 4.773473ms)
Oct 22 00:01:21.546: INFO: (8) /api/v1/nodes/mip-bd-vm40.mip.storage.hpecorp.net:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="bluedata/">bluedata/... (200; 4.988016ms)
Oct 22 00:01:21.550: INFO: (9) /api/v1/nodes/mip-bd-vm40.mip.storage.hpecorp.net:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="bluedata/">bluedata/... (200; 4.523467ms)
Oct 22 00:01:21.555: INFO: (10) /api/v1/nodes/mip-bd-vm40.mip.storage.hpecorp.net:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="bluedata/">bluedata/... (200; 4.758777ms)
Oct 22 00:01:21.561: INFO: (11) /api/v1/nodes/mip-bd-vm40.mip.storage.hpecorp.net:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="bluedata/">bluedata/... (200; 5.767274ms)
Oct 22 00:01:21.565: INFO: (12) /api/v1/nodes/mip-bd-vm40.mip.storage.hpecorp.net:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="bluedata/">bluedata/... (200; 4.663745ms)
Oct 22 00:01:21.570: INFO: (13) /api/v1/nodes/mip-bd-vm40.mip.storage.hpecorp.net:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="bluedata/">bluedata/... (200; 4.700285ms)
Oct 22 00:01:21.575: INFO: (14) /api/v1/nodes/mip-bd-vm40.mip.storage.hpecorp.net:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="bluedata/">bluedata/... (200; 4.828528ms)
Oct 22 00:01:21.580: INFO: (15) /api/v1/nodes/mip-bd-vm40.mip.storage.hpecorp.net:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="bluedata/">bluedata/... (200; 4.892542ms)
Oct 22 00:01:21.585: INFO: (16) /api/v1/nodes/mip-bd-vm40.mip.storage.hpecorp.net:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="bluedata/">bluedata/... (200; 4.580714ms)
Oct 22 00:01:21.589: INFO: (17) /api/v1/nodes/mip-bd-vm40.mip.storage.hpecorp.net:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="bluedata/">bluedata/... (200; 4.691342ms)
Oct 22 00:01:21.594: INFO: (18) /api/v1/nodes/mip-bd-vm40.mip.storage.hpecorp.net:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="bluedata/">bluedata/... (200; 4.844736ms)
Oct 22 00:01:21.600: INFO: (19) /api/v1/nodes/mip-bd-vm40.mip.storage.hpecorp.net:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="bluedata/">bluedata/... (200; 5.319544ms)
[AfterEach] version v1
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 00:01:21.600: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-7338" for this suite.
Oct 22 00:01:27.618: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 00:01:27.758: INFO: namespace proxy-7338 deletion completed in 6.154713614s

• [SLOW TEST:6.310 seconds]
[sig-network] Proxy
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:58
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 00:01:27.759: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-3781
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace statefulset-3781
STEP: Creating statefulset with conflicting port in namespace statefulset-3781
STEP: Waiting until pod test-pod will start running in namespace statefulset-3781
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-3781
Oct 22 00:01:29.859: INFO: Observed stateful pod in namespace: statefulset-3781, name: ss-0, uid: bbcb9c80-3008-4c97-9449-efe93d05212c, status phase: Pending. Waiting for statefulset controller to delete.
Oct 22 00:01:30.442: INFO: Observed stateful pod in namespace: statefulset-3781, name: ss-0, uid: bbcb9c80-3008-4c97-9449-efe93d05212c, status phase: Failed. Waiting for statefulset controller to delete.
Oct 22 00:01:30.456: INFO: Observed stateful pod in namespace: statefulset-3781, name: ss-0, uid: bbcb9c80-3008-4c97-9449-efe93d05212c, status phase: Failed. Waiting for statefulset controller to delete.
Oct 22 00:01:30.459: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-3781
STEP: Removing pod with conflicting port in namespace statefulset-3781
STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-3781 and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Oct 22 00:01:34.511: INFO: Deleting all statefulset in ns statefulset-3781
Oct 22 00:01:34.515: INFO: Scaling statefulset ss to 0
Oct 22 00:01:44.550: INFO: Waiting for statefulset status.replicas updated to 0
Oct 22 00:01:44.554: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 00:01:44.571: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-3781" for this suite.
Oct 22 00:01:58.597: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 00:01:58.752: INFO: namespace statefulset-3781 deletion completed in 14.176373643s

• [SLOW TEST:30.992 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 00:01:58.752: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-39dfc5b6-c2a3-4c2c-afad-363a8122e562
STEP: Creating a pod to test consume configMaps
Oct 22 00:01:58.819: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-b40ecea2-af16-4038-99ae-c4cef80e8fc2" in namespace "projected-4514" to be "success or failure"
Oct 22 00:01:58.825: INFO: Pod "pod-projected-configmaps-b40ecea2-af16-4038-99ae-c4cef80e8fc2": Phase="Pending", Reason="", readiness=false. Elapsed: 6.116101ms
Oct 22 00:02:00.833: INFO: Pod "pod-projected-configmaps-b40ecea2-af16-4038-99ae-c4cef80e8fc2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013447931s
STEP: Saw pod success
Oct 22 00:02:00.833: INFO: Pod "pod-projected-configmaps-b40ecea2-af16-4038-99ae-c4cef80e8fc2" satisfied condition "success or failure"
Oct 22 00:02:00.836: INFO: Trying to get logs from node mip-bd-vm41.mip.storage.hpecorp.net pod pod-projected-configmaps-b40ecea2-af16-4038-99ae-c4cef80e8fc2 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Oct 22 00:02:00.872: INFO: Waiting for pod pod-projected-configmaps-b40ecea2-af16-4038-99ae-c4cef80e8fc2 to disappear
Oct 22 00:02:00.877: INFO: Pod pod-projected-configmaps-b40ecea2-af16-4038-99ae-c4cef80e8fc2 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 00:02:00.877: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4514" for this suite.
Oct 22 00:02:06.900: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 00:02:07.059: INFO: namespace projected-4514 deletion completed in 6.177254907s

• [SLOW TEST:8.307 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 00:02:07.061: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: validating cluster-info
Oct 22 00:02:07.114: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 cluster-info'
Oct 22 00:02:07.279: INFO: stderr: ""
Oct 22 00:02:07.279: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://10.96.0.1:443\x1b[0m\n\x1b[0;32mKubeDNS\x1b[0m is running at \x1b[0;33mhttps://10.96.0.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 00:02:07.279: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2420" for this suite.
Oct 22 00:02:13.306: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 00:02:13.451: INFO: namespace kubectl-2420 deletion completed in 6.167060326s

• [SLOW TEST:6.391 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl cluster-info
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 00:02:13.452: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
Oct 22 00:02:13.507: INFO: observed the pod list
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 00:02:20.937: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-1117" for this suite.
Oct 22 00:02:26.961: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 00:02:27.249: INFO: namespace pods-1117 deletion completed in 6.304440525s

• [SLOW TEST:13.797 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 00:02:27.250: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 00:02:31.315: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-2667" for this suite.
Oct 22 00:02:37.338: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 00:02:37.494: INFO: namespace kubelet-test-2667 deletion completed in 6.17426319s

• [SLOW TEST:10.244 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should have an terminated reason [NodeConformance] [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 00:02:37.494: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Oct 22 00:02:37.569: INFO: Waiting up to 5m0s for pod "downwardapi-volume-389e7ce8-1ea1-409d-b39b-2a2da5570c13" in namespace "projected-2086" to be "success or failure"
Oct 22 00:02:37.574: INFO: Pod "downwardapi-volume-389e7ce8-1ea1-409d-b39b-2a2da5570c13": Phase="Pending", Reason="", readiness=false. Elapsed: 5.026667ms
Oct 22 00:02:39.580: INFO: Pod "downwardapi-volume-389e7ce8-1ea1-409d-b39b-2a2da5570c13": Phase="Running", Reason="", readiness=true. Elapsed: 2.01018537s
Oct 22 00:02:41.585: INFO: Pod "downwardapi-volume-389e7ce8-1ea1-409d-b39b-2a2da5570c13": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015430564s
STEP: Saw pod success
Oct 22 00:02:41.585: INFO: Pod "downwardapi-volume-389e7ce8-1ea1-409d-b39b-2a2da5570c13" satisfied condition "success or failure"
Oct 22 00:02:41.588: INFO: Trying to get logs from node mip-bd-vm41.mip.storage.hpecorp.net pod downwardapi-volume-389e7ce8-1ea1-409d-b39b-2a2da5570c13 container client-container: <nil>
STEP: delete the pod
Oct 22 00:02:41.621: INFO: Waiting for pod downwardapi-volume-389e7ce8-1ea1-409d-b39b-2a2da5570c13 to disappear
Oct 22 00:02:41.626: INFO: Pod downwardapi-volume-389e7ce8-1ea1-409d-b39b-2a2da5570c13 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 00:02:41.626: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2086" for this suite.
Oct 22 00:02:47.648: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 00:02:47.795: INFO: namespace projected-2086 deletion completed in 6.164528345s

• [SLOW TEST:10.301 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 00:02:47.796: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0777 on node default medium
Oct 22 00:02:47.849: INFO: Waiting up to 5m0s for pod "pod-d8f1a0ff-a535-42e2-8317-7dcfcc36e890" in namespace "emptydir-7107" to be "success or failure"
Oct 22 00:02:47.856: INFO: Pod "pod-d8f1a0ff-a535-42e2-8317-7dcfcc36e890": Phase="Pending", Reason="", readiness=false. Elapsed: 6.782477ms
Oct 22 00:02:49.863: INFO: Pod "pod-d8f1a0ff-a535-42e2-8317-7dcfcc36e890": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013425582s
Oct 22 00:02:51.868: INFO: Pod "pod-d8f1a0ff-a535-42e2-8317-7dcfcc36e890": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018738828s
STEP: Saw pod success
Oct 22 00:02:51.868: INFO: Pod "pod-d8f1a0ff-a535-42e2-8317-7dcfcc36e890" satisfied condition "success or failure"
Oct 22 00:02:51.874: INFO: Trying to get logs from node mip-bd-vm41.mip.storage.hpecorp.net pod pod-d8f1a0ff-a535-42e2-8317-7dcfcc36e890 container test-container: <nil>
STEP: delete the pod
Oct 22 00:02:51.904: INFO: Waiting for pod pod-d8f1a0ff-a535-42e2-8317-7dcfcc36e890 to disappear
Oct 22 00:02:51.911: INFO: Pod pod-d8f1a0ff-a535-42e2-8317-7dcfcc36e890 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 00:02:51.911: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7107" for this suite.
Oct 22 00:02:57.932: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 00:02:58.083: INFO: namespace emptydir-7107 deletion completed in 6.164677388s

• [SLOW TEST:10.287 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 00:02:58.083: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-7094.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-7094.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Oct 22 00:03:00.192: INFO: DNS probes using dns-7094/dns-test-9b2934ea-4314-48eb-9c15-0932d6cbb573 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 00:03:00.208: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-7094" for this suite.
Oct 22 00:03:06.230: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 00:03:06.376: INFO: namespace dns-7094 deletion completed in 6.160431954s

• [SLOW TEST:8.293 seconds]
[sig-network] DNS
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 00:03:06.376: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Performing setup for networking test in namespace pod-network-test-1591
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Oct 22 00:03:06.421: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Oct 22 00:03:32.535: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.1.33:8080/dial?request=hostName&protocol=udp&host=10.244.1.32&port=8081&tries=1'] Namespace:pod-network-test-1591 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 22 00:03:32.535: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
Oct 22 00:03:32.671: INFO: Waiting for endpoints: map[]
Oct 22 00:03:32.675: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.1.33:8080/dial?request=hostName&protocol=udp&host=10.244.2.25&port=8081&tries=1'] Namespace:pod-network-test-1591 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 22 00:03:32.676: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
Oct 22 00:03:32.815: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 00:03:32.815: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-1591" for this suite.
Oct 22 00:03:54.838: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 00:03:54.995: INFO: namespace pod-network-test-1591 deletion completed in 22.174513391s

• [SLOW TEST:48.619 seconds]
[sig-network] Networking
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 00:03:54.996: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod liveness-3dfcd8d0-fa26-4a42-aa58-166564d13aed in namespace container-probe-6345
Oct 22 00:03:59.062: INFO: Started pod liveness-3dfcd8d0-fa26-4a42-aa58-166564d13aed in namespace container-probe-6345
STEP: checking the pod's current state and verifying that restartCount is present
Oct 22 00:03:59.065: INFO: Initial restart count of pod liveness-3dfcd8d0-fa26-4a42-aa58-166564d13aed is 0
Oct 22 00:04:20.202: INFO: Restart count of pod container-probe-6345/liveness-3dfcd8d0-fa26-4a42-aa58-166564d13aed is now 1 (21.13698845s elapsed)
Oct 22 00:04:38.248: INFO: Restart count of pod container-probe-6345/liveness-3dfcd8d0-fa26-4a42-aa58-166564d13aed is now 2 (39.183496825s elapsed)
Oct 22 00:04:58.301: INFO: Restart count of pod container-probe-6345/liveness-3dfcd8d0-fa26-4a42-aa58-166564d13aed is now 3 (59.236293702s elapsed)
Oct 22 00:05:18.353: INFO: Restart count of pod container-probe-6345/liveness-3dfcd8d0-fa26-4a42-aa58-166564d13aed is now 4 (1m19.288596472s elapsed)
Oct 22 00:06:26.549: INFO: Restart count of pod container-probe-6345/liveness-3dfcd8d0-fa26-4a42-aa58-166564d13aed is now 5 (2m27.484397902s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 00:06:26.571: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-6345" for this suite.
Oct 22 00:06:32.594: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 00:06:32.742: INFO: namespace container-probe-6345 deletion completed in 6.164125068s

• [SLOW TEST:157.746 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 00:06:32.742: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:273
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a replication controller
Oct 22 00:06:32.796: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 create -f - --namespace=kubectl-2853'
Oct 22 00:06:33.139: INFO: stderr: ""
Oct 22 00:06:33.139: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Oct 22 00:06:33.139: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-2853'
Oct 22 00:06:33.314: INFO: stderr: ""
Oct 22 00:06:33.314: INFO: stdout: "update-demo-nautilus-ljjlh update-demo-nautilus-tjndl "
Oct 22 00:06:33.314: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 get pods update-demo-nautilus-ljjlh -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2853'
Oct 22 00:06:33.487: INFO: stderr: ""
Oct 22 00:06:33.487: INFO: stdout: ""
Oct 22 00:06:33.487: INFO: update-demo-nautilus-ljjlh is created but not running
Oct 22 00:06:38.487: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-2853'
Oct 22 00:06:38.656: INFO: stderr: ""
Oct 22 00:06:38.656: INFO: stdout: "update-demo-nautilus-ljjlh update-demo-nautilus-tjndl "
Oct 22 00:06:38.656: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 get pods update-demo-nautilus-ljjlh -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2853'
Oct 22 00:06:38.819: INFO: stderr: ""
Oct 22 00:06:38.819: INFO: stdout: "true"
Oct 22 00:06:38.819: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 get pods update-demo-nautilus-ljjlh -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-2853'
Oct 22 00:06:38.989: INFO: stderr: ""
Oct 22 00:06:38.989: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Oct 22 00:06:38.989: INFO: validating pod update-demo-nautilus-ljjlh
Oct 22 00:06:38.998: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct 22 00:06:38.998: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct 22 00:06:38.998: INFO: update-demo-nautilus-ljjlh is verified up and running
Oct 22 00:06:38.998: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 get pods update-demo-nautilus-tjndl -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2853'
Oct 22 00:06:39.165: INFO: stderr: ""
Oct 22 00:06:39.165: INFO: stdout: "true"
Oct 22 00:06:39.165: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 get pods update-demo-nautilus-tjndl -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-2853'
Oct 22 00:06:39.345: INFO: stderr: ""
Oct 22 00:06:39.345: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Oct 22 00:06:39.345: INFO: validating pod update-demo-nautilus-tjndl
Oct 22 00:06:39.353: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct 22 00:06:39.353: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct 22 00:06:39.353: INFO: update-demo-nautilus-tjndl is verified up and running
STEP: using delete to clean up resources
Oct 22 00:06:39.353: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 delete --grace-period=0 --force -f - --namespace=kubectl-2853'
Oct 22 00:06:39.539: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct 22 00:06:39.539: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Oct 22 00:06:39.539: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-2853'
Oct 22 00:06:39.719: INFO: stderr: "No resources found.\n"
Oct 22 00:06:39.719: INFO: stdout: ""
Oct 22 00:06:39.720: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 get pods -l name=update-demo --namespace=kubectl-2853 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Oct 22 00:06:39.888: INFO: stderr: ""
Oct 22 00:06:39.888: INFO: stdout: "update-demo-nautilus-ljjlh\nupdate-demo-nautilus-tjndl\n"
Oct 22 00:06:40.389: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-2853'
Oct 22 00:06:40.571: INFO: stderr: "No resources found.\n"
Oct 22 00:06:40.571: INFO: stdout: ""
Oct 22 00:06:40.571: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 get pods -l name=update-demo --namespace=kubectl-2853 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Oct 22 00:06:40.741: INFO: stderr: ""
Oct 22 00:06:40.741: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 00:06:40.741: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2853" for this suite.
Oct 22 00:07:02.765: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 00:07:02.925: INFO: namespace kubectl-2853 deletion completed in 22.177278341s

• [SLOW TEST:30.183 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 00:07:02.925: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating the pod
Oct 22 00:07:05.535: INFO: Successfully updated pod "annotationupdate2cd32d79-c874-4a8c-ba49-079334b66231"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 00:07:07.569: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5730" for this suite.
Oct 22 00:07:29.589: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 00:07:29.735: INFO: namespace projected-5730 deletion completed in 22.160761106s

• [SLOW TEST:26.810 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 00:07:29.735: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Oct 22 00:07:29.794: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9dbf71b0-948c-4681-98b2-199b6c8784c8" in namespace "downward-api-3215" to be "success or failure"
Oct 22 00:07:29.799: INFO: Pod "downwardapi-volume-9dbf71b0-948c-4681-98b2-199b6c8784c8": Phase="Pending", Reason="", readiness=false. Elapsed: 5.110751ms
Oct 22 00:07:31.804: INFO: Pod "downwardapi-volume-9dbf71b0-948c-4681-98b2-199b6c8784c8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010097749s
STEP: Saw pod success
Oct 22 00:07:31.804: INFO: Pod "downwardapi-volume-9dbf71b0-948c-4681-98b2-199b6c8784c8" satisfied condition "success or failure"
Oct 22 00:07:31.808: INFO: Trying to get logs from node mip-bd-vm41.mip.storage.hpecorp.net pod downwardapi-volume-9dbf71b0-948c-4681-98b2-199b6c8784c8 container client-container: <nil>
STEP: delete the pod
Oct 22 00:07:31.833: INFO: Waiting for pod downwardapi-volume-9dbf71b0-948c-4681-98b2-199b6c8784c8 to disappear
Oct 22 00:07:31.840: INFO: Pod downwardapi-volume-9dbf71b0-948c-4681-98b2-199b6c8784c8 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 00:07:31.840: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3215" for this suite.
Oct 22 00:07:37.864: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 00:07:38.009: INFO: namespace downward-api-3215 deletion completed in 6.160906597s

• [SLOW TEST:8.274 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 00:07:38.009: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-map-2945f637-849e-4794-b743-c850b4ce1393
STEP: Creating a pod to test consume configMaps
Oct 22 00:07:38.066: INFO: Waiting up to 5m0s for pod "pod-configmaps-7828aa23-bd59-41e3-bee2-79415732d59b" in namespace "configmap-3232" to be "success or failure"
Oct 22 00:07:38.071: INFO: Pod "pod-configmaps-7828aa23-bd59-41e3-bee2-79415732d59b": Phase="Pending", Reason="", readiness=false. Elapsed: 5.297442ms
Oct 22 00:07:40.076: INFO: Pod "pod-configmaps-7828aa23-bd59-41e3-bee2-79415732d59b": Phase="Running", Reason="", readiness=true. Elapsed: 2.010208311s
Oct 22 00:07:42.082: INFO: Pod "pod-configmaps-7828aa23-bd59-41e3-bee2-79415732d59b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015597872s
STEP: Saw pod success
Oct 22 00:07:42.082: INFO: Pod "pod-configmaps-7828aa23-bd59-41e3-bee2-79415732d59b" satisfied condition "success or failure"
Oct 22 00:07:42.086: INFO: Trying to get logs from node mip-bd-vm40.mip.storage.hpecorp.net pod pod-configmaps-7828aa23-bd59-41e3-bee2-79415732d59b container configmap-volume-test: <nil>
STEP: delete the pod
Oct 22 00:07:42.113: INFO: Waiting for pod pod-configmaps-7828aa23-bd59-41e3-bee2-79415732d59b to disappear
Oct 22 00:07:42.118: INFO: Pod pod-configmaps-7828aa23-bd59-41e3-bee2-79415732d59b no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 00:07:42.118: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3232" for this suite.
Oct 22 00:07:48.140: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 00:07:48.285: INFO: namespace configmap-3232 deletion completed in 6.162153929s

• [SLOW TEST:10.276 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 00:07:48.286: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
Oct 22 00:07:48.329: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 00:07:51.727: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-6351" for this suite.
Oct 22 00:07:57.757: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 00:07:57.918: INFO: namespace init-container-6351 deletion completed in 6.184114219s

• [SLOW TEST:9.632 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 00:07:57.919: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod busybox-7782c329-7d8f-45a5-addf-3349f71bd7a9 in namespace container-probe-6513
Oct 22 00:07:59.981: INFO: Started pod busybox-7782c329-7d8f-45a5-addf-3349f71bd7a9 in namespace container-probe-6513
STEP: checking the pod's current state and verifying that restartCount is present
Oct 22 00:07:59.984: INFO: Initial restart count of pod busybox-7782c329-7d8f-45a5-addf-3349f71bd7a9 is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 00:12:00.679: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-6513" for this suite.
Oct 22 00:12:06.700: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 00:12:06.862: INFO: namespace container-probe-6513 deletion completed in 6.178060391s

• [SLOW TEST:248.944 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 00:12:06.863: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:63
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Oct 22 00:12:14.973: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct 22 00:12:14.982: INFO: Pod pod-with-poststart-exec-hook still exists
Oct 22 00:12:16.982: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct 22 00:12:16.988: INFO: Pod pod-with-poststart-exec-hook still exists
Oct 22 00:12:18.982: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct 22 00:12:18.989: INFO: Pod pod-with-poststart-exec-hook still exists
Oct 22 00:12:20.982: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct 22 00:12:20.987: INFO: Pod pod-with-poststart-exec-hook still exists
Oct 22 00:12:22.982: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct 22 00:12:22.987: INFO: Pod pod-with-poststart-exec-hook still exists
Oct 22 00:12:24.982: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct 22 00:12:24.988: INFO: Pod pod-with-poststart-exec-hook still exists
Oct 22 00:12:26.982: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct 22 00:12:26.988: INFO: Pod pod-with-poststart-exec-hook still exists
Oct 22 00:12:28.982: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct 22 00:12:28.987: INFO: Pod pod-with-poststart-exec-hook still exists
Oct 22 00:12:30.982: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct 22 00:12:30.987: INFO: Pod pod-with-poststart-exec-hook still exists
Oct 22 00:12:32.982: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct 22 00:12:32.989: INFO: Pod pod-with-poststart-exec-hook still exists
Oct 22 00:12:34.982: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct 22 00:12:34.988: INFO: Pod pod-with-poststart-exec-hook still exists
Oct 22 00:12:36.982: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct 22 00:12:36.988: INFO: Pod pod-with-poststart-exec-hook still exists
Oct 22 00:12:38.982: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct 22 00:12:38.987: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 00:12:38.987: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-7613" for this suite.
Oct 22 00:13:01.006: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 00:13:01.161: INFO: namespace container-lifecycle-hook-7613 deletion completed in 22.169687528s

• [SLOW TEST:54.298 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when create a pod with lifecycle hook
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 00:13:01.162: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: executing a command with run --rm and attach with stdin
Oct 22 00:13:01.207: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 --namespace=kubectl-1812 run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Oct 22 00:13:02.851: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Oct 22 00:13:02.851: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 00:13:04.861: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1812" for this suite.
Oct 22 00:13:10.885: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 00:13:11.047: INFO: namespace kubectl-1812 deletion completed in 6.179839849s

• [SLOW TEST:9.884 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run --rm job
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 00:13:11.047: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Oct 22 00:13:11.103: INFO: Waiting up to 5m0s for pod "downwardapi-volume-84b81431-22b2-4662-be4a-3cf03afc00f2" in namespace "projected-5854" to be "success or failure"
Oct 22 00:13:11.109: INFO: Pod "downwardapi-volume-84b81431-22b2-4662-be4a-3cf03afc00f2": Phase="Pending", Reason="", readiness=false. Elapsed: 6.048479ms
Oct 22 00:13:13.115: INFO: Pod "downwardapi-volume-84b81431-22b2-4662-be4a-3cf03afc00f2": Phase="Running", Reason="", readiness=true. Elapsed: 2.011999635s
Oct 22 00:13:15.120: INFO: Pod "downwardapi-volume-84b81431-22b2-4662-be4a-3cf03afc00f2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016887224s
STEP: Saw pod success
Oct 22 00:13:15.120: INFO: Pod "downwardapi-volume-84b81431-22b2-4662-be4a-3cf03afc00f2" satisfied condition "success or failure"
Oct 22 00:13:15.123: INFO: Trying to get logs from node mip-bd-vm40.mip.storage.hpecorp.net pod downwardapi-volume-84b81431-22b2-4662-be4a-3cf03afc00f2 container client-container: <nil>
STEP: delete the pod
Oct 22 00:13:15.154: INFO: Waiting for pod downwardapi-volume-84b81431-22b2-4662-be4a-3cf03afc00f2 to disappear
Oct 22 00:13:15.158: INFO: Pod downwardapi-volume-84b81431-22b2-4662-be4a-3cf03afc00f2 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 00:13:15.158: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5854" for this suite.
Oct 22 00:13:21.178: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 00:13:21.335: INFO: namespace projected-5854 deletion completed in 6.172365857s

• [SLOW TEST:10.288 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 00:13:21.335: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-projected-all-test-volume-941f9282-2024-400e-8a8c-8f32cdd55173
STEP: Creating secret with name secret-projected-all-test-volume-24ee7cb6-1126-402f-8baf-88758e5577f4
STEP: Creating a pod to test Check all projections for projected volume plugin
Oct 22 00:13:21.422: INFO: Waiting up to 5m0s for pod "projected-volume-019240ca-7f1e-47d0-988d-438e7039ce32" in namespace "projected-6315" to be "success or failure"
Oct 22 00:13:21.428: INFO: Pod "projected-volume-019240ca-7f1e-47d0-988d-438e7039ce32": Phase="Pending", Reason="", readiness=false. Elapsed: 6.149757ms
Oct 22 00:13:23.433: INFO: Pod "projected-volume-019240ca-7f1e-47d0-988d-438e7039ce32": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011200842s
STEP: Saw pod success
Oct 22 00:13:23.433: INFO: Pod "projected-volume-019240ca-7f1e-47d0-988d-438e7039ce32" satisfied condition "success or failure"
Oct 22 00:13:23.437: INFO: Trying to get logs from node mip-bd-vm41.mip.storage.hpecorp.net pod projected-volume-019240ca-7f1e-47d0-988d-438e7039ce32 container projected-all-volume-test: <nil>
STEP: delete the pod
Oct 22 00:13:23.469: INFO: Waiting for pod projected-volume-019240ca-7f1e-47d0-988d-438e7039ce32 to disappear
Oct 22 00:13:23.473: INFO: Pod projected-volume-019240ca-7f1e-47d0-988d-438e7039ce32 no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 00:13:23.473: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6315" for this suite.
Oct 22 00:13:29.494: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 00:13:29.654: INFO: namespace projected-6315 deletion completed in 6.174892613s

• [SLOW TEST:8.319 seconds]
[sig-storage] Projected combined
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_combined.go:31
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 00:13:29.654: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0666 on tmpfs
Oct 22 00:13:29.713: INFO: Waiting up to 5m0s for pod "pod-975f21c6-17ea-4c17-805a-50cf46bac7ef" in namespace "emptydir-6799" to be "success or failure"
Oct 22 00:13:29.717: INFO: Pod "pod-975f21c6-17ea-4c17-805a-50cf46bac7ef": Phase="Pending", Reason="", readiness=false. Elapsed: 4.35416ms
Oct 22 00:13:31.722: INFO: Pod "pod-975f21c6-17ea-4c17-805a-50cf46bac7ef": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009655779s
STEP: Saw pod success
Oct 22 00:13:31.723: INFO: Pod "pod-975f21c6-17ea-4c17-805a-50cf46bac7ef" satisfied condition "success or failure"
Oct 22 00:13:31.726: INFO: Trying to get logs from node mip-bd-vm40.mip.storage.hpecorp.net pod pod-975f21c6-17ea-4c17-805a-50cf46bac7ef container test-container: <nil>
STEP: delete the pod
Oct 22 00:13:31.752: INFO: Waiting for pod pod-975f21c6-17ea-4c17-805a-50cf46bac7ef to disappear
Oct 22 00:13:31.763: INFO: Pod pod-975f21c6-17ea-4c17-805a-50cf46bac7ef no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 00:13:31.763: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6799" for this suite.
Oct 22 00:13:37.783: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 00:13:37.939: INFO: namespace emptydir-6799 deletion completed in 6.171046943s

• [SLOW TEST:8.285 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 00:13:37.940: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test override arguments
Oct 22 00:13:37.997: INFO: Waiting up to 5m0s for pod "client-containers-84de7449-f39b-4b7a-bf60-e9c03568db79" in namespace "containers-968" to be "success or failure"
Oct 22 00:13:38.001: INFO: Pod "client-containers-84de7449-f39b-4b7a-bf60-e9c03568db79": Phase="Pending", Reason="", readiness=false. Elapsed: 3.764373ms
Oct 22 00:13:40.007: INFO: Pod "client-containers-84de7449-f39b-4b7a-bf60-e9c03568db79": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009951803s
Oct 22 00:13:42.013: INFO: Pod "client-containers-84de7449-f39b-4b7a-bf60-e9c03568db79": Phase="Pending", Reason="", readiness=false. Elapsed: 4.016109175s
Oct 22 00:13:44.019: INFO: Pod "client-containers-84de7449-f39b-4b7a-bf60-e9c03568db79": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.022465131s
STEP: Saw pod success
Oct 22 00:13:44.019: INFO: Pod "client-containers-84de7449-f39b-4b7a-bf60-e9c03568db79" satisfied condition "success or failure"
Oct 22 00:13:44.023: INFO: Trying to get logs from node mip-bd-vm41.mip.storage.hpecorp.net pod client-containers-84de7449-f39b-4b7a-bf60-e9c03568db79 container test-container: <nil>
STEP: delete the pod
Oct 22 00:13:44.051: INFO: Waiting for pod client-containers-84de7449-f39b-4b7a-bf60-e9c03568db79 to disappear
Oct 22 00:13:44.055: INFO: Pod client-containers-84de7449-f39b-4b7a-bf60-e9c03568db79 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 00:13:44.055: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-968" for this suite.
Oct 22 00:13:50.077: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 00:13:50.254: INFO: namespace containers-968 deletion completed in 6.193391274s

• [SLOW TEST:12.314 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 00:13:50.254: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0644 on tmpfs
Oct 22 00:13:50.309: INFO: Waiting up to 5m0s for pod "pod-ecb9b727-c0f8-4932-a48f-fb8ca60b7536" in namespace "emptydir-2085" to be "success or failure"
Oct 22 00:13:50.313: INFO: Pod "pod-ecb9b727-c0f8-4932-a48f-fb8ca60b7536": Phase="Pending", Reason="", readiness=false. Elapsed: 3.793871ms
Oct 22 00:13:52.317: INFO: Pod "pod-ecb9b727-c0f8-4932-a48f-fb8ca60b7536": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008228554s
STEP: Saw pod success
Oct 22 00:13:52.318: INFO: Pod "pod-ecb9b727-c0f8-4932-a48f-fb8ca60b7536" satisfied condition "success or failure"
Oct 22 00:13:52.321: INFO: Trying to get logs from node mip-bd-vm40.mip.storage.hpecorp.net pod pod-ecb9b727-c0f8-4932-a48f-fb8ca60b7536 container test-container: <nil>
STEP: delete the pod
Oct 22 00:13:52.348: INFO: Waiting for pod pod-ecb9b727-c0f8-4932-a48f-fb8ca60b7536 to disappear
Oct 22 00:13:52.352: INFO: Pod pod-ecb9b727-c0f8-4932-a48f-fb8ca60b7536 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 00:13:52.352: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2085" for this suite.
Oct 22 00:13:58.373: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 00:13:58.521: INFO: namespace emptydir-2085 deletion completed in 6.163666155s

• [SLOW TEST:8.266 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 00:13:58.521: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Oct 22 00:13:58.574: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f1e3e562-68d5-40be-a5ea-79af36ca60fc" in namespace "projected-3757" to be "success or failure"
Oct 22 00:13:58.579: INFO: Pod "downwardapi-volume-f1e3e562-68d5-40be-a5ea-79af36ca60fc": Phase="Pending", Reason="", readiness=false. Elapsed: 4.626209ms
Oct 22 00:14:00.584: INFO: Pod "downwardapi-volume-f1e3e562-68d5-40be-a5ea-79af36ca60fc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009287322s
STEP: Saw pod success
Oct 22 00:14:00.584: INFO: Pod "downwardapi-volume-f1e3e562-68d5-40be-a5ea-79af36ca60fc" satisfied condition "success or failure"
Oct 22 00:14:00.588: INFO: Trying to get logs from node mip-bd-vm40.mip.storage.hpecorp.net pod downwardapi-volume-f1e3e562-68d5-40be-a5ea-79af36ca60fc container client-container: <nil>
STEP: delete the pod
Oct 22 00:14:00.616: INFO: Waiting for pod downwardapi-volume-f1e3e562-68d5-40be-a5ea-79af36ca60fc to disappear
Oct 22 00:14:00.620: INFO: Pod downwardapi-volume-f1e3e562-68d5-40be-a5ea-79af36ca60fc no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 00:14:00.620: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3757" for this suite.
Oct 22 00:14:06.640: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 00:14:06.788: INFO: namespace projected-3757 deletion completed in 6.161700825s

• [SLOW TEST:8.267 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job 
  should delete a job [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 00:14:06.789: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename job
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete a job [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: delete a job
STEP: deleting Job.batch foo in namespace job-5353, will wait for the garbage collector to delete the pods
Oct 22 00:14:08.918: INFO: Deleting Job.batch foo took: 8.997483ms
Oct 22 00:14:09.318: INFO: Terminating Job.batch foo pods took: 400.276125ms
STEP: Ensuring job was deleted
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 00:14:51.023: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-5353" for this suite.
Oct 22 00:14:57.044: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 00:14:57.209: INFO: namespace job-5353 deletion completed in 6.180574277s

• [SLOW TEST:50.419 seconds]
[sig-apps] Job
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should delete a job [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 00:14:57.209: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Oct 22 00:14:57.261: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 00:14:59.406: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-4667" for this suite.
Oct 22 00:15:41.428: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 00:15:41.576: INFO: namespace pods-4667 deletion completed in 42.164865083s

• [SLOW TEST:44.367 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 00:15:41.577: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1421
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Oct 22 00:15:41.631: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-1324'
Oct 22 00:15:41.822: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Oct 22 00:15:41.822: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1427
Oct 22 00:15:43.839: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 delete deployment e2e-test-nginx-deployment --namespace=kubectl-1324'
Oct 22 00:15:44.014: INFO: stderr: ""
Oct 22 00:15:44.014: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 00:15:44.014: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1324" for this suite.
Oct 22 00:15:50.039: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 00:15:50.195: INFO: namespace kubectl-1324 deletion completed in 6.174975591s

• [SLOW TEST:8.618 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run default
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] version v1
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 00:15:50.195: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Oct 22 00:15:50.292: INFO: (0) /api/v1/nodes/mip-bd-vm40.mip.storage.hpecorp.net/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="bluedata/">bluedata/... (200; 24.596737ms)
Oct 22 00:15:50.301: INFO: (1) /api/v1/nodes/mip-bd-vm40.mip.storage.hpecorp.net/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="bluedata/">bluedata/... (200; 8.178102ms)
Oct 22 00:15:50.339: INFO: (2) /api/v1/nodes/mip-bd-vm40.mip.storage.hpecorp.net/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="bluedata/">bluedata/... (200; 37.826769ms)
Oct 22 00:15:50.363: INFO: (3) /api/v1/nodes/mip-bd-vm40.mip.storage.hpecorp.net/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="bluedata/">bluedata/... (200; 24.445785ms)
Oct 22 00:15:50.370: INFO: (4) /api/v1/nodes/mip-bd-vm40.mip.storage.hpecorp.net/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="bluedata/">bluedata/... (200; 7.001795ms)
Oct 22 00:15:50.375: INFO: (5) /api/v1/nodes/mip-bd-vm40.mip.storage.hpecorp.net/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="bluedata/">bluedata/... (200; 5.14397ms)
Oct 22 00:15:50.381: INFO: (6) /api/v1/nodes/mip-bd-vm40.mip.storage.hpecorp.net/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="bluedata/">bluedata/... (200; 5.182728ms)
Oct 22 00:15:50.386: INFO: (7) /api/v1/nodes/mip-bd-vm40.mip.storage.hpecorp.net/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="bluedata/">bluedata/... (200; 5.656414ms)
Oct 22 00:15:50.391: INFO: (8) /api/v1/nodes/mip-bd-vm40.mip.storage.hpecorp.net/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="bluedata/">bluedata/... (200; 4.985076ms)
Oct 22 00:15:50.396: INFO: (9) /api/v1/nodes/mip-bd-vm40.mip.storage.hpecorp.net/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="bluedata/">bluedata/... (200; 4.969357ms)
Oct 22 00:15:50.405: INFO: (10) /api/v1/nodes/mip-bd-vm40.mip.storage.hpecorp.net/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="bluedata/">bluedata/... (200; 8.806938ms)
Oct 22 00:15:50.410: INFO: (11) /api/v1/nodes/mip-bd-vm40.mip.storage.hpecorp.net/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="bluedata/">bluedata/... (200; 5.162058ms)
Oct 22 00:15:50.415: INFO: (12) /api/v1/nodes/mip-bd-vm40.mip.storage.hpecorp.net/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="bluedata/">bluedata/... (200; 5.058911ms)
Oct 22 00:15:50.421: INFO: (13) /api/v1/nodes/mip-bd-vm40.mip.storage.hpecorp.net/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="bluedata/">bluedata/... (200; 5.254662ms)
Oct 22 00:15:50.426: INFO: (14) /api/v1/nodes/mip-bd-vm40.mip.storage.hpecorp.net/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="bluedata/">bluedata/... (200; 4.822387ms)
Oct 22 00:15:50.430: INFO: (15) /api/v1/nodes/mip-bd-vm40.mip.storage.hpecorp.net/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="bluedata/">bluedata/... (200; 4.509905ms)
Oct 22 00:15:50.435: INFO: (16) /api/v1/nodes/mip-bd-vm40.mip.storage.hpecorp.net/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="bluedata/">bluedata/... (200; 4.687644ms)
Oct 22 00:15:50.440: INFO: (17) /api/v1/nodes/mip-bd-vm40.mip.storage.hpecorp.net/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="bluedata/">bluedata/... (200; 4.63323ms)
Oct 22 00:15:50.444: INFO: (18) /api/v1/nodes/mip-bd-vm40.mip.storage.hpecorp.net/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="bluedata/">bluedata/... (200; 4.559316ms)
Oct 22 00:15:50.449: INFO: (19) /api/v1/nodes/mip-bd-vm40.mip.storage.hpecorp.net/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="bluedata/">bluedata/... (200; 4.817267ms)
[AfterEach] version v1
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 00:15:50.449: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-5329" for this suite.
Oct 22 00:15:56.468: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 00:15:56.627: INFO: namespace proxy-5329 deletion completed in 6.173777583s

• [SLOW TEST:6.432 seconds]
[sig-network] Proxy
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:58
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 00:15:56.628: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Oct 22 00:15:56.702: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-6762,SelfLink:/api/v1/namespaces/watch-6762/configmaps/e2e-watch-test-label-changed,UID:346726cc-f01f-40d0-838b-59a3e73a12bd,ResourceVersion:13964,Generation:0,CreationTimestamp:2019-10-22 00:15:56 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Oct 22 00:15:56.702: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-6762,SelfLink:/api/v1/namespaces/watch-6762/configmaps/e2e-watch-test-label-changed,UID:346726cc-f01f-40d0-838b-59a3e73a12bd,ResourceVersion:13965,Generation:0,CreationTimestamp:2019-10-22 00:15:56 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Oct 22 00:15:56.702: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-6762,SelfLink:/api/v1/namespaces/watch-6762/configmaps/e2e-watch-test-label-changed,UID:346726cc-f01f-40d0-838b-59a3e73a12bd,ResourceVersion:13966,Generation:0,CreationTimestamp:2019-10-22 00:15:56 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Oct 22 00:16:06.739: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-6762,SelfLink:/api/v1/namespaces/watch-6762/configmaps/e2e-watch-test-label-changed,UID:346726cc-f01f-40d0-838b-59a3e73a12bd,ResourceVersion:13984,Generation:0,CreationTimestamp:2019-10-22 00:15:56 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Oct 22 00:16:06.739: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-6762,SelfLink:/api/v1/namespaces/watch-6762/configmaps/e2e-watch-test-label-changed,UID:346726cc-f01f-40d0-838b-59a3e73a12bd,ResourceVersion:13985,Generation:0,CreationTimestamp:2019-10-22 00:15:56 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Oct 22 00:16:06.739: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-6762,SelfLink:/api/v1/namespaces/watch-6762/configmaps/e2e-watch-test-label-changed,UID:346726cc-f01f-40d0-838b-59a3e73a12bd,ResourceVersion:13986,Generation:0,CreationTimestamp:2019-10-22 00:15:56 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 00:16:06.739: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-6762" for this suite.
Oct 22 00:16:12.758: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 00:16:12.916: INFO: namespace watch-6762 deletion completed in 6.171584544s

• [SLOW TEST:16.288 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 00:16:12.917: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0777 on tmpfs
Oct 22 00:16:12.968: INFO: Waiting up to 5m0s for pod "pod-5d996414-2e00-427f-a5e9-a4ead58289b2" in namespace "emptydir-7631" to be "success or failure"
Oct 22 00:16:12.972: INFO: Pod "pod-5d996414-2e00-427f-a5e9-a4ead58289b2": Phase="Pending", Reason="", readiness=false. Elapsed: 4.284232ms
Oct 22 00:16:14.978: INFO: Pod "pod-5d996414-2e00-427f-a5e9-a4ead58289b2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010187712s
STEP: Saw pod success
Oct 22 00:16:14.978: INFO: Pod "pod-5d996414-2e00-427f-a5e9-a4ead58289b2" satisfied condition "success or failure"
Oct 22 00:16:14.982: INFO: Trying to get logs from node mip-bd-vm40.mip.storage.hpecorp.net pod pod-5d996414-2e00-427f-a5e9-a4ead58289b2 container test-container: <nil>
STEP: delete the pod
Oct 22 00:16:15.010: INFO: Waiting for pod pod-5d996414-2e00-427f-a5e9-a4ead58289b2 to disappear
Oct 22 00:16:15.013: INFO: Pod pod-5d996414-2e00-427f-a5e9-a4ead58289b2 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 00:16:15.013: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7631" for this suite.
Oct 22 00:16:21.033: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 00:16:21.203: INFO: namespace emptydir-7631 deletion completed in 6.18516331s

• [SLOW TEST:8.286 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 00:16:21.203: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test substitution in container's args
Oct 22 00:16:21.266: INFO: Waiting up to 5m0s for pod "var-expansion-48eeb67e-b646-464c-a1ab-e0047e1fbbf3" in namespace "var-expansion-5306" to be "success or failure"
Oct 22 00:16:21.270: INFO: Pod "var-expansion-48eeb67e-b646-464c-a1ab-e0047e1fbbf3": Phase="Pending", Reason="", readiness=false. Elapsed: 3.974888ms
Oct 22 00:16:23.276: INFO: Pod "var-expansion-48eeb67e-b646-464c-a1ab-e0047e1fbbf3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0093376s
STEP: Saw pod success
Oct 22 00:16:23.276: INFO: Pod "var-expansion-48eeb67e-b646-464c-a1ab-e0047e1fbbf3" satisfied condition "success or failure"
Oct 22 00:16:23.279: INFO: Trying to get logs from node mip-bd-vm41.mip.storage.hpecorp.net pod var-expansion-48eeb67e-b646-464c-a1ab-e0047e1fbbf3 container dapi-container: <nil>
STEP: delete the pod
Oct 22 00:16:23.310: INFO: Waiting for pod var-expansion-48eeb67e-b646-464c-a1ab-e0047e1fbbf3 to disappear
Oct 22 00:16:23.314: INFO: Pod var-expansion-48eeb67e-b646-464c-a1ab-e0047e1fbbf3 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 00:16:23.314: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-5306" for this suite.
Oct 22 00:16:29.340: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 00:16:29.507: INFO: namespace var-expansion-5306 deletion completed in 6.186526538s

• [SLOW TEST:8.304 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 00:16:29.507: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Oct 22 00:16:29.581: INFO: Create a RollingUpdate DaemonSet
Oct 22 00:16:29.586: INFO: Check that daemon pods launch on every node of the cluster
Oct 22 00:16:29.591: INFO: DaemonSet pods can't tolerate node mip-bd-vm39.mip.storage.hpecorp.net with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 22 00:16:29.594: INFO: Number of nodes with available pods: 0
Oct 22 00:16:29.594: INFO: Node mip-bd-vm40.mip.storage.hpecorp.net is running more than one daemon pod
Oct 22 00:16:30.601: INFO: DaemonSet pods can't tolerate node mip-bd-vm39.mip.storage.hpecorp.net with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 22 00:16:30.606: INFO: Number of nodes with available pods: 0
Oct 22 00:16:30.606: INFO: Node mip-bd-vm40.mip.storage.hpecorp.net is running more than one daemon pod
Oct 22 00:16:31.601: INFO: DaemonSet pods can't tolerate node mip-bd-vm39.mip.storage.hpecorp.net with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 22 00:16:31.604: INFO: Number of nodes with available pods: 2
Oct 22 00:16:31.605: INFO: Number of running nodes: 2, number of available pods: 2
Oct 22 00:16:31.605: INFO: Update the DaemonSet to trigger a rollout
Oct 22 00:16:31.615: INFO: Updating DaemonSet daemon-set
Oct 22 00:16:35.637: INFO: Roll back the DaemonSet before rollout is complete
Oct 22 00:16:35.646: INFO: Updating DaemonSet daemon-set
Oct 22 00:16:35.646: INFO: Make sure DaemonSet rollback is complete
Oct 22 00:16:35.651: INFO: Wrong image for pod: daemon-set-dmnrj. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Oct 22 00:16:35.651: INFO: Pod daemon-set-dmnrj is not available
Oct 22 00:16:35.657: INFO: DaemonSet pods can't tolerate node mip-bd-vm39.mip.storage.hpecorp.net with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 22 00:16:36.663: INFO: Wrong image for pod: daemon-set-dmnrj. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Oct 22 00:16:36.663: INFO: Pod daemon-set-dmnrj is not available
Oct 22 00:16:36.668: INFO: DaemonSet pods can't tolerate node mip-bd-vm39.mip.storage.hpecorp.net with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 22 00:16:37.663: INFO: Pod daemon-set-77qpf is not available
Oct 22 00:16:37.669: INFO: DaemonSet pods can't tolerate node mip-bd-vm39.mip.storage.hpecorp.net with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-9760, will wait for the garbage collector to delete the pods
Oct 22 00:16:37.741: INFO: Deleting DaemonSet.extensions daemon-set took: 9.714021ms
Oct 22 00:16:40.041: INFO: Terminating DaemonSet.extensions daemon-set pods took: 2.300275014s
Oct 22 00:16:50.947: INFO: Number of nodes with available pods: 0
Oct 22 00:16:50.947: INFO: Number of running nodes: 0, number of available pods: 0
Oct 22 00:16:50.954: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-9760/daemonsets","resourceVersion":"14183"},"items":null}

Oct 22 00:16:50.958: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-9760/pods","resourceVersion":"14183"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 00:16:50.973: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-9760" for this suite.
Oct 22 00:16:56.994: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 00:16:57.148: INFO: namespace daemonsets-9760 deletion completed in 6.170554091s

• [SLOW TEST:27.641 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 00:16:57.149: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test override command
Oct 22 00:16:57.216: INFO: Waiting up to 5m0s for pod "client-containers-318b3299-e56e-4085-82f5-d792c64d4467" in namespace "containers-2933" to be "success or failure"
Oct 22 00:16:57.221: INFO: Pod "client-containers-318b3299-e56e-4085-82f5-d792c64d4467": Phase="Pending", Reason="", readiness=false. Elapsed: 5.685501ms
Oct 22 00:16:59.227: INFO: Pod "client-containers-318b3299-e56e-4085-82f5-d792c64d4467": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010842476s
Oct 22 00:17:01.232: INFO: Pod "client-containers-318b3299-e56e-4085-82f5-d792c64d4467": Phase="Running", Reason="", readiness=true. Elapsed: 4.016035239s
Oct 22 00:17:03.237: INFO: Pod "client-containers-318b3299-e56e-4085-82f5-d792c64d4467": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.021677814s
STEP: Saw pod success
Oct 22 00:17:03.237: INFO: Pod "client-containers-318b3299-e56e-4085-82f5-d792c64d4467" satisfied condition "success or failure"
Oct 22 00:17:03.242: INFO: Trying to get logs from node mip-bd-vm40.mip.storage.hpecorp.net pod client-containers-318b3299-e56e-4085-82f5-d792c64d4467 container test-container: <nil>
STEP: delete the pod
Oct 22 00:17:03.269: INFO: Waiting for pod client-containers-318b3299-e56e-4085-82f5-d792c64d4467 to disappear
Oct 22 00:17:03.273: INFO: Pod client-containers-318b3299-e56e-4085-82f5-d792c64d4467 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 00:17:03.273: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-2933" for this suite.
Oct 22 00:17:09.294: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 00:17:09.465: INFO: namespace containers-2933 deletion completed in 6.187330391s

• [SLOW TEST:12.316 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 00:17:09.465: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 00:17:11.555: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-6477" for this suite.
Oct 22 00:18:05.577: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 00:18:05.716: INFO: namespace kubelet-test-6477 deletion completed in 54.155988616s

• [SLOW TEST:56.251 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when scheduling a read only busybox container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:187
    should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 00:18:05.717: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
Oct 22 00:18:05.768: INFO: PodSpec: initContainers in spec.initContainers
Oct 22 00:18:49.180: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-6d282a90-dd52-4f79-8a5a-78c3d04b9fa6", GenerateName:"", Namespace:"init-container-5984", SelfLink:"/api/v1/namespaces/init-container-5984/pods/pod-init-6d282a90-dd52-4f79-8a5a-78c3d04b9fa6", UID:"8b12014e-fda0-4bb1-9eeb-1ed4f5fb2602", ResourceVersion:"14466", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63707300285, loc:(*time.Location)(0x7ec7a20)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"768402010"}, Annotations:map[string]string{"cni.projectcalico.org/podIP":"10.244.1.47/32"}, OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-vt52d", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc0024b46c0), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-vt52d", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-vt52d", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-vt52d", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc0024c3ac8), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"mip-bd-vm41.mip.storage.hpecorp.net", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc00368aba0), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0024c3b40)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0024c3b60)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc0024c3b68), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc0024c3b6c), PreemptionPolicy:(*v1.PreemptionPolicy)(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707300285, loc:(*time.Location)(0x7ec7a20)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707300285, loc:(*time.Location)(0x7ec7a20)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707300285, loc:(*time.Location)(0x7ec7a20)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707300285, loc:(*time.Location)(0x7ec7a20)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"16.143.20.138", PodIP:"10.244.1.47", StartTime:(*v1.Time)(0xc002f57200), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(0xc002f57240), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc002cccb60)}, Ready:false, RestartCount:3, Image:"docker.io/busybox:1.29", ImageID:"docker-pullable://docker.io/busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"docker://3226d9fa7d9df2563108cf2fa5d57917aaa696e064b3a81aff0d2fbdc0e70e5d"}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc002f57260), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:""}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc002f57220), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:""}}, QOSClass:"Guaranteed"}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 00:18:49.181: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-5984" for this suite.
Oct 22 00:19:11.216: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 00:19:11.373: INFO: namespace init-container-5984 deletion completed in 22.183431059s

• [SLOW TEST:65.656 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 00:19:11.374: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-configmap-nm4k
STEP: Creating a pod to test atomic-volume-subpath
Oct 22 00:19:11.450: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-nm4k" in namespace "subpath-4925" to be "success or failure"
Oct 22 00:19:11.454: INFO: Pod "pod-subpath-test-configmap-nm4k": Phase="Pending", Reason="", readiness=false. Elapsed: 3.484822ms
Oct 22 00:19:13.459: INFO: Pod "pod-subpath-test-configmap-nm4k": Phase="Running", Reason="", readiness=true. Elapsed: 2.009174787s
Oct 22 00:19:15.466: INFO: Pod "pod-subpath-test-configmap-nm4k": Phase="Running", Reason="", readiness=true. Elapsed: 4.015673546s
Oct 22 00:19:17.472: INFO: Pod "pod-subpath-test-configmap-nm4k": Phase="Running", Reason="", readiness=true. Elapsed: 6.02183745s
Oct 22 00:19:19.477: INFO: Pod "pod-subpath-test-configmap-nm4k": Phase="Running", Reason="", readiness=true. Elapsed: 8.026966634s
Oct 22 00:19:21.482: INFO: Pod "pod-subpath-test-configmap-nm4k": Phase="Running", Reason="", readiness=true. Elapsed: 10.032035975s
Oct 22 00:19:23.487: INFO: Pod "pod-subpath-test-configmap-nm4k": Phase="Running", Reason="", readiness=true. Elapsed: 12.036977719s
Oct 22 00:19:25.493: INFO: Pod "pod-subpath-test-configmap-nm4k": Phase="Running", Reason="", readiness=true. Elapsed: 14.042660105s
Oct 22 00:19:27.498: INFO: Pod "pod-subpath-test-configmap-nm4k": Phase="Running", Reason="", readiness=true. Elapsed: 16.048082152s
Oct 22 00:19:29.504: INFO: Pod "pod-subpath-test-configmap-nm4k": Phase="Running", Reason="", readiness=true. Elapsed: 18.054203447s
Oct 22 00:19:31.511: INFO: Pod "pod-subpath-test-configmap-nm4k": Phase="Running", Reason="", readiness=true. Elapsed: 20.06061672s
Oct 22 00:19:33.517: INFO: Pod "pod-subpath-test-configmap-nm4k": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.066882653s
STEP: Saw pod success
Oct 22 00:19:33.517: INFO: Pod "pod-subpath-test-configmap-nm4k" satisfied condition "success or failure"
Oct 22 00:19:33.521: INFO: Trying to get logs from node mip-bd-vm41.mip.storage.hpecorp.net pod pod-subpath-test-configmap-nm4k container test-container-subpath-configmap-nm4k: <nil>
STEP: delete the pod
Oct 22 00:19:33.556: INFO: Waiting for pod pod-subpath-test-configmap-nm4k to disappear
Oct 22 00:19:33.560: INFO: Pod pod-subpath-test-configmap-nm4k no longer exists
STEP: Deleting pod pod-subpath-test-configmap-nm4k
Oct 22 00:19:33.560: INFO: Deleting pod "pod-subpath-test-configmap-nm4k" in namespace "subpath-4925"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 00:19:33.565: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-4925" for this suite.
Oct 22 00:19:39.589: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 00:19:39.727: INFO: namespace subpath-4925 deletion completed in 6.157200803s

• [SLOW TEST:28.353 seconds]
[sig-storage] Subpath
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 00:19:39.728: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-2ec856df-b3a0-49b8-8130-25c47fd497fa
STEP: Creating a pod to test consume secrets
Oct 22 00:19:39.795: INFO: Waiting up to 5m0s for pod "pod-secrets-ff31c50f-6ade-455c-80be-a94681df395a" in namespace "secrets-8386" to be "success or failure"
Oct 22 00:19:39.801: INFO: Pod "pod-secrets-ff31c50f-6ade-455c-80be-a94681df395a": Phase="Pending", Reason="", readiness=false. Elapsed: 6.268314ms
Oct 22 00:19:41.807: INFO: Pod "pod-secrets-ff31c50f-6ade-455c-80be-a94681df395a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011619112s
STEP: Saw pod success
Oct 22 00:19:41.807: INFO: Pod "pod-secrets-ff31c50f-6ade-455c-80be-a94681df395a" satisfied condition "success or failure"
Oct 22 00:19:41.810: INFO: Trying to get logs from node mip-bd-vm40.mip.storage.hpecorp.net pod pod-secrets-ff31c50f-6ade-455c-80be-a94681df395a container secret-volume-test: <nil>
STEP: delete the pod
Oct 22 00:19:41.843: INFO: Waiting for pod pod-secrets-ff31c50f-6ade-455c-80be-a94681df395a to disappear
Oct 22 00:19:41.847: INFO: Pod pod-secrets-ff31c50f-6ade-455c-80be-a94681df395a no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 00:19:41.847: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8386" for this suite.
Oct 22 00:19:47.866: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 00:19:48.130: INFO: namespace secrets-8386 deletion completed in 6.278943654s

• [SLOW TEST:8.403 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 00:19:48.131: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap configmap-4879/configmap-test-36a543ae-a21e-45f5-8d3b-50318a6d5645
STEP: Creating a pod to test consume configMaps
Oct 22 00:19:48.189: INFO: Waiting up to 5m0s for pod "pod-configmaps-571be280-5771-412c-b6a5-18b8f0cb6f7b" in namespace "configmap-4879" to be "success or failure"
Oct 22 00:19:48.192: INFO: Pod "pod-configmaps-571be280-5771-412c-b6a5-18b8f0cb6f7b": Phase="Pending", Reason="", readiness=false. Elapsed: 3.234568ms
Oct 22 00:19:50.197: INFO: Pod "pod-configmaps-571be280-5771-412c-b6a5-18b8f0cb6f7b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008307794s
STEP: Saw pod success
Oct 22 00:19:50.197: INFO: Pod "pod-configmaps-571be280-5771-412c-b6a5-18b8f0cb6f7b" satisfied condition "success or failure"
Oct 22 00:19:50.201: INFO: Trying to get logs from node mip-bd-vm41.mip.storage.hpecorp.net pod pod-configmaps-571be280-5771-412c-b6a5-18b8f0cb6f7b container env-test: <nil>
STEP: delete the pod
Oct 22 00:19:50.231: INFO: Waiting for pod pod-configmaps-571be280-5771-412c-b6a5-18b8f0cb6f7b to disappear
Oct 22 00:19:50.234: INFO: Pod pod-configmaps-571be280-5771-412c-b6a5-18b8f0cb6f7b no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 00:19:50.234: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4879" for this suite.
Oct 22 00:19:56.253: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 00:19:56.408: INFO: namespace configmap-4879 deletion completed in 6.169429037s

• [SLOW TEST:8.277 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 00:19:56.408: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Oct 22 00:19:59.500: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 00:20:00.520: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-207" for this suite.
Oct 22 00:20:22.545: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 00:20:22.696: INFO: namespace replicaset-207 deletion completed in 22.170380562s

• [SLOW TEST:26.288 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 00:20:22.696: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
Oct 22 00:21:02.781: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
W1022 00:21:02.781605      18 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Oct 22 00:21:02.781: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-3618" for this suite.
Oct 22 00:21:08.811: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 00:21:09.027: INFO: namespace gc-3618 deletion completed in 6.241250213s

• [SLOW TEST:46.331 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 00:21:09.028: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Oct 22 00:21:09.133: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"66e731f2-578a-4df6-b24a-fbdcac6a47a2", Controller:(*bool)(0xc00334361a), BlockOwnerDeletion:(*bool)(0xc00334361b)}}
Oct 22 00:21:09.139: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"aa830085-abd1-41a0-be9f-0b0bdaf188ee", Controller:(*bool)(0xc001efa3d6), BlockOwnerDeletion:(*bool)(0xc001efa3d7)}}
Oct 22 00:21:09.147: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"e9d1627b-f244-4eca-a943-894291ae87ff", Controller:(*bool)(0xc0033438c6), BlockOwnerDeletion:(*bool)(0xc0033438c7)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 00:21:14.165: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-9794" for this suite.
Oct 22 00:21:20.185: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 00:21:20.337: INFO: namespace gc-9794 deletion completed in 6.166608262s

• [SLOW TEST:11.309 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 00:21:20.337: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Oct 22 00:21:20.389: INFO: Waiting up to 5m0s for pod "downward-api-1e203f9d-6cdb-4e8a-bdc1-276499bdfc2d" in namespace "downward-api-1473" to be "success or failure"
Oct 22 00:21:20.393: INFO: Pod "downward-api-1e203f9d-6cdb-4e8a-bdc1-276499bdfc2d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.489855ms
Oct 22 00:21:22.398: INFO: Pod "downward-api-1e203f9d-6cdb-4e8a-bdc1-276499bdfc2d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009617713s
STEP: Saw pod success
Oct 22 00:21:22.399: INFO: Pod "downward-api-1e203f9d-6cdb-4e8a-bdc1-276499bdfc2d" satisfied condition "success or failure"
Oct 22 00:21:22.403: INFO: Trying to get logs from node mip-bd-vm41.mip.storage.hpecorp.net pod downward-api-1e203f9d-6cdb-4e8a-bdc1-276499bdfc2d container dapi-container: <nil>
STEP: delete the pod
Oct 22 00:21:22.431: INFO: Waiting for pod downward-api-1e203f9d-6cdb-4e8a-bdc1-276499bdfc2d to disappear
Oct 22 00:21:22.439: INFO: Pod downward-api-1e203f9d-6cdb-4e8a-bdc1-276499bdfc2d no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 00:21:22.439: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1473" for this suite.
Oct 22 00:21:28.458: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 00:21:28.624: INFO: namespace downward-api-1473 deletion completed in 6.180118102s

• [SLOW TEST:8.287 seconds]
[sig-node] Downward API
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 00:21:28.624: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 00:21:30.707: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-4703" for this suite.
Oct 22 00:22:12.733: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 00:22:12.880: INFO: namespace kubelet-test-4703 deletion completed in 42.167328923s

• [SLOW TEST:44.256 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when scheduling a busybox Pod with hostAliases
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:136
    should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 00:22:12.881: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating service multi-endpoint-test in namespace services-8052
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-8052 to expose endpoints map[]
Oct 22 00:22:12.952: INFO: successfully validated that service multi-endpoint-test in namespace services-8052 exposes endpoints map[] (9.306419ms elapsed)
STEP: Creating pod pod1 in namespace services-8052
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-8052 to expose endpoints map[pod1:[100]]
Oct 22 00:22:14.998: INFO: successfully validated that service multi-endpoint-test in namespace services-8052 exposes endpoints map[pod1:[100]] (2.036592746s elapsed)
STEP: Creating pod pod2 in namespace services-8052
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-8052 to expose endpoints map[pod1:[100] pod2:[101]]
Oct 22 00:22:17.060: INFO: successfully validated that service multi-endpoint-test in namespace services-8052 exposes endpoints map[pod1:[100] pod2:[101]] (2.05215144s elapsed)
STEP: Deleting pod pod1 in namespace services-8052
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-8052 to expose endpoints map[pod2:[101]]
Oct 22 00:22:18.095: INFO: successfully validated that service multi-endpoint-test in namespace services-8052 exposes endpoints map[pod2:[101]] (1.022930787s elapsed)
STEP: Deleting pod pod2 in namespace services-8052
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-8052 to expose endpoints map[]
Oct 22 00:22:19.108: INFO: successfully validated that service multi-endpoint-test in namespace services-8052 exposes endpoints map[] (1.007102828s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 00:22:19.132: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-8052" for this suite.
Oct 22 00:22:41.175: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 00:22:41.324: INFO: namespace services-8052 deletion completed in 22.163907099s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:92

• [SLOW TEST:28.444 seconds]
[sig-network] Services
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 00:22:41.325: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-map-c1ce0cc9-9173-4d96-ab60-8311355988d3
STEP: Creating a pod to test consume configMaps
Oct 22 00:22:41.387: INFO: Waiting up to 5m0s for pod "pod-configmaps-bf4232c5-bbc6-45de-b570-7093f89922e8" in namespace "configmap-159" to be "success or failure"
Oct 22 00:22:41.391: INFO: Pod "pod-configmaps-bf4232c5-bbc6-45de-b570-7093f89922e8": Phase="Pending", Reason="", readiness=false. Elapsed: 3.959963ms
Oct 22 00:22:43.399: INFO: Pod "pod-configmaps-bf4232c5-bbc6-45de-b570-7093f89922e8": Phase="Running", Reason="", readiness=true. Elapsed: 2.011334643s
Oct 22 00:22:45.405: INFO: Pod "pod-configmaps-bf4232c5-bbc6-45de-b570-7093f89922e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017458906s
STEP: Saw pod success
Oct 22 00:22:45.405: INFO: Pod "pod-configmaps-bf4232c5-bbc6-45de-b570-7093f89922e8" satisfied condition "success or failure"
Oct 22 00:22:45.408: INFO: Trying to get logs from node mip-bd-vm41.mip.storage.hpecorp.net pod pod-configmaps-bf4232c5-bbc6-45de-b570-7093f89922e8 container configmap-volume-test: <nil>
STEP: delete the pod
Oct 22 00:22:45.439: INFO: Waiting for pod pod-configmaps-bf4232c5-bbc6-45de-b570-7093f89922e8 to disappear
Oct 22 00:22:45.444: INFO: Pod pod-configmaps-bf4232c5-bbc6-45de-b570-7093f89922e8 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 00:22:45.444: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-159" for this suite.
Oct 22 00:22:51.466: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 00:22:51.614: INFO: namespace configmap-159 deletion completed in 6.165162465s

• [SLOW TEST:10.289 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 00:22:51.615: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod busybox-8dddb49d-4343-4000-80e6-14d1d7d3a9f4 in namespace container-probe-7930
Oct 22 00:22:53.681: INFO: Started pod busybox-8dddb49d-4343-4000-80e6-14d1d7d3a9f4 in namespace container-probe-7930
STEP: checking the pod's current state and verifying that restartCount is present
Oct 22 00:22:53.685: INFO: Initial restart count of pod busybox-8dddb49d-4343-4000-80e6-14d1d7d3a9f4 is 0
Oct 22 00:23:41.838: INFO: Restart count of pod container-probe-7930/busybox-8dddb49d-4343-4000-80e6-14d1d7d3a9f4 is now 1 (48.152916263s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 00:23:41.852: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-7930" for this suite.
Oct 22 00:23:47.882: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 00:23:48.042: INFO: namespace container-probe-7930 deletion completed in 6.176417022s

• [SLOW TEST:56.427 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 00:23:48.042: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-d7de325b-0f40-4641-bb46-92a3c93a19cf
STEP: Creating a pod to test consume secrets
Oct 22 00:23:48.117: INFO: Waiting up to 5m0s for pod "pod-secrets-01fca938-8267-4664-ab6b-10521049b85d" in namespace "secrets-7891" to be "success or failure"
Oct 22 00:23:48.121: INFO: Pod "pod-secrets-01fca938-8267-4664-ab6b-10521049b85d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.780828ms
Oct 22 00:23:50.127: INFO: Pod "pod-secrets-01fca938-8267-4664-ab6b-10521049b85d": Phase="Running", Reason="", readiness=true. Elapsed: 2.010582315s
Oct 22 00:23:52.133: INFO: Pod "pod-secrets-01fca938-8267-4664-ab6b-10521049b85d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016674744s
STEP: Saw pod success
Oct 22 00:23:52.133: INFO: Pod "pod-secrets-01fca938-8267-4664-ab6b-10521049b85d" satisfied condition "success or failure"
Oct 22 00:23:52.138: INFO: Trying to get logs from node mip-bd-vm41.mip.storage.hpecorp.net pod pod-secrets-01fca938-8267-4664-ab6b-10521049b85d container secret-volume-test: <nil>
STEP: delete the pod
Oct 22 00:23:52.175: INFO: Waiting for pod pod-secrets-01fca938-8267-4664-ab6b-10521049b85d to disappear
Oct 22 00:23:52.179: INFO: Pod pod-secrets-01fca938-8267-4664-ab6b-10521049b85d no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 00:23:52.179: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7891" for this suite.
Oct 22 00:23:58.203: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 00:23:58.348: INFO: namespace secrets-7891 deletion completed in 6.161888358s

• [SLOW TEST:10.306 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 00:23:58.348: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1293
STEP: creating an rc
Oct 22 00:24:02.256: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 create -f - --namespace=kubectl-1347'
Oct 22 00:24:02.685: INFO: stderr: ""
Oct 22 00:24:02.685: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Waiting for Redis master to start.
Oct 22 00:24:03.691: INFO: Selector matched 1 pods for map[app:redis]
Oct 22 00:24:03.691: INFO: Found 0 / 1
Oct 22 00:24:04.690: INFO: Selector matched 1 pods for map[app:redis]
Oct 22 00:24:04.691: INFO: Found 0 / 1
Oct 22 00:24:05.690: INFO: Selector matched 1 pods for map[app:redis]
Oct 22 00:24:05.690: INFO: Found 0 / 1
Oct 22 00:24:06.691: INFO: Selector matched 1 pods for map[app:redis]
Oct 22 00:24:06.691: INFO: Found 1 / 1
Oct 22 00:24:06.691: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Oct 22 00:24:06.695: INFO: Selector matched 1 pods for map[app:redis]
Oct 22 00:24:06.695: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
STEP: checking for a matching strings
Oct 22 00:24:06.695: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 logs redis-master-cwl6f redis-master --namespace=kubectl-1347'
Oct 22 00:24:06.877: INFO: stderr: ""
Oct 22 00:24:06.877: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 22 Oct 00:24:06.416 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 22 Oct 00:24:06.416 # Server started, Redis version 3.2.12\n1:M 22 Oct 00:24:06.416 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log lines
Oct 22 00:24:06.877: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 log redis-master-cwl6f redis-master --namespace=kubectl-1347 --tail=1'
Oct 22 00:24:07.056: INFO: stderr: ""
Oct 22 00:24:07.056: INFO: stdout: "1:M 22 Oct 00:24:06.416 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log bytes
Oct 22 00:24:07.057: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 log redis-master-cwl6f redis-master --namespace=kubectl-1347 --limit-bytes=1'
Oct 22 00:24:07.232: INFO: stderr: ""
Oct 22 00:24:07.232: INFO: stdout: " "
STEP: exposing timestamps
Oct 22 00:24:07.232: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 log redis-master-cwl6f redis-master --namespace=kubectl-1347 --tail=1 --timestamps'
Oct 22 00:24:07.412: INFO: stderr: ""
Oct 22 00:24:07.412: INFO: stdout: "2019-10-22T00:24:06.416751091Z 1:M 22 Oct 00:24:06.416 * The server is now ready to accept connections on port 6379\n"
STEP: restricting to a time range
Oct 22 00:24:09.912: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 log redis-master-cwl6f redis-master --namespace=kubectl-1347 --since=1s'
Oct 22 00:24:10.114: INFO: stderr: ""
Oct 22 00:24:10.114: INFO: stdout: ""
Oct 22 00:24:10.114: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 log redis-master-cwl6f redis-master --namespace=kubectl-1347 --since=24h'
Oct 22 00:24:10.311: INFO: stderr: ""
Oct 22 00:24:10.312: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 22 Oct 00:24:06.416 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 22 Oct 00:24:06.416 # Server started, Redis version 3.2.12\n1:M 22 Oct 00:24:06.416 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1299
STEP: using delete to clean up resources
Oct 22 00:24:10.312: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 delete --grace-period=0 --force -f - --namespace=kubectl-1347'
Oct 22 00:24:10.485: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct 22 00:24:10.485: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
Oct 22 00:24:10.485: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 get rc,svc -l name=nginx --no-headers --namespace=kubectl-1347'
Oct 22 00:24:10.661: INFO: stderr: "No resources found.\n"
Oct 22 00:24:10.661: INFO: stdout: ""
Oct 22 00:24:10.661: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 get pods -l name=nginx --namespace=kubectl-1347 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Oct 22 00:24:10.820: INFO: stderr: ""
Oct 22 00:24:10.820: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 00:24:10.820: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1347" for this suite.
Oct 22 00:24:32.848: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 00:24:33.005: INFO: namespace kubectl-1347 deletion completed in 22.177927222s

• [SLOW TEST:34.656 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl logs
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Delete Grace Period 
  should be submitted and removed [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 00:24:33.005: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Delete Grace Period
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:47
[It] should be submitted and removed [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: setting up selector
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
Oct 22 00:24:35.092: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-172996996 proxy -p 0'
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
Oct 22 00:24:50.257: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 00:24:50.261: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-8628" for this suite.
Oct 22 00:24:56.283: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 00:24:56.427: INFO: namespace pods-8628 deletion completed in 6.161213567s

• [SLOW TEST:23.423 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  [k8s.io] Delete Grace Period
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should be submitted and removed [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 00:24:56.428: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-63483575-7bf5-4a5f-9478-1381805a8867
STEP: Creating a pod to test consume configMaps
Oct 22 00:24:56.490: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-c5d83bf5-20aa-4d52-b586-4a3b2c1c9607" in namespace "projected-1838" to be "success or failure"
Oct 22 00:24:56.496: INFO: Pod "pod-projected-configmaps-c5d83bf5-20aa-4d52-b586-4a3b2c1c9607": Phase="Pending", Reason="", readiness=false. Elapsed: 6.16664ms
Oct 22 00:24:58.502: INFO: Pod "pod-projected-configmaps-c5d83bf5-20aa-4d52-b586-4a3b2c1c9607": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012339732s
STEP: Saw pod success
Oct 22 00:24:58.502: INFO: Pod "pod-projected-configmaps-c5d83bf5-20aa-4d52-b586-4a3b2c1c9607" satisfied condition "success or failure"
Oct 22 00:24:58.506: INFO: Trying to get logs from node mip-bd-vm40.mip.storage.hpecorp.net pod pod-projected-configmaps-c5d83bf5-20aa-4d52-b586-4a3b2c1c9607 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Oct 22 00:24:58.535: INFO: Waiting for pod pod-projected-configmaps-c5d83bf5-20aa-4d52-b586-4a3b2c1c9607 to disappear
Oct 22 00:24:58.540: INFO: Pod pod-projected-configmaps-c5d83bf5-20aa-4d52-b586-4a3b2c1c9607 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 00:24:58.540: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1838" for this suite.
Oct 22 00:25:04.560: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 00:25:04.720: INFO: namespace projected-1838 deletion completed in 6.17509351s

• [SLOW TEST:8.292 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 00:25:04.721: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-downwardapi-drn5
STEP: Creating a pod to test atomic-volume-subpath
Oct 22 00:25:04.786: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-drn5" in namespace "subpath-2435" to be "success or failure"
Oct 22 00:25:04.791: INFO: Pod "pod-subpath-test-downwardapi-drn5": Phase="Pending", Reason="", readiness=false. Elapsed: 5.299287ms
Oct 22 00:25:06.796: INFO: Pod "pod-subpath-test-downwardapi-drn5": Phase="Running", Reason="", readiness=true. Elapsed: 2.010269293s
Oct 22 00:25:08.802: INFO: Pod "pod-subpath-test-downwardapi-drn5": Phase="Running", Reason="", readiness=true. Elapsed: 4.015674291s
Oct 22 00:25:10.807: INFO: Pod "pod-subpath-test-downwardapi-drn5": Phase="Running", Reason="", readiness=true. Elapsed: 6.021397321s
Oct 22 00:25:12.813: INFO: Pod "pod-subpath-test-downwardapi-drn5": Phase="Running", Reason="", readiness=true. Elapsed: 8.026725989s
Oct 22 00:25:14.818: INFO: Pod "pod-subpath-test-downwardapi-drn5": Phase="Running", Reason="", readiness=true. Elapsed: 10.031706447s
Oct 22 00:25:16.823: INFO: Pod "pod-subpath-test-downwardapi-drn5": Phase="Running", Reason="", readiness=true. Elapsed: 12.037180832s
Oct 22 00:25:18.828: INFO: Pod "pod-subpath-test-downwardapi-drn5": Phase="Running", Reason="", readiness=true. Elapsed: 14.041923461s
Oct 22 00:25:20.834: INFO: Pod "pod-subpath-test-downwardapi-drn5": Phase="Running", Reason="", readiness=true. Elapsed: 16.048374531s
Oct 22 00:25:22.840: INFO: Pod "pod-subpath-test-downwardapi-drn5": Phase="Running", Reason="", readiness=true. Elapsed: 18.053584966s
Oct 22 00:25:24.844: INFO: Pod "pod-subpath-test-downwardapi-drn5": Phase="Running", Reason="", readiness=true. Elapsed: 20.057775949s
Oct 22 00:25:26.849: INFO: Pod "pod-subpath-test-downwardapi-drn5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.06250313s
STEP: Saw pod success
Oct 22 00:25:26.849: INFO: Pod "pod-subpath-test-downwardapi-drn5" satisfied condition "success or failure"
Oct 22 00:25:26.852: INFO: Trying to get logs from node mip-bd-vm41.mip.storage.hpecorp.net pod pod-subpath-test-downwardapi-drn5 container test-container-subpath-downwardapi-drn5: <nil>
STEP: delete the pod
Oct 22 00:25:26.883: INFO: Waiting for pod pod-subpath-test-downwardapi-drn5 to disappear
Oct 22 00:25:26.886: INFO: Pod pod-subpath-test-downwardapi-drn5 no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-drn5
Oct 22 00:25:26.886: INFO: Deleting pod "pod-subpath-test-downwardapi-drn5" in namespace "subpath-2435"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 00:25:26.890: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-2435" for this suite.
Oct 22 00:25:32.907: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 00:25:33.067: INFO: namespace subpath-2435 deletion completed in 6.172856669s

• [SLOW TEST:28.347 seconds]
[sig-storage] Subpath
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with downward pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 00:25:33.068: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Oct 22 00:25:33.127: INFO: Waiting up to 5m0s for pod "downwardapi-volume-15ddab8c-157f-410d-9677-a82bbf6df7c1" in namespace "downward-api-3634" to be "success or failure"
Oct 22 00:25:33.131: INFO: Pod "downwardapi-volume-15ddab8c-157f-410d-9677-a82bbf6df7c1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.16411ms
Oct 22 00:25:35.137: INFO: Pod "downwardapi-volume-15ddab8c-157f-410d-9677-a82bbf6df7c1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009621134s
STEP: Saw pod success
Oct 22 00:25:35.137: INFO: Pod "downwardapi-volume-15ddab8c-157f-410d-9677-a82bbf6df7c1" satisfied condition "success or failure"
Oct 22 00:25:35.140: INFO: Trying to get logs from node mip-bd-vm40.mip.storage.hpecorp.net pod downwardapi-volume-15ddab8c-157f-410d-9677-a82bbf6df7c1 container client-container: <nil>
STEP: delete the pod
Oct 22 00:25:35.171: INFO: Waiting for pod downwardapi-volume-15ddab8c-157f-410d-9677-a82bbf6df7c1 to disappear
Oct 22 00:25:35.174: INFO: Pod downwardapi-volume-15ddab8c-157f-410d-9677-a82bbf6df7c1 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 00:25:35.175: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3634" for this suite.
Oct 22 00:25:41.196: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 00:25:41.344: INFO: namespace downward-api-3634 deletion completed in 6.16426122s

• [SLOW TEST:8.276 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 00:25:41.344: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir volume type on tmpfs
Oct 22 00:25:41.400: INFO: Waiting up to 5m0s for pod "pod-7e0cf0e5-b974-429f-bff9-bbde7ac7c543" in namespace "emptydir-1964" to be "success or failure"
Oct 22 00:25:41.406: INFO: Pod "pod-7e0cf0e5-b974-429f-bff9-bbde7ac7c543": Phase="Pending", Reason="", readiness=false. Elapsed: 5.418064ms
Oct 22 00:25:43.411: INFO: Pod "pod-7e0cf0e5-b974-429f-bff9-bbde7ac7c543": Phase="Running", Reason="", readiness=true. Elapsed: 2.010924723s
Oct 22 00:25:45.417: INFO: Pod "pod-7e0cf0e5-b974-429f-bff9-bbde7ac7c543": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016501506s
STEP: Saw pod success
Oct 22 00:25:45.417: INFO: Pod "pod-7e0cf0e5-b974-429f-bff9-bbde7ac7c543" satisfied condition "success or failure"
Oct 22 00:25:45.420: INFO: Trying to get logs from node mip-bd-vm41.mip.storage.hpecorp.net pod pod-7e0cf0e5-b974-429f-bff9-bbde7ac7c543 container test-container: <nil>
STEP: delete the pod
Oct 22 00:25:45.446: INFO: Waiting for pod pod-7e0cf0e5-b974-429f-bff9-bbde7ac7c543 to disappear
Oct 22 00:25:45.450: INFO: Pod pod-7e0cf0e5-b974-429f-bff9-bbde7ac7c543 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 00:25:45.450: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1964" for this suite.
Oct 22 00:25:51.473: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 00:25:51.626: INFO: namespace emptydir-1964 deletion completed in 6.170715723s

• [SLOW TEST:10.282 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 00:25:51.626: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Oct 22 00:25:54.716: INFO: Expected: &{OK} to match Container's Termination Message: OK --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 00:25:54.740: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-2066" for this suite.
Oct 22 00:26:00.767: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 00:26:00.942: INFO: namespace container-runtime-2066 deletion completed in 6.195291685s

• [SLOW TEST:9.316 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  blackbox test
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
    on terminated container
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:129
      should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 00:26:00.942: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-map-20616724-eaf9-4465-bfb4-2a76035906a7
STEP: Creating a pod to test consume configMaps
Oct 22 00:26:01.003: INFO: Waiting up to 5m0s for pod "pod-configmaps-b2974b92-3b2e-40ec-8821-c4a52935aa94" in namespace "configmap-1756" to be "success or failure"
Oct 22 00:26:01.008: INFO: Pod "pod-configmaps-b2974b92-3b2e-40ec-8821-c4a52935aa94": Phase="Pending", Reason="", readiness=false. Elapsed: 5.177863ms
Oct 22 00:26:03.014: INFO: Pod "pod-configmaps-b2974b92-3b2e-40ec-8821-c4a52935aa94": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010641711s
STEP: Saw pod success
Oct 22 00:26:03.014: INFO: Pod "pod-configmaps-b2974b92-3b2e-40ec-8821-c4a52935aa94" satisfied condition "success or failure"
Oct 22 00:26:03.017: INFO: Trying to get logs from node mip-bd-vm41.mip.storage.hpecorp.net pod pod-configmaps-b2974b92-3b2e-40ec-8821-c4a52935aa94 container configmap-volume-test: <nil>
STEP: delete the pod
Oct 22 00:26:03.045: INFO: Waiting for pod pod-configmaps-b2974b92-3b2e-40ec-8821-c4a52935aa94 to disappear
Oct 22 00:26:03.050: INFO: Pod pod-configmaps-b2974b92-3b2e-40ec-8821-c4a52935aa94 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 00:26:03.050: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1756" for this suite.
Oct 22 00:26:09.070: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 00:26:09.222: INFO: namespace configmap-1756 deletion completed in 6.167674808s

• [SLOW TEST:8.280 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 00:26:09.222: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Oct 22 00:26:09.283: INFO: Pod name pod-release: Found 0 pods out of 1
Oct 22 00:26:14.289: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 00:26:15.310: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-7413" for this suite.
Oct 22 00:26:21.334: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 00:26:21.477: INFO: namespace replication-controller-7413 deletion completed in 6.16176067s

• [SLOW TEST:12.255 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 00:26:21.477: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
Oct 22 00:26:31.559: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 00:26:31.559: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
W1022 00:26:31.559488      18 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
STEP: Destroying namespace "gc-2575" for this suite.
Oct 22 00:26:37.581: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 00:26:37.735: INFO: namespace gc-2575 deletion completed in 6.170837754s

• [SLOW TEST:16.258 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 00:26:37.735: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod liveness-7b8070d3-65d2-41ca-afdd-da33c17acb28 in namespace container-probe-1115
Oct 22 00:26:43.800: INFO: Started pod liveness-7b8070d3-65d2-41ca-afdd-da33c17acb28 in namespace container-probe-1115
STEP: checking the pod's current state and verifying that restartCount is present
Oct 22 00:26:43.804: INFO: Initial restart count of pod liveness-7b8070d3-65d2-41ca-afdd-da33c17acb28 is 0
Oct 22 00:27:05.870: INFO: Restart count of pod container-probe-1115/liveness-7b8070d3-65d2-41ca-afdd-da33c17acb28 is now 1 (22.065906687s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 00:27:05.893: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-1115" for this suite.
Oct 22 00:27:11.914: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 00:27:12.061: INFO: namespace container-probe-1115 deletion completed in 6.162486638s

• [SLOW TEST:34.326 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 00:27:12.062: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1686
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Oct 22 00:27:12.110: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-2027'
Oct 22 00:27:12.289: INFO: stderr: ""
Oct 22 00:27:12.289: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1691
Oct 22 00:27:12.293: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 delete pods e2e-test-nginx-pod --namespace=kubectl-2027'
Oct 22 00:27:13.934: INFO: stderr: ""
Oct 22 00:27:13.934: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 00:27:13.934: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2027" for this suite.
Oct 22 00:27:19.956: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 00:27:20.114: INFO: namespace kubectl-2027 deletion completed in 6.174778532s

• [SLOW TEST:8.053 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run pod
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 00:27:20.115: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-map-990371ad-66d2-4018-99de-23ba64d8bef5
STEP: Creating a pod to test consume secrets
Oct 22 00:27:20.182: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-a3b67e28-dafe-4490-9f5f-fd36a5217275" in namespace "projected-3703" to be "success or failure"
Oct 22 00:27:20.186: INFO: Pod "pod-projected-secrets-a3b67e28-dafe-4490-9f5f-fd36a5217275": Phase="Pending", Reason="", readiness=false. Elapsed: 3.701924ms
Oct 22 00:27:22.191: INFO: Pod "pod-projected-secrets-a3b67e28-dafe-4490-9f5f-fd36a5217275": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008272447s
STEP: Saw pod success
Oct 22 00:27:22.191: INFO: Pod "pod-projected-secrets-a3b67e28-dafe-4490-9f5f-fd36a5217275" satisfied condition "success or failure"
Oct 22 00:27:22.194: INFO: Trying to get logs from node mip-bd-vm40.mip.storage.hpecorp.net pod pod-projected-secrets-a3b67e28-dafe-4490-9f5f-fd36a5217275 container projected-secret-volume-test: <nil>
STEP: delete the pod
Oct 22 00:27:22.234: INFO: Waiting for pod pod-projected-secrets-a3b67e28-dafe-4490-9f5f-fd36a5217275 to disappear
Oct 22 00:27:22.237: INFO: Pod pod-projected-secrets-a3b67e28-dafe-4490-9f5f-fd36a5217275 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 00:27:22.237: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3703" for this suite.
Oct 22 00:27:28.262: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 00:27:28.418: INFO: namespace projected-3703 deletion completed in 6.173341121s

• [SLOW TEST:8.303 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 00:27:28.418: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1613
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Oct 22 00:27:28.464: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-3945'
Oct 22 00:27:28.638: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Oct 22 00:27:28.638: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
STEP: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1618
Oct 22 00:27:28.653: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 delete jobs e2e-test-nginx-job --namespace=kubectl-3945'
Oct 22 00:27:28.819: INFO: stderr: ""
Oct 22 00:27:28.819: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 00:27:28.819: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3945" for this suite.
Oct 22 00:27:34.844: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 00:27:34.997: INFO: namespace kubectl-3945 deletion completed in 6.170852214s

• [SLOW TEST:6.579 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run job
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 00:27:34.997: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Oct 22 00:27:35.108: INFO: Waiting up to 5m0s for pod "downwardapi-volume-8cb2eccd-ccd4-48fb-b244-8ad2334035e8" in namespace "downward-api-8200" to be "success or failure"
Oct 22 00:27:35.114: INFO: Pod "downwardapi-volume-8cb2eccd-ccd4-48fb-b244-8ad2334035e8": Phase="Pending", Reason="", readiness=false. Elapsed: 5.954083ms
Oct 22 00:27:37.119: INFO: Pod "downwardapi-volume-8cb2eccd-ccd4-48fb-b244-8ad2334035e8": Phase="Running", Reason="", readiness=true. Elapsed: 2.011514543s
Oct 22 00:27:39.125: INFO: Pod "downwardapi-volume-8cb2eccd-ccd4-48fb-b244-8ad2334035e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017561976s
STEP: Saw pod success
Oct 22 00:27:39.126: INFO: Pod "downwardapi-volume-8cb2eccd-ccd4-48fb-b244-8ad2334035e8" satisfied condition "success or failure"
Oct 22 00:27:39.129: INFO: Trying to get logs from node mip-bd-vm40.mip.storage.hpecorp.net pod downwardapi-volume-8cb2eccd-ccd4-48fb-b244-8ad2334035e8 container client-container: <nil>
STEP: delete the pod
Oct 22 00:27:39.156: INFO: Waiting for pod downwardapi-volume-8cb2eccd-ccd4-48fb-b244-8ad2334035e8 to disappear
Oct 22 00:27:39.160: INFO: Pod downwardapi-volume-8cb2eccd-ccd4-48fb-b244-8ad2334035e8 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 00:27:39.160: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8200" for this suite.
Oct 22 00:27:45.181: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 00:27:45.325: INFO: namespace downward-api-8200 deletion completed in 6.160068435s

• [SLOW TEST:10.328 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 00:27:45.325: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Oct 22 00:27:51.405: INFO: &Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-ddadff3f-53d7-4520-8a2b-010aaa4a2460,GenerateName:,Namespace:events-2998,SelfLink:/api/v1/namespaces/events-2998/pods/send-events-ddadff3f-53d7-4520-8a2b-010aaa4a2460,UID:547db678-a2c4-4fea-969f-fd9d453d88d0,ResourceVersion:16299,Generation:0,CreationTimestamp:2019-10-22 00:27:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 372640948,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.244.1.67/32,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-xvv55 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-xvv55,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-xvv55 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:mip-bd-vm41.mip.storage.hpecorp.net,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003394630} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003394650}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:27:45 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:27:50 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:27:50 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:27:45 +0000 UTC  }],Message:,Reason:,HostIP:16.143.20.138,PodIP:10.244.1.67,StartTime:2019-10-22 00:27:45 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2019-10-22 00:27:49 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 docker-pullable://gcr.io/kubernetes-e2e-test-images/serve-hostname@sha256:bab70473a6d8ef65a22625dc9a1b0f0452e811530fdbe77e4408523460177ff1 docker://1ab371d01b2d305e350ed308024354648da5debe2531486b4e1631819b12655a}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}

STEP: checking for scheduler event about the pod
Oct 22 00:27:53.410: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Oct 22 00:27:55.416: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 00:27:55.423: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-2998" for this suite.
Oct 22 00:28:35.450: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 00:28:35.593: INFO: namespace events-2998 deletion completed in 40.16162332s

• [SLOW TEST:50.268 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 00:28:35.593: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 00:28:59.752: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-6309" for this suite.
Oct 22 00:29:05.774: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 00:29:05.918: INFO: namespace namespaces-6309 deletion completed in 6.158158487s
STEP: Destroying namespace "nsdeletetest-5841" for this suite.
Oct 22 00:29:05.921: INFO: Namespace nsdeletetest-5841 was already deleted
STEP: Destroying namespace "nsdeletetest-9707" for this suite.
Oct 22 00:29:11.936: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 00:29:12.086: INFO: namespace nsdeletetest-9707 deletion completed in 6.164749429s

• [SLOW TEST:36.493 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 00:29:12.086: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Oct 22 00:29:12.147: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ee187495-8b2b-432f-a767-1b8c8b03d255" in namespace "downward-api-363" to be "success or failure"
Oct 22 00:29:12.152: INFO: Pod "downwardapi-volume-ee187495-8b2b-432f-a767-1b8c8b03d255": Phase="Pending", Reason="", readiness=false. Elapsed: 5.038147ms
Oct 22 00:29:14.158: INFO: Pod "downwardapi-volume-ee187495-8b2b-432f-a767-1b8c8b03d255": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01128732s
STEP: Saw pod success
Oct 22 00:29:14.158: INFO: Pod "downwardapi-volume-ee187495-8b2b-432f-a767-1b8c8b03d255" satisfied condition "success or failure"
Oct 22 00:29:14.162: INFO: Trying to get logs from node mip-bd-vm41.mip.storage.hpecorp.net pod downwardapi-volume-ee187495-8b2b-432f-a767-1b8c8b03d255 container client-container: <nil>
STEP: delete the pod
Oct 22 00:29:14.191: INFO: Waiting for pod downwardapi-volume-ee187495-8b2b-432f-a767-1b8c8b03d255 to disappear
Oct 22 00:29:14.195: INFO: Pod downwardapi-volume-ee187495-8b2b-432f-a767-1b8c8b03d255 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 00:29:14.195: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-363" for this suite.
Oct 22 00:29:20.219: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 00:29:20.365: INFO: namespace downward-api-363 deletion completed in 6.165691909s

• [SLOW TEST:8.279 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 00:29:20.366: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Oct 22 00:29:20.413: INFO: Creating ReplicaSet my-hostname-basic-30eda748-505c-4363-a196-5b2c87c501d4
Oct 22 00:29:20.423: INFO: Pod name my-hostname-basic-30eda748-505c-4363-a196-5b2c87c501d4: Found 0 pods out of 1
Oct 22 00:29:25.429: INFO: Pod name my-hostname-basic-30eda748-505c-4363-a196-5b2c87c501d4: Found 1 pods out of 1
Oct 22 00:29:25.429: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-30eda748-505c-4363-a196-5b2c87c501d4" is running
Oct 22 00:29:25.433: INFO: Pod "my-hostname-basic-30eda748-505c-4363-a196-5b2c87c501d4-q497n" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-10-22 00:29:20 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-10-22 00:29:24 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-10-22 00:29:24 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-10-22 00:29:20 +0000 UTC Reason: Message:}])
Oct 22 00:29:25.433: INFO: Trying to dial the pod
Oct 22 00:29:30.449: INFO: Controller my-hostname-basic-30eda748-505c-4363-a196-5b2c87c501d4: Got expected result from replica 1 [my-hostname-basic-30eda748-505c-4363-a196-5b2c87c501d4-q497n]: "my-hostname-basic-30eda748-505c-4363-a196-5b2c87c501d4-q497n", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 00:29:30.449: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-6714" for this suite.
Oct 22 00:29:36.469: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 00:29:36.622: INFO: namespace replicaset-6714 deletion completed in 6.168206969s

• [SLOW TEST:16.256 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 00:29:36.622: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1722
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Oct 22 00:29:36.667: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 run e2e-test-nginx-pod --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --labels=run=e2e-test-nginx-pod --namespace=kubectl-9254'
Oct 22 00:29:36.851: INFO: stderr: ""
Oct 22 00:29:36.851: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod is running
STEP: verifying the pod e2e-test-nginx-pod was created
Oct 22 00:29:41.902: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 get pod e2e-test-nginx-pod --namespace=kubectl-9254 -o json'
Oct 22 00:29:42.065: INFO: stderr: ""
Oct 22 00:29:42.065: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"annotations\": {\n            \"cni.projectcalico.org/podIP\": \"10.244.1.69/32\"\n        },\n        \"creationTimestamp\": \"2019-10-22T00:29:36Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"kubectl-9254\",\n        \"resourceVersion\": \"16583\",\n        \"selfLink\": \"/api/v1/namespaces/kubectl-9254/pods/e2e-test-nginx-pod\",\n        \"uid\": \"0b630822-71c1-400a-94ec-27c06af6816a\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-pbmp7\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"mip-bd-vm41.mip.storage.hpecorp.net\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-pbmp7\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-pbmp7\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-10-22T00:29:36Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-10-22T00:29:38Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-10-22T00:29:38Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-10-22T00:29:36Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://5b7583543faed96c005800d3c68a6db52e1d09d39f367b050f844e7f4fe259f8\",\n                \"image\": \"docker.io/nginx:1.14-alpine\",\n                \"imageID\": \"docker-pullable://docker.io/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2019-10-22T00:29:37Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"16.143.20.138\",\n        \"phase\": \"Running\",\n        \"podIP\": \"10.244.1.69\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2019-10-22T00:29:36Z\"\n    }\n}\n"
STEP: replace the image in the pod
Oct 22 00:29:42.065: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 replace -f - --namespace=kubectl-9254'
Oct 22 00:29:42.388: INFO: stderr: ""
Oct 22 00:29:42.388: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
STEP: verifying the pod e2e-test-nginx-pod has the right image docker.io/library/busybox:1.29
[AfterEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1727
Oct 22 00:29:42.393: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 delete pods e2e-test-nginx-pod --namespace=kubectl-9254'
Oct 22 00:29:48.883: INFO: stderr: ""
Oct 22 00:29:48.883: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 00:29:48.883: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9254" for this suite.
Oct 22 00:29:54.904: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 00:29:55.093: INFO: namespace kubectl-9254 deletion completed in 6.205009971s

• [SLOW TEST:18.471 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl replace
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 00:29:55.093: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1558
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Oct 22 00:29:55.154: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --generator=deployment/apps.v1 --namespace=kubectl-5050'
Oct 22 00:29:55.330: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Oct 22 00:29:55.331: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the deployment e2e-test-nginx-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1563
Oct 22 00:29:57.347: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 delete deployment e2e-test-nginx-deployment --namespace=kubectl-5050'
Oct 22 00:29:57.532: INFO: stderr: ""
Oct 22 00:29:57.532: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 00:29:57.532: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5050" for this suite.
Oct 22 00:30:19.559: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 00:30:19.708: INFO: namespace kubectl-5050 deletion completed in 22.170312279s

• [SLOW TEST:24.615 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 00:30:19.708: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 00:30:25.874: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-653" for this suite.
Oct 22 00:30:31.894: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 00:30:32.044: INFO: namespace namespaces-653 deletion completed in 6.16532817s
STEP: Destroying namespace "nsdeletetest-2358" for this suite.
Oct 22 00:30:32.048: INFO: Namespace nsdeletetest-2358 was already deleted
STEP: Destroying namespace "nsdeletetest-6592" for this suite.
Oct 22 00:30:38.063: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 00:30:38.214: INFO: namespace nsdeletetest-6592 deletion completed in 6.16572406s

• [SLOW TEST:18.505 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 00:30:38.214: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: getting the auto-created API token
STEP: reading a file in the container
Oct 22 00:30:40.786: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-951 pod-service-account-2d0baff5-36b8-4635-904e-9efe513893cb -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
STEP: reading a file in the container
Oct 22 00:30:41.078: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-951 pod-service-account-2d0baff5-36b8-4635-904e-9efe513893cb -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
STEP: reading a file in the container
Oct 22 00:30:41.379: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-951 pod-service-account-2d0baff5-36b8-4635-904e-9efe513893cb -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 00:30:41.683: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-951" for this suite.
Oct 22 00:30:47.706: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 00:30:47.858: INFO: namespace svcaccounts-951 deletion completed in 6.169131041s

• [SLOW TEST:9.644 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:23
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 00:30:47.858: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-upd-0c83b6a2-170b-4fdd-9c5a-61d0bde8d2ed
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 00:30:51.963: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-109" for this suite.
Oct 22 00:31:13.984: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 00:31:14.134: INFO: namespace configmap-109 deletion completed in 22.165816782s

• [SLOW TEST:26.275 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 00:31:14.134: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Oct 22 00:31:17.215: INFO: Expected: &{} to match Container's Termination Message:  --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 00:31:17.233: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-2907" for this suite.
Oct 22 00:31:23.253: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 00:31:23.407: INFO: namespace container-runtime-2907 deletion completed in 6.169042362s

• [SLOW TEST:9.273 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  blackbox test
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
    on terminated container
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:129
      should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 00:31:23.407: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-9660
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace statefulset-9660
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-9660
Oct 22 00:31:23.478: INFO: Found 0 stateful pods, waiting for 1
Oct 22 00:31:33.484: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Oct 22 00:31:33.488: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 exec --namespace=statefulset-9660 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Oct 22 00:31:33.814: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Oct 22 00:31:33.814: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Oct 22 00:31:33.814: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Oct 22 00:31:33.819: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Oct 22 00:31:43.826: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Oct 22 00:31:43.826: INFO: Waiting for statefulset status.replicas updated to 0
Oct 22 00:31:43.847: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999459s
Oct 22 00:31:44.859: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.991754584s
Oct 22 00:31:45.865: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.980055491s
Oct 22 00:31:46.871: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.973786561s
Oct 22 00:31:47.877: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.967722402s
Oct 22 00:31:48.883: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.961712071s
Oct 22 00:31:49.889: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.955826098s
Oct 22 00:31:50.896: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.949788759s
Oct 22 00:31:51.902: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.943265468s
Oct 22 00:31:52.909: INFO: Verifying statefulset ss doesn't scale past 1 for another 936.769591ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-9660
Oct 22 00:31:53.915: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 exec --namespace=statefulset-9660 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 22 00:31:54.237: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Oct 22 00:31:54.237: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Oct 22 00:31:54.237: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Oct 22 00:31:54.241: INFO: Found 1 stateful pods, waiting for 3
Oct 22 00:32:04.249: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Oct 22 00:32:04.249: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Oct 22 00:32:04.249: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Oct 22 00:32:04.257: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 exec --namespace=statefulset-9660 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Oct 22 00:32:04.556: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Oct 22 00:32:04.556: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Oct 22 00:32:04.556: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Oct 22 00:32:04.556: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 exec --namespace=statefulset-9660 ss-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Oct 22 00:32:04.881: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Oct 22 00:32:04.881: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Oct 22 00:32:04.881: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Oct 22 00:32:04.881: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 exec --namespace=statefulset-9660 ss-2 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Oct 22 00:32:05.224: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Oct 22 00:32:05.224: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Oct 22 00:32:05.224: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Oct 22 00:32:05.224: INFO: Waiting for statefulset status.replicas updated to 0
Oct 22 00:32:05.229: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 1
Oct 22 00:32:15.240: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Oct 22 00:32:15.240: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Oct 22 00:32:15.240: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Oct 22 00:32:15.255: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999532s
Oct 22 00:32:16.262: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.994899468s
Oct 22 00:32:17.269: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.988265588s
Oct 22 00:32:18.275: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.981202135s
Oct 22 00:32:19.281: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.975117769s
Oct 22 00:32:20.288: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.969089445s
Oct 22 00:32:21.295: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.962395278s
Oct 22 00:32:22.301: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.955033722s
Oct 22 00:32:23.308: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.948723575s
Oct 22 00:32:24.314: INFO: Verifying statefulset ss doesn't scale past 3 for another 942.451223ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-9660
Oct 22 00:32:25.320: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 exec --namespace=statefulset-9660 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 22 00:32:25.622: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Oct 22 00:32:25.622: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Oct 22 00:32:25.622: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Oct 22 00:32:25.622: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 exec --namespace=statefulset-9660 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 22 00:32:25.939: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Oct 22 00:32:25.939: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Oct 22 00:32:25.939: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Oct 22 00:32:25.939: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 exec --namespace=statefulset-9660 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 22 00:32:26.247: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Oct 22 00:32:26.247: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Oct 22 00:32:26.247: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Oct 22 00:32:26.247: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Oct 22 00:32:46.269: INFO: Deleting all statefulset in ns statefulset-9660
Oct 22 00:32:46.274: INFO: Scaling statefulset ss to 0
Oct 22 00:32:46.286: INFO: Waiting for statefulset status.replicas updated to 0
Oct 22 00:32:46.289: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 00:32:46.306: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-9660" for this suite.
Oct 22 00:33:02.327: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 00:33:02.469: INFO: namespace statefulset-9660 deletion completed in 16.158130155s

• [SLOW TEST:99.062 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 00:33:02.470: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 00:33:02.518: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-4958" for this suite.
Oct 22 00:33:08.538: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 00:33:08.697: INFO: namespace services-4958 deletion completed in 6.174421708s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:92

• [SLOW TEST:6.227 seconds]
[sig-network] Services
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide secure master service  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 00:33:08.697: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Performing setup for networking test in namespace pod-network-test-7832
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Oct 22 00:33:08.748: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Oct 22 00:33:24.834: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.244.1.74:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-7832 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 22 00:33:24.834: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
Oct 22 00:33:24.982: INFO: Found all expected endpoints: [netserver-0]
Oct 22 00:33:24.987: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.244.2.67:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-7832 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 22 00:33:24.987: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
Oct 22 00:33:25.130: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 00:33:25.130: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-7832" for this suite.
Oct 22 00:33:47.151: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 00:33:47.316: INFO: namespace pod-network-test-7832 deletion completed in 22.180442492s

• [SLOW TEST:38.619 seconds]
[sig-network] Networking
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 00:33:47.317: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 00:34:13.640: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-7929" for this suite.
Oct 22 00:34:19.662: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 00:34:19.823: INFO: namespace container-runtime-7929 deletion completed in 6.177000899s

• [SLOW TEST:32.506 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  blackbox test
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
    when starting a container that exits
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 00:34:19.823: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating Pod
STEP: Waiting for the pod running
STEP: Geting the pod
STEP: Reading file content from the nginx-container
Oct 22 00:34:23.913: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 exec pod-sharedvolume-b4613ef0-1efc-4d84-b6d8-21a4c10e5069 -c busybox-main-container --namespace=emptydir-2641 -- cat /usr/share/volumeshare/shareddata.txt'
Oct 22 00:34:24.325: INFO: stderr: ""
Oct 22 00:34:24.325: INFO: stdout: "Hello from the busy-box sub-container\n"
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 00:34:24.326: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2641" for this suite.
Oct 22 00:34:30.348: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 00:34:30.494: INFO: namespace emptydir-2641 deletion completed in 6.161781449s

• [SLOW TEST:10.671 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 00:34:30.495: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Oct 22 00:34:30.581: INFO: DaemonSet pods can't tolerate node mip-bd-vm39.mip.storage.hpecorp.net with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 22 00:34:30.586: INFO: Number of nodes with available pods: 0
Oct 22 00:34:30.586: INFO: Node mip-bd-vm40.mip.storage.hpecorp.net is running more than one daemon pod
Oct 22 00:34:31.592: INFO: DaemonSet pods can't tolerate node mip-bd-vm39.mip.storage.hpecorp.net with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 22 00:34:31.596: INFO: Number of nodes with available pods: 0
Oct 22 00:34:31.596: INFO: Node mip-bd-vm40.mip.storage.hpecorp.net is running more than one daemon pod
Oct 22 00:34:32.592: INFO: DaemonSet pods can't tolerate node mip-bd-vm39.mip.storage.hpecorp.net with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 22 00:34:32.597: INFO: Number of nodes with available pods: 2
Oct 22 00:34:32.597: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Stop a daemon pod, check that the daemon pod is revived.
Oct 22 00:34:32.617: INFO: DaemonSet pods can't tolerate node mip-bd-vm39.mip.storage.hpecorp.net with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 22 00:34:32.621: INFO: Number of nodes with available pods: 1
Oct 22 00:34:32.621: INFO: Node mip-bd-vm40.mip.storage.hpecorp.net is running more than one daemon pod
Oct 22 00:34:33.629: INFO: DaemonSet pods can't tolerate node mip-bd-vm39.mip.storage.hpecorp.net with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 22 00:34:33.633: INFO: Number of nodes with available pods: 1
Oct 22 00:34:33.633: INFO: Node mip-bd-vm40.mip.storage.hpecorp.net is running more than one daemon pod
Oct 22 00:34:34.628: INFO: DaemonSet pods can't tolerate node mip-bd-vm39.mip.storage.hpecorp.net with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 22 00:34:34.634: INFO: Number of nodes with available pods: 1
Oct 22 00:34:34.634: INFO: Node mip-bd-vm40.mip.storage.hpecorp.net is running more than one daemon pod
Oct 22 00:34:35.628: INFO: DaemonSet pods can't tolerate node mip-bd-vm39.mip.storage.hpecorp.net with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 22 00:34:35.633: INFO: Number of nodes with available pods: 1
Oct 22 00:34:35.633: INFO: Node mip-bd-vm40.mip.storage.hpecorp.net is running more than one daemon pod
Oct 22 00:34:36.628: INFO: DaemonSet pods can't tolerate node mip-bd-vm39.mip.storage.hpecorp.net with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 22 00:34:36.632: INFO: Number of nodes with available pods: 1
Oct 22 00:34:36.632: INFO: Node mip-bd-vm40.mip.storage.hpecorp.net is running more than one daemon pod
Oct 22 00:34:37.629: INFO: DaemonSet pods can't tolerate node mip-bd-vm39.mip.storage.hpecorp.net with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 22 00:34:37.634: INFO: Number of nodes with available pods: 1
Oct 22 00:34:37.634: INFO: Node mip-bd-vm40.mip.storage.hpecorp.net is running more than one daemon pod
Oct 22 00:34:38.630: INFO: DaemonSet pods can't tolerate node mip-bd-vm39.mip.storage.hpecorp.net with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 22 00:34:38.635: INFO: Number of nodes with available pods: 1
Oct 22 00:34:38.635: INFO: Node mip-bd-vm40.mip.storage.hpecorp.net is running more than one daemon pod
Oct 22 00:34:39.628: INFO: DaemonSet pods can't tolerate node mip-bd-vm39.mip.storage.hpecorp.net with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 22 00:34:39.632: INFO: Number of nodes with available pods: 1
Oct 22 00:34:39.632: INFO: Node mip-bd-vm40.mip.storage.hpecorp.net is running more than one daemon pod
Oct 22 00:34:40.628: INFO: DaemonSet pods can't tolerate node mip-bd-vm39.mip.storage.hpecorp.net with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 22 00:34:40.631: INFO: Number of nodes with available pods: 1
Oct 22 00:34:40.631: INFO: Node mip-bd-vm40.mip.storage.hpecorp.net is running more than one daemon pod
Oct 22 00:34:41.628: INFO: DaemonSet pods can't tolerate node mip-bd-vm39.mip.storage.hpecorp.net with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 22 00:34:41.633: INFO: Number of nodes with available pods: 1
Oct 22 00:34:41.633: INFO: Node mip-bd-vm40.mip.storage.hpecorp.net is running more than one daemon pod
Oct 22 00:34:42.628: INFO: DaemonSet pods can't tolerate node mip-bd-vm39.mip.storage.hpecorp.net with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 22 00:34:42.631: INFO: Number of nodes with available pods: 2
Oct 22 00:34:42.631: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-8717, will wait for the garbage collector to delete the pods
Oct 22 00:34:42.700: INFO: Deleting DaemonSet.extensions daemon-set took: 11.017794ms
Oct 22 00:34:43.100: INFO: Terminating DaemonSet.extensions daemon-set pods took: 400.274973ms
Oct 22 00:34:51.006: INFO: Number of nodes with available pods: 0
Oct 22 00:34:51.006: INFO: Number of running nodes: 0, number of available pods: 0
Oct 22 00:34:51.011: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-8717/daemonsets","resourceVersion":"17662"},"items":null}

Oct 22 00:34:51.014: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-8717/pods","resourceVersion":"17662"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 00:34:51.028: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-8717" for this suite.
Oct 22 00:34:57.049: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 00:34:57.212: INFO: namespace daemonsets-8717 deletion completed in 6.178881061s

• [SLOW TEST:26.717 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 00:34:57.212: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 00:35:00.296: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-5378" for this suite.
Oct 22 00:35:22.319: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 00:35:22.475: INFO: namespace replication-controller-5378 deletion completed in 22.174054266s

• [SLOW TEST:25.263 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 00:35:22.475: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating all guestbook components
Oct 22 00:35:22.525: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Oct 22 00:35:22.525: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 create -f - --namespace=kubectl-9893'
Oct 22 00:35:22.868: INFO: stderr: ""
Oct 22 00:35:22.868: INFO: stdout: "service/redis-slave created\n"
Oct 22 00:35:22.868: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Oct 22 00:35:22.868: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 create -f - --namespace=kubectl-9893'
Oct 22 00:35:23.216: INFO: stderr: ""
Oct 22 00:35:23.216: INFO: stdout: "service/redis-master created\n"
Oct 22 00:35:23.216: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Oct 22 00:35:23.216: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 create -f - --namespace=kubectl-9893'
Oct 22 00:35:23.551: INFO: stderr: ""
Oct 22 00:35:23.551: INFO: stdout: "service/frontend created\n"
Oct 22 00:35:23.551: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: guestbook
      tier: frontend
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Oct 22 00:35:23.551: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 create -f - --namespace=kubectl-9893'
Oct 22 00:35:23.867: INFO: stderr: ""
Oct 22 00:35:23.867: INFO: stdout: "deployment.apps/frontend created\n"
Oct 22 00:35:23.868: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  selector:
    matchLabels:
      app: redis
      role: master
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Oct 22 00:35:23.868: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 create -f - --namespace=kubectl-9893'
Oct 22 00:35:24.196: INFO: stderr: ""
Oct 22 00:35:24.196: INFO: stdout: "deployment.apps/redis-master created\n"
Oct 22 00:35:24.196: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  selector:
    matchLabels:
      app: redis
      role: slave
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave:v3
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Oct 22 00:35:24.196: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 create -f - --namespace=kubectl-9893'
Oct 22 00:35:24.532: INFO: stderr: ""
Oct 22 00:35:24.532: INFO: stdout: "deployment.apps/redis-slave created\n"
STEP: validating guestbook app
Oct 22 00:35:24.532: INFO: Waiting for all frontend pods to be Running.
Oct 22 00:35:59.584: INFO: Waiting for frontend to serve content.
Oct 22 00:36:04.617: INFO: Failed to get response from guestbook. err: <nil>, response: <br />
<b>Fatal error</b>:  Uncaught exception 'Predis\Connection\ConnectionException' with message 'Connection timed out [tcp://redis-slave:6379]' in /usr/local/lib/php/Predis/Connection/AbstractConnection.php:155
Stack trace:
#0 /usr/local/lib/php/Predis/Connection/StreamConnection.php(128): Predis\Connection\AbstractConnection-&gt;onConnectionError('Connection time...', 110)
#1 /usr/local/lib/php/Predis/Connection/StreamConnection.php(178): Predis\Connection\StreamConnection-&gt;createStreamSocket(Object(Predis\Connection\Parameters), 'tcp://redis-sla...', 4)
#2 /usr/local/lib/php/Predis/Connection/StreamConnection.php(100): Predis\Connection\StreamConnection-&gt;tcpStreamInitializer(Object(Predis\Connection\Parameters))
#3 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(81): Predis\Connection\StreamConnection-&gt;createResource()
#4 /usr/local/lib/php/Predis/Connection/StreamConnection.php(258): Predis\Connection\AbstractConnection-&gt;connect()
#5 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(180): Predis\Connection\Stre in <b>/usr/local/lib/php/Predis/Connection/AbstractConnection.php</b> on line <b>155</b><br />

Oct 22 00:36:09.645: INFO: Trying to add a new entry to the guestbook.
Oct 22 00:36:09.671: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Oct 22 00:36:09.698: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 delete --grace-period=0 --force -f - --namespace=kubectl-9893'
Oct 22 00:36:09.887: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct 22 00:36:09.888: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Oct 22 00:36:09.888: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 delete --grace-period=0 --force -f - --namespace=kubectl-9893'
Oct 22 00:36:10.091: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct 22 00:36:10.091: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Oct 22 00:36:10.091: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 delete --grace-period=0 --force -f - --namespace=kubectl-9893'
Oct 22 00:36:10.300: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct 22 00:36:10.300: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Oct 22 00:36:10.300: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 delete --grace-period=0 --force -f - --namespace=kubectl-9893'
Oct 22 00:36:10.491: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct 22 00:36:10.491: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Oct 22 00:36:10.491: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 delete --grace-period=0 --force -f - --namespace=kubectl-9893'
Oct 22 00:36:10.650: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct 22 00:36:10.650: INFO: stdout: "deployment.apps \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Oct 22 00:36:10.650: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 delete --grace-period=0 --force -f - --namespace=kubectl-9893'
Oct 22 00:36:10.815: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct 22 00:36:10.815: INFO: stdout: "deployment.apps \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 00:36:10.816: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9893" for this suite.
Oct 22 00:36:52.837: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 00:36:53.001: INFO: namespace kubectl-9893 deletion completed in 42.179457115s

• [SLOW TEST:90.526 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Guestbook application
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 00:36:53.002: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Oct 22 00:36:53.054: INFO: Waiting up to 5m0s for pod "downward-api-f745e104-5667-4ffb-8aac-71237a246db3" in namespace "downward-api-709" to be "success or failure"
Oct 22 00:36:53.058: INFO: Pod "downward-api-f745e104-5667-4ffb-8aac-71237a246db3": Phase="Pending", Reason="", readiness=false. Elapsed: 3.991667ms
Oct 22 00:36:55.064: INFO: Pod "downward-api-f745e104-5667-4ffb-8aac-71237a246db3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009999635s
Oct 22 00:36:57.070: INFO: Pod "downward-api-f745e104-5667-4ffb-8aac-71237a246db3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015795264s
STEP: Saw pod success
Oct 22 00:36:57.070: INFO: Pod "downward-api-f745e104-5667-4ffb-8aac-71237a246db3" satisfied condition "success or failure"
Oct 22 00:36:57.074: INFO: Trying to get logs from node mip-bd-vm40.mip.storage.hpecorp.net pod downward-api-f745e104-5667-4ffb-8aac-71237a246db3 container dapi-container: <nil>
STEP: delete the pod
Oct 22 00:36:57.107: INFO: Waiting for pod downward-api-f745e104-5667-4ffb-8aac-71237a246db3 to disappear
Oct 22 00:36:57.115: INFO: Pod downward-api-f745e104-5667-4ffb-8aac-71237a246db3 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 00:36:57.115: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-709" for this suite.
Oct 22 00:37:03.137: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 00:37:03.301: INFO: namespace downward-api-709 deletion completed in 6.179580961s

• [SLOW TEST:10.300 seconds]
[sig-node] Downward API
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 00:37:03.302: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
Oct 22 00:37:13.445: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W1022 00:37:13.445864      18 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 00:37:13.446: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-9038" for this suite.
Oct 22 00:37:19.465: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 00:37:19.617: INFO: namespace gc-9038 deletion completed in 6.165961092s

• [SLOW TEST:16.315 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 00:37:19.617: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Oct 22 00:37:22.208: INFO: Successfully updated pod "pod-update-activedeadlineseconds-d7bfc918-2d75-45e7-be2b-172ecfb5bd56"
Oct 22 00:37:22.208: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-d7bfc918-2d75-45e7-be2b-172ecfb5bd56" in namespace "pods-2417" to be "terminated due to deadline exceeded"
Oct 22 00:37:22.212: INFO: Pod "pod-update-activedeadlineseconds-d7bfc918-2d75-45e7-be2b-172ecfb5bd56": Phase="Running", Reason="", readiness=true. Elapsed: 3.39656ms
Oct 22 00:37:24.217: INFO: Pod "pod-update-activedeadlineseconds-d7bfc918-2d75-45e7-be2b-172ecfb5bd56": Phase="Running", Reason="", readiness=true. Elapsed: 2.00855077s
Oct 22 00:37:26.223: INFO: Pod "pod-update-activedeadlineseconds-d7bfc918-2d75-45e7-be2b-172ecfb5bd56": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 4.014433728s
Oct 22 00:37:26.223: INFO: Pod "pod-update-activedeadlineseconds-d7bfc918-2d75-45e7-be2b-172ecfb5bd56" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 00:37:26.223: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-2417" for this suite.
Oct 22 00:37:32.243: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 00:37:32.384: INFO: namespace pods-2417 deletion completed in 6.155421615s

• [SLOW TEST:12.767 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 00:37:32.384: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: starting a background goroutine to produce watch events
STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 00:37:37.847: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-3848" for this suite.
Oct 22 00:37:43.996: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 00:37:44.141: INFO: namespace watch-3848 deletion completed in 6.248304914s

• [SLOW TEST:11.757 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 00:37:44.142: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-9166
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating stateful set ss in namespace statefulset-9166
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-9166
Oct 22 00:37:44.231: INFO: Found 0 stateful pods, waiting for 1
Oct 22 00:37:54.238: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Oct 22 00:37:54.242: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 exec --namespace=statefulset-9166 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Oct 22 00:37:54.545: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Oct 22 00:37:54.545: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Oct 22 00:37:54.545: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Oct 22 00:37:54.551: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Oct 22 00:38:04.558: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Oct 22 00:38:04.558: INFO: Waiting for statefulset status.replicas updated to 0
Oct 22 00:38:04.579: INFO: POD   NODE                                 PHASE    GRACE  CONDITIONS
Oct 22 00:38:04.579: INFO: ss-0  mip-bd-vm40.mip.storage.hpecorp.net  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:37:44 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:37:54 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:37:54 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:37:44 +0000 UTC  }]
Oct 22 00:38:04.579: INFO: 
Oct 22 00:38:04.579: INFO: StatefulSet ss has not reached scale 3, at 1
Oct 22 00:38:05.584: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.992653225s
Oct 22 00:38:06.589: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.987038947s
Oct 22 00:38:07.598: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.981818539s
Oct 22 00:38:08.605: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.973170007s
Oct 22 00:38:09.611: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.966592919s
Oct 22 00:38:10.617: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.960567643s
Oct 22 00:38:11.625: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.954411459s
Oct 22 00:38:12.631: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.946236782s
Oct 22 00:38:13.638: INFO: Verifying statefulset ss doesn't scale past 3 for another 939.814326ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-9166
Oct 22 00:38:14.644: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 exec --namespace=statefulset-9166 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 22 00:38:14.954: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Oct 22 00:38:14.954: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Oct 22 00:38:14.954: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Oct 22 00:38:14.954: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 exec --namespace=statefulset-9166 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 22 00:38:15.277: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Oct 22 00:38:15.277: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Oct 22 00:38:15.277: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Oct 22 00:38:15.277: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 exec --namespace=statefulset-9166 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 22 00:38:15.602: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Oct 22 00:38:15.602: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Oct 22 00:38:15.602: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Oct 22 00:38:15.607: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=false
Oct 22 00:38:25.612: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Oct 22 00:38:25.612: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Oct 22 00:38:25.612: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Oct 22 00:38:25.617: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 exec --namespace=statefulset-9166 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Oct 22 00:38:25.927: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Oct 22 00:38:25.927: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Oct 22 00:38:25.927: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Oct 22 00:38:25.927: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 exec --namespace=statefulset-9166 ss-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Oct 22 00:38:26.243: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Oct 22 00:38:26.243: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Oct 22 00:38:26.243: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Oct 22 00:38:26.243: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 exec --namespace=statefulset-9166 ss-2 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Oct 22 00:38:26.547: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Oct 22 00:38:26.547: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Oct 22 00:38:26.547: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Oct 22 00:38:26.547: INFO: Waiting for statefulset status.replicas updated to 0
Oct 22 00:38:26.552: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
Oct 22 00:38:36.562: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Oct 22 00:38:36.562: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Oct 22 00:38:36.562: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Oct 22 00:38:36.578: INFO: POD   NODE                                 PHASE    GRACE  CONDITIONS
Oct 22 00:38:36.578: INFO: ss-0  mip-bd-vm40.mip.storage.hpecorp.net  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:37:44 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:38:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:38:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:37:44 +0000 UTC  }]
Oct 22 00:38:36.578: INFO: ss-1  mip-bd-vm41.mip.storage.hpecorp.net  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:38:04 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:38:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:38:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:38:04 +0000 UTC  }]
Oct 22 00:38:36.578: INFO: ss-2  mip-bd-vm41.mip.storage.hpecorp.net  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:38:04 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:38:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:38:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:38:04 +0000 UTC  }]
Oct 22 00:38:36.578: INFO: 
Oct 22 00:38:36.578: INFO: StatefulSet ss has not reached scale 0, at 3
Oct 22 00:38:37.584: INFO: POD   NODE                                 PHASE    GRACE  CONDITIONS
Oct 22 00:38:37.584: INFO: ss-0  mip-bd-vm40.mip.storage.hpecorp.net  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:37:44 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:38:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:38:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:37:44 +0000 UTC  }]
Oct 22 00:38:37.585: INFO: ss-1  mip-bd-vm41.mip.storage.hpecorp.net  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:38:04 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:38:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:38:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:38:04 +0000 UTC  }]
Oct 22 00:38:37.585: INFO: ss-2  mip-bd-vm41.mip.storage.hpecorp.net  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:38:04 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:38:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:38:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:38:04 +0000 UTC  }]
Oct 22 00:38:37.585: INFO: 
Oct 22 00:38:37.585: INFO: StatefulSet ss has not reached scale 0, at 3
Oct 22 00:38:38.592: INFO: POD   NODE                                 PHASE    GRACE  CONDITIONS
Oct 22 00:38:38.592: INFO: ss-0  mip-bd-vm40.mip.storage.hpecorp.net  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:37:44 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:38:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:38:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:37:44 +0000 UTC  }]
Oct 22 00:38:38.592: INFO: ss-1  mip-bd-vm41.mip.storage.hpecorp.net  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:38:04 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:38:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:38:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:38:04 +0000 UTC  }]
Oct 22 00:38:38.592: INFO: ss-2  mip-bd-vm41.mip.storage.hpecorp.net  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:38:04 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:38:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:38:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:38:04 +0000 UTC  }]
Oct 22 00:38:38.592: INFO: 
Oct 22 00:38:38.592: INFO: StatefulSet ss has not reached scale 0, at 3
Oct 22 00:38:39.598: INFO: POD   NODE                                 PHASE    GRACE  CONDITIONS
Oct 22 00:38:39.598: INFO: ss-0  mip-bd-vm40.mip.storage.hpecorp.net  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:37:44 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:38:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:38:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:37:44 +0000 UTC  }]
Oct 22 00:38:39.598: INFO: ss-1  mip-bd-vm41.mip.storage.hpecorp.net  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:38:04 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:38:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:38:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:38:04 +0000 UTC  }]
Oct 22 00:38:39.598: INFO: ss-2  mip-bd-vm41.mip.storage.hpecorp.net  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:38:04 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:38:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:38:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:38:04 +0000 UTC  }]
Oct 22 00:38:39.598: INFO: 
Oct 22 00:38:39.598: INFO: StatefulSet ss has not reached scale 0, at 3
Oct 22 00:38:40.605: INFO: POD   NODE                                 PHASE    GRACE  CONDITIONS
Oct 22 00:38:40.605: INFO: ss-0  mip-bd-vm40.mip.storage.hpecorp.net  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:37:44 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:38:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:38:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:37:44 +0000 UTC  }]
Oct 22 00:38:40.605: INFO: ss-1  mip-bd-vm41.mip.storage.hpecorp.net  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:38:04 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:38:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:38:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:38:04 +0000 UTC  }]
Oct 22 00:38:40.605: INFO: ss-2  mip-bd-vm41.mip.storage.hpecorp.net  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:38:04 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:38:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:38:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:38:04 +0000 UTC  }]
Oct 22 00:38:40.605: INFO: 
Oct 22 00:38:40.605: INFO: StatefulSet ss has not reached scale 0, at 3
Oct 22 00:38:41.611: INFO: POD   NODE                                 PHASE    GRACE  CONDITIONS
Oct 22 00:38:41.611: INFO: ss-1  mip-bd-vm41.mip.storage.hpecorp.net  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:38:04 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:38:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:38:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:38:04 +0000 UTC  }]
Oct 22 00:38:41.611: INFO: ss-2  mip-bd-vm41.mip.storage.hpecorp.net  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:38:04 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:38:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:38:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:38:04 +0000 UTC  }]
Oct 22 00:38:41.611: INFO: 
Oct 22 00:38:41.611: INFO: StatefulSet ss has not reached scale 0, at 2
Oct 22 00:38:42.617: INFO: POD   NODE                                 PHASE    GRACE  CONDITIONS
Oct 22 00:38:42.617: INFO: ss-1  mip-bd-vm41.mip.storage.hpecorp.net  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:38:04 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:38:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:38:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:38:04 +0000 UTC  }]
Oct 22 00:38:42.617: INFO: ss-2  mip-bd-vm41.mip.storage.hpecorp.net  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:38:04 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:38:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:38:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:38:04 +0000 UTC  }]
Oct 22 00:38:42.618: INFO: 
Oct 22 00:38:42.618: INFO: StatefulSet ss has not reached scale 0, at 2
Oct 22 00:38:43.624: INFO: POD   NODE                                 PHASE    GRACE  CONDITIONS
Oct 22 00:38:43.624: INFO: ss-1  mip-bd-vm41.mip.storage.hpecorp.net  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:38:04 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:38:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:38:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:38:04 +0000 UTC  }]
Oct 22 00:38:43.624: INFO: ss-2  mip-bd-vm41.mip.storage.hpecorp.net  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:38:04 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:38:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:38:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:38:04 +0000 UTC  }]
Oct 22 00:38:43.624: INFO: 
Oct 22 00:38:43.624: INFO: StatefulSet ss has not reached scale 0, at 2
Oct 22 00:38:44.631: INFO: POD   NODE                                 PHASE    GRACE  CONDITIONS
Oct 22 00:38:44.631: INFO: ss-1  mip-bd-vm41.mip.storage.hpecorp.net  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:38:04 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:38:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:38:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:38:04 +0000 UTC  }]
Oct 22 00:38:44.631: INFO: ss-2  mip-bd-vm41.mip.storage.hpecorp.net  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:38:04 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:38:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:38:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:38:04 +0000 UTC  }]
Oct 22 00:38:44.631: INFO: 
Oct 22 00:38:44.631: INFO: StatefulSet ss has not reached scale 0, at 2
Oct 22 00:38:45.636: INFO: POD   NODE                                 PHASE    GRACE  CONDITIONS
Oct 22 00:38:45.636: INFO: ss-1  mip-bd-vm41.mip.storage.hpecorp.net  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:38:04 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:38:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:38:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:38:04 +0000 UTC  }]
Oct 22 00:38:45.637: INFO: ss-2  mip-bd-vm41.mip.storage.hpecorp.net  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:38:04 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:38:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:38:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:38:04 +0000 UTC  }]
Oct 22 00:38:45.637: INFO: 
Oct 22 00:38:45.637: INFO: StatefulSet ss has not reached scale 0, at 2
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-9166
Oct 22 00:38:46.643: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 exec --namespace=statefulset-9166 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 22 00:38:46.864: INFO: rc: 1
Oct 22 00:38:46.865: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-172996996 exec --namespace=statefulset-9166 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  error: unable to upgrade connection: container not found ("nginx")
 [] <nil> 0xc001089a40 exit status 1 <nil> <nil> true [0xc00227e1f8 0xc00227e210 0xc00227e228] [0xc00227e1f8 0xc00227e210 0xc00227e228] [0xc00227e208 0xc00227e220] [0x9d21f0 0x9d21f0] 0xc002badc80 <nil>}:
Command stdout:

stderr:
error: unable to upgrade connection: container not found ("nginx")

error:
exit status 1
Oct 22 00:38:56.865: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 exec --namespace=statefulset-9166 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 22 00:38:57.039: INFO: rc: 1
Oct 22 00:38:57.039: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-172996996 exec --namespace=statefulset-9166 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc001c143c0 exit status 1 <nil> <nil> true [0xc001ceb6b0 0xc001ceb718 0xc001ceb798] [0xc001ceb6b0 0xc001ceb718 0xc001ceb798] [0xc001ceb710 0xc001ceb740] [0x9d21f0 0x9d21f0] 0xc002486d80 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Oct 22 00:39:07.039: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 exec --namespace=statefulset-9166 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 22 00:39:07.210: INFO: rc: 1
Oct 22 00:39:07.210: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-172996996 exec --namespace=statefulset-9166 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc00241a330 exit status 1 <nil> <nil> true [0xc000182000 0xc0001820e8 0xc0001821c0] [0xc000182000 0xc0001820e8 0xc0001821c0] [0xc0001820c8 0xc000182180] [0x9d21f0 0x9d21f0] 0xc001d182a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Oct 22 00:39:17.210: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 exec --namespace=statefulset-9166 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 22 00:39:17.365: INFO: rc: 1
Oct 22 00:39:17.365: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-172996996 exec --namespace=statefulset-9166 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc00365be90 exit status 1 <nil> <nil> true [0xc0027c81f0 0xc0027c8218 0xc0027c8260] [0xc0027c81f0 0xc0027c8218 0xc0027c8260] [0xc0027c8208 0xc0027c8250] [0x9d21f0 0x9d21f0] 0xc003755260 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Oct 22 00:39:27.366: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 exec --namespace=statefulset-9166 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 22 00:39:27.528: INFO: rc: 1
Oct 22 00:39:27.528: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-172996996 exec --namespace=statefulset-9166 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc001c14750 exit status 1 <nil> <nil> true [0xc001ceb7a8 0xc001ceb7f8 0xc001ceb818] [0xc001ceb7a8 0xc001ceb7f8 0xc001ceb818] [0xc001ceb7d8 0xc001ceb808] [0x9d21f0 0x9d21f0] 0xc0024870e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Oct 22 00:39:37.528: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 exec --namespace=statefulset-9166 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 22 00:39:37.696: INFO: rc: 1
Oct 22 00:39:37.696: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-172996996 exec --namespace=statefulset-9166 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc001c14ab0 exit status 1 <nil> <nil> true [0xc001ceb828 0xc001ceb928 0xc001ceb9f8] [0xc001ceb828 0xc001ceb928 0xc001ceb9f8] [0xc001ceb8d8 0xc001ceb948] [0x9d21f0 0x9d21f0] 0xc002487440 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Oct 22 00:39:47.697: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 exec --namespace=statefulset-9166 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 22 00:39:47.864: INFO: rc: 1
Oct 22 00:39:47.864: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-172996996 exec --namespace=statefulset-9166 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc001089e00 exit status 1 <nil> <nil> true [0xc00227e238 0xc00227e250 0xc00227e268] [0xc00227e238 0xc00227e250 0xc00227e268] [0xc00227e248 0xc00227e260] [0x9d21f0 0x9d21f0] 0xc003556000 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Oct 22 00:39:57.864: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 exec --namespace=statefulset-9166 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 22 00:39:58.032: INFO: rc: 1
Oct 22 00:39:58.032: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-172996996 exec --namespace=statefulset-9166 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc000ac4360 exit status 1 <nil> <nil> true [0xc0000102f8 0xc00064b8a0 0xc00064b940] [0xc0000102f8 0xc00064b8a0 0xc00064b940] [0xc00064b7c0 0xc00064b908] [0x9d21f0 0x9d21f0] 0xc001ea2720 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Oct 22 00:40:08.032: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 exec --namespace=statefulset-9166 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 22 00:40:08.194: INFO: rc: 1
Oct 22 00:40:08.194: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-172996996 exec --namespace=statefulset-9166 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc00373c360 exit status 1 <nil> <nil> true [0xc0005963a0 0xc0005964e0 0xc000596b90] [0xc0005963a0 0xc0005964e0 0xc000596b90] [0xc000596418 0xc000596b68] [0x9d21f0 0x9d21f0] 0xc00368a2a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Oct 22 00:40:18.194: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 exec --namespace=statefulset-9166 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 22 00:40:18.345: INFO: rc: 1
Oct 22 00:40:18.345: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-172996996 exec --namespace=statefulset-9166 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc002aaa5d0 exit status 1 <nil> <nil> true [0xc000210148 0xc0002116c0 0xc000211d68] [0xc000210148 0xc0002116c0 0xc000211d68] [0xc000211418 0xc000211bb0] [0x9d21f0 0x9d21f0] 0xc002bac4e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Oct 22 00:40:28.346: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 exec --namespace=statefulset-9166 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 22 00:40:28.509: INFO: rc: 1
Oct 22 00:40:28.509: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-172996996 exec --namespace=statefulset-9166 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc000ac4720 exit status 1 <nil> <nil> true [0xc00064b9f8 0xc00064bb80 0xc00064bcf0] [0xc00064b9f8 0xc00064bb80 0xc00064bcf0] [0xc00064bb50 0xc00064bc60] [0x9d21f0 0x9d21f0] 0xc001ea2e40 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Oct 22 00:40:38.509: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 exec --namespace=statefulset-9166 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 22 00:40:38.682: INFO: rc: 1
Oct 22 00:40:38.682: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-172996996 exec --namespace=statefulset-9166 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc00373c780 exit status 1 <nil> <nil> true [0xc000596bb0 0xc000596fd8 0xc0005970e8] [0xc000596bb0 0xc000596fd8 0xc0005970e8] [0xc000596ef8 0xc0005970d0] [0x9d21f0 0x9d21f0] 0xc00368a780 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Oct 22 00:40:48.683: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 exec --namespace=statefulset-9166 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 22 00:40:48.858: INFO: rc: 1
Oct 22 00:40:48.858: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-172996996 exec --namespace=statefulset-9166 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc000ac4ab0 exit status 1 <nil> <nil> true [0xc00064bd90 0xc00064bee0 0xc00227e008] [0xc00064bd90 0xc00064bee0 0xc00227e008] [0xc00064be90 0xc00227e000] [0x9d21f0 0x9d21f0] 0xc001ea3500 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Oct 22 00:40:58.858: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 exec --namespace=statefulset-9166 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 22 00:40:59.024: INFO: rc: 1
Oct 22 00:40:59.024: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-172996996 exec --namespace=statefulset-9166 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc00373cb10 exit status 1 <nil> <nil> true [0xc0005970f8 0xc000597298 0xc000597408] [0xc0005970f8 0xc000597298 0xc000597408] [0xc000597248 0xc000597380] [0x9d21f0 0x9d21f0] 0xc00368ae40 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Oct 22 00:41:09.024: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 exec --namespace=statefulset-9166 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 22 00:41:09.194: INFO: rc: 1
Oct 22 00:41:09.194: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-172996996 exec --namespace=statefulset-9166 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc000ac4e10 exit status 1 <nil> <nil> true [0xc00227e010 0xc00227e028 0xc00227e040] [0xc00227e010 0xc00227e028 0xc00227e040] [0xc00227e020 0xc00227e038] [0x9d21f0 0x9d21f0] 0xc001ea3e00 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Oct 22 00:41:19.195: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 exec --namespace=statefulset-9166 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 22 00:41:19.352: INFO: rc: 1
Oct 22 00:41:19.352: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-172996996 exec --namespace=statefulset-9166 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc000ac51d0 exit status 1 <nil> <nil> true [0xc00227e048 0xc00227e060 0xc00227e078] [0xc00227e048 0xc00227e060 0xc00227e078] [0xc00227e058 0xc00227e070] [0x9d21f0 0x9d21f0] 0xc003556300 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Oct 22 00:41:29.352: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 exec --namespace=statefulset-9166 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 22 00:41:29.508: INFO: rc: 1
Oct 22 00:41:29.508: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-172996996 exec --namespace=statefulset-9166 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc00373ced0 exit status 1 <nil> <nil> true [0xc000597440 0xc0005974c8 0xc0005976d0] [0xc000597440 0xc0005974c8 0xc0005976d0] [0xc000597478 0xc000597610] [0x9d21f0 0x9d21f0] 0xc00368b260 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Oct 22 00:41:39.508: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 exec --namespace=statefulset-9166 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 22 00:41:39.677: INFO: rc: 1
Oct 22 00:41:39.677: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-172996996 exec --namespace=statefulset-9166 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc00373d230 exit status 1 <nil> <nil> true [0xc000597750 0xc000597858 0xc000597938] [0xc000597750 0xc000597858 0xc000597938] [0xc000597818 0xc0005978d8] [0x9d21f0 0x9d21f0] 0xc00368b5c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Oct 22 00:41:49.677: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 exec --namespace=statefulset-9166 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 22 00:41:49.841: INFO: rc: 1
Oct 22 00:41:49.841: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-172996996 exec --namespace=statefulset-9166 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc002aaa600 exit status 1 <nil> <nil> true [0xc00064b7c0 0xc00064b908 0xc00064bab8] [0xc00064b7c0 0xc00064b908 0xc00064bab8] [0xc00064b8c8 0xc00064b9f8] [0x9d21f0 0x9d21f0] 0xc001ea2600 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Oct 22 00:41:59.842: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 exec --namespace=statefulset-9166 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 22 00:42:00.005: INFO: rc: 1
Oct 22 00:42:00.005: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-172996996 exec --namespace=statefulset-9166 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc00373c390 exit status 1 <nil> <nil> true [0xc0000102f8 0xc000211418 0xc000211bb0] [0xc0000102f8 0xc000211418 0xc000211bb0] [0xc000210d40 0xc0002117f0] [0x9d21f0 0x9d21f0] 0xc002bac600 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Oct 22 00:42:10.006: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 exec --namespace=statefulset-9166 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 22 00:42:10.172: INFO: rc: 1
Oct 22 00:42:10.173: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-172996996 exec --namespace=statefulset-9166 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc00373c750 exit status 1 <nil> <nil> true [0xc000211d68 0xc000211fb0 0xc000596418] [0xc000211d68 0xc000211fb0 0xc000596418] [0xc000211f38 0xc000596408] [0x9d21f0 0x9d21f0] 0xc002baca20 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Oct 22 00:42:20.173: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 exec --namespace=statefulset-9166 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 22 00:42:20.339: INFO: rc: 1
Oct 22 00:42:20.339: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-172996996 exec --namespace=statefulset-9166 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc000ac4390 exit status 1 <nil> <nil> true [0xc00227e000 0xc00227e018 0xc00227e030] [0xc00227e000 0xc00227e018 0xc00227e030] [0xc00227e010 0xc00227e028] [0x9d21f0 0x9d21f0] 0xc0035562a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Oct 22 00:42:30.339: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 exec --namespace=statefulset-9166 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 22 00:42:30.501: INFO: rc: 1
Oct 22 00:42:30.501: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-172996996 exec --namespace=statefulset-9166 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc0021b4360 exit status 1 <nil> <nil> true [0xc000182000 0xc0001820e8 0xc0001821c0] [0xc000182000 0xc0001820e8 0xc0001821c0] [0xc0001820c8 0xc000182180] [0x9d21f0 0x9d21f0] 0xc00368a2a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Oct 22 00:42:40.501: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 exec --namespace=statefulset-9166 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 22 00:42:40.661: INFO: rc: 1
Oct 22 00:42:40.661: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-172996996 exec --namespace=statefulset-9166 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc002aaa9f0 exit status 1 <nil> <nil> true [0xc00064bb50 0xc00064bc60 0xc00064bdf0] [0xc00064bb50 0xc00064bc60 0xc00064bdf0] [0xc00064bc18 0xc00064bd90] [0x9d21f0 0x9d21f0] 0xc001ea2d80 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Oct 22 00:42:50.661: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 exec --namespace=statefulset-9166 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 22 00:42:50.837: INFO: rc: 1
Oct 22 00:42:50.837: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-172996996 exec --namespace=statefulset-9166 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc002aaad80 exit status 1 <nil> <nil> true [0xc00064be90 0xc001cea108 0xc001cea1e0] [0xc00064be90 0xc001cea108 0xc001cea1e0] [0xc00064bf78 0xc001cea148] [0x9d21f0 0x9d21f0] 0xc001ea3440 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Oct 22 00:43:00.837: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 exec --namespace=statefulset-9166 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 22 00:43:01.003: INFO: rc: 1
Oct 22 00:43:01.003: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-172996996 exec --namespace=statefulset-9166 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc002aab0e0 exit status 1 <nil> <nil> true [0xc001cea240 0xc001cea2c8 0xc001cea2e0] [0xc001cea240 0xc001cea2c8 0xc001cea2e0] [0xc001cea2c0 0xc001cea2d8] [0x9d21f0 0x9d21f0] 0xc001ea3d40 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Oct 22 00:43:11.004: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 exec --namespace=statefulset-9166 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 22 00:43:11.162: INFO: rc: 1
Oct 22 00:43:11.162: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-172996996 exec --namespace=statefulset-9166 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc002aab440 exit status 1 <nil> <nil> true [0xc001cea398 0xc001cea458 0xc001cea5f0] [0xc001cea398 0xc001cea458 0xc001cea5f0] [0xc001cea430 0xc001cea558] [0x9d21f0 0x9d21f0] 0xc001d181e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Oct 22 00:43:21.163: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 exec --namespace=statefulset-9166 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 22 00:43:21.327: INFO: rc: 1
Oct 22 00:43:21.328: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-172996996 exec --namespace=statefulset-9166 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc002aab7d0 exit status 1 <nil> <nil> true [0xc001cea668 0xc001cea718 0xc001cea7a8] [0xc001cea668 0xc001cea718 0xc001cea7a8] [0xc001cea710 0xc001cea748] [0x9d21f0 0x9d21f0] 0xc001d18540 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Oct 22 00:43:31.328: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 exec --namespace=statefulset-9166 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 22 00:43:31.487: INFO: rc: 1
Oct 22 00:43:31.487: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-172996996 exec --namespace=statefulset-9166 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc000ac47e0 exit status 1 <nil> <nil> true [0xc00227e038 0xc00227e050 0xc00227e068] [0xc00227e038 0xc00227e050 0xc00227e068] [0xc00227e048 0xc00227e060] [0x9d21f0 0x9d21f0] 0xc003556660 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Oct 22 00:43:41.487: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 exec --namespace=statefulset-9166 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 22 00:43:41.646: INFO: rc: 1
Oct 22 00:43:41.646: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-172996996 exec --namespace=statefulset-9166 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc000ac4ba0 exit status 1 <nil> <nil> true [0xc00227e070 0xc00227e088 0xc00227e0a0] [0xc00227e070 0xc00227e088 0xc00227e0a0] [0xc00227e080 0xc00227e098] [0x9d21f0 0x9d21f0] 0xc0035569c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Oct 22 00:43:51.648: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 exec --namespace=statefulset-9166 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 22 00:43:51.815: INFO: rc: 1
Oct 22 00:43:51.815: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: 
Oct 22 00:43:51.815: INFO: Scaling statefulset ss to 0
Oct 22 00:43:51.833: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Oct 22 00:43:51.838: INFO: Deleting all statefulset in ns statefulset-9166
Oct 22 00:43:51.842: INFO: Scaling statefulset ss to 0
Oct 22 00:43:51.853: INFO: Waiting for statefulset status.replicas updated to 0
Oct 22 00:43:51.856: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 00:43:51.879: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-9166" for this suite.
Oct 22 00:44:05.908: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 00:44:06.071: INFO: namespace statefulset-9166 deletion completed in 14.185061248s

• [SLOW TEST:381.930 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 00:44:06.072: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-2c0b93f4-dce5-40ac-8066-a9a71f57dc8b
STEP: Creating a pod to test consume configMaps
Oct 22 00:44:06.129: INFO: Waiting up to 5m0s for pod "pod-configmaps-37730988-9ed4-4c75-9963-9a5a257b91c6" in namespace "configmap-9833" to be "success or failure"
Oct 22 00:44:06.134: INFO: Pod "pod-configmaps-37730988-9ed4-4c75-9963-9a5a257b91c6": Phase="Pending", Reason="", readiness=false. Elapsed: 4.802293ms
Oct 22 00:44:08.140: INFO: Pod "pod-configmaps-37730988-9ed4-4c75-9963-9a5a257b91c6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011112545s
Oct 22 00:44:10.145: INFO: Pod "pod-configmaps-37730988-9ed4-4c75-9963-9a5a257b91c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016371675s
STEP: Saw pod success
Oct 22 00:44:10.145: INFO: Pod "pod-configmaps-37730988-9ed4-4c75-9963-9a5a257b91c6" satisfied condition "success or failure"
Oct 22 00:44:10.149: INFO: Trying to get logs from node mip-bd-vm41.mip.storage.hpecorp.net pod pod-configmaps-37730988-9ed4-4c75-9963-9a5a257b91c6 container configmap-volume-test: <nil>
STEP: delete the pod
Oct 22 00:44:10.178: INFO: Waiting for pod pod-configmaps-37730988-9ed4-4c75-9963-9a5a257b91c6 to disappear
Oct 22 00:44:10.182: INFO: Pod pod-configmaps-37730988-9ed4-4c75-9963-9a5a257b91c6 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 00:44:10.182: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9833" for this suite.
Oct 22 00:44:16.204: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 00:44:16.351: INFO: namespace configmap-9833 deletion completed in 6.162869314s

• [SLOW TEST:10.279 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 00:44:16.351: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1457
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Oct 22 00:44:16.396: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=kubectl-259'
Oct 22 00:44:16.575: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Oct 22 00:44:16.575: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: verifying the pod controlled by rc e2e-test-nginx-rc was created
STEP: confirm that you can get logs from an rc
Oct 22 00:44:16.591: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-znvfv]
Oct 22 00:44:16.591: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-znvfv" in namespace "kubectl-259" to be "running and ready"
Oct 22 00:44:16.595: INFO: Pod "e2e-test-nginx-rc-znvfv": Phase="Pending", Reason="", readiness=false. Elapsed: 4.062179ms
Oct 22 00:44:18.599: INFO: Pod "e2e-test-nginx-rc-znvfv": Phase="Running", Reason="", readiness=true. Elapsed: 2.008211161s
Oct 22 00:44:18.599: INFO: Pod "e2e-test-nginx-rc-znvfv" satisfied condition "running and ready"
Oct 22 00:44:18.599: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-znvfv]
Oct 22 00:44:18.599: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 logs rc/e2e-test-nginx-rc --namespace=kubectl-259'
Oct 22 00:44:18.792: INFO: stderr: ""
Oct 22 00:44:18.792: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1462
Oct 22 00:44:18.792: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 delete rc e2e-test-nginx-rc --namespace=kubectl-259'
Oct 22 00:44:18.962: INFO: stderr: ""
Oct 22 00:44:18.963: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 00:44:18.963: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-259" for this suite.
Oct 22 00:44:40.988: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 00:44:41.130: INFO: namespace kubectl-259 deletion completed in 22.161013923s

• [SLOW TEST:24.779 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run rc
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 00:44:41.130: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl label
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1211
STEP: creating the pod
Oct 22 00:44:41.177: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 create -f - --namespace=kubectl-4624'
Oct 22 00:44:41.619: INFO: stderr: ""
Oct 22 00:44:41.619: INFO: stdout: "pod/pause created\n"
Oct 22 00:44:41.619: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Oct 22 00:44:41.619: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-4624" to be "running and ready"
Oct 22 00:44:41.627: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 7.589283ms
Oct 22 00:44:43.632: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.013259894s
Oct 22 00:44:43.632: INFO: Pod "pause" satisfied condition "running and ready"
Oct 22 00:44:43.632: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: adding the label testing-label with value testing-label-value to a pod
Oct 22 00:44:43.633: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 label pods pause testing-label=testing-label-value --namespace=kubectl-4624'
Oct 22 00:44:43.803: INFO: stderr: ""
Oct 22 00:44:43.803: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Oct 22 00:44:43.803: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 get pod pause -L testing-label --namespace=kubectl-4624'
Oct 22 00:44:43.967: INFO: stderr: ""
Oct 22 00:44:43.967: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Oct 22 00:44:43.967: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 label pods pause testing-label- --namespace=kubectl-4624'
Oct 22 00:44:44.135: INFO: stderr: ""
Oct 22 00:44:44.135: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Oct 22 00:44:44.135: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 get pod pause -L testing-label --namespace=kubectl-4624'
Oct 22 00:44:44.296: INFO: stderr: ""
Oct 22 00:44:44.296: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          3s    \n"
[AfterEach] [k8s.io] Kubectl label
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1218
STEP: using delete to clean up resources
Oct 22 00:44:44.297: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 delete --grace-period=0 --force -f - --namespace=kubectl-4624'
Oct 22 00:44:44.466: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct 22 00:44:44.466: INFO: stdout: "pod \"pause\" force deleted\n"
Oct 22 00:44:44.467: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 get rc,svc -l name=pause --no-headers --namespace=kubectl-4624'
Oct 22 00:44:44.644: INFO: stderr: "No resources found.\n"
Oct 22 00:44:44.644: INFO: stdout: ""
Oct 22 00:44:44.644: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 get pods -l name=pause --namespace=kubectl-4624 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Oct 22 00:44:44.805: INFO: stderr: ""
Oct 22 00:44:44.805: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 00:44:44.805: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4624" for this suite.
Oct 22 00:44:50.830: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 00:44:51.001: INFO: namespace kubectl-4624 deletion completed in 6.189174569s

• [SLOW TEST:9.871 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl label
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 00:44:51.001: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0644 on node default medium
Oct 22 00:44:51.060: INFO: Waiting up to 5m0s for pod "pod-ded8d2e6-2f87-4965-8b49-91ece300349b" in namespace "emptydir-7734" to be "success or failure"
Oct 22 00:44:51.064: INFO: Pod "pod-ded8d2e6-2f87-4965-8b49-91ece300349b": Phase="Pending", Reason="", readiness=false. Elapsed: 3.877882ms
Oct 22 00:44:53.069: INFO: Pod "pod-ded8d2e6-2f87-4965-8b49-91ece300349b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009291731s
STEP: Saw pod success
Oct 22 00:44:53.069: INFO: Pod "pod-ded8d2e6-2f87-4965-8b49-91ece300349b" satisfied condition "success or failure"
Oct 22 00:44:53.073: INFO: Trying to get logs from node mip-bd-vm40.mip.storage.hpecorp.net pod pod-ded8d2e6-2f87-4965-8b49-91ece300349b container test-container: <nil>
STEP: delete the pod
Oct 22 00:44:53.098: INFO: Waiting for pod pod-ded8d2e6-2f87-4965-8b49-91ece300349b to disappear
Oct 22 00:44:53.102: INFO: Pod pod-ded8d2e6-2f87-4965-8b49-91ece300349b no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 00:44:53.102: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7734" for this suite.
Oct 22 00:44:59.124: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 00:44:59.276: INFO: namespace emptydir-7734 deletion completed in 6.168142533s

• [SLOW TEST:8.274 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 00:44:59.276: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:81
Oct 22 00:44:59.323: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Oct 22 00:44:59.333: INFO: Waiting for terminating namespaces to be deleted...
Oct 22 00:44:59.338: INFO: 
Logging pods the kubelet thinks is on node mip-bd-vm40.mip.storage.hpecorp.net before test
Oct 22 00:44:59.347: INFO: kubedirector-fsmount-gfmbk from kube-system started at 2019-10-21 22:12:39 +0000 UTC (1 container statuses recorded)
Oct 22 00:44:59.347: INFO: 	Container kubedirector-fsmount ready: true, restart count 0
Oct 22 00:44:59.347: INFO: sonobuoy-systemd-logs-daemon-set-d36ba0a04f4c410a-66d8l from heptio-sonobuoy started at 2019-10-21 23:53:49 +0000 UTC (2 container statuses recorded)
Oct 22 00:44:59.347: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct 22 00:44:59.347: INFO: 	Container systemd-logs ready: true, restart count 0
Oct 22 00:44:59.347: INFO: kube-proxy-p4s2t from kube-system started at 2019-10-21 22:10:33 +0000 UTC (1 container statuses recorded)
Oct 22 00:44:59.347: INFO: 	Container kube-proxy ready: true, restart count 0
Oct 22 00:44:59.347: INFO: kubedirector-6466dc856f-mh7mk from kube-system started at 2019-10-21 22:11:04 +0000 UTC (1 container statuses recorded)
Oct 22 00:44:59.347: INFO: 	Container kubedirector ready: true, restart count 0
Oct 22 00:44:59.347: INFO: canal-r9n5g from kube-system started at 2019-10-21 22:11:11 +0000 UTC (3 container statuses recorded)
Oct 22 00:44:59.347: INFO: 	Container calico-node ready: true, restart count 0
Oct 22 00:44:59.347: INFO: 	Container install-cni ready: true, restart count 0
Oct 22 00:44:59.347: INFO: 	Container kube-flannel ready: true, restart count 0
Oct 22 00:44:59.347: INFO: sonobuoy-e2e-job-d7290e8bc6084643 from heptio-sonobuoy started at 2019-10-21 23:53:49 +0000 UTC (2 container statuses recorded)
Oct 22 00:44:59.347: INFO: 	Container e2e ready: true, restart count 0
Oct 22 00:44:59.347: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct 22 00:44:59.347: INFO: 
Logging pods the kubelet thinks is on node mip-bd-vm41.mip.storage.hpecorp.net before test
Oct 22 00:44:59.356: INFO: kube-state-metrics-549d594744-hlwrw from kube-system started at 2019-10-21 22:11:00 +0000 UTC (1 container statuses recorded)
Oct 22 00:44:59.356: INFO: 	Container kube-state-metrics ready: true, restart count 0
Oct 22 00:44:59.356: INFO: canal-7vsf6 from kube-system started at 2019-10-21 22:11:11 +0000 UTC (3 container statuses recorded)
Oct 22 00:44:59.356: INFO: 	Container calico-node ready: true, restart count 0
Oct 22 00:44:59.356: INFO: 	Container install-cni ready: true, restart count 0
Oct 22 00:44:59.356: INFO: 	Container kube-flannel ready: true, restart count 0
Oct 22 00:44:59.356: INFO: sonobuoy-systemd-logs-daemon-set-d36ba0a04f4c410a-4nk8z from heptio-sonobuoy started at 2019-10-21 23:53:49 +0000 UTC (2 container statuses recorded)
Oct 22 00:44:59.356: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct 22 00:44:59.356: INFO: 	Container systemd-logs ready: true, restart count 0
Oct 22 00:44:59.356: INFO: kube-proxy-lc4z4 from kube-system started at 2019-10-21 22:10:31 +0000 UTC (1 container statuses recorded)
Oct 22 00:44:59.356: INFO: 	Container kube-proxy ready: true, restart count 0
Oct 22 00:44:59.356: INFO: sonobuoy from heptio-sonobuoy started at 2019-10-21 23:53:46 +0000 UTC (1 container statuses recorded)
Oct 22 00:44:59.356: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Oct 22 00:44:59.356: INFO: kubedirector-fsmount-vgwfc from kube-system started at 2019-10-21 22:12:39 +0000 UTC (1 container statuses recorded)
Oct 22 00:44:59.356: INFO: 	Container kubedirector-fsmount ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.15cfd175ec68e7e0], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 00:45:00.388: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-2613" for this suite.
Oct 22 00:45:06.411: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 00:45:06.576: INFO: namespace sched-pred-2613 deletion completed in 6.181750374s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:72

• [SLOW TEST:7.300 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 00:45:06.577: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-map-1785f342-71d5-4f8b-b734-c4446740c1bc
STEP: Creating a pod to test consume configMaps
Oct 22 00:45:06.637: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-43c43b2f-0558-47a7-a9f8-6de84e5eba84" in namespace "projected-6375" to be "success or failure"
Oct 22 00:45:06.642: INFO: Pod "pod-projected-configmaps-43c43b2f-0558-47a7-a9f8-6de84e5eba84": Phase="Pending", Reason="", readiness=false. Elapsed: 4.784513ms
Oct 22 00:45:08.647: INFO: Pod "pod-projected-configmaps-43c43b2f-0558-47a7-a9f8-6de84e5eba84": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010347144s
STEP: Saw pod success
Oct 22 00:45:08.647: INFO: Pod "pod-projected-configmaps-43c43b2f-0558-47a7-a9f8-6de84e5eba84" satisfied condition "success or failure"
Oct 22 00:45:08.651: INFO: Trying to get logs from node mip-bd-vm41.mip.storage.hpecorp.net pod pod-projected-configmaps-43c43b2f-0558-47a7-a9f8-6de84e5eba84 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Oct 22 00:45:08.683: INFO: Waiting for pod pod-projected-configmaps-43c43b2f-0558-47a7-a9f8-6de84e5eba84 to disappear
Oct 22 00:45:08.686: INFO: Pod pod-projected-configmaps-43c43b2f-0558-47a7-a9f8-6de84e5eba84 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 00:45:08.687: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6375" for this suite.
Oct 22 00:45:14.721: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 00:45:14.885: INFO: namespace projected-6375 deletion completed in 6.193889732s

• [SLOW TEST:8.308 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 00:45:14.885: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Oct 22 00:45:14.944: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d10a405d-2ac2-489d-b653-ed2f50b97bfa" in namespace "downward-api-3735" to be "success or failure"
Oct 22 00:45:14.951: INFO: Pod "downwardapi-volume-d10a405d-2ac2-489d-b653-ed2f50b97bfa": Phase="Pending", Reason="", readiness=false. Elapsed: 6.373906ms
Oct 22 00:45:16.956: INFO: Pod "downwardapi-volume-d10a405d-2ac2-489d-b653-ed2f50b97bfa": Phase="Running", Reason="", readiness=true. Elapsed: 2.011500135s
Oct 22 00:45:18.961: INFO: Pod "downwardapi-volume-d10a405d-2ac2-489d-b653-ed2f50b97bfa": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017277639s
STEP: Saw pod success
Oct 22 00:45:18.962: INFO: Pod "downwardapi-volume-d10a405d-2ac2-489d-b653-ed2f50b97bfa" satisfied condition "success or failure"
Oct 22 00:45:18.966: INFO: Trying to get logs from node mip-bd-vm40.mip.storage.hpecorp.net pod downwardapi-volume-d10a405d-2ac2-489d-b653-ed2f50b97bfa container client-container: <nil>
STEP: delete the pod
Oct 22 00:45:18.995: INFO: Waiting for pod downwardapi-volume-d10a405d-2ac2-489d-b653-ed2f50b97bfa to disappear
Oct 22 00:45:18.998: INFO: Pod downwardapi-volume-d10a405d-2ac2-489d-b653-ed2f50b97bfa no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 00:45:18.998: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3735" for this suite.
Oct 22 00:45:25.022: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 00:45:25.173: INFO: namespace downward-api-3735 deletion completed in 6.170279008s

• [SLOW TEST:10.289 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 00:45:25.174: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test env composition
Oct 22 00:45:25.229: INFO: Waiting up to 5m0s for pod "var-expansion-50597c78-bbbe-4803-9e78-92ea063c5a1f" in namespace "var-expansion-1306" to be "success or failure"
Oct 22 00:45:25.237: INFO: Pod "var-expansion-50597c78-bbbe-4803-9e78-92ea063c5a1f": Phase="Pending", Reason="", readiness=false. Elapsed: 7.564087ms
Oct 22 00:45:27.243: INFO: Pod "var-expansion-50597c78-bbbe-4803-9e78-92ea063c5a1f": Phase="Running", Reason="", readiness=true. Elapsed: 2.01309403s
Oct 22 00:45:29.248: INFO: Pod "var-expansion-50597c78-bbbe-4803-9e78-92ea063c5a1f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018816464s
STEP: Saw pod success
Oct 22 00:45:29.248: INFO: Pod "var-expansion-50597c78-bbbe-4803-9e78-92ea063c5a1f" satisfied condition "success or failure"
Oct 22 00:45:29.252: INFO: Trying to get logs from node mip-bd-vm41.mip.storage.hpecorp.net pod var-expansion-50597c78-bbbe-4803-9e78-92ea063c5a1f container dapi-container: <nil>
STEP: delete the pod
Oct 22 00:45:29.285: INFO: Waiting for pod var-expansion-50597c78-bbbe-4803-9e78-92ea063c5a1f to disappear
Oct 22 00:45:29.289: INFO: Pod var-expansion-50597c78-bbbe-4803-9e78-92ea063c5a1f no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 00:45:29.289: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-1306" for this suite.
Oct 22 00:45:35.314: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 00:45:35.456: INFO: namespace var-expansion-1306 deletion completed in 6.162582333s

• [SLOW TEST:10.283 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 00:45:35.456: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod test-webserver-1840443e-ee9a-4c63-aee5-0adcc1e0b5fc in namespace container-probe-5592
Oct 22 00:45:37.529: INFO: Started pod test-webserver-1840443e-ee9a-4c63-aee5-0adcc1e0b5fc in namespace container-probe-5592
STEP: checking the pod's current state and verifying that restartCount is present
Oct 22 00:45:37.534: INFO: Initial restart count of pod test-webserver-1840443e-ee9a-4c63-aee5-0adcc1e0b5fc is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 00:49:38.283: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-5592" for this suite.
Oct 22 00:49:44.305: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 00:49:44.454: INFO: namespace container-probe-5592 deletion completed in 6.164195691s

• [SLOW TEST:248.997 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 00:49:44.454: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test override all
Oct 22 00:49:44.509: INFO: Waiting up to 5m0s for pod "client-containers-00ed3d39-4ab7-4629-823e-de0a5ff4c7f0" in namespace "containers-4066" to be "success or failure"
Oct 22 00:49:44.514: INFO: Pod "client-containers-00ed3d39-4ab7-4629-823e-de0a5ff4c7f0": Phase="Pending", Reason="", readiness=false. Elapsed: 4.745858ms
Oct 22 00:49:46.519: INFO: Pod "client-containers-00ed3d39-4ab7-4629-823e-de0a5ff4c7f0": Phase="Running", Reason="", readiness=true. Elapsed: 2.01026809s
Oct 22 00:49:48.525: INFO: Pod "client-containers-00ed3d39-4ab7-4629-823e-de0a5ff4c7f0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015713893s
STEP: Saw pod success
Oct 22 00:49:48.525: INFO: Pod "client-containers-00ed3d39-4ab7-4629-823e-de0a5ff4c7f0" satisfied condition "success or failure"
Oct 22 00:49:48.528: INFO: Trying to get logs from node mip-bd-vm41.mip.storage.hpecorp.net pod client-containers-00ed3d39-4ab7-4629-823e-de0a5ff4c7f0 container test-container: <nil>
STEP: delete the pod
Oct 22 00:49:48.561: INFO: Waiting for pod client-containers-00ed3d39-4ab7-4629-823e-de0a5ff4c7f0 to disappear
Oct 22 00:49:48.564: INFO: Pod client-containers-00ed3d39-4ab7-4629-823e-de0a5ff4c7f0 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 00:49:48.564: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-4066" for this suite.
Oct 22 00:49:54.584: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 00:49:54.731: INFO: namespace containers-4066 deletion completed in 6.161507875s

• [SLOW TEST:10.277 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 00:49:54.731: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Oct 22 00:49:56.828: INFO: Waiting up to 5m0s for pod "client-envvars-84ea3c0b-71de-4673-b853-0486d64ce24b" in namespace "pods-7532" to be "success or failure"
Oct 22 00:49:56.840: INFO: Pod "client-envvars-84ea3c0b-71de-4673-b853-0486d64ce24b": Phase="Pending", Reason="", readiness=false. Elapsed: 11.961988ms
Oct 22 00:49:58.846: INFO: Pod "client-envvars-84ea3c0b-71de-4673-b853-0486d64ce24b": Phase="Running", Reason="", readiness=true. Elapsed: 2.017764731s
Oct 22 00:50:00.851: INFO: Pod "client-envvars-84ea3c0b-71de-4673-b853-0486d64ce24b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023215329s
STEP: Saw pod success
Oct 22 00:50:00.851: INFO: Pod "client-envvars-84ea3c0b-71de-4673-b853-0486d64ce24b" satisfied condition "success or failure"
Oct 22 00:50:00.855: INFO: Trying to get logs from node mip-bd-vm41.mip.storage.hpecorp.net pod client-envvars-84ea3c0b-71de-4673-b853-0486d64ce24b container env3cont: <nil>
STEP: delete the pod
Oct 22 00:50:00.886: INFO: Waiting for pod client-envvars-84ea3c0b-71de-4673-b853-0486d64ce24b to disappear
Oct 22 00:50:00.891: INFO: Pod client-envvars-84ea3c0b-71de-4673-b853-0486d64ce24b no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 00:50:00.892: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-7532" for this suite.
Oct 22 00:50:42.912: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 00:50:43.065: INFO: namespace pods-7532 deletion completed in 42.168753s

• [SLOW TEST:48.334 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 00:50:43.065: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Oct 22 00:50:43.112: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 00:50:45.163: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-7466" for this suite.
Oct 22 00:51:33.185: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 00:51:33.332: INFO: namespace pods-7466 deletion completed in 48.163290124s

• [SLOW TEST:50.267 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 00:51:33.333: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Oct 22 00:51:33.389: INFO: Waiting up to 5m0s for pod "downwardapi-volume-7ff0f1ea-cc63-4733-8404-8f3d94448314" in namespace "downward-api-4656" to be "success or failure"
Oct 22 00:51:33.395: INFO: Pod "downwardapi-volume-7ff0f1ea-cc63-4733-8404-8f3d94448314": Phase="Pending", Reason="", readiness=false. Elapsed: 5.916086ms
Oct 22 00:51:35.401: INFO: Pod "downwardapi-volume-7ff0f1ea-cc63-4733-8404-8f3d94448314": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011844875s
STEP: Saw pod success
Oct 22 00:51:35.401: INFO: Pod "downwardapi-volume-7ff0f1ea-cc63-4733-8404-8f3d94448314" satisfied condition "success or failure"
Oct 22 00:51:35.404: INFO: Trying to get logs from node mip-bd-vm41.mip.storage.hpecorp.net pod downwardapi-volume-7ff0f1ea-cc63-4733-8404-8f3d94448314 container client-container: <nil>
STEP: delete the pod
Oct 22 00:51:35.432: INFO: Waiting for pod downwardapi-volume-7ff0f1ea-cc63-4733-8404-8f3d94448314 to disappear
Oct 22 00:51:35.436: INFO: Pod downwardapi-volume-7ff0f1ea-cc63-4733-8404-8f3d94448314 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 00:51:35.436: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4656" for this suite.
Oct 22 00:51:41.459: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 00:51:41.607: INFO: namespace downward-api-4656 deletion completed in 6.165439461s

• [SLOW TEST:8.275 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 00:51:41.608: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Oct 22 00:51:41.665: INFO: Waiting up to 5m0s for pod "downwardapi-volume-04ea658d-0d1d-4d9a-8b9c-ec207df3da23" in namespace "projected-1470" to be "success or failure"
Oct 22 00:51:41.671: INFO: Pod "downwardapi-volume-04ea658d-0d1d-4d9a-8b9c-ec207df3da23": Phase="Pending", Reason="", readiness=false. Elapsed: 6.12141ms
Oct 22 00:51:43.677: INFO: Pod "downwardapi-volume-04ea658d-0d1d-4d9a-8b9c-ec207df3da23": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011315161s
STEP: Saw pod success
Oct 22 00:51:43.677: INFO: Pod "downwardapi-volume-04ea658d-0d1d-4d9a-8b9c-ec207df3da23" satisfied condition "success or failure"
Oct 22 00:51:43.681: INFO: Trying to get logs from node mip-bd-vm41.mip.storage.hpecorp.net pod downwardapi-volume-04ea658d-0d1d-4d9a-8b9c-ec207df3da23 container client-container: <nil>
STEP: delete the pod
Oct 22 00:51:43.709: INFO: Waiting for pod downwardapi-volume-04ea658d-0d1d-4d9a-8b9c-ec207df3da23 to disappear
Oct 22 00:51:43.715: INFO: Pod downwardapi-volume-04ea658d-0d1d-4d9a-8b9c-ec207df3da23 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 00:51:43.715: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1470" for this suite.
Oct 22 00:51:49.736: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 00:51:49.889: INFO: namespace projected-1470 deletion completed in 6.168941196s

• [SLOW TEST:8.280 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 00:51:49.889: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Oct 22 00:51:49.939: INFO: Waiting up to 5m0s for pod "downwardapi-volume-bbd97428-cb04-4675-b475-1d3fc6c49d75" in namespace "projected-1763" to be "success or failure"
Oct 22 00:51:49.943: INFO: Pod "downwardapi-volume-bbd97428-cb04-4675-b475-1d3fc6c49d75": Phase="Pending", Reason="", readiness=false. Elapsed: 3.605001ms
Oct 22 00:51:51.949: INFO: Pod "downwardapi-volume-bbd97428-cb04-4675-b475-1d3fc6c49d75": Phase="Running", Reason="", readiness=true. Elapsed: 2.009298078s
Oct 22 00:51:53.955: INFO: Pod "downwardapi-volume-bbd97428-cb04-4675-b475-1d3fc6c49d75": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015315564s
STEP: Saw pod success
Oct 22 00:51:53.955: INFO: Pod "downwardapi-volume-bbd97428-cb04-4675-b475-1d3fc6c49d75" satisfied condition "success or failure"
Oct 22 00:51:53.958: INFO: Trying to get logs from node mip-bd-vm41.mip.storage.hpecorp.net pod downwardapi-volume-bbd97428-cb04-4675-b475-1d3fc6c49d75 container client-container: <nil>
STEP: delete the pod
Oct 22 00:51:53.984: INFO: Waiting for pod downwardapi-volume-bbd97428-cb04-4675-b475-1d3fc6c49d75 to disappear
Oct 22 00:51:53.988: INFO: Pod downwardapi-volume-bbd97428-cb04-4675-b475-1d3fc6c49d75 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 00:51:53.988: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1763" for this suite.
Oct 22 00:52:00.009: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 00:52:00.164: INFO: namespace projected-1763 deletion completed in 6.170993226s

• [SLOW TEST:10.275 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 00:52:00.164: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:273
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a replication controller
Oct 22 00:52:00.209: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 create -f - --namespace=kubectl-2304'
Oct 22 00:52:00.551: INFO: stderr: ""
Oct 22 00:52:00.551: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Oct 22 00:52:00.551: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-2304'
Oct 22 00:52:00.715: INFO: stderr: ""
Oct 22 00:52:00.715: INFO: stdout: "update-demo-nautilus-952r5 update-demo-nautilus-rqlwh "
Oct 22 00:52:00.715: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 get pods update-demo-nautilus-952r5 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2304'
Oct 22 00:52:00.872: INFO: stderr: ""
Oct 22 00:52:00.872: INFO: stdout: ""
Oct 22 00:52:00.872: INFO: update-demo-nautilus-952r5 is created but not running
Oct 22 00:52:05.873: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-2304'
Oct 22 00:52:06.044: INFO: stderr: ""
Oct 22 00:52:06.044: INFO: stdout: "update-demo-nautilus-952r5 update-demo-nautilus-rqlwh "
Oct 22 00:52:06.044: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 get pods update-demo-nautilus-952r5 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2304'
Oct 22 00:52:06.229: INFO: stderr: ""
Oct 22 00:52:06.229: INFO: stdout: "true"
Oct 22 00:52:06.229: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 get pods update-demo-nautilus-952r5 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-2304'
Oct 22 00:52:06.391: INFO: stderr: ""
Oct 22 00:52:06.391: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Oct 22 00:52:06.391: INFO: validating pod update-demo-nautilus-952r5
Oct 22 00:52:06.399: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct 22 00:52:06.399: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct 22 00:52:06.399: INFO: update-demo-nautilus-952r5 is verified up and running
Oct 22 00:52:06.399: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 get pods update-demo-nautilus-rqlwh -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2304'
Oct 22 00:52:06.564: INFO: stderr: ""
Oct 22 00:52:06.564: INFO: stdout: "true"
Oct 22 00:52:06.565: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 get pods update-demo-nautilus-rqlwh -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-2304'
Oct 22 00:52:06.726: INFO: stderr: ""
Oct 22 00:52:06.726: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Oct 22 00:52:06.726: INFO: validating pod update-demo-nautilus-rqlwh
Oct 22 00:52:06.734: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct 22 00:52:06.734: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct 22 00:52:06.734: INFO: update-demo-nautilus-rqlwh is verified up and running
STEP: scaling down the replication controller
Oct 22 00:52:06.736: INFO: scanned /root for discovery docs: <nil>
Oct 22 00:52:06.736: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=kubectl-2304'
Oct 22 00:52:07.934: INFO: stderr: ""
Oct 22 00:52:07.934: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Oct 22 00:52:07.934: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-2304'
Oct 22 00:52:08.098: INFO: stderr: ""
Oct 22 00:52:08.098: INFO: stdout: "update-demo-nautilus-952r5 update-demo-nautilus-rqlwh "
STEP: Replicas for name=update-demo: expected=1 actual=2
Oct 22 00:52:13.098: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-2304'
Oct 22 00:52:13.262: INFO: stderr: ""
Oct 22 00:52:13.262: INFO: stdout: "update-demo-nautilus-rqlwh "
Oct 22 00:52:13.262: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 get pods update-demo-nautilus-rqlwh -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2304'
Oct 22 00:52:13.427: INFO: stderr: ""
Oct 22 00:52:13.427: INFO: stdout: "true"
Oct 22 00:52:13.427: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 get pods update-demo-nautilus-rqlwh -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-2304'
Oct 22 00:52:13.582: INFO: stderr: ""
Oct 22 00:52:13.582: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Oct 22 00:52:13.582: INFO: validating pod update-demo-nautilus-rqlwh
Oct 22 00:52:13.589: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct 22 00:52:13.589: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct 22 00:52:13.589: INFO: update-demo-nautilus-rqlwh is verified up and running
STEP: scaling up the replication controller
Oct 22 00:52:13.592: INFO: scanned /root for discovery docs: <nil>
Oct 22 00:52:13.592: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=kubectl-2304'
Oct 22 00:52:14.796: INFO: stderr: ""
Oct 22 00:52:14.796: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Oct 22 00:52:14.796: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-2304'
Oct 22 00:52:14.963: INFO: stderr: ""
Oct 22 00:52:14.963: INFO: stdout: "update-demo-nautilus-nmsm4 update-demo-nautilus-rqlwh "
Oct 22 00:52:14.964: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 get pods update-demo-nautilus-nmsm4 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2304'
Oct 22 00:52:15.122: INFO: stderr: ""
Oct 22 00:52:15.122: INFO: stdout: ""
Oct 22 00:52:15.122: INFO: update-demo-nautilus-nmsm4 is created but not running
Oct 22 00:52:20.122: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-2304'
Oct 22 00:52:20.298: INFO: stderr: ""
Oct 22 00:52:20.298: INFO: stdout: "update-demo-nautilus-nmsm4 update-demo-nautilus-rqlwh "
Oct 22 00:52:20.299: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 get pods update-demo-nautilus-nmsm4 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2304'
Oct 22 00:52:20.462: INFO: stderr: ""
Oct 22 00:52:20.462: INFO: stdout: "true"
Oct 22 00:52:20.462: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 get pods update-demo-nautilus-nmsm4 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-2304'
Oct 22 00:52:20.623: INFO: stderr: ""
Oct 22 00:52:20.623: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Oct 22 00:52:20.623: INFO: validating pod update-demo-nautilus-nmsm4
Oct 22 00:52:20.631: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct 22 00:52:20.631: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct 22 00:52:20.631: INFO: update-demo-nautilus-nmsm4 is verified up and running
Oct 22 00:52:20.631: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 get pods update-demo-nautilus-rqlwh -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2304'
Oct 22 00:52:20.790: INFO: stderr: ""
Oct 22 00:52:20.790: INFO: stdout: "true"
Oct 22 00:52:20.790: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 get pods update-demo-nautilus-rqlwh -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-2304'
Oct 22 00:52:20.950: INFO: stderr: ""
Oct 22 00:52:20.950: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Oct 22 00:52:20.950: INFO: validating pod update-demo-nautilus-rqlwh
Oct 22 00:52:20.956: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct 22 00:52:20.956: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct 22 00:52:20.956: INFO: update-demo-nautilus-rqlwh is verified up and running
STEP: using delete to clean up resources
Oct 22 00:52:20.956: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 delete --grace-period=0 --force -f - --namespace=kubectl-2304'
Oct 22 00:52:21.127: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct 22 00:52:21.127: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Oct 22 00:52:21.127: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-2304'
Oct 22 00:52:21.299: INFO: stderr: "No resources found.\n"
Oct 22 00:52:21.299: INFO: stdout: ""
Oct 22 00:52:21.299: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 get pods -l name=update-demo --namespace=kubectl-2304 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Oct 22 00:52:21.464: INFO: stderr: ""
Oct 22 00:52:21.464: INFO: stdout: "update-demo-nautilus-nmsm4\nupdate-demo-nautilus-rqlwh\n"
Oct 22 00:52:21.964: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-2304'
Oct 22 00:52:22.149: INFO: stderr: "No resources found.\n"
Oct 22 00:52:22.149: INFO: stdout: ""
Oct 22 00:52:22.149: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 get pods -l name=update-demo --namespace=kubectl-2304 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Oct 22 00:52:22.309: INFO: stderr: ""
Oct 22 00:52:22.309: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 00:52:22.309: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2304" for this suite.
Oct 22 00:52:28.331: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 00:52:28.484: INFO: namespace kubectl-2304 deletion completed in 6.17007645s

• [SLOW TEST:28.320 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 00:52:28.485: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a test externalName service
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-3270.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-3270.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-3270.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-3270.svc.cluster.local; sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Oct 22 00:52:32.583: INFO: DNS probes using dns-test-0bdc10ee-cb55-46c0-9bf0-1d789614ca57 succeeded

STEP: deleting the pod
STEP: changing the externalName to bar.example.com
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-3270.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-3270.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-3270.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-3270.svc.cluster.local; sleep 1; done

STEP: creating a second pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Oct 22 00:52:36.643: INFO: File wheezy_udp@dns-test-service-3.dns-3270.svc.cluster.local from pod  dns-3270/dns-test-f29ad0ae-cd0d-4200-91f9-3a1819e9bd69 contains 'foo.example.com.
' instead of 'bar.example.com.'
Oct 22 00:52:36.648: INFO: File jessie_udp@dns-test-service-3.dns-3270.svc.cluster.local from pod  dns-3270/dns-test-f29ad0ae-cd0d-4200-91f9-3a1819e9bd69 contains 'foo.example.com.
' instead of 'bar.example.com.'
Oct 22 00:52:36.648: INFO: Lookups using dns-3270/dns-test-f29ad0ae-cd0d-4200-91f9-3a1819e9bd69 failed for: [wheezy_udp@dns-test-service-3.dns-3270.svc.cluster.local jessie_udp@dns-test-service-3.dns-3270.svc.cluster.local]

Oct 22 00:52:41.655: INFO: File wheezy_udp@dns-test-service-3.dns-3270.svc.cluster.local from pod  dns-3270/dns-test-f29ad0ae-cd0d-4200-91f9-3a1819e9bd69 contains 'foo.example.com.
' instead of 'bar.example.com.'
Oct 22 00:52:41.660: INFO: File jessie_udp@dns-test-service-3.dns-3270.svc.cluster.local from pod  dns-3270/dns-test-f29ad0ae-cd0d-4200-91f9-3a1819e9bd69 contains 'foo.example.com.
' instead of 'bar.example.com.'
Oct 22 00:52:41.660: INFO: Lookups using dns-3270/dns-test-f29ad0ae-cd0d-4200-91f9-3a1819e9bd69 failed for: [wheezy_udp@dns-test-service-3.dns-3270.svc.cluster.local jessie_udp@dns-test-service-3.dns-3270.svc.cluster.local]

Oct 22 00:52:46.655: INFO: File wheezy_udp@dns-test-service-3.dns-3270.svc.cluster.local from pod  dns-3270/dns-test-f29ad0ae-cd0d-4200-91f9-3a1819e9bd69 contains 'foo.example.com.
' instead of 'bar.example.com.'
Oct 22 00:52:46.660: INFO: File jessie_udp@dns-test-service-3.dns-3270.svc.cluster.local from pod  dns-3270/dns-test-f29ad0ae-cd0d-4200-91f9-3a1819e9bd69 contains 'foo.example.com.
' instead of 'bar.example.com.'
Oct 22 00:52:46.660: INFO: Lookups using dns-3270/dns-test-f29ad0ae-cd0d-4200-91f9-3a1819e9bd69 failed for: [wheezy_udp@dns-test-service-3.dns-3270.svc.cluster.local jessie_udp@dns-test-service-3.dns-3270.svc.cluster.local]

Oct 22 00:52:51.655: INFO: File wheezy_udp@dns-test-service-3.dns-3270.svc.cluster.local from pod  dns-3270/dns-test-f29ad0ae-cd0d-4200-91f9-3a1819e9bd69 contains 'foo.example.com.
' instead of 'bar.example.com.'
Oct 22 00:52:51.660: INFO: File jessie_udp@dns-test-service-3.dns-3270.svc.cluster.local from pod  dns-3270/dns-test-f29ad0ae-cd0d-4200-91f9-3a1819e9bd69 contains 'foo.example.com.
' instead of 'bar.example.com.'
Oct 22 00:52:51.660: INFO: Lookups using dns-3270/dns-test-f29ad0ae-cd0d-4200-91f9-3a1819e9bd69 failed for: [wheezy_udp@dns-test-service-3.dns-3270.svc.cluster.local jessie_udp@dns-test-service-3.dns-3270.svc.cluster.local]

Oct 22 00:52:56.655: INFO: File wheezy_udp@dns-test-service-3.dns-3270.svc.cluster.local from pod  dns-3270/dns-test-f29ad0ae-cd0d-4200-91f9-3a1819e9bd69 contains 'foo.example.com.
' instead of 'bar.example.com.'
Oct 22 00:52:56.660: INFO: File jessie_udp@dns-test-service-3.dns-3270.svc.cluster.local from pod  dns-3270/dns-test-f29ad0ae-cd0d-4200-91f9-3a1819e9bd69 contains 'foo.example.com.
' instead of 'bar.example.com.'
Oct 22 00:52:56.660: INFO: Lookups using dns-3270/dns-test-f29ad0ae-cd0d-4200-91f9-3a1819e9bd69 failed for: [wheezy_udp@dns-test-service-3.dns-3270.svc.cluster.local jessie_udp@dns-test-service-3.dns-3270.svc.cluster.local]

Oct 22 00:53:01.660: INFO: DNS probes using dns-test-f29ad0ae-cd0d-4200-91f9-3a1819e9bd69 succeeded

STEP: deleting the pod
STEP: changing the service to type=ClusterIP
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-3270.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-3270.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-3270.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-3270.svc.cluster.local; sleep 1; done

STEP: creating a third pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Oct 22 00:53:05.743: INFO: DNS probes using dns-test-bca946da-58b1-4255-8dfb-732cf20c03e0 succeeded

STEP: deleting the pod
STEP: deleting the test externalName service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 00:53:05.778: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-3270" for this suite.
Oct 22 00:53:11.810: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 00:53:11.958: INFO: namespace dns-3270 deletion completed in 6.171113415s

• [SLOW TEST:43.473 seconds]
[sig-network] DNS
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 00:53:11.958: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1517
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Oct 22 00:53:12.003: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=kubectl-5270'
Oct 22 00:53:12.186: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Oct 22 00:53:12.186: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
Oct 22 00:53:12.199: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 1 spec.replicas 1 status.replicas 0
STEP: rolling-update to same image controller
Oct 22 00:53:12.215: INFO: scanned /root for discovery docs: <nil>
Oct 22 00:53:12.215: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 rolling-update e2e-test-nginx-rc --update-period=1s --image=docker.io/library/nginx:1.14-alpine --image-pull-policy=IfNotPresent --namespace=kubectl-5270'
Oct 22 00:53:28.139: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Oct 22 00:53:28.139: INFO: stdout: "Created e2e-test-nginx-rc-e9d6304b505ed312889d50eb00fd3c66\nScaling up e2e-test-nginx-rc-e9d6304b505ed312889d50eb00fd3c66 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-e9d6304b505ed312889d50eb00fd3c66 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-e9d6304b505ed312889d50eb00fd3c66 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
Oct 22 00:53:28.140: INFO: stdout: "Created e2e-test-nginx-rc-e9d6304b505ed312889d50eb00fd3c66\nScaling up e2e-test-nginx-rc-e9d6304b505ed312889d50eb00fd3c66 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-e9d6304b505ed312889d50eb00fd3c66 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-e9d6304b505ed312889d50eb00fd3c66 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
Oct 22 00:53:28.140: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=kubectl-5270'
Oct 22 00:53:28.311: INFO: stderr: ""
Oct 22 00:53:28.311: INFO: stdout: "e2e-test-nginx-rc-e9d6304b505ed312889d50eb00fd3c66-n9jbb "
Oct 22 00:53:28.311: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 get pods e2e-test-nginx-rc-e9d6304b505ed312889d50eb00fd3c66-n9jbb -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-5270'
Oct 22 00:53:28.469: INFO: stderr: ""
Oct 22 00:53:28.469: INFO: stdout: "true"
Oct 22 00:53:28.469: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 get pods e2e-test-nginx-rc-e9d6304b505ed312889d50eb00fd3c66-n9jbb -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-5270'
Oct 22 00:53:28.629: INFO: stderr: ""
Oct 22 00:53:28.629: INFO: stdout: "docker.io/library/nginx:1.14-alpine"
Oct 22 00:53:28.629: INFO: e2e-test-nginx-rc-e9d6304b505ed312889d50eb00fd3c66-n9jbb is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1523
Oct 22 00:53:28.629: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 delete rc e2e-test-nginx-rc --namespace=kubectl-5270'
Oct 22 00:53:28.800: INFO: stderr: ""
Oct 22 00:53:28.800: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 00:53:28.800: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5270" for this suite.
Oct 22 00:53:50.828: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 00:53:50.976: INFO: namespace kubectl-5270 deletion completed in 22.167406667s

• [SLOW TEST:39.018 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 00:53:50.976: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Oct 22 00:53:51.035: INFO: Waiting up to 5m0s for pod "downwardapi-volume-680aaea9-5766-4889-adde-80d7e6cb115a" in namespace "downward-api-3629" to be "success or failure"
Oct 22 00:53:51.039: INFO: Pod "downwardapi-volume-680aaea9-5766-4889-adde-80d7e6cb115a": Phase="Pending", Reason="", readiness=false. Elapsed: 4.268105ms
Oct 22 00:53:53.046: INFO: Pod "downwardapi-volume-680aaea9-5766-4889-adde-80d7e6cb115a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011280308s
STEP: Saw pod success
Oct 22 00:53:53.046: INFO: Pod "downwardapi-volume-680aaea9-5766-4889-adde-80d7e6cb115a" satisfied condition "success or failure"
Oct 22 00:53:53.051: INFO: Trying to get logs from node mip-bd-vm40.mip.storage.hpecorp.net pod downwardapi-volume-680aaea9-5766-4889-adde-80d7e6cb115a container client-container: <nil>
STEP: delete the pod
Oct 22 00:53:53.080: INFO: Waiting for pod downwardapi-volume-680aaea9-5766-4889-adde-80d7e6cb115a to disappear
Oct 22 00:53:53.084: INFO: Pod downwardapi-volume-680aaea9-5766-4889-adde-80d7e6cb115a no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 00:53:53.084: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3629" for this suite.
Oct 22 00:53:59.121: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 00:53:59.261: INFO: namespace downward-api-3629 deletion completed in 6.15972862s

• [SLOW TEST:8.284 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 00:53:59.261: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 00:54:59.320: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-8487" for this suite.
Oct 22 00:55:21.343: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 00:55:21.510: INFO: namespace container-probe-8487 deletion completed in 22.184180059s

• [SLOW TEST:82.249 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 00:55:21.510: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0777 on node default medium
Oct 22 00:55:21.567: INFO: Waiting up to 5m0s for pod "pod-82e5ca47-73f3-4c45-b34c-ca00246eabb0" in namespace "emptydir-4806" to be "success or failure"
Oct 22 00:55:21.570: INFO: Pod "pod-82e5ca47-73f3-4c45-b34c-ca00246eabb0": Phase="Pending", Reason="", readiness=false. Elapsed: 3.858248ms
Oct 22 00:55:23.576: INFO: Pod "pod-82e5ca47-73f3-4c45-b34c-ca00246eabb0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009462425s
STEP: Saw pod success
Oct 22 00:55:23.576: INFO: Pod "pod-82e5ca47-73f3-4c45-b34c-ca00246eabb0" satisfied condition "success or failure"
Oct 22 00:55:23.580: INFO: Trying to get logs from node mip-bd-vm40.mip.storage.hpecorp.net pod pod-82e5ca47-73f3-4c45-b34c-ca00246eabb0 container test-container: <nil>
STEP: delete the pod
Oct 22 00:55:23.605: INFO: Waiting for pod pod-82e5ca47-73f3-4c45-b34c-ca00246eabb0 to disappear
Oct 22 00:55:23.610: INFO: Pod pod-82e5ca47-73f3-4c45-b34c-ca00246eabb0 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 00:55:23.610: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4806" for this suite.
Oct 22 00:55:29.630: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 00:55:29.788: INFO: namespace emptydir-4806 deletion completed in 6.172456553s

• [SLOW TEST:8.278 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 00:55:29.788: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Oct 22 00:55:32.382: INFO: Successfully updated pod "pod-update-015638db-2efd-443b-8a73-0291cac9abac"
STEP: verifying the updated pod is in kubernetes
Oct 22 00:55:32.390: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 00:55:32.390: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-2296" for this suite.
Oct 22 00:55:54.411: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 00:55:54.561: INFO: namespace pods-2296 deletion completed in 22.165515858s

• [SLOW TEST:24.773 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 00:55:54.561: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:81
Oct 22 00:55:54.607: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Oct 22 00:55:54.617: INFO: Waiting for terminating namespaces to be deleted...
Oct 22 00:55:54.620: INFO: 
Logging pods the kubelet thinks is on node mip-bd-vm40.mip.storage.hpecorp.net before test
Oct 22 00:55:54.632: INFO: kubedirector-6466dc856f-mh7mk from kube-system started at 2019-10-21 22:11:04 +0000 UTC (1 container statuses recorded)
Oct 22 00:55:54.632: INFO: 	Container kubedirector ready: true, restart count 0
Oct 22 00:55:54.632: INFO: canal-r9n5g from kube-system started at 2019-10-21 22:11:11 +0000 UTC (3 container statuses recorded)
Oct 22 00:55:54.632: INFO: 	Container calico-node ready: true, restart count 0
Oct 22 00:55:54.632: INFO: 	Container install-cni ready: true, restart count 0
Oct 22 00:55:54.632: INFO: 	Container kube-flannel ready: true, restart count 0
Oct 22 00:55:54.632: INFO: kubedirector-fsmount-gfmbk from kube-system started at 2019-10-21 22:12:39 +0000 UTC (1 container statuses recorded)
Oct 22 00:55:54.632: INFO: 	Container kubedirector-fsmount ready: true, restart count 0
Oct 22 00:55:54.632: INFO: sonobuoy-systemd-logs-daemon-set-d36ba0a04f4c410a-66d8l from heptio-sonobuoy started at 2019-10-21 23:53:49 +0000 UTC (2 container statuses recorded)
Oct 22 00:55:54.632: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Oct 22 00:55:54.632: INFO: 	Container systemd-logs ready: true, restart count 1
Oct 22 00:55:54.632: INFO: kube-proxy-p4s2t from kube-system started at 2019-10-21 22:10:33 +0000 UTC (1 container statuses recorded)
Oct 22 00:55:54.632: INFO: 	Container kube-proxy ready: true, restart count 0
Oct 22 00:55:54.632: INFO: sonobuoy-e2e-job-d7290e8bc6084643 from heptio-sonobuoy started at 2019-10-21 23:53:49 +0000 UTC (2 container statuses recorded)
Oct 22 00:55:54.632: INFO: 	Container e2e ready: true, restart count 0
Oct 22 00:55:54.632: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct 22 00:55:54.632: INFO: 
Logging pods the kubelet thinks is on node mip-bd-vm41.mip.storage.hpecorp.net before test
Oct 22 00:55:54.646: INFO: kubedirector-fsmount-vgwfc from kube-system started at 2019-10-21 22:12:39 +0000 UTC (1 container statuses recorded)
Oct 22 00:55:54.646: INFO: 	Container kubedirector-fsmount ready: true, restart count 0
Oct 22 00:55:54.646: INFO: sonobuoy from heptio-sonobuoy started at 2019-10-21 23:53:46 +0000 UTC (1 container statuses recorded)
Oct 22 00:55:54.646: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Oct 22 00:55:54.646: INFO: kube-proxy-lc4z4 from kube-system started at 2019-10-21 22:10:31 +0000 UTC (1 container statuses recorded)
Oct 22 00:55:54.646: INFO: 	Container kube-proxy ready: true, restart count 0
Oct 22 00:55:54.646: INFO: kube-state-metrics-549d594744-hlwrw from kube-system started at 2019-10-21 22:11:00 +0000 UTC (1 container statuses recorded)
Oct 22 00:55:54.646: INFO: 	Container kube-state-metrics ready: true, restart count 0
Oct 22 00:55:54.646: INFO: canal-7vsf6 from kube-system started at 2019-10-21 22:11:11 +0000 UTC (3 container statuses recorded)
Oct 22 00:55:54.646: INFO: 	Container calico-node ready: true, restart count 0
Oct 22 00:55:54.646: INFO: 	Container install-cni ready: true, restart count 0
Oct 22 00:55:54.646: INFO: 	Container kube-flannel ready: true, restart count 0
Oct 22 00:55:54.646: INFO: sonobuoy-systemd-logs-daemon-set-d36ba0a04f4c410a-4nk8z from heptio-sonobuoy started at 2019-10-21 23:53:49 +0000 UTC (2 container statuses recorded)
Oct 22 00:55:54.646: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Oct 22 00:55:54.646: INFO: 	Container systemd-logs ready: true, restart count 1
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-fa840232-fff8-49f9-9bb1-cc718925baf8 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-fa840232-fff8-49f9-9bb1-cc718925baf8 off the node mip-bd-vm40.mip.storage.hpecorp.net
STEP: verifying the node doesn't have the label kubernetes.io/e2e-fa840232-fff8-49f9-9bb1-cc718925baf8
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 00:55:58.749: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-8985" for this suite.
Oct 22 00:56:12.770: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 00:56:12.933: INFO: namespace sched-pred-8985 deletion completed in 14.178276721s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:72

• [SLOW TEST:18.371 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 00:56:12.933: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-dcaa5d70-e3d2-4047-a7e1-7f8902a27143
STEP: Creating a pod to test consume configMaps
Oct 22 00:56:13.009: INFO: Waiting up to 5m0s for pod "pod-configmaps-a4f231b0-330b-496a-84c1-03835c639cf5" in namespace "configmap-8138" to be "success or failure"
Oct 22 00:56:13.012: INFO: Pod "pod-configmaps-a4f231b0-330b-496a-84c1-03835c639cf5": Phase="Pending", Reason="", readiness=false. Elapsed: 3.449277ms
Oct 22 00:56:15.021: INFO: Pod "pod-configmaps-a4f231b0-330b-496a-84c1-03835c639cf5": Phase="Running", Reason="", readiness=true. Elapsed: 2.011756276s
Oct 22 00:56:17.026: INFO: Pod "pod-configmaps-a4f231b0-330b-496a-84c1-03835c639cf5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017311984s
STEP: Saw pod success
Oct 22 00:56:17.026: INFO: Pod "pod-configmaps-a4f231b0-330b-496a-84c1-03835c639cf5" satisfied condition "success or failure"
Oct 22 00:56:17.030: INFO: Trying to get logs from node mip-bd-vm41.mip.storage.hpecorp.net pod pod-configmaps-a4f231b0-330b-496a-84c1-03835c639cf5 container configmap-volume-test: <nil>
STEP: delete the pod
Oct 22 00:56:17.064: INFO: Waiting for pod pod-configmaps-a4f231b0-330b-496a-84c1-03835c639cf5 to disappear
Oct 22 00:56:17.069: INFO: Pod pod-configmaps-a4f231b0-330b-496a-84c1-03835c639cf5 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 00:56:17.069: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8138" for this suite.
Oct 22 00:56:23.088: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 00:56:23.232: INFO: namespace configmap-8138 deletion completed in 6.158210906s

• [SLOW TEST:10.299 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 00:56:23.233: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Oct 22 00:56:23.287: INFO: Creating deployment "nginx-deployment"
Oct 22 00:56:23.297: INFO: Waiting for observed generation 1
Oct 22 00:56:25.307: INFO: Waiting for all required pods to come up
Oct 22 00:56:25.313: INFO: Pod name nginx: Found 10 pods out of 10
STEP: ensuring each pod is running
Oct 22 00:56:27.334: INFO: Waiting for deployment "nginx-deployment" to complete
Oct 22 00:56:27.344: INFO: Updating deployment "nginx-deployment" with a non-existent image
Oct 22 00:56:27.356: INFO: Updating deployment nginx-deployment
Oct 22 00:56:27.356: INFO: Waiting for observed generation 2
Oct 22 00:56:29.367: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Oct 22 00:56:29.371: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Oct 22 00:56:29.374: INFO: Waiting for the first rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Oct 22 00:56:29.386: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Oct 22 00:56:29.386: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Oct 22 00:56:29.389: INFO: Waiting for the second rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Oct 22 00:56:29.396: INFO: Verifying that deployment "nginx-deployment" has minimum required number of available replicas
Oct 22 00:56:29.396: INFO: Scaling up the deployment "nginx-deployment" from 10 to 30
Oct 22 00:56:29.407: INFO: Updating deployment nginx-deployment
Oct 22 00:56:29.407: INFO: Waiting for the replicasets of deployment "nginx-deployment" to have desired number of replicas
Oct 22 00:56:29.416: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Oct 22 00:56:29.420: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
Oct 22 00:56:29.439: INFO: Deployment "nginx-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment,GenerateName:,Namespace:deployment-5867,SelfLink:/apis/apps/v1/namespaces/deployment-5867/deployments/nginx-deployment,UID:e364725b-3016-4380-81ec-b7636431a9c9,ResourceVersion:21496,Generation:3,CreationTimestamp:2019-10-22 00:56:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*30,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:13,UpdatedReplicas:5,AvailableReplicas:8,UnavailableReplicas:5,Conditions:[{Available True 2019-10-22 00:56:25 +0000 UTC 2019-10-22 00:56:25 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-10-22 00:56:27 +0000 UTC 2019-10-22 00:56:23 +0000 UTC ReplicaSetUpdated ReplicaSet "nginx-deployment-55fb7cb77f" is progressing.}],ReadyReplicas:8,CollisionCount:nil,},}

Oct 22 00:56:29.459: INFO: New ReplicaSet "nginx-deployment-55fb7cb77f" of Deployment "nginx-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f,GenerateName:,Namespace:deployment-5867,SelfLink:/apis/apps/v1/namespaces/deployment-5867/replicasets/nginx-deployment-55fb7cb77f,UID:1d521cf1-6b46-477f-aa6d-68b05898dddd,ResourceVersion:21499,Generation:3,CreationTimestamp:2019-10-22 00:56:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment nginx-deployment e364725b-3016-4380-81ec-b7636431a9c9 0xc002fc2bd7 0xc002fc2bd8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*13,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:5,FullyLabeledReplicas:5,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Oct 22 00:56:29.459: INFO: All old ReplicaSets of Deployment "nginx-deployment":
Oct 22 00:56:29.460: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498,GenerateName:,Namespace:deployment-5867,SelfLink:/apis/apps/v1/namespaces/deployment-5867/replicasets/nginx-deployment-7b8c6f4498,UID:437bf9a0-baea-4847-8c11-2266b5cb7e80,ResourceVersion:21497,Generation:3,CreationTimestamp:2019-10-22 00:56:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment nginx-deployment e364725b-3016-4380-81ec-b7636431a9c9 0xc002fc2ca7 0xc002fc2ca8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*20,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:8,FullyLabeledReplicas:8,ObservedGeneration:2,ReadyReplicas:8,AvailableReplicas:8,Conditions:[],},}
Oct 22 00:56:29.503: INFO: Pod "nginx-deployment-55fb7cb77f-2ngjx" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-2ngjx,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-5867,SelfLink:/api/v1/namespaces/deployment-5867/pods/nginx-deployment-55fb7cb77f-2ngjx,UID:d1ae2034-fda1-4edd-8c55-74b2beead529,ResourceVersion:21488,Generation:0,CreationTimestamp:2019-10-22 00:56:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.244.2.100/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 1d521cf1-6b46-477f-aa6d-68b05898dddd 0xc002fc3657 0xc002fc3658}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-kzwd2 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kzwd2,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-kzwd2 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:mip-bd-vm40.mip.storage.hpecorp.net,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002fc36c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002fc36e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:56:27 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:56:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:56:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:56:27 +0000 UTC  }],Message:,Reason:,HostIP:16.143.20.137,PodIP:,StartTime:2019-10-22 00:56:27 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 22 00:56:29.503: INFO: Pod "nginx-deployment-55fb7cb77f-7v5hd" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-7v5hd,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-5867,SelfLink:/api/v1/namespaces/deployment-5867/pods/nginx-deployment-55fb7cb77f-7v5hd,UID:d4dc5a01-8b7b-4134-9072-9279ec561538,ResourceVersion:21509,Generation:0,CreationTimestamp:2019-10-22 00:56:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 1d521cf1-6b46-477f-aa6d-68b05898dddd 0xc002fc37d0 0xc002fc37d1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-kzwd2 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kzwd2,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-kzwd2 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:mip-bd-vm40.mip.storage.hpecorp.net,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002fc3840} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002fc3860}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:56:29 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 22 00:56:29.504: INFO: Pod "nginx-deployment-55fb7cb77f-b5l2d" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-b5l2d,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-5867,SelfLink:/api/v1/namespaces/deployment-5867/pods/nginx-deployment-55fb7cb77f-b5l2d,UID:c96da8ad-f85d-4e8b-b992-7a03dd9cca02,ResourceVersion:21492,Generation:0,CreationTimestamp:2019-10-22 00:56:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.244.1.115/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 1d521cf1-6b46-477f-aa6d-68b05898dddd 0xc002fc38f0 0xc002fc38f1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-kzwd2 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kzwd2,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-kzwd2 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:mip-bd-vm41.mip.storage.hpecorp.net,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002fc3970} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002fc3990}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:56:27 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:56:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:56:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:56:27 +0000 UTC  }],Message:,Reason:,HostIP:16.143.20.138,PodIP:,StartTime:2019-10-22 00:56:27 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 22 00:56:29.504: INFO: Pod "nginx-deployment-55fb7cb77f-mp6mt" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-mp6mt,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-5867,SelfLink:/api/v1/namespaces/deployment-5867/pods/nginx-deployment-55fb7cb77f-mp6mt,UID:5361319b-0c4d-405b-be3d-1ba68d88fdfc,ResourceVersion:21494,Generation:0,CreationTimestamp:2019-10-22 00:56:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.244.1.116/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 1d521cf1-6b46-477f-aa6d-68b05898dddd 0xc002fc3a70 0xc002fc3a71}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-kzwd2 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kzwd2,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-kzwd2 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:mip-bd-vm41.mip.storage.hpecorp.net,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002fc3ae0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002fc3b00}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:56:27 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:56:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:56:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:56:27 +0000 UTC  }],Message:,Reason:,HostIP:16.143.20.138,PodIP:,StartTime:2019-10-22 00:56:27 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 22 00:56:29.504: INFO: Pod "nginx-deployment-55fb7cb77f-r5tns" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-r5tns,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-5867,SelfLink:/api/v1/namespaces/deployment-5867/pods/nginx-deployment-55fb7cb77f-r5tns,UID:4e755ec9-d685-47de-8acd-242a7950fba2,ResourceVersion:21511,Generation:0,CreationTimestamp:2019-10-22 00:56:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 1d521cf1-6b46-477f-aa6d-68b05898dddd 0xc002fc3bd0 0xc002fc3bd1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-kzwd2 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kzwd2,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-kzwd2 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002fc3c40} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002fc3c60}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 22 00:56:29.504: INFO: Pod "nginx-deployment-55fb7cb77f-sdjhb" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-sdjhb,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-5867,SelfLink:/api/v1/namespaces/deployment-5867/pods/nginx-deployment-55fb7cb77f-sdjhb,UID:e7fc3894-8562-42d7-bfa3-d0d8e1aa9cca,ResourceVersion:21487,Generation:0,CreationTimestamp:2019-10-22 00:56:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.244.1.114/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 1d521cf1-6b46-477f-aa6d-68b05898dddd 0xc002fc3cd7 0xc002fc3cd8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-kzwd2 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kzwd2,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-kzwd2 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:mip-bd-vm41.mip.storage.hpecorp.net,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002fc3d40} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002fc3d60}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:56:27 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:56:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:56:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:56:27 +0000 UTC  }],Message:,Reason:,HostIP:16.143.20.138,PodIP:,StartTime:2019-10-22 00:56:27 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 22 00:56:29.507: INFO: Pod "nginx-deployment-55fb7cb77f-v7mhl" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-v7mhl,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-5867,SelfLink:/api/v1/namespaces/deployment-5867/pods/nginx-deployment-55fb7cb77f-v7mhl,UID:8bb4fb3a-7804-491f-ab98-a8e3b3b9b15e,ResourceVersion:21486,Generation:0,CreationTimestamp:2019-10-22 00:56:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.244.2.99/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 1d521cf1-6b46-477f-aa6d-68b05898dddd 0xc002fc3e40 0xc002fc3e41}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-kzwd2 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kzwd2,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-kzwd2 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:mip-bd-vm40.mip.storage.hpecorp.net,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002fc3eb0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002fc3ed0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:56:27 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:56:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:56:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:56:27 +0000 UTC  }],Message:,Reason:,HostIP:16.143.20.137,PodIP:,StartTime:2019-10-22 00:56:27 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 22 00:56:29.507: INFO: Pod "nginx-deployment-7b8c6f4498-fsz9n" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-fsz9n,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-5867,SelfLink:/api/v1/namespaces/deployment-5867/pods/nginx-deployment-7b8c6f4498-fsz9n,UID:8287ea1e-5c36-491d-8d1d-b2fba1cce2d9,ResourceVersion:21408,Generation:0,CreationTimestamp:2019-10-22 00:56:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.244.1.111/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 437bf9a0-baea-4847-8c11-2266b5cb7e80 0xc002fc3fb0 0xc002fc3fb1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-kzwd2 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kzwd2,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-kzwd2 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:mip-bd-vm41.mip.storage.hpecorp.net,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002666010} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002666030}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:56:23 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:56:25 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:56:25 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:56:23 +0000 UTC  }],Message:,Reason:,HostIP:16.143.20.138,PodIP:10.244.1.111,StartTime:2019-10-22 00:56:23 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-10-22 00:56:24 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/nginx:1.14-alpine docker-pullable://docker.io/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://98cf7547f4e8f31eee76981fd95bfe119dcb3361e90e47458f32447af073957e}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 22 00:56:29.507: INFO: Pod "nginx-deployment-7b8c6f4498-k22jk" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-k22jk,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-5867,SelfLink:/api/v1/namespaces/deployment-5867/pods/nginx-deployment-7b8c6f4498-k22jk,UID:43623fcd-b01d-48bd-9bbc-3cef414cd831,ResourceVersion:21398,Generation:0,CreationTimestamp:2019-10-22 00:56:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.244.2.98/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 437bf9a0-baea-4847-8c11-2266b5cb7e80 0xc002666117 0xc002666118}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-kzwd2 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kzwd2,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-kzwd2 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:mip-bd-vm40.mip.storage.hpecorp.net,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002666180} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0026661a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:56:23 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:56:25 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:56:25 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:56:23 +0000 UTC  }],Message:,Reason:,HostIP:16.143.20.137,PodIP:10.244.2.98,StartTime:2019-10-22 00:56:23 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-10-22 00:56:24 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/nginx:1.14-alpine docker-pullable://docker.io/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://0de250ca63d43011043bb79b97651a20497a297b0e168f639a360a81d4ec4b27}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 22 00:56:29.508: INFO: Pod "nginx-deployment-7b8c6f4498-kf7jb" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-kf7jb,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-5867,SelfLink:/api/v1/namespaces/deployment-5867/pods/nginx-deployment-7b8c6f4498-kf7jb,UID:cda99bb1-db13-4e79-b605-83bce0fc6130,ResourceVersion:21508,Generation:0,CreationTimestamp:2019-10-22 00:56:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 437bf9a0-baea-4847-8c11-2266b5cb7e80 0xc002666270 0xc002666271}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-kzwd2 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kzwd2,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-kzwd2 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:mip-bd-vm40.mip.storage.hpecorp.net,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0026662e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002666310}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:56:29 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 22 00:56:29.508: INFO: Pod "nginx-deployment-7b8c6f4498-m7mjt" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-m7mjt,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-5867,SelfLink:/api/v1/namespaces/deployment-5867/pods/nginx-deployment-7b8c6f4498-m7mjt,UID:aa3e45ae-f296-407f-b3c9-3b45d97d2b6a,ResourceVersion:21402,Generation:0,CreationTimestamp:2019-10-22 00:56:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.244.1.112/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 437bf9a0-baea-4847-8c11-2266b5cb7e80 0xc0026663a0 0xc0026663a1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-kzwd2 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kzwd2,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-kzwd2 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:mip-bd-vm41.mip.storage.hpecorp.net,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002666400} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002666420}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:56:23 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:56:25 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:56:25 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:56:23 +0000 UTC  }],Message:,Reason:,HostIP:16.143.20.138,PodIP:10.244.1.112,StartTime:2019-10-22 00:56:23 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-10-22 00:56:24 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/nginx:1.14-alpine docker-pullable://docker.io/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://9bb326de819db261fa98b37f1aa8b903846c2db26d5aed791e76ac97023e3c25}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 22 00:56:29.508: INFO: Pod "nginx-deployment-7b8c6f4498-n5fmf" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-n5fmf,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-5867,SelfLink:/api/v1/namespaces/deployment-5867/pods/nginx-deployment-7b8c6f4498-n5fmf,UID:06c536a6-46e1-4430-b5b4-0738251b5754,ResourceVersion:21505,Generation:0,CreationTimestamp:2019-10-22 00:56:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 437bf9a0-baea-4847-8c11-2266b5cb7e80 0xc0026664f7 0xc0026664f8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-kzwd2 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kzwd2,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-kzwd2 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:mip-bd-vm41.mip.storage.hpecorp.net,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002666560} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002666580}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:56:29 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 22 00:56:29.508: INFO: Pod "nginx-deployment-7b8c6f4498-rvtfz" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-rvtfz,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-5867,SelfLink:/api/v1/namespaces/deployment-5867/pods/nginx-deployment-7b8c6f4498-rvtfz,UID:cd7a6c3d-482f-4e3f-9035-c7795f435de5,ResourceVersion:21421,Generation:0,CreationTimestamp:2019-10-22 00:56:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.244.2.95/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 437bf9a0-baea-4847-8c11-2266b5cb7e80 0xc002666610 0xc002666611}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-kzwd2 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kzwd2,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-kzwd2 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:mip-bd-vm40.mip.storage.hpecorp.net,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002666670} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002666690}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:56:23 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:56:25 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:56:25 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:56:23 +0000 UTC  }],Message:,Reason:,HostIP:16.143.20.137,PodIP:10.244.2.95,StartTime:2019-10-22 00:56:23 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-10-22 00:56:24 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/nginx:1.14-alpine docker-pullable://docker.io/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://6a4b0ab3c789f655b67f4e4c654fbb21376c37127163e043b33119a20bb43a79}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 22 00:56:29.509: INFO: Pod "nginx-deployment-7b8c6f4498-s2cbb" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-s2cbb,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-5867,SelfLink:/api/v1/namespaces/deployment-5867/pods/nginx-deployment-7b8c6f4498-s2cbb,UID:c5d2abc9-9029-47cf-8982-e5dc58a57471,ResourceVersion:21412,Generation:0,CreationTimestamp:2019-10-22 00:56:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.244.1.110/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 437bf9a0-baea-4847-8c11-2266b5cb7e80 0xc002666770 0xc002666771}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-kzwd2 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kzwd2,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-kzwd2 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:mip-bd-vm41.mip.storage.hpecorp.net,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0026667d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0026667f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:56:23 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:56:25 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:56:25 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:56:23 +0000 UTC  }],Message:,Reason:,HostIP:16.143.20.138,PodIP:10.244.1.110,StartTime:2019-10-22 00:56:23 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-10-22 00:56:24 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/nginx:1.14-alpine docker-pullable://docker.io/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://03cd55a05ed98d029e969c7642e8be3d965a998d8b504713bbd7e8e31c4a5070}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 22 00:56:29.509: INFO: Pod "nginx-deployment-7b8c6f4498-sg2pg" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-sg2pg,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-5867,SelfLink:/api/v1/namespaces/deployment-5867/pods/nginx-deployment-7b8c6f4498-sg2pg,UID:39487db2-0cc5-4b85-8a40-bf51c4795785,ResourceVersion:21512,Generation:0,CreationTimestamp:2019-10-22 00:56:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 437bf9a0-baea-4847-8c11-2266b5cb7e80 0xc0026668c7 0xc0026668c8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-kzwd2 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kzwd2,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-kzwd2 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:mip-bd-vm40.mip.storage.hpecorp.net,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002666930} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002666950}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:56:29 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 22 00:56:29.509: INFO: Pod "nginx-deployment-7b8c6f4498-vkf5g" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-vkf5g,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-5867,SelfLink:/api/v1/namespaces/deployment-5867/pods/nginx-deployment-7b8c6f4498-vkf5g,UID:15c00067-6f5b-4ae9-8cd9-30370ad83e94,ResourceVersion:21410,Generation:0,CreationTimestamp:2019-10-22 00:56:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.244.2.96/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 437bf9a0-baea-4847-8c11-2266b5cb7e80 0xc0026669e0 0xc0026669e1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-kzwd2 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kzwd2,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-kzwd2 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:mip-bd-vm40.mip.storage.hpecorp.net,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002666a40} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002666a60}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:56:23 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:56:25 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:56:25 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:56:23 +0000 UTC  }],Message:,Reason:,HostIP:16.143.20.137,PodIP:10.244.2.96,StartTime:2019-10-22 00:56:23 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-10-22 00:56:24 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/nginx:1.14-alpine docker-pullable://docker.io/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://834059e94bb0bb6bdb2258c1ead9662d73b797fe31a8a83b00d49dc3ef9e193f}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 22 00:56:29.510: INFO: Pod "nginx-deployment-7b8c6f4498-z5ls7" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-z5ls7,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-5867,SelfLink:/api/v1/namespaces/deployment-5867/pods/nginx-deployment-7b8c6f4498-z5ls7,UID:f6fec3d9-8c51-4c0a-b36f-c35be68179d4,ResourceVersion:21406,Generation:0,CreationTimestamp:2019-10-22 00:56:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.244.2.97/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 437bf9a0-baea-4847-8c11-2266b5cb7e80 0xc002666b50 0xc002666b51}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-kzwd2 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kzwd2,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-kzwd2 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:mip-bd-vm40.mip.storage.hpecorp.net,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002666bb0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002666bd0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:56:23 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:56:25 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:56:25 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:56:23 +0000 UTC  }],Message:,Reason:,HostIP:16.143.20.137,PodIP:10.244.2.97,StartTime:2019-10-22 00:56:23 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-10-22 00:56:24 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/nginx:1.14-alpine docker-pullable://docker.io/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://646c5c687e86d925478d6da953c68c3e837021654c3194469785fd075d8a0f4e}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 22 00:56:29.510: INFO: Pod "nginx-deployment-7b8c6f4498-zlsgs" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-zlsgs,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-5867,SelfLink:/api/v1/namespaces/deployment-5867/pods/nginx-deployment-7b8c6f4498-zlsgs,UID:ffb9e4b9-2cdb-40fc-af3b-7bcdf596476a,ResourceVersion:21396,Generation:0,CreationTimestamp:2019-10-22 00:56:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.244.1.113/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 437bf9a0-baea-4847-8c11-2266b5cb7e80 0xc002666cb0 0xc002666cb1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-kzwd2 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kzwd2,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-kzwd2 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:mip-bd-vm41.mip.storage.hpecorp.net,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002666d10} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002666d30}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:56:23 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:56:25 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:56:25 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:56:23 +0000 UTC  }],Message:,Reason:,HostIP:16.143.20.138,PodIP:10.244.1.113,StartTime:2019-10-22 00:56:23 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-10-22 00:56:24 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/nginx:1.14-alpine docker-pullable://docker.io/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://087e66019d579d76ff35a7c44b3acf69eeb4dd27a2ab5d183b62792cde810206}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 00:56:29.510: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-5867" for this suite.
Oct 22 00:56:37.583: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 00:56:37.742: INFO: namespace deployment-5867 deletion completed in 8.216221151s

• [SLOW TEST:14.509 seconds]
[sig-apps] Deployment
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 00:56:37.743: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-map-d37bf15a-357e-4590-87dd-457d9b4e7ba3
STEP: Creating a pod to test consume secrets
Oct 22 00:56:37.807: INFO: Waiting up to 5m0s for pod "pod-secrets-d1cc247f-8ee1-419a-8406-7216855de587" in namespace "secrets-9704" to be "success or failure"
Oct 22 00:56:37.811: INFO: Pod "pod-secrets-d1cc247f-8ee1-419a-8406-7216855de587": Phase="Pending", Reason="", readiness=false. Elapsed: 4.182257ms
Oct 22 00:56:39.816: INFO: Pod "pod-secrets-d1cc247f-8ee1-419a-8406-7216855de587": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009579725s
STEP: Saw pod success
Oct 22 00:56:39.817: INFO: Pod "pod-secrets-d1cc247f-8ee1-419a-8406-7216855de587" satisfied condition "success or failure"
Oct 22 00:56:39.820: INFO: Trying to get logs from node mip-bd-vm41.mip.storage.hpecorp.net pod pod-secrets-d1cc247f-8ee1-419a-8406-7216855de587 container secret-volume-test: <nil>
STEP: delete the pod
Oct 22 00:56:39.851: INFO: Waiting for pod pod-secrets-d1cc247f-8ee1-419a-8406-7216855de587 to disappear
Oct 22 00:56:39.855: INFO: Pod pod-secrets-d1cc247f-8ee1-419a-8406-7216855de587 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 00:56:39.855: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9704" for this suite.
Oct 22 00:56:45.877: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 00:56:46.028: INFO: namespace secrets-9704 deletion completed in 6.167593075s

• [SLOW TEST:8.285 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 00:56:46.028: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test use defaults
Oct 22 00:56:46.082: INFO: Waiting up to 5m0s for pod "client-containers-22534e2f-ff63-432d-90de-09481ce24658" in namespace "containers-7830" to be "success or failure"
Oct 22 00:56:46.086: INFO: Pod "client-containers-22534e2f-ff63-432d-90de-09481ce24658": Phase="Pending", Reason="", readiness=false. Elapsed: 3.413392ms
Oct 22 00:56:48.091: INFO: Pod "client-containers-22534e2f-ff63-432d-90de-09481ce24658": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00836896s
STEP: Saw pod success
Oct 22 00:56:48.091: INFO: Pod "client-containers-22534e2f-ff63-432d-90de-09481ce24658" satisfied condition "success or failure"
Oct 22 00:56:48.094: INFO: Trying to get logs from node mip-bd-vm41.mip.storage.hpecorp.net pod client-containers-22534e2f-ff63-432d-90de-09481ce24658 container test-container: <nil>
STEP: delete the pod
Oct 22 00:56:48.119: INFO: Waiting for pod client-containers-22534e2f-ff63-432d-90de-09481ce24658 to disappear
Oct 22 00:56:48.125: INFO: Pod client-containers-22534e2f-ff63-432d-90de-09481ce24658 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 00:56:48.125: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-7830" for this suite.
Oct 22 00:56:54.146: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 00:56:54.294: INFO: namespace containers-7830 deletion completed in 6.162821201s

• [SLOW TEST:8.266 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 00:56:54.294: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating service endpoint-test2 in namespace services-688
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-688 to expose endpoints map[]
Oct 22 00:56:54.353: INFO: Get endpoints failed (3.834484ms elapsed, ignoring for 5s): endpoints "endpoint-test2" not found
Oct 22 00:56:55.359: INFO: successfully validated that service endpoint-test2 in namespace services-688 exposes endpoints map[] (1.010485548s elapsed)
STEP: Creating pod pod1 in namespace services-688
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-688 to expose endpoints map[pod1:[80]]
Oct 22 00:56:57.398: INFO: successfully validated that service endpoint-test2 in namespace services-688 exposes endpoints map[pod1:[80]] (2.028728778s elapsed)
STEP: Creating pod pod2 in namespace services-688
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-688 to expose endpoints map[pod1:[80] pod2:[80]]
Oct 22 00:56:59.452: INFO: successfully validated that service endpoint-test2 in namespace services-688 exposes endpoints map[pod1:[80] pod2:[80]] (2.047483279s elapsed)
STEP: Deleting pod pod1 in namespace services-688
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-688 to expose endpoints map[pod2:[80]]
Oct 22 00:57:00.477: INFO: successfully validated that service endpoint-test2 in namespace services-688 exposes endpoints map[pod2:[80]] (1.018992523s elapsed)
STEP: Deleting pod pod2 in namespace services-688
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-688 to expose endpoints map[]
Oct 22 00:57:01.497: INFO: successfully validated that service endpoint-test2 in namespace services-688 exposes endpoints map[] (1.009917233s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 00:57:01.524: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-688" for this suite.
Oct 22 00:57:07.545: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 00:57:07.703: INFO: namespace services-688 deletion completed in 6.173585449s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:92

• [SLOW TEST:13.409 seconds]
[sig-network] Services
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 00:57:07.703: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Oct 22 00:57:07.766: INFO: Waiting up to 5m0s for pod "downwardapi-volume-2cac3a57-53e0-4002-a2b5-8b41013212ce" in namespace "projected-734" to be "success or failure"
Oct 22 00:57:07.770: INFO: Pod "downwardapi-volume-2cac3a57-53e0-4002-a2b5-8b41013212ce": Phase="Pending", Reason="", readiness=false. Elapsed: 3.936058ms
Oct 22 00:57:09.775: INFO: Pod "downwardapi-volume-2cac3a57-53e0-4002-a2b5-8b41013212ce": Phase="Running", Reason="", readiness=true. Elapsed: 2.009297877s
Oct 22 00:57:11.782: INFO: Pod "downwardapi-volume-2cac3a57-53e0-4002-a2b5-8b41013212ce": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016200174s
STEP: Saw pod success
Oct 22 00:57:11.782: INFO: Pod "downwardapi-volume-2cac3a57-53e0-4002-a2b5-8b41013212ce" satisfied condition "success or failure"
Oct 22 00:57:11.786: INFO: Trying to get logs from node mip-bd-vm40.mip.storage.hpecorp.net pod downwardapi-volume-2cac3a57-53e0-4002-a2b5-8b41013212ce container client-container: <nil>
STEP: delete the pod
Oct 22 00:57:11.817: INFO: Waiting for pod downwardapi-volume-2cac3a57-53e0-4002-a2b5-8b41013212ce to disappear
Oct 22 00:57:11.820: INFO: Pod downwardapi-volume-2cac3a57-53e0-4002-a2b5-8b41013212ce no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 00:57:11.821: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-734" for this suite.
Oct 22 00:57:17.844: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 00:57:17.987: INFO: namespace projected-734 deletion completed in 6.161678201s

• [SLOW TEST:10.284 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 00:57:17.988: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-daa6b54e-9d8a-4cd8-bbda-05f1fd38b839
STEP: Creating a pod to test consume configMaps
Oct 22 00:57:18.047: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-02900eb6-3220-415d-bcae-c9a3bc383b3c" in namespace "projected-6147" to be "success or failure"
Oct 22 00:57:18.050: INFO: Pod "pod-projected-configmaps-02900eb6-3220-415d-bcae-c9a3bc383b3c": Phase="Pending", Reason="", readiness=false. Elapsed: 3.111799ms
Oct 22 00:57:20.056: INFO: Pod "pod-projected-configmaps-02900eb6-3220-415d-bcae-c9a3bc383b3c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008602044s
STEP: Saw pod success
Oct 22 00:57:20.056: INFO: Pod "pod-projected-configmaps-02900eb6-3220-415d-bcae-c9a3bc383b3c" satisfied condition "success or failure"
Oct 22 00:57:20.060: INFO: Trying to get logs from node mip-bd-vm41.mip.storage.hpecorp.net pod pod-projected-configmaps-02900eb6-3220-415d-bcae-c9a3bc383b3c container projected-configmap-volume-test: <nil>
STEP: delete the pod
Oct 22 00:57:20.093: INFO: Waiting for pod pod-projected-configmaps-02900eb6-3220-415d-bcae-c9a3bc383b3c to disappear
Oct 22 00:57:20.101: INFO: Pod pod-projected-configmaps-02900eb6-3220-415d-bcae-c9a3bc383b3c no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 00:57:20.101: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6147" for this suite.
Oct 22 00:57:26.124: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 00:57:26.289: INFO: namespace projected-6147 deletion completed in 6.182204006s

• [SLOW TEST:8.300 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 00:57:26.289: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating Redis RC
Oct 22 00:57:26.333: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 create -f - --namespace=kubectl-8000'
Oct 22 00:57:26.756: INFO: stderr: ""
Oct 22 00:57:26.756: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Oct 22 00:57:27.761: INFO: Selector matched 1 pods for map[app:redis]
Oct 22 00:57:27.761: INFO: Found 0 / 1
Oct 22 00:57:28.762: INFO: Selector matched 1 pods for map[app:redis]
Oct 22 00:57:28.762: INFO: Found 1 / 1
Oct 22 00:57:28.762: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Oct 22 00:57:28.767: INFO: Selector matched 1 pods for map[app:redis]
Oct 22 00:57:28.767: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Oct 22 00:57:28.767: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 patch pod redis-master-bxwvl --namespace=kubectl-8000 -p {"metadata":{"annotations":{"x":"y"}}}'
Oct 22 00:57:28.941: INFO: stderr: ""
Oct 22 00:57:28.941: INFO: stdout: "pod/redis-master-bxwvl patched\n"
STEP: checking annotations
Oct 22 00:57:28.945: INFO: Selector matched 1 pods for map[app:redis]
Oct 22 00:57:28.946: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 00:57:28.946: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8000" for this suite.
Oct 22 00:57:50.966: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 00:57:51.115: INFO: namespace kubectl-8000 deletion completed in 22.163906962s

• [SLOW TEST:24.826 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl patch
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 00:57:51.115: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-4704.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-4704.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-4704.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-4704.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-4704.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-4704.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-4704.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-4704.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-4704.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-4704.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-4704.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-4704.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-4704.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 195.97.96.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.96.97.195_udp@PTR;check="$$(dig +tcp +noall +answer +search 195.97.96.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.96.97.195_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-4704.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-4704.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-4704.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-4704.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-4704.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-4704.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-4704.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-4704.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-4704.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-4704.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-4704.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-4704.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-4704.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 195.97.96.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.96.97.195_udp@PTR;check="$$(dig +tcp +noall +answer +search 195.97.96.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.96.97.195_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Oct 22 00:57:55.243: INFO: Unable to read wheezy_udp@dns-test-service.dns-4704.svc.cluster.local from pod dns-4704/dns-test-79ff06c6-9be7-4744-b522-dd3d0fcaf2aa: the server could not find the requested resource (get pods dns-test-79ff06c6-9be7-4744-b522-dd3d0fcaf2aa)
Oct 22 00:57:55.248: INFO: Unable to read wheezy_tcp@dns-test-service.dns-4704.svc.cluster.local from pod dns-4704/dns-test-79ff06c6-9be7-4744-b522-dd3d0fcaf2aa: the server could not find the requested resource (get pods dns-test-79ff06c6-9be7-4744-b522-dd3d0fcaf2aa)
Oct 22 00:57:55.252: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-4704.svc.cluster.local from pod dns-4704/dns-test-79ff06c6-9be7-4744-b522-dd3d0fcaf2aa: the server could not find the requested resource (get pods dns-test-79ff06c6-9be7-4744-b522-dd3d0fcaf2aa)
Oct 22 00:57:55.258: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-4704.svc.cluster.local from pod dns-4704/dns-test-79ff06c6-9be7-4744-b522-dd3d0fcaf2aa: the server could not find the requested resource (get pods dns-test-79ff06c6-9be7-4744-b522-dd3d0fcaf2aa)
Oct 22 00:57:55.295: INFO: Unable to read jessie_udp@dns-test-service.dns-4704.svc.cluster.local from pod dns-4704/dns-test-79ff06c6-9be7-4744-b522-dd3d0fcaf2aa: the server could not find the requested resource (get pods dns-test-79ff06c6-9be7-4744-b522-dd3d0fcaf2aa)
Oct 22 00:57:55.300: INFO: Unable to read jessie_tcp@dns-test-service.dns-4704.svc.cluster.local from pod dns-4704/dns-test-79ff06c6-9be7-4744-b522-dd3d0fcaf2aa: the server could not find the requested resource (get pods dns-test-79ff06c6-9be7-4744-b522-dd3d0fcaf2aa)
Oct 22 00:57:55.306: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-4704.svc.cluster.local from pod dns-4704/dns-test-79ff06c6-9be7-4744-b522-dd3d0fcaf2aa: the server could not find the requested resource (get pods dns-test-79ff06c6-9be7-4744-b522-dd3d0fcaf2aa)
Oct 22 00:57:55.311: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-4704.svc.cluster.local from pod dns-4704/dns-test-79ff06c6-9be7-4744-b522-dd3d0fcaf2aa: the server could not find the requested resource (get pods dns-test-79ff06c6-9be7-4744-b522-dd3d0fcaf2aa)
Oct 22 00:57:55.339: INFO: Lookups using dns-4704/dns-test-79ff06c6-9be7-4744-b522-dd3d0fcaf2aa failed for: [wheezy_udp@dns-test-service.dns-4704.svc.cluster.local wheezy_tcp@dns-test-service.dns-4704.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-4704.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-4704.svc.cluster.local jessie_udp@dns-test-service.dns-4704.svc.cluster.local jessie_tcp@dns-test-service.dns-4704.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-4704.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-4704.svc.cluster.local]

Oct 22 00:58:00.347: INFO: Unable to read wheezy_udp@dns-test-service.dns-4704.svc.cluster.local from pod dns-4704/dns-test-79ff06c6-9be7-4744-b522-dd3d0fcaf2aa: the server could not find the requested resource (get pods dns-test-79ff06c6-9be7-4744-b522-dd3d0fcaf2aa)
Oct 22 00:58:00.352: INFO: Unable to read wheezy_tcp@dns-test-service.dns-4704.svc.cluster.local from pod dns-4704/dns-test-79ff06c6-9be7-4744-b522-dd3d0fcaf2aa: the server could not find the requested resource (get pods dns-test-79ff06c6-9be7-4744-b522-dd3d0fcaf2aa)
Oct 22 00:58:00.357: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-4704.svc.cluster.local from pod dns-4704/dns-test-79ff06c6-9be7-4744-b522-dd3d0fcaf2aa: the server could not find the requested resource (get pods dns-test-79ff06c6-9be7-4744-b522-dd3d0fcaf2aa)
Oct 22 00:58:00.361: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-4704.svc.cluster.local from pod dns-4704/dns-test-79ff06c6-9be7-4744-b522-dd3d0fcaf2aa: the server could not find the requested resource (get pods dns-test-79ff06c6-9be7-4744-b522-dd3d0fcaf2aa)
Oct 22 00:58:00.395: INFO: Unable to read jessie_udp@dns-test-service.dns-4704.svc.cluster.local from pod dns-4704/dns-test-79ff06c6-9be7-4744-b522-dd3d0fcaf2aa: the server could not find the requested resource (get pods dns-test-79ff06c6-9be7-4744-b522-dd3d0fcaf2aa)
Oct 22 00:58:00.399: INFO: Unable to read jessie_tcp@dns-test-service.dns-4704.svc.cluster.local from pod dns-4704/dns-test-79ff06c6-9be7-4744-b522-dd3d0fcaf2aa: the server could not find the requested resource (get pods dns-test-79ff06c6-9be7-4744-b522-dd3d0fcaf2aa)
Oct 22 00:58:00.403: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-4704.svc.cluster.local from pod dns-4704/dns-test-79ff06c6-9be7-4744-b522-dd3d0fcaf2aa: the server could not find the requested resource (get pods dns-test-79ff06c6-9be7-4744-b522-dd3d0fcaf2aa)
Oct 22 00:58:00.409: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-4704.svc.cluster.local from pod dns-4704/dns-test-79ff06c6-9be7-4744-b522-dd3d0fcaf2aa: the server could not find the requested resource (get pods dns-test-79ff06c6-9be7-4744-b522-dd3d0fcaf2aa)
Oct 22 00:58:00.440: INFO: Lookups using dns-4704/dns-test-79ff06c6-9be7-4744-b522-dd3d0fcaf2aa failed for: [wheezy_udp@dns-test-service.dns-4704.svc.cluster.local wheezy_tcp@dns-test-service.dns-4704.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-4704.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-4704.svc.cluster.local jessie_udp@dns-test-service.dns-4704.svc.cluster.local jessie_tcp@dns-test-service.dns-4704.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-4704.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-4704.svc.cluster.local]

Oct 22 00:58:05.346: INFO: Unable to read wheezy_udp@dns-test-service.dns-4704.svc.cluster.local from pod dns-4704/dns-test-79ff06c6-9be7-4744-b522-dd3d0fcaf2aa: the server could not find the requested resource (get pods dns-test-79ff06c6-9be7-4744-b522-dd3d0fcaf2aa)
Oct 22 00:58:05.351: INFO: Unable to read wheezy_tcp@dns-test-service.dns-4704.svc.cluster.local from pod dns-4704/dns-test-79ff06c6-9be7-4744-b522-dd3d0fcaf2aa: the server could not find the requested resource (get pods dns-test-79ff06c6-9be7-4744-b522-dd3d0fcaf2aa)
Oct 22 00:58:05.356: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-4704.svc.cluster.local from pod dns-4704/dns-test-79ff06c6-9be7-4744-b522-dd3d0fcaf2aa: the server could not find the requested resource (get pods dns-test-79ff06c6-9be7-4744-b522-dd3d0fcaf2aa)
Oct 22 00:58:05.361: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-4704.svc.cluster.local from pod dns-4704/dns-test-79ff06c6-9be7-4744-b522-dd3d0fcaf2aa: the server could not find the requested resource (get pods dns-test-79ff06c6-9be7-4744-b522-dd3d0fcaf2aa)
Oct 22 00:58:05.400: INFO: Unable to read jessie_udp@dns-test-service.dns-4704.svc.cluster.local from pod dns-4704/dns-test-79ff06c6-9be7-4744-b522-dd3d0fcaf2aa: the server could not find the requested resource (get pods dns-test-79ff06c6-9be7-4744-b522-dd3d0fcaf2aa)
Oct 22 00:58:05.404: INFO: Unable to read jessie_tcp@dns-test-service.dns-4704.svc.cluster.local from pod dns-4704/dns-test-79ff06c6-9be7-4744-b522-dd3d0fcaf2aa: the server could not find the requested resource (get pods dns-test-79ff06c6-9be7-4744-b522-dd3d0fcaf2aa)
Oct 22 00:58:05.410: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-4704.svc.cluster.local from pod dns-4704/dns-test-79ff06c6-9be7-4744-b522-dd3d0fcaf2aa: the server could not find the requested resource (get pods dns-test-79ff06c6-9be7-4744-b522-dd3d0fcaf2aa)
Oct 22 00:58:05.415: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-4704.svc.cluster.local from pod dns-4704/dns-test-79ff06c6-9be7-4744-b522-dd3d0fcaf2aa: the server could not find the requested resource (get pods dns-test-79ff06c6-9be7-4744-b522-dd3d0fcaf2aa)
Oct 22 00:58:05.446: INFO: Lookups using dns-4704/dns-test-79ff06c6-9be7-4744-b522-dd3d0fcaf2aa failed for: [wheezy_udp@dns-test-service.dns-4704.svc.cluster.local wheezy_tcp@dns-test-service.dns-4704.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-4704.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-4704.svc.cluster.local jessie_udp@dns-test-service.dns-4704.svc.cluster.local jessie_tcp@dns-test-service.dns-4704.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-4704.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-4704.svc.cluster.local]

Oct 22 00:58:10.346: INFO: Unable to read wheezy_udp@dns-test-service.dns-4704.svc.cluster.local from pod dns-4704/dns-test-79ff06c6-9be7-4744-b522-dd3d0fcaf2aa: the server could not find the requested resource (get pods dns-test-79ff06c6-9be7-4744-b522-dd3d0fcaf2aa)
Oct 22 00:58:10.351: INFO: Unable to read wheezy_tcp@dns-test-service.dns-4704.svc.cluster.local from pod dns-4704/dns-test-79ff06c6-9be7-4744-b522-dd3d0fcaf2aa: the server could not find the requested resource (get pods dns-test-79ff06c6-9be7-4744-b522-dd3d0fcaf2aa)
Oct 22 00:58:10.356: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-4704.svc.cluster.local from pod dns-4704/dns-test-79ff06c6-9be7-4744-b522-dd3d0fcaf2aa: the server could not find the requested resource (get pods dns-test-79ff06c6-9be7-4744-b522-dd3d0fcaf2aa)
Oct 22 00:58:10.361: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-4704.svc.cluster.local from pod dns-4704/dns-test-79ff06c6-9be7-4744-b522-dd3d0fcaf2aa: the server could not find the requested resource (get pods dns-test-79ff06c6-9be7-4744-b522-dd3d0fcaf2aa)
Oct 22 00:58:10.396: INFO: Unable to read jessie_udp@dns-test-service.dns-4704.svc.cluster.local from pod dns-4704/dns-test-79ff06c6-9be7-4744-b522-dd3d0fcaf2aa: the server could not find the requested resource (get pods dns-test-79ff06c6-9be7-4744-b522-dd3d0fcaf2aa)
Oct 22 00:58:10.404: INFO: Unable to read jessie_tcp@dns-test-service.dns-4704.svc.cluster.local from pod dns-4704/dns-test-79ff06c6-9be7-4744-b522-dd3d0fcaf2aa: the server could not find the requested resource (get pods dns-test-79ff06c6-9be7-4744-b522-dd3d0fcaf2aa)
Oct 22 00:58:10.410: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-4704.svc.cluster.local from pod dns-4704/dns-test-79ff06c6-9be7-4744-b522-dd3d0fcaf2aa: the server could not find the requested resource (get pods dns-test-79ff06c6-9be7-4744-b522-dd3d0fcaf2aa)
Oct 22 00:58:10.415: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-4704.svc.cluster.local from pod dns-4704/dns-test-79ff06c6-9be7-4744-b522-dd3d0fcaf2aa: the server could not find the requested resource (get pods dns-test-79ff06c6-9be7-4744-b522-dd3d0fcaf2aa)
Oct 22 00:58:10.448: INFO: Lookups using dns-4704/dns-test-79ff06c6-9be7-4744-b522-dd3d0fcaf2aa failed for: [wheezy_udp@dns-test-service.dns-4704.svc.cluster.local wheezy_tcp@dns-test-service.dns-4704.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-4704.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-4704.svc.cluster.local jessie_udp@dns-test-service.dns-4704.svc.cluster.local jessie_tcp@dns-test-service.dns-4704.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-4704.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-4704.svc.cluster.local]

Oct 22 00:58:15.347: INFO: Unable to read wheezy_udp@dns-test-service.dns-4704.svc.cluster.local from pod dns-4704/dns-test-79ff06c6-9be7-4744-b522-dd3d0fcaf2aa: the server could not find the requested resource (get pods dns-test-79ff06c6-9be7-4744-b522-dd3d0fcaf2aa)
Oct 22 00:58:15.361: INFO: Unable to read wheezy_tcp@dns-test-service.dns-4704.svc.cluster.local from pod dns-4704/dns-test-79ff06c6-9be7-4744-b522-dd3d0fcaf2aa: the server could not find the requested resource (get pods dns-test-79ff06c6-9be7-4744-b522-dd3d0fcaf2aa)
Oct 22 00:58:15.366: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-4704.svc.cluster.local from pod dns-4704/dns-test-79ff06c6-9be7-4744-b522-dd3d0fcaf2aa: the server could not find the requested resource (get pods dns-test-79ff06c6-9be7-4744-b522-dd3d0fcaf2aa)
Oct 22 00:58:15.371: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-4704.svc.cluster.local from pod dns-4704/dns-test-79ff06c6-9be7-4744-b522-dd3d0fcaf2aa: the server could not find the requested resource (get pods dns-test-79ff06c6-9be7-4744-b522-dd3d0fcaf2aa)
Oct 22 00:58:15.403: INFO: Unable to read jessie_udp@dns-test-service.dns-4704.svc.cluster.local from pod dns-4704/dns-test-79ff06c6-9be7-4744-b522-dd3d0fcaf2aa: the server could not find the requested resource (get pods dns-test-79ff06c6-9be7-4744-b522-dd3d0fcaf2aa)
Oct 22 00:58:15.408: INFO: Unable to read jessie_tcp@dns-test-service.dns-4704.svc.cluster.local from pod dns-4704/dns-test-79ff06c6-9be7-4744-b522-dd3d0fcaf2aa: the server could not find the requested resource (get pods dns-test-79ff06c6-9be7-4744-b522-dd3d0fcaf2aa)
Oct 22 00:58:15.412: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-4704.svc.cluster.local from pod dns-4704/dns-test-79ff06c6-9be7-4744-b522-dd3d0fcaf2aa: the server could not find the requested resource (get pods dns-test-79ff06c6-9be7-4744-b522-dd3d0fcaf2aa)
Oct 22 00:58:15.417: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-4704.svc.cluster.local from pod dns-4704/dns-test-79ff06c6-9be7-4744-b522-dd3d0fcaf2aa: the server could not find the requested resource (get pods dns-test-79ff06c6-9be7-4744-b522-dd3d0fcaf2aa)
Oct 22 00:58:15.443: INFO: Lookups using dns-4704/dns-test-79ff06c6-9be7-4744-b522-dd3d0fcaf2aa failed for: [wheezy_udp@dns-test-service.dns-4704.svc.cluster.local wheezy_tcp@dns-test-service.dns-4704.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-4704.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-4704.svc.cluster.local jessie_udp@dns-test-service.dns-4704.svc.cluster.local jessie_tcp@dns-test-service.dns-4704.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-4704.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-4704.svc.cluster.local]

Oct 22 00:58:20.347: INFO: Unable to read wheezy_udp@dns-test-service.dns-4704.svc.cluster.local from pod dns-4704/dns-test-79ff06c6-9be7-4744-b522-dd3d0fcaf2aa: the server could not find the requested resource (get pods dns-test-79ff06c6-9be7-4744-b522-dd3d0fcaf2aa)
Oct 22 00:58:20.351: INFO: Unable to read wheezy_tcp@dns-test-service.dns-4704.svc.cluster.local from pod dns-4704/dns-test-79ff06c6-9be7-4744-b522-dd3d0fcaf2aa: the server could not find the requested resource (get pods dns-test-79ff06c6-9be7-4744-b522-dd3d0fcaf2aa)
Oct 22 00:58:20.356: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-4704.svc.cluster.local from pod dns-4704/dns-test-79ff06c6-9be7-4744-b522-dd3d0fcaf2aa: the server could not find the requested resource (get pods dns-test-79ff06c6-9be7-4744-b522-dd3d0fcaf2aa)
Oct 22 00:58:20.361: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-4704.svc.cluster.local from pod dns-4704/dns-test-79ff06c6-9be7-4744-b522-dd3d0fcaf2aa: the server could not find the requested resource (get pods dns-test-79ff06c6-9be7-4744-b522-dd3d0fcaf2aa)
Oct 22 00:58:20.393: INFO: Unable to read jessie_udp@dns-test-service.dns-4704.svc.cluster.local from pod dns-4704/dns-test-79ff06c6-9be7-4744-b522-dd3d0fcaf2aa: the server could not find the requested resource (get pods dns-test-79ff06c6-9be7-4744-b522-dd3d0fcaf2aa)
Oct 22 00:58:20.397: INFO: Unable to read jessie_tcp@dns-test-service.dns-4704.svc.cluster.local from pod dns-4704/dns-test-79ff06c6-9be7-4744-b522-dd3d0fcaf2aa: the server could not find the requested resource (get pods dns-test-79ff06c6-9be7-4744-b522-dd3d0fcaf2aa)
Oct 22 00:58:20.401: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-4704.svc.cluster.local from pod dns-4704/dns-test-79ff06c6-9be7-4744-b522-dd3d0fcaf2aa: the server could not find the requested resource (get pods dns-test-79ff06c6-9be7-4744-b522-dd3d0fcaf2aa)
Oct 22 00:58:20.407: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-4704.svc.cluster.local from pod dns-4704/dns-test-79ff06c6-9be7-4744-b522-dd3d0fcaf2aa: the server could not find the requested resource (get pods dns-test-79ff06c6-9be7-4744-b522-dd3d0fcaf2aa)
Oct 22 00:58:20.434: INFO: Lookups using dns-4704/dns-test-79ff06c6-9be7-4744-b522-dd3d0fcaf2aa failed for: [wheezy_udp@dns-test-service.dns-4704.svc.cluster.local wheezy_tcp@dns-test-service.dns-4704.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-4704.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-4704.svc.cluster.local jessie_udp@dns-test-service.dns-4704.svc.cluster.local jessie_tcp@dns-test-service.dns-4704.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-4704.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-4704.svc.cluster.local]

Oct 22 00:58:25.440: INFO: DNS probes using dns-4704/dns-test-79ff06c6-9be7-4744-b522-dd3d0fcaf2aa succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 00:58:25.535: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-4704" for this suite.
Oct 22 00:58:31.564: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 00:58:31.711: INFO: namespace dns-4704 deletion completed in 6.169466852s

• [SLOW TEST:40.596 seconds]
[sig-network] DNS
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 00:58:31.712: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Oct 22 00:58:31.767: INFO: Pod name rollover-pod: Found 0 pods out of 1
Oct 22 00:58:39.262: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Oct 22 00:58:39.262: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Oct 22 00:58:41.267: INFO: Creating deployment "test-rollover-deployment"
Oct 22 00:58:41.283: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Oct 22 00:58:43.296: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Oct 22 00:58:43.305: INFO: Ensure that both replica sets have 1 created replica
Oct 22 00:58:43.316: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Oct 22 00:58:43.333: INFO: Updating deployment test-rollover-deployment
Oct 22 00:58:43.333: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Oct 22 00:58:45.343: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Oct 22 00:58:45.350: INFO: Make sure deployment "test-rollover-deployment" is complete
Oct 22 00:58:45.358: INFO: all replica sets need to contain the pod-template-hash label
Oct 22 00:58:45.358: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707302721, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707302721, loc:(*time.Location)(0x7ec7a20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707302723, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707302721, loc:(*time.Location)(0x7ec7a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 22 00:58:47.367: INFO: all replica sets need to contain the pod-template-hash label
Oct 22 00:58:47.368: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707302721, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707302721, loc:(*time.Location)(0x7ec7a20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707302726, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707302721, loc:(*time.Location)(0x7ec7a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 22 00:58:49.367: INFO: all replica sets need to contain the pod-template-hash label
Oct 22 00:58:49.367: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707302721, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707302721, loc:(*time.Location)(0x7ec7a20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707302726, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707302721, loc:(*time.Location)(0x7ec7a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 22 00:58:51.368: INFO: all replica sets need to contain the pod-template-hash label
Oct 22 00:58:51.368: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707302721, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707302721, loc:(*time.Location)(0x7ec7a20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707302726, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707302721, loc:(*time.Location)(0x7ec7a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 22 00:58:53.368: INFO: all replica sets need to contain the pod-template-hash label
Oct 22 00:58:53.368: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707302721, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707302721, loc:(*time.Location)(0x7ec7a20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707302726, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707302721, loc:(*time.Location)(0x7ec7a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 22 00:58:55.369: INFO: all replica sets need to contain the pod-template-hash label
Oct 22 00:58:55.369: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707302721, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707302721, loc:(*time.Location)(0x7ec7a20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707302726, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707302721, loc:(*time.Location)(0x7ec7a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 22 00:58:57.369: INFO: 
Oct 22 00:58:57.369: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
Oct 22 00:58:57.383: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment,GenerateName:,Namespace:deployment-8062,SelfLink:/apis/apps/v1/namespaces/deployment-8062/deployments/test-rollover-deployment,UID:269ec644-3eff-46d2-9d4a-2ef9e422544d,ResourceVersion:22320,Generation:2,CreationTimestamp:2019-10-22 00:58:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-10-22 00:58:41 +0000 UTC 2019-10-22 00:58:41 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-10-22 00:58:56 +0000 UTC 2019-10-22 00:58:41 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rollover-deployment-854595fc44" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Oct 22 00:58:57.388: INFO: New ReplicaSet "test-rollover-deployment-854595fc44" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-854595fc44,GenerateName:,Namespace:deployment-8062,SelfLink:/apis/apps/v1/namespaces/deployment-8062/replicasets/test-rollover-deployment-854595fc44,UID:7d42d2d4-c9fa-4dc9-9a44-a0ef134cecf8,ResourceVersion:22309,Generation:2,CreationTimestamp:2019-10-22 00:58:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 854595fc44,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 269ec644-3eff-46d2-9d4a-2ef9e422544d 0xc0024eaa07 0xc0024eaa08}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 854595fc44,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 854595fc44,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Oct 22 00:58:57.388: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Oct 22 00:58:57.388: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-controller,GenerateName:,Namespace:deployment-8062,SelfLink:/apis/apps/v1/namespaces/deployment-8062/replicasets/test-rollover-controller,UID:ce843e5f-49d1-4b7a-93a4-17b40e7ca5ca,ResourceVersion:22318,Generation:2,CreationTimestamp:2019-10-22 00:58:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 269ec644-3eff-46d2-9d4a-2ef9e422544d 0xc0024ea917 0xc0024ea918}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Oct 22 00:58:57.389: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-9b8b997cf,GenerateName:,Namespace:deployment-8062,SelfLink:/apis/apps/v1/namespaces/deployment-8062/replicasets/test-rollover-deployment-9b8b997cf,UID:94bb648d-e517-4c99-9a87-cb17c026a444,ResourceVersion:22276,Generation:2,CreationTimestamp:2019-10-22 00:58:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 9b8b997cf,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 269ec644-3eff-46d2-9d4a-2ef9e422544d 0xc0024eaad0 0xc0024eaad1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 9b8b997cf,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 9b8b997cf,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Oct 22 00:58:57.393: INFO: Pod "test-rollover-deployment-854595fc44-nxvjw" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-854595fc44-nxvjw,GenerateName:test-rollover-deployment-854595fc44-,Namespace:deployment-8062,SelfLink:/api/v1/namespaces/deployment-8062/pods/test-rollover-deployment-854595fc44-nxvjw,UID:e56ccab8-9e9f-4e70-b70e-8b94d4e3b83d,ResourceVersion:22292,Generation:0,CreationTimestamp:2019-10-22 00:58:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 854595fc44,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.244.1.131/32,},OwnerReferences:[{apps/v1 ReplicaSet test-rollover-deployment-854595fc44 7d42d2d4-c9fa-4dc9-9a44-a0ef134cecf8 0xc0024ebef7 0xc0024ebef8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-fkg5r {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-fkg5r,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-fkg5r true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:mip-bd-vm41.mip.storage.hpecorp.net,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0024ebf80} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0009f0010}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:58:43 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:58:46 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:58:46 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-22 00:58:43 +0000 UTC  }],Message:,Reason:,HostIP:16.143.20.138,PodIP:10.244.1.131,StartTime:2019-10-22 00:58:43 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-10-22 00:58:45 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://2e94943c3d0da120222a6475954e824ea9c40bdcf68847519d70c63a86dc2675}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 00:58:57.393: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-8062" for this suite.
Oct 22 00:59:03.417: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 00:59:03.697: INFO: namespace deployment-8062 deletion completed in 6.299276289s

• [SLOW TEST:31.985 seconds]
[sig-apps] Deployment
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support rollover [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 00:59:03.697: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:179
[It] should be submitted and removed  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 00:59:03.765: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-6991" for this suite.
Oct 22 00:59:25.790: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 00:59:25.934: INFO: namespace pods-6991 deletion completed in 22.163045956s

• [SLOW TEST:22.237 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should be submitted and removed  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 00:59:25.934: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Starting the proxy
Oct 22 00:59:25.982: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-172996996 proxy --unix-socket=/tmp/kubectl-proxy-unix964845331/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 00:59:26.105: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5124" for this suite.
Oct 22 00:59:32.127: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 00:59:32.278: INFO: namespace kubectl-5124 deletion completed in 6.166273592s

• [SLOW TEST:6.344 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Proxy server
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 00:59:32.279: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 00:59:34.391: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-3215" for this suite.
Oct 22 00:59:40.415: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 00:59:40.562: INFO: namespace emptydir-wrapper-3215 deletion completed in 6.165851018s

• [SLOW TEST:8.283 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not conflict [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 00:59:40.562: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename hostpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test hostPath mode
Oct 22 00:59:40.625: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "hostpath-9554" to be "success or failure"
Oct 22 00:59:40.631: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 5.869364ms
Oct 22 00:59:42.637: INFO: Pod "pod-host-path-test": Phase="Running", Reason="", readiness=false. Elapsed: 2.01151583s
Oct 22 00:59:44.642: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017226144s
STEP: Saw pod success
Oct 22 00:59:44.643: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Oct 22 00:59:44.646: INFO: Trying to get logs from node mip-bd-vm41.mip.storage.hpecorp.net pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Oct 22 00:59:44.674: INFO: Waiting for pod pod-host-path-test to disappear
Oct 22 00:59:44.679: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 00:59:44.679: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "hostpath-9554" for this suite.
Oct 22 00:59:50.700: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 00:59:50.853: INFO: namespace hostpath-9554 deletion completed in 6.168665239s

• [SLOW TEST:10.291 seconds]
[sig-storage] HostPath
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 00:59:50.855: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-a1647cb1-c20b-4526-ae76-92410588ecf8
STEP: Creating a pod to test consume configMaps
Oct 22 00:59:50.951: INFO: Waiting up to 5m0s for pod "pod-configmaps-7683ff06-2628-4c0c-87bb-a95627218ed7" in namespace "configmap-2163" to be "success or failure"
Oct 22 00:59:50.961: INFO: Pod "pod-configmaps-7683ff06-2628-4c0c-87bb-a95627218ed7": Phase="Pending", Reason="", readiness=false. Elapsed: 10.120184ms
Oct 22 00:59:52.966: INFO: Pod "pod-configmaps-7683ff06-2628-4c0c-87bb-a95627218ed7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01436101s
STEP: Saw pod success
Oct 22 00:59:52.966: INFO: Pod "pod-configmaps-7683ff06-2628-4c0c-87bb-a95627218ed7" satisfied condition "success or failure"
Oct 22 00:59:52.969: INFO: Trying to get logs from node mip-bd-vm40.mip.storage.hpecorp.net pod pod-configmaps-7683ff06-2628-4c0c-87bb-a95627218ed7 container configmap-volume-test: <nil>
STEP: delete the pod
Oct 22 00:59:52.995: INFO: Waiting for pod pod-configmaps-7683ff06-2628-4c0c-87bb-a95627218ed7 to disappear
Oct 22 00:59:52.999: INFO: Pod pod-configmaps-7683ff06-2628-4c0c-87bb-a95627218ed7 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 00:59:52.999: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2163" for this suite.
Oct 22 00:59:59.020: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 00:59:59.168: INFO: namespace configmap-2163 deletion completed in 6.164696295s

• [SLOW TEST:8.313 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 00:59:59.169: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name cm-test-opt-del-e009516a-c349-4520-ab9c-4d67909aba94
STEP: Creating configMap with name cm-test-opt-upd-3a8e63f1-3179-4b58-9d72-c1bb28fb3d27
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-e009516a-c349-4520-ab9c-4d67909aba94
STEP: Updating configmap cm-test-opt-upd-3a8e63f1-3179-4b58-9d72-c1bb28fb3d27
STEP: Creating configMap with name cm-test-opt-create-e6a71a53-0d0c-419c-beaf-958941cab9b5
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 01:00:23.346: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5756" for this suite.
Oct 22 01:01:11.365: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 01:01:11.500: INFO: namespace projected-5756 deletion completed in 48.150175194s

• [SLOW TEST:72.332 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 01:01:11.501: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Performing setup for networking test in namespace pod-network-test-2888
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Oct 22 01:01:11.548: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Oct 22 01:01:27.648: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.244.1.135 8081 | grep -v '^\s*$'] Namespace:pod-network-test-2888 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 22 01:01:27.648: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
Oct 22 01:01:28.784: INFO: Found all expected endpoints: [netserver-0]
Oct 22 01:01:32.265: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.244.2.112 8081 | grep -v '^\s*$'] Namespace:pod-network-test-2888 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 22 01:01:32.265: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
Oct 22 01:01:33.416: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 01:01:33.416: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-2888" for this suite.
Oct 22 01:01:55.438: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 01:01:55.583: INFO: namespace pod-network-test-2888 deletion completed in 22.160695607s

• [SLOW TEST:44.083 seconds]
[sig-network] Networking
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 01:01:55.584: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:63
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Oct 22 01:02:07.698: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Oct 22 01:02:07.702: INFO: Pod pod-with-poststart-http-hook still exists
Oct 22 01:02:09.703: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Oct 22 01:02:13.290: INFO: Pod pod-with-poststart-http-hook still exists
Oct 22 01:02:13.703: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Oct 22 01:02:13.708: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 01:02:13.708: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-2464" for this suite.
Oct 22 01:02:39.729: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 01:02:39.880: INFO: namespace container-lifecycle-hook-2464 deletion completed in 26.167523507s

• [SLOW TEST:44.296 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when create a pod with lifecycle hook
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 01:02:39.881: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Oct 22 01:02:43.347: INFO: Pod name wrapped-volume-race-a185c394-8d7b-4ada-964e-bdd80c02c1e0: Found 0 pods out of 5
Oct 22 01:02:48.356: INFO: Pod name wrapped-volume-race-a185c394-8d7b-4ada-964e-bdd80c02c1e0: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-a185c394-8d7b-4ada-964e-bdd80c02c1e0 in namespace emptydir-wrapper-6587, will wait for the garbage collector to delete the pods
Oct 22 01:02:58.449: INFO: Deleting ReplicationController wrapped-volume-race-a185c394-8d7b-4ada-964e-bdd80c02c1e0 took: 10.35135ms
Oct 22 01:02:58.949: INFO: Terminating ReplicationController wrapped-volume-race-a185c394-8d7b-4ada-964e-bdd80c02c1e0 pods took: 500.348975ms
STEP: Creating RC which spawns configmap-volume pods
Oct 22 01:03:41.070: INFO: Pod name wrapped-volume-race-881cc911-bd0e-49b5-8143-69b577426614: Found 0 pods out of 5
Oct 22 01:03:46.082: INFO: Pod name wrapped-volume-race-881cc911-bd0e-49b5-8143-69b577426614: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-881cc911-bd0e-49b5-8143-69b577426614 in namespace emptydir-wrapper-6587, will wait for the garbage collector to delete the pods
Oct 22 01:04:00.180: INFO: Deleting ReplicationController wrapped-volume-race-881cc911-bd0e-49b5-8143-69b577426614 took: 9.553287ms
Oct 22 01:04:00.686: INFO: Terminating ReplicationController wrapped-volume-race-881cc911-bd0e-49b5-8143-69b577426614 pods took: 505.522956ms
STEP: Creating RC which spawns configmap-volume pods
Oct 22 01:04:41.410: INFO: Pod name wrapped-volume-race-d5281304-e3a0-4dfa-a9a1-86ef87bb5f1c: Found 0 pods out of 5
Oct 22 01:04:47.290: INFO: Pod name wrapped-volume-race-d5281304-e3a0-4dfa-a9a1-86ef87bb5f1c: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-d5281304-e3a0-4dfa-a9a1-86ef87bb5f1c in namespace emptydir-wrapper-6587, will wait for the garbage collector to delete the pods
Oct 22 01:04:59.389: INFO: Deleting ReplicationController wrapped-volume-race-d5281304-e3a0-4dfa-a9a1-86ef87bb5f1c took: 9.562292ms
Oct 22 01:04:59.890: INFO: Terminating ReplicationController wrapped-volume-race-d5281304-e3a0-4dfa-a9a1-86ef87bb5f1c pods took: 500.366161ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 01:05:42.366: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-6587" for this suite.
Oct 22 01:05:50.396: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 01:05:50.572: INFO: namespace emptydir-wrapper-6587 deletion completed in 8.201490018s

• [SLOW TEST:190.692 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 01:05:50.573: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Oct 22 01:06:08.643: INFO: Container started at 2019-10-22 01:05:51 +0000 UTC, pod became ready at 2019-10-22 01:06:06 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 01:06:08.643: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-4837" for this suite.
Oct 22 01:06:32.667: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 01:06:32.817: INFO: namespace container-probe-4837 deletion completed in 24.168375011s

• [SLOW TEST:42.244 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 01:06:32.817: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Oct 22 01:06:32.876: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Oct 22 01:06:37.882: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Oct 22 01:06:37.882: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
Oct 22 01:06:37.908: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment,GenerateName:,Namespace:deployment-753,SelfLink:/apis/apps/v1/namespaces/deployment-753/deployments/test-cleanup-deployment,UID:aa009985-7fee-4627-9b5d-f118bfa2c2a9,ResourceVersion:24147,Generation:1,CreationTimestamp:2019-10-22 01:06:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[],ReadyReplicas:0,CollisionCount:nil,},}

Oct 22 01:06:37.918: INFO: New ReplicaSet of Deployment "test-cleanup-deployment" is nil.
Oct 22 01:06:37.918: INFO: All old ReplicaSets of Deployment "test-cleanup-deployment":
Oct 22 01:06:37.918: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller,GenerateName:,Namespace:deployment-753,SelfLink:/apis/apps/v1/namespaces/deployment-753/replicasets/test-cleanup-controller,UID:c2320e42-7926-4ede-aff4-3f8824069da2,ResourceVersion:24148,Generation:1,CreationTimestamp:2019-10-22 01:06:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment aa009985-7fee-4627-9b5d-f118bfa2c2a9 0xc0024c3077 0xc0024c3078}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Oct 22 01:06:37.932: INFO: Pod "test-cleanup-controller-6bdbz" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller-6bdbz,GenerateName:test-cleanup-controller-,Namespace:deployment-753,SelfLink:/api/v1/namespaces/deployment-753/pods/test-cleanup-controller-6bdbz,UID:05b4a940-02f0-4f93-9bce-ee5f5f9a956b,ResourceVersion:24139,Generation:0,CreationTimestamp:2019-10-22 01:06:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.244.1.138/32,},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-controller c2320e42-7926-4ede-aff4-3f8824069da2 0xc0033de417 0xc0033de418}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-cpnwt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-cpnwt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-cpnwt true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:mip-bd-vm41.mip.storage.hpecorp.net,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0033de480} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0033de4a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-22 01:06:32 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-10-22 01:06:33 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-10-22 01:06:33 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-22 01:06:32 +0000 UTC  }],Message:,Reason:,HostIP:16.143.20.138,PodIP:10.244.1.138,StartTime:2019-10-22 01:06:32 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-10-22 01:06:33 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/nginx:1.14-alpine docker-pullable://docker.io/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://bf06fddf4e464521f622dd0338d64071af9452e90318c536be2d24d231e5a556}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 01:06:37.932: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-753" for this suite.
Oct 22 01:06:43.967: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 01:06:44.114: INFO: namespace deployment-753 deletion completed in 6.168817679s

• [SLOW TEST:11.296 seconds]
[sig-apps] Deployment
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 01:06:44.114: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
Oct 22 01:07:14.213: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W1022 01:07:14.213199      18 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 01:07:14.213: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-6150" for this suite.
Oct 22 01:07:20.233: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 01:07:20.387: INFO: namespace gc-6150 deletion completed in 6.169062844s

• [SLOW TEST:36.273 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 01:07:20.388: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating the pod
Oct 22 01:07:22.985: INFO: Successfully updated pod "labelsupdateadf10c01-6606-476a-83cf-9e5c08c3434a"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 01:07:27.027: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9049" for this suite.
Oct 22 01:07:49.053: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 01:07:49.208: INFO: namespace downward-api-9049 deletion completed in 22.173529018s

• [SLOW TEST:28.820 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 01:07:49.209: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Oct 22 01:07:49.255: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 create -f - --namespace=kubectl-9538'
Oct 22 01:07:49.688: INFO: stderr: ""
Oct 22 01:07:49.688: INFO: stdout: "replicationcontroller/redis-master created\n"
Oct 22 01:07:49.688: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 create -f - --namespace=kubectl-9538'
Oct 22 01:07:50.015: INFO: stderr: ""
Oct 22 01:07:50.015: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Oct 22 01:07:51.021: INFO: Selector matched 1 pods for map[app:redis]
Oct 22 01:07:51.021: INFO: Found 0 / 1
Oct 22 01:07:52.022: INFO: Selector matched 1 pods for map[app:redis]
Oct 22 01:07:52.022: INFO: Found 1 / 1
Oct 22 01:07:52.022: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Oct 22 01:07:52.026: INFO: Selector matched 1 pods for map[app:redis]
Oct 22 01:07:52.026: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Oct 22 01:07:52.026: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 describe pod redis-master-5xn7z --namespace=kubectl-9538'
Oct 22 01:07:52.214: INFO: stderr: ""
Oct 22 01:07:52.214: INFO: stdout: "Name:           redis-master-5xn7z\nNamespace:      kubectl-9538\nPriority:       0\nNode:           mip-bd-vm40.mip.storage.hpecorp.net/16.143.20.137\nStart Time:     Tue, 22 Oct 2019 01:07:49 +0000\nLabels:         app=redis\n                role=master\nAnnotations:    cni.projectcalico.org/podIP: 10.244.2.132/32\nStatus:         Running\nIP:             10.244.2.132\nControlled By:  ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   docker://faaffbe2291c9249b3e4917bbaa0db3729aaa99082b8eb3b4883da20f9e2c472\n    Image:          gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Image ID:       docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Tue, 22 Oct 2019 01:07:50 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-wvqpz (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-wvqpz:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-wvqpz\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age   From                                          Message\n  ----    ------     ----  ----                                          -------\n  Normal  Scheduled  3s    default-scheduler                             Successfully assigned kubectl-9538/redis-master-5xn7z to mip-bd-vm40.mip.storage.hpecorp.net\n  Normal  Pulled     2s    kubelet, mip-bd-vm40.mip.storage.hpecorp.net  Container image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\" already present on machine\n  Normal  Created    2s    kubelet, mip-bd-vm40.mip.storage.hpecorp.net  Created container redis-master\n  Normal  Started    2s    kubelet, mip-bd-vm40.mip.storage.hpecorp.net  Started container redis-master\n"
Oct 22 01:07:52.214: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 describe rc redis-master --namespace=kubectl-9538'
Oct 22 01:07:52.404: INFO: stderr: ""
Oct 22 01:07:52.405: INFO: stdout: "Name:         redis-master\nNamespace:    kubectl-9538\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  3s    replication-controller  Created pod: redis-master-5xn7z\n"
Oct 22 01:07:52.405: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 describe service redis-master --namespace=kubectl-9538'
Oct 22 01:07:52.589: INFO: stderr: ""
Oct 22 01:07:52.589: INFO: stdout: "Name:              redis-master\nNamespace:         kubectl-9538\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                10.96.95.178\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         10.244.2.132:6379\nSession Affinity:  None\nEvents:            <none>\n"
Oct 22 01:07:52.594: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 describe node mip-bd-vm39.mip.storage.hpecorp.net'
Oct 22 01:07:52.801: INFO: stderr: ""
Oct 22 01:07:52.801: INFO: stdout: "Name:               mip-bd-vm39.mip.storage.hpecorp.net\nRoles:              master\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=mip-bd-vm39.mip.storage.hpecorp.net\n                    kubernetes.io/os=linux\n                    node-role.kubernetes.io/master=\nAnnotations:        flannel.alpha.coreos.com/backend-data: {\"VtepMAC\":\"06:26:eb:1f:bb:4b\"}\n                    flannel.alpha.coreos.com/backend-type: vxlan\n                    flannel.alpha.coreos.com/kube-subnet-manager: true\n                    flannel.alpha.coreos.com/public-ip: 16.143.20.136\n                    kubeadm.alpha.kubernetes.io/cri-socket: /var/run/dockershim.sock\n                    node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Mon, 21 Oct 2019 22:09:27 +0000\nTaints:             node-role.kubernetes.io/master:NoSchedule\nUnschedulable:      false\nConditions:\n  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----             ------  -----------------                 ------------------                ------                       -------\n  MemoryPressure   False   Tue, 22 Oct 2019 01:07:22 +0000   Mon, 21 Oct 2019 22:09:27 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure     False   Tue, 22 Oct 2019 01:07:22 +0000   Mon, 21 Oct 2019 22:09:27 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure      False   Tue, 22 Oct 2019 01:07:22 +0000   Mon, 21 Oct 2019 22:09:27 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready            True    Tue, 22 Oct 2019 01:07:22 +0000   Mon, 21 Oct 2019 22:11:37 +0000   KubeletReady                 kubelet is posting ready status\nAddresses:\n  InternalIP:  16.143.20.136\n  Hostname:    mip-bd-vm39.mip.storage.hpecorp.net\nCapacity:\n cpu:                4\n ephemeral-storage:  401682812Ki\n hugepages-2Mi:      0\n memory:             32780576Ki\n pods:               110\nAllocatable:\n cpu:                4\n ephemeral-storage:  370190878927\n hugepages-2Mi:      0\n memory:             32678176Ki\n pods:               110\nSystem Info:\n Machine ID:                 dbc639b839944b4286efa366e6005397\n System UUID:                54D22B42-093C-E1CA-E7F7-88C7E15728CA\n Boot ID:                    a2df1b4b-a668-491d-a639-103cb0d819fb\n Kernel Version:             3.10.0-1062.1.2.el7.x86_64\n OS Image:                   CentOS Linux 7 (Core)\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  docker://1.13.1\n Kubelet Version:            v1.15.3\n Kube-Proxy Version:         v1.15.3\nPodCIDR:                     10.244.0.0/24\nNon-terminated Pods:         (10 in total)\n  Namespace                  Name                                                           CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                  ----                                                           ------------  ----------  ---------------  -------------  ---\n  heptio-sonobuoy            sonobuoy-systemd-logs-daemon-set-d36ba0a04f4c410a-h7jb5        0 (0%)        0 (0%)      0 (0%)           0 (0%)         74m\n  kube-system                canal-ntxnd                                                    250m (6%)     0 (0%)      0 (0%)           0 (0%)         176m\n  kube-system                coredns-5c98db65d4-cd58r                                       100m (2%)     0 (0%)      70Mi (0%)        170Mi (0%)     178m\n  kube-system                coredns-5c98db65d4-dmhq2                                       100m (2%)     0 (0%)      70Mi (0%)        170Mi (0%)     178m\n  kube-system                etcd-mip-bd-vm39.mip.storage.hpecorp.net                       0 (0%)        0 (0%)      0 (0%)           0 (0%)         177m\n  kube-system                kube-apiserver-mip-bd-vm39.mip.storage.hpecorp.net             250m (6%)     0 (0%)      0 (0%)           0 (0%)         147m\n  kube-system                kube-controller-manager-mip-bd-vm39.mip.storage.hpecorp.net    200m (5%)     0 (0%)      0 (0%)           0 (0%)         177m\n  kube-system                kube-proxy-st6jh                                               0 (0%)        0 (0%)      0 (0%)           0 (0%)         178m\n  kube-system                kube-scheduler-mip-bd-vm39.mip.storage.hpecorp.net             100m (2%)     0 (0%)      0 (0%)           0 (0%)         177m\n  kube-system                kubernetes-dashboard-7d75c474bb-hxg75                          0 (0%)        0 (0%)      0 (0%)           0 (0%)         176m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests    Limits\n  --------           --------    ------\n  cpu                1 (25%)     0 (0%)\n  memory             140Mi (0%)  340Mi (1%)\n  ephemeral-storage  0 (0%)      0 (0%)\nEvents:              <none>\n"
Oct 22 01:07:52.801: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 describe namespace kubectl-9538'
Oct 22 01:07:52.994: INFO: stderr: ""
Oct 22 01:07:52.994: INFO: stdout: "Name:         kubectl-9538\nLabels:       e2e-framework=kubectl\n              e2e-run=f78efc7c-21e8-43ed-bdf6-34bfcaef6b7b\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 01:07:52.994: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9538" for this suite.
Oct 22 01:08:15.014: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 01:08:15.166: INFO: namespace kubectl-9538 deletion completed in 22.166169953s

• [SLOW TEST:25.957 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl describe
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 01:08:15.166: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating the pod
Oct 22 01:08:17.777: INFO: Successfully updated pod "annotationupdate9b150b9f-90af-40ea-8456-b3573685b0df"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 01:08:19.805: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3207" for this suite.
Oct 22 01:08:41.826: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 01:08:41.987: INFO: namespace downward-api-3207 deletion completed in 22.176273519s

• [SLOW TEST:26.820 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 01:08:41.988: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-52c6230b-cac6-436c-9fba-f5fbdcfc9949
STEP: Creating a pod to test consume secrets
Oct 22 01:08:42.050: INFO: Waiting up to 5m0s for pod "pod-secrets-11b767a5-f9fa-46d5-bf0b-b38de33f2994" in namespace "secrets-2544" to be "success or failure"
Oct 22 01:08:42.054: INFO: Pod "pod-secrets-11b767a5-f9fa-46d5-bf0b-b38de33f2994": Phase="Pending", Reason="", readiness=false. Elapsed: 3.846909ms
Oct 22 01:08:44.060: INFO: Pod "pod-secrets-11b767a5-f9fa-46d5-bf0b-b38de33f2994": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009637956s
STEP: Saw pod success
Oct 22 01:08:44.060: INFO: Pod "pod-secrets-11b767a5-f9fa-46d5-bf0b-b38de33f2994" satisfied condition "success or failure"
Oct 22 01:08:44.064: INFO: Trying to get logs from node mip-bd-vm40.mip.storage.hpecorp.net pod pod-secrets-11b767a5-f9fa-46d5-bf0b-b38de33f2994 container secret-volume-test: <nil>
STEP: delete the pod
Oct 22 01:08:44.091: INFO: Waiting for pod pod-secrets-11b767a5-f9fa-46d5-bf0b-b38de33f2994 to disappear
Oct 22 01:08:44.094: INFO: Pod pod-secrets-11b767a5-f9fa-46d5-bf0b-b38de33f2994 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 01:08:44.094: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-2544" for this suite.
Oct 22 01:08:50.114: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 01:08:50.265: INFO: namespace secrets-2544 deletion completed in 6.165705593s

• [SLOW TEST:8.278 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 01:08:50.266: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name cm-test-opt-del-ac711cd3-2f58-418f-b191-127a5160d30b
STEP: Creating configMap with name cm-test-opt-upd-810986d1-6aa0-44a1-a3a4-e486d70addf4
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-ac711cd3-2f58-418f-b191-127a5160d30b
STEP: Updating configmap cm-test-opt-upd-810986d1-6aa0-44a1-a3a4-e486d70addf4
STEP: Creating configMap with name cm-test-opt-create-616da2dd-1367-44d2-a71b-f1c4bd5e4c30
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 01:10:04.471: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9291" for this suite.
Oct 22 01:10:26.491: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 01:10:26.658: INFO: namespace configmap-9291 deletion completed in 22.182378826s

• [SLOW TEST:96.393 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 01:10:26.659: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 01:10:28.739: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-1234" for this suite.
Oct 22 01:11:14.779: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 01:11:14.934: INFO: namespace kubelet-test-1234 deletion completed in 46.172664015s

• [SLOW TEST:48.275 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when scheduling a busybox command in a pod
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:40
    should print the output to logs [NodeConformance] [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 01:11:14.935: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-18911bd9-704b-4bbe-8eb9-d1fe379b6a64
STEP: Creating a pod to test consume secrets
Oct 22 01:11:14.999: INFO: Waiting up to 5m0s for pod "pod-secrets-48a92783-84bb-439e-9a38-f0938a0d642e" in namespace "secrets-5972" to be "success or failure"
Oct 22 01:11:15.004: INFO: Pod "pod-secrets-48a92783-84bb-439e-9a38-f0938a0d642e": Phase="Pending", Reason="", readiness=false. Elapsed: 5.091513ms
Oct 22 01:11:17.011: INFO: Pod "pod-secrets-48a92783-84bb-439e-9a38-f0938a0d642e": Phase="Running", Reason="", readiness=true. Elapsed: 2.012109694s
Oct 22 01:11:19.016: INFO: Pod "pod-secrets-48a92783-84bb-439e-9a38-f0938a0d642e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016998529s
STEP: Saw pod success
Oct 22 01:11:19.016: INFO: Pod "pod-secrets-48a92783-84bb-439e-9a38-f0938a0d642e" satisfied condition "success or failure"
Oct 22 01:11:19.020: INFO: Trying to get logs from node mip-bd-vm41.mip.storage.hpecorp.net pod pod-secrets-48a92783-84bb-439e-9a38-f0938a0d642e container secret-volume-test: <nil>
STEP: delete the pod
Oct 22 01:11:19.047: INFO: Waiting for pod pod-secrets-48a92783-84bb-439e-9a38-f0938a0d642e to disappear
Oct 22 01:11:19.050: INFO: Pod pod-secrets-48a92783-84bb-439e-9a38-f0938a0d642e no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 01:11:19.050: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5972" for this suite.
Oct 22 01:11:25.068: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 01:11:25.216: INFO: namespace secrets-5972 deletion completed in 6.161360014s

• [SLOW TEST:10.281 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 01:11:25.216: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-map-dd8af8aa-bf60-4d18-ba49-7047a492e75c
STEP: Creating a pod to test consume configMaps
Oct 22 01:11:25.271: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-fdfb8d01-edc2-45bd-b964-a153693c5061" in namespace "projected-9205" to be "success or failure"
Oct 22 01:11:25.276: INFO: Pod "pod-projected-configmaps-fdfb8d01-edc2-45bd-b964-a153693c5061": Phase="Pending", Reason="", readiness=false. Elapsed: 4.117896ms
Oct 22 01:11:27.281: INFO: Pod "pod-projected-configmaps-fdfb8d01-edc2-45bd-b964-a153693c5061": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009578161s
STEP: Saw pod success
Oct 22 01:11:27.281: INFO: Pod "pod-projected-configmaps-fdfb8d01-edc2-45bd-b964-a153693c5061" satisfied condition "success or failure"
Oct 22 01:11:27.285: INFO: Trying to get logs from node mip-bd-vm40.mip.storage.hpecorp.net pod pod-projected-configmaps-fdfb8d01-edc2-45bd-b964-a153693c5061 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Oct 22 01:11:27.313: INFO: Waiting for pod pod-projected-configmaps-fdfb8d01-edc2-45bd-b964-a153693c5061 to disappear
Oct 22 01:11:27.317: INFO: Pod pod-projected-configmaps-fdfb8d01-edc2-45bd-b964-a153693c5061 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 01:11:27.317: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9205" for this suite.
Oct 22 01:11:33.338: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 01:11:33.500: INFO: namespace projected-9205 deletion completed in 6.177815564s

• [SLOW TEST:8.284 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 01:11:33.500: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename svc-latency
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating replication controller svc-latency-rc in namespace svc-latency-6005
I1022 01:11:33.556989      18 runners.go:180] Created replication controller with name: svc-latency-rc, namespace: svc-latency-6005, replica count: 1
I1022 01:11:34.607591      18 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1022 01:11:35.607880      18 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Oct 22 01:11:35.726: INFO: Created: latency-svc-7nzkm
Oct 22 01:11:35.730: INFO: Got endpoints: latency-svc-7nzkm [22.658681ms]
Oct 22 01:11:35.767: INFO: Created: latency-svc-cj7cp
Oct 22 01:11:35.771: INFO: Got endpoints: latency-svc-cj7cp [40.716694ms]
Oct 22 01:11:35.774: INFO: Created: latency-svc-lp6td
Oct 22 01:11:35.786: INFO: Got endpoints: latency-svc-lp6td [55.110297ms]
Oct 22 01:11:35.794: INFO: Created: latency-svc-dhh9m
Oct 22 01:11:35.798: INFO: Got endpoints: latency-svc-dhh9m [66.333769ms]
Oct 22 01:11:35.814: INFO: Created: latency-svc-2bz8x
Oct 22 01:11:35.822: INFO: Got endpoints: latency-svc-2bz8x [90.612263ms]
Oct 22 01:11:35.833: INFO: Created: latency-svc-g8vvf
Oct 22 01:11:35.833: INFO: Got endpoints: latency-svc-g8vvf [101.081302ms]
Oct 22 01:11:35.835: INFO: Created: latency-svc-ksznq
Oct 22 01:11:35.843: INFO: Got endpoints: latency-svc-ksznq [111.039193ms]
Oct 22 01:11:35.847: INFO: Created: latency-svc-6xcw7
Oct 22 01:11:35.854: INFO: Created: latency-svc-tlgvk
Oct 22 01:11:35.857: INFO: Got endpoints: latency-svc-6xcw7 [124.964818ms]
Oct 22 01:11:35.866: INFO: Got endpoints: latency-svc-tlgvk [134.420916ms]
Oct 22 01:11:35.872: INFO: Created: latency-svc-tvgfs
Oct 22 01:11:35.877: INFO: Got endpoints: latency-svc-tvgfs [33.844282ms]
Oct 22 01:11:35.884: INFO: Created: latency-svc-tfnpg
Oct 22 01:11:35.893: INFO: Created: latency-svc-7gccr
Oct 22 01:11:35.897: INFO: Got endpoints: latency-svc-tfnpg [165.39282ms]
Oct 22 01:11:35.900: INFO: Got endpoints: latency-svc-7gccr [168.690497ms]
Oct 22 01:11:35.909: INFO: Created: latency-svc-cf87x
Oct 22 01:11:35.913: INFO: Got endpoints: latency-svc-cf87x [181.414996ms]
Oct 22 01:11:35.917: INFO: Created: latency-svc-vc5vk
Oct 22 01:11:35.925: INFO: Got endpoints: latency-svc-vc5vk [194.12914ms]
Oct 22 01:11:35.929: INFO: Created: latency-svc-zj8fk
Oct 22 01:11:35.937: INFO: Got endpoints: latency-svc-zj8fk [204.958618ms]
Oct 22 01:11:35.946: INFO: Created: latency-svc-jsqm5
Oct 22 01:11:35.951: INFO: Got endpoints: latency-svc-jsqm5 [219.486562ms]
Oct 22 01:11:35.956: INFO: Created: latency-svc-lrwwk
Oct 22 01:11:35.963: INFO: Got endpoints: latency-svc-lrwwk [231.679017ms]
Oct 22 01:11:35.964: INFO: Created: latency-svc-z6dnf
Oct 22 01:11:35.972: INFO: Got endpoints: latency-svc-z6dnf [200.168795ms]
Oct 22 01:11:35.977: INFO: Created: latency-svc-phdb5
Oct 22 01:11:35.984: INFO: Got endpoints: latency-svc-phdb5 [197.527592ms]
Oct 22 01:11:35.988: INFO: Created: latency-svc-ptbk5
Oct 22 01:11:35.994: INFO: Got endpoints: latency-svc-ptbk5 [195.889476ms]
Oct 22 01:11:36.013: INFO: Created: latency-svc-wmgft
Oct 22 01:11:36.018: INFO: Got endpoints: latency-svc-wmgft [196.197689ms]
Oct 22 01:11:36.022: INFO: Created: latency-svc-dctvx
Oct 22 01:11:36.033: INFO: Got endpoints: latency-svc-dctvx [199.994517ms]
Oct 22 01:11:36.043: INFO: Created: latency-svc-4vbch
Oct 22 01:11:36.047: INFO: Got endpoints: latency-svc-4vbch [190.353874ms]
Oct 22 01:11:36.051: INFO: Created: latency-svc-rqxkg
Oct 22 01:11:36.057: INFO: Got endpoints: latency-svc-rqxkg [191.04265ms]
Oct 22 01:11:36.061: INFO: Created: latency-svc-n4bqj
Oct 22 01:11:36.064: INFO: Got endpoints: latency-svc-n4bqj [187.453858ms]
Oct 22 01:11:36.069: INFO: Created: latency-svc-kpldd
Oct 22 01:11:36.078: INFO: Got endpoints: latency-svc-kpldd [181.171828ms]
Oct 22 01:11:36.080: INFO: Created: latency-svc-fqnd6
Oct 22 01:11:36.086: INFO: Got endpoints: latency-svc-fqnd6 [186.326247ms]
Oct 22 01:11:36.091: INFO: Created: latency-svc-6kwr9
Oct 22 01:11:36.099: INFO: Got endpoints: latency-svc-6kwr9 [185.889099ms]
Oct 22 01:11:36.101: INFO: Created: latency-svc-g2vwh
Oct 22 01:11:36.106: INFO: Got endpoints: latency-svc-g2vwh [180.836336ms]
Oct 22 01:11:36.112: INFO: Created: latency-svc-fnfbh
Oct 22 01:11:36.119: INFO: Got endpoints: latency-svc-fnfbh [182.531255ms]
Oct 22 01:11:36.124: INFO: Created: latency-svc-qtwlx
Oct 22 01:11:36.127: INFO: Created: latency-svc-fz7nm
Oct 22 01:11:36.133: INFO: Got endpoints: latency-svc-qtwlx [181.850853ms]
Oct 22 01:11:36.134: INFO: Got endpoints: latency-svc-fz7nm [170.670788ms]
Oct 22 01:11:36.144: INFO: Created: latency-svc-6mhkk
Oct 22 01:11:36.149: INFO: Got endpoints: latency-svc-6mhkk [177.817397ms]
Oct 22 01:11:36.154: INFO: Created: latency-svc-qtvdz
Oct 22 01:11:36.162: INFO: Got endpoints: latency-svc-qtvdz [178.119408ms]
Oct 22 01:11:36.166: INFO: Created: latency-svc-d72xn
Oct 22 01:11:36.172: INFO: Got endpoints: latency-svc-d72xn [178.383564ms]
Oct 22 01:11:36.174: INFO: Created: latency-svc-ghts2
Oct 22 01:11:36.175: INFO: Got endpoints: latency-svc-ghts2 [156.469579ms]
Oct 22 01:11:36.182: INFO: Created: latency-svc-jfbhx
Oct 22 01:11:36.188: INFO: Created: latency-svc-vv998
Oct 22 01:11:36.195: INFO: Got endpoints: latency-svc-jfbhx [161.983488ms]
Oct 22 01:11:36.196: INFO: Created: latency-svc-8wlrj
Oct 22 01:11:36.199: INFO: Got endpoints: latency-svc-vv998 [152.026192ms]
Oct 22 01:11:36.203: INFO: Got endpoints: latency-svc-8wlrj [146.277258ms]
Oct 22 01:11:36.210: INFO: Created: latency-svc-d5kzx
Oct 22 01:11:36.220: INFO: Created: latency-svc-ss4fq
Oct 22 01:11:36.224: INFO: Created: latency-svc-42rwp
Oct 22 01:11:36.231: INFO: Got endpoints: latency-svc-d5kzx [166.567034ms]
Oct 22 01:11:36.264: INFO: Created: latency-svc-2kw6b
Oct 22 01:11:36.272: INFO: Created: latency-svc-5t97g
Oct 22 01:11:36.281: INFO: Created: latency-svc-znmc8
Oct 22 01:11:36.284: INFO: Got endpoints: latency-svc-ss4fq [205.741466ms]
Oct 22 01:11:36.291: INFO: Created: latency-svc-wqntx
Oct 22 01:11:36.296: INFO: Created: latency-svc-csns7
Oct 22 01:11:36.302: INFO: Created: latency-svc-lppb5
Oct 22 01:11:36.308: INFO: Created: latency-svc-jtb8q
Oct 22 01:11:36.318: INFO: Created: latency-svc-c94fz
Oct 22 01:11:36.324: INFO: Created: latency-svc-nwbpz
Oct 22 01:11:36.329: INFO: Got endpoints: latency-svc-42rwp [242.335927ms]
Oct 22 01:11:36.339: INFO: Created: latency-svc-qmcrg
Oct 22 01:11:36.343: INFO: Created: latency-svc-h7d25
Oct 22 01:11:36.352: INFO: Created: latency-svc-2vtw9
Oct 22 01:11:36.362: INFO: Created: latency-svc-zqlc5
Oct 22 01:11:36.368: INFO: Created: latency-svc-phrzc
Oct 22 01:11:36.377: INFO: Created: latency-svc-4s5fr
Oct 22 01:11:36.379: INFO: Got endpoints: latency-svc-2kw6b [280.05457ms]
Oct 22 01:11:36.391: INFO: Created: latency-svc-2z48m
Oct 22 01:11:36.428: INFO: Got endpoints: latency-svc-5t97g [321.537969ms]
Oct 22 01:11:36.442: INFO: Created: latency-svc-lbn48
Oct 22 01:11:36.480: INFO: Got endpoints: latency-svc-znmc8 [361.008748ms]
Oct 22 01:11:36.491: INFO: Created: latency-svc-s7wnh
Oct 22 01:11:36.530: INFO: Got endpoints: latency-svc-wqntx [397.07187ms]
Oct 22 01:11:36.544: INFO: Created: latency-svc-bkvbb
Oct 22 01:11:36.579: INFO: Got endpoints: latency-svc-csns7 [444.712497ms]
Oct 22 01:11:36.591: INFO: Created: latency-svc-kht8w
Oct 22 01:11:36.631: INFO: Got endpoints: latency-svc-lppb5 [481.658217ms]
Oct 22 01:11:36.643: INFO: Created: latency-svc-kmmkh
Oct 22 01:11:36.680: INFO: Got endpoints: latency-svc-jtb8q [517.891783ms]
Oct 22 01:11:36.694: INFO: Created: latency-svc-22k2z
Oct 22 01:11:36.729: INFO: Got endpoints: latency-svc-c94fz [556.484136ms]
Oct 22 01:11:36.747: INFO: Created: latency-svc-k9z44
Oct 22 01:11:36.779: INFO: Got endpoints: latency-svc-nwbpz [603.954105ms]
Oct 22 01:11:36.794: INFO: Created: latency-svc-jw9h2
Oct 22 01:11:36.828: INFO: Got endpoints: latency-svc-qmcrg [633.145845ms]
Oct 22 01:11:36.842: INFO: Created: latency-svc-8dkzl
Oct 22 01:11:36.880: INFO: Got endpoints: latency-svc-h7d25 [680.485766ms]
Oct 22 01:11:36.891: INFO: Created: latency-svc-lbxhf
Oct 22 01:11:36.932: INFO: Got endpoints: latency-svc-2vtw9 [728.625423ms]
Oct 22 01:11:36.946: INFO: Created: latency-svc-vf4ht
Oct 22 01:11:36.982: INFO: Got endpoints: latency-svc-zqlc5 [751.016628ms]
Oct 22 01:11:36.994: INFO: Created: latency-svc-8pgl7
Oct 22 01:11:37.031: INFO: Got endpoints: latency-svc-phrzc [747.550206ms]
Oct 22 01:11:37.043: INFO: Created: latency-svc-k4sfn
Oct 22 01:11:37.083: INFO: Got endpoints: latency-svc-4s5fr [754.279521ms]
Oct 22 01:11:37.100: INFO: Created: latency-svc-r8wvp
Oct 22 01:11:37.130: INFO: Got endpoints: latency-svc-2z48m [751.219593ms]
Oct 22 01:11:37.149: INFO: Created: latency-svc-6wn9l
Oct 22 01:11:37.183: INFO: Got endpoints: latency-svc-lbn48 [754.797677ms]
Oct 22 01:11:37.194: INFO: Created: latency-svc-pcs5l
Oct 22 01:11:37.229: INFO: Got endpoints: latency-svc-s7wnh [748.434572ms]
Oct 22 01:11:37.241: INFO: Created: latency-svc-ljrlw
Oct 22 01:11:37.281: INFO: Got endpoints: latency-svc-bkvbb [750.350919ms]
Oct 22 01:11:37.300: INFO: Created: latency-svc-bnkxg
Oct 22 01:11:37.331: INFO: Got endpoints: latency-svc-kht8w [752.113155ms]
Oct 22 01:11:37.344: INFO: Created: latency-svc-q9v4t
Oct 22 01:11:37.378: INFO: Got endpoints: latency-svc-kmmkh [746.918908ms]
Oct 22 01:11:37.393: INFO: Created: latency-svc-wwjbb
Oct 22 01:11:37.440: INFO: Got endpoints: latency-svc-22k2z [760.453407ms]
Oct 22 01:11:37.456: INFO: Created: latency-svc-h7rpn
Oct 22 01:11:37.481: INFO: Got endpoints: latency-svc-k9z44 [752.299162ms]
Oct 22 01:11:37.495: INFO: Created: latency-svc-qq976
Oct 22 01:11:37.530: INFO: Got endpoints: latency-svc-jw9h2 [750.756676ms]
Oct 22 01:11:37.544: INFO: Created: latency-svc-77zcx
Oct 22 01:11:37.579: INFO: Got endpoints: latency-svc-8dkzl [751.162013ms]
Oct 22 01:11:37.594: INFO: Created: latency-svc-2tww4
Oct 22 01:11:37.629: INFO: Got endpoints: latency-svc-lbxhf [749.382646ms]
Oct 22 01:11:37.644: INFO: Created: latency-svc-hhqmm
Oct 22 01:11:37.680: INFO: Got endpoints: latency-svc-vf4ht [748.50376ms]
Oct 22 01:11:37.695: INFO: Created: latency-svc-jcxr4
Oct 22 01:11:37.730: INFO: Got endpoints: latency-svc-8pgl7 [748.303364ms]
Oct 22 01:11:37.745: INFO: Created: latency-svc-2g5h7
Oct 22 01:11:37.778: INFO: Got endpoints: latency-svc-k4sfn [747.075592ms]
Oct 22 01:11:37.792: INFO: Created: latency-svc-d6rdg
Oct 22 01:11:37.833: INFO: Got endpoints: latency-svc-r8wvp [749.399732ms]
Oct 22 01:11:37.845: INFO: Created: latency-svc-r5dtj
Oct 22 01:11:37.878: INFO: Got endpoints: latency-svc-6wn9l [748.224235ms]
Oct 22 01:11:37.890: INFO: Created: latency-svc-pzwkv
Oct 22 01:11:37.928: INFO: Got endpoints: latency-svc-pcs5l [745.596744ms]
Oct 22 01:11:37.943: INFO: Created: latency-svc-w6mn7
Oct 22 01:11:37.979: INFO: Got endpoints: latency-svc-ljrlw [750.291446ms]
Oct 22 01:11:37.992: INFO: Created: latency-svc-phbsq
Oct 22 01:11:38.029: INFO: Got endpoints: latency-svc-bnkxg [748.486583ms]
Oct 22 01:11:38.046: INFO: Created: latency-svc-mrvlh
Oct 22 01:11:38.082: INFO: Got endpoints: latency-svc-q9v4t [750.777466ms]
Oct 22 01:11:38.096: INFO: Created: latency-svc-bpdq6
Oct 22 01:11:38.130: INFO: Got endpoints: latency-svc-wwjbb [752.262533ms]
Oct 22 01:11:38.143: INFO: Created: latency-svc-b5nlh
Oct 22 01:11:38.179: INFO: Got endpoints: latency-svc-h7rpn [738.420317ms]
Oct 22 01:11:38.193: INFO: Created: latency-svc-tvjt7
Oct 22 01:11:38.229: INFO: Got endpoints: latency-svc-qq976 [747.454241ms]
Oct 22 01:11:38.244: INFO: Created: latency-svc-gs775
Oct 22 01:11:38.279: INFO: Got endpoints: latency-svc-77zcx [749.428102ms]
Oct 22 01:11:38.294: INFO: Created: latency-svc-t6gbr
Oct 22 01:11:38.329: INFO: Got endpoints: latency-svc-2tww4 [750.249034ms]
Oct 22 01:11:38.346: INFO: Created: latency-svc-qtjss
Oct 22 01:11:38.381: INFO: Got endpoints: latency-svc-hhqmm [751.349514ms]
Oct 22 01:11:38.392: INFO: Created: latency-svc-mv6bq
Oct 22 01:11:38.429: INFO: Got endpoints: latency-svc-jcxr4 [748.636863ms]
Oct 22 01:11:38.444: INFO: Created: latency-svc-xrwwr
Oct 22 01:11:38.480: INFO: Got endpoints: latency-svc-2g5h7 [749.959722ms]
Oct 22 01:11:38.497: INFO: Created: latency-svc-lchll
Oct 22 01:11:38.528: INFO: Got endpoints: latency-svc-d6rdg [749.770943ms]
Oct 22 01:11:38.545: INFO: Created: latency-svc-kgcwk
Oct 22 01:11:38.580: INFO: Got endpoints: latency-svc-r5dtj [747.207205ms]
Oct 22 01:11:38.593: INFO: Created: latency-svc-j4gwx
Oct 22 01:11:38.631: INFO: Got endpoints: latency-svc-pzwkv [753.057324ms]
Oct 22 01:11:38.645: INFO: Created: latency-svc-dcp4c
Oct 22 01:11:38.682: INFO: Got endpoints: latency-svc-w6mn7 [753.674143ms]
Oct 22 01:11:38.697: INFO: Created: latency-svc-j8v8s
Oct 22 01:11:38.730: INFO: Got endpoints: latency-svc-phbsq [750.569923ms]
Oct 22 01:11:38.744: INFO: Created: latency-svc-b5p7k
Oct 22 01:11:38.779: INFO: Got endpoints: latency-svc-mrvlh [750.093627ms]
Oct 22 01:11:38.792: INFO: Created: latency-svc-49d8d
Oct 22 01:11:38.828: INFO: Got endpoints: latency-svc-bpdq6 [746.36048ms]
Oct 22 01:11:38.846: INFO: Created: latency-svc-9fqks
Oct 22 01:11:38.879: INFO: Got endpoints: latency-svc-b5nlh [748.527073ms]
Oct 22 01:11:38.893: INFO: Created: latency-svc-bzr27
Oct 22 01:11:38.929: INFO: Got endpoints: latency-svc-tvjt7 [749.979751ms]
Oct 22 01:11:38.945: INFO: Created: latency-svc-pk46t
Oct 22 01:11:38.983: INFO: Got endpoints: latency-svc-gs775 [754.60585ms]
Oct 22 01:11:39.000: INFO: Created: latency-svc-dzsh5
Oct 22 01:11:39.030: INFO: Got endpoints: latency-svc-t6gbr [751.112562ms]
Oct 22 01:11:39.044: INFO: Created: latency-svc-6wgl4
Oct 22 01:11:39.080: INFO: Got endpoints: latency-svc-qtjss [750.306817ms]
Oct 22 01:11:39.095: INFO: Created: latency-svc-4bmph
Oct 22 01:11:39.134: INFO: Got endpoints: latency-svc-mv6bq [753.205146ms]
Oct 22 01:11:39.151: INFO: Created: latency-svc-2p88k
Oct 22 01:11:39.181: INFO: Got endpoints: latency-svc-xrwwr [751.565534ms]
Oct 22 01:11:39.195: INFO: Created: latency-svc-m5bf8
Oct 22 01:11:39.229: INFO: Got endpoints: latency-svc-lchll [748.933815ms]
Oct 22 01:11:39.244: INFO: Created: latency-svc-znl99
Oct 22 01:11:39.280: INFO: Got endpoints: latency-svc-kgcwk [751.852981ms]
Oct 22 01:11:39.293: INFO: Created: latency-svc-tcr2r
Oct 22 01:11:39.336: INFO: Got endpoints: latency-svc-j4gwx [755.876822ms]
Oct 22 01:11:39.349: INFO: Created: latency-svc-5crss
Oct 22 01:11:39.378: INFO: Got endpoints: latency-svc-dcp4c [746.816839ms]
Oct 22 01:11:39.393: INFO: Created: latency-svc-2f5vf
Oct 22 01:11:39.435: INFO: Got endpoints: latency-svc-j8v8s [753.256876ms]
Oct 22 01:11:39.449: INFO: Created: latency-svc-4rjdr
Oct 22 01:11:39.482: INFO: Got endpoints: latency-svc-b5p7k [751.916615ms]
Oct 22 01:11:39.493: INFO: Created: latency-svc-qljt8
Oct 22 01:11:39.529: INFO: Got endpoints: latency-svc-49d8d [749.966275ms]
Oct 22 01:11:39.544: INFO: Created: latency-svc-4bvk6
Oct 22 01:11:39.583: INFO: Got endpoints: latency-svc-9fqks [754.696299ms]
Oct 22 01:11:39.596: INFO: Created: latency-svc-c4j8x
Oct 22 01:11:39.630: INFO: Got endpoints: latency-svc-bzr27 [750.544843ms]
Oct 22 01:11:39.646: INFO: Created: latency-svc-dr4cq
Oct 22 01:11:39.681: INFO: Got endpoints: latency-svc-pk46t [752.504143ms]
Oct 22 01:11:39.697: INFO: Created: latency-svc-r8nxd
Oct 22 01:11:39.729: INFO: Got endpoints: latency-svc-dzsh5 [745.320775ms]
Oct 22 01:11:39.744: INFO: Created: latency-svc-4v2wh
Oct 22 01:11:39.780: INFO: Got endpoints: latency-svc-6wgl4 [749.132956ms]
Oct 22 01:11:39.795: INFO: Created: latency-svc-z5ppw
Oct 22 01:11:39.829: INFO: Got endpoints: latency-svc-4bmph [749.328252ms]
Oct 22 01:11:39.843: INFO: Created: latency-svc-rn9w8
Oct 22 01:11:39.879: INFO: Got endpoints: latency-svc-2p88k [745.591241ms]
Oct 22 01:11:39.894: INFO: Created: latency-svc-kzv8x
Oct 22 01:11:39.930: INFO: Got endpoints: latency-svc-m5bf8 [748.643791ms]
Oct 22 01:11:39.943: INFO: Created: latency-svc-djkdm
Oct 22 01:11:39.982: INFO: Got endpoints: latency-svc-znl99 [752.563992ms]
Oct 22 01:11:39.998: INFO: Created: latency-svc-w7mgg
Oct 22 01:11:40.029: INFO: Got endpoints: latency-svc-tcr2r [748.723494ms]
Oct 22 01:11:40.043: INFO: Created: latency-svc-56g27
Oct 22 01:11:40.080: INFO: Got endpoints: latency-svc-5crss [743.900316ms]
Oct 22 01:11:40.093: INFO: Created: latency-svc-nwhj2
Oct 22 01:11:40.129: INFO: Got endpoints: latency-svc-2f5vf [750.989359ms]
Oct 22 01:11:40.144: INFO: Created: latency-svc-4snxc
Oct 22 01:11:40.180: INFO: Got endpoints: latency-svc-4rjdr [744.866157ms]
Oct 22 01:11:40.193: INFO: Created: latency-svc-mm8jx
Oct 22 01:11:40.229: INFO: Got endpoints: latency-svc-qljt8 [747.347042ms]
Oct 22 01:11:40.243: INFO: Created: latency-svc-4jmjc
Oct 22 01:11:40.278: INFO: Got endpoints: latency-svc-4bvk6 [748.963249ms]
Oct 22 01:11:40.297: INFO: Created: latency-svc-q2m6p
Oct 22 01:11:40.330: INFO: Got endpoints: latency-svc-c4j8x [747.549903ms]
Oct 22 01:11:40.348: INFO: Created: latency-svc-4cwwt
Oct 22 01:11:40.380: INFO: Got endpoints: latency-svc-dr4cq [750.401723ms]
Oct 22 01:11:40.394: INFO: Created: latency-svc-nmrrd
Oct 22 01:11:40.429: INFO: Got endpoints: latency-svc-r8nxd [747.958398ms]
Oct 22 01:11:40.444: INFO: Created: latency-svc-ktwl5
Oct 22 01:11:40.483: INFO: Got endpoints: latency-svc-4v2wh [753.97582ms]
Oct 22 01:11:40.497: INFO: Created: latency-svc-r4mpf
Oct 22 01:11:40.529: INFO: Got endpoints: latency-svc-z5ppw [749.48973ms]
Oct 22 01:11:40.547: INFO: Created: latency-svc-5tzsg
Oct 22 01:11:40.579: INFO: Got endpoints: latency-svc-rn9w8 [749.616507ms]
Oct 22 01:11:40.595: INFO: Created: latency-svc-85tzd
Oct 22 01:11:40.629: INFO: Got endpoints: latency-svc-kzv8x [749.616591ms]
Oct 22 01:11:40.641: INFO: Created: latency-svc-5nqc9
Oct 22 01:11:40.680: INFO: Got endpoints: latency-svc-djkdm [750.109449ms]
Oct 22 01:11:40.690: INFO: Created: latency-svc-vvjxg
Oct 22 01:11:40.730: INFO: Got endpoints: latency-svc-w7mgg [748.42381ms]
Oct 22 01:11:40.743: INFO: Created: latency-svc-jh7fp
Oct 22 01:11:40.779: INFO: Got endpoints: latency-svc-56g27 [750.104242ms]
Oct 22 01:11:40.790: INFO: Created: latency-svc-wv7dd
Oct 22 01:11:40.829: INFO: Got endpoints: latency-svc-nwhj2 [748.872598ms]
Oct 22 01:11:40.841: INFO: Created: latency-svc-7sgd4
Oct 22 01:11:40.882: INFO: Got endpoints: latency-svc-4snxc [752.373852ms]
Oct 22 01:11:40.894: INFO: Created: latency-svc-twdsc
Oct 22 01:11:40.929: INFO: Got endpoints: latency-svc-mm8jx [748.545454ms]
Oct 22 01:11:40.945: INFO: Created: latency-svc-slmnf
Oct 22 01:11:40.978: INFO: Got endpoints: latency-svc-4jmjc [749.241635ms]
Oct 22 01:11:40.991: INFO: Created: latency-svc-lkc95
Oct 22 01:11:41.030: INFO: Got endpoints: latency-svc-q2m6p [751.714701ms]
Oct 22 01:11:41.040: INFO: Created: latency-svc-zw4f8
Oct 22 01:11:41.078: INFO: Got endpoints: latency-svc-4cwwt [747.62162ms]
Oct 22 01:11:41.096: INFO: Created: latency-svc-tmh7p
Oct 22 01:11:41.128: INFO: Got endpoints: latency-svc-nmrrd [747.852103ms]
Oct 22 01:11:41.145: INFO: Created: latency-svc-82p9j
Oct 22 01:11:41.178: INFO: Got endpoints: latency-svc-ktwl5 [748.207256ms]
Oct 22 01:11:41.187: INFO: Created: latency-svc-w6mmc
Oct 22 01:11:41.229: INFO: Got endpoints: latency-svc-r4mpf [745.981381ms]
Oct 22 01:11:41.239: INFO: Created: latency-svc-9ls2f
Oct 22 01:11:41.278: INFO: Got endpoints: latency-svc-5tzsg [748.278117ms]
Oct 22 01:11:41.291: INFO: Created: latency-svc-976lk
Oct 22 01:11:41.331: INFO: Got endpoints: latency-svc-85tzd [751.983046ms]
Oct 22 01:11:41.350: INFO: Created: latency-svc-4tf6r
Oct 22 01:11:41.378: INFO: Got endpoints: latency-svc-5nqc9 [748.939568ms]
Oct 22 01:11:41.390: INFO: Created: latency-svc-d9r6s
Oct 22 01:11:41.429: INFO: Got endpoints: latency-svc-vvjxg [749.139571ms]
Oct 22 01:11:41.444: INFO: Created: latency-svc-fg8r7
Oct 22 01:11:41.479: INFO: Got endpoints: latency-svc-jh7fp [748.365246ms]
Oct 22 01:11:41.490: INFO: Created: latency-svc-62rxd
Oct 22 01:11:41.528: INFO: Got endpoints: latency-svc-wv7dd [749.24513ms]
Oct 22 01:11:41.543: INFO: Created: latency-svc-5bxnx
Oct 22 01:11:41.579: INFO: Got endpoints: latency-svc-7sgd4 [749.768417ms]
Oct 22 01:11:41.591: INFO: Created: latency-svc-9zsdp
Oct 22 01:11:41.628: INFO: Got endpoints: latency-svc-twdsc [746.477662ms]
Oct 22 01:11:41.659: INFO: Created: latency-svc-nsk6b
Oct 22 01:11:41.711: INFO: Got endpoints: latency-svc-slmnf [782.20544ms]
Oct 22 01:11:41.750: INFO: Got endpoints: latency-svc-lkc95 [771.111935ms]
Oct 22 01:11:41.797: INFO: Got endpoints: latency-svc-zw4f8 [766.993569ms]
Oct 22 01:11:41.803: INFO: Created: latency-svc-fwt8b
Oct 22 01:11:41.808: INFO: Created: latency-svc-mp7lc
Oct 22 01:11:41.813: INFO: Created: latency-svc-78d2v
Oct 22 01:11:41.828: INFO: Got endpoints: latency-svc-tmh7p [749.611945ms]
Oct 22 01:11:41.843: INFO: Created: latency-svc-scrzx
Oct 22 01:11:41.877: INFO: Got endpoints: latency-svc-82p9j [748.35818ms]
Oct 22 01:11:41.888: INFO: Created: latency-svc-ftjs4
Oct 22 01:11:41.927: INFO: Got endpoints: latency-svc-w6mmc [749.726517ms]
Oct 22 01:11:41.938: INFO: Created: latency-svc-28qbj
Oct 22 01:11:41.978: INFO: Got endpoints: latency-svc-9ls2f [748.720657ms]
Oct 22 01:11:41.989: INFO: Created: latency-svc-h4nm8
Oct 22 01:11:42.029: INFO: Got endpoints: latency-svc-976lk [751.112369ms]
Oct 22 01:11:42.042: INFO: Created: latency-svc-r6nb6
Oct 22 01:11:42.078: INFO: Got endpoints: latency-svc-4tf6r [746.905078ms]
Oct 22 01:11:42.093: INFO: Created: latency-svc-jzdnj
Oct 22 01:11:42.129: INFO: Got endpoints: latency-svc-d9r6s [750.779169ms]
Oct 22 01:11:42.144: INFO: Created: latency-svc-2fsww
Oct 22 01:11:42.178: INFO: Got endpoints: latency-svc-fg8r7 [748.958454ms]
Oct 22 01:11:42.195: INFO: Created: latency-svc-8jlhb
Oct 22 01:11:42.229: INFO: Got endpoints: latency-svc-62rxd [750.015733ms]
Oct 22 01:11:42.239: INFO: Created: latency-svc-hdck2
Oct 22 01:11:42.278: INFO: Got endpoints: latency-svc-5bxnx [749.359381ms]
Oct 22 01:11:42.290: INFO: Created: latency-svc-66hh9
Oct 22 01:11:42.330: INFO: Got endpoints: latency-svc-9zsdp [751.540195ms]
Oct 22 01:11:42.342: INFO: Created: latency-svc-hgmdm
Oct 22 01:11:42.380: INFO: Got endpoints: latency-svc-nsk6b [752.000762ms]
Oct 22 01:11:42.393: INFO: Created: latency-svc-hvxq8
Oct 22 01:11:42.429: INFO: Got endpoints: latency-svc-fwt8b [717.724579ms]
Oct 22 01:11:42.443: INFO: Created: latency-svc-9rkbf
Oct 22 01:11:42.478: INFO: Got endpoints: latency-svc-mp7lc [728.423429ms]
Oct 22 01:11:42.495: INFO: Created: latency-svc-r7ljh
Oct 22 01:11:42.529: INFO: Got endpoints: latency-svc-78d2v [731.882487ms]
Oct 22 01:11:42.545: INFO: Created: latency-svc-rnf8f
Oct 22 01:11:42.578: INFO: Got endpoints: latency-svc-scrzx [750.418397ms]
Oct 22 01:11:42.590: INFO: Created: latency-svc-9jz5j
Oct 22 01:11:42.629: INFO: Got endpoints: latency-svc-ftjs4 [752.272851ms]
Oct 22 01:11:42.640: INFO: Created: latency-svc-tqwwm
Oct 22 01:11:42.678: INFO: Got endpoints: latency-svc-28qbj [750.677047ms]
Oct 22 01:11:42.691: INFO: Created: latency-svc-r8gjg
Oct 22 01:11:42.729: INFO: Got endpoints: latency-svc-h4nm8 [751.858955ms]
Oct 22 01:11:42.743: INFO: Created: latency-svc-8254j
Oct 22 01:11:42.778: INFO: Got endpoints: latency-svc-r6nb6 [749.377426ms]
Oct 22 01:11:42.790: INFO: Created: latency-svc-kdp77
Oct 22 01:11:42.828: INFO: Got endpoints: latency-svc-jzdnj [750.062491ms]
Oct 22 01:11:42.841: INFO: Created: latency-svc-k8djf
Oct 22 01:11:42.878: INFO: Got endpoints: latency-svc-2fsww [749.105133ms]
Oct 22 01:11:42.896: INFO: Created: latency-svc-q9bwm
Oct 22 01:11:42.928: INFO: Got endpoints: latency-svc-8jlhb [750.012562ms]
Oct 22 01:11:42.942: INFO: Created: latency-svc-qdqh6
Oct 22 01:11:42.979: INFO: Got endpoints: latency-svc-hdck2 [749.989529ms]
Oct 22 01:11:42.992: INFO: Created: latency-svc-jkf68
Oct 22 01:11:43.028: INFO: Got endpoints: latency-svc-66hh9 [750.239386ms]
Oct 22 01:11:43.044: INFO: Created: latency-svc-85tcr
Oct 22 01:11:43.080: INFO: Got endpoints: latency-svc-hgmdm [749.755142ms]
Oct 22 01:11:43.093: INFO: Created: latency-svc-fqlz7
Oct 22 01:11:43.128: INFO: Got endpoints: latency-svc-hvxq8 [747.979799ms]
Oct 22 01:11:43.139: INFO: Created: latency-svc-ztggx
Oct 22 01:11:43.178: INFO: Got endpoints: latency-svc-9rkbf [749.488528ms]
Oct 22 01:11:43.190: INFO: Created: latency-svc-fvp6h
Oct 22 01:11:43.232: INFO: Got endpoints: latency-svc-r7ljh [754.070566ms]
Oct 22 01:11:43.242: INFO: Created: latency-svc-frzjw
Oct 22 01:11:43.278: INFO: Got endpoints: latency-svc-rnf8f [749.215792ms]
Oct 22 01:11:43.291: INFO: Created: latency-svc-bzdgm
Oct 22 01:11:43.329: INFO: Got endpoints: latency-svc-9jz5j [750.788844ms]
Oct 22 01:11:43.340: INFO: Created: latency-svc-lsjkt
Oct 22 01:11:43.380: INFO: Got endpoints: latency-svc-tqwwm [750.757704ms]
Oct 22 01:11:43.399: INFO: Created: latency-svc-p768q
Oct 22 01:11:43.428: INFO: Got endpoints: latency-svc-r8gjg [750.177441ms]
Oct 22 01:11:43.460: INFO: Created: latency-svc-9lfn7
Oct 22 01:11:43.479: INFO: Got endpoints: latency-svc-8254j [749.606946ms]
Oct 22 01:11:43.490: INFO: Created: latency-svc-sljlb
Oct 22 01:11:43.529: INFO: Got endpoints: latency-svc-kdp77 [750.857346ms]
Oct 22 01:11:43.540: INFO: Created: latency-svc-4qnc7
Oct 22 01:11:43.578: INFO: Got endpoints: latency-svc-k8djf [750.101233ms]
Oct 22 01:11:43.628: INFO: Got endpoints: latency-svc-q9bwm [750.046275ms]
Oct 22 01:11:43.679: INFO: Got endpoints: latency-svc-qdqh6 [750.999661ms]
Oct 22 01:11:43.729: INFO: Got endpoints: latency-svc-jkf68 [749.784775ms]
Oct 22 01:11:43.779: INFO: Got endpoints: latency-svc-85tcr [750.797994ms]
Oct 22 01:11:43.828: INFO: Got endpoints: latency-svc-fqlz7 [748.201802ms]
Oct 22 01:11:43.879: INFO: Got endpoints: latency-svc-ztggx [750.704712ms]
Oct 22 01:11:43.931: INFO: Got endpoints: latency-svc-fvp6h [752.597715ms]
Oct 22 01:11:43.980: INFO: Got endpoints: latency-svc-frzjw [747.724202ms]
Oct 22 01:11:44.029: INFO: Got endpoints: latency-svc-bzdgm [750.839462ms]
Oct 22 01:11:44.079: INFO: Got endpoints: latency-svc-lsjkt [750.290668ms]
Oct 22 01:11:44.128: INFO: Got endpoints: latency-svc-p768q [748.406509ms]
Oct 22 01:11:44.181: INFO: Got endpoints: latency-svc-9lfn7 [752.657156ms]
Oct 22 01:11:44.229: INFO: Got endpoints: latency-svc-sljlb [749.858611ms]
Oct 22 01:11:44.279: INFO: Got endpoints: latency-svc-4qnc7 [749.941086ms]
Oct 22 01:11:44.279: INFO: Latencies: [33.844282ms 40.716694ms 55.110297ms 66.333769ms 90.612263ms 101.081302ms 111.039193ms 124.964818ms 134.420916ms 146.277258ms 152.026192ms 156.469579ms 161.983488ms 165.39282ms 166.567034ms 168.690497ms 170.670788ms 177.817397ms 178.119408ms 178.383564ms 180.836336ms 181.171828ms 181.414996ms 181.850853ms 182.531255ms 185.889099ms 186.326247ms 187.453858ms 190.353874ms 191.04265ms 194.12914ms 195.889476ms 196.197689ms 197.527592ms 199.994517ms 200.168795ms 204.958618ms 205.741466ms 219.486562ms 231.679017ms 242.335927ms 280.05457ms 321.537969ms 361.008748ms 397.07187ms 444.712497ms 481.658217ms 517.891783ms 556.484136ms 603.954105ms 633.145845ms 680.485766ms 717.724579ms 728.423429ms 728.625423ms 731.882487ms 738.420317ms 743.900316ms 744.866157ms 745.320775ms 745.591241ms 745.596744ms 745.981381ms 746.36048ms 746.477662ms 746.816839ms 746.905078ms 746.918908ms 747.075592ms 747.207205ms 747.347042ms 747.454241ms 747.549903ms 747.550206ms 747.62162ms 747.724202ms 747.852103ms 747.958398ms 747.979799ms 748.201802ms 748.207256ms 748.224235ms 748.278117ms 748.303364ms 748.35818ms 748.365246ms 748.406509ms 748.42381ms 748.434572ms 748.486583ms 748.50376ms 748.527073ms 748.545454ms 748.636863ms 748.643791ms 748.720657ms 748.723494ms 748.872598ms 748.933815ms 748.939568ms 748.958454ms 748.963249ms 749.105133ms 749.132956ms 749.139571ms 749.215792ms 749.241635ms 749.24513ms 749.328252ms 749.359381ms 749.377426ms 749.382646ms 749.399732ms 749.428102ms 749.488528ms 749.48973ms 749.606946ms 749.611945ms 749.616507ms 749.616591ms 749.726517ms 749.755142ms 749.768417ms 749.770943ms 749.784775ms 749.858611ms 749.941086ms 749.959722ms 749.966275ms 749.979751ms 749.989529ms 750.012562ms 750.015733ms 750.046275ms 750.062491ms 750.093627ms 750.101233ms 750.104242ms 750.109449ms 750.177441ms 750.239386ms 750.249034ms 750.290668ms 750.291446ms 750.306817ms 750.350919ms 750.401723ms 750.418397ms 750.544843ms 750.569923ms 750.677047ms 750.704712ms 750.756676ms 750.757704ms 750.777466ms 750.779169ms 750.788844ms 750.797994ms 750.839462ms 750.857346ms 750.989359ms 750.999661ms 751.016628ms 751.112369ms 751.112562ms 751.162013ms 751.219593ms 751.349514ms 751.540195ms 751.565534ms 751.714701ms 751.852981ms 751.858955ms 751.916615ms 751.983046ms 752.000762ms 752.113155ms 752.262533ms 752.272851ms 752.299162ms 752.373852ms 752.504143ms 752.563992ms 752.597715ms 752.657156ms 753.057324ms 753.205146ms 753.256876ms 753.674143ms 753.97582ms 754.070566ms 754.279521ms 754.60585ms 754.696299ms 754.797677ms 755.876822ms 760.453407ms 766.993569ms 771.111935ms 782.20544ms]
Oct 22 01:11:44.279: INFO: 50 %ile: 748.958454ms
Oct 22 01:11:44.279: INFO: 90 %ile: 752.373852ms
Oct 22 01:11:44.279: INFO: 99 %ile: 771.111935ms
Oct 22 01:11:44.279: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 01:11:44.279: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svc-latency-6005" for this suite.
Oct 22 01:12:12.300: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 01:12:12.441: INFO: namespace svc-latency-6005 deletion completed in 28.155699224s

• [SLOW TEST:38.941 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should not be very high  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 01:12:12.442: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-upd-f721f748-8f51-4b88-ba11-e793aa8094a5
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-f721f748-8f51-4b88-ba11-e793aa8094a5
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 01:12:16.576: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4060" for this suite.
Oct 22 01:12:38.598: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 01:12:38.741: INFO: namespace configmap-4060 deletion completed in 22.159120613s

• [SLOW TEST:26.299 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 01:12:38.741: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
Oct 22 01:12:39.843: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 01:12:39.843: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
W1022 01:12:39.843139      18 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
STEP: Destroying namespace "gc-52" for this suite.
Oct 22 01:12:45.862: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 01:12:46.002: INFO: namespace gc-52 deletion completed in 6.154302462s

• [SLOW TEST:7.261 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 01:12:46.002: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: getting the auto-created API token
Oct 22 01:12:46.572: INFO: created pod pod-service-account-defaultsa
Oct 22 01:12:46.572: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Oct 22 01:12:46.578: INFO: created pod pod-service-account-mountsa
Oct 22 01:12:46.578: INFO: pod pod-service-account-mountsa service account token volume mount: true
Oct 22 01:12:46.588: INFO: created pod pod-service-account-nomountsa
Oct 22 01:12:46.588: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Oct 22 01:12:46.595: INFO: created pod pod-service-account-defaultsa-mountspec
Oct 22 01:12:46.595: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Oct 22 01:12:46.609: INFO: created pod pod-service-account-mountsa-mountspec
Oct 22 01:12:46.609: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Oct 22 01:12:46.620: INFO: created pod pod-service-account-nomountsa-mountspec
Oct 22 01:12:46.620: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Oct 22 01:12:46.631: INFO: created pod pod-service-account-defaultsa-nomountspec
Oct 22 01:12:46.631: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Oct 22 01:12:46.638: INFO: created pod pod-service-account-mountsa-nomountspec
Oct 22 01:12:46.638: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Oct 22 01:12:46.645: INFO: created pod pod-service-account-nomountsa-nomountspec
Oct 22 01:12:46.645: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 01:12:46.645: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-3835" for this suite.
Oct 22 01:12:52.692: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 01:12:52.830: INFO: namespace svcaccounts-3835 deletion completed in 6.172346216s

• [SLOW TEST:6.828 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:23
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 01:12:52.831: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name projected-secret-test-4f62e70a-e3a7-4ff1-89dd-7c149b2f0bee
STEP: Creating a pod to test consume secrets
Oct 22 01:12:52.894: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-1373e3c6-8a73-4fe6-ae10-159dde62bc5e" in namespace "projected-490" to be "success or failure"
Oct 22 01:12:52.899: INFO: Pod "pod-projected-secrets-1373e3c6-8a73-4fe6-ae10-159dde62bc5e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.609616ms
Oct 22 01:12:54.904: INFO: Pod "pod-projected-secrets-1373e3c6-8a73-4fe6-ae10-159dde62bc5e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009044785s
STEP: Saw pod success
Oct 22 01:12:54.904: INFO: Pod "pod-projected-secrets-1373e3c6-8a73-4fe6-ae10-159dde62bc5e" satisfied condition "success or failure"
Oct 22 01:12:54.907: INFO: Trying to get logs from node mip-bd-vm40.mip.storage.hpecorp.net pod pod-projected-secrets-1373e3c6-8a73-4fe6-ae10-159dde62bc5e container secret-volume-test: <nil>
STEP: delete the pod
Oct 22 01:12:54.934: INFO: Waiting for pod pod-projected-secrets-1373e3c6-8a73-4fe6-ae10-159dde62bc5e to disappear
Oct 22 01:12:54.938: INFO: Pod pod-projected-secrets-1373e3c6-8a73-4fe6-ae10-159dde62bc5e no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 01:12:54.938: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-490" for this suite.
Oct 22 01:13:00.957: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 01:13:01.090: INFO: namespace projected-490 deletion completed in 6.146368126s

• [SLOW TEST:8.259 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 01:13:01.090: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating replication controller my-hostname-basic-422808d9-d7b6-4ba0-bf7d-1762c9f13106
Oct 22 01:13:01.146: INFO: Pod name my-hostname-basic-422808d9-d7b6-4ba0-bf7d-1762c9f13106: Found 0 pods out of 1
Oct 22 01:13:06.152: INFO: Pod name my-hostname-basic-422808d9-d7b6-4ba0-bf7d-1762c9f13106: Found 1 pods out of 1
Oct 22 01:13:06.152: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-422808d9-d7b6-4ba0-bf7d-1762c9f13106" are running
Oct 22 01:13:06.156: INFO: Pod "my-hostname-basic-422808d9-d7b6-4ba0-bf7d-1762c9f13106-jxhnz" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-10-22 01:13:01 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-10-22 01:13:02 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-10-22 01:13:02 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-10-22 01:13:01 +0000 UTC Reason: Message:}])
Oct 22 01:13:06.156: INFO: Trying to dial the pod
Oct 22 01:13:11.171: INFO: Controller my-hostname-basic-422808d9-d7b6-4ba0-bf7d-1762c9f13106: Got expected result from replica 1 [my-hostname-basic-422808d9-d7b6-4ba0-bf7d-1762c9f13106-jxhnz]: "my-hostname-basic-422808d9-d7b6-4ba0-bf7d-1762c9f13106-jxhnz", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 01:13:11.171: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-7486" for this suite.
Oct 22 01:13:17.190: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 01:13:17.325: INFO: namespace replication-controller-7486 deletion completed in 6.149074571s

• [SLOW TEST:16.235 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Aggregator 
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 01:13:17.325: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename aggregator
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:76
Oct 22 01:13:17.370: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
[It] Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Registering the sample API server.
Oct 22 01:13:17.952: INFO: deployment "sample-apiserver-deployment" doesn't have the required revision set
Oct 22 01:13:20.015: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707303597, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707303597, loc:(*time.Location)(0x7ec7a20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707303597, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707303597, loc:(*time.Location)(0x7ec7a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 22 01:13:22.021: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707303597, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707303597, loc:(*time.Location)(0x7ec7a20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707303597, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707303597, loc:(*time.Location)(0x7ec7a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 22 01:13:24.020: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707303597, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707303597, loc:(*time.Location)(0x7ec7a20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707303597, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707303597, loc:(*time.Location)(0x7ec7a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 22 01:13:26.021: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707303597, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707303597, loc:(*time.Location)(0x7ec7a20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707303597, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707303597, loc:(*time.Location)(0x7ec7a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 22 01:13:28.020: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707303597, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707303597, loc:(*time.Location)(0x7ec7a20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707303597, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707303597, loc:(*time.Location)(0x7ec7a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 22 01:13:30.021: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707303597, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707303597, loc:(*time.Location)(0x7ec7a20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707303597, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707303597, loc:(*time.Location)(0x7ec7a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 22 01:13:32.020: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707303597, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707303597, loc:(*time.Location)(0x7ec7a20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707303597, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707303597, loc:(*time.Location)(0x7ec7a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 22 01:13:34.021: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707303597, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707303597, loc:(*time.Location)(0x7ec7a20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707303597, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707303597, loc:(*time.Location)(0x7ec7a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 22 01:13:36.021: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707303597, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707303597, loc:(*time.Location)(0x7ec7a20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707303597, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707303597, loc:(*time.Location)(0x7ec7a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 22 01:13:38.020: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707303597, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707303597, loc:(*time.Location)(0x7ec7a20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707303597, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707303597, loc:(*time.Location)(0x7ec7a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 22 01:13:40.021: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707303597, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707303597, loc:(*time.Location)(0x7ec7a20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707303597, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707303597, loc:(*time.Location)(0x7ec7a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 22 01:13:42.021: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707303597, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707303597, loc:(*time.Location)(0x7ec7a20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707303597, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707303597, loc:(*time.Location)(0x7ec7a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 22 01:13:45.171: INFO: Waited 1.14181987s for the sample-apiserver to be ready to handle requests.
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:67
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 01:13:45.720: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "aggregator-3591" for this suite.
Oct 22 01:13:51.889: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 01:13:52.050: INFO: namespace aggregator-3591 deletion completed in 6.276968096s

• [SLOW TEST:34.725 seconds]
[sig-api-machinery] Aggregator
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 01:13:52.051: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Oct 22 01:13:52.117: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
STEP: Creating rc "condition-test" that asks for more than the allowed pod quota
STEP: Checking rc "condition-test" has the desired failure condition set
STEP: Scaling down rc "condition-test" to satisfy pod quota
Oct 22 01:13:54.161: INFO: Updating replication controller "condition-test"
STEP: Checking rc "condition-test" has no failure condition set
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 01:13:54.167: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-7896" for this suite.
Oct 22 01:14:00.191: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 01:14:00.341: INFO: namespace replication-controller-7896 deletion completed in 6.169242043s

• [SLOW TEST:8.290 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 01:14:00.342: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-map-ca708115-f069-4ac6-9a5f-e00800ed30c6
STEP: Creating a pod to test consume secrets
Oct 22 01:14:00.454: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-d060772a-e32a-430c-8c24-696c82eb2c2e" in namespace "projected-4886" to be "success or failure"
Oct 22 01:14:00.460: INFO: Pod "pod-projected-secrets-d060772a-e32a-430c-8c24-696c82eb2c2e": Phase="Pending", Reason="", readiness=false. Elapsed: 6.644573ms
Oct 22 01:14:02.466: INFO: Pod "pod-projected-secrets-d060772a-e32a-430c-8c24-696c82eb2c2e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012364942s
STEP: Saw pod success
Oct 22 01:14:02.466: INFO: Pod "pod-projected-secrets-d060772a-e32a-430c-8c24-696c82eb2c2e" satisfied condition "success or failure"
Oct 22 01:14:02.470: INFO: Trying to get logs from node mip-bd-vm41.mip.storage.hpecorp.net pod pod-projected-secrets-d060772a-e32a-430c-8c24-696c82eb2c2e container projected-secret-volume-test: <nil>
STEP: delete the pod
Oct 22 01:14:02.499: INFO: Waiting for pod pod-projected-secrets-d060772a-e32a-430c-8c24-696c82eb2c2e to disappear
Oct 22 01:14:02.503: INFO: Pod pod-projected-secrets-d060772a-e32a-430c-8c24-696c82eb2c2e no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 01:14:02.504: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4886" for this suite.
Oct 22 01:14:08.527: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 01:14:08.677: INFO: namespace projected-4886 deletion completed in 6.168580062s

• [SLOW TEST:8.335 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 01:14:08.677: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Performing setup for networking test in namespace pod-network-test-8673
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Oct 22 01:14:08.724: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Oct 22 01:14:28.815: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.1.154:8080/dial?request=hostName&protocol=http&host=10.244.1.153&port=8080&tries=1'] Namespace:pod-network-test-8673 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 22 01:14:28.815: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
Oct 22 01:14:28.962: INFO: Waiting for endpoints: map[]
Oct 22 01:14:28.966: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.1.154:8080/dial?request=hostName&protocol=http&host=10.244.2.145&port=8080&tries=1'] Namespace:pod-network-test-8673 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 22 01:14:28.966: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
Oct 22 01:14:29.107: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 01:14:29.107: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-8673" for this suite.
Oct 22 01:14:51.130: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 01:14:51.285: INFO: namespace pod-network-test-8673 deletion completed in 22.172375957s

• [SLOW TEST:42.608 seconds]
[sig-network] Networking
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 01:14:51.285: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0644 on node default medium
Oct 22 01:14:51.339: INFO: Waiting up to 5m0s for pod "pod-63d77358-cc3e-4b5d-bfb8-ba581898ddff" in namespace "emptydir-3086" to be "success or failure"
Oct 22 01:14:51.343: INFO: Pod "pod-63d77358-cc3e-4b5d-bfb8-ba581898ddff": Phase="Pending", Reason="", readiness=false. Elapsed: 3.256141ms
Oct 22 01:14:53.349: INFO: Pod "pod-63d77358-cc3e-4b5d-bfb8-ba581898ddff": Phase="Running", Reason="", readiness=true. Elapsed: 2.008805765s
Oct 22 01:14:55.355: INFO: Pod "pod-63d77358-cc3e-4b5d-bfb8-ba581898ddff": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014450533s
STEP: Saw pod success
Oct 22 01:14:55.355: INFO: Pod "pod-63d77358-cc3e-4b5d-bfb8-ba581898ddff" satisfied condition "success or failure"
Oct 22 01:14:55.359: INFO: Trying to get logs from node mip-bd-vm40.mip.storage.hpecorp.net pod pod-63d77358-cc3e-4b5d-bfb8-ba581898ddff container test-container: <nil>
STEP: delete the pod
Oct 22 01:14:55.391: INFO: Waiting for pod pod-63d77358-cc3e-4b5d-bfb8-ba581898ddff to disappear
Oct 22 01:14:55.394: INFO: Pod pod-63d77358-cc3e-4b5d-bfb8-ba581898ddff no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 01:14:55.394: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3086" for this suite.
Oct 22 01:15:01.415: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 01:15:01.579: INFO: namespace emptydir-3086 deletion completed in 6.179255554s

• [SLOW TEST:10.294 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-api-machinery] Secrets 
  should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 01:15:01.579: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name secret-emptykey-test-0aa5a883-daa1-47ef-a64d-ba105a8fbd0d
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 01:15:01.638: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6890" for this suite.
Oct 22 01:15:07.659: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 01:15:07.804: INFO: namespace secrets-6890 deletion completed in 6.160362097s

• [SLOW TEST:6.225 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 01:15:07.805: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename prestop
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pre_stop.go:167
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating server pod server in namespace prestop-7568
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace prestop-7568
STEP: Deleting pre-stop pod
Oct 22 01:15:20.926: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 01:15:20.939: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "prestop-7568" for this suite.
Oct 22 01:16:02.963: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 01:16:03.117: INFO: namespace prestop-7568 deletion completed in 42.172889748s

• [SLOW TEST:55.312 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 01:16:03.118: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap configmap-5495/configmap-test-22a150f7-1b3a-4728-92a8-1b47b604cb06
STEP: Creating a pod to test consume configMaps
Oct 22 01:16:03.185: INFO: Waiting up to 5m0s for pod "pod-configmaps-5446d11e-2882-4ab9-b5d2-555ec0c36a4f" in namespace "configmap-5495" to be "success or failure"
Oct 22 01:16:03.191: INFO: Pod "pod-configmaps-5446d11e-2882-4ab9-b5d2-555ec0c36a4f": Phase="Pending", Reason="", readiness=false. Elapsed: 6.090264ms
Oct 22 01:16:05.197: INFO: Pod "pod-configmaps-5446d11e-2882-4ab9-b5d2-555ec0c36a4f": Phase="Running", Reason="", readiness=true. Elapsed: 2.012285183s
Oct 22 01:16:07.203: INFO: Pod "pod-configmaps-5446d11e-2882-4ab9-b5d2-555ec0c36a4f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.0179434s
STEP: Saw pod success
Oct 22 01:16:07.203: INFO: Pod "pod-configmaps-5446d11e-2882-4ab9-b5d2-555ec0c36a4f" satisfied condition "success or failure"
Oct 22 01:16:07.207: INFO: Trying to get logs from node mip-bd-vm41.mip.storage.hpecorp.net pod pod-configmaps-5446d11e-2882-4ab9-b5d2-555ec0c36a4f container env-test: <nil>
STEP: delete the pod
Oct 22 01:16:07.233: INFO: Waiting for pod pod-configmaps-5446d11e-2882-4ab9-b5d2-555ec0c36a4f to disappear
Oct 22 01:16:07.236: INFO: Pod pod-configmaps-5446d11e-2882-4ab9-b5d2-555ec0c36a4f no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 01:16:07.237: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5495" for this suite.
Oct 22 01:16:13.256: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 01:16:13.413: INFO: namespace configmap-5495 deletion completed in 6.17223665s

• [SLOW TEST:10.295 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 01:16:13.414: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-configmap-st9g
STEP: Creating a pod to test atomic-volume-subpath
Oct 22 01:16:13.478: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-st9g" in namespace "subpath-8468" to be "success or failure"
Oct 22 01:16:13.482: INFO: Pod "pod-subpath-test-configmap-st9g": Phase="Pending", Reason="", readiness=false. Elapsed: 3.61732ms
Oct 22 01:16:15.488: INFO: Pod "pod-subpath-test-configmap-st9g": Phase="Running", Reason="", readiness=true. Elapsed: 2.009281467s
Oct 22 01:16:17.493: INFO: Pod "pod-subpath-test-configmap-st9g": Phase="Running", Reason="", readiness=true. Elapsed: 4.014332947s
Oct 22 01:16:19.498: INFO: Pod "pod-subpath-test-configmap-st9g": Phase="Running", Reason="", readiness=true. Elapsed: 6.019931037s
Oct 22 01:16:21.504: INFO: Pod "pod-subpath-test-configmap-st9g": Phase="Running", Reason="", readiness=true. Elapsed: 8.025570219s
Oct 22 01:16:23.509: INFO: Pod "pod-subpath-test-configmap-st9g": Phase="Running", Reason="", readiness=true. Elapsed: 10.030923969s
Oct 22 01:16:25.515: INFO: Pod "pod-subpath-test-configmap-st9g": Phase="Running", Reason="", readiness=true. Elapsed: 12.036544803s
Oct 22 01:16:27.520: INFO: Pod "pod-subpath-test-configmap-st9g": Phase="Running", Reason="", readiness=true. Elapsed: 14.041732945s
Oct 22 01:16:29.526: INFO: Pod "pod-subpath-test-configmap-st9g": Phase="Running", Reason="", readiness=true. Elapsed: 16.047974208s
Oct 22 01:16:31.532: INFO: Pod "pod-subpath-test-configmap-st9g": Phase="Running", Reason="", readiness=true. Elapsed: 18.054129508s
Oct 22 01:16:33.538: INFO: Pod "pod-subpath-test-configmap-st9g": Phase="Running", Reason="", readiness=true. Elapsed: 20.059780837s
Oct 22 01:16:35.543: INFO: Pod "pod-subpath-test-configmap-st9g": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.064821365s
STEP: Saw pod success
Oct 22 01:16:35.543: INFO: Pod "pod-subpath-test-configmap-st9g" satisfied condition "success or failure"
Oct 22 01:16:35.548: INFO: Trying to get logs from node mip-bd-vm40.mip.storage.hpecorp.net pod pod-subpath-test-configmap-st9g container test-container-subpath-configmap-st9g: <nil>
STEP: delete the pod
Oct 22 01:16:35.577: INFO: Waiting for pod pod-subpath-test-configmap-st9g to disappear
Oct 22 01:16:35.581: INFO: Pod pod-subpath-test-configmap-st9g no longer exists
STEP: Deleting pod pod-subpath-test-configmap-st9g
Oct 22 01:16:35.581: INFO: Deleting pod "pod-subpath-test-configmap-st9g" in namespace "subpath-8468"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 01:16:35.585: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-8468" for this suite.
Oct 22 01:16:41.606: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 01:16:41.756: INFO: namespace subpath-8468 deletion completed in 6.166806721s

• [SLOW TEST:28.342 seconds]
[sig-storage] Subpath
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with configmap pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 01:16:41.757: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-map-2f6b94ca-c1e6-4d81-8d4f-2e5a294d1fb3
STEP: Creating a pod to test consume configMaps
Oct 22 01:16:41.813: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-0749f73d-16af-4c3e-8ad0-585a7b3b25be" in namespace "projected-8228" to be "success or failure"
Oct 22 01:16:41.817: INFO: Pod "pod-projected-configmaps-0749f73d-16af-4c3e-8ad0-585a7b3b25be": Phase="Pending", Reason="", readiness=false. Elapsed: 4.198109ms
Oct 22 01:16:43.823: INFO: Pod "pod-projected-configmaps-0749f73d-16af-4c3e-8ad0-585a7b3b25be": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009597125s
STEP: Saw pod success
Oct 22 01:16:43.823: INFO: Pod "pod-projected-configmaps-0749f73d-16af-4c3e-8ad0-585a7b3b25be" satisfied condition "success or failure"
Oct 22 01:16:43.827: INFO: Trying to get logs from node mip-bd-vm41.mip.storage.hpecorp.net pod pod-projected-configmaps-0749f73d-16af-4c3e-8ad0-585a7b3b25be container projected-configmap-volume-test: <nil>
STEP: delete the pod
Oct 22 01:16:43.856: INFO: Waiting for pod pod-projected-configmaps-0749f73d-16af-4c3e-8ad0-585a7b3b25be to disappear
Oct 22 01:16:43.860: INFO: Pod pod-projected-configmaps-0749f73d-16af-4c3e-8ad0-585a7b3b25be no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 01:16:43.861: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8228" for this suite.
Oct 22 01:16:49.884: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 01:16:50.066: INFO: namespace projected-8228 deletion completed in 6.200100849s

• [SLOW TEST:8.309 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 01:16:50.067: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Oct 22 01:16:50.148: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Oct 22 01:16:50.169: INFO: DaemonSet pods can't tolerate node mip-bd-vm39.mip.storage.hpecorp.net with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 22 01:16:50.176: INFO: Number of nodes with available pods: 0
Oct 22 01:16:50.176: INFO: Node mip-bd-vm40.mip.storage.hpecorp.net is running more than one daemon pod
Oct 22 01:16:51.183: INFO: DaemonSet pods can't tolerate node mip-bd-vm39.mip.storage.hpecorp.net with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 22 01:16:51.187: INFO: Number of nodes with available pods: 0
Oct 22 01:16:51.187: INFO: Node mip-bd-vm40.mip.storage.hpecorp.net is running more than one daemon pod
Oct 22 01:16:52.183: INFO: DaemonSet pods can't tolerate node mip-bd-vm39.mip.storage.hpecorp.net with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 22 01:16:52.187: INFO: Number of nodes with available pods: 2
Oct 22 01:16:52.187: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Oct 22 01:16:52.227: INFO: Wrong image for pod: daemon-set-jrzll. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 22 01:16:52.227: INFO: Wrong image for pod: daemon-set-qn5gq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 22 01:16:52.232: INFO: DaemonSet pods can't tolerate node mip-bd-vm39.mip.storage.hpecorp.net with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 22 01:16:53.239: INFO: Wrong image for pod: daemon-set-jrzll. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 22 01:16:53.239: INFO: Wrong image for pod: daemon-set-qn5gq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 22 01:16:53.244: INFO: DaemonSet pods can't tolerate node mip-bd-vm39.mip.storage.hpecorp.net with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 22 01:16:54.238: INFO: Wrong image for pod: daemon-set-jrzll. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 22 01:16:54.238: INFO: Wrong image for pod: daemon-set-qn5gq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 22 01:16:54.244: INFO: DaemonSet pods can't tolerate node mip-bd-vm39.mip.storage.hpecorp.net with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 22 01:16:55.238: INFO: Wrong image for pod: daemon-set-jrzll. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 22 01:16:55.238: INFO: Pod daemon-set-jrzll is not available
Oct 22 01:16:55.238: INFO: Wrong image for pod: daemon-set-qn5gq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 22 01:16:55.243: INFO: DaemonSet pods can't tolerate node mip-bd-vm39.mip.storage.hpecorp.net with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 22 01:16:56.238: INFO: Wrong image for pod: daemon-set-jrzll. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 22 01:16:56.238: INFO: Pod daemon-set-jrzll is not available
Oct 22 01:16:56.238: INFO: Wrong image for pod: daemon-set-qn5gq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 22 01:16:56.244: INFO: DaemonSet pods can't tolerate node mip-bd-vm39.mip.storage.hpecorp.net with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 22 01:16:57.238: INFO: Wrong image for pod: daemon-set-jrzll. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 22 01:16:57.238: INFO: Pod daemon-set-jrzll is not available
Oct 22 01:16:57.238: INFO: Wrong image for pod: daemon-set-qn5gq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 22 01:16:57.244: INFO: DaemonSet pods can't tolerate node mip-bd-vm39.mip.storage.hpecorp.net with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 22 01:16:58.238: INFO: Wrong image for pod: daemon-set-jrzll. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 22 01:16:58.238: INFO: Pod daemon-set-jrzll is not available
Oct 22 01:16:58.238: INFO: Wrong image for pod: daemon-set-qn5gq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 22 01:16:58.244: INFO: DaemonSet pods can't tolerate node mip-bd-vm39.mip.storage.hpecorp.net with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 22 01:16:59.239: INFO: Wrong image for pod: daemon-set-jrzll. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 22 01:16:59.239: INFO: Pod daemon-set-jrzll is not available
Oct 22 01:16:59.239: INFO: Wrong image for pod: daemon-set-qn5gq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 22 01:16:59.244: INFO: DaemonSet pods can't tolerate node mip-bd-vm39.mip.storage.hpecorp.net with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 22 01:17:00.239: INFO: Wrong image for pod: daemon-set-jrzll. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 22 01:17:00.239: INFO: Pod daemon-set-jrzll is not available
Oct 22 01:17:00.239: INFO: Wrong image for pod: daemon-set-qn5gq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 22 01:17:00.244: INFO: DaemonSet pods can't tolerate node mip-bd-vm39.mip.storage.hpecorp.net with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 22 01:17:01.239: INFO: Wrong image for pod: daemon-set-qn5gq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 22 01:17:01.239: INFO: Pod daemon-set-vb8bt is not available
Oct 22 01:17:01.244: INFO: DaemonSet pods can't tolerate node mip-bd-vm39.mip.storage.hpecorp.net with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 22 01:17:02.238: INFO: Wrong image for pod: daemon-set-qn5gq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 22 01:17:02.243: INFO: DaemonSet pods can't tolerate node mip-bd-vm39.mip.storage.hpecorp.net with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 22 01:17:03.238: INFO: Wrong image for pod: daemon-set-qn5gq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 22 01:17:03.238: INFO: Pod daemon-set-qn5gq is not available
Oct 22 01:17:03.243: INFO: DaemonSet pods can't tolerate node mip-bd-vm39.mip.storage.hpecorp.net with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 22 01:17:04.238: INFO: Wrong image for pod: daemon-set-qn5gq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 22 01:17:04.238: INFO: Pod daemon-set-qn5gq is not available
Oct 22 01:17:04.244: INFO: DaemonSet pods can't tolerate node mip-bd-vm39.mip.storage.hpecorp.net with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 22 01:17:05.237: INFO: Wrong image for pod: daemon-set-qn5gq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 22 01:17:05.237: INFO: Pod daemon-set-qn5gq is not available
Oct 22 01:17:05.244: INFO: DaemonSet pods can't tolerate node mip-bd-vm39.mip.storage.hpecorp.net with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 22 01:17:06.238: INFO: Wrong image for pod: daemon-set-qn5gq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 22 01:17:06.239: INFO: Pod daemon-set-qn5gq is not available
Oct 22 01:17:06.245: INFO: DaemonSet pods can't tolerate node mip-bd-vm39.mip.storage.hpecorp.net with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 22 01:17:07.239: INFO: Wrong image for pod: daemon-set-qn5gq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 22 01:17:07.239: INFO: Pod daemon-set-qn5gq is not available
Oct 22 01:17:07.244: INFO: DaemonSet pods can't tolerate node mip-bd-vm39.mip.storage.hpecorp.net with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 22 01:17:08.238: INFO: Wrong image for pod: daemon-set-qn5gq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 22 01:17:08.238: INFO: Pod daemon-set-qn5gq is not available
Oct 22 01:17:08.243: INFO: DaemonSet pods can't tolerate node mip-bd-vm39.mip.storage.hpecorp.net with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 22 01:17:09.239: INFO: Pod daemon-set-65bqg is not available
Oct 22 01:17:09.246: INFO: DaemonSet pods can't tolerate node mip-bd-vm39.mip.storage.hpecorp.net with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
STEP: Check that daemon pods are still running on every node of the cluster.
Oct 22 01:17:09.252: INFO: DaemonSet pods can't tolerate node mip-bd-vm39.mip.storage.hpecorp.net with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 22 01:17:09.256: INFO: Number of nodes with available pods: 1
Oct 22 01:17:09.256: INFO: Node mip-bd-vm41.mip.storage.hpecorp.net is running more than one daemon pod
Oct 22 01:17:10.263: INFO: DaemonSet pods can't tolerate node mip-bd-vm39.mip.storage.hpecorp.net with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 22 01:17:10.268: INFO: Number of nodes with available pods: 2
Oct 22 01:17:10.268: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-7510, will wait for the garbage collector to delete the pods
Oct 22 01:17:10.352: INFO: Deleting DaemonSet.extensions daemon-set took: 9.112756ms
Oct 22 01:17:10.753: INFO: Terminating DaemonSet.extensions daemon-set pods took: 400.350726ms
Oct 22 01:17:18.958: INFO: Number of nodes with available pods: 0
Oct 22 01:17:18.958: INFO: Number of running nodes: 0, number of available pods: 0
Oct 22 01:17:18.961: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-7510/daemonsets","resourceVersion":"27584"},"items":null}

Oct 22 01:17:18.964: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-7510/pods","resourceVersion":"27584"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 01:17:18.978: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-7510" for this suite.
Oct 22 01:17:24.996: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 01:17:25.149: INFO: namespace daemonsets-7510 deletion completed in 6.166771087s

• [SLOW TEST:35.082 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 01:17:25.149: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Oct 22 01:17:25.204: INFO: Waiting up to 5m0s for pod "downwardapi-volume-7296d5a3-0ec1-40ac-bcd3-42f96624bc10" in namespace "projected-4915" to be "success or failure"
Oct 22 01:17:25.209: INFO: Pod "downwardapi-volume-7296d5a3-0ec1-40ac-bcd3-42f96624bc10": Phase="Pending", Reason="", readiness=false. Elapsed: 4.404508ms
Oct 22 01:17:27.215: INFO: Pod "downwardapi-volume-7296d5a3-0ec1-40ac-bcd3-42f96624bc10": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01029697s
STEP: Saw pod success
Oct 22 01:17:27.215: INFO: Pod "downwardapi-volume-7296d5a3-0ec1-40ac-bcd3-42f96624bc10" satisfied condition "success or failure"
Oct 22 01:17:27.218: INFO: Trying to get logs from node mip-bd-vm40.mip.storage.hpecorp.net pod downwardapi-volume-7296d5a3-0ec1-40ac-bcd3-42f96624bc10 container client-container: <nil>
STEP: delete the pod
Oct 22 01:17:27.246: INFO: Waiting for pod downwardapi-volume-7296d5a3-0ec1-40ac-bcd3-42f96624bc10 to disappear
Oct 22 01:17:27.250: INFO: Pod downwardapi-volume-7296d5a3-0ec1-40ac-bcd3-42f96624bc10 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 01:17:27.250: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4915" for this suite.
Oct 22 01:17:33.269: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 01:17:33.443: INFO: namespace projected-4915 deletion completed in 6.187889535s

• [SLOW TEST:8.294 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 01:17:33.443: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-9419
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a new StatefulSet
Oct 22 01:17:33.519: INFO: Found 0 stateful pods, waiting for 3
Oct 22 01:17:43.526: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Oct 22 01:17:43.526: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Oct 22 01:17:43.526: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Oct 22 01:17:43.540: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 exec --namespace=statefulset-9419 ss2-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Oct 22 01:17:43.850: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Oct 22 01:17:43.851: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Oct 22 01:17:43.851: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Oct 22 01:17:53.890: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Oct 22 01:18:03.914: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 exec --namespace=statefulset-9419 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 22 01:18:04.316: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Oct 22 01:18:04.316: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Oct 22 01:18:04.316: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Oct 22 01:18:24.346: INFO: Waiting for StatefulSet statefulset-9419/ss2 to complete update
Oct 22 01:18:24.346: INFO: Waiting for Pod statefulset-9419/ss2-0 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
STEP: Rolling back to a previous revision
Oct 22 01:18:34.357: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 exec --namespace=statefulset-9419 ss2-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Oct 22 01:18:34.662: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Oct 22 01:18:34.662: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Oct 22 01:18:34.662: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Oct 22 01:18:44.704: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Oct 22 01:18:54.729: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 exec --namespace=statefulset-9419 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 22 01:18:55.040: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Oct 22 01:18:55.040: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Oct 22 01:18:55.040: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Oct 22 01:19:15.068: INFO: Waiting for StatefulSet statefulset-9419/ss2 to complete update
Oct 22 01:19:15.068: INFO: Waiting for Pod statefulset-9419/ss2-0 to have revision ss2-7c9b54fd4c update revision ss2-6c5cd755cd
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Oct 22 01:19:25.078: INFO: Deleting all statefulset in ns statefulset-9419
Oct 22 01:19:25.082: INFO: Scaling statefulset ss2 to 0
Oct 22 01:19:35.102: INFO: Waiting for statefulset status.replicas updated to 0
Oct 22 01:19:35.106: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 01:19:35.128: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-9419" for this suite.
Oct 22 01:19:51.154: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 01:19:51.311: INFO: namespace statefulset-9419 deletion completed in 16.177502859s

• [SLOW TEST:137.867 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 01:19:51.311: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with configMap that has name projected-configmap-test-upd-e11b1675-b7bf-469c-a5f7-09221010a464
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-e11b1675-b7bf-469c-a5f7-09221010a464
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 01:19:55.443: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2824" for this suite.
Oct 22 01:20:17.466: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 01:20:17.611: INFO: namespace projected-2824 deletion completed in 22.161980767s

• [SLOW TEST:26.300 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 01:20:17.611: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Oct 22 01:20:17.668: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e16f25d9-5a64-4939-bd78-e526c5d4a795" in namespace "projected-644" to be "success or failure"
Oct 22 01:20:17.672: INFO: Pod "downwardapi-volume-e16f25d9-5a64-4939-bd78-e526c5d4a795": Phase="Pending", Reason="", readiness=false. Elapsed: 3.85161ms
Oct 22 01:20:19.678: INFO: Pod "downwardapi-volume-e16f25d9-5a64-4939-bd78-e526c5d4a795": Phase="Running", Reason="", readiness=true. Elapsed: 2.009533358s
Oct 22 01:20:21.684: INFO: Pod "downwardapi-volume-e16f25d9-5a64-4939-bd78-e526c5d4a795": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015737612s
STEP: Saw pod success
Oct 22 01:20:21.684: INFO: Pod "downwardapi-volume-e16f25d9-5a64-4939-bd78-e526c5d4a795" satisfied condition "success or failure"
Oct 22 01:20:21.688: INFO: Trying to get logs from node mip-bd-vm41.mip.storage.hpecorp.net pod downwardapi-volume-e16f25d9-5a64-4939-bd78-e526c5d4a795 container client-container: <nil>
STEP: delete the pod
Oct 22 01:20:21.721: INFO: Waiting for pod downwardapi-volume-e16f25d9-5a64-4939-bd78-e526c5d4a795 to disappear
Oct 22 01:20:21.727: INFO: Pod downwardapi-volume-e16f25d9-5a64-4939-bd78-e526c5d4a795 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 01:20:21.728: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-644" for this suite.
Oct 22 01:20:27.753: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 01:20:27.897: INFO: namespace projected-644 deletion completed in 6.164633253s

• [SLOW TEST:10.286 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 01:20:27.898: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0777 on tmpfs
Oct 22 01:20:27.956: INFO: Waiting up to 5m0s for pod "pod-d5d6cbab-ed7e-4a7a-b2f0-7527a1a3d221" in namespace "emptydir-698" to be "success or failure"
Oct 22 01:20:27.964: INFO: Pod "pod-d5d6cbab-ed7e-4a7a-b2f0-7527a1a3d221": Phase="Pending", Reason="", readiness=false. Elapsed: 7.454006ms
Oct 22 01:20:29.970: INFO: Pod "pod-d5d6cbab-ed7e-4a7a-b2f0-7527a1a3d221": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01317084s
STEP: Saw pod success
Oct 22 01:20:29.970: INFO: Pod "pod-d5d6cbab-ed7e-4a7a-b2f0-7527a1a3d221" satisfied condition "success or failure"
Oct 22 01:20:29.979: INFO: Trying to get logs from node mip-bd-vm40.mip.storage.hpecorp.net pod pod-d5d6cbab-ed7e-4a7a-b2f0-7527a1a3d221 container test-container: <nil>
STEP: delete the pod
Oct 22 01:20:30.004: INFO: Waiting for pod pod-d5d6cbab-ed7e-4a7a-b2f0-7527a1a3d221 to disappear
Oct 22 01:20:30.008: INFO: Pod pod-d5d6cbab-ed7e-4a7a-b2f0-7527a1a3d221 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 01:20:30.008: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-698" for this suite.
Oct 22 01:20:36.031: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 01:20:36.186: INFO: namespace emptydir-698 deletion completed in 6.17212167s

• [SLOW TEST:8.288 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 01:20:36.187: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:63
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Oct 22 01:20:40.277: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Oct 22 01:20:40.281: INFO: Pod pod-with-prestop-http-hook still exists
Oct 22 01:20:42.281: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Oct 22 01:20:42.286: INFO: Pod pod-with-prestop-http-hook still exists
Oct 22 01:20:44.281: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Oct 22 01:20:44.286: INFO: Pod pod-with-prestop-http-hook still exists
Oct 22 01:20:46.281: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Oct 22 01:20:46.286: INFO: Pod pod-with-prestop-http-hook still exists
Oct 22 01:20:48.281: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Oct 22 01:20:48.285: INFO: Pod pod-with-prestop-http-hook still exists
Oct 22 01:20:50.281: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Oct 22 01:20:50.287: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 01:20:50.301: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-8913" for this suite.
Oct 22 01:21:12.323: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 01:21:12.470: INFO: namespace container-lifecycle-hook-8913 deletion completed in 22.164040489s

• [SLOW TEST:36.283 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when create a pod with lifecycle hook
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 01:21:12.470: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0666 on tmpfs
Oct 22 01:21:12.525: INFO: Waiting up to 5m0s for pod "pod-5e541eff-60b1-4b24-bfbb-8730664dc3ee" in namespace "emptydir-4663" to be "success or failure"
Oct 22 01:21:12.537: INFO: Pod "pod-5e541eff-60b1-4b24-bfbb-8730664dc3ee": Phase="Pending", Reason="", readiness=false. Elapsed: 12.286394ms
Oct 22 01:21:14.544: INFO: Pod "pod-5e541eff-60b1-4b24-bfbb-8730664dc3ee": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018766792s
Oct 22 01:21:16.549: INFO: Pod "pod-5e541eff-60b1-4b24-bfbb-8730664dc3ee": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02387123s
STEP: Saw pod success
Oct 22 01:21:16.549: INFO: Pod "pod-5e541eff-60b1-4b24-bfbb-8730664dc3ee" satisfied condition "success or failure"
Oct 22 01:21:16.553: INFO: Trying to get logs from node mip-bd-vm41.mip.storage.hpecorp.net pod pod-5e541eff-60b1-4b24-bfbb-8730664dc3ee container test-container: <nil>
STEP: delete the pod
Oct 22 01:21:16.581: INFO: Waiting for pod pod-5e541eff-60b1-4b24-bfbb-8730664dc3ee to disappear
Oct 22 01:21:16.585: INFO: Pod pod-5e541eff-60b1-4b24-bfbb-8730664dc3ee no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 01:21:16.585: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4663" for this suite.
Oct 22 01:21:22.604: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 01:21:22.750: INFO: namespace emptydir-4663 deletion completed in 6.160617533s

• [SLOW TEST:10.280 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 01:21:22.751: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Oct 22 01:21:22.809: INFO: Waiting up to 5m0s for pod "downward-api-c64a549a-caaa-4fe3-a7a9-1e063e7a00af" in namespace "downward-api-174" to be "success or failure"
Oct 22 01:21:22.814: INFO: Pod "downward-api-c64a549a-caaa-4fe3-a7a9-1e063e7a00af": Phase="Pending", Reason="", readiness=false. Elapsed: 4.474337ms
Oct 22 01:21:24.820: INFO: Pod "downward-api-c64a549a-caaa-4fe3-a7a9-1e063e7a00af": Phase="Running", Reason="", readiness=true. Elapsed: 2.010779645s
Oct 22 01:21:26.826: INFO: Pod "downward-api-c64a549a-caaa-4fe3-a7a9-1e063e7a00af": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017032028s
STEP: Saw pod success
Oct 22 01:21:26.826: INFO: Pod "downward-api-c64a549a-caaa-4fe3-a7a9-1e063e7a00af" satisfied condition "success or failure"
Oct 22 01:21:26.831: INFO: Trying to get logs from node mip-bd-vm41.mip.storage.hpecorp.net pod downward-api-c64a549a-caaa-4fe3-a7a9-1e063e7a00af container dapi-container: <nil>
STEP: delete the pod
Oct 22 01:21:26.902: INFO: Waiting for pod downward-api-c64a549a-caaa-4fe3-a7a9-1e063e7a00af to disappear
Oct 22 01:21:26.910: INFO: Pod downward-api-c64a549a-caaa-4fe3-a7a9-1e063e7a00af no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 01:21:26.910: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-174" for this suite.
Oct 22 01:21:32.967: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 01:21:33.106: INFO: namespace downward-api-174 deletion completed in 6.182384864s

• [SLOW TEST:10.355 seconds]
[sig-node] Downward API
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 01:21:33.106: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Oct 22 01:21:39.211: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-3344 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 22 01:21:39.211: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
Oct 22 01:21:39.340: INFO: Exec stderr: ""
Oct 22 01:21:39.340: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-3344 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 22 01:21:39.340: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
Oct 22 01:21:39.496: INFO: Exec stderr: ""
Oct 22 01:21:39.496: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-3344 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 22 01:21:39.496: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
Oct 22 01:21:39.713: INFO: Exec stderr: ""
Oct 22 01:21:39.713: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-3344 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 22 01:21:39.713: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
Oct 22 01:21:39.846: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Oct 22 01:21:39.846: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-3344 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 22 01:21:39.846: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
Oct 22 01:21:39.992: INFO: Exec stderr: ""
Oct 22 01:21:39.992: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-3344 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 22 01:21:39.992: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
Oct 22 01:21:40.142: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Oct 22 01:21:40.142: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-3344 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 22 01:21:40.142: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
Oct 22 01:21:40.294: INFO: Exec stderr: ""
Oct 22 01:21:40.294: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-3344 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 22 01:21:40.294: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
Oct 22 01:21:40.424: INFO: Exec stderr: ""
Oct 22 01:21:40.424: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-3344 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 22 01:21:40.424: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
Oct 22 01:21:40.567: INFO: Exec stderr: ""
Oct 22 01:21:40.567: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-3344 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 22 01:21:40.567: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
Oct 22 01:21:40.698: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 01:21:40.698: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-kubelet-etc-hosts-3344" for this suite.
Oct 22 01:22:22.722: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 01:22:22.870: INFO: namespace e2e-kubelet-etc-hosts-3344 deletion completed in 42.165432221s

• [SLOW TEST:49.764 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 01:22:22.871: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Oct 22 01:22:22.917: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Oct 22 01:22:22.926: INFO: Pod name sample-pod: Found 0 pods out of 1
Oct 22 01:22:27.932: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Oct 22 01:22:27.932: INFO: Creating deployment "test-rolling-update-deployment"
Oct 22 01:22:27.939: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Oct 22 01:22:27.953: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Oct 22 01:22:29.963: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Oct 22 01:22:29.967: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
Oct 22 01:22:29.979: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment,GenerateName:,Namespace:deployment-7460,SelfLink:/apis/apps/v1/namespaces/deployment-7460/deployments/test-rolling-update-deployment,UID:cc799734-1175-487c-82db-cdf83f889b22,ResourceVersion:28712,Generation:1,CreationTimestamp:2019-10-22 01:22:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-10-22 01:22:27 +0000 UTC 2019-10-22 01:22:27 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-10-22 01:22:29 +0000 UTC 2019-10-22 01:22:27 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rolling-update-deployment-79f6b9d75c" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Oct 22 01:22:29.984: INFO: New ReplicaSet "test-rolling-update-deployment-79f6b9d75c" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-79f6b9d75c,GenerateName:,Namespace:deployment-7460,SelfLink:/apis/apps/v1/namespaces/deployment-7460/replicasets/test-rolling-update-deployment-79f6b9d75c,UID:bd979afc-dab1-4ad5-b07f-583c4b7e3f91,ResourceVersion:28701,Generation:1,CreationTimestamp:2019-10-22 01:22:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 79f6b9d75c,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment cc799734-1175-487c-82db-cdf83f889b22 0xc00348c9a7 0xc00348c9a8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 79f6b9d75c,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 79f6b9d75c,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Oct 22 01:22:29.984: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Oct 22 01:22:29.984: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-controller,GenerateName:,Namespace:deployment-7460,SelfLink:/apis/apps/v1/namespaces/deployment-7460/replicasets/test-rolling-update-controller,UID:5078560b-b0ff-45a8-a2c0-509266c9ff21,ResourceVersion:28711,Generation:2,CreationTimestamp:2019-10-22 01:22:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305832,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment cc799734-1175-487c-82db-cdf83f889b22 0xc00348c8c7 0xc00348c8c8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Oct 22 01:22:29.990: INFO: Pod "test-rolling-update-deployment-79f6b9d75c-blllz" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-79f6b9d75c-blllz,GenerateName:test-rolling-update-deployment-79f6b9d75c-,Namespace:deployment-7460,SelfLink:/api/v1/namespaces/deployment-7460/pods/test-rolling-update-deployment-79f6b9d75c-blllz,UID:dc198b5b-f054-48f3-b207-955dbbe58c62,ResourceVersion:28700,Generation:0,CreationTimestamp:2019-10-22 01:22:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 79f6b9d75c,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.244.2.157/32,},OwnerReferences:[{apps/v1 ReplicaSet test-rolling-update-deployment-79f6b9d75c bd979afc-dab1-4ad5-b07f-583c4b7e3f91 0xc00348d297 0xc00348d298}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-ggtzt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-ggtzt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-ggtzt true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:mip-bd-vm40.mip.storage.hpecorp.net,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00348d300} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00348d320}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-22 01:22:27 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-10-22 01:22:28 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-10-22 01:22:28 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-22 01:22:27 +0000 UTC  }],Message:,Reason:,HostIP:16.143.20.137,PodIP:10.244.2.157,StartTime:2019-10-22 01:22:27 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-10-22 01:22:28 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://067e64f489181d600f7c889e281d2f6536f3760a2ab74e6142376c330e37290d}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 01:22:29.990: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-7460" for this suite.
Oct 22 01:22:36.010: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 01:22:36.149: INFO: namespace deployment-7460 deletion completed in 6.153576596s

• [SLOW TEST:13.278 seconds]
[sig-apps] Deployment
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 01:22:36.149: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Oct 22 01:22:38.219: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 01:22:38.239: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-8759" for this suite.
Oct 22 01:22:44.258: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 01:22:44.432: INFO: namespace container-runtime-8759 deletion completed in 6.187636165s

• [SLOW TEST:8.283 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  blackbox test
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
    on terminated container
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:129
      should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
      /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 01:22:44.432: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Oct 22 01:22:44.498: INFO: Waiting up to 5m0s for pod "downwardapi-volume-99b3a8a6-704e-45aa-a5de-db902dc1deff" in namespace "downward-api-9408" to be "success or failure"
Oct 22 01:22:44.503: INFO: Pod "downwardapi-volume-99b3a8a6-704e-45aa-a5de-db902dc1deff": Phase="Pending", Reason="", readiness=false. Elapsed: 4.840505ms
Oct 22 01:22:46.509: INFO: Pod "downwardapi-volume-99b3a8a6-704e-45aa-a5de-db902dc1deff": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010585285s
STEP: Saw pod success
Oct 22 01:22:46.509: INFO: Pod "downwardapi-volume-99b3a8a6-704e-45aa-a5de-db902dc1deff" satisfied condition "success or failure"
Oct 22 01:22:46.513: INFO: Trying to get logs from node mip-bd-vm40.mip.storage.hpecorp.net pod downwardapi-volume-99b3a8a6-704e-45aa-a5de-db902dc1deff container client-container: <nil>
STEP: delete the pod
Oct 22 01:22:46.537: INFO: Waiting for pod downwardapi-volume-99b3a8a6-704e-45aa-a5de-db902dc1deff to disappear
Oct 22 01:22:46.543: INFO: Pod downwardapi-volume-99b3a8a6-704e-45aa-a5de-db902dc1deff no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 01:22:46.543: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9408" for this suite.
Oct 22 01:22:52.564: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 01:22:52.717: INFO: namespace downward-api-9408 deletion completed in 6.167410665s

• [SLOW TEST:8.285 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 01:22:52.717: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: validating api versions
Oct 22 01:22:52.768: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 api-versions'
Oct 22 01:22:52.929: INFO: stderr: ""
Oct 22 01:22:52.929: INFO: stdout: "admissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\napps/v1beta1\napps/v1beta2\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1\ncoordination.k8s.io/v1beta1\ncrd.projectcalico.org/v1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nkubedirector.bluedata.io/v1alpha1\nnetworking.k8s.io/v1\nnetworking.k8s.io/v1beta1\nnode.k8s.io/v1beta1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1\nscheduling.k8s.io/v1beta1\nsettings.k8s.io/v1alpha1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 01:22:52.929: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2726" for this suite.
Oct 22 01:22:58.952: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 01:22:59.100: INFO: namespace kubectl-2726 deletion completed in 6.16484028s

• [SLOW TEST:6.382 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl api-versions
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 01:22:59.100: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
Oct 22 01:22:59.149: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 01:23:03.300: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-2797" for this suite.
Oct 22 01:23:25.321: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 01:23:25.466: INFO: namespace init-container-2797 deletion completed in 22.159851534s

• [SLOW TEST:26.366 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 01:23:25.466: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test substitution in container's command
Oct 22 01:23:25.521: INFO: Waiting up to 5m0s for pod "var-expansion-da21e904-7d23-45bc-b320-9a115c91340c" in namespace "var-expansion-1141" to be "success or failure"
Oct 22 01:23:25.526: INFO: Pod "var-expansion-da21e904-7d23-45bc-b320-9a115c91340c": Phase="Pending", Reason="", readiness=false. Elapsed: 4.752863ms
Oct 22 01:23:27.531: INFO: Pod "var-expansion-da21e904-7d23-45bc-b320-9a115c91340c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009553658s
STEP: Saw pod success
Oct 22 01:23:27.531: INFO: Pod "var-expansion-da21e904-7d23-45bc-b320-9a115c91340c" satisfied condition "success or failure"
Oct 22 01:23:27.535: INFO: Trying to get logs from node mip-bd-vm40.mip.storage.hpecorp.net pod var-expansion-da21e904-7d23-45bc-b320-9a115c91340c container dapi-container: <nil>
STEP: delete the pod
Oct 22 01:23:27.562: INFO: Waiting for pod var-expansion-da21e904-7d23-45bc-b320-9a115c91340c to disappear
Oct 22 01:23:27.566: INFO: Pod var-expansion-da21e904-7d23-45bc-b320-9a115c91340c no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 01:23:27.566: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-1141" for this suite.
Oct 22 01:23:33.588: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 01:23:33.741: INFO: namespace var-expansion-1141 deletion completed in 6.169904401s

• [SLOW TEST:8.275 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 01:23:33.742: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:63
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Oct 22 01:23:37.840: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct 22 01:23:37.845: INFO: Pod pod-with-prestop-exec-hook still exists
Oct 22 01:23:39.845: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct 22 01:23:39.850: INFO: Pod pod-with-prestop-exec-hook still exists
Oct 22 01:23:41.845: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct 22 01:23:41.850: INFO: Pod pod-with-prestop-exec-hook still exists
Oct 22 01:23:43.845: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct 22 01:23:43.851: INFO: Pod pod-with-prestop-exec-hook still exists
Oct 22 01:23:45.845: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct 22 01:23:45.851: INFO: Pod pod-with-prestop-exec-hook still exists
Oct 22 01:23:47.845: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct 22 01:23:47.851: INFO: Pod pod-with-prestop-exec-hook still exists
Oct 22 01:23:49.845: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct 22 01:23:49.850: INFO: Pod pod-with-prestop-exec-hook still exists
Oct 22 01:23:51.845: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct 22 01:23:51.852: INFO: Pod pod-with-prestop-exec-hook still exists
Oct 22 01:23:53.845: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct 22 01:23:53.850: INFO: Pod pod-with-prestop-exec-hook still exists
Oct 22 01:23:55.845: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct 22 01:23:55.851: INFO: Pod pod-with-prestop-exec-hook still exists
Oct 22 01:23:57.845: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct 22 01:23:57.851: INFO: Pod pod-with-prestop-exec-hook still exists
Oct 22 01:23:59.845: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct 22 01:23:59.849: INFO: Pod pod-with-prestop-exec-hook still exists
Oct 22 01:24:01.845: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct 22 01:24:01.851: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 01:24:01.865: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-899" for this suite.
Oct 22 01:24:23.889: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 01:24:24.058: INFO: namespace container-lifecycle-hook-899 deletion completed in 22.186978815s

• [SLOW TEST:50.317 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when create a pod with lifecycle hook
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 01:24:24.059: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-16c4b210-38bf-4e1e-9d00-522fa0b4cd80
STEP: Creating a pod to test consume configMaps
Oct 22 01:24:24.118: INFO: Waiting up to 5m0s for pod "pod-configmaps-aea97e96-bd29-4042-8f27-a122c6b7442a" in namespace "configmap-5539" to be "success or failure"
Oct 22 01:24:24.123: INFO: Pod "pod-configmaps-aea97e96-bd29-4042-8f27-a122c6b7442a": Phase="Pending", Reason="", readiness=false. Elapsed: 4.742378ms
Oct 22 01:24:26.128: INFO: Pod "pod-configmaps-aea97e96-bd29-4042-8f27-a122c6b7442a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009920117s
STEP: Saw pod success
Oct 22 01:24:26.129: INFO: Pod "pod-configmaps-aea97e96-bd29-4042-8f27-a122c6b7442a" satisfied condition "success or failure"
Oct 22 01:24:26.132: INFO: Trying to get logs from node mip-bd-vm41.mip.storage.hpecorp.net pod pod-configmaps-aea97e96-bd29-4042-8f27-a122c6b7442a container configmap-volume-test: <nil>
STEP: delete the pod
Oct 22 01:24:26.161: INFO: Waiting for pod pod-configmaps-aea97e96-bd29-4042-8f27-a122c6b7442a to disappear
Oct 22 01:24:26.164: INFO: Pod pod-configmaps-aea97e96-bd29-4042-8f27-a122c6b7442a no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 01:24:26.164: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5539" for this suite.
Oct 22 01:24:32.191: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 01:24:32.322: INFO: namespace configmap-5539 deletion completed in 6.152657249s

• [SLOW TEST:8.263 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 01:24:32.322: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Oct 22 01:24:32.403: INFO: DaemonSet pods can't tolerate node mip-bd-vm39.mip.storage.hpecorp.net with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 22 01:24:32.407: INFO: Number of nodes with available pods: 0
Oct 22 01:24:32.407: INFO: Node mip-bd-vm40.mip.storage.hpecorp.net is running more than one daemon pod
Oct 22 01:24:33.413: INFO: DaemonSet pods can't tolerate node mip-bd-vm39.mip.storage.hpecorp.net with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 22 01:24:33.417: INFO: Number of nodes with available pods: 0
Oct 22 01:24:33.417: INFO: Node mip-bd-vm40.mip.storage.hpecorp.net is running more than one daemon pod
Oct 22 01:24:34.414: INFO: DaemonSet pods can't tolerate node mip-bd-vm39.mip.storage.hpecorp.net with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 22 01:24:34.420: INFO: Number of nodes with available pods: 1
Oct 22 01:24:34.420: INFO: Node mip-bd-vm40.mip.storage.hpecorp.net is running more than one daemon pod
Oct 22 01:24:35.412: INFO: DaemonSet pods can't tolerate node mip-bd-vm39.mip.storage.hpecorp.net with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 22 01:24:35.417: INFO: Number of nodes with available pods: 2
Oct 22 01:24:35.417: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Oct 22 01:24:35.437: INFO: DaemonSet pods can't tolerate node mip-bd-vm39.mip.storage.hpecorp.net with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 22 01:24:35.446: INFO: Number of nodes with available pods: 1
Oct 22 01:24:35.446: INFO: Node mip-bd-vm40.mip.storage.hpecorp.net is running more than one daemon pod
Oct 22 01:24:36.453: INFO: DaemonSet pods can't tolerate node mip-bd-vm39.mip.storage.hpecorp.net with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 22 01:24:36.458: INFO: Number of nodes with available pods: 1
Oct 22 01:24:36.458: INFO: Node mip-bd-vm40.mip.storage.hpecorp.net is running more than one daemon pod
Oct 22 01:24:37.452: INFO: DaemonSet pods can't tolerate node mip-bd-vm39.mip.storage.hpecorp.net with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 22 01:24:37.457: INFO: Number of nodes with available pods: 2
Oct 22 01:24:37.457: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-2713, will wait for the garbage collector to delete the pods
Oct 22 01:24:37.527: INFO: Deleting DaemonSet.extensions daemon-set took: 8.200651ms
Oct 22 01:24:37.928: INFO: Terminating DaemonSet.extensions daemon-set pods took: 400.301353ms
Oct 22 01:24:51.032: INFO: Number of nodes with available pods: 0
Oct 22 01:24:51.032: INFO: Number of running nodes: 0, number of available pods: 0
Oct 22 01:24:51.036: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-2713/daemonsets","resourceVersion":"29197"},"items":null}

Oct 22 01:24:51.039: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-2713/pods","resourceVersion":"29197"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 01:24:51.059: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-2713" for this suite.
Oct 22 01:24:57.083: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 01:24:57.237: INFO: namespace daemonsets-2713 deletion completed in 6.172973187s

• [SLOW TEST:24.915 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 01:24:57.238: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Oct 22 01:24:57.297: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-1165,SelfLink:/api/v1/namespaces/watch-1165/configmaps/e2e-watch-test-configmap-a,UID:e4b14e3c-3047-44ed-a864-d20197e0cc11,ResourceVersion:29232,Generation:0,CreationTimestamp:2019-10-22 01:24:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Oct 22 01:24:57.298: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-1165,SelfLink:/api/v1/namespaces/watch-1165/configmaps/e2e-watch-test-configmap-a,UID:e4b14e3c-3047-44ed-a864-d20197e0cc11,ResourceVersion:29232,Generation:0,CreationTimestamp:2019-10-22 01:24:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Oct 22 01:25:07.308: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-1165,SelfLink:/api/v1/namespaces/watch-1165/configmaps/e2e-watch-test-configmap-a,UID:e4b14e3c-3047-44ed-a864-d20197e0cc11,ResourceVersion:29247,Generation:0,CreationTimestamp:2019-10-22 01:24:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Oct 22 01:25:07.308: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-1165,SelfLink:/api/v1/namespaces/watch-1165/configmaps/e2e-watch-test-configmap-a,UID:e4b14e3c-3047-44ed-a864-d20197e0cc11,ResourceVersion:29247,Generation:0,CreationTimestamp:2019-10-22 01:24:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Oct 22 01:25:17.319: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-1165,SelfLink:/api/v1/namespaces/watch-1165/configmaps/e2e-watch-test-configmap-a,UID:e4b14e3c-3047-44ed-a864-d20197e0cc11,ResourceVersion:29262,Generation:0,CreationTimestamp:2019-10-22 01:24:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Oct 22 01:25:17.319: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-1165,SelfLink:/api/v1/namespaces/watch-1165/configmaps/e2e-watch-test-configmap-a,UID:e4b14e3c-3047-44ed-a864-d20197e0cc11,ResourceVersion:29262,Generation:0,CreationTimestamp:2019-10-22 01:24:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Oct 22 01:25:27.345: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-1165,SelfLink:/api/v1/namespaces/watch-1165/configmaps/e2e-watch-test-configmap-a,UID:e4b14e3c-3047-44ed-a864-d20197e0cc11,ResourceVersion:29279,Generation:0,CreationTimestamp:2019-10-22 01:24:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Oct 22 01:25:27.345: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-1165,SelfLink:/api/v1/namespaces/watch-1165/configmaps/e2e-watch-test-configmap-a,UID:e4b14e3c-3047-44ed-a864-d20197e0cc11,ResourceVersion:29279,Generation:0,CreationTimestamp:2019-10-22 01:24:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Oct 22 01:25:37.356: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-1165,SelfLink:/api/v1/namespaces/watch-1165/configmaps/e2e-watch-test-configmap-b,UID:bad1bd92-7afa-43a6-8682-6440916d7457,ResourceVersion:29295,Generation:0,CreationTimestamp:2019-10-22 01:25:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Oct 22 01:25:37.356: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-1165,SelfLink:/api/v1/namespaces/watch-1165/configmaps/e2e-watch-test-configmap-b,UID:bad1bd92-7afa-43a6-8682-6440916d7457,ResourceVersion:29295,Generation:0,CreationTimestamp:2019-10-22 01:25:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Oct 22 01:25:47.368: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-1165,SelfLink:/api/v1/namespaces/watch-1165/configmaps/e2e-watch-test-configmap-b,UID:bad1bd92-7afa-43a6-8682-6440916d7457,ResourceVersion:29310,Generation:0,CreationTimestamp:2019-10-22 01:25:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Oct 22 01:25:47.368: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-1165,SelfLink:/api/v1/namespaces/watch-1165/configmaps/e2e-watch-test-configmap-b,UID:bad1bd92-7afa-43a6-8682-6440916d7457,ResourceVersion:29310,Generation:0,CreationTimestamp:2019-10-22 01:25:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 01:25:57.368: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-1165" for this suite.
Oct 22 01:26:03.394: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 01:26:03.544: INFO: namespace watch-1165 deletion completed in 6.169456986s

• [SLOW TEST:66.305 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 01:26:03.544: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-c9f00cd3-bfc6-4b9d-af2d-315070be6832
STEP: Creating a pod to test consume secrets
Oct 22 01:26:03.602: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-943e9ae8-05bc-4c43-ae80-cb6a7c9936db" in namespace "projected-6967" to be "success or failure"
Oct 22 01:26:03.606: INFO: Pod "pod-projected-secrets-943e9ae8-05bc-4c43-ae80-cb6a7c9936db": Phase="Pending", Reason="", readiness=false. Elapsed: 3.785551ms
Oct 22 01:26:05.611: INFO: Pod "pod-projected-secrets-943e9ae8-05bc-4c43-ae80-cb6a7c9936db": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009232733s
STEP: Saw pod success
Oct 22 01:26:05.611: INFO: Pod "pod-projected-secrets-943e9ae8-05bc-4c43-ae80-cb6a7c9936db" satisfied condition "success or failure"
Oct 22 01:26:05.615: INFO: Trying to get logs from node mip-bd-vm40.mip.storage.hpecorp.net pod pod-projected-secrets-943e9ae8-05bc-4c43-ae80-cb6a7c9936db container projected-secret-volume-test: <nil>
STEP: delete the pod
Oct 22 01:26:05.652: INFO: Waiting for pod pod-projected-secrets-943e9ae8-05bc-4c43-ae80-cb6a7c9936db to disappear
Oct 22 01:26:05.657: INFO: Pod pod-projected-secrets-943e9ae8-05bc-4c43-ae80-cb6a7c9936db no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 01:26:05.657: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6967" for this suite.
Oct 22 01:26:11.678: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 01:26:11.837: INFO: namespace projected-6967 deletion completed in 6.17395888s

• [SLOW TEST:8.293 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 01:26:11.837: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating Redis RC
Oct 22 01:26:11.891: INFO: namespace kubectl-3384
Oct 22 01:26:11.891: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 create -f - --namespace=kubectl-3384'
Oct 22 01:26:12.384: INFO: stderr: ""
Oct 22 01:26:12.384: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Oct 22 01:26:13.389: INFO: Selector matched 1 pods for map[app:redis]
Oct 22 01:26:13.389: INFO: Found 0 / 1
Oct 22 01:26:14.390: INFO: Selector matched 1 pods for map[app:redis]
Oct 22 01:26:14.390: INFO: Found 1 / 1
Oct 22 01:26:14.390: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Oct 22 01:26:14.395: INFO: Selector matched 1 pods for map[app:redis]
Oct 22 01:26:14.395: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Oct 22 01:26:14.395: INFO: wait on redis-master startup in kubectl-3384 
Oct 22 01:26:14.395: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 logs redis-master-4ddnp redis-master --namespace=kubectl-3384'
Oct 22 01:26:14.582: INFO: stderr: ""
Oct 22 01:26:14.582: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 22 Oct 01:26:13.405 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 22 Oct 01:26:13.405 # Server started, Redis version 3.2.12\n1:M 22 Oct 01:26:13.405 * The server is now ready to accept connections on port 6379\n"
STEP: exposing RC
Oct 22 01:26:14.582: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=kubectl-3384'
Oct 22 01:26:14.779: INFO: stderr: ""
Oct 22 01:26:14.779: INFO: stdout: "service/rm2 exposed\n"
Oct 22 01:26:14.784: INFO: Service rm2 in namespace kubectl-3384 found.
STEP: exposing service
Oct 22 01:26:16.793: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=kubectl-3384'
Oct 22 01:26:16.984: INFO: stderr: ""
Oct 22 01:26:16.985: INFO: stdout: "service/rm3 exposed\n"
Oct 22 01:26:16.992: INFO: Service rm3 in namespace kubectl-3384 found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 01:26:19.002: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3384" for this suite.
Oct 22 01:26:41.022: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 01:26:41.167: INFO: namespace kubectl-3384 deletion completed in 22.15984508s

• [SLOW TEST:29.330 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl expose
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create services for rc  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] version v1
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 01:26:41.168: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-27sd4 in namespace proxy-8293
I1022 01:26:41.235612      18 runners.go:180] Created replication controller with name: proxy-service-27sd4, namespace: proxy-8293, replica count: 1
I1022 01:26:42.286099      18 runners.go:180] proxy-service-27sd4 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1022 01:26:43.286427      18 runners.go:180] proxy-service-27sd4 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1022 01:26:44.286806      18 runners.go:180] proxy-service-27sd4 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1022 01:26:45.287177      18 runners.go:180] proxy-service-27sd4 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1022 01:26:46.287565      18 runners.go:180] proxy-service-27sd4 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1022 01:26:47.287866      18 runners.go:180] proxy-service-27sd4 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1022 01:26:48.288242      18 runners.go:180] proxy-service-27sd4 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1022 01:26:49.288528      18 runners.go:180] proxy-service-27sd4 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1022 01:26:50.288846      18 runners.go:180] proxy-service-27sd4 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1022 01:26:51.289166      18 runners.go:180] proxy-service-27sd4 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1022 01:26:52.289490      18 runners.go:180] proxy-service-27sd4 Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Oct 22 01:26:52.293: INFO: setup took 11.079715103s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Oct 22 01:26:52.308: INFO: (0) /api/v1/namespaces/proxy-8293/pods/proxy-service-27sd4-bwjhf/proxy/: <a href="/api/v1/namespaces/proxy-8293/pods/proxy-service-27sd4-bwjhf/proxy/rewriteme">test</a> (200; 14.002868ms)
Oct 22 01:26:52.308: INFO: (0) /api/v1/namespaces/proxy-8293/pods/proxy-service-27sd4-bwjhf:162/proxy/: bar (200; 14.2517ms)
Oct 22 01:26:52.308: INFO: (0) /api/v1/namespaces/proxy-8293/pods/http:proxy-service-27sd4-bwjhf:1080/proxy/: <a href="/api/v1/namespaces/proxy-8293/pods/http:proxy-service-27sd4-bwjhf:1080/proxy/rewriteme">... (200; 13.994629ms)
Oct 22 01:26:52.308: INFO: (0) /api/v1/namespaces/proxy-8293/pods/proxy-service-27sd4-bwjhf:1080/proxy/: <a href="/api/v1/namespaces/proxy-8293/pods/proxy-service-27sd4-bwjhf:1080/proxy/rewriteme">test<... (200; 13.696893ms)
Oct 22 01:26:52.308: INFO: (0) /api/v1/namespaces/proxy-8293/pods/proxy-service-27sd4-bwjhf:160/proxy/: foo (200; 13.997526ms)
Oct 22 01:26:52.312: INFO: (0) /api/v1/namespaces/proxy-8293/pods/http:proxy-service-27sd4-bwjhf:162/proxy/: bar (200; 17.378788ms)
Oct 22 01:26:52.317: INFO: (0) /api/v1/namespaces/proxy-8293/services/proxy-service-27sd4:portname2/proxy/: bar (200; 23.132295ms)
Oct 22 01:26:52.320: INFO: (0) /api/v1/namespaces/proxy-8293/pods/http:proxy-service-27sd4-bwjhf:160/proxy/: foo (200; 24.895509ms)
Oct 22 01:26:52.320: INFO: (0) /api/v1/namespaces/proxy-8293/services/http:proxy-service-27sd4:portname2/proxy/: bar (200; 24.848124ms)
Oct 22 01:26:52.320: INFO: (0) /api/v1/namespaces/proxy-8293/services/http:proxy-service-27sd4:portname1/proxy/: foo (200; 25.675734ms)
Oct 22 01:26:52.320: INFO: (0) /api/v1/namespaces/proxy-8293/pods/https:proxy-service-27sd4-bwjhf:460/proxy/: tls baz (200; 25.2152ms)
Oct 22 01:26:52.321: INFO: (0) /api/v1/namespaces/proxy-8293/pods/https:proxy-service-27sd4-bwjhf:443/proxy/: <a href="/api/v1/namespaces/proxy-8293/pods/https:proxy-service-27sd4-bwjhf:443/proxy/tlsrewritem... (200; 26.886445ms)
Oct 22 01:26:52.321: INFO: (0) /api/v1/namespaces/proxy-8293/services/proxy-service-27sd4:portname1/proxy/: foo (200; 27.094366ms)
Oct 22 01:26:52.324: INFO: (0) /api/v1/namespaces/proxy-8293/pods/https:proxy-service-27sd4-bwjhf:462/proxy/: tls qux (200; 30.125126ms)
Oct 22 01:26:52.324: INFO: (0) /api/v1/namespaces/proxy-8293/services/https:proxy-service-27sd4:tlsportname2/proxy/: tls qux (200; 30.429995ms)
Oct 22 01:26:52.325: INFO: (0) /api/v1/namespaces/proxy-8293/services/https:proxy-service-27sd4:tlsportname1/proxy/: tls baz (200; 31.087675ms)
Oct 22 01:26:52.331: INFO: (1) /api/v1/namespaces/proxy-8293/pods/http:proxy-service-27sd4-bwjhf:1080/proxy/: <a href="/api/v1/namespaces/proxy-8293/pods/http:proxy-service-27sd4-bwjhf:1080/proxy/rewriteme">... (200; 6.250149ms)
Oct 22 01:26:52.335: INFO: (1) /api/v1/namespaces/proxy-8293/pods/https:proxy-service-27sd4-bwjhf:460/proxy/: tls baz (200; 9.625077ms)
Oct 22 01:26:52.336: INFO: (1) /api/v1/namespaces/proxy-8293/pods/proxy-service-27sd4-bwjhf/proxy/: <a href="/api/v1/namespaces/proxy-8293/pods/proxy-service-27sd4-bwjhf/proxy/rewriteme">test</a> (200; 10.3539ms)
Oct 22 01:26:52.337: INFO: (1) /api/v1/namespaces/proxy-8293/pods/http:proxy-service-27sd4-bwjhf:160/proxy/: foo (200; 11.284569ms)
Oct 22 01:26:52.337: INFO: (1) /api/v1/namespaces/proxy-8293/pods/https:proxy-service-27sd4-bwjhf:443/proxy/: <a href="/api/v1/namespaces/proxy-8293/pods/https:proxy-service-27sd4-bwjhf:443/proxy/tlsrewritem... (200; 10.853666ms)
Oct 22 01:26:52.337: INFO: (1) /api/v1/namespaces/proxy-8293/pods/proxy-service-27sd4-bwjhf:162/proxy/: bar (200; 10.737029ms)
Oct 22 01:26:52.338: INFO: (1) /api/v1/namespaces/proxy-8293/pods/proxy-service-27sd4-bwjhf:1080/proxy/: <a href="/api/v1/namespaces/proxy-8293/pods/proxy-service-27sd4-bwjhf:1080/proxy/rewriteme">test<... (200; 12.253367ms)
Oct 22 01:26:52.338: INFO: (1) /api/v1/namespaces/proxy-8293/pods/proxy-service-27sd4-bwjhf:160/proxy/: foo (200; 11.992647ms)
Oct 22 01:26:52.339: INFO: (1) /api/v1/namespaces/proxy-8293/pods/http:proxy-service-27sd4-bwjhf:162/proxy/: bar (200; 13.091108ms)
Oct 22 01:26:52.339: INFO: (1) /api/v1/namespaces/proxy-8293/pods/https:proxy-service-27sd4-bwjhf:462/proxy/: tls qux (200; 13.967925ms)
Oct 22 01:26:52.346: INFO: (1) /api/v1/namespaces/proxy-8293/services/http:proxy-service-27sd4:portname1/proxy/: foo (200; 19.763293ms)
Oct 22 01:26:52.346: INFO: (1) /api/v1/namespaces/proxy-8293/services/http:proxy-service-27sd4:portname2/proxy/: bar (200; 21.310771ms)
Oct 22 01:26:52.347: INFO: (1) /api/v1/namespaces/proxy-8293/services/https:proxy-service-27sd4:tlsportname2/proxy/: tls qux (200; 20.48111ms)
Oct 22 01:26:52.348: INFO: (1) /api/v1/namespaces/proxy-8293/services/proxy-service-27sd4:portname2/proxy/: bar (200; 21.52818ms)
Oct 22 01:26:52.348: INFO: (1) /api/v1/namespaces/proxy-8293/services/https:proxy-service-27sd4:tlsportname1/proxy/: tls baz (200; 21.755931ms)
Oct 22 01:26:52.350: INFO: (1) /api/v1/namespaces/proxy-8293/services/proxy-service-27sd4:portname1/proxy/: foo (200; 24.357227ms)
Oct 22 01:26:52.372: INFO: (2) /api/v1/namespaces/proxy-8293/services/https:proxy-service-27sd4:tlsportname1/proxy/: tls baz (200; 20.94803ms)
Oct 22 01:26:52.373: INFO: (2) /api/v1/namespaces/proxy-8293/pods/https:proxy-service-27sd4-bwjhf:443/proxy/: <a href="/api/v1/namespaces/proxy-8293/pods/https:proxy-service-27sd4-bwjhf:443/proxy/tlsrewritem... (200; 22.056302ms)
Oct 22 01:26:52.373: INFO: (2) /api/v1/namespaces/proxy-8293/pods/proxy-service-27sd4-bwjhf:160/proxy/: foo (200; 21.961883ms)
Oct 22 01:26:52.373: INFO: (2) /api/v1/namespaces/proxy-8293/pods/proxy-service-27sd4-bwjhf:162/proxy/: bar (200; 22.428878ms)
Oct 22 01:26:52.373: INFO: (2) /api/v1/namespaces/proxy-8293/pods/proxy-service-27sd4-bwjhf/proxy/: <a href="/api/v1/namespaces/proxy-8293/pods/proxy-service-27sd4-bwjhf/proxy/rewriteme">test</a> (200; 22.892366ms)
Oct 22 01:26:52.374: INFO: (2) /api/v1/namespaces/proxy-8293/pods/https:proxy-service-27sd4-bwjhf:460/proxy/: tls baz (200; 22.730017ms)
Oct 22 01:26:52.374: INFO: (2) /api/v1/namespaces/proxy-8293/pods/https:proxy-service-27sd4-bwjhf:462/proxy/: tls qux (200; 22.582507ms)
Oct 22 01:26:52.374: INFO: (2) /api/v1/namespaces/proxy-8293/services/proxy-service-27sd4:portname1/proxy/: foo (200; 22.970854ms)
Oct 22 01:26:52.375: INFO: (2) /api/v1/namespaces/proxy-8293/services/http:proxy-service-27sd4:portname1/proxy/: foo (200; 24.072765ms)
Oct 22 01:26:52.375: INFO: (2) /api/v1/namespaces/proxy-8293/services/proxy-service-27sd4:portname2/proxy/: bar (200; 24.290114ms)
Oct 22 01:26:52.377: INFO: (2) /api/v1/namespaces/proxy-8293/services/http:proxy-service-27sd4:portname2/proxy/: bar (200; 26.187457ms)
Oct 22 01:26:52.379: INFO: (2) /api/v1/namespaces/proxy-8293/pods/http:proxy-service-27sd4-bwjhf:162/proxy/: bar (200; 27.969898ms)
Oct 22 01:26:52.379: INFO: (2) /api/v1/namespaces/proxy-8293/pods/http:proxy-service-27sd4-bwjhf:1080/proxy/: <a href="/api/v1/namespaces/proxy-8293/pods/http:proxy-service-27sd4-bwjhf:1080/proxy/rewriteme">... (200; 28.245245ms)
Oct 22 01:26:52.380: INFO: (2) /api/v1/namespaces/proxy-8293/pods/http:proxy-service-27sd4-bwjhf:160/proxy/: foo (200; 28.481535ms)
Oct 22 01:26:52.380: INFO: (2) /api/v1/namespaces/proxy-8293/pods/proxy-service-27sd4-bwjhf:1080/proxy/: <a href="/api/v1/namespaces/proxy-8293/pods/proxy-service-27sd4-bwjhf:1080/proxy/rewriteme">test<... (200; 29.669859ms)
Oct 22 01:26:52.382: INFO: (2) /api/v1/namespaces/proxy-8293/services/https:proxy-service-27sd4:tlsportname2/proxy/: tls qux (200; 31.515641ms)
Oct 22 01:26:52.393: INFO: (3) /api/v1/namespaces/proxy-8293/pods/proxy-service-27sd4-bwjhf:1080/proxy/: <a href="/api/v1/namespaces/proxy-8293/pods/proxy-service-27sd4-bwjhf:1080/proxy/rewriteme">test<... (200; 10.11852ms)
Oct 22 01:26:52.394: INFO: (3) /api/v1/namespaces/proxy-8293/pods/https:proxy-service-27sd4-bwjhf:460/proxy/: tls baz (200; 10.712492ms)
Oct 22 01:26:52.394: INFO: (3) /api/v1/namespaces/proxy-8293/pods/https:proxy-service-27sd4-bwjhf:462/proxy/: tls qux (200; 11.836805ms)
Oct 22 01:26:52.395: INFO: (3) /api/v1/namespaces/proxy-8293/pods/http:proxy-service-27sd4-bwjhf:162/proxy/: bar (200; 11.674407ms)
Oct 22 01:26:52.395: INFO: (3) /api/v1/namespaces/proxy-8293/pods/http:proxy-service-27sd4-bwjhf:1080/proxy/: <a href="/api/v1/namespaces/proxy-8293/pods/http:proxy-service-27sd4-bwjhf:1080/proxy/rewriteme">... (200; 11.604783ms)
Oct 22 01:26:52.395: INFO: (3) /api/v1/namespaces/proxy-8293/pods/https:proxy-service-27sd4-bwjhf:443/proxy/: <a href="/api/v1/namespaces/proxy-8293/pods/https:proxy-service-27sd4-bwjhf:443/proxy/tlsrewritem... (200; 11.59007ms)
Oct 22 01:26:52.395: INFO: (3) /api/v1/namespaces/proxy-8293/pods/proxy-service-27sd4-bwjhf:160/proxy/: foo (200; 11.58947ms)
Oct 22 01:26:52.395: INFO: (3) /api/v1/namespaces/proxy-8293/pods/proxy-service-27sd4-bwjhf/proxy/: <a href="/api/v1/namespaces/proxy-8293/pods/proxy-service-27sd4-bwjhf/proxy/rewriteme">test</a> (200; 11.685377ms)
Oct 22 01:26:52.395: INFO: (3) /api/v1/namespaces/proxy-8293/pods/http:proxy-service-27sd4-bwjhf:160/proxy/: foo (200; 11.565051ms)
Oct 22 01:26:52.395: INFO: (3) /api/v1/namespaces/proxy-8293/pods/proxy-service-27sd4-bwjhf:162/proxy/: bar (200; 12.515186ms)
Oct 22 01:26:52.399: INFO: (3) /api/v1/namespaces/proxy-8293/services/http:proxy-service-27sd4:portname1/proxy/: foo (200; 15.621166ms)
Oct 22 01:26:52.399: INFO: (3) /api/v1/namespaces/proxy-8293/services/proxy-service-27sd4:portname2/proxy/: bar (200; 16.324645ms)
Oct 22 01:26:52.399: INFO: (3) /api/v1/namespaces/proxy-8293/services/https:proxy-service-27sd4:tlsportname2/proxy/: tls qux (200; 16.312094ms)
Oct 22 01:26:52.399: INFO: (3) /api/v1/namespaces/proxy-8293/services/http:proxy-service-27sd4:portname2/proxy/: bar (200; 16.203174ms)
Oct 22 01:26:52.399: INFO: (3) /api/v1/namespaces/proxy-8293/services/proxy-service-27sd4:portname1/proxy/: foo (200; 16.233797ms)
Oct 22 01:26:52.400: INFO: (3) /api/v1/namespaces/proxy-8293/services/https:proxy-service-27sd4:tlsportname1/proxy/: tls baz (200; 17.540782ms)
Oct 22 01:26:52.405: INFO: (4) /api/v1/namespaces/proxy-8293/pods/http:proxy-service-27sd4-bwjhf:162/proxy/: bar (200; 4.986198ms)
Oct 22 01:26:52.413: INFO: (4) /api/v1/namespaces/proxy-8293/pods/proxy-service-27sd4-bwjhf:1080/proxy/: <a href="/api/v1/namespaces/proxy-8293/pods/proxy-service-27sd4-bwjhf:1080/proxy/rewriteme">test<... (200; 11.839703ms)
Oct 22 01:26:52.413: INFO: (4) /api/v1/namespaces/proxy-8293/pods/https:proxy-service-27sd4-bwjhf:462/proxy/: tls qux (200; 11.820701ms)
Oct 22 01:26:52.414: INFO: (4) /api/v1/namespaces/proxy-8293/pods/https:proxy-service-27sd4-bwjhf:460/proxy/: tls baz (200; 12.871954ms)
Oct 22 01:26:52.414: INFO: (4) /api/v1/namespaces/proxy-8293/pods/proxy-service-27sd4-bwjhf:162/proxy/: bar (200; 12.175612ms)
Oct 22 01:26:52.414: INFO: (4) /api/v1/namespaces/proxy-8293/pods/http:proxy-service-27sd4-bwjhf:1080/proxy/: <a href="/api/v1/namespaces/proxy-8293/pods/http:proxy-service-27sd4-bwjhf:1080/proxy/rewriteme">... (200; 11.693786ms)
Oct 22 01:26:52.414: INFO: (4) /api/v1/namespaces/proxy-8293/pods/http:proxy-service-27sd4-bwjhf:160/proxy/: foo (200; 13.149192ms)
Oct 22 01:26:52.415: INFO: (4) /api/v1/namespaces/proxy-8293/pods/proxy-service-27sd4-bwjhf:160/proxy/: foo (200; 12.117988ms)
Oct 22 01:26:52.415: INFO: (4) /api/v1/namespaces/proxy-8293/pods/proxy-service-27sd4-bwjhf/proxy/: <a href="/api/v1/namespaces/proxy-8293/pods/proxy-service-27sd4-bwjhf/proxy/rewriteme">test</a> (200; 13.330262ms)
Oct 22 01:26:52.416: INFO: (4) /api/v1/namespaces/proxy-8293/pods/https:proxy-service-27sd4-bwjhf:443/proxy/: <a href="/api/v1/namespaces/proxy-8293/pods/https:proxy-service-27sd4-bwjhf:443/proxy/tlsrewritem... (200; 13.603308ms)
Oct 22 01:26:52.416: INFO: (4) /api/v1/namespaces/proxy-8293/services/proxy-service-27sd4:portname2/proxy/: bar (200; 14.463383ms)
Oct 22 01:26:52.418: INFO: (4) /api/v1/namespaces/proxy-8293/services/https:proxy-service-27sd4:tlsportname1/proxy/: tls baz (200; 15.288656ms)
Oct 22 01:26:52.418: INFO: (4) /api/v1/namespaces/proxy-8293/services/http:proxy-service-27sd4:portname2/proxy/: bar (200; 17.22591ms)
Oct 22 01:26:52.418: INFO: (4) /api/v1/namespaces/proxy-8293/services/proxy-service-27sd4:portname1/proxy/: foo (200; 17.490263ms)
Oct 22 01:26:52.418: INFO: (4) /api/v1/namespaces/proxy-8293/services/https:proxy-service-27sd4:tlsportname2/proxy/: tls qux (200; 16.660894ms)
Oct 22 01:26:52.419: INFO: (4) /api/v1/namespaces/proxy-8293/services/http:proxy-service-27sd4:portname1/proxy/: foo (200; 16.234807ms)
Oct 22 01:26:52.423: INFO: (5) /api/v1/namespaces/proxy-8293/pods/https:proxy-service-27sd4-bwjhf:462/proxy/: tls qux (200; 4.382226ms)
Oct 22 01:26:52.432: INFO: (5) /api/v1/namespaces/proxy-8293/pods/http:proxy-service-27sd4-bwjhf:160/proxy/: foo (200; 10.589616ms)
Oct 22 01:26:52.435: INFO: (5) /api/v1/namespaces/proxy-8293/pods/proxy-service-27sd4-bwjhf:1080/proxy/: <a href="/api/v1/namespaces/proxy-8293/pods/proxy-service-27sd4-bwjhf:1080/proxy/rewriteme">test<... (200; 14.117288ms)
Oct 22 01:26:52.435: INFO: (5) /api/v1/namespaces/proxy-8293/pods/proxy-service-27sd4-bwjhf:162/proxy/: bar (200; 15.596691ms)
Oct 22 01:26:52.435: INFO: (5) /api/v1/namespaces/proxy-8293/pods/http:proxy-service-27sd4-bwjhf:1080/proxy/: <a href="/api/v1/namespaces/proxy-8293/pods/http:proxy-service-27sd4-bwjhf:1080/proxy/rewriteme">... (200; 14.954145ms)
Oct 22 01:26:52.435: INFO: (5) /api/v1/namespaces/proxy-8293/pods/http:proxy-service-27sd4-bwjhf:162/proxy/: bar (200; 14.708477ms)
Oct 22 01:26:52.436: INFO: (5) /api/v1/namespaces/proxy-8293/pods/proxy-service-27sd4-bwjhf/proxy/: <a href="/api/v1/namespaces/proxy-8293/pods/proxy-service-27sd4-bwjhf/proxy/rewriteme">test</a> (200; 16.61978ms)
Oct 22 01:26:52.436: INFO: (5) /api/v1/namespaces/proxy-8293/pods/https:proxy-service-27sd4-bwjhf:460/proxy/: tls baz (200; 14.757661ms)
Oct 22 01:26:52.436: INFO: (5) /api/v1/namespaces/proxy-8293/services/proxy-service-27sd4:portname1/proxy/: foo (200; 15.262199ms)
Oct 22 01:26:52.436: INFO: (5) /api/v1/namespaces/proxy-8293/pods/https:proxy-service-27sd4-bwjhf:443/proxy/: <a href="/api/v1/namespaces/proxy-8293/pods/https:proxy-service-27sd4-bwjhf:443/proxy/tlsrewritem... (200; 16.409173ms)
Oct 22 01:26:52.436: INFO: (5) /api/v1/namespaces/proxy-8293/services/https:proxy-service-27sd4:tlsportname2/proxy/: tls qux (200; 16.89228ms)
Oct 22 01:26:52.436: INFO: (5) /api/v1/namespaces/proxy-8293/services/proxy-service-27sd4:portname2/proxy/: bar (200; 17.096626ms)
Oct 22 01:26:52.436: INFO: (5) /api/v1/namespaces/proxy-8293/services/https:proxy-service-27sd4:tlsportname1/proxy/: tls baz (200; 16.100091ms)
Oct 22 01:26:52.436: INFO: (5) /api/v1/namespaces/proxy-8293/services/http:proxy-service-27sd4:portname2/proxy/: bar (200; 15.740504ms)
Oct 22 01:26:52.436: INFO: (5) /api/v1/namespaces/proxy-8293/pods/proxy-service-27sd4-bwjhf:160/proxy/: foo (200; 16.087132ms)
Oct 22 01:26:52.436: INFO: (5) /api/v1/namespaces/proxy-8293/services/http:proxy-service-27sd4:portname1/proxy/: foo (200; 16.665373ms)
Oct 22 01:26:52.443: INFO: (6) /api/v1/namespaces/proxy-8293/pods/https:proxy-service-27sd4-bwjhf:462/proxy/: tls qux (200; 6.494849ms)
Oct 22 01:26:52.449: INFO: (6) /api/v1/namespaces/proxy-8293/pods/proxy-service-27sd4-bwjhf:160/proxy/: foo (200; 11.409467ms)
Oct 22 01:26:52.450: INFO: (6) /api/v1/namespaces/proxy-8293/pods/http:proxy-service-27sd4-bwjhf:162/proxy/: bar (200; 11.708803ms)
Oct 22 01:26:52.450: INFO: (6) /api/v1/namespaces/proxy-8293/pods/proxy-service-27sd4-bwjhf:162/proxy/: bar (200; 12.729428ms)
Oct 22 01:26:52.450: INFO: (6) /api/v1/namespaces/proxy-8293/pods/https:proxy-service-27sd4-bwjhf:443/proxy/: <a href="/api/v1/namespaces/proxy-8293/pods/https:proxy-service-27sd4-bwjhf:443/proxy/tlsrewritem... (200; 12.715995ms)
Oct 22 01:26:52.450: INFO: (6) /api/v1/namespaces/proxy-8293/pods/proxy-service-27sd4-bwjhf:1080/proxy/: <a href="/api/v1/namespaces/proxy-8293/pods/proxy-service-27sd4-bwjhf:1080/proxy/rewriteme">test<... (200; 11.687302ms)
Oct 22 01:26:52.451: INFO: (6) /api/v1/namespaces/proxy-8293/pods/http:proxy-service-27sd4-bwjhf:160/proxy/: foo (200; 12.019064ms)
Oct 22 01:26:52.451: INFO: (6) /api/v1/namespaces/proxy-8293/pods/proxy-service-27sd4-bwjhf/proxy/: <a href="/api/v1/namespaces/proxy-8293/pods/proxy-service-27sd4-bwjhf/proxy/rewriteme">test</a> (200; 13.627026ms)
Oct 22 01:26:52.451: INFO: (6) /api/v1/namespaces/proxy-8293/pods/https:proxy-service-27sd4-bwjhf:460/proxy/: tls baz (200; 11.941001ms)
Oct 22 01:26:52.451: INFO: (6) /api/v1/namespaces/proxy-8293/pods/http:proxy-service-27sd4-bwjhf:1080/proxy/: <a href="/api/v1/namespaces/proxy-8293/pods/http:proxy-service-27sd4-bwjhf:1080/proxy/rewriteme">... (200; 12.948038ms)
Oct 22 01:26:52.455: INFO: (6) /api/v1/namespaces/proxy-8293/services/http:proxy-service-27sd4:portname1/proxy/: foo (200; 17.409664ms)
Oct 22 01:26:52.455: INFO: (6) /api/v1/namespaces/proxy-8293/services/http:proxy-service-27sd4:portname2/proxy/: bar (200; 16.749234ms)
Oct 22 01:26:52.455: INFO: (6) /api/v1/namespaces/proxy-8293/services/proxy-service-27sd4:portname1/proxy/: foo (200; 16.742593ms)
Oct 22 01:26:52.455: INFO: (6) /api/v1/namespaces/proxy-8293/services/https:proxy-service-27sd4:tlsportname1/proxy/: tls baz (200; 17.485631ms)
Oct 22 01:26:52.455: INFO: (6) /api/v1/namespaces/proxy-8293/services/https:proxy-service-27sd4:tlsportname2/proxy/: tls qux (200; 18.339669ms)
Oct 22 01:26:52.456: INFO: (6) /api/v1/namespaces/proxy-8293/services/proxy-service-27sd4:portname2/proxy/: bar (200; 18.883666ms)
Oct 22 01:26:52.465: INFO: (7) /api/v1/namespaces/proxy-8293/pods/proxy-service-27sd4-bwjhf:160/proxy/: foo (200; 9.122735ms)
Oct 22 01:26:52.466: INFO: (7) /api/v1/namespaces/proxy-8293/pods/http:proxy-service-27sd4-bwjhf:160/proxy/: foo (200; 10.496201ms)
Oct 22 01:26:52.466: INFO: (7) /api/v1/namespaces/proxy-8293/pods/http:proxy-service-27sd4-bwjhf:162/proxy/: bar (200; 9.922803ms)
Oct 22 01:26:52.467: INFO: (7) /api/v1/namespaces/proxy-8293/pods/proxy-service-27sd4-bwjhf:1080/proxy/: <a href="/api/v1/namespaces/proxy-8293/pods/proxy-service-27sd4-bwjhf:1080/proxy/rewriteme">test<... (200; 10.227509ms)
Oct 22 01:26:52.467: INFO: (7) /api/v1/namespaces/proxy-8293/pods/https:proxy-service-27sd4-bwjhf:460/proxy/: tls baz (200; 11.15654ms)
Oct 22 01:26:52.467: INFO: (7) /api/v1/namespaces/proxy-8293/pods/https:proxy-service-27sd4-bwjhf:443/proxy/: <a href="/api/v1/namespaces/proxy-8293/pods/https:proxy-service-27sd4-bwjhf:443/proxy/tlsrewritem... (200; 11.255622ms)
Oct 22 01:26:52.468: INFO: (7) /api/v1/namespaces/proxy-8293/pods/http:proxy-service-27sd4-bwjhf:1080/proxy/: <a href="/api/v1/namespaces/proxy-8293/pods/http:proxy-service-27sd4-bwjhf:1080/proxy/rewriteme">... (200; 11.558209ms)
Oct 22 01:26:52.468: INFO: (7) /api/v1/namespaces/proxy-8293/pods/proxy-service-27sd4-bwjhf:162/proxy/: bar (200; 12.129956ms)
Oct 22 01:26:52.469: INFO: (7) /api/v1/namespaces/proxy-8293/pods/proxy-service-27sd4-bwjhf/proxy/: <a href="/api/v1/namespaces/proxy-8293/pods/proxy-service-27sd4-bwjhf/proxy/rewriteme">test</a> (200; 12.724964ms)
Oct 22 01:26:52.469: INFO: (7) /api/v1/namespaces/proxy-8293/pods/https:proxy-service-27sd4-bwjhf:462/proxy/: tls qux (200; 12.924461ms)
Oct 22 01:26:52.469: INFO: (7) /api/v1/namespaces/proxy-8293/services/proxy-service-27sd4:portname2/proxy/: bar (200; 13.20275ms)
Oct 22 01:26:52.473: INFO: (7) /api/v1/namespaces/proxy-8293/services/https:proxy-service-27sd4:tlsportname1/proxy/: tls baz (200; 16.317456ms)
Oct 22 01:26:52.473: INFO: (7) /api/v1/namespaces/proxy-8293/services/http:proxy-service-27sd4:portname1/proxy/: foo (200; 16.831973ms)
Oct 22 01:26:52.473: INFO: (7) /api/v1/namespaces/proxy-8293/services/proxy-service-27sd4:portname1/proxy/: foo (200; 17.089159ms)
Oct 22 01:26:52.473: INFO: (7) /api/v1/namespaces/proxy-8293/services/https:proxy-service-27sd4:tlsportname2/proxy/: tls qux (200; 17.047186ms)
Oct 22 01:26:52.473: INFO: (7) /api/v1/namespaces/proxy-8293/services/http:proxy-service-27sd4:portname2/proxy/: bar (200; 16.594147ms)
Oct 22 01:26:52.484: INFO: (8) /api/v1/namespaces/proxy-8293/pods/https:proxy-service-27sd4-bwjhf:462/proxy/: tls qux (200; 10.511045ms)
Oct 22 01:26:52.487: INFO: (8) /api/v1/namespaces/proxy-8293/pods/proxy-service-27sd4-bwjhf:160/proxy/: foo (200; 12.626075ms)
Oct 22 01:26:52.487: INFO: (8) /api/v1/namespaces/proxy-8293/pods/proxy-service-27sd4-bwjhf:1080/proxy/: <a href="/api/v1/namespaces/proxy-8293/pods/proxy-service-27sd4-bwjhf:1080/proxy/rewriteme">test<... (200; 13.730743ms)
Oct 22 01:26:52.487: INFO: (8) /api/v1/namespaces/proxy-8293/pods/https:proxy-service-27sd4-bwjhf:443/proxy/: <a href="/api/v1/namespaces/proxy-8293/pods/https:proxy-service-27sd4-bwjhf:443/proxy/tlsrewritem... (200; 13.109286ms)
Oct 22 01:26:52.487: INFO: (8) /api/v1/namespaces/proxy-8293/pods/proxy-service-27sd4-bwjhf/proxy/: <a href="/api/v1/namespaces/proxy-8293/pods/proxy-service-27sd4-bwjhf/proxy/rewriteme">test</a> (200; 13.758722ms)
Oct 22 01:26:52.487: INFO: (8) /api/v1/namespaces/proxy-8293/pods/proxy-service-27sd4-bwjhf:162/proxy/: bar (200; 13.412183ms)
Oct 22 01:26:52.487: INFO: (8) /api/v1/namespaces/proxy-8293/services/https:proxy-service-27sd4:tlsportname2/proxy/: tls qux (200; 13.572059ms)
Oct 22 01:26:52.488: INFO: (8) /api/v1/namespaces/proxy-8293/services/http:proxy-service-27sd4:portname2/proxy/: bar (200; 14.264164ms)
Oct 22 01:26:52.488: INFO: (8) /api/v1/namespaces/proxy-8293/pods/http:proxy-service-27sd4-bwjhf:160/proxy/: foo (200; 14.1277ms)
Oct 22 01:26:52.488: INFO: (8) /api/v1/namespaces/proxy-8293/services/proxy-service-27sd4:portname2/proxy/: bar (200; 14.084794ms)
Oct 22 01:26:52.488: INFO: (8) /api/v1/namespaces/proxy-8293/pods/http:proxy-service-27sd4-bwjhf:1080/proxy/: <a href="/api/v1/namespaces/proxy-8293/pods/http:proxy-service-27sd4-bwjhf:1080/proxy/rewriteme">... (200; 14.342175ms)
Oct 22 01:26:52.488: INFO: (8) /api/v1/namespaces/proxy-8293/pods/https:proxy-service-27sd4-bwjhf:460/proxy/: tls baz (200; 14.849226ms)
Oct 22 01:26:52.488: INFO: (8) /api/v1/namespaces/proxy-8293/pods/http:proxy-service-27sd4-bwjhf:162/proxy/: bar (200; 15.297994ms)
Oct 22 01:26:52.489: INFO: (8) /api/v1/namespaces/proxy-8293/services/proxy-service-27sd4:portname1/proxy/: foo (200; 15.685691ms)
Oct 22 01:26:52.491: INFO: (8) /api/v1/namespaces/proxy-8293/services/http:proxy-service-27sd4:portname1/proxy/: foo (200; 16.974191ms)
Oct 22 01:26:52.491: INFO: (8) /api/v1/namespaces/proxy-8293/services/https:proxy-service-27sd4:tlsportname1/proxy/: tls baz (200; 17.295344ms)
Oct 22 01:26:52.499: INFO: (9) /api/v1/namespaces/proxy-8293/pods/https:proxy-service-27sd4-bwjhf:462/proxy/: tls qux (200; 8.064141ms)
Oct 22 01:26:52.501: INFO: (9) /api/v1/namespaces/proxy-8293/pods/proxy-service-27sd4-bwjhf:162/proxy/: bar (200; 9.137538ms)
Oct 22 01:26:52.501: INFO: (9) /api/v1/namespaces/proxy-8293/pods/http:proxy-service-27sd4-bwjhf:1080/proxy/: <a href="/api/v1/namespaces/proxy-8293/pods/http:proxy-service-27sd4-bwjhf:1080/proxy/rewriteme">... (200; 8.542011ms)
Oct 22 01:26:52.501: INFO: (9) /api/v1/namespaces/proxy-8293/pods/https:proxy-service-27sd4-bwjhf:443/proxy/: <a href="/api/v1/namespaces/proxy-8293/pods/https:proxy-service-27sd4-bwjhf:443/proxy/tlsrewritem... (200; 9.093167ms)
Oct 22 01:26:52.503: INFO: (9) /api/v1/namespaces/proxy-8293/services/https:proxy-service-27sd4:tlsportname2/proxy/: tls qux (200; 11.369221ms)
Oct 22 01:26:52.503: INFO: (9) /api/v1/namespaces/proxy-8293/pods/http:proxy-service-27sd4-bwjhf:160/proxy/: foo (200; 9.904071ms)
Oct 22 01:26:52.503: INFO: (9) /api/v1/namespaces/proxy-8293/pods/proxy-service-27sd4-bwjhf:1080/proxy/: <a href="/api/v1/namespaces/proxy-8293/pods/proxy-service-27sd4-bwjhf:1080/proxy/rewriteme">test<... (200; 10.837647ms)
Oct 22 01:26:52.504: INFO: (9) /api/v1/namespaces/proxy-8293/pods/proxy-service-27sd4-bwjhf/proxy/: <a href="/api/v1/namespaces/proxy-8293/pods/proxy-service-27sd4-bwjhf/proxy/rewriteme">test</a> (200; 11.928586ms)
Oct 22 01:26:52.504: INFO: (9) /api/v1/namespaces/proxy-8293/pods/https:proxy-service-27sd4-bwjhf:460/proxy/: tls baz (200; 10.607666ms)
Oct 22 01:26:52.504: INFO: (9) /api/v1/namespaces/proxy-8293/pods/http:proxy-service-27sd4-bwjhf:162/proxy/: bar (200; 10.843908ms)
Oct 22 01:26:52.504: INFO: (9) /api/v1/namespaces/proxy-8293/pods/proxy-service-27sd4-bwjhf:160/proxy/: foo (200; 10.976714ms)
Oct 22 01:26:52.504: INFO: (9) /api/v1/namespaces/proxy-8293/services/proxy-service-27sd4:portname2/proxy/: bar (200; 12.574371ms)
Oct 22 01:26:52.507: INFO: (9) /api/v1/namespaces/proxy-8293/services/proxy-service-27sd4:portname1/proxy/: foo (200; 14.647249ms)
Oct 22 01:26:52.507: INFO: (9) /api/v1/namespaces/proxy-8293/services/http:proxy-service-27sd4:portname1/proxy/: foo (200; 15.2046ms)
Oct 22 01:26:52.508: INFO: (9) /api/v1/namespaces/proxy-8293/services/https:proxy-service-27sd4:tlsportname1/proxy/: tls baz (200; 15.57375ms)
Oct 22 01:26:52.508: INFO: (9) /api/v1/namespaces/proxy-8293/services/http:proxy-service-27sd4:portname2/proxy/: bar (200; 15.02471ms)
Oct 22 01:26:52.517: INFO: (10) /api/v1/namespaces/proxy-8293/pods/https:proxy-service-27sd4-bwjhf:460/proxy/: tls baz (200; 8.859746ms)
Oct 22 01:26:52.517: INFO: (10) /api/v1/namespaces/proxy-8293/pods/https:proxy-service-27sd4-bwjhf:443/proxy/: <a href="/api/v1/namespaces/proxy-8293/pods/https:proxy-service-27sd4-bwjhf:443/proxy/tlsrewritem... (200; 8.662992ms)
Oct 22 01:26:52.520: INFO: (10) /api/v1/namespaces/proxy-8293/pods/http:proxy-service-27sd4-bwjhf:1080/proxy/: <a href="/api/v1/namespaces/proxy-8293/pods/http:proxy-service-27sd4-bwjhf:1080/proxy/rewriteme">... (200; 11.031242ms)
Oct 22 01:26:52.520: INFO: (10) /api/v1/namespaces/proxy-8293/pods/http:proxy-service-27sd4-bwjhf:160/proxy/: foo (200; 11.412141ms)
Oct 22 01:26:52.521: INFO: (10) /api/v1/namespaces/proxy-8293/pods/proxy-service-27sd4-bwjhf/proxy/: <a href="/api/v1/namespaces/proxy-8293/pods/proxy-service-27sd4-bwjhf/proxy/rewriteme">test</a> (200; 11.490071ms)
Oct 22 01:26:52.521: INFO: (10) /api/v1/namespaces/proxy-8293/pods/http:proxy-service-27sd4-bwjhf:162/proxy/: bar (200; 12.079117ms)
Oct 22 01:26:52.523: INFO: (10) /api/v1/namespaces/proxy-8293/pods/https:proxy-service-27sd4-bwjhf:462/proxy/: tls qux (200; 13.868135ms)
Oct 22 01:26:52.523: INFO: (10) /api/v1/namespaces/proxy-8293/pods/proxy-service-27sd4-bwjhf:162/proxy/: bar (200; 13.565802ms)
Oct 22 01:26:52.523: INFO: (10) /api/v1/namespaces/proxy-8293/pods/proxy-service-27sd4-bwjhf:1080/proxy/: <a href="/api/v1/namespaces/proxy-8293/pods/proxy-service-27sd4-bwjhf:1080/proxy/rewriteme">test<... (200; 14.171277ms)
Oct 22 01:26:52.523: INFO: (10) /api/v1/namespaces/proxy-8293/pods/proxy-service-27sd4-bwjhf:160/proxy/: foo (200; 14.439074ms)
Oct 22 01:26:52.523: INFO: (10) /api/v1/namespaces/proxy-8293/services/https:proxy-service-27sd4:tlsportname2/proxy/: tls qux (200; 14.897336ms)
Oct 22 01:26:52.524: INFO: (10) /api/v1/namespaces/proxy-8293/services/http:proxy-service-27sd4:portname1/proxy/: foo (200; 14.372564ms)
Oct 22 01:26:52.524: INFO: (10) /api/v1/namespaces/proxy-8293/services/proxy-service-27sd4:portname2/proxy/: bar (200; 15.382709ms)
Oct 22 01:26:52.524: INFO: (10) /api/v1/namespaces/proxy-8293/services/proxy-service-27sd4:portname1/proxy/: foo (200; 15.443192ms)
Oct 22 01:26:52.525: INFO: (10) /api/v1/namespaces/proxy-8293/services/http:proxy-service-27sd4:portname2/proxy/: bar (200; 16.232428ms)
Oct 22 01:26:52.525: INFO: (10) /api/v1/namespaces/proxy-8293/services/https:proxy-service-27sd4:tlsportname1/proxy/: tls baz (200; 15.839785ms)
Oct 22 01:26:52.536: INFO: (11) /api/v1/namespaces/proxy-8293/pods/proxy-service-27sd4-bwjhf:160/proxy/: foo (200; 10.551541ms)
Oct 22 01:26:52.536: INFO: (11) /api/v1/namespaces/proxy-8293/pods/https:proxy-service-27sd4-bwjhf:462/proxy/: tls qux (200; 10.462695ms)
Oct 22 01:26:52.539: INFO: (11) /api/v1/namespaces/proxy-8293/pods/proxy-service-27sd4-bwjhf:162/proxy/: bar (200; 12.709518ms)
Oct 22 01:26:52.539: INFO: (11) /api/v1/namespaces/proxy-8293/pods/https:proxy-service-27sd4-bwjhf:460/proxy/: tls baz (200; 12.817114ms)
Oct 22 01:26:52.539: INFO: (11) /api/v1/namespaces/proxy-8293/pods/http:proxy-service-27sd4-bwjhf:162/proxy/: bar (200; 12.716693ms)
Oct 22 01:26:52.539: INFO: (11) /api/v1/namespaces/proxy-8293/pods/http:proxy-service-27sd4-bwjhf:1080/proxy/: <a href="/api/v1/namespaces/proxy-8293/pods/http:proxy-service-27sd4-bwjhf:1080/proxy/rewriteme">... (200; 13.473602ms)
Oct 22 01:26:52.539: INFO: (11) /api/v1/namespaces/proxy-8293/pods/proxy-service-27sd4-bwjhf:1080/proxy/: <a href="/api/v1/namespaces/proxy-8293/pods/proxy-service-27sd4-bwjhf:1080/proxy/rewriteme">test<... (200; 13.050454ms)
Oct 22 01:26:52.539: INFO: (11) /api/v1/namespaces/proxy-8293/pods/http:proxy-service-27sd4-bwjhf:160/proxy/: foo (200; 12.983747ms)
Oct 22 01:26:52.541: INFO: (11) /api/v1/namespaces/proxy-8293/pods/proxy-service-27sd4-bwjhf/proxy/: <a href="/api/v1/namespaces/proxy-8293/pods/proxy-service-27sd4-bwjhf/proxy/rewriteme">test</a> (200; 15.249537ms)
Oct 22 01:26:52.542: INFO: (11) /api/v1/namespaces/proxy-8293/pods/https:proxy-service-27sd4-bwjhf:443/proxy/: <a href="/api/v1/namespaces/proxy-8293/pods/https:proxy-service-27sd4-bwjhf:443/proxy/tlsrewritem... (200; 15.896521ms)
Oct 22 01:26:52.543: INFO: (11) /api/v1/namespaces/proxy-8293/services/http:proxy-service-27sd4:portname2/proxy/: bar (200; 17.615715ms)
Oct 22 01:26:52.543: INFO: (11) /api/v1/namespaces/proxy-8293/services/http:proxy-service-27sd4:portname1/proxy/: foo (200; 17.455749ms)
Oct 22 01:26:52.544: INFO: (11) /api/v1/namespaces/proxy-8293/services/https:proxy-service-27sd4:tlsportname1/proxy/: tls baz (200; 17.888382ms)
Oct 22 01:26:52.544: INFO: (11) /api/v1/namespaces/proxy-8293/services/proxy-service-27sd4:portname1/proxy/: foo (200; 18.094745ms)
Oct 22 01:26:52.544: INFO: (11) /api/v1/namespaces/proxy-8293/services/proxy-service-27sd4:portname2/proxy/: bar (200; 17.842926ms)
Oct 22 01:26:52.545: INFO: (11) /api/v1/namespaces/proxy-8293/services/https:proxy-service-27sd4:tlsportname2/proxy/: tls qux (200; 20.210235ms)
Oct 22 01:26:52.559: INFO: (12) /api/v1/namespaces/proxy-8293/pods/http:proxy-service-27sd4-bwjhf:160/proxy/: foo (200; 12.383386ms)
Oct 22 01:26:52.559: INFO: (12) /api/v1/namespaces/proxy-8293/pods/http:proxy-service-27sd4-bwjhf:1080/proxy/: <a href="/api/v1/namespaces/proxy-8293/pods/http:proxy-service-27sd4-bwjhf:1080/proxy/rewriteme">... (200; 12.253479ms)
Oct 22 01:26:52.559: INFO: (12) /api/v1/namespaces/proxy-8293/pods/proxy-service-27sd4-bwjhf:160/proxy/: foo (200; 12.287442ms)
Oct 22 01:26:52.567: INFO: (12) /api/v1/namespaces/proxy-8293/services/http:proxy-service-27sd4:portname2/proxy/: bar (200; 20.642543ms)
Oct 22 01:26:52.567: INFO: (12) /api/v1/namespaces/proxy-8293/services/https:proxy-service-27sd4:tlsportname1/proxy/: tls baz (200; 21.515643ms)
Oct 22 01:26:52.568: INFO: (12) /api/v1/namespaces/proxy-8293/pods/proxy-service-27sd4-bwjhf/proxy/: <a href="/api/v1/namespaces/proxy-8293/pods/proxy-service-27sd4-bwjhf/proxy/rewriteme">test</a> (200; 21.960779ms)
Oct 22 01:26:52.568: INFO: (12) /api/v1/namespaces/proxy-8293/services/http:proxy-service-27sd4:portname1/proxy/: foo (200; 22.247882ms)
Oct 22 01:26:52.568: INFO: (12) /api/v1/namespaces/proxy-8293/pods/https:proxy-service-27sd4-bwjhf:460/proxy/: tls baz (200; 22.116225ms)
Oct 22 01:26:52.568: INFO: (12) /api/v1/namespaces/proxy-8293/pods/https:proxy-service-27sd4-bwjhf:462/proxy/: tls qux (200; 22.116149ms)
Oct 22 01:26:52.568: INFO: (12) /api/v1/namespaces/proxy-8293/services/proxy-service-27sd4:portname2/proxy/: bar (200; 21.940688ms)
Oct 22 01:26:52.568: INFO: (12) /api/v1/namespaces/proxy-8293/services/https:proxy-service-27sd4:tlsportname2/proxy/: tls qux (200; 22.075101ms)
Oct 22 01:26:52.568: INFO: (12) /api/v1/namespaces/proxy-8293/pods/proxy-service-27sd4-bwjhf:1080/proxy/: <a href="/api/v1/namespaces/proxy-8293/pods/proxy-service-27sd4-bwjhf:1080/proxy/rewriteme">test<... (200; 22.8556ms)
Oct 22 01:26:52.568: INFO: (12) /api/v1/namespaces/proxy-8293/services/proxy-service-27sd4:portname1/proxy/: foo (200; 22.209818ms)
Oct 22 01:26:52.568: INFO: (12) /api/v1/namespaces/proxy-8293/pods/http:proxy-service-27sd4-bwjhf:162/proxy/: bar (200; 22.536273ms)
Oct 22 01:26:52.568: INFO: (12) /api/v1/namespaces/proxy-8293/pods/proxy-service-27sd4-bwjhf:162/proxy/: bar (200; 22.144675ms)
Oct 22 01:26:52.569: INFO: (12) /api/v1/namespaces/proxy-8293/pods/https:proxy-service-27sd4-bwjhf:443/proxy/: <a href="/api/v1/namespaces/proxy-8293/pods/https:proxy-service-27sd4-bwjhf:443/proxy/tlsrewritem... (200; 22.293168ms)
Oct 22 01:26:52.574: INFO: (13) /api/v1/namespaces/proxy-8293/pods/proxy-service-27sd4-bwjhf:160/proxy/: foo (200; 5.525162ms)
Oct 22 01:26:52.575: INFO: (13) /api/v1/namespaces/proxy-8293/pods/https:proxy-service-27sd4-bwjhf:462/proxy/: tls qux (200; 6.041587ms)
Oct 22 01:26:52.580: INFO: (13) /api/v1/namespaces/proxy-8293/pods/proxy-service-27sd4-bwjhf/proxy/: <a href="/api/v1/namespaces/proxy-8293/pods/proxy-service-27sd4-bwjhf/proxy/rewriteme">test</a> (200; 9.538771ms)
Oct 22 01:26:52.580: INFO: (13) /api/v1/namespaces/proxy-8293/pods/https:proxy-service-27sd4-bwjhf:460/proxy/: tls baz (200; 10.783394ms)
Oct 22 01:26:52.581: INFO: (13) /api/v1/namespaces/proxy-8293/pods/http:proxy-service-27sd4-bwjhf:162/proxy/: bar (200; 10.398391ms)
Oct 22 01:26:52.581: INFO: (13) /api/v1/namespaces/proxy-8293/pods/proxy-service-27sd4-bwjhf:1080/proxy/: <a href="/api/v1/namespaces/proxy-8293/pods/proxy-service-27sd4-bwjhf:1080/proxy/rewriteme">test<... (200; 11.970117ms)
Oct 22 01:26:52.582: INFO: (13) /api/v1/namespaces/proxy-8293/pods/proxy-service-27sd4-bwjhf:162/proxy/: bar (200; 11.681706ms)
Oct 22 01:26:52.582: INFO: (13) /api/v1/namespaces/proxy-8293/pods/https:proxy-service-27sd4-bwjhf:443/proxy/: <a href="/api/v1/namespaces/proxy-8293/pods/https:proxy-service-27sd4-bwjhf:443/proxy/tlsrewritem... (200; 12.256737ms)
Oct 22 01:26:52.582: INFO: (13) /api/v1/namespaces/proxy-8293/pods/http:proxy-service-27sd4-bwjhf:160/proxy/: foo (200; 12.707967ms)
Oct 22 01:26:52.582: INFO: (13) /api/v1/namespaces/proxy-8293/pods/http:proxy-service-27sd4-bwjhf:1080/proxy/: <a href="/api/v1/namespaces/proxy-8293/pods/http:proxy-service-27sd4-bwjhf:1080/proxy/rewriteme">... (200; 11.234945ms)
Oct 22 01:26:52.588: INFO: (13) /api/v1/namespaces/proxy-8293/services/http:proxy-service-27sd4:portname2/proxy/: bar (200; 19.030423ms)
Oct 22 01:26:52.588: INFO: (13) /api/v1/namespaces/proxy-8293/services/proxy-service-27sd4:portname2/proxy/: bar (200; 18.586568ms)
Oct 22 01:26:52.588: INFO: (13) /api/v1/namespaces/proxy-8293/services/proxy-service-27sd4:portname1/proxy/: foo (200; 19.36926ms)
Oct 22 01:26:52.588: INFO: (13) /api/v1/namespaces/proxy-8293/services/https:proxy-service-27sd4:tlsportname1/proxy/: tls baz (200; 17.72315ms)
Oct 22 01:26:52.589: INFO: (13) /api/v1/namespaces/proxy-8293/services/https:proxy-service-27sd4:tlsportname2/proxy/: tls qux (200; 18.833398ms)
Oct 22 01:26:52.589: INFO: (13) /api/v1/namespaces/proxy-8293/services/http:proxy-service-27sd4:portname1/proxy/: foo (200; 18.338063ms)
Oct 22 01:26:52.596: INFO: (14) /api/v1/namespaces/proxy-8293/pods/https:proxy-service-27sd4-bwjhf:443/proxy/: <a href="/api/v1/namespaces/proxy-8293/pods/https:proxy-service-27sd4-bwjhf:443/proxy/tlsrewritem... (200; 6.795863ms)
Oct 22 01:26:52.597: INFO: (14) /api/v1/namespaces/proxy-8293/pods/proxy-service-27sd4-bwjhf:162/proxy/: bar (200; 7.469079ms)
Oct 22 01:26:52.600: INFO: (14) /api/v1/namespaces/proxy-8293/pods/proxy-service-27sd4-bwjhf/proxy/: <a href="/api/v1/namespaces/proxy-8293/pods/proxy-service-27sd4-bwjhf/proxy/rewriteme">test</a> (200; 11.006613ms)
Oct 22 01:26:52.601: INFO: (14) /api/v1/namespaces/proxy-8293/pods/http:proxy-service-27sd4-bwjhf:160/proxy/: foo (200; 10.685474ms)
Oct 22 01:26:52.602: INFO: (14) /api/v1/namespaces/proxy-8293/pods/https:proxy-service-27sd4-bwjhf:460/proxy/: tls baz (200; 11.081143ms)
Oct 22 01:26:52.603: INFO: (14) /api/v1/namespaces/proxy-8293/pods/proxy-service-27sd4-bwjhf:1080/proxy/: <a href="/api/v1/namespaces/proxy-8293/pods/proxy-service-27sd4-bwjhf:1080/proxy/rewriteme">test<... (200; 12.797053ms)
Oct 22 01:26:52.604: INFO: (14) /api/v1/namespaces/proxy-8293/pods/http:proxy-service-27sd4-bwjhf:1080/proxy/: <a href="/api/v1/namespaces/proxy-8293/pods/http:proxy-service-27sd4-bwjhf:1080/proxy/rewriteme">... (200; 13.698009ms)
Oct 22 01:26:52.605: INFO: (14) /api/v1/namespaces/proxy-8293/pods/proxy-service-27sd4-bwjhf:160/proxy/: foo (200; 14.386323ms)
Oct 22 01:26:52.605: INFO: (14) /api/v1/namespaces/proxy-8293/services/proxy-service-27sd4:portname1/proxy/: foo (200; 16.21329ms)
Oct 22 01:26:52.607: INFO: (14) /api/v1/namespaces/proxy-8293/services/http:proxy-service-27sd4:portname2/proxy/: bar (200; 16.04431ms)
Oct 22 01:26:52.607: INFO: (14) /api/v1/namespaces/proxy-8293/services/https:proxy-service-27sd4:tlsportname2/proxy/: tls qux (200; 17.882919ms)
Oct 22 01:26:52.607: INFO: (14) /api/v1/namespaces/proxy-8293/pods/https:proxy-service-27sd4-bwjhf:462/proxy/: tls qux (200; 16.221999ms)
Oct 22 01:26:52.607: INFO: (14) /api/v1/namespaces/proxy-8293/pods/http:proxy-service-27sd4-bwjhf:162/proxy/: bar (200; 16.84665ms)
Oct 22 01:26:52.607: INFO: (14) /api/v1/namespaces/proxy-8293/services/https:proxy-service-27sd4:tlsportname1/proxy/: tls baz (200; 17.3869ms)
Oct 22 01:26:52.608: INFO: (14) /api/v1/namespaces/proxy-8293/services/proxy-service-27sd4:portname2/proxy/: bar (200; 17.856889ms)
Oct 22 01:26:52.608: INFO: (14) /api/v1/namespaces/proxy-8293/services/http:proxy-service-27sd4:portname1/proxy/: foo (200; 16.900272ms)
Oct 22 01:26:52.621: INFO: (15) /api/v1/namespaces/proxy-8293/pods/proxy-service-27sd4-bwjhf:1080/proxy/: <a href="/api/v1/namespaces/proxy-8293/pods/proxy-service-27sd4-bwjhf:1080/proxy/rewriteme">test<... (200; 12.341889ms)
Oct 22 01:26:52.621: INFO: (15) /api/v1/namespaces/proxy-8293/pods/http:proxy-service-27sd4-bwjhf:1080/proxy/: <a href="/api/v1/namespaces/proxy-8293/pods/http:proxy-service-27sd4-bwjhf:1080/proxy/rewriteme">... (200; 13.247182ms)
Oct 22 01:26:52.621: INFO: (15) /api/v1/namespaces/proxy-8293/pods/http:proxy-service-27sd4-bwjhf:162/proxy/: bar (200; 11.410745ms)
Oct 22 01:26:52.621: INFO: (15) /api/v1/namespaces/proxy-8293/pods/https:proxy-service-27sd4-bwjhf:443/proxy/: <a href="/api/v1/namespaces/proxy-8293/pods/https:proxy-service-27sd4-bwjhf:443/proxy/tlsrewritem... (200; 12.218959ms)
Oct 22 01:26:52.621: INFO: (15) /api/v1/namespaces/proxy-8293/pods/http:proxy-service-27sd4-bwjhf:160/proxy/: foo (200; 12.540475ms)
Oct 22 01:26:52.621: INFO: (15) /api/v1/namespaces/proxy-8293/pods/proxy-service-27sd4-bwjhf:162/proxy/: bar (200; 12.5125ms)
Oct 22 01:26:52.622: INFO: (15) /api/v1/namespaces/proxy-8293/pods/https:proxy-service-27sd4-bwjhf:462/proxy/: tls qux (200; 13.527203ms)
Oct 22 01:26:52.622: INFO: (15) /api/v1/namespaces/proxy-8293/pods/proxy-service-27sd4-bwjhf/proxy/: <a href="/api/v1/namespaces/proxy-8293/pods/proxy-service-27sd4-bwjhf/proxy/rewriteme">test</a> (200; 12.36003ms)
Oct 22 01:26:52.622: INFO: (15) /api/v1/namespaces/proxy-8293/pods/https:proxy-service-27sd4-bwjhf:460/proxy/: tls baz (200; 13.858161ms)
Oct 22 01:26:52.622: INFO: (15) /api/v1/namespaces/proxy-8293/pods/proxy-service-27sd4-bwjhf:160/proxy/: foo (200; 12.314023ms)
Oct 22 01:26:52.623: INFO: (15) /api/v1/namespaces/proxy-8293/services/proxy-service-27sd4:portname1/proxy/: foo (200; 15.089525ms)
Oct 22 01:26:52.624: INFO: (15) /api/v1/namespaces/proxy-8293/services/http:proxy-service-27sd4:portname2/proxy/: bar (200; 15.870027ms)
Oct 22 01:26:52.624: INFO: (15) /api/v1/namespaces/proxy-8293/services/https:proxy-service-27sd4:tlsportname2/proxy/: tls qux (200; 15.019721ms)
Oct 22 01:26:52.625: INFO: (15) /api/v1/namespaces/proxy-8293/services/http:proxy-service-27sd4:portname1/proxy/: foo (200; 14.993777ms)
Oct 22 01:26:52.625: INFO: (15) /api/v1/namespaces/proxy-8293/services/proxy-service-27sd4:portname2/proxy/: bar (200; 15.902672ms)
Oct 22 01:26:52.625: INFO: (15) /api/v1/namespaces/proxy-8293/services/https:proxy-service-27sd4:tlsportname1/proxy/: tls baz (200; 15.181745ms)
Oct 22 01:26:52.637: INFO: (16) /api/v1/namespaces/proxy-8293/pods/http:proxy-service-27sd4-bwjhf:1080/proxy/: <a href="/api/v1/namespaces/proxy-8293/pods/http:proxy-service-27sd4-bwjhf:1080/proxy/rewriteme">... (200; 10.091138ms)
Oct 22 01:26:52.637: INFO: (16) /api/v1/namespaces/proxy-8293/pods/http:proxy-service-27sd4-bwjhf:162/proxy/: bar (200; 11.695609ms)
Oct 22 01:26:52.637: INFO: (16) /api/v1/namespaces/proxy-8293/pods/proxy-service-27sd4-bwjhf:1080/proxy/: <a href="/api/v1/namespaces/proxy-8293/pods/proxy-service-27sd4-bwjhf:1080/proxy/rewriteme">test<... (200; 11.499892ms)
Oct 22 01:26:52.637: INFO: (16) /api/v1/namespaces/proxy-8293/pods/https:proxy-service-27sd4-bwjhf:462/proxy/: tls qux (200; 11.086192ms)
Oct 22 01:26:52.638: INFO: (16) /api/v1/namespaces/proxy-8293/pods/proxy-service-27sd4-bwjhf/proxy/: <a href="/api/v1/namespaces/proxy-8293/pods/proxy-service-27sd4-bwjhf/proxy/rewriteme">test</a> (200; 11.150717ms)
Oct 22 01:26:52.638: INFO: (16) /api/v1/namespaces/proxy-8293/pods/proxy-service-27sd4-bwjhf:162/proxy/: bar (200; 11.120504ms)
Oct 22 01:26:52.638: INFO: (16) /api/v1/namespaces/proxy-8293/pods/proxy-service-27sd4-bwjhf:160/proxy/: foo (200; 11.071024ms)
Oct 22 01:26:52.638: INFO: (16) /api/v1/namespaces/proxy-8293/pods/https:proxy-service-27sd4-bwjhf:443/proxy/: <a href="/api/v1/namespaces/proxy-8293/pods/https:proxy-service-27sd4-bwjhf:443/proxy/tlsrewritem... (200; 11.318738ms)
Oct 22 01:26:52.640: INFO: (16) /api/v1/namespaces/proxy-8293/services/proxy-service-27sd4:portname2/proxy/: bar (200; 13.712345ms)
Oct 22 01:26:52.640: INFO: (16) /api/v1/namespaces/proxy-8293/pods/https:proxy-service-27sd4-bwjhf:460/proxy/: tls baz (200; 14.159721ms)
Oct 22 01:26:52.641: INFO: (16) /api/v1/namespaces/proxy-8293/pods/http:proxy-service-27sd4-bwjhf:160/proxy/: foo (200; 14.628798ms)
Oct 22 01:26:52.645: INFO: (16) /api/v1/namespaces/proxy-8293/services/http:proxy-service-27sd4:portname1/proxy/: foo (200; 18.433263ms)
Oct 22 01:26:52.645: INFO: (16) /api/v1/namespaces/proxy-8293/services/http:proxy-service-27sd4:portname2/proxy/: bar (200; 19.695056ms)
Oct 22 01:26:52.646: INFO: (16) /api/v1/namespaces/proxy-8293/services/proxy-service-27sd4:portname1/proxy/: foo (200; 19.976493ms)
Oct 22 01:26:52.646: INFO: (16) /api/v1/namespaces/proxy-8293/services/https:proxy-service-27sd4:tlsportname2/proxy/: tls qux (200; 19.43318ms)
Oct 22 01:26:52.646: INFO: (16) /api/v1/namespaces/proxy-8293/services/https:proxy-service-27sd4:tlsportname1/proxy/: tls baz (200; 19.555191ms)
Oct 22 01:26:52.656: INFO: (17) /api/v1/namespaces/proxy-8293/pods/proxy-service-27sd4-bwjhf:160/proxy/: foo (200; 9.91478ms)
Oct 22 01:26:52.661: INFO: (17) /api/v1/namespaces/proxy-8293/pods/http:proxy-service-27sd4-bwjhf:1080/proxy/: <a href="/api/v1/namespaces/proxy-8293/pods/http:proxy-service-27sd4-bwjhf:1080/proxy/rewriteme">... (200; 13.559978ms)
Oct 22 01:26:52.662: INFO: (17) /api/v1/namespaces/proxy-8293/pods/proxy-service-27sd4-bwjhf:162/proxy/: bar (200; 14.189594ms)
Oct 22 01:26:52.665: INFO: (17) /api/v1/namespaces/proxy-8293/services/https:proxy-service-27sd4:tlsportname1/proxy/: tls baz (200; 17.00465ms)
Oct 22 01:26:52.665: INFO: (17) /api/v1/namespaces/proxy-8293/services/proxy-service-27sd4:portname1/proxy/: foo (200; 17.803403ms)
Oct 22 01:26:52.665: INFO: (17) /api/v1/namespaces/proxy-8293/services/http:proxy-service-27sd4:portname1/proxy/: foo (200; 17.816208ms)
Oct 22 01:26:52.668: INFO: (17) /api/v1/namespaces/proxy-8293/pods/https:proxy-service-27sd4-bwjhf:460/proxy/: tls baz (200; 21.248296ms)
Oct 22 01:26:52.668: INFO: (17) /api/v1/namespaces/proxy-8293/services/http:proxy-service-27sd4:portname2/proxy/: bar (200; 21.700818ms)
Oct 22 01:26:52.669: INFO: (17) /api/v1/namespaces/proxy-8293/pods/proxy-service-27sd4-bwjhf/proxy/: <a href="/api/v1/namespaces/proxy-8293/pods/proxy-service-27sd4-bwjhf/proxy/rewriteme">test</a> (200; 21.384533ms)
Oct 22 01:26:52.669: INFO: (17) /api/v1/namespaces/proxy-8293/services/proxy-service-27sd4:portname2/proxy/: bar (200; 22.21429ms)
Oct 22 01:26:52.669: INFO: (17) /api/v1/namespaces/proxy-8293/pods/https:proxy-service-27sd4-bwjhf:443/proxy/: <a href="/api/v1/namespaces/proxy-8293/pods/https:proxy-service-27sd4-bwjhf:443/proxy/tlsrewritem... (200; 21.730809ms)
Oct 22 01:26:52.669: INFO: (17) /api/v1/namespaces/proxy-8293/pods/https:proxy-service-27sd4-bwjhf:462/proxy/: tls qux (200; 22.417457ms)
Oct 22 01:26:52.669: INFO: (17) /api/v1/namespaces/proxy-8293/services/https:proxy-service-27sd4:tlsportname2/proxy/: tls qux (200; 22.654473ms)
Oct 22 01:26:52.670: INFO: (17) /api/v1/namespaces/proxy-8293/pods/http:proxy-service-27sd4-bwjhf:162/proxy/: bar (200; 22.06308ms)
Oct 22 01:26:52.670: INFO: (17) /api/v1/namespaces/proxy-8293/pods/http:proxy-service-27sd4-bwjhf:160/proxy/: foo (200; 22.900635ms)
Oct 22 01:26:52.670: INFO: (17) /api/v1/namespaces/proxy-8293/pods/proxy-service-27sd4-bwjhf:1080/proxy/: <a href="/api/v1/namespaces/proxy-8293/pods/proxy-service-27sd4-bwjhf:1080/proxy/rewriteme">test<... (200; 23.033676ms)
Oct 22 01:26:52.681: INFO: (18) /api/v1/namespaces/proxy-8293/pods/proxy-service-27sd4-bwjhf:162/proxy/: bar (200; 10.120992ms)
Oct 22 01:26:52.682: INFO: (18) /api/v1/namespaces/proxy-8293/pods/https:proxy-service-27sd4-bwjhf:462/proxy/: tls qux (200; 11.079401ms)
Oct 22 01:26:52.682: INFO: (18) /api/v1/namespaces/proxy-8293/pods/http:proxy-service-27sd4-bwjhf:1080/proxy/: <a href="/api/v1/namespaces/proxy-8293/pods/http:proxy-service-27sd4-bwjhf:1080/proxy/rewriteme">... (200; 12.021327ms)
Oct 22 01:26:52.683: INFO: (18) /api/v1/namespaces/proxy-8293/pods/proxy-service-27sd4-bwjhf:1080/proxy/: <a href="/api/v1/namespaces/proxy-8293/pods/proxy-service-27sd4-bwjhf:1080/proxy/rewriteme">test<... (200; 12.511976ms)
Oct 22 01:26:52.684: INFO: (18) /api/v1/namespaces/proxy-8293/pods/http:proxy-service-27sd4-bwjhf:160/proxy/: foo (200; 12.753709ms)
Oct 22 01:26:52.684: INFO: (18) /api/v1/namespaces/proxy-8293/pods/https:proxy-service-27sd4-bwjhf:443/proxy/: <a href="/api/v1/namespaces/proxy-8293/pods/https:proxy-service-27sd4-bwjhf:443/proxy/tlsrewritem... (200; 13.023068ms)
Oct 22 01:26:52.685: INFO: (18) /api/v1/namespaces/proxy-8293/pods/proxy-service-27sd4-bwjhf/proxy/: <a href="/api/v1/namespaces/proxy-8293/pods/proxy-service-27sd4-bwjhf/proxy/rewriteme">test</a> (200; 13.280634ms)
Oct 22 01:26:52.685: INFO: (18) /api/v1/namespaces/proxy-8293/pods/https:proxy-service-27sd4-bwjhf:460/proxy/: tls baz (200; 14.713513ms)
Oct 22 01:26:52.685: INFO: (18) /api/v1/namespaces/proxy-8293/pods/http:proxy-service-27sd4-bwjhf:162/proxy/: bar (200; 13.497986ms)
Oct 22 01:26:52.685: INFO: (18) /api/v1/namespaces/proxy-8293/pods/proxy-service-27sd4-bwjhf:160/proxy/: foo (200; 13.671531ms)
Oct 22 01:26:52.688: INFO: (18) /api/v1/namespaces/proxy-8293/services/http:proxy-service-27sd4:portname2/proxy/: bar (200; 18.05615ms)
Oct 22 01:26:52.688: INFO: (18) /api/v1/namespaces/proxy-8293/services/http:proxy-service-27sd4:portname1/proxy/: foo (200; 16.493314ms)
Oct 22 01:26:52.689: INFO: (18) /api/v1/namespaces/proxy-8293/services/proxy-service-27sd4:portname2/proxy/: bar (200; 17.085927ms)
Oct 22 01:26:52.689: INFO: (18) /api/v1/namespaces/proxy-8293/services/proxy-service-27sd4:portname1/proxy/: foo (200; 17.840266ms)
Oct 22 01:26:52.689: INFO: (18) /api/v1/namespaces/proxy-8293/services/https:proxy-service-27sd4:tlsportname2/proxy/: tls qux (200; 16.998937ms)
Oct 22 01:26:52.689: INFO: (18) /api/v1/namespaces/proxy-8293/services/https:proxy-service-27sd4:tlsportname1/proxy/: tls baz (200; 17.261031ms)
Oct 22 01:26:52.696: INFO: (19) /api/v1/namespaces/proxy-8293/pods/https:proxy-service-27sd4-bwjhf:460/proxy/: tls baz (200; 6.576525ms)
Oct 22 01:26:52.696: INFO: (19) /api/v1/namespaces/proxy-8293/pods/https:proxy-service-27sd4-bwjhf:443/proxy/: <a href="/api/v1/namespaces/proxy-8293/pods/https:proxy-service-27sd4-bwjhf:443/proxy/tlsrewritem... (200; 6.444951ms)
Oct 22 01:26:52.701: INFO: (19) /api/v1/namespaces/proxy-8293/pods/proxy-service-27sd4-bwjhf:160/proxy/: foo (200; 9.703465ms)
Oct 22 01:26:52.701: INFO: (19) /api/v1/namespaces/proxy-8293/pods/proxy-service-27sd4-bwjhf:162/proxy/: bar (200; 10.436435ms)
Oct 22 01:26:52.701: INFO: (19) /api/v1/namespaces/proxy-8293/pods/proxy-service-27sd4-bwjhf/proxy/: <a href="/api/v1/namespaces/proxy-8293/pods/proxy-service-27sd4-bwjhf/proxy/rewriteme">test</a> (200; 11.246825ms)
Oct 22 01:26:52.702: INFO: (19) /api/v1/namespaces/proxy-8293/pods/http:proxy-service-27sd4-bwjhf:160/proxy/: foo (200; 10.247476ms)
Oct 22 01:26:52.702: INFO: (19) /api/v1/namespaces/proxy-8293/pods/proxy-service-27sd4-bwjhf:1080/proxy/: <a href="/api/v1/namespaces/proxy-8293/pods/proxy-service-27sd4-bwjhf:1080/proxy/rewriteme">test<... (200; 10.821312ms)
Oct 22 01:26:52.703: INFO: (19) /api/v1/namespaces/proxy-8293/pods/http:proxy-service-27sd4-bwjhf:162/proxy/: bar (200; 13.04475ms)
Oct 22 01:26:52.703: INFO: (19) /api/v1/namespaces/proxy-8293/pods/https:proxy-service-27sd4-bwjhf:462/proxy/: tls qux (200; 12.19943ms)
Oct 22 01:26:52.703: INFO: (19) /api/v1/namespaces/proxy-8293/pods/http:proxy-service-27sd4-bwjhf:1080/proxy/: <a href="/api/v1/namespaces/proxy-8293/pods/http:proxy-service-27sd4-bwjhf:1080/proxy/rewriteme">... (200; 12.6884ms)
Oct 22 01:26:52.705: INFO: (19) /api/v1/namespaces/proxy-8293/services/http:proxy-service-27sd4:portname1/proxy/: foo (200; 14.771998ms)
Oct 22 01:26:52.705: INFO: (19) /api/v1/namespaces/proxy-8293/services/https:proxy-service-27sd4:tlsportname2/proxy/: tls qux (200; 15.404445ms)
Oct 22 01:26:52.705: INFO: (19) /api/v1/namespaces/proxy-8293/services/proxy-service-27sd4:portname2/proxy/: bar (200; 15.621166ms)
Oct 22 01:26:52.706: INFO: (19) /api/v1/namespaces/proxy-8293/services/https:proxy-service-27sd4:tlsportname1/proxy/: tls baz (200; 15.106662ms)
Oct 22 01:26:52.706: INFO: (19) /api/v1/namespaces/proxy-8293/services/proxy-service-27sd4:portname1/proxy/: foo (200; 14.413312ms)
Oct 22 01:26:52.706: INFO: (19) /api/v1/namespaces/proxy-8293/services/http:proxy-service-27sd4:portname2/proxy/: bar (200; 15.134938ms)
STEP: deleting ReplicationController proxy-service-27sd4 in namespace proxy-8293, will wait for the garbage collector to delete the pods
Oct 22 01:26:52.770: INFO: Deleting ReplicationController proxy-service-27sd4 took: 9.986316ms
Oct 22 01:26:53.171: INFO: Terminating ReplicationController proxy-service-27sd4 pods took: 400.301342ms
[AfterEach] version v1
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 01:26:55.171: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-8293" for this suite.
Oct 22 01:27:09.194: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 01:27:09.344: INFO: namespace proxy-8293 deletion completed in 14.166872385s

• [SLOW TEST:28.176 seconds]
[sig-network] Proxy
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:58
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 01:27:09.345: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-1c914fe0-e4b6-493b-987d-0b8068056d74
STEP: Creating a pod to test consume configMaps
Oct 22 01:27:09.425: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-7e6c77ee-20f7-44e8-b7af-53a5ddb6fbab" in namespace "projected-3710" to be "success or failure"
Oct 22 01:27:09.435: INFO: Pod "pod-projected-configmaps-7e6c77ee-20f7-44e8-b7af-53a5ddb6fbab": Phase="Pending", Reason="", readiness=false. Elapsed: 9.982856ms
Oct 22 01:27:11.440: INFO: Pod "pod-projected-configmaps-7e6c77ee-20f7-44e8-b7af-53a5ddb6fbab": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015355709s
STEP: Saw pod success
Oct 22 01:27:11.440: INFO: Pod "pod-projected-configmaps-7e6c77ee-20f7-44e8-b7af-53a5ddb6fbab" satisfied condition "success or failure"
Oct 22 01:27:11.444: INFO: Trying to get logs from node mip-bd-vm41.mip.storage.hpecorp.net pod pod-projected-configmaps-7e6c77ee-20f7-44e8-b7af-53a5ddb6fbab container projected-configmap-volume-test: <nil>
STEP: delete the pod
Oct 22 01:27:11.474: INFO: Waiting for pod pod-projected-configmaps-7e6c77ee-20f7-44e8-b7af-53a5ddb6fbab to disappear
Oct 22 01:27:11.477: INFO: Pod pod-projected-configmaps-7e6c77ee-20f7-44e8-b7af-53a5ddb6fbab no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 01:27:11.477: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3710" for this suite.
Oct 22 01:27:17.496: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 01:27:17.642: INFO: namespace projected-3710 deletion completed in 6.159637096s

• [SLOW TEST:8.298 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 01:27:17.643: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating secret secrets-6080/secret-test-78db8b1f-cc35-4753-89a6-0f41e121d33d
STEP: Creating a pod to test consume secrets
Oct 22 01:27:17.708: INFO: Waiting up to 5m0s for pod "pod-configmaps-ef32c851-14b8-49ea-92b7-22869245894a" in namespace "secrets-6080" to be "success or failure"
Oct 22 01:27:17.712: INFO: Pod "pod-configmaps-ef32c851-14b8-49ea-92b7-22869245894a": Phase="Pending", Reason="", readiness=false. Elapsed: 4.222711ms
Oct 22 01:27:19.716: INFO: Pod "pod-configmaps-ef32c851-14b8-49ea-92b7-22869245894a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00864413s
STEP: Saw pod success
Oct 22 01:27:19.716: INFO: Pod "pod-configmaps-ef32c851-14b8-49ea-92b7-22869245894a" satisfied condition "success or failure"
Oct 22 01:27:19.720: INFO: Trying to get logs from node mip-bd-vm40.mip.storage.hpecorp.net pod pod-configmaps-ef32c851-14b8-49ea-92b7-22869245894a container env-test: <nil>
STEP: delete the pod
Oct 22 01:27:19.746: INFO: Waiting for pod pod-configmaps-ef32c851-14b8-49ea-92b7-22869245894a to disappear
Oct 22 01:27:19.749: INFO: Pod pod-configmaps-ef32c851-14b8-49ea-92b7-22869245894a no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 01:27:19.749: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6080" for this suite.
Oct 22 01:27:25.768: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 01:27:25.912: INFO: namespace secrets-6080 deletion completed in 6.158035806s

• [SLOW TEST:8.269 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 01:27:25.912: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:81
Oct 22 01:27:25.960: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Oct 22 01:27:25.969: INFO: Waiting for terminating namespaces to be deleted...
Oct 22 01:27:25.972: INFO: 
Logging pods the kubelet thinks is on node mip-bd-vm40.mip.storage.hpecorp.net before test
Oct 22 01:27:25.984: INFO: kubedirector-6466dc856f-mh7mk from kube-system started at 2019-10-21 22:11:04 +0000 UTC (1 container statuses recorded)
Oct 22 01:27:25.984: INFO: 	Container kubedirector ready: true, restart count 0
Oct 22 01:27:25.984: INFO: canal-r9n5g from kube-system started at 2019-10-21 22:11:11 +0000 UTC (3 container statuses recorded)
Oct 22 01:27:25.984: INFO: 	Container calico-node ready: true, restart count 0
Oct 22 01:27:25.984: INFO: 	Container install-cni ready: true, restart count 0
Oct 22 01:27:25.984: INFO: 	Container kube-flannel ready: true, restart count 0
Oct 22 01:27:25.984: INFO: kubedirector-fsmount-gfmbk from kube-system started at 2019-10-21 22:12:39 +0000 UTC (1 container statuses recorded)
Oct 22 01:27:25.984: INFO: 	Container kubedirector-fsmount ready: true, restart count 0
Oct 22 01:27:25.984: INFO: sonobuoy-systemd-logs-daemon-set-d36ba0a04f4c410a-66d8l from heptio-sonobuoy started at 2019-10-21 23:53:49 +0000 UTC (2 container statuses recorded)
Oct 22 01:27:25.984: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Oct 22 01:27:25.984: INFO: 	Container systemd-logs ready: true, restart count 1
Oct 22 01:27:25.984: INFO: kube-proxy-p4s2t from kube-system started at 2019-10-21 22:10:33 +0000 UTC (1 container statuses recorded)
Oct 22 01:27:25.984: INFO: 	Container kube-proxy ready: true, restart count 0
Oct 22 01:27:25.984: INFO: sonobuoy-e2e-job-d7290e8bc6084643 from heptio-sonobuoy started at 2019-10-21 23:53:49 +0000 UTC (2 container statuses recorded)
Oct 22 01:27:25.984: INFO: 	Container e2e ready: true, restart count 0
Oct 22 01:27:25.984: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct 22 01:27:25.984: INFO: 
Logging pods the kubelet thinks is on node mip-bd-vm41.mip.storage.hpecorp.net before test
Oct 22 01:27:25.995: INFO: kube-proxy-lc4z4 from kube-system started at 2019-10-21 22:10:31 +0000 UTC (1 container statuses recorded)
Oct 22 01:27:25.995: INFO: 	Container kube-proxy ready: true, restart count 0
Oct 22 01:27:25.995: INFO: kube-state-metrics-549d594744-hlwrw from kube-system started at 2019-10-21 22:11:00 +0000 UTC (1 container statuses recorded)
Oct 22 01:27:25.995: INFO: 	Container kube-state-metrics ready: true, restart count 0
Oct 22 01:27:25.995: INFO: sonobuoy from heptio-sonobuoy started at 2019-10-21 23:53:46 +0000 UTC (1 container statuses recorded)
Oct 22 01:27:25.995: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Oct 22 01:27:25.995: INFO: canal-7vsf6 from kube-system started at 2019-10-21 22:11:11 +0000 UTC (3 container statuses recorded)
Oct 22 01:27:25.995: INFO: 	Container calico-node ready: true, restart count 0
Oct 22 01:27:25.995: INFO: 	Container install-cni ready: true, restart count 0
Oct 22 01:27:25.995: INFO: 	Container kube-flannel ready: true, restart count 0
Oct 22 01:27:25.995: INFO: sonobuoy-systemd-logs-daemon-set-d36ba0a04f4c410a-4nk8z from heptio-sonobuoy started at 2019-10-21 23:53:49 +0000 UTC (2 container statuses recorded)
Oct 22 01:27:25.995: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Oct 22 01:27:25.995: INFO: 	Container systemd-logs ready: true, restart count 1
Oct 22 01:27:25.995: INFO: kubedirector-fsmount-vgwfc from kube-system started at 2019-10-21 22:12:39 +0000 UTC (1 container statuses recorded)
Oct 22 01:27:25.995: INFO: 	Container kubedirector-fsmount ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: verifying the node has the label node mip-bd-vm40.mip.storage.hpecorp.net
STEP: verifying the node has the label node mip-bd-vm41.mip.storage.hpecorp.net
Oct 22 01:27:26.050: INFO: Pod sonobuoy requesting resource cpu=0m on Node mip-bd-vm41.mip.storage.hpecorp.net
Oct 22 01:27:26.050: INFO: Pod sonobuoy-e2e-job-d7290e8bc6084643 requesting resource cpu=0m on Node mip-bd-vm40.mip.storage.hpecorp.net
Oct 22 01:27:26.050: INFO: Pod sonobuoy-systemd-logs-daemon-set-d36ba0a04f4c410a-4nk8z requesting resource cpu=0m on Node mip-bd-vm41.mip.storage.hpecorp.net
Oct 22 01:27:26.050: INFO: Pod sonobuoy-systemd-logs-daemon-set-d36ba0a04f4c410a-66d8l requesting resource cpu=0m on Node mip-bd-vm40.mip.storage.hpecorp.net
Oct 22 01:27:26.050: INFO: Pod canal-7vsf6 requesting resource cpu=250m on Node mip-bd-vm41.mip.storage.hpecorp.net
Oct 22 01:27:26.050: INFO: Pod canal-r9n5g requesting resource cpu=250m on Node mip-bd-vm40.mip.storage.hpecorp.net
Oct 22 01:27:26.050: INFO: Pod kube-proxy-lc4z4 requesting resource cpu=0m on Node mip-bd-vm41.mip.storage.hpecorp.net
Oct 22 01:27:26.050: INFO: Pod kube-proxy-p4s2t requesting resource cpu=0m on Node mip-bd-vm40.mip.storage.hpecorp.net
Oct 22 01:27:26.050: INFO: Pod kube-state-metrics-549d594744-hlwrw requesting resource cpu=0m on Node mip-bd-vm41.mip.storage.hpecorp.net
Oct 22 01:27:26.050: INFO: Pod kubedirector-6466dc856f-mh7mk requesting resource cpu=0m on Node mip-bd-vm40.mip.storage.hpecorp.net
Oct 22 01:27:26.050: INFO: Pod kubedirector-fsmount-gfmbk requesting resource cpu=250m on Node mip-bd-vm40.mip.storage.hpecorp.net
Oct 22 01:27:26.050: INFO: Pod kubedirector-fsmount-vgwfc requesting resource cpu=250m on Node mip-bd-vm41.mip.storage.hpecorp.net
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-635f9c7f-7acf-4ac6-a468-8cd1898e45c5.15cfd3c6def4fec9], Reason = [Scheduled], Message = [Successfully assigned sched-pred-5250/filler-pod-635f9c7f-7acf-4ac6-a468-8cd1898e45c5 to mip-bd-vm40.mip.storage.hpecorp.net]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-635f9c7f-7acf-4ac6-a468-8cd1898e45c5.15cfd3c70cafe226], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-635f9c7f-7acf-4ac6-a468-8cd1898e45c5.15cfd3c7106c7fd8], Reason = [Created], Message = [Created container filler-pod-635f9c7f-7acf-4ac6-a468-8cd1898e45c5]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-635f9c7f-7acf-4ac6-a468-8cd1898e45c5.15cfd3c71b9840f7], Reason = [Started], Message = [Started container filler-pod-635f9c7f-7acf-4ac6-a468-8cd1898e45c5]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-a0e3d639-24f1-465e-9652-9d23d28ac762.15cfd3c6df3fbc6a], Reason = [Scheduled], Message = [Successfully assigned sched-pred-5250/filler-pod-a0e3d639-24f1-465e-9652-9d23d28ac762 to mip-bd-vm41.mip.storage.hpecorp.net]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-a0e3d639-24f1-465e-9652-9d23d28ac762.15cfd3c70ce3427f], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-a0e3d639-24f1-465e-9652-9d23d28ac762.15cfd3c70f6225b8], Reason = [Created], Message = [Created container filler-pod-a0e3d639-24f1-465e-9652-9d23d28ac762]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-a0e3d639-24f1-465e-9652-9d23d28ac762.15cfd3c71b7d184c], Reason = [Started], Message = [Started container filler-pod-a0e3d639-24f1-465e-9652-9d23d28ac762]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.15cfd3c757d4f530], Reason = [FailedScheduling], Message = [0/3 nodes are available: 1 node(s) had taints that the pod didn't tolerate, 2 Insufficient cpu.]
STEP: removing the label node off the node mip-bd-vm40.mip.storage.hpecorp.net
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node mip-bd-vm41.mip.storage.hpecorp.net
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 01:27:29.143: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-5250" for this suite.
Oct 22 01:27:35.161: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 01:27:35.315: INFO: namespace sched-pred-5250 deletion completed in 6.167514023s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:72

• [SLOW TEST:9.403 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 01:27:35.315: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir volume type on node default medium
Oct 22 01:27:35.378: INFO: Waiting up to 5m0s for pod "pod-a9025248-54fa-4665-b364-cac167a8dd3d" in namespace "emptydir-2006" to be "success or failure"
Oct 22 01:27:35.381: INFO: Pod "pod-a9025248-54fa-4665-b364-cac167a8dd3d": Phase="Pending", Reason="", readiness=false. Elapsed: 3.618156ms
Oct 22 01:27:37.388: INFO: Pod "pod-a9025248-54fa-4665-b364-cac167a8dd3d": Phase="Running", Reason="", readiness=true. Elapsed: 2.009843677s
Oct 22 01:27:39.394: INFO: Pod "pod-a9025248-54fa-4665-b364-cac167a8dd3d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016303942s
STEP: Saw pod success
Oct 22 01:27:39.394: INFO: Pod "pod-a9025248-54fa-4665-b364-cac167a8dd3d" satisfied condition "success or failure"
Oct 22 01:27:39.398: INFO: Trying to get logs from node mip-bd-vm41.mip.storage.hpecorp.net pod pod-a9025248-54fa-4665-b364-cac167a8dd3d container test-container: <nil>
STEP: delete the pod
Oct 22 01:27:39.426: INFO: Waiting for pod pod-a9025248-54fa-4665-b364-cac167a8dd3d to disappear
Oct 22 01:27:39.430: INFO: Pod pod-a9025248-54fa-4665-b364-cac167a8dd3d no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 01:27:39.430: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2006" for this suite.
Oct 22 01:27:47.450: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 01:27:47.600: INFO: namespace emptydir-2006 deletion completed in 8.1646707s

• [SLOW TEST:12.285 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 01:27:47.601: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating the pod
Oct 22 01:27:50.199: INFO: Successfully updated pod "labelsupdateddbb979a-2f06-4b5b-9e02-b2b44c5c3941"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 01:27:54.239: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-870" for this suite.
Oct 22 01:28:16.260: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 01:28:16.413: INFO: namespace projected-870 deletion completed in 22.168658223s

• [SLOW TEST:28.812 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 01:28:16.413: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
Oct 22 01:28:22.511: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 01:28:22.511: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
W1022 01:28:22.511377      18 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
STEP: Destroying namespace "gc-5409" for this suite.
Oct 22 01:28:28.532: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 01:28:28.694: INFO: namespace gc-5409 deletion completed in 6.177250379s

• [SLOW TEST:12.281 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 01:28:28.695: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0644 on tmpfs
Oct 22 01:28:28.747: INFO: Waiting up to 5m0s for pod "pod-6a836bd1-9cdd-4712-b780-7e7bb5c22b55" in namespace "emptydir-385" to be "success or failure"
Oct 22 01:28:28.752: INFO: Pod "pod-6a836bd1-9cdd-4712-b780-7e7bb5c22b55": Phase="Pending", Reason="", readiness=false. Elapsed: 4.715289ms
Oct 22 01:28:30.757: INFO: Pod "pod-6a836bd1-9cdd-4712-b780-7e7bb5c22b55": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009725561s
STEP: Saw pod success
Oct 22 01:28:30.757: INFO: Pod "pod-6a836bd1-9cdd-4712-b780-7e7bb5c22b55" satisfied condition "success or failure"
Oct 22 01:28:30.760: INFO: Trying to get logs from node mip-bd-vm41.mip.storage.hpecorp.net pod pod-6a836bd1-9cdd-4712-b780-7e7bb5c22b55 container test-container: <nil>
STEP: delete the pod
Oct 22 01:28:30.783: INFO: Waiting for pod pod-6a836bd1-9cdd-4712-b780-7e7bb5c22b55 to disappear
Oct 22 01:28:30.788: INFO: Pod pod-6a836bd1-9cdd-4712-b780-7e7bb5c22b55 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 01:28:30.788: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-385" for this suite.
Oct 22 01:28:36.811: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 01:28:36.977: INFO: namespace emptydir-385 deletion completed in 6.183644755s

• [SLOW TEST:8.282 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 01:28:36.977: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Oct 22 01:28:37.030: INFO: Creating deployment "test-recreate-deployment"
Oct 22 01:28:37.037: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Oct 22 01:28:37.065: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
Oct 22 01:28:39.076: INFO: Waiting deployment "test-recreate-deployment" to complete
Oct 22 01:28:39.079: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Oct 22 01:28:39.090: INFO: Updating deployment test-recreate-deployment
Oct 22 01:28:39.090: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
Oct 22 01:28:39.180: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment,GenerateName:,Namespace:deployment-1178,SelfLink:/apis/apps/v1/namespaces/deployment-1178/deployments/test-recreate-deployment,UID:dd672fce-8281-44fe-a5fd-06d32f66295f,ResourceVersion:30140,Generation:2,CreationTimestamp:2019-10-22 01:28:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[{Available False 2019-10-22 01:28:39 +0000 UTC 2019-10-22 01:28:39 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-10-22 01:28:39 +0000 UTC 2019-10-22 01:28:37 +0000 UTC ReplicaSetUpdated ReplicaSet "test-recreate-deployment-5c8c9cc69d" is progressing.}],ReadyReplicas:0,CollisionCount:nil,},}

Oct 22 01:28:39.185: INFO: New ReplicaSet "test-recreate-deployment-5c8c9cc69d" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-5c8c9cc69d,GenerateName:,Namespace:deployment-1178,SelfLink:/apis/apps/v1/namespaces/deployment-1178/replicasets/test-recreate-deployment-5c8c9cc69d,UID:e2c2a615-d1b3-407a-b4f0-70d3be38ef3a,ResourceVersion:30137,Generation:1,CreationTimestamp:2019-10-22 01:28:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5c8c9cc69d,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment dd672fce-8281-44fe-a5fd-06d32f66295f 0xc002ec9de7 0xc002ec9de8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 5c8c9cc69d,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5c8c9cc69d,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Oct 22 01:28:39.185: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Oct 22 01:28:39.185: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-6df85df6b9,GenerateName:,Namespace:deployment-1178,SelfLink:/apis/apps/v1/namespaces/deployment-1178/replicasets/test-recreate-deployment-6df85df6b9,UID:1dd13bfb-e7d0-45b0-bed1-157695de6ddf,ResourceVersion:30129,Generation:2,CreationTimestamp:2019-10-22 01:28:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 6df85df6b9,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment dd672fce-8281-44fe-a5fd-06d32f66295f 0xc002ec9eb7 0xc002ec9eb8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 6df85df6b9,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 6df85df6b9,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Oct 22 01:28:39.192: INFO: Pod "test-recreate-deployment-5c8c9cc69d-tlps5" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-5c8c9cc69d-tlps5,GenerateName:test-recreate-deployment-5c8c9cc69d-,Namespace:deployment-1178,SelfLink:/api/v1/namespaces/deployment-1178/pods/test-recreate-deployment-5c8c9cc69d-tlps5,UID:2d5e0821-e41a-49ff-b3d3-92363f82ada6,ResourceVersion:30141,Generation:0,CreationTimestamp:2019-10-22 01:28:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5c8c9cc69d,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-recreate-deployment-5c8c9cc69d e2c2a615-d1b3-407a-b4f0-70d3be38ef3a 0xc00233a7a7 0xc00233a7a8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-4jj5h {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4jj5h,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4jj5h true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:mip-bd-vm41.mip.storage.hpecorp.net,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00233a810} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00233a830}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-22 01:28:39 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-22 01:28:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-22 01:28:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-22 01:28:39 +0000 UTC  }],Message:,Reason:,HostIP:16.143.20.138,PodIP:,StartTime:2019-10-22 01:28:39 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 01:28:39.192: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-1178" for this suite.
Oct 22 01:28:45.216: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 01:28:45.367: INFO: namespace deployment-1178 deletion completed in 6.169136802s

• [SLOW TEST:8.390 seconds]
[sig-apps] Deployment
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-network] DNS 
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 01:28:45.367: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-5347.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-5347.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-5347.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-5347.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-5347.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-5347.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe /etc/hosts
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Oct 22 01:28:47.485: INFO: DNS probes using dns-5347/dns-test-e43d2b96-79f5-4ef9-a4a1-6b0632b618e5 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 01:28:47.500: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-5347" for this suite.
Oct 22 01:28:53.525: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 01:28:53.674: INFO: namespace dns-5347 deletion completed in 6.168937721s

• [SLOW TEST:8.307 seconds]
[sig-network] DNS
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 01:28:53.676: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Oct 22 01:28:53.729: INFO: Waiting up to 5m0s for pod "downward-api-cc61730f-48e4-4171-a571-d38a5274cf22" in namespace "downward-api-3662" to be "success or failure"
Oct 22 01:28:53.733: INFO: Pod "downward-api-cc61730f-48e4-4171-a571-d38a5274cf22": Phase="Pending", Reason="", readiness=false. Elapsed: 4.26226ms
Oct 22 01:28:55.739: INFO: Pod "downward-api-cc61730f-48e4-4171-a571-d38a5274cf22": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009936332s
STEP: Saw pod success
Oct 22 01:28:55.739: INFO: Pod "downward-api-cc61730f-48e4-4171-a571-d38a5274cf22" satisfied condition "success or failure"
Oct 22 01:28:55.742: INFO: Trying to get logs from node mip-bd-vm41.mip.storage.hpecorp.net pod downward-api-cc61730f-48e4-4171-a571-d38a5274cf22 container dapi-container: <nil>
STEP: delete the pod
Oct 22 01:28:55.770: INFO: Waiting for pod downward-api-cc61730f-48e4-4171-a571-d38a5274cf22 to disappear
Oct 22 01:28:55.773: INFO: Pod downward-api-cc61730f-48e4-4171-a571-d38a5274cf22 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 01:28:55.773: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3662" for this suite.
Oct 22 01:29:01.794: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 01:29:01.939: INFO: namespace downward-api-3662 deletion completed in 6.160624362s

• [SLOW TEST:8.263 seconds]
[sig-node] Downward API
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 01:29:01.939: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0666 on node default medium
Oct 22 01:29:01.993: INFO: Waiting up to 5m0s for pod "pod-34779367-233a-4836-aa75-71fe02ae1726" in namespace "emptydir-348" to be "success or failure"
Oct 22 01:29:01.998: INFO: Pod "pod-34779367-233a-4836-aa75-71fe02ae1726": Phase="Pending", Reason="", readiness=false. Elapsed: 5.126509ms
Oct 22 01:29:04.004: INFO: Pod "pod-34779367-233a-4836-aa75-71fe02ae1726": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011214728s
STEP: Saw pod success
Oct 22 01:29:04.004: INFO: Pod "pod-34779367-233a-4836-aa75-71fe02ae1726" satisfied condition "success or failure"
Oct 22 01:29:04.008: INFO: Trying to get logs from node mip-bd-vm40.mip.storage.hpecorp.net pod pod-34779367-233a-4836-aa75-71fe02ae1726 container test-container: <nil>
STEP: delete the pod
Oct 22 01:29:04.048: INFO: Waiting for pod pod-34779367-233a-4836-aa75-71fe02ae1726 to disappear
Oct 22 01:29:04.051: INFO: Pod pod-34779367-233a-4836-aa75-71fe02ae1726 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 01:29:04.051: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-348" for this suite.
Oct 22 01:29:10.072: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 01:29:10.229: INFO: namespace emptydir-348 deletion completed in 6.171439466s

• [SLOW TEST:8.290 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 01:29:10.230: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-secret-jcw5
STEP: Creating a pod to test atomic-volume-subpath
Oct 22 01:29:10.290: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-jcw5" in namespace "subpath-8167" to be "success or failure"
Oct 22 01:29:10.296: INFO: Pod "pod-subpath-test-secret-jcw5": Phase="Pending", Reason="", readiness=false. Elapsed: 6.564794ms
Oct 22 01:29:12.301: INFO: Pod "pod-subpath-test-secret-jcw5": Phase="Running", Reason="", readiness=true. Elapsed: 2.011348788s
Oct 22 01:29:14.307: INFO: Pod "pod-subpath-test-secret-jcw5": Phase="Running", Reason="", readiness=true. Elapsed: 4.016954213s
Oct 22 01:29:16.312: INFO: Pod "pod-subpath-test-secret-jcw5": Phase="Running", Reason="", readiness=true. Elapsed: 6.022555208s
Oct 22 01:29:18.317: INFO: Pod "pod-subpath-test-secret-jcw5": Phase="Running", Reason="", readiness=true. Elapsed: 8.027626367s
Oct 22 01:29:20.323: INFO: Pod "pod-subpath-test-secret-jcw5": Phase="Running", Reason="", readiness=true. Elapsed: 10.033509328s
Oct 22 01:29:22.329: INFO: Pod "pod-subpath-test-secret-jcw5": Phase="Running", Reason="", readiness=true. Elapsed: 12.039098121s
Oct 22 01:29:24.334: INFO: Pod "pod-subpath-test-secret-jcw5": Phase="Running", Reason="", readiness=true. Elapsed: 14.043915987s
Oct 22 01:29:26.340: INFO: Pod "pod-subpath-test-secret-jcw5": Phase="Running", Reason="", readiness=true. Elapsed: 16.050099987s
Oct 22 01:29:28.345: INFO: Pod "pod-subpath-test-secret-jcw5": Phase="Running", Reason="", readiness=true. Elapsed: 18.055493154s
Oct 22 01:29:30.351: INFO: Pod "pod-subpath-test-secret-jcw5": Phase="Running", Reason="", readiness=true. Elapsed: 20.060991048s
Oct 22 01:29:32.357: INFO: Pod "pod-subpath-test-secret-jcw5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.066847392s
STEP: Saw pod success
Oct 22 01:29:32.357: INFO: Pod "pod-subpath-test-secret-jcw5" satisfied condition "success or failure"
Oct 22 01:29:32.362: INFO: Trying to get logs from node mip-bd-vm41.mip.storage.hpecorp.net pod pod-subpath-test-secret-jcw5 container test-container-subpath-secret-jcw5: <nil>
STEP: delete the pod
Oct 22 01:29:32.391: INFO: Waiting for pod pod-subpath-test-secret-jcw5 to disappear
Oct 22 01:29:32.397: INFO: Pod pod-subpath-test-secret-jcw5 no longer exists
STEP: Deleting pod pod-subpath-test-secret-jcw5
Oct 22 01:29:32.397: INFO: Deleting pod "pod-subpath-test-secret-jcw5" in namespace "subpath-8167"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 01:29:32.401: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-8167" for this suite.
Oct 22 01:29:38.422: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 01:29:38.576: INFO: namespace subpath-8167 deletion completed in 6.169716934s

• [SLOW TEST:28.346 seconds]
[sig-storage] Subpath
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with secret pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 01:29:38.576: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating pod
Oct 22 01:29:40.655: INFO: Pod pod-hostip-3d708c76-ca50-4193-919a-52dcc616e67c has hostIP: 16.143.20.137
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 01:29:40.655: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-6041" for this suite.
Oct 22 01:30:02.677: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 01:30:02.836: INFO: namespace pods-6041 deletion completed in 22.175274897s

• [SLOW TEST:24.260 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 01:30:02.837: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Oct 22 01:30:02.909: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Oct 22 01:30:02.923: INFO: Number of nodes with available pods: 0
Oct 22 01:30:02.923: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Oct 22 01:30:02.945: INFO: Number of nodes with available pods: 0
Oct 22 01:30:02.945: INFO: Node mip-bd-vm40.mip.storage.hpecorp.net is running more than one daemon pod
Oct 22 01:30:03.949: INFO: Number of nodes with available pods: 0
Oct 22 01:30:03.950: INFO: Node mip-bd-vm40.mip.storage.hpecorp.net is running more than one daemon pod
Oct 22 01:30:04.951: INFO: Number of nodes with available pods: 1
Oct 22 01:30:04.951: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Oct 22 01:30:04.971: INFO: Number of nodes with available pods: 1
Oct 22 01:30:04.971: INFO: Number of running nodes: 0, number of available pods: 1
Oct 22 01:30:05.978: INFO: Number of nodes with available pods: 0
Oct 22 01:30:05.978: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Oct 22 01:30:05.989: INFO: Number of nodes with available pods: 0
Oct 22 01:30:05.989: INFO: Node mip-bd-vm40.mip.storage.hpecorp.net is running more than one daemon pod
Oct 22 01:30:06.995: INFO: Number of nodes with available pods: 0
Oct 22 01:30:06.995: INFO: Node mip-bd-vm40.mip.storage.hpecorp.net is running more than one daemon pod
Oct 22 01:30:07.995: INFO: Number of nodes with available pods: 0
Oct 22 01:30:07.995: INFO: Node mip-bd-vm40.mip.storage.hpecorp.net is running more than one daemon pod
Oct 22 01:30:08.998: INFO: Number of nodes with available pods: 0
Oct 22 01:30:08.998: INFO: Node mip-bd-vm40.mip.storage.hpecorp.net is running more than one daemon pod
Oct 22 01:30:09.995: INFO: Number of nodes with available pods: 0
Oct 22 01:30:09.995: INFO: Node mip-bd-vm40.mip.storage.hpecorp.net is running more than one daemon pod
Oct 22 01:30:10.995: INFO: Number of nodes with available pods: 0
Oct 22 01:30:10.995: INFO: Node mip-bd-vm40.mip.storage.hpecorp.net is running more than one daemon pod
Oct 22 01:30:11.995: INFO: Number of nodes with available pods: 0
Oct 22 01:30:11.995: INFO: Node mip-bd-vm40.mip.storage.hpecorp.net is running more than one daemon pod
Oct 22 01:30:12.995: INFO: Number of nodes with available pods: 1
Oct 22 01:30:12.995: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-9879, will wait for the garbage collector to delete the pods
Oct 22 01:30:13.068: INFO: Deleting DaemonSet.extensions daemon-set took: 10.481673ms
Oct 22 01:30:13.468: INFO: Terminating DaemonSet.extensions daemon-set pods took: 400.23928ms
Oct 22 01:30:20.972: INFO: Number of nodes with available pods: 0
Oct 22 01:30:20.972: INFO: Number of running nodes: 0, number of available pods: 0
Oct 22 01:30:20.976: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-9879/daemonsets","resourceVersion":"30515"},"items":null}

Oct 22 01:30:20.979: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-9879/pods","resourceVersion":"30515"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 01:30:21.003: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-9879" for this suite.
Oct 22 01:30:27.028: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 01:30:27.183: INFO: namespace daemonsets-9879 deletion completed in 6.176108828s

• [SLOW TEST:24.347 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 01:30:27.184: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Oct 22 01:30:27.244: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-5602,SelfLink:/api/v1/namespaces/watch-5602/configmaps/e2e-watch-test-watch-closed,UID:71eaf3ff-ccfb-4f5e-ad2d-6d1c98323c03,ResourceVersion:30547,Generation:0,CreationTimestamp:2019-10-22 01:30:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Oct 22 01:30:27.244: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-5602,SelfLink:/api/v1/namespaces/watch-5602/configmaps/e2e-watch-test-watch-closed,UID:71eaf3ff-ccfb-4f5e-ad2d-6d1c98323c03,ResourceVersion:30548,Generation:0,CreationTimestamp:2019-10-22 01:30:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Oct 22 01:30:27.260: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-5602,SelfLink:/api/v1/namespaces/watch-5602/configmaps/e2e-watch-test-watch-closed,UID:71eaf3ff-ccfb-4f5e-ad2d-6d1c98323c03,ResourceVersion:30549,Generation:0,CreationTimestamp:2019-10-22 01:30:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Oct 22 01:30:27.260: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-5602,SelfLink:/api/v1/namespaces/watch-5602/configmaps/e2e-watch-test-watch-closed,UID:71eaf3ff-ccfb-4f5e-ad2d-6d1c98323c03,ResourceVersion:30550,Generation:0,CreationTimestamp:2019-10-22 01:30:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 01:30:27.260: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-5602" for this suite.
Oct 22 01:30:33.278: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 01:30:33.463: INFO: namespace watch-5602 deletion completed in 6.198086729s

• [SLOW TEST:6.279 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 01:30:33.463: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Oct 22 01:30:33.508: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172996996 version'
Oct 22 01:30:33.650: INFO: stderr: ""
Oct 22 01:30:33.650: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"15\", GitVersion:\"v1.15.3\", GitCommit:\"2d3c76f9091b6bec110a5e63777c332469e0cba2\", GitTreeState:\"clean\", BuildDate:\"2019-08-19T11:13:54Z\", GoVersion:\"go1.12.9\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"15\", GitVersion:\"v1.15.3\", GitCommit:\"2d3c76f9091b6bec110a5e63777c332469e0cba2\", GitTreeState:\"clean\", BuildDate:\"2019-08-19T11:05:50Z\", GoVersion:\"go1.12.9\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 01:30:33.650: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6381" for this suite.
Oct 22 01:30:39.673: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 01:30:39.820: INFO: namespace kubectl-6381 deletion completed in 6.163791592s

• [SLOW TEST:6.357 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl version
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 01:30:39.820: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Oct 22 01:30:39.878: INFO: Waiting up to 5m0s for pod "downward-api-9419d948-e73e-454b-914d-5a3a07a67f9f" in namespace "downward-api-6656" to be "success or failure"
Oct 22 01:30:39.882: INFO: Pod "downward-api-9419d948-e73e-454b-914d-5a3a07a67f9f": Phase="Pending", Reason="", readiness=false. Elapsed: 3.71051ms
Oct 22 01:30:41.889: INFO: Pod "downward-api-9419d948-e73e-454b-914d-5a3a07a67f9f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010863095s
STEP: Saw pod success
Oct 22 01:30:41.889: INFO: Pod "downward-api-9419d948-e73e-454b-914d-5a3a07a67f9f" satisfied condition "success or failure"
Oct 22 01:30:41.893: INFO: Trying to get logs from node mip-bd-vm41.mip.storage.hpecorp.net pod downward-api-9419d948-e73e-454b-914d-5a3a07a67f9f container dapi-container: <nil>
STEP: delete the pod
Oct 22 01:30:41.922: INFO: Waiting for pod downward-api-9419d948-e73e-454b-914d-5a3a07a67f9f to disappear
Oct 22 01:30:41.926: INFO: Pod downward-api-9419d948-e73e-454b-914d-5a3a07a67f9f no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 01:30:41.926: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6656" for this suite.
Oct 22 01:30:47.944: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 01:30:48.086: INFO: namespace downward-api-6656 deletion completed in 6.154592596s

• [SLOW TEST:8.266 seconds]
[sig-node] Downward API
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 01:30:48.087: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name s-test-opt-del-618175f8-9dbf-444d-bac2-d79a0fbb1e31
STEP: Creating secret with name s-test-opt-upd-bef2e55e-b1ab-4db1-a45f-e65a73872cae
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-618175f8-9dbf-444d-bac2-d79a0fbb1e31
STEP: Updating secret s-test-opt-upd-bef2e55e-b1ab-4db1-a45f-e65a73872cae
STEP: Creating secret with name s-test-opt-create-c128f1f9-9c0e-4f66-b5f6-c9445b7009f8
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 01:32:18.174: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5537" for this suite.
Oct 22 01:32:40.195: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 01:32:40.352: INFO: namespace projected-5537 deletion completed in 22.173124283s

• [SLOW TEST:112.266 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 22 01:32:40.352: INFO: >>> kubeConfig: /tmp/kubeconfig-172996996
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Oct 22 01:32:40.410: INFO: Waiting up to 5m0s for pod "downwardapi-volume-7e54ffef-30dd-4bc0-b85a-ff73ecc92b0d" in namespace "downward-api-2364" to be "success or failure"
Oct 22 01:32:40.415: INFO: Pod "downwardapi-volume-7e54ffef-30dd-4bc0-b85a-ff73ecc92b0d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.631755ms
Oct 22 01:32:42.420: INFO: Pod "downwardapi-volume-7e54ffef-30dd-4bc0-b85a-ff73ecc92b0d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01004261s
STEP: Saw pod success
Oct 22 01:32:42.421: INFO: Pod "downwardapi-volume-7e54ffef-30dd-4bc0-b85a-ff73ecc92b0d" satisfied condition "success or failure"
Oct 22 01:32:42.424: INFO: Trying to get logs from node mip-bd-vm41.mip.storage.hpecorp.net pod downwardapi-volume-7e54ffef-30dd-4bc0-b85a-ff73ecc92b0d container client-container: <nil>
STEP: delete the pod
Oct 22 01:32:42.459: INFO: Waiting for pod downwardapi-volume-7e54ffef-30dd-4bc0-b85a-ff73ecc92b0d to disappear
Oct 22 01:32:42.464: INFO: Pod downwardapi-volume-7e54ffef-30dd-4bc0-b85a-ff73ecc92b0d no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 22 01:32:42.464: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2364" for this suite.
Oct 22 01:32:48.484: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 22 01:32:48.641: INFO: namespace downward-api-2364 deletion completed in 6.171616702s

• [SLOW TEST:8.288 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSOct 22 01:32:48.641: INFO: Running AfterSuite actions on all nodes
Oct 22 01:32:48.641: INFO: Running AfterSuite actions on node 1
Oct 22 01:32:48.641: INFO: Skipping dumping logs from cluster

Ran 215 of 4413 Specs in 5934.024 seconds
SUCCESS! -- 215 Passed | 0 Failed | 0 Pending | 4198 Skipped
PASS

Ginkgo ran 1 suite in 1h38m56.466048023s
Test Suite Passed
