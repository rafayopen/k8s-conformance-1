I0803 17:37:16.078490      17 test_context.go:406] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-322553265
I0803 17:37:16.078585      17 e2e.go:241] Starting e2e run "58b31e28-0c16-4685-8313-d0347234ae20" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1564853834 - Will randomize all specs
Will run 215 of 4413 specs

Aug  3 17:37:16.272: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
Aug  3 17:37:16.274: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Aug  3 17:37:16.336: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Aug  3 17:37:16.399: INFO: 21 / 21 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Aug  3 17:37:16.400: INFO: expected 9 pod replicas in namespace 'kube-system', 9 are Running and Ready.
Aug  3 17:37:16.400: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Aug  3 17:37:16.418: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'calico-node' (0 seconds elapsed)
Aug  3 17:37:16.418: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'ibm-keepalived-watcher' (0 seconds elapsed)
Aug  3 17:37:16.418: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'ibm-kube-fluentd' (0 seconds elapsed)
Aug  3 17:37:16.418: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'ibm-master-proxy' (0 seconds elapsed)
Aug  3 17:37:16.418: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'node-local-dns' (0 seconds elapsed)
Aug  3 17:37:16.418: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'nvidia-driver-installer' (0 seconds elapsed)
Aug  3 17:37:16.418: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'nvidia-gpu-device-plugin' (0 seconds elapsed)
Aug  3 17:37:16.418: INFO: e2e test version: v1.15.1
Aug  3 17:37:16.421: INFO: kube-apiserver version: v1.15.1+IKS
SSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 17:37:16.421: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename container-runtime
Aug  3 17:37:16.514: INFO: Found PodSecurityPolicies; assuming PodSecurityPolicy is enabled.
Aug  3 17:37:16.539: INFO: Found ClusterRoles; assuming RBAC is enabled.
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-7051
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the container
STEP: wait for the container to reach Failed
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Aug  3 17:37:18.896: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 17:37:18.936: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-7051" for this suite.
Aug  3 17:37:24.999: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 17:37:25.324: INFO: namespace container-runtime-7051 deletion completed in 6.373798191s

• [SLOW TEST:8.903 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  blackbox test
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
    on terminated container
    /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:129
      should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 17:37:25.324: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-196
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 17:37:28.628: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-196" for this suite.
Aug  3 17:37:52.694: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 17:37:53.015: INFO: namespace replication-controller-196 deletion completed in 24.364049038s

• [SLOW TEST:27.691 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 17:37:53.016: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-1592
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Aug  3 17:37:53.247: INFO: Waiting up to 5m0s for pod "downwardapi-volume-547173c9-491e-46ce-9d0a-1332dfdb8bef" in namespace "downward-api-1592" to be "success or failure"
Aug  3 17:37:53.259: INFO: Pod "downwardapi-volume-547173c9-491e-46ce-9d0a-1332dfdb8bef": Phase="Pending", Reason="", readiness=false. Elapsed: 12.691578ms
Aug  3 17:37:55.269: INFO: Pod "downwardapi-volume-547173c9-491e-46ce-9d0a-1332dfdb8bef": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022314995s
Aug  3 17:37:57.283: INFO: Pod "downwardapi-volume-547173c9-491e-46ce-9d0a-1332dfdb8bef": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.03657s
STEP: Saw pod success
Aug  3 17:37:57.283: INFO: Pod "downwardapi-volume-547173c9-491e-46ce-9d0a-1332dfdb8bef" satisfied condition "success or failure"
Aug  3 17:37:57.294: INFO: Trying to get logs from node 10.188.31.32 pod downwardapi-volume-547173c9-491e-46ce-9d0a-1332dfdb8bef container client-container: <nil>
STEP: delete the pod
Aug  3 17:37:57.346: INFO: Waiting for pod downwardapi-volume-547173c9-491e-46ce-9d0a-1332dfdb8bef to disappear
Aug  3 17:37:57.353: INFO: Pod downwardapi-volume-547173c9-491e-46ce-9d0a-1332dfdb8bef no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 17:37:57.354: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1592" for this suite.
Aug  3 17:38:03.394: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 17:38:03.758: INFO: namespace downward-api-1592 deletion completed in 6.393571906s

• [SLOW TEST:10.742 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 17:38:03.758: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7204
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name projected-secret-test-a4eab8a9-6303-451e-9508-b10bf0f3c6c7
STEP: Creating a pod to test consume secrets
Aug  3 17:38:04.003: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-69dd35d0-62c3-470a-96d7-2a943a64ccb5" in namespace "projected-7204" to be "success or failure"
Aug  3 17:38:04.010: INFO: Pod "pod-projected-secrets-69dd35d0-62c3-470a-96d7-2a943a64ccb5": Phase="Pending", Reason="", readiness=false. Elapsed: 7.246968ms
Aug  3 17:38:06.018: INFO: Pod "pod-projected-secrets-69dd35d0-62c3-470a-96d7-2a943a64ccb5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015116291s
Aug  3 17:38:08.028: INFO: Pod "pod-projected-secrets-69dd35d0-62c3-470a-96d7-2a943a64ccb5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.025554309s
STEP: Saw pod success
Aug  3 17:38:08.028: INFO: Pod "pod-projected-secrets-69dd35d0-62c3-470a-96d7-2a943a64ccb5" satisfied condition "success or failure"
Aug  3 17:38:08.049: INFO: Trying to get logs from node 10.188.31.32 pod pod-projected-secrets-69dd35d0-62c3-470a-96d7-2a943a64ccb5 container secret-volume-test: <nil>
STEP: delete the pod
Aug  3 17:38:08.093: INFO: Waiting for pod pod-projected-secrets-69dd35d0-62c3-470a-96d7-2a943a64ccb5 to disappear
Aug  3 17:38:08.100: INFO: Pod pod-projected-secrets-69dd35d0-62c3-470a-96d7-2a943a64ccb5 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 17:38:08.100: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7204" for this suite.
Aug  3 17:38:14.144: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 17:38:14.500: INFO: namespace projected-7204 deletion completed in 6.387171809s

• [SLOW TEST:10.741 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 17:38:14.501: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-7062
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
Aug  3 17:38:14.742: INFO: observed the pod list
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 17:38:26.986: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-7062" for this suite.
Aug  3 17:38:33.038: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 17:38:33.403: INFO: namespace pods-7062 deletion completed in 6.402965417s

• [SLOW TEST:18.903 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Delete Grace Period 
  should be submitted and removed [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 17:38:33.405: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-6940
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Delete Grace Period
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:47
[It] should be submitted and removed [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: setting up selector
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
Aug  3 17:38:35.692: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-322553265 proxy -p 0'
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
Aug  3 17:38:40.852: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 17:38:40.860: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-6940" for this suite.
Aug  3 17:38:46.900: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 17:38:47.312: INFO: namespace pods-6940 deletion completed in 6.441794599s

• [SLOW TEST:13.907 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  [k8s.io] Delete Grace Period
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should be submitted and removed [Conformance]
    /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 17:38:47.313: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-2337
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0666 on tmpfs
Aug  3 17:38:47.561: INFO: Waiting up to 5m0s for pod "pod-f26c4e0f-0838-4221-a567-0098b010ce32" in namespace "emptydir-2337" to be "success or failure"
Aug  3 17:38:47.569: INFO: Pod "pod-f26c4e0f-0838-4221-a567-0098b010ce32": Phase="Pending", Reason="", readiness=false. Elapsed: 7.96711ms
Aug  3 17:38:49.577: INFO: Pod "pod-f26c4e0f-0838-4221-a567-0098b010ce32": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015849585s
STEP: Saw pod success
Aug  3 17:38:49.577: INFO: Pod "pod-f26c4e0f-0838-4221-a567-0098b010ce32" satisfied condition "success or failure"
Aug  3 17:38:49.589: INFO: Trying to get logs from node 10.188.31.32 pod pod-f26c4e0f-0838-4221-a567-0098b010ce32 container test-container: <nil>
STEP: delete the pod
Aug  3 17:38:49.638: INFO: Waiting for pod pod-f26c4e0f-0838-4221-a567-0098b010ce32 to disappear
Aug  3 17:38:49.645: INFO: Pod pod-f26c4e0f-0838-4221-a567-0098b010ce32 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 17:38:49.646: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2337" for this suite.
Aug  3 17:38:55.689: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 17:38:56.024: INFO: namespace emptydir-2337 deletion completed in 6.367434869s

• [SLOW TEST:8.711 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 17:38:56.025: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-5271
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Aug  3 17:38:56.233: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 17:39:00.326: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-5271" for this suite.
Aug  3 17:39:40.383: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 17:39:40.816: INFO: namespace pods-5271 deletion completed in 40.464382313s

• [SLOW TEST:44.791 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 17:39:40.816: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-173
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Aug  3 17:39:41.054: INFO: Waiting up to 5m0s for pod "downwardapi-volume-52f7909c-aab1-4bcd-85ba-53fa21bad2c9" in namespace "downward-api-173" to be "success or failure"
Aug  3 17:39:41.063: INFO: Pod "downwardapi-volume-52f7909c-aab1-4bcd-85ba-53fa21bad2c9": Phase="Pending", Reason="", readiness=false. Elapsed: 8.55353ms
Aug  3 17:39:43.072: INFO: Pod "downwardapi-volume-52f7909c-aab1-4bcd-85ba-53fa21bad2c9": Phase="Running", Reason="", readiness=true. Elapsed: 2.017238277s
Aug  3 17:39:45.079: INFO: Pod "downwardapi-volume-52f7909c-aab1-4bcd-85ba-53fa21bad2c9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.024898567s
STEP: Saw pod success
Aug  3 17:39:45.079: INFO: Pod "downwardapi-volume-52f7909c-aab1-4bcd-85ba-53fa21bad2c9" satisfied condition "success or failure"
Aug  3 17:39:45.087: INFO: Trying to get logs from node 10.188.31.32 pod downwardapi-volume-52f7909c-aab1-4bcd-85ba-53fa21bad2c9 container client-container: <nil>
STEP: delete the pod
Aug  3 17:39:45.136: INFO: Waiting for pod downwardapi-volume-52f7909c-aab1-4bcd-85ba-53fa21bad2c9 to disappear
Aug  3 17:39:45.144: INFO: Pod downwardapi-volume-52f7909c-aab1-4bcd-85ba-53fa21bad2c9 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 17:39:45.144: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-173" for this suite.
Aug  3 17:39:51.186: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 17:39:51.527: INFO: namespace downward-api-173 deletion completed in 6.37231364s

• [SLOW TEST:10.711 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 17:39:51.528: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-6454
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 17:39:53.806: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-6454" for this suite.
Aug  3 17:40:33.851: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 17:40:34.205: INFO: namespace kubelet-test-6454 deletion completed in 40.387092799s

• [SLOW TEST:42.678 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when scheduling a read only busybox container
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:187
    should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 17:40:34.205: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-251
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-a07bbc91-b1b9-4536-b644-2c5dd67a3689
STEP: Creating a pod to test consume secrets
Aug  3 17:40:34.470: INFO: Waiting up to 5m0s for pod "pod-secrets-1a6cb699-2788-4475-abc2-193a511195c4" in namespace "secrets-251" to be "success or failure"
Aug  3 17:40:34.479: INFO: Pod "pod-secrets-1a6cb699-2788-4475-abc2-193a511195c4": Phase="Pending", Reason="", readiness=false. Elapsed: 8.408427ms
Aug  3 17:40:36.486: INFO: Pod "pod-secrets-1a6cb699-2788-4475-abc2-193a511195c4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016275436s
Aug  3 17:40:38.495: INFO: Pod "pod-secrets-1a6cb699-2788-4475-abc2-193a511195c4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.024669452s
STEP: Saw pod success
Aug  3 17:40:38.495: INFO: Pod "pod-secrets-1a6cb699-2788-4475-abc2-193a511195c4" satisfied condition "success or failure"
Aug  3 17:40:38.509: INFO: Trying to get logs from node 10.188.31.32 pod pod-secrets-1a6cb699-2788-4475-abc2-193a511195c4 container secret-volume-test: <nil>
STEP: delete the pod
Aug  3 17:40:38.550: INFO: Waiting for pod pod-secrets-1a6cb699-2788-4475-abc2-193a511195c4 to disappear
Aug  3 17:40:38.557: INFO: Pod pod-secrets-1a6cb699-2788-4475-abc2-193a511195c4 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 17:40:38.557: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-251" for this suite.
Aug  3 17:40:44.602: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 17:40:44.903: INFO: namespace secrets-251 deletion completed in 6.333968764s

• [SLOW TEST:10.698 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 17:40:44.905: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-6081
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-e88b2ae8-7095-42d5-828b-005ee7144197
STEP: Creating a pod to test consume configMaps
Aug  3 17:40:45.153: INFO: Waiting up to 5m0s for pod "pod-configmaps-615a3b3c-889e-4e51-9fa8-0439d0e9fcd0" in namespace "configmap-6081" to be "success or failure"
Aug  3 17:40:45.161: INFO: Pod "pod-configmaps-615a3b3c-889e-4e51-9fa8-0439d0e9fcd0": Phase="Pending", Reason="", readiness=false. Elapsed: 7.864752ms
Aug  3 17:40:47.169: INFO: Pod "pod-configmaps-615a3b3c-889e-4e51-9fa8-0439d0e9fcd0": Phase="Running", Reason="", readiness=true. Elapsed: 2.016006657s
Aug  3 17:40:49.182: INFO: Pod "pod-configmaps-615a3b3c-889e-4e51-9fa8-0439d0e9fcd0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.028688054s
STEP: Saw pod success
Aug  3 17:40:49.182: INFO: Pod "pod-configmaps-615a3b3c-889e-4e51-9fa8-0439d0e9fcd0" satisfied condition "success or failure"
Aug  3 17:40:49.198: INFO: Trying to get logs from node 10.188.31.32 pod pod-configmaps-615a3b3c-889e-4e51-9fa8-0439d0e9fcd0 container configmap-volume-test: <nil>
STEP: delete the pod
Aug  3 17:40:49.248: INFO: Waiting for pod pod-configmaps-615a3b3c-889e-4e51-9fa8-0439d0e9fcd0 to disappear
Aug  3 17:40:49.255: INFO: Pod pod-configmaps-615a3b3c-889e-4e51-9fa8-0439d0e9fcd0 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 17:40:49.255: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6081" for this suite.
Aug  3 17:40:55.303: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 17:40:55.648: INFO: namespace configmap-6081 deletion completed in 6.383054578s

• [SLOW TEST:10.744 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 17:40:55.649: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-2265
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0777 on tmpfs
Aug  3 17:40:56.038: INFO: Waiting up to 5m0s for pod "pod-5510eea0-81ef-4e38-a673-8ea071848227" in namespace "emptydir-2265" to be "success or failure"
Aug  3 17:40:56.046: INFO: Pod "pod-5510eea0-81ef-4e38-a673-8ea071848227": Phase="Pending", Reason="", readiness=false. Elapsed: 7.967657ms
Aug  3 17:40:58.055: INFO: Pod "pod-5510eea0-81ef-4e38-a673-8ea071848227": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016555205s
STEP: Saw pod success
Aug  3 17:40:58.055: INFO: Pod "pod-5510eea0-81ef-4e38-a673-8ea071848227" satisfied condition "success or failure"
Aug  3 17:40:58.069: INFO: Trying to get logs from node 10.188.31.32 pod pod-5510eea0-81ef-4e38-a673-8ea071848227 container test-container: <nil>
STEP: delete the pod
Aug  3 17:40:58.114: INFO: Waiting for pod pod-5510eea0-81ef-4e38-a673-8ea071848227 to disappear
Aug  3 17:40:58.122: INFO: Pod pod-5510eea0-81ef-4e38-a673-8ea071848227 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 17:40:58.122: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2265" for this suite.
Aug  3 17:41:04.177: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 17:41:04.550: INFO: namespace emptydir-2265 deletion completed in 6.407169167s

• [SLOW TEST:8.901 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 17:41:04.551: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-6645
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
Aug  3 17:41:04.768: INFO: PodSpec: initContainers in spec.initContainers
Aug  3 17:41:51.764: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-1c92241c-f292-44a3-9699-587bf9d8e9d8", GenerateName:"", Namespace:"init-container-6645", SelfLink:"/api/v1/namespaces/init-container-6645/pods/pod-init-1c92241c-f292-44a3-9699-587bf9d8e9d8", UID:"c99e1c9b-a5a7-4559-ac09-4074b1d2f252", ResourceVersion:"31433", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63700450864, loc:(*time.Location)(0x80c0a20)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"768223651"}, Annotations:map[string]string{"kubernetes.io/psp":"e2e-test-privileged-psp"}, OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-jhkxg", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc001f79300), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-jhkxg", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-jhkxg", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-jhkxg", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc0022328e8), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"10.188.31.32", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc0026248a0), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc002232970)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc002232990)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc002232998), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc00223299c), PreemptionPolicy:(*v1.PreemptionPolicy)(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700450864, loc:(*time.Location)(0x80c0a20)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700450864, loc:(*time.Location)(0x80c0a20)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700450864, loc:(*time.Location)(0x80c0a20)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700450864, loc:(*time.Location)(0x80c0a20)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.188.31.32", PodIP:"172.30.72.72", StartTime:(*v1.Time)(0xc001b24140), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc002c24460)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc002c244d0)}, Ready:false, RestartCount:3, Image:"docker.io/library/busybox:1.29", ImageID:"docker.io/library/busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"containerd://e1924cdf0de372d595cba7c97f0c8ae3f45bea40b3f434cd52e776e9ff42083b"}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc001b24180), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:""}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc001b24160), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:""}}, QOSClass:"Guaranteed"}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 17:41:51.764: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-6645" for this suite.
Aug  3 17:42:15.813: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 17:42:16.134: INFO: namespace init-container-6645 deletion completed in 24.355897647s

• [SLOW TEST:71.583 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 17:42:16.135: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-9580
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Aug  3 17:42:16.397: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-9580,SelfLink:/api/v1/namespaces/watch-9580/configmaps/e2e-watch-test-watch-closed,UID:a90bf77b-4470-40cf-9db6-f3d83447860d,ResourceVersion:31505,Generation:0,CreationTimestamp:2019-08-03 17:42:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Aug  3 17:42:16.397: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-9580,SelfLink:/api/v1/namespaces/watch-9580/configmaps/e2e-watch-test-watch-closed,UID:a90bf77b-4470-40cf-9db6-f3d83447860d,ResourceVersion:31506,Generation:0,CreationTimestamp:2019-08-03 17:42:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Aug  3 17:42:16.435: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-9580,SelfLink:/api/v1/namespaces/watch-9580/configmaps/e2e-watch-test-watch-closed,UID:a90bf77b-4470-40cf-9db6-f3d83447860d,ResourceVersion:31507,Generation:0,CreationTimestamp:2019-08-03 17:42:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Aug  3 17:42:16.435: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-9580,SelfLink:/api/v1/namespaces/watch-9580/configmaps/e2e-watch-test-watch-closed,UID:a90bf77b-4470-40cf-9db6-f3d83447860d,ResourceVersion:31508,Generation:0,CreationTimestamp:2019-08-03 17:42:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 17:42:16.435: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-9580" for this suite.
Aug  3 17:42:22.476: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 17:42:22.905: INFO: namespace watch-9580 deletion completed in 6.460732504s

• [SLOW TEST:6.770 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 17:42:22.905: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-544
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test substitution in container's args
Aug  3 17:42:23.153: INFO: Waiting up to 5m0s for pod "var-expansion-5636cc38-0690-42ac-a660-4d796c34cf88" in namespace "var-expansion-544" to be "success or failure"
Aug  3 17:42:23.176: INFO: Pod "var-expansion-5636cc38-0690-42ac-a660-4d796c34cf88": Phase="Pending", Reason="", readiness=false. Elapsed: 23.003972ms
Aug  3 17:42:25.189: INFO: Pod "var-expansion-5636cc38-0690-42ac-a660-4d796c34cf88": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.035447426s
STEP: Saw pod success
Aug  3 17:42:25.189: INFO: Pod "var-expansion-5636cc38-0690-42ac-a660-4d796c34cf88" satisfied condition "success or failure"
Aug  3 17:42:25.196: INFO: Trying to get logs from node 10.188.31.32 pod var-expansion-5636cc38-0690-42ac-a660-4d796c34cf88 container dapi-container: <nil>
STEP: delete the pod
Aug  3 17:42:25.237: INFO: Waiting for pod var-expansion-5636cc38-0690-42ac-a660-4d796c34cf88 to disappear
Aug  3 17:42:25.244: INFO: Pod var-expansion-5636cc38-0690-42ac-a660-4d796c34cf88 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 17:42:25.244: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-544" for this suite.
Aug  3 17:42:31.289: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 17:42:31.632: INFO: namespace var-expansion-544 deletion completed in 6.375536902s

• [SLOW TEST:8.727 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 17:42:31.633: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-7344
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-429b744d-ac1d-4bd8-b37c-7d0fa28d957c
STEP: Creating a pod to test consume secrets
Aug  3 17:42:32.001: INFO: Waiting up to 5m0s for pod "pod-secrets-280868bc-b70b-44a6-b2dd-411193c1ac6d" in namespace "secrets-7344" to be "success or failure"
Aug  3 17:42:32.016: INFO: Pod "pod-secrets-280868bc-b70b-44a6-b2dd-411193c1ac6d": Phase="Pending", Reason="", readiness=false. Elapsed: 15.044453ms
Aug  3 17:42:34.029: INFO: Pod "pod-secrets-280868bc-b70b-44a6-b2dd-411193c1ac6d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.02772147s
STEP: Saw pod success
Aug  3 17:42:34.029: INFO: Pod "pod-secrets-280868bc-b70b-44a6-b2dd-411193c1ac6d" satisfied condition "success or failure"
Aug  3 17:42:34.055: INFO: Trying to get logs from node 10.188.31.32 pod pod-secrets-280868bc-b70b-44a6-b2dd-411193c1ac6d container secret-volume-test: <nil>
STEP: delete the pod
Aug  3 17:42:34.095: INFO: Waiting for pod pod-secrets-280868bc-b70b-44a6-b2dd-411193c1ac6d to disappear
Aug  3 17:42:34.109: INFO: Pod pod-secrets-280868bc-b70b-44a6-b2dd-411193c1ac6d no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 17:42:34.109: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7344" for this suite.
Aug  3 17:42:40.154: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 17:42:40.506: INFO: namespace secrets-7344 deletion completed in 6.38575828s

• [SLOW TEST:8.874 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 17:42:40.507: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-2501
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-2501
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating stateful set ss in namespace statefulset-2501
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-2501
Aug  3 17:42:40.748: INFO: Found 0 stateful pods, waiting for 1
Aug  3 17:42:50.758: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Aug  3 17:42:50.769: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 exec --namespace=statefulset-2501 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Aug  3 17:42:51.322: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Aug  3 17:42:51.323: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Aug  3 17:42:51.323: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Aug  3 17:42:51.331: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Aug  3 17:43:01.342: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Aug  3 17:43:01.342: INFO: Waiting for statefulset status.replicas updated to 0
Aug  3 17:43:01.397: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
Aug  3 17:43:01.397: INFO: ss-0  10.188.31.32  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-03 17:42:40 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-03 17:42:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-03 17:42:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-03 17:42:40 +0000 UTC  }]
Aug  3 17:43:01.397: INFO: 
Aug  3 17:43:01.397: INFO: StatefulSet ss has not reached scale 3, at 1
Aug  3 17:43:02.406: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.991990937s
Aug  3 17:43:03.415: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.982930412s
Aug  3 17:43:04.425: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.973413892s
Aug  3 17:43:05.434: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.963493419s
Aug  3 17:43:06.444: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.954370365s
Aug  3 17:43:07.460: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.944475479s
Aug  3 17:43:08.468: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.92928772s
Aug  3 17:43:09.476: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.921004569s
Aug  3 17:43:10.489: INFO: Verifying statefulset ss doesn't scale past 3 for another 912.615111ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-2501
Aug  3 17:43:11.500: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 exec --namespace=statefulset-2501 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  3 17:43:12.004: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Aug  3 17:43:12.004: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Aug  3 17:43:12.004: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Aug  3 17:43:12.004: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 exec --namespace=statefulset-2501 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  3 17:43:12.412: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Aug  3 17:43:12.412: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Aug  3 17:43:12.412: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Aug  3 17:43:12.412: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 exec --namespace=statefulset-2501 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  3 17:43:12.866: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Aug  3 17:43:12.867: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Aug  3 17:43:12.867: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Aug  3 17:43:12.880: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Aug  3 17:43:12.880: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Aug  3 17:43:12.880: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Aug  3 17:43:12.888: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 exec --namespace=statefulset-2501 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Aug  3 17:43:13.334: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Aug  3 17:43:13.334: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Aug  3 17:43:13.334: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Aug  3 17:43:13.334: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 exec --namespace=statefulset-2501 ss-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Aug  3 17:43:13.769: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Aug  3 17:43:13.769: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Aug  3 17:43:13.769: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Aug  3 17:43:13.770: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 exec --namespace=statefulset-2501 ss-2 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Aug  3 17:43:14.244: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Aug  3 17:43:14.244: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Aug  3 17:43:14.244: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Aug  3 17:43:14.244: INFO: Waiting for statefulset status.replicas updated to 0
Aug  3 17:43:14.252: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Aug  3 17:43:24.422: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Aug  3 17:43:24.422: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Aug  3 17:43:24.423: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Aug  3 17:43:24.459: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
Aug  3 17:43:24.459: INFO: ss-0  10.188.31.32  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-03 17:42:40 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-03 17:43:13 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-03 17:43:13 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-03 17:42:40 +0000 UTC  }]
Aug  3 17:43:24.459: INFO: ss-1  10.188.31.24  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-03 17:43:01 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-03 17:43:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-03 17:43:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-03 17:43:01 +0000 UTC  }]
Aug  3 17:43:24.459: INFO: ss-2  10.188.31.22  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-03 17:43:01 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-03 17:43:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-03 17:43:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-03 17:43:01 +0000 UTC  }]
Aug  3 17:43:24.459: INFO: 
Aug  3 17:43:24.459: INFO: StatefulSet ss has not reached scale 0, at 3
Aug  3 17:43:25.468: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
Aug  3 17:43:25.468: INFO: ss-0  10.188.31.32  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-03 17:42:40 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-03 17:43:13 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-03 17:43:13 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-03 17:42:40 +0000 UTC  }]
Aug  3 17:43:25.469: INFO: ss-1  10.188.31.24  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-03 17:43:01 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-03 17:43:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-03 17:43:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-03 17:43:01 +0000 UTC  }]
Aug  3 17:43:25.469: INFO: ss-2  10.188.31.22  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-03 17:43:01 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-03 17:43:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-03 17:43:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-03 17:43:01 +0000 UTC  }]
Aug  3 17:43:25.469: INFO: 
Aug  3 17:43:25.469: INFO: StatefulSet ss has not reached scale 0, at 3
Aug  3 17:43:26.478: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
Aug  3 17:43:26.478: INFO: ss-0  10.188.31.32  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-03 17:42:40 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-03 17:43:13 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-03 17:43:13 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-03 17:42:40 +0000 UTC  }]
Aug  3 17:43:26.478: INFO: ss-1  10.188.31.24  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-03 17:43:01 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-03 17:43:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-03 17:43:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-03 17:43:01 +0000 UTC  }]
Aug  3 17:43:26.478: INFO: ss-2  10.188.31.22  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-03 17:43:01 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-03 17:43:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-03 17:43:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-03 17:43:01 +0000 UTC  }]
Aug  3 17:43:26.478: INFO: 
Aug  3 17:43:26.478: INFO: StatefulSet ss has not reached scale 0, at 3
Aug  3 17:43:27.487: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
Aug  3 17:43:27.487: INFO: ss-1  10.188.31.24  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-03 17:43:01 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-03 17:43:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-03 17:43:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-03 17:43:01 +0000 UTC  }]
Aug  3 17:43:27.487: INFO: ss-2  10.188.31.22  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-03 17:43:01 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-03 17:43:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-03 17:43:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-03 17:43:01 +0000 UTC  }]
Aug  3 17:43:27.487: INFO: 
Aug  3 17:43:27.487: INFO: StatefulSet ss has not reached scale 0, at 2
Aug  3 17:43:28.498: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
Aug  3 17:43:28.498: INFO: ss-1  10.188.31.24  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-03 17:43:01 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-03 17:43:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-03 17:43:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-03 17:43:01 +0000 UTC  }]
Aug  3 17:43:28.498: INFO: ss-2  10.188.31.22  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-03 17:43:01 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-03 17:43:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-03 17:43:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-03 17:43:01 +0000 UTC  }]
Aug  3 17:43:28.498: INFO: 
Aug  3 17:43:28.498: INFO: StatefulSet ss has not reached scale 0, at 2
Aug  3 17:43:29.507: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
Aug  3 17:43:29.507: INFO: ss-1  10.188.31.24  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-03 17:43:01 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-03 17:43:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-03 17:43:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-03 17:43:01 +0000 UTC  }]
Aug  3 17:43:29.507: INFO: ss-2  10.188.31.22  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-03 17:43:01 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-03 17:43:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-03 17:43:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-03 17:43:01 +0000 UTC  }]
Aug  3 17:43:29.507: INFO: 
Aug  3 17:43:29.507: INFO: StatefulSet ss has not reached scale 0, at 2
Aug  3 17:43:30.516: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
Aug  3 17:43:30.516: INFO: ss-1  10.188.31.24  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-03 17:43:01 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-03 17:43:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-03 17:43:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-03 17:43:01 +0000 UTC  }]
Aug  3 17:43:30.516: INFO: ss-2  10.188.31.22  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-03 17:43:01 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-03 17:43:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-03 17:43:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-03 17:43:01 +0000 UTC  }]
Aug  3 17:43:30.516: INFO: 
Aug  3 17:43:30.516: INFO: StatefulSet ss has not reached scale 0, at 2
Aug  3 17:43:31.527: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
Aug  3 17:43:31.527: INFO: ss-1  10.188.31.24  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-03 17:43:01 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-03 17:43:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-03 17:43:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-03 17:43:01 +0000 UTC  }]
Aug  3 17:43:31.527: INFO: ss-2  10.188.31.22  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-03 17:43:01 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-03 17:43:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-03 17:43:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-03 17:43:01 +0000 UTC  }]
Aug  3 17:43:31.527: INFO: 
Aug  3 17:43:31.527: INFO: StatefulSet ss has not reached scale 0, at 2
Aug  3 17:43:32.535: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
Aug  3 17:43:32.535: INFO: ss-1  10.188.31.24  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-03 17:43:01 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-03 17:43:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-03 17:43:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-03 17:43:01 +0000 UTC  }]
Aug  3 17:43:32.535: INFO: 
Aug  3 17:43:32.535: INFO: StatefulSet ss has not reached scale 0, at 1
Aug  3 17:43:33.544: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
Aug  3 17:43:33.544: INFO: ss-1  10.188.31.24  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-03 17:43:01 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-03 17:43:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-03 17:43:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-03 17:43:01 +0000 UTC  }]
Aug  3 17:43:33.544: INFO: 
Aug  3 17:43:33.544: INFO: StatefulSet ss has not reached scale 0, at 1
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-2501
Aug  3 17:43:34.553: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 exec --namespace=statefulset-2501 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  3 17:43:34.755: INFO: rc: 1
Aug  3 17:43:34.755: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-322553265 exec --namespace=statefulset-2501 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  error: unable to upgrade connection: container not found ("nginx")
 [] <nil> 0xc001cf5050 exit status 1 <nil> <nil> true [0xc0024e80e0 0xc0024e8160 0xc0024e8190] [0xc0024e80e0 0xc0024e8160 0xc0024e8190] [0xc0024e8120 0xc0024e8180] [0x9d17b0 0x9d17b0] 0xc0037a0e40 <nil>}:
Command stdout:

stderr:
error: unable to upgrade connection: container not found ("nginx")

error:
exit status 1
Aug  3 17:43:44.755: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 exec --namespace=statefulset-2501 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  3 17:43:44.867: INFO: rc: 1
Aug  3 17:43:44.867: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-322553265 exec --namespace=statefulset-2501 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc000b38c90 exit status 1 <nil> <nil> true [0xc00098e898 0xc00098e8f0 0xc00098ea28] [0xc00098e898 0xc00098e8f0 0xc00098ea28] [0xc00098e8c8 0xc00098ea20] [0x9d17b0 0x9d17b0] 0xc002c8dd40 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Aug  3 17:43:54.867: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 exec --namespace=statefulset-2501 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  3 17:43:54.986: INFO: rc: 1
Aug  3 17:43:54.986: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-322553265 exec --namespace=statefulset-2501 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc001909650 exit status 1 <nil> <nil> true [0xc0025ba020 0xc0025ba038 0xc0025ba050] [0xc0025ba020 0xc0025ba038 0xc0025ba050] [0xc0025ba030 0xc0025ba048] [0x9d17b0 0x9d17b0] 0xc00376a540 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Aug  3 17:44:04.986: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 exec --namespace=statefulset-2501 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  3 17:44:05.116: INFO: rc: 1
Aug  3 17:44:05.116: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-322553265 exec --namespace=statefulset-2501 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc000b39020 exit status 1 <nil> <nil> true [0xc00098ea48 0xc00098eaf8 0xc00098eb58] [0xc00098ea48 0xc00098eaf8 0xc00098eb58] [0xc00098ea90 0xc00098eb30] [0x9d17b0 0x9d17b0] 0xc0036a80c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Aug  3 17:44:15.116: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 exec --namespace=statefulset-2501 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  3 17:44:15.248: INFO: rc: 1
Aug  3 17:44:15.248: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-322553265 exec --namespace=statefulset-2501 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc001cf5380 exit status 1 <nil> <nil> true [0xc0024e81e8 0xc0024e8220 0xc0024e8288] [0xc0024e81e8 0xc0024e8220 0xc0024e8288] [0xc0024e8210 0xc0024e8258] [0x9d17b0 0x9d17b0] 0xc0037a11a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Aug  3 17:44:25.248: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 exec --namespace=statefulset-2501 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  3 17:44:25.381: INFO: rc: 1
Aug  3 17:44:25.381: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-322553265 exec --namespace=statefulset-2501 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc001cf56e0 exit status 1 <nil> <nil> true [0xc0024e8290 0xc0024e82f0 0xc0024e8370] [0xc0024e8290 0xc0024e82f0 0xc0024e8370] [0xc0024e82b0 0xc0024e8348] [0x9d17b0 0x9d17b0] 0xc0037a1620 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Aug  3 17:44:35.381: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 exec --namespace=statefulset-2501 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  3 17:44:35.520: INFO: rc: 1
Aug  3 17:44:35.520: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-322553265 exec --namespace=statefulset-2501 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc001cf5a70 exit status 1 <nil> <nil> true [0xc0024e83c8 0xc0024e8418 0xc0024e8448] [0xc0024e83c8 0xc0024e8418 0xc0024e8448] [0xc0024e8408 0xc0024e8438] [0x9d17b0 0x9d17b0] 0xc0037a1c20 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Aug  3 17:44:45.520: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 exec --namespace=statefulset-2501 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  3 17:44:45.652: INFO: rc: 1
Aug  3 17:44:45.652: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-322553265 exec --namespace=statefulset-2501 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc001cf5dd0 exit status 1 <nil> <nil> true [0xc0024e8478 0xc0024e84a0 0xc0024e8518] [0xc0024e8478 0xc0024e84a0 0xc0024e8518] [0xc0024e8498 0xc0024e8500] [0x9d17b0 0x9d17b0] 0xc00372a0c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Aug  3 17:44:55.652: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 exec --namespace=statefulset-2501 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  3 17:44:55.768: INFO: rc: 1
Aug  3 17:44:55.768: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-322553265 exec --namespace=statefulset-2501 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc002ce6420 exit status 1 <nil> <nil> true [0xc0001a59b8 0xc0001a5c00 0xc0000cc6e8] [0xc0001a59b8 0xc0001a5c00 0xc0000cc6e8] [0xc0001a5b98 0xc0000cc360] [0x9d17b0 0x9d17b0] 0xc0037a0300 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Aug  3 17:45:05.768: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 exec --namespace=statefulset-2501 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  3 17:45:05.888: INFO: rc: 1
Aug  3 17:45:05.889: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-322553265 exec --namespace=statefulset-2501 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc002ce6750 exit status 1 <nil> <nil> true [0xc0000cc810 0xc0000ccde8 0xc0000cd098] [0xc0000cc810 0xc0000ccde8 0xc0000cd098] [0xc0000ccae8 0xc0000ccf58] [0x9d17b0 0x9d17b0] 0xc0037a0720 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Aug  3 17:45:15.889: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 exec --namespace=statefulset-2501 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  3 17:45:16.015: INFO: rc: 1
Aug  3 17:45:16.015: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-322553265 exec --namespace=statefulset-2501 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc0024dc450 exit status 1 <nil> <nil> true [0xc0004b2110 0xc0004b2318 0xc0004b2558] [0xc0004b2110 0xc0004b2318 0xc0004b2558] [0xc0004b21b0 0xc0004b2528] [0x9d17b0 0x9d17b0] 0xc002bd02a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Aug  3 17:45:26.015: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 exec --namespace=statefulset-2501 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  3 17:45:26.146: INFO: rc: 1
Aug  3 17:45:26.146: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-322553265 exec --namespace=statefulset-2501 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc002ce6ab0 exit status 1 <nil> <nil> true [0xc0000cd0b0 0xc0000cd630 0xc0000cd9b8] [0xc0000cd0b0 0xc0000cd630 0xc0000cd9b8] [0xc0000cd460 0xc0000cd918] [0x9d17b0 0x9d17b0] 0xc0037a0ae0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Aug  3 17:45:36.146: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 exec --namespace=statefulset-2501 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  3 17:45:36.287: INFO: rc: 1
Aug  3 17:45:36.287: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-322553265 exec --namespace=statefulset-2501 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc0024dc7b0 exit status 1 <nil> <nil> true [0xc0004b2678 0xc0004b2aa8 0xc0004b2c48] [0xc0004b2678 0xc0004b2aa8 0xc0004b2c48] [0xc0004b29b0 0xc0004b2b80] [0x9d17b0 0x9d17b0] 0xc002bd0960 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Aug  3 17:45:46.287: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 exec --namespace=statefulset-2501 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  3 17:45:46.413: INFO: rc: 1
Aug  3 17:45:46.413: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-322553265 exec --namespace=statefulset-2501 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc0024dcb40 exit status 1 <nil> <nil> true [0xc0004b2ca8 0xc0004b3118 0xc0004b3210] [0xc0004b2ca8 0xc0004b3118 0xc0004b3210] [0xc0004b3078 0xc0004b3198] [0x9d17b0 0x9d17b0] 0xc002bd1020 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Aug  3 17:45:56.413: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 exec --namespace=statefulset-2501 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  3 17:45:56.531: INFO: rc: 1
Aug  3 17:45:56.531: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-322553265 exec --namespace=statefulset-2501 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc0031f2330 exit status 1 <nil> <nil> true [0xc0025ba000 0xc0025ba018 0xc0025ba030] [0xc0025ba000 0xc0025ba018 0xc0025ba030] [0xc0025ba010 0xc0025ba028] [0x9d17b0 0x9d17b0] 0xc002c8c480 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Aug  3 17:46:06.531: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 exec --namespace=statefulset-2501 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  3 17:46:06.661: INFO: rc: 1
Aug  3 17:46:06.661: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-322553265 exec --namespace=statefulset-2501 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc0031f2720 exit status 1 <nil> <nil> true [0xc0025ba038 0xc0025ba050 0xc0025ba068] [0xc0025ba038 0xc0025ba050 0xc0025ba068] [0xc0025ba048 0xc0025ba060] [0x9d17b0 0x9d17b0] 0xc002c8c7e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Aug  3 17:46:16.662: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 exec --namespace=statefulset-2501 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  3 17:46:16.773: INFO: rc: 1
Aug  3 17:46:16.773: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-322553265 exec --namespace=statefulset-2501 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc0024dced0 exit status 1 <nil> <nil> true [0xc0004b32e8 0xc0004b3458 0xc0004b35b0] [0xc0004b32e8 0xc0004b3458 0xc0004b35b0] [0xc0004b3438 0xc0004b3540] [0x9d17b0 0x9d17b0] 0xc002bd14a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Aug  3 17:46:26.774: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 exec --namespace=statefulset-2501 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  3 17:46:26.889: INFO: rc: 1
Aug  3 17:46:26.889: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-322553265 exec --namespace=statefulset-2501 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc0031f2ab0 exit status 1 <nil> <nil> true [0xc0025ba070 0xc0025ba088 0xc0025ba0a0] [0xc0025ba070 0xc0025ba088 0xc0025ba0a0] [0xc0025ba080 0xc0025ba098] [0x9d17b0 0x9d17b0] 0xc002c8cb40 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Aug  3 17:46:36.889: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 exec --namespace=statefulset-2501 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  3 17:46:37.021: INFO: rc: 1
Aug  3 17:46:37.021: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-322553265 exec --namespace=statefulset-2501 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc002ce6e40 exit status 1 <nil> <nil> true [0xc0000cd9e8 0xc0000cdbc8 0xc0000cdcd8] [0xc0000cd9e8 0xc0000cdbc8 0xc0000cdcd8] [0xc0000cdb50 0xc0000cdc88] [0x9d17b0 0x9d17b0] 0xc0037a0ea0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Aug  3 17:46:47.021: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 exec --namespace=statefulset-2501 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  3 17:46:47.138: INFO: rc: 1
Aug  3 17:46:47.138: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-322553265 exec --namespace=statefulset-2501 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc002ce71a0 exit status 1 <nil> <nil> true [0xc0000cdcf8 0xc0000cded0 0xc0000cdfe0] [0xc0000cdcf8 0xc0000cded0 0xc0000cdfe0] [0xc0000cde70 0xc0000cdfc8] [0x9d17b0 0x9d17b0] 0xc0037a1200 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Aug  3 17:46:57.138: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 exec --namespace=statefulset-2501 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  3 17:46:57.263: INFO: rc: 1
Aug  3 17:46:57.263: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-322553265 exec --namespace=statefulset-2501 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc002ce63c0 exit status 1 <nil> <nil> true [0xc0001a59b8 0xc0001a5c00 0xc0000cc6e8] [0xc0001a59b8 0xc0001a5c00 0xc0000cc6e8] [0xc0001a5b98 0xc0000cc360] [0x9d17b0 0x9d17b0] 0xc0037a0300 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Aug  3 17:47:07.264: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 exec --namespace=statefulset-2501 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  3 17:47:07.390: INFO: rc: 1
Aug  3 17:47:07.390: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-322553265 exec --namespace=statefulset-2501 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc003724330 exit status 1 <nil> <nil> true [0xc0004b2110 0xc0004b2318 0xc0004b2558] [0xc0004b2110 0xc0004b2318 0xc0004b2558] [0xc0004b21b0 0xc0004b2528] [0x9d17b0 0x9d17b0] 0xc002bd02a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Aug  3 17:47:17.390: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 exec --namespace=statefulset-2501 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  3 17:47:17.517: INFO: rc: 1
Aug  3 17:47:17.517: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-322553265 exec --namespace=statefulset-2501 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc0024dc4b0 exit status 1 <nil> <nil> true [0xc0025ba000 0xc0025ba018 0xc0025ba030] [0xc0025ba000 0xc0025ba018 0xc0025ba030] [0xc0025ba010 0xc0025ba028] [0x9d17b0 0x9d17b0] 0xc002c8c480 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Aug  3 17:47:27.517: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 exec --namespace=statefulset-2501 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  3 17:47:27.655: INFO: rc: 1
Aug  3 17:47:27.655: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-322553265 exec --namespace=statefulset-2501 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc0037246f0 exit status 1 <nil> <nil> true [0xc0004b2678 0xc0004b2aa8 0xc0004b2c48] [0xc0004b2678 0xc0004b2aa8 0xc0004b2c48] [0xc0004b29b0 0xc0004b2b80] [0x9d17b0 0x9d17b0] 0xc002bd0960 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Aug  3 17:47:37.655: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 exec --namespace=statefulset-2501 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  3 17:47:37.764: INFO: rc: 1
Aug  3 17:47:37.765: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-322553265 exec --namespace=statefulset-2501 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc0024dc840 exit status 1 <nil> <nil> true [0xc0025ba038 0xc0025ba050 0xc0025ba068] [0xc0025ba038 0xc0025ba050 0xc0025ba068] [0xc0025ba048 0xc0025ba060] [0x9d17b0 0x9d17b0] 0xc002c8c7e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Aug  3 17:47:47.765: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 exec --namespace=statefulset-2501 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  3 17:47:47.904: INFO: rc: 1
Aug  3 17:47:47.905: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-322553265 exec --namespace=statefulset-2501 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc003724a50 exit status 1 <nil> <nil> true [0xc0004b2ca8 0xc0004b3118 0xc0004b3210] [0xc0004b2ca8 0xc0004b3118 0xc0004b3210] [0xc0004b3078 0xc0004b3198] [0x9d17b0 0x9d17b0] 0xc002bd1020 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Aug  3 17:47:57.905: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 exec --namespace=statefulset-2501 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  3 17:47:58.036: INFO: rc: 1
Aug  3 17:47:58.036: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-322553265 exec --namespace=statefulset-2501 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc003724db0 exit status 1 <nil> <nil> true [0xc0004b32e8 0xc0004b3458 0xc0004b35b0] [0xc0004b32e8 0xc0004b3458 0xc0004b35b0] [0xc0004b3438 0xc0004b3540] [0x9d17b0 0x9d17b0] 0xc002bd14a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Aug  3 17:48:08.036: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 exec --namespace=statefulset-2501 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  3 17:48:08.157: INFO: rc: 1
Aug  3 17:48:08.157: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-322553265 exec --namespace=statefulset-2501 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc0031f2360 exit status 1 <nil> <nil> true [0xc0024e8018 0xc0024e80b8 0xc0024e80f0] [0xc0024e8018 0xc0024e80b8 0xc0024e80f0] [0xc0024e80a8 0xc0024e80e0] [0x9d17b0 0x9d17b0] 0xc00376a2a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Aug  3 17:48:18.157: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 exec --namespace=statefulset-2501 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  3 17:48:18.274: INFO: rc: 1
Aug  3 17:48:18.274: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-322553265 exec --namespace=statefulset-2501 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc0024dcbd0 exit status 1 <nil> <nil> true [0xc0025ba070 0xc0025ba088 0xc0025ba0a0] [0xc0025ba070 0xc0025ba088 0xc0025ba0a0] [0xc0025ba080 0xc0025ba098] [0x9d17b0 0x9d17b0] 0xc002c8cb40 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Aug  3 17:48:28.275: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 exec --namespace=statefulset-2501 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  3 17:48:28.394: INFO: rc: 1
Aug  3 17:48:28.394: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-322553265 exec --namespace=statefulset-2501 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc003725140 exit status 1 <nil> <nil> true [0xc0004b3600 0xc0004b3658 0xc0004b36b8] [0xc0004b3600 0xc0004b3658 0xc0004b36b8] [0xc0004b3638 0xc0004b36a8] [0x9d17b0 0x9d17b0] 0xc002bd1800 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Aug  3 17:48:38.394: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 exec --namespace=statefulset-2501 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  3 17:48:38.532: INFO: rc: 1
Aug  3 17:48:38.532: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: 
Aug  3 17:48:38.532: INFO: Scaling statefulset ss to 0
Aug  3 17:48:38.558: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Aug  3 17:48:38.567: INFO: Deleting all statefulset in ns statefulset-2501
Aug  3 17:48:38.576: INFO: Scaling statefulset ss to 0
Aug  3 17:48:38.600: INFO: Waiting for statefulset status.replicas updated to 0
Aug  3 17:48:38.609: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 17:48:38.646: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-2501" for this suite.
Aug  3 17:48:44.691: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 17:48:45.013: INFO: namespace statefulset-2501 deletion completed in 6.352970327s

• [SLOW TEST:364.507 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 17:48:45.014: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename events
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in events-2476
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Aug  3 17:48:49.309: INFO: &Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-82b0620b-892f-4200-98fe-2669689f58ff,GenerateName:,Namespace:events-2476,SelfLink:/api/v1/namespaces/events-2476/pods/send-events-82b0620b-892f-4200-98fe-2669689f58ff,UID:97e5c15d-ea58-4146-8681-8a0156d310ab,ResourceVersion:32438,Generation:0,CreationTimestamp:2019-08-03 17:48:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 232522438,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-fnd9t {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-fnd9t,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-fnd9t true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.188.31.32,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001afab20} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001afab40}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-03 17:48:45 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-03 17:48:47 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-03 17:48:47 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-03 17:48:45 +0000 UTC  }],Message:,Reason:,HostIP:10.188.31.32,PodIP:172.30.72.77,StartTime:2019-08-03 17:48:45 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2019-08-03 17:48:46 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 gcr.io/kubernetes-e2e-test-images/serve-hostname@sha256:bab70473a6d8ef65a22625dc9a1b0f0452e811530fdbe77e4408523460177ff1 containerd://39b95ebef0d0170c111dc110feb23dff4198d8f03558386c1f245c6f10c14040}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}

STEP: checking for scheduler event about the pod
Aug  3 17:48:51.318: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Aug  3 17:48:53.326: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 17:48:53.339: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-2476" for this suite.
Aug  3 17:49:33.382: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 17:49:33.843: INFO: namespace events-2476 deletion completed in 40.49132749s

• [SLOW TEST:48.829 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 17:49:33.846: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-9400
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Aug  3 17:49:34.129: INFO: Waiting up to 5m0s for pod "downwardapi-volume-dfac31b1-9d8d-4a66-9821-77bcb3b9309b" in namespace "downward-api-9400" to be "success or failure"
Aug  3 17:49:34.136: INFO: Pod "downwardapi-volume-dfac31b1-9d8d-4a66-9821-77bcb3b9309b": Phase="Pending", Reason="", readiness=false. Elapsed: 7.151398ms
Aug  3 17:49:36.144: INFO: Pod "downwardapi-volume-dfac31b1-9d8d-4a66-9821-77bcb3b9309b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015212781s
STEP: Saw pod success
Aug  3 17:49:36.144: INFO: Pod "downwardapi-volume-dfac31b1-9d8d-4a66-9821-77bcb3b9309b" satisfied condition "success or failure"
Aug  3 17:49:36.152: INFO: Trying to get logs from node 10.188.31.32 pod downwardapi-volume-dfac31b1-9d8d-4a66-9821-77bcb3b9309b container client-container: <nil>
STEP: delete the pod
Aug  3 17:49:36.209: INFO: Waiting for pod downwardapi-volume-dfac31b1-9d8d-4a66-9821-77bcb3b9309b to disappear
Aug  3 17:49:36.216: INFO: Pod downwardapi-volume-dfac31b1-9d8d-4a66-9821-77bcb3b9309b no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 17:49:36.216: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9400" for this suite.
Aug  3 17:49:42.257: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 17:49:42.554: INFO: namespace downward-api-9400 deletion completed in 6.326848836s

• [SLOW TEST:8.709 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 17:49:42.555: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-3177
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
Aug  3 17:50:12.864: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W0803 17:50:12.864564      17 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 17:50:12.864: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-3177" for this suite.
Aug  3 17:50:18.909: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 17:50:19.243: INFO: namespace gc-3177 deletion completed in 6.366511812s

• [SLOW TEST:36.688 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 17:50:19.244: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in namespaces-2575
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-5167
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-9435
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 17:50:44.959: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-2575" for this suite.
Aug  3 17:50:51.006: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 17:50:51.382: INFO: namespace namespaces-2575 deletion completed in 6.410280357s
STEP: Destroying namespace "nsdeletetest-5167" for this suite.
Aug  3 17:50:51.390: INFO: Namespace nsdeletetest-5167 was already deleted
STEP: Destroying namespace "nsdeletetest-9435" for this suite.
Aug  3 17:50:57.422: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 17:50:57.743: INFO: namespace nsdeletetest-9435 deletion completed in 6.353171924s

• [SLOW TEST:38.500 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 17:50:57.744: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-6117
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Aug  3 17:50:58.042: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Aug  3 17:50:58.062: INFO: Number of nodes with available pods: 0
Aug  3 17:50:58.062: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Aug  3 17:50:58.100: INFO: Number of nodes with available pods: 0
Aug  3 17:50:58.100: INFO: Node 10.188.31.22 is running more than one daemon pod
Aug  3 17:50:59.109: INFO: Number of nodes with available pods: 0
Aug  3 17:50:59.109: INFO: Node 10.188.31.22 is running more than one daemon pod
Aug  3 17:51:00.109: INFO: Number of nodes with available pods: 1
Aug  3 17:51:00.109: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Aug  3 17:51:00.149: INFO: Number of nodes with available pods: 1
Aug  3 17:51:00.150: INFO: Number of running nodes: 0, number of available pods: 1
Aug  3 17:51:01.158: INFO: Number of nodes with available pods: 0
Aug  3 17:51:01.158: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Aug  3 17:51:01.191: INFO: Number of nodes with available pods: 0
Aug  3 17:51:01.191: INFO: Node 10.188.31.22 is running more than one daemon pod
Aug  3 17:51:02.209: INFO: Number of nodes with available pods: 0
Aug  3 17:51:02.209: INFO: Node 10.188.31.22 is running more than one daemon pod
Aug  3 17:51:03.200: INFO: Number of nodes with available pods: 0
Aug  3 17:51:03.200: INFO: Node 10.188.31.22 is running more than one daemon pod
Aug  3 17:51:04.199: INFO: Number of nodes with available pods: 0
Aug  3 17:51:04.199: INFO: Node 10.188.31.22 is running more than one daemon pod
Aug  3 17:51:05.200: INFO: Number of nodes with available pods: 0
Aug  3 17:51:05.200: INFO: Node 10.188.31.22 is running more than one daemon pod
Aug  3 17:51:06.200: INFO: Number of nodes with available pods: 0
Aug  3 17:51:06.200: INFO: Node 10.188.31.22 is running more than one daemon pod
Aug  3 17:51:07.199: INFO: Number of nodes with available pods: 0
Aug  3 17:51:07.199: INFO: Node 10.188.31.22 is running more than one daemon pod
Aug  3 17:51:08.199: INFO: Number of nodes with available pods: 0
Aug  3 17:51:08.199: INFO: Node 10.188.31.22 is running more than one daemon pod
Aug  3 17:51:09.199: INFO: Number of nodes with available pods: 0
Aug  3 17:51:09.199: INFO: Node 10.188.31.22 is running more than one daemon pod
Aug  3 17:51:10.199: INFO: Number of nodes with available pods: 0
Aug  3 17:51:10.199: INFO: Node 10.188.31.22 is running more than one daemon pod
Aug  3 17:51:11.200: INFO: Number of nodes with available pods: 0
Aug  3 17:51:11.200: INFO: Node 10.188.31.22 is running more than one daemon pod
Aug  3 17:51:12.199: INFO: Number of nodes with available pods: 0
Aug  3 17:51:12.199: INFO: Node 10.188.31.22 is running more than one daemon pod
Aug  3 17:51:13.199: INFO: Number of nodes with available pods: 0
Aug  3 17:51:13.199: INFO: Node 10.188.31.22 is running more than one daemon pod
Aug  3 17:51:14.200: INFO: Number of nodes with available pods: 1
Aug  3 17:51:14.200: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-6117, will wait for the garbage collector to delete the pods
Aug  3 17:51:14.298: INFO: Deleting DaemonSet.extensions daemon-set took: 21.186098ms
Aug  3 17:51:14.498: INFO: Terminating DaemonSet.extensions daemon-set pods took: 200.313145ms
Aug  3 17:51:22.008: INFO: Number of nodes with available pods: 0
Aug  3 17:51:22.008: INFO: Number of running nodes: 0, number of available pods: 0
Aug  3 17:51:22.024: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-6117/daemonsets","resourceVersion":"32957"},"items":null}

Aug  3 17:51:22.031: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-6117/pods","resourceVersion":"32957"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 17:51:22.093: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-6117" for this suite.
Aug  3 17:51:28.136: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 17:51:28.454: INFO: namespace daemonsets-6117 deletion completed in 6.350907557s

• [SLOW TEST:30.711 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 17:51:28.454: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-7907
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Aug  3 17:51:28.758: INFO: Number of nodes with available pods: 0
Aug  3 17:51:28.758: INFO: Node 10.188.31.22 is running more than one daemon pod
Aug  3 17:51:29.787: INFO: Number of nodes with available pods: 0
Aug  3 17:51:29.787: INFO: Node 10.188.31.22 is running more than one daemon pod
Aug  3 17:51:30.780: INFO: Number of nodes with available pods: 1
Aug  3 17:51:30.780: INFO: Node 10.188.31.24 is running more than one daemon pod
Aug  3 17:51:31.777: INFO: Number of nodes with available pods: 3
Aug  3 17:51:31.777: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Aug  3 17:51:31.822: INFO: Number of nodes with available pods: 2
Aug  3 17:51:31.822: INFO: Node 10.188.31.22 is running more than one daemon pod
Aug  3 17:51:32.843: INFO: Number of nodes with available pods: 2
Aug  3 17:51:32.843: INFO: Node 10.188.31.22 is running more than one daemon pod
Aug  3 17:51:33.842: INFO: Number of nodes with available pods: 3
Aug  3 17:51:33.842: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-7907, will wait for the garbage collector to delete the pods
Aug  3 17:51:33.938: INFO: Deleting DaemonSet.extensions daemon-set took: 22.918206ms
Aug  3 17:51:34.038: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.264248ms
Aug  3 17:51:42.056: INFO: Number of nodes with available pods: 0
Aug  3 17:51:42.056: INFO: Number of running nodes: 0, number of available pods: 0
Aug  3 17:51:42.064: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-7907/daemonsets","resourceVersion":"33112"},"items":null}

Aug  3 17:51:42.071: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-7907/pods","resourceVersion":"33112"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 17:51:42.105: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-7907" for this suite.
Aug  3 17:51:50.369: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 17:51:50.694: INFO: namespace daemonsets-7907 deletion completed in 8.573984341s

• [SLOW TEST:22.240 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 17:51:50.694: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-4262
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap configmap-4262/configmap-test-31172168-63a4-4135-9c6d-0ac510183890
STEP: Creating a pod to test consume configMaps
Aug  3 17:51:50.939: INFO: Waiting up to 5m0s for pod "pod-configmaps-f600dc88-6c5e-4423-ac4e-b722bd50087b" in namespace "configmap-4262" to be "success or failure"
Aug  3 17:51:50.946: INFO: Pod "pod-configmaps-f600dc88-6c5e-4423-ac4e-b722bd50087b": Phase="Pending", Reason="", readiness=false. Elapsed: 7.00496ms
Aug  3 17:51:52.969: INFO: Pod "pod-configmaps-f600dc88-6c5e-4423-ac4e-b722bd50087b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.029872377s
STEP: Saw pod success
Aug  3 17:51:52.969: INFO: Pod "pod-configmaps-f600dc88-6c5e-4423-ac4e-b722bd50087b" satisfied condition "success or failure"
Aug  3 17:51:52.976: INFO: Trying to get logs from node 10.188.31.32 pod pod-configmaps-f600dc88-6c5e-4423-ac4e-b722bd50087b container env-test: <nil>
STEP: delete the pod
Aug  3 17:51:53.016: INFO: Waiting for pod pod-configmaps-f600dc88-6c5e-4423-ac4e-b722bd50087b to disappear
Aug  3 17:51:53.023: INFO: Pod pod-configmaps-f600dc88-6c5e-4423-ac4e-b722bd50087b no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 17:51:53.023: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4262" for this suite.
Aug  3 17:51:59.066: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 17:51:59.418: INFO: namespace configmap-4262 deletion completed in 6.381960117s

• [SLOW TEST:8.724 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 17:51:59.419: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-3900
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1421
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Aug  3 17:51:59.650: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-3900'
Aug  3 17:51:59.783: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Aug  3 17:51:59.783: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1427
Aug  3 17:52:01.801: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 delete deployment e2e-test-nginx-deployment --namespace=kubectl-3900'
Aug  3 17:52:01.995: INFO: stderr: ""
Aug  3 17:52:01.995: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 17:52:01.995: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3900" for this suite.
Aug  3 17:52:34.042: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 17:52:34.347: INFO: namespace kubectl-3900 deletion completed in 32.336975758s

• [SLOW TEST:34.928 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run default
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 17:52:34.349: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-8578
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:179
[It] should be submitted and removed  [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 17:52:34.610: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-8578" for this suite.
Aug  3 17:52:58.660: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 17:52:59.014: INFO: namespace pods-8578 deletion completed in 24.386529797s

• [SLOW TEST:24.665 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should be submitted and removed  [Conformance]
    /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 17:52:59.015: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-6432
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1613
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Aug  3 17:52:59.231: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-6432'
Aug  3 17:52:59.425: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Aug  3 17:52:59.425: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
STEP: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1618
Aug  3 17:52:59.436: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 delete jobs e2e-test-nginx-job --namespace=kubectl-6432'
Aug  3 17:52:59.581: INFO: stderr: ""
Aug  3 17:52:59.581: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 17:52:59.582: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6432" for this suite.
Aug  3 17:53:05.629: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 17:53:05.950: INFO: namespace kubectl-6432 deletion completed in 6.355998797s

• [SLOW TEST:6.935 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run job
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 17:53:05.951: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-2057
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap configmap-2057/configmap-test-cd917789-afe6-485e-bbf4-57f2d5002742
STEP: Creating a pod to test consume configMaps
Aug  3 17:53:06.191: INFO: Waiting up to 5m0s for pod "pod-configmaps-546aa334-e75a-49ca-81bc-e5e538763571" in namespace "configmap-2057" to be "success or failure"
Aug  3 17:53:06.202: INFO: Pod "pod-configmaps-546aa334-e75a-49ca-81bc-e5e538763571": Phase="Pending", Reason="", readiness=false. Elapsed: 10.674847ms
Aug  3 17:53:08.212: INFO: Pod "pod-configmaps-546aa334-e75a-49ca-81bc-e5e538763571": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020474868s
STEP: Saw pod success
Aug  3 17:53:08.212: INFO: Pod "pod-configmaps-546aa334-e75a-49ca-81bc-e5e538763571" satisfied condition "success or failure"
Aug  3 17:53:08.229: INFO: Trying to get logs from node 10.188.31.32 pod pod-configmaps-546aa334-e75a-49ca-81bc-e5e538763571 container env-test: <nil>
STEP: delete the pod
Aug  3 17:53:08.277: INFO: Waiting for pod pod-configmaps-546aa334-e75a-49ca-81bc-e5e538763571 to disappear
Aug  3 17:53:08.285: INFO: Pod pod-configmaps-546aa334-e75a-49ca-81bc-e5e538763571 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 17:53:08.285: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2057" for this suite.
Aug  3 17:53:14.349: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 17:53:14.740: INFO: namespace configmap-2057 deletion completed in 6.442745345s

• [SLOW TEST:8.789 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 17:53:14.740: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-1011
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1517
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Aug  3 17:53:14.952: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=kubectl-1011'
Aug  3 17:53:15.078: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Aug  3 17:53:15.078: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
Aug  3 17:53:15.093: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 0 spec.replicas 1 status.replicas 0
Aug  3 17:53:15.109: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 1 spec.replicas 1 status.replicas 0
STEP: rolling-update to same image controller
Aug  3 17:53:15.121: INFO: scanned /root for discovery docs: <nil>
Aug  3 17:53:15.121: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 rolling-update e2e-test-nginx-rc --update-period=1s --image=docker.io/library/nginx:1.14-alpine --image-pull-policy=IfNotPresent --namespace=kubectl-1011'
Aug  3 17:53:31.080: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Aug  3 17:53:31.080: INFO: stdout: "Created e2e-test-nginx-rc-5c8105d873d3e73deba959ad974a35fd\nScaling up e2e-test-nginx-rc-5c8105d873d3e73deba959ad974a35fd from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-5c8105d873d3e73deba959ad974a35fd up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-5c8105d873d3e73deba959ad974a35fd to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
Aug  3 17:53:31.080: INFO: stdout: "Created e2e-test-nginx-rc-5c8105d873d3e73deba959ad974a35fd\nScaling up e2e-test-nginx-rc-5c8105d873d3e73deba959ad974a35fd from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-5c8105d873d3e73deba959ad974a35fd up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-5c8105d873d3e73deba959ad974a35fd to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
Aug  3 17:53:31.080: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=kubectl-1011'
Aug  3 17:53:31.212: INFO: stderr: ""
Aug  3 17:53:31.212: INFO: stdout: "e2e-test-nginx-rc-5c8105d873d3e73deba959ad974a35fd-28nv8 "
Aug  3 17:53:31.212: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 get pods e2e-test-nginx-rc-5c8105d873d3e73deba959ad974a35fd-28nv8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1011'
Aug  3 17:53:31.331: INFO: stderr: ""
Aug  3 17:53:31.331: INFO: stdout: "true"
Aug  3 17:53:31.331: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 get pods e2e-test-nginx-rc-5c8105d873d3e73deba959ad974a35fd-28nv8 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1011'
Aug  3 17:53:31.463: INFO: stderr: ""
Aug  3 17:53:31.463: INFO: stdout: "docker.io/library/nginx:1.14-alpine"
Aug  3 17:53:31.463: INFO: e2e-test-nginx-rc-5c8105d873d3e73deba959ad974a35fd-28nv8 is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1523
Aug  3 17:53:31.463: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 delete rc e2e-test-nginx-rc --namespace=kubectl-1011'
Aug  3 17:53:31.617: INFO: stderr: ""
Aug  3 17:53:31.617: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 17:53:31.617: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1011" for this suite.
Aug  3 17:53:37.661: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 17:53:37.974: INFO: namespace kubectl-1011 deletion completed in 6.345239993s

• [SLOW TEST:23.234 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Aggregator 
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 17:53:37.975: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename aggregator
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in aggregator-5293
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:76
Aug  3 17:53:38.183: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
[It] Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Registering the sample API server.
Aug  3 17:53:38.798: INFO: deployment "sample-apiserver-deployment" doesn't have the required revision set
Aug  3 17:53:40.903: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700451618, loc:(*time.Location)(0x80c0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700451618, loc:(*time.Location)(0x80c0a20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700451618, loc:(*time.Location)(0x80c0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700451618, loc:(*time.Location)(0x80c0a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug  3 17:53:42.912: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700451618, loc:(*time.Location)(0x80c0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700451618, loc:(*time.Location)(0x80c0a20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700451618, loc:(*time.Location)(0x80c0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700451618, loc:(*time.Location)(0x80c0a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug  3 17:53:44.912: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700451618, loc:(*time.Location)(0x80c0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700451618, loc:(*time.Location)(0x80c0a20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700451618, loc:(*time.Location)(0x80c0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700451618, loc:(*time.Location)(0x80c0a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug  3 17:53:46.912: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700451618, loc:(*time.Location)(0x80c0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700451618, loc:(*time.Location)(0x80c0a20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700451618, loc:(*time.Location)(0x80c0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700451618, loc:(*time.Location)(0x80c0a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug  3 17:53:48.914: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700451618, loc:(*time.Location)(0x80c0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700451618, loc:(*time.Location)(0x80c0a20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700451618, loc:(*time.Location)(0x80c0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700451618, loc:(*time.Location)(0x80c0a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug  3 17:53:53.388: INFO: Waited 2.465211643s for the sample-apiserver to be ready to handle requests.
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:67
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 17:53:53.820: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "aggregator-5293" for this suite.
Aug  3 17:53:59.939: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 17:54:00.255: INFO: namespace aggregator-5293 deletion completed in 6.409713213s

• [SLOW TEST:22.280 seconds]
[sig-api-machinery] Aggregator
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 17:54:00.255: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5353
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-07eef1a8-f6db-4420-952e-ff986cd36dd5
STEP: Creating a pod to test consume secrets
Aug  3 17:54:00.500: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-3b27f09b-86f0-464d-804a-140d441b34c2" in namespace "projected-5353" to be "success or failure"
Aug  3 17:54:00.508: INFO: Pod "pod-projected-secrets-3b27f09b-86f0-464d-804a-140d441b34c2": Phase="Pending", Reason="", readiness=false. Elapsed: 7.811039ms
Aug  3 17:54:02.519: INFO: Pod "pod-projected-secrets-3b27f09b-86f0-464d-804a-140d441b34c2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.018998952s
STEP: Saw pod success
Aug  3 17:54:02.519: INFO: Pod "pod-projected-secrets-3b27f09b-86f0-464d-804a-140d441b34c2" satisfied condition "success or failure"
Aug  3 17:54:02.528: INFO: Trying to get logs from node 10.188.31.32 pod pod-projected-secrets-3b27f09b-86f0-464d-804a-140d441b34c2 container projected-secret-volume-test: <nil>
STEP: delete the pod
Aug  3 17:54:02.593: INFO: Waiting for pod pod-projected-secrets-3b27f09b-86f0-464d-804a-140d441b34c2 to disappear
Aug  3 17:54:02.601: INFO: Pod pod-projected-secrets-3b27f09b-86f0-464d-804a-140d441b34c2 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 17:54:02.601: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5353" for this suite.
Aug  3 17:54:08.661: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 17:54:08.990: INFO: namespace projected-5353 deletion completed in 6.373396936s

• [SLOW TEST:8.735 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 17:54:08.990: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-5478
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Aug  3 17:54:09.231: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-5478,SelfLink:/api/v1/namespaces/watch-5478/configmaps/e2e-watch-test-configmap-a,UID:fbd6bdf2-b2b9-4679-aaa2-bb082d940c33,ResourceVersion:33816,Generation:0,CreationTimestamp:2019-08-03 17:54:09 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Aug  3 17:54:09.231: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-5478,SelfLink:/api/v1/namespaces/watch-5478/configmaps/e2e-watch-test-configmap-a,UID:fbd6bdf2-b2b9-4679-aaa2-bb082d940c33,ResourceVersion:33816,Generation:0,CreationTimestamp:2019-08-03 17:54:09 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Aug  3 17:54:19.259: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-5478,SelfLink:/api/v1/namespaces/watch-5478/configmaps/e2e-watch-test-configmap-a,UID:fbd6bdf2-b2b9-4679-aaa2-bb082d940c33,ResourceVersion:33834,Generation:0,CreationTimestamp:2019-08-03 17:54:09 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Aug  3 17:54:19.259: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-5478,SelfLink:/api/v1/namespaces/watch-5478/configmaps/e2e-watch-test-configmap-a,UID:fbd6bdf2-b2b9-4679-aaa2-bb082d940c33,ResourceVersion:33834,Generation:0,CreationTimestamp:2019-08-03 17:54:09 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Aug  3 17:54:29.279: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-5478,SelfLink:/api/v1/namespaces/watch-5478/configmaps/e2e-watch-test-configmap-a,UID:fbd6bdf2-b2b9-4679-aaa2-bb082d940c33,ResourceVersion:33852,Generation:0,CreationTimestamp:2019-08-03 17:54:09 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Aug  3 17:54:29.279: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-5478,SelfLink:/api/v1/namespaces/watch-5478/configmaps/e2e-watch-test-configmap-a,UID:fbd6bdf2-b2b9-4679-aaa2-bb082d940c33,ResourceVersion:33852,Generation:0,CreationTimestamp:2019-08-03 17:54:09 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Aug  3 17:54:39.299: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-5478,SelfLink:/api/v1/namespaces/watch-5478/configmaps/e2e-watch-test-configmap-a,UID:fbd6bdf2-b2b9-4679-aaa2-bb082d940c33,ResourceVersion:33869,Generation:0,CreationTimestamp:2019-08-03 17:54:09 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Aug  3 17:54:39.299: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-5478,SelfLink:/api/v1/namespaces/watch-5478/configmaps/e2e-watch-test-configmap-a,UID:fbd6bdf2-b2b9-4679-aaa2-bb082d940c33,ResourceVersion:33869,Generation:0,CreationTimestamp:2019-08-03 17:54:09 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Aug  3 17:54:49.320: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-5478,SelfLink:/api/v1/namespaces/watch-5478/configmaps/e2e-watch-test-configmap-b,UID:14326aee-3e77-407c-8241-51d302dcaa4e,ResourceVersion:33886,Generation:0,CreationTimestamp:2019-08-03 17:54:49 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Aug  3 17:54:49.320: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-5478,SelfLink:/api/v1/namespaces/watch-5478/configmaps/e2e-watch-test-configmap-b,UID:14326aee-3e77-407c-8241-51d302dcaa4e,ResourceVersion:33886,Generation:0,CreationTimestamp:2019-08-03 17:54:49 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Aug  3 17:54:59.342: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-5478,SelfLink:/api/v1/namespaces/watch-5478/configmaps/e2e-watch-test-configmap-b,UID:14326aee-3e77-407c-8241-51d302dcaa4e,ResourceVersion:33903,Generation:0,CreationTimestamp:2019-08-03 17:54:49 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Aug  3 17:54:59.342: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-5478,SelfLink:/api/v1/namespaces/watch-5478/configmaps/e2e-watch-test-configmap-b,UID:14326aee-3e77-407c-8241-51d302dcaa4e,ResourceVersion:33903,Generation:0,CreationTimestamp:2019-08-03 17:54:49 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 17:55:09.343: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-5478" for this suite.
Aug  3 17:55:15.409: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 17:55:15.884: INFO: namespace watch-5478 deletion completed in 6.514388917s

• [SLOW TEST:66.894 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 17:55:15.885: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-3717
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-map-09913b16-488b-4bac-ad58-bf3222eed847
STEP: Creating a pod to test consume configMaps
Aug  3 17:55:16.129: INFO: Waiting up to 5m0s for pod "pod-configmaps-5dabba15-a3f1-4647-b92b-21ebd36c5c1a" in namespace "configmap-3717" to be "success or failure"
Aug  3 17:55:16.138: INFO: Pod "pod-configmaps-5dabba15-a3f1-4647-b92b-21ebd36c5c1a": Phase="Pending", Reason="", readiness=false. Elapsed: 8.522742ms
Aug  3 17:55:18.149: INFO: Pod "pod-configmaps-5dabba15-a3f1-4647-b92b-21ebd36c5c1a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020077581s
Aug  3 17:55:20.160: INFO: Pod "pod-configmaps-5dabba15-a3f1-4647-b92b-21ebd36c5c1a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.030605976s
STEP: Saw pod success
Aug  3 17:55:20.160: INFO: Pod "pod-configmaps-5dabba15-a3f1-4647-b92b-21ebd36c5c1a" satisfied condition "success or failure"
Aug  3 17:55:20.172: INFO: Trying to get logs from node 10.188.31.32 pod pod-configmaps-5dabba15-a3f1-4647-b92b-21ebd36c5c1a container configmap-volume-test: <nil>
STEP: delete the pod
Aug  3 17:55:20.218: INFO: Waiting for pod pod-configmaps-5dabba15-a3f1-4647-b92b-21ebd36c5c1a to disappear
Aug  3 17:55:20.229: INFO: Pod pod-configmaps-5dabba15-a3f1-4647-b92b-21ebd36c5c1a no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 17:55:20.229: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3717" for this suite.
Aug  3 17:55:26.274: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 17:55:26.722: INFO: namespace configmap-3717 deletion completed in 6.480835751s

• [SLOW TEST:10.838 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 17:55:26.722: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-9217
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Aug  3 17:55:30.022: INFO: Expected: &{} to match Container's Termination Message:  --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 17:55:30.053: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-9217" for this suite.
Aug  3 17:55:36.096: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 17:55:36.393: INFO: namespace container-runtime-9217 deletion completed in 6.327188643s

• [SLOW TEST:9.670 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  blackbox test
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
    on terminated container
    /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:129
      should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 17:55:36.393: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-2015
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secret-namespace-5961
STEP: Creating secret with name secret-test-ed93f8a3-dce6-4032-9973-4ce17d4ac3f3
STEP: Creating a pod to test consume secrets
Aug  3 17:55:37.049: INFO: Waiting up to 5m0s for pod "pod-secrets-727533fa-ba1b-42ad-868d-717e5522bf36" in namespace "secrets-2015" to be "success or failure"
Aug  3 17:55:37.057: INFO: Pod "pod-secrets-727533fa-ba1b-42ad-868d-717e5522bf36": Phase="Pending", Reason="", readiness=false. Elapsed: 7.764271ms
Aug  3 17:55:39.065: INFO: Pod "pod-secrets-727533fa-ba1b-42ad-868d-717e5522bf36": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015839422s
Aug  3 17:55:41.073: INFO: Pod "pod-secrets-727533fa-ba1b-42ad-868d-717e5522bf36": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023783493s
STEP: Saw pod success
Aug  3 17:55:41.073: INFO: Pod "pod-secrets-727533fa-ba1b-42ad-868d-717e5522bf36" satisfied condition "success or failure"
Aug  3 17:55:41.081: INFO: Trying to get logs from node 10.188.31.32 pod pod-secrets-727533fa-ba1b-42ad-868d-717e5522bf36 container secret-volume-test: <nil>
STEP: delete the pod
Aug  3 17:55:41.128: INFO: Waiting for pod pod-secrets-727533fa-ba1b-42ad-868d-717e5522bf36 to disappear
Aug  3 17:55:41.134: INFO: Pod pod-secrets-727533fa-ba1b-42ad-868d-717e5522bf36 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 17:55:41.134: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-2015" for this suite.
Aug  3 17:55:47.189: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 17:55:47.581: INFO: namespace secrets-2015 deletion completed in 6.432853327s
STEP: Destroying namespace "secret-namespace-5961" for this suite.
Aug  3 17:55:53.616: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 17:55:53.956: INFO: namespace secret-namespace-5961 deletion completed in 6.375003903s

• [SLOW TEST:17.563 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 17:55:53.958: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-8865
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0644 on node default medium
Aug  3 17:55:54.192: INFO: Waiting up to 5m0s for pod "pod-1f2fe60c-b0b7-4aa1-b335-2c0aa36fe626" in namespace "emptydir-8865" to be "success or failure"
Aug  3 17:55:54.200: INFO: Pod "pod-1f2fe60c-b0b7-4aa1-b335-2c0aa36fe626": Phase="Pending", Reason="", readiness=false. Elapsed: 8.307244ms
Aug  3 17:55:56.210: INFO: Pod "pod-1f2fe60c-b0b7-4aa1-b335-2c0aa36fe626": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017814223s
Aug  3 17:55:58.229: INFO: Pod "pod-1f2fe60c-b0b7-4aa1-b335-2c0aa36fe626": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.037113083s
STEP: Saw pod success
Aug  3 17:55:58.229: INFO: Pod "pod-1f2fe60c-b0b7-4aa1-b335-2c0aa36fe626" satisfied condition "success or failure"
Aug  3 17:55:58.239: INFO: Trying to get logs from node 10.188.31.32 pod pod-1f2fe60c-b0b7-4aa1-b335-2c0aa36fe626 container test-container: <nil>
STEP: delete the pod
Aug  3 17:55:58.283: INFO: Waiting for pod pod-1f2fe60c-b0b7-4aa1-b335-2c0aa36fe626 to disappear
Aug  3 17:55:58.293: INFO: Pod pod-1f2fe60c-b0b7-4aa1-b335-2c0aa36fe626 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 17:55:58.293: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8865" for this suite.
Aug  3 17:56:04.339: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 17:56:04.634: INFO: namespace emptydir-8865 deletion completed in 6.328190854s

• [SLOW TEST:10.676 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 17:56:04.634: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-1058
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0644 on node default medium
Aug  3 17:56:04.887: INFO: Waiting up to 5m0s for pod "pod-44354b03-c70a-4162-869b-67469e95fc7d" in namespace "emptydir-1058" to be "success or failure"
Aug  3 17:56:04.897: INFO: Pod "pod-44354b03-c70a-4162-869b-67469e95fc7d": Phase="Pending", Reason="", readiness=false. Elapsed: 9.095475ms
Aug  3 17:56:06.905: INFO: Pod "pod-44354b03-c70a-4162-869b-67469e95fc7d": Phase="Running", Reason="", readiness=true. Elapsed: 2.017731416s
Aug  3 17:56:08.914: INFO: Pod "pod-44354b03-c70a-4162-869b-67469e95fc7d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.026246151s
STEP: Saw pod success
Aug  3 17:56:08.914: INFO: Pod "pod-44354b03-c70a-4162-869b-67469e95fc7d" satisfied condition "success or failure"
Aug  3 17:56:08.921: INFO: Trying to get logs from node 10.188.31.32 pod pod-44354b03-c70a-4162-869b-67469e95fc7d container test-container: <nil>
STEP: delete the pod
Aug  3 17:56:08.968: INFO: Waiting for pod pod-44354b03-c70a-4162-869b-67469e95fc7d to disappear
Aug  3 17:56:08.976: INFO: Pod pod-44354b03-c70a-4162-869b-67469e95fc7d no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 17:56:08.976: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1058" for this suite.
Aug  3 17:56:15.029: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 17:56:15.376: INFO: namespace emptydir-1058 deletion completed in 6.386626607s

• [SLOW TEST:10.741 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 17:56:15.376: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-2940
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-c3e75f51-83a1-49aa-bb36-d8a96014ebc8
STEP: Creating a pod to test consume secrets
Aug  3 17:56:15.624: INFO: Waiting up to 5m0s for pod "pod-secrets-bcbcf9fb-699d-47a7-8a13-454aafc7714b" in namespace "secrets-2940" to be "success or failure"
Aug  3 17:56:15.633: INFO: Pod "pod-secrets-bcbcf9fb-699d-47a7-8a13-454aafc7714b": Phase="Pending", Reason="", readiness=false. Elapsed: 9.201886ms
Aug  3 17:56:17.641: INFO: Pod "pod-secrets-bcbcf9fb-699d-47a7-8a13-454aafc7714b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.017370326s
STEP: Saw pod success
Aug  3 17:56:17.641: INFO: Pod "pod-secrets-bcbcf9fb-699d-47a7-8a13-454aafc7714b" satisfied condition "success or failure"
Aug  3 17:56:17.649: INFO: Trying to get logs from node 10.188.31.32 pod pod-secrets-bcbcf9fb-699d-47a7-8a13-454aafc7714b container secret-env-test: <nil>
STEP: delete the pod
Aug  3 17:56:17.688: INFO: Waiting for pod pod-secrets-bcbcf9fb-699d-47a7-8a13-454aafc7714b to disappear
Aug  3 17:56:17.698: INFO: Pod pod-secrets-bcbcf9fb-699d-47a7-8a13-454aafc7714b no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 17:56:17.698: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-2940" for this suite.
Aug  3 17:56:23.750: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 17:56:24.070: INFO: namespace secrets-2940 deletion completed in 6.359904624s

• [SLOW TEST:8.694 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-storage] EmptyDir volumes 
  pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 17:56:24.071: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-5555
STEP: Waiting for a default service account to be provisioned in namespace
[It] pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating Pod
STEP: Waiting for the pod running
STEP: Geting the pod
STEP: Reading file content from the nginx-container
Aug  3 17:56:28.365: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 exec pod-sharedvolume-b629c559-9736-4ef5-9bf4-673413bbe650 -c busybox-main-container --namespace=emptydir-5555 -- cat /usr/share/volumeshare/shareddata.txt'
Aug  3 17:56:28.832: INFO: stderr: ""
Aug  3 17:56:28.832: INFO: stdout: "Hello from the busy-box sub-container\n"
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 17:56:28.832: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5555" for this suite.
Aug  3 17:56:34.890: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 17:56:35.201: INFO: namespace emptydir-5555 deletion completed in 6.350920984s

• [SLOW TEST:11.130 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 17:56:35.202: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-3907
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Aug  3 17:56:39.494: INFO: Waiting up to 5m0s for pod "client-envvars-7a939a24-22aa-4e84-86d6-bfd039e892f4" in namespace "pods-3907" to be "success or failure"
Aug  3 17:56:39.502: INFO: Pod "client-envvars-7a939a24-22aa-4e84-86d6-bfd039e892f4": Phase="Pending", Reason="", readiness=false. Elapsed: 8.333535ms
Aug  3 17:56:41.511: INFO: Pod "client-envvars-7a939a24-22aa-4e84-86d6-bfd039e892f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016654597s
STEP: Saw pod success
Aug  3 17:56:41.511: INFO: Pod "client-envvars-7a939a24-22aa-4e84-86d6-bfd039e892f4" satisfied condition "success or failure"
Aug  3 17:56:41.549: INFO: Trying to get logs from node 10.188.31.22 pod client-envvars-7a939a24-22aa-4e84-86d6-bfd039e892f4 container env3cont: <nil>
STEP: delete the pod
Aug  3 17:56:41.604: INFO: Waiting for pod client-envvars-7a939a24-22aa-4e84-86d6-bfd039e892f4 to disappear
Aug  3 17:56:41.629: INFO: Pod client-envvars-7a939a24-22aa-4e84-86d6-bfd039e892f4 no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 17:56:41.629: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-3907" for this suite.
Aug  3 17:57:27.673: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 17:57:28.099: INFO: namespace pods-3907 deletion completed in 46.45772273s

• [SLOW TEST:52.897 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 17:57:28.099: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-4700
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
Aug  3 17:57:28.336: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 17:57:31.573: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-4700" for this suite.
Aug  3 17:57:37.633: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 17:57:37.946: INFO: namespace init-container-4700 deletion completed in 6.360626118s

• [SLOW TEST:9.847 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 17:57:37.946: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-4961
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating all guestbook components
Aug  3 17:57:38.189: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Aug  3 17:57:38.189: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 create -f - --namespace=kubectl-4961'
Aug  3 17:57:38.526: INFO: stderr: ""
Aug  3 17:57:38.526: INFO: stdout: "service/redis-slave created\n"
Aug  3 17:57:38.526: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Aug  3 17:57:38.526: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 create -f - --namespace=kubectl-4961'
Aug  3 17:57:38.810: INFO: stderr: ""
Aug  3 17:57:38.810: INFO: stdout: "service/redis-master created\n"
Aug  3 17:57:38.810: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Aug  3 17:57:38.810: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 create -f - --namespace=kubectl-4961'
Aug  3 17:57:39.052: INFO: stderr: ""
Aug  3 17:57:39.052: INFO: stdout: "service/frontend created\n"
Aug  3 17:57:39.052: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: guestbook
      tier: frontend
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Aug  3 17:57:39.052: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 create -f - --namespace=kubectl-4961'
Aug  3 17:57:39.361: INFO: stderr: ""
Aug  3 17:57:39.361: INFO: stdout: "deployment.apps/frontend created\n"
Aug  3 17:57:39.361: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  selector:
    matchLabels:
      app: redis
      role: master
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Aug  3 17:57:39.361: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 create -f - --namespace=kubectl-4961'
Aug  3 17:57:39.586: INFO: stderr: ""
Aug  3 17:57:39.586: INFO: stdout: "deployment.apps/redis-master created\n"
Aug  3 17:57:39.586: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  selector:
    matchLabels:
      app: redis
      role: slave
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave:v3
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Aug  3 17:57:39.586: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 create -f - --namespace=kubectl-4961'
Aug  3 17:57:39.825: INFO: stderr: ""
Aug  3 17:57:39.825: INFO: stdout: "deployment.apps/redis-slave created\n"
STEP: validating guestbook app
Aug  3 17:57:39.825: INFO: Waiting for all frontend pods to be Running.
Aug  3 17:57:44.875: INFO: Waiting for frontend to serve content.
Aug  3 17:57:44.904: INFO: Trying to add a new entry to the guestbook.
Aug  3 17:57:44.933: INFO: Verifying that added entry can be retrieved.
Aug  3 17:57:44.962: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Aug  3 17:57:49.992: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Aug  3 17:57:55.024: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Aug  3 17:58:00.062: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Aug  3 17:58:05.094: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Aug  3 17:58:10.129: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Aug  3 17:58:15.159: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Aug  3 17:58:20.191: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Aug  3 17:58:25.238: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Aug  3 17:58:30.268: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Aug  3 17:58:35.309: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Aug  3 17:58:40.359: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
STEP: using delete to clean up resources
Aug  3 17:58:45.389: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 delete --grace-period=0 --force -f - --namespace=kubectl-4961'
Aug  3 17:58:45.562: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug  3 17:58:45.562: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Aug  3 17:58:45.562: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 delete --grace-period=0 --force -f - --namespace=kubectl-4961'
Aug  3 17:58:45.714: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug  3 17:58:45.714: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Aug  3 17:58:45.714: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 delete --grace-period=0 --force -f - --namespace=kubectl-4961'
Aug  3 17:58:45.898: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug  3 17:58:45.898: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Aug  3 17:58:45.898: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 delete --grace-period=0 --force -f - --namespace=kubectl-4961'
Aug  3 17:58:46.027: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug  3 17:58:46.027: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Aug  3 17:58:46.027: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 delete --grace-period=0 --force -f - --namespace=kubectl-4961'
Aug  3 17:58:46.299: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug  3 17:58:46.299: INFO: stdout: "deployment.apps \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Aug  3 17:58:46.299: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 delete --grace-period=0 --force -f - --namespace=kubectl-4961'
Aug  3 17:58:46.474: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug  3 17:58:46.474: INFO: stdout: "deployment.apps \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 17:58:46.474: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4961" for this suite.
Aug  3 17:59:28.528: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 17:59:28.840: INFO: namespace kubectl-4961 deletion completed in 42.353411443s

• [SLOW TEST:110.895 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Guestbook application
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 17:59:28.843: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-5961
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test override command
Aug  3 17:59:29.081: INFO: Waiting up to 5m0s for pod "client-containers-de3e21f6-c1aa-4743-b634-e822d0b8d784" in namespace "containers-5961" to be "success or failure"
Aug  3 17:59:29.089: INFO: Pod "client-containers-de3e21f6-c1aa-4743-b634-e822d0b8d784": Phase="Pending", Reason="", readiness=false. Elapsed: 7.996075ms
Aug  3 17:59:31.109: INFO: Pod "client-containers-de3e21f6-c1aa-4743-b634-e822d0b8d784": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.028547422s
STEP: Saw pod success
Aug  3 17:59:31.109: INFO: Pod "client-containers-de3e21f6-c1aa-4743-b634-e822d0b8d784" satisfied condition "success or failure"
Aug  3 17:59:31.117: INFO: Trying to get logs from node 10.188.31.32 pod client-containers-de3e21f6-c1aa-4743-b634-e822d0b8d784 container test-container: <nil>
STEP: delete the pod
Aug  3 17:59:31.161: INFO: Waiting for pod client-containers-de3e21f6-c1aa-4743-b634-e822d0b8d784 to disappear
Aug  3 17:59:31.169: INFO: Pod client-containers-de3e21f6-c1aa-4743-b634-e822d0b8d784 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 17:59:31.169: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-5961" for this suite.
Aug  3 17:59:37.214: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 17:59:37.520: INFO: namespace containers-5961 deletion completed in 6.340711544s

• [SLOW TEST:8.678 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 17:59:37.521: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-3783
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Aug  3 17:59:37.748: INFO: Waiting up to 5m0s for pod "downward-api-c3b92b4b-297f-43ff-be76-23801a6642ae" in namespace "downward-api-3783" to be "success or failure"
Aug  3 17:59:37.755: INFO: Pod "downward-api-c3b92b4b-297f-43ff-be76-23801a6642ae": Phase="Pending", Reason="", readiness=false. Elapsed: 7.258352ms
Aug  3 17:59:39.763: INFO: Pod "downward-api-c3b92b4b-297f-43ff-be76-23801a6642ae": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015368963s
Aug  3 17:59:41.771: INFO: Pod "downward-api-c3b92b4b-297f-43ff-be76-23801a6642ae": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023174364s
STEP: Saw pod success
Aug  3 17:59:41.771: INFO: Pod "downward-api-c3b92b4b-297f-43ff-be76-23801a6642ae" satisfied condition "success or failure"
Aug  3 17:59:41.779: INFO: Trying to get logs from node 10.188.31.32 pod downward-api-c3b92b4b-297f-43ff-be76-23801a6642ae container dapi-container: <nil>
STEP: delete the pod
Aug  3 17:59:41.822: INFO: Waiting for pod downward-api-c3b92b4b-297f-43ff-be76-23801a6642ae to disappear
Aug  3 17:59:41.829: INFO: Pod downward-api-c3b92b4b-297f-43ff-be76-23801a6642ae no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 17:59:41.829: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3783" for this suite.
Aug  3 17:59:47.873: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 17:59:48.215: INFO: namespace downward-api-3783 deletion completed in 6.374085467s

• [SLOW TEST:10.695 seconds]
[sig-node] Downward API
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 17:59:48.216: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-7312
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1686
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Aug  3 17:59:48.434: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-7312'
Aug  3 17:59:48.579: INFO: stderr: ""
Aug  3 17:59:48.579: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1691
Aug  3 17:59:48.587: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 delete pods e2e-test-nginx-pod --namespace=kubectl-7312'
Aug  3 17:59:56.984: INFO: stderr: ""
Aug  3 17:59:56.984: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 17:59:56.984: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7312" for this suite.
Aug  3 18:00:03.252: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 18:00:03.568: INFO: namespace kubectl-7312 deletion completed in 6.571029134s

• [SLOW TEST:15.352 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run pod
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 18:00:03.568: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7680
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-map-71318015-36fc-4f12-80eb-c498f382c01d
STEP: Creating a pod to test consume configMaps
Aug  3 18:00:03.805: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-72b6e045-56d8-4242-a825-78f8410983de" in namespace "projected-7680" to be "success or failure"
Aug  3 18:00:03.814: INFO: Pod "pod-projected-configmaps-72b6e045-56d8-4242-a825-78f8410983de": Phase="Pending", Reason="", readiness=false. Elapsed: 8.540391ms
Aug  3 18:00:05.829: INFO: Pod "pod-projected-configmaps-72b6e045-56d8-4242-a825-78f8410983de": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024144468s
Aug  3 18:00:07.838: INFO: Pod "pod-projected-configmaps-72b6e045-56d8-4242-a825-78f8410983de": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.033064027s
STEP: Saw pod success
Aug  3 18:00:07.838: INFO: Pod "pod-projected-configmaps-72b6e045-56d8-4242-a825-78f8410983de" satisfied condition "success or failure"
Aug  3 18:00:07.845: INFO: Trying to get logs from node 10.188.31.32 pod pod-projected-configmaps-72b6e045-56d8-4242-a825-78f8410983de container projected-configmap-volume-test: <nil>
STEP: delete the pod
Aug  3 18:00:07.915: INFO: Waiting for pod pod-projected-configmaps-72b6e045-56d8-4242-a825-78f8410983de to disappear
Aug  3 18:00:07.926: INFO: Pod pod-projected-configmaps-72b6e045-56d8-4242-a825-78f8410983de no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 18:00:07.926: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7680" for this suite.
Aug  3 18:00:13.975: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 18:00:14.331: INFO: namespace projected-7680 deletion completed in 6.392212834s

• [SLOW TEST:10.763 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 18:00:14.331: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-7949
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-downwardapi-l2lb
STEP: Creating a pod to test atomic-volume-subpath
Aug  3 18:00:14.593: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-l2lb" in namespace "subpath-7949" to be "success or failure"
Aug  3 18:00:14.601: INFO: Pod "pod-subpath-test-downwardapi-l2lb": Phase="Pending", Reason="", readiness=false. Elapsed: 8.429983ms
Aug  3 18:00:16.611: INFO: Pod "pod-subpath-test-downwardapi-l2lb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01777241s
Aug  3 18:00:18.619: INFO: Pod "pod-subpath-test-downwardapi-l2lb": Phase="Running", Reason="", readiness=true. Elapsed: 4.02650778s
Aug  3 18:00:20.631: INFO: Pod "pod-subpath-test-downwardapi-l2lb": Phase="Running", Reason="", readiness=true. Elapsed: 6.037783057s
Aug  3 18:00:22.649: INFO: Pod "pod-subpath-test-downwardapi-l2lb": Phase="Running", Reason="", readiness=true. Elapsed: 8.056157789s
Aug  3 18:00:24.657: INFO: Pod "pod-subpath-test-downwardapi-l2lb": Phase="Running", Reason="", readiness=true. Elapsed: 10.064592864s
Aug  3 18:00:26.665: INFO: Pod "pod-subpath-test-downwardapi-l2lb": Phase="Running", Reason="", readiness=true. Elapsed: 12.072383845s
Aug  3 18:00:28.674: INFO: Pod "pod-subpath-test-downwardapi-l2lb": Phase="Running", Reason="", readiness=true. Elapsed: 14.080822807s
Aug  3 18:00:30.683: INFO: Pod "pod-subpath-test-downwardapi-l2lb": Phase="Running", Reason="", readiness=true. Elapsed: 16.090125801s
Aug  3 18:00:32.691: INFO: Pod "pod-subpath-test-downwardapi-l2lb": Phase="Running", Reason="", readiness=true. Elapsed: 18.098418367s
Aug  3 18:00:34.700: INFO: Pod "pod-subpath-test-downwardapi-l2lb": Phase="Running", Reason="", readiness=true. Elapsed: 20.106803094s
Aug  3 18:00:36.708: INFO: Pod "pod-subpath-test-downwardapi-l2lb": Phase="Running", Reason="", readiness=true. Elapsed: 22.115412388s
Aug  3 18:00:38.716: INFO: Pod "pod-subpath-test-downwardapi-l2lb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.123398849s
STEP: Saw pod success
Aug  3 18:00:38.716: INFO: Pod "pod-subpath-test-downwardapi-l2lb" satisfied condition "success or failure"
Aug  3 18:00:38.724: INFO: Trying to get logs from node 10.188.31.32 pod pod-subpath-test-downwardapi-l2lb container test-container-subpath-downwardapi-l2lb: <nil>
STEP: delete the pod
Aug  3 18:00:38.771: INFO: Waiting for pod pod-subpath-test-downwardapi-l2lb to disappear
Aug  3 18:00:38.778: INFO: Pod pod-subpath-test-downwardapi-l2lb no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-l2lb
Aug  3 18:00:38.778: INFO: Deleting pod "pod-subpath-test-downwardapi-l2lb" in namespace "subpath-7949"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 18:00:38.786: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-7949" for this suite.
Aug  3 18:00:44.845: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 18:00:45.130: INFO: namespace subpath-7949 deletion completed in 6.330973607s

• [SLOW TEST:30.799 seconds]
[sig-storage] Subpath
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with downward pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 18:00:45.131: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8078
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Aug  3 18:00:45.391: INFO: Waiting up to 5m0s for pod "downwardapi-volume-eb42db0e-f04d-4700-ae34-e9f17dafd544" in namespace "projected-8078" to be "success or failure"
Aug  3 18:00:45.399: INFO: Pod "downwardapi-volume-eb42db0e-f04d-4700-ae34-e9f17dafd544": Phase="Pending", Reason="", readiness=false. Elapsed: 7.962182ms
Aug  3 18:00:47.409: INFO: Pod "downwardapi-volume-eb42db0e-f04d-4700-ae34-e9f17dafd544": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.018212239s
STEP: Saw pod success
Aug  3 18:00:47.409: INFO: Pod "downwardapi-volume-eb42db0e-f04d-4700-ae34-e9f17dafd544" satisfied condition "success or failure"
Aug  3 18:00:47.416: INFO: Trying to get logs from node 10.188.31.32 pod downwardapi-volume-eb42db0e-f04d-4700-ae34-e9f17dafd544 container client-container: <nil>
STEP: delete the pod
Aug  3 18:00:47.460: INFO: Waiting for pod downwardapi-volume-eb42db0e-f04d-4700-ae34-e9f17dafd544 to disappear
Aug  3 18:00:47.470: INFO: Pod downwardapi-volume-eb42db0e-f04d-4700-ae34-e9f17dafd544 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 18:00:47.470: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8078" for this suite.
Aug  3 18:00:53.520: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 18:00:53.927: INFO: namespace projected-8078 deletion completed in 6.444151799s

• [SLOW TEST:8.796 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 18:00:53.929: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-3536
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test env composition
Aug  3 18:00:54.159: INFO: Waiting up to 5m0s for pod "var-expansion-ce2d518c-e42a-4886-b91a-9301f7a16879" in namespace "var-expansion-3536" to be "success or failure"
Aug  3 18:00:54.166: INFO: Pod "var-expansion-ce2d518c-e42a-4886-b91a-9301f7a16879": Phase="Pending", Reason="", readiness=false. Elapsed: 7.550994ms
Aug  3 18:00:56.175: INFO: Pod "var-expansion-ce2d518c-e42a-4886-b91a-9301f7a16879": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016395205s
STEP: Saw pod success
Aug  3 18:00:56.175: INFO: Pod "var-expansion-ce2d518c-e42a-4886-b91a-9301f7a16879" satisfied condition "success or failure"
Aug  3 18:00:56.183: INFO: Trying to get logs from node 10.188.31.32 pod var-expansion-ce2d518c-e42a-4886-b91a-9301f7a16879 container dapi-container: <nil>
STEP: delete the pod
Aug  3 18:00:56.233: INFO: Waiting for pod var-expansion-ce2d518c-e42a-4886-b91a-9301f7a16879 to disappear
Aug  3 18:00:56.241: INFO: Pod var-expansion-ce2d518c-e42a-4886-b91a-9301f7a16879 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 18:00:56.241: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-3536" for this suite.
Aug  3 18:01:02.284: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 18:01:02.644: INFO: namespace var-expansion-3536 deletion completed in 6.391175802s

• [SLOW TEST:8.716 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 18:01:02.645: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-2415
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0666 on tmpfs
Aug  3 18:01:03.092: INFO: Waiting up to 5m0s for pod "pod-cd6808d4-a409-423e-8e78-25f2af529001" in namespace "emptydir-2415" to be "success or failure"
Aug  3 18:01:03.099: INFO: Pod "pod-cd6808d4-a409-423e-8e78-25f2af529001": Phase="Pending", Reason="", readiness=false. Elapsed: 7.003756ms
Aug  3 18:01:05.117: INFO: Pod "pod-cd6808d4-a409-423e-8e78-25f2af529001": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.025276376s
STEP: Saw pod success
Aug  3 18:01:05.117: INFO: Pod "pod-cd6808d4-a409-423e-8e78-25f2af529001" satisfied condition "success or failure"
Aug  3 18:01:05.126: INFO: Trying to get logs from node 10.188.31.32 pod pod-cd6808d4-a409-423e-8e78-25f2af529001 container test-container: <nil>
STEP: delete the pod
Aug  3 18:01:05.166: INFO: Waiting for pod pod-cd6808d4-a409-423e-8e78-25f2af529001 to disappear
Aug  3 18:01:05.177: INFO: Pod pod-cd6808d4-a409-423e-8e78-25f2af529001 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 18:01:05.177: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2415" for this suite.
Aug  3 18:01:11.226: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 18:01:11.636: INFO: namespace emptydir-2415 deletion completed in 6.447749334s

• [SLOW TEST:8.991 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 18:01:11.636: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-1017
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-be4532b2-c5f2-4eca-8ed8-e36181d52735
STEP: Creating a pod to test consume secrets
Aug  3 18:01:11.893: INFO: Waiting up to 5m0s for pod "pod-secrets-52b8ee0b-e153-41a8-b005-8da4d1f55ef6" in namespace "secrets-1017" to be "success or failure"
Aug  3 18:01:11.903: INFO: Pod "pod-secrets-52b8ee0b-e153-41a8-b005-8da4d1f55ef6": Phase="Pending", Reason="", readiness=false. Elapsed: 10.307737ms
Aug  3 18:01:13.913: INFO: Pod "pod-secrets-52b8ee0b-e153-41a8-b005-8da4d1f55ef6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019539689s
Aug  3 18:01:15.921: INFO: Pod "pod-secrets-52b8ee0b-e153-41a8-b005-8da4d1f55ef6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.027859967s
STEP: Saw pod success
Aug  3 18:01:15.921: INFO: Pod "pod-secrets-52b8ee0b-e153-41a8-b005-8da4d1f55ef6" satisfied condition "success or failure"
Aug  3 18:01:15.931: INFO: Trying to get logs from node 10.188.31.32 pod pod-secrets-52b8ee0b-e153-41a8-b005-8da4d1f55ef6 container secret-volume-test: <nil>
STEP: delete the pod
Aug  3 18:01:15.998: INFO: Waiting for pod pod-secrets-52b8ee0b-e153-41a8-b005-8da4d1f55ef6 to disappear
Aug  3 18:01:16.007: INFO: Pod pod-secrets-52b8ee0b-e153-41a8-b005-8da4d1f55ef6 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 18:01:16.007: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-1017" for this suite.
Aug  3 18:01:22.048: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 18:01:22.386: INFO: namespace secrets-1017 deletion completed in 6.368422132s

• [SLOW TEST:10.750 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 18:01:22.388: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-7490
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 18:01:24.684: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-7490" for this suite.
Aug  3 18:02:08.740: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 18:02:09.092: INFO: namespace kubelet-test-7490 deletion completed in 44.389220259s

• [SLOW TEST:46.704 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when scheduling a busybox Pod with hostAliases
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:136
    should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 18:02:09.093: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-7551
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Aug  3 18:02:09.403: INFO: Number of nodes with available pods: 0
Aug  3 18:02:09.403: INFO: Node 10.188.31.22 is running more than one daemon pod
Aug  3 18:02:10.425: INFO: Number of nodes with available pods: 0
Aug  3 18:02:10.425: INFO: Node 10.188.31.22 is running more than one daemon pod
Aug  3 18:02:11.423: INFO: Number of nodes with available pods: 2
Aug  3 18:02:11.423: INFO: Node 10.188.31.22 is running more than one daemon pod
Aug  3 18:02:12.501: INFO: Number of nodes with available pods: 3
Aug  3 18:02:12.501: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Stop a daemon pod, check that the daemon pod is revived.
Aug  3 18:02:12.557: INFO: Number of nodes with available pods: 2
Aug  3 18:02:12.557: INFO: Node 10.188.31.22 is running more than one daemon pod
Aug  3 18:02:13.581: INFO: Number of nodes with available pods: 2
Aug  3 18:02:13.581: INFO: Node 10.188.31.22 is running more than one daemon pod
Aug  3 18:02:14.578: INFO: Number of nodes with available pods: 2
Aug  3 18:02:14.578: INFO: Node 10.188.31.22 is running more than one daemon pod
Aug  3 18:02:15.578: INFO: Number of nodes with available pods: 2
Aug  3 18:02:15.578: INFO: Node 10.188.31.22 is running more than one daemon pod
Aug  3 18:02:16.578: INFO: Number of nodes with available pods: 2
Aug  3 18:02:16.578: INFO: Node 10.188.31.22 is running more than one daemon pod
Aug  3 18:02:17.586: INFO: Number of nodes with available pods: 2
Aug  3 18:02:17.586: INFO: Node 10.188.31.22 is running more than one daemon pod
Aug  3 18:02:18.580: INFO: Number of nodes with available pods: 2
Aug  3 18:02:18.580: INFO: Node 10.188.31.22 is running more than one daemon pod
Aug  3 18:02:19.580: INFO: Number of nodes with available pods: 2
Aug  3 18:02:19.580: INFO: Node 10.188.31.22 is running more than one daemon pod
Aug  3 18:02:20.589: INFO: Number of nodes with available pods: 2
Aug  3 18:02:20.589: INFO: Node 10.188.31.22 is running more than one daemon pod
Aug  3 18:02:21.578: INFO: Number of nodes with available pods: 2
Aug  3 18:02:21.579: INFO: Node 10.188.31.22 is running more than one daemon pod
Aug  3 18:02:22.577: INFO: Number of nodes with available pods: 2
Aug  3 18:02:22.577: INFO: Node 10.188.31.22 is running more than one daemon pod
Aug  3 18:02:23.578: INFO: Number of nodes with available pods: 2
Aug  3 18:02:23.578: INFO: Node 10.188.31.22 is running more than one daemon pod
Aug  3 18:02:24.580: INFO: Number of nodes with available pods: 3
Aug  3 18:02:24.580: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-7551, will wait for the garbage collector to delete the pods
Aug  3 18:02:24.668: INFO: Deleting DaemonSet.extensions daemon-set took: 22.069616ms
Aug  3 18:02:24.868: INFO: Terminating DaemonSet.extensions daemon-set pods took: 200.417981ms
Aug  3 18:02:35.677: INFO: Number of nodes with available pods: 0
Aug  3 18:02:35.678: INFO: Number of running nodes: 0, number of available pods: 0
Aug  3 18:02:35.685: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-7551/daemonsets","resourceVersion":"35730"},"items":null}

Aug  3 18:02:35.693: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-7551/pods","resourceVersion":"35730"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 18:02:35.734: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-7551" for this suite.
Aug  3 18:02:41.786: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 18:02:42.127: INFO: namespace daemonsets-7551 deletion completed in 6.381831283s

• [SLOW TEST:33.034 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 18:02:42.128: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-1262
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0777 on node default medium
Aug  3 18:02:42.369: INFO: Waiting up to 5m0s for pod "pod-8fad28ea-c16d-42e6-b007-1e84a6c630a1" in namespace "emptydir-1262" to be "success or failure"
Aug  3 18:02:42.380: INFO: Pod "pod-8fad28ea-c16d-42e6-b007-1e84a6c630a1": Phase="Pending", Reason="", readiness=false. Elapsed: 11.514382ms
Aug  3 18:02:44.389: INFO: Pod "pod-8fad28ea-c16d-42e6-b007-1e84a6c630a1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.019967531s
STEP: Saw pod success
Aug  3 18:02:44.389: INFO: Pod "pod-8fad28ea-c16d-42e6-b007-1e84a6c630a1" satisfied condition "success or failure"
Aug  3 18:02:44.397: INFO: Trying to get logs from node 10.188.31.32 pod pod-8fad28ea-c16d-42e6-b007-1e84a6c630a1 container test-container: <nil>
STEP: delete the pod
Aug  3 18:02:44.439: INFO: Waiting for pod pod-8fad28ea-c16d-42e6-b007-1e84a6c630a1 to disappear
Aug  3 18:02:44.446: INFO: Pod pod-8fad28ea-c16d-42e6-b007-1e84a6c630a1 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 18:02:44.446: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1262" for this suite.
Aug  3 18:02:50.489: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 18:02:50.792: INFO: namespace emptydir-1262 deletion completed in 6.332700816s

• [SLOW TEST:8.665 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 18:02:50.793: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-wrapper-2968
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Aug  3 18:02:51.562: INFO: Pod name wrapped-volume-race-0704ff64-ad22-422c-a552-becad41b24ba: Found 0 pods out of 5
Aug  3 18:02:56.576: INFO: Pod name wrapped-volume-race-0704ff64-ad22-422c-a552-becad41b24ba: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-0704ff64-ad22-422c-a552-becad41b24ba in namespace emptydir-wrapper-2968, will wait for the garbage collector to delete the pods
Aug  3 18:02:56.738: INFO: Deleting ReplicationController wrapped-volume-race-0704ff64-ad22-422c-a552-becad41b24ba took: 44.904781ms
Aug  3 18:02:56.939: INFO: Terminating ReplicationController wrapped-volume-race-0704ff64-ad22-422c-a552-becad41b24ba pods took: 200.27198ms
STEP: Creating RC which spawns configmap-volume pods
Aug  3 18:03:42.197: INFO: Pod name wrapped-volume-race-f5262af3-2ab7-40db-930d-86d11ab015e0: Found 0 pods out of 5
Aug  3 18:03:47.211: INFO: Pod name wrapped-volume-race-f5262af3-2ab7-40db-930d-86d11ab015e0: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-f5262af3-2ab7-40db-930d-86d11ab015e0 in namespace emptydir-wrapper-2968, will wait for the garbage collector to delete the pods
Aug  3 18:03:47.363: INFO: Deleting ReplicationController wrapped-volume-race-f5262af3-2ab7-40db-930d-86d11ab015e0 took: 31.259217ms
Aug  3 18:03:47.563: INFO: Terminating ReplicationController wrapped-volume-race-f5262af3-2ab7-40db-930d-86d11ab015e0 pods took: 200.19904ms
STEP: Creating RC which spawns configmap-volume pods
Aug  3 18:04:32.004: INFO: Pod name wrapped-volume-race-21128b34-ddc9-4ab9-9001-5e8aa835592e: Found 0 pods out of 5
Aug  3 18:04:37.029: INFO: Pod name wrapped-volume-race-21128b34-ddc9-4ab9-9001-5e8aa835592e: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-21128b34-ddc9-4ab9-9001-5e8aa835592e in namespace emptydir-wrapper-2968, will wait for the garbage collector to delete the pods
Aug  3 18:04:37.165: INFO: Deleting ReplicationController wrapped-volume-race-21128b34-ddc9-4ab9-9001-5e8aa835592e took: 26.503311ms
Aug  3 18:04:37.366: INFO: Terminating ReplicationController wrapped-volume-race-21128b34-ddc9-4ab9-9001-5e8aa835592e pods took: 200.214306ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 18:05:22.908: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-2968" for this suite.
Aug  3 18:05:30.965: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 18:05:31.323: INFO: namespace emptydir-wrapper-2968 deletion completed in 8.394400028s

• [SLOW TEST:160.529 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 18:05:31.323: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-2539
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating pod
Aug  3 18:05:33.600: INFO: Pod pod-hostip-71552657-c6c4-405a-b671-45f3918319d7 has hostIP: 10.188.31.32
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 18:05:33.600: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-2539" for this suite.
Aug  3 18:05:57.669: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 18:05:57.992: INFO: namespace pods-2539 deletion completed in 24.361327271s

• [SLOW TEST:26.670 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 18:05:57.993: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-618
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0666 on node default medium
Aug  3 18:05:58.250: INFO: Waiting up to 5m0s for pod "pod-177294fd-5e8e-4e22-9970-26a67a7de468" in namespace "emptydir-618" to be "success or failure"
Aug  3 18:05:58.258: INFO: Pod "pod-177294fd-5e8e-4e22-9970-26a67a7de468": Phase="Pending", Reason="", readiness=false. Elapsed: 7.708846ms
Aug  3 18:06:00.266: INFO: Pod "pod-177294fd-5e8e-4e22-9970-26a67a7de468": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015925172s
Aug  3 18:06:02.275: INFO: Pod "pod-177294fd-5e8e-4e22-9970-26a67a7de468": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.025442783s
STEP: Saw pod success
Aug  3 18:06:02.275: INFO: Pod "pod-177294fd-5e8e-4e22-9970-26a67a7de468" satisfied condition "success or failure"
Aug  3 18:06:02.284: INFO: Trying to get logs from node 10.188.31.32 pod pod-177294fd-5e8e-4e22-9970-26a67a7de468 container test-container: <nil>
STEP: delete the pod
Aug  3 18:06:02.350: INFO: Waiting for pod pod-177294fd-5e8e-4e22-9970-26a67a7de468 to disappear
Aug  3 18:06:02.358: INFO: Pod pod-177294fd-5e8e-4e22-9970-26a67a7de468 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 18:06:02.358: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-618" for this suite.
Aug  3 18:06:08.405: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 18:06:08.777: INFO: namespace emptydir-618 deletion completed in 6.4062879s

• [SLOW TEST:10.784 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 18:06:08.778: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-6575
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Aug  3 18:06:08.987: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Aug  3 18:06:09.018: INFO: Pod name sample-pod: Found 0 pods out of 1
Aug  3 18:06:14.034: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Aug  3 18:06:14.034: INFO: Creating deployment "test-rolling-update-deployment"
Aug  3 18:06:14.045: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Aug  3 18:06:14.061: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Aug  3 18:06:16.079: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Aug  3 18:06:16.087: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
Aug  3 18:06:16.138: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment,GenerateName:,Namespace:deployment-6575,SelfLink:/apis/apps/v1/namespaces/deployment-6575/deployments/test-rolling-update-deployment,UID:dcb90b88-c9dd-4ac3-a954-e997b9f1da08,ResourceVersion:36826,Generation:1,CreationTimestamp:2019-08-03 18:06:14 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-08-03 18:06:14 +0000 UTC 2019-08-03 18:06:14 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-08-03 18:06:15 +0000 UTC 2019-08-03 18:06:14 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rolling-update-deployment-79f6b9d75c" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Aug  3 18:06:16.148: INFO: New ReplicaSet "test-rolling-update-deployment-79f6b9d75c" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-79f6b9d75c,GenerateName:,Namespace:deployment-6575,SelfLink:/apis/apps/v1/namespaces/deployment-6575/replicasets/test-rolling-update-deployment-79f6b9d75c,UID:a5fe3d19-3591-488b-a9e1-a45ad599247e,ResourceVersion:36815,Generation:1,CreationTimestamp:2019-08-03 18:06:14 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 79f6b9d75c,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment dcb90b88-c9dd-4ac3-a954-e997b9f1da08 0xc002db0687 0xc002db0688}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 79f6b9d75c,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 79f6b9d75c,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Aug  3 18:06:16.148: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Aug  3 18:06:16.149: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-controller,GenerateName:,Namespace:deployment-6575,SelfLink:/apis/apps/v1/namespaces/deployment-6575/replicasets/test-rolling-update-controller,UID:8216d473-1991-419e-bcb9-1c4c0e676468,ResourceVersion:36825,Generation:2,CreationTimestamp:2019-08-03 18:06:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305832,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment dcb90b88-c9dd-4ac3-a954-e997b9f1da08 0xc002db05b7 0xc002db05b8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Aug  3 18:06:16.160: INFO: Pod "test-rolling-update-deployment-79f6b9d75c-7cbzs" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-79f6b9d75c-7cbzs,GenerateName:test-rolling-update-deployment-79f6b9d75c-,Namespace:deployment-6575,SelfLink:/api/v1/namespaces/deployment-6575/pods/test-rolling-update-deployment-79f6b9d75c-7cbzs,UID:72adbda1-8239-4676-82fa-8127cb4a8ec9,ResourceVersion:36814,Generation:0,CreationTimestamp:2019-08-03 18:06:14 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 79f6b9d75c,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-rolling-update-deployment-79f6b9d75c a5fe3d19-3591-488b-a9e1-a45ad599247e 0xc002db0f87 0xc002db0f88}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-gjmtg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-gjmtg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-gjmtg true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.188.31.32,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002db1000} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002db1020}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-03 18:06:14 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-03 18:06:15 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-03 18:06:15 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-03 18:06:14 +0000 UTC  }],Message:,Reason:,HostIP:10.188.31.32,PodIP:172.30.72.117,StartTime:2019-08-03 18:06:14 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-08-03 18:06:15 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 containerd://782672d6e9792bc6a5cd646d3a3e21f13f67680c60d538b9f30be4ead64a0732}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 18:06:16.160: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-6575" for this suite.
Aug  3 18:06:22.209: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 18:06:22.509: INFO: namespace deployment-6575 deletion completed in 6.335736408s

• [SLOW TEST:13.731 seconds]
[sig-apps] Deployment
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 18:06:22.509: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-3690
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 18:06:46.227: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-3690" for this suite.
Aug  3 18:06:52.289: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 18:06:52.648: INFO: namespace container-runtime-3690 deletion completed in 6.398299358s

• [SLOW TEST:30.138 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  blackbox test
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
    when starting a container that exits
    /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-apps] ReplicationController 
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 18:06:52.648: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-727
STEP: Waiting for a default service account to be provisioned in namespace
[It] should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Aug  3 18:06:52.872: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
STEP: Creating rc "condition-test" that asks for more than the allowed pod quota
STEP: Checking rc "condition-test" has the desired failure condition set
STEP: Scaling down rc "condition-test" to satisfy pod quota
Aug  3 18:06:53.967: INFO: Updating replication controller "condition-test"
STEP: Checking rc "condition-test" has no failure condition set
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 18:06:53.977: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-727" for this suite.
Aug  3 18:07:00.020: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 18:07:00.353: INFO: namespace replication-controller-727 deletion completed in 6.364428012s

• [SLOW TEST:7.705 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 18:07:00.353: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-2578
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir volume type on tmpfs
Aug  3 18:07:00.636: INFO: Waiting up to 5m0s for pod "pod-c0aa9ed5-10bb-4bf0-be3a-ff12067085f4" in namespace "emptydir-2578" to be "success or failure"
Aug  3 18:07:00.644: INFO: Pod "pod-c0aa9ed5-10bb-4bf0-be3a-ff12067085f4": Phase="Pending", Reason="", readiness=false. Elapsed: 7.598409ms
Aug  3 18:07:02.652: INFO: Pod "pod-c0aa9ed5-10bb-4bf0-be3a-ff12067085f4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015582068s
Aug  3 18:07:04.661: INFO: Pod "pod-c0aa9ed5-10bb-4bf0-be3a-ff12067085f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.025138386s
STEP: Saw pod success
Aug  3 18:07:04.661: INFO: Pod "pod-c0aa9ed5-10bb-4bf0-be3a-ff12067085f4" satisfied condition "success or failure"
Aug  3 18:07:04.689: INFO: Trying to get logs from node 10.188.31.32 pod pod-c0aa9ed5-10bb-4bf0-be3a-ff12067085f4 container test-container: <nil>
STEP: delete the pod
Aug  3 18:07:04.731: INFO: Waiting for pod pod-c0aa9ed5-10bb-4bf0-be3a-ff12067085f4 to disappear
Aug  3 18:07:04.739: INFO: Pod pod-c0aa9ed5-10bb-4bf0-be3a-ff12067085f4 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 18:07:04.739: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2578" for this suite.
Aug  3 18:07:10.785: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 18:07:11.093: INFO: namespace emptydir-2578 deletion completed in 6.341848304s

• [SLOW TEST:10.740 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 18:07:11.094: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-8703
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 18:07:11.346: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-8703" for this suite.
Aug  3 18:07:35.398: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 18:07:35.729: INFO: namespace kubelet-test-8703 deletion completed in 24.371306069s

• [SLOW TEST:24.636 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should be possible to delete [NodeConformance] [Conformance]
    /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 18:07:35.731: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-71
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0666 on node default medium
Aug  3 18:07:35.985: INFO: Waiting up to 5m0s for pod "pod-99bc191c-9b52-4cff-b53d-1ca134f20fdb" in namespace "emptydir-71" to be "success or failure"
Aug  3 18:07:35.992: INFO: Pod "pod-99bc191c-9b52-4cff-b53d-1ca134f20fdb": Phase="Pending", Reason="", readiness=false. Elapsed: 7.165659ms
Aug  3 18:07:38.000: INFO: Pod "pod-99bc191c-9b52-4cff-b53d-1ca134f20fdb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015506269s
STEP: Saw pod success
Aug  3 18:07:38.000: INFO: Pod "pod-99bc191c-9b52-4cff-b53d-1ca134f20fdb" satisfied condition "success or failure"
Aug  3 18:07:38.018: INFO: Trying to get logs from node 10.188.31.32 pod pod-99bc191c-9b52-4cff-b53d-1ca134f20fdb container test-container: <nil>
STEP: delete the pod
Aug  3 18:07:38.059: INFO: Waiting for pod pod-99bc191c-9b52-4cff-b53d-1ca134f20fdb to disappear
Aug  3 18:07:38.066: INFO: Pod pod-99bc191c-9b52-4cff-b53d-1ca134f20fdb no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 18:07:38.066: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-71" for this suite.
Aug  3 18:07:44.110: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 18:07:44.397: INFO: namespace emptydir-71 deletion completed in 6.319914663s

• [SLOW TEST:8.666 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 18:07:44.398: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-7510
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Aug  3 18:07:47.670: INFO: Expected: &{OK} to match Container's Termination Message: OK --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 18:07:47.703: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-7510" for this suite.
Aug  3 18:07:53.877: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 18:07:54.200: INFO: namespace container-runtime-7510 deletion completed in 6.48428219s

• [SLOW TEST:9.802 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  blackbox test
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
    on terminated container
    /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:129
      should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 18:07:54.201: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-2120
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 18:07:58.450: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-2120" for this suite.
Aug  3 18:08:04.509: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 18:08:04.835: INFO: namespace kubelet-test-2120 deletion completed in 6.373182912s

• [SLOW TEST:10.635 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should have an terminated reason [NodeConformance] [Conformance]
    /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 18:08:04.836: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-7927
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Aug  3 18:08:05.121: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Aug  3 18:08:05.149: INFO: Number of nodes with available pods: 0
Aug  3 18:08:05.149: INFO: Node 10.188.31.22 is running more than one daemon pod
Aug  3 18:08:06.171: INFO: Number of nodes with available pods: 0
Aug  3 18:08:06.171: INFO: Node 10.188.31.22 is running more than one daemon pod
Aug  3 18:08:07.173: INFO: Number of nodes with available pods: 1
Aug  3 18:08:07.173: INFO: Node 10.188.31.22 is running more than one daemon pod
Aug  3 18:08:08.168: INFO: Number of nodes with available pods: 3
Aug  3 18:08:08.168: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Aug  3 18:08:08.234: INFO: Wrong image for pod: daemon-set-bc4dh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug  3 18:08:08.234: INFO: Wrong image for pod: daemon-set-h8c5q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug  3 18:08:08.234: INFO: Wrong image for pod: daemon-set-mgjj2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug  3 18:08:09.251: INFO: Wrong image for pod: daemon-set-bc4dh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug  3 18:08:09.251: INFO: Wrong image for pod: daemon-set-h8c5q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug  3 18:08:09.251: INFO: Wrong image for pod: daemon-set-mgjj2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug  3 18:08:10.267: INFO: Wrong image for pod: daemon-set-bc4dh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug  3 18:08:10.267: INFO: Wrong image for pod: daemon-set-h8c5q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug  3 18:08:10.267: INFO: Pod daemon-set-h8c5q is not available
Aug  3 18:08:10.267: INFO: Wrong image for pod: daemon-set-mgjj2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug  3 18:08:11.251: INFO: Wrong image for pod: daemon-set-bc4dh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug  3 18:08:11.251: INFO: Wrong image for pod: daemon-set-h8c5q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug  3 18:08:11.251: INFO: Pod daemon-set-h8c5q is not available
Aug  3 18:08:11.251: INFO: Wrong image for pod: daemon-set-mgjj2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug  3 18:08:12.251: INFO: Wrong image for pod: daemon-set-bc4dh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug  3 18:08:12.251: INFO: Wrong image for pod: daemon-set-h8c5q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug  3 18:08:12.251: INFO: Pod daemon-set-h8c5q is not available
Aug  3 18:08:12.251: INFO: Wrong image for pod: daemon-set-mgjj2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug  3 18:08:13.251: INFO: Wrong image for pod: daemon-set-bc4dh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug  3 18:08:13.251: INFO: Wrong image for pod: daemon-set-h8c5q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug  3 18:08:13.251: INFO: Pod daemon-set-h8c5q is not available
Aug  3 18:08:13.251: INFO: Wrong image for pod: daemon-set-mgjj2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug  3 18:08:14.252: INFO: Wrong image for pod: daemon-set-bc4dh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug  3 18:08:14.252: INFO: Wrong image for pod: daemon-set-h8c5q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug  3 18:08:14.252: INFO: Pod daemon-set-h8c5q is not available
Aug  3 18:08:14.252: INFO: Wrong image for pod: daemon-set-mgjj2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug  3 18:08:15.252: INFO: Wrong image for pod: daemon-set-bc4dh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug  3 18:08:15.252: INFO: Wrong image for pod: daemon-set-h8c5q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug  3 18:08:15.252: INFO: Pod daemon-set-h8c5q is not available
Aug  3 18:08:15.252: INFO: Wrong image for pod: daemon-set-mgjj2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug  3 18:08:16.251: INFO: Wrong image for pod: daemon-set-bc4dh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug  3 18:08:16.251: INFO: Wrong image for pod: daemon-set-h8c5q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug  3 18:08:16.251: INFO: Pod daemon-set-h8c5q is not available
Aug  3 18:08:16.251: INFO: Wrong image for pod: daemon-set-mgjj2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug  3 18:08:17.269: INFO: Wrong image for pod: daemon-set-bc4dh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug  3 18:08:17.269: INFO: Pod daemon-set-k5kbv is not available
Aug  3 18:08:17.269: INFO: Wrong image for pod: daemon-set-mgjj2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug  3 18:08:18.251: INFO: Wrong image for pod: daemon-set-bc4dh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug  3 18:08:18.251: INFO: Pod daemon-set-k5kbv is not available
Aug  3 18:08:18.251: INFO: Wrong image for pod: daemon-set-mgjj2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug  3 18:08:19.251: INFO: Wrong image for pod: daemon-set-bc4dh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug  3 18:08:19.251: INFO: Wrong image for pod: daemon-set-mgjj2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug  3 18:08:20.250: INFO: Wrong image for pod: daemon-set-bc4dh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug  3 18:08:20.250: INFO: Wrong image for pod: daemon-set-mgjj2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug  3 18:08:21.263: INFO: Wrong image for pod: daemon-set-bc4dh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug  3 18:08:21.263: INFO: Wrong image for pod: daemon-set-mgjj2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug  3 18:08:21.263: INFO: Pod daemon-set-mgjj2 is not available
Aug  3 18:08:22.252: INFO: Wrong image for pod: daemon-set-bc4dh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug  3 18:08:22.252: INFO: Wrong image for pod: daemon-set-mgjj2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug  3 18:08:22.252: INFO: Pod daemon-set-mgjj2 is not available
Aug  3 18:08:23.252: INFO: Wrong image for pod: daemon-set-bc4dh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug  3 18:08:23.252: INFO: Wrong image for pod: daemon-set-mgjj2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug  3 18:08:23.252: INFO: Pod daemon-set-mgjj2 is not available
Aug  3 18:08:24.256: INFO: Wrong image for pod: daemon-set-bc4dh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug  3 18:08:24.256: INFO: Wrong image for pod: daemon-set-mgjj2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug  3 18:08:24.256: INFO: Pod daemon-set-mgjj2 is not available
Aug  3 18:08:25.252: INFO: Wrong image for pod: daemon-set-bc4dh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug  3 18:08:25.252: INFO: Wrong image for pod: daemon-set-mgjj2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug  3 18:08:25.252: INFO: Pod daemon-set-mgjj2 is not available
Aug  3 18:08:26.251: INFO: Wrong image for pod: daemon-set-bc4dh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug  3 18:08:26.251: INFO: Wrong image for pod: daemon-set-mgjj2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug  3 18:08:26.251: INFO: Pod daemon-set-mgjj2 is not available
Aug  3 18:08:27.251: INFO: Wrong image for pod: daemon-set-bc4dh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug  3 18:08:27.251: INFO: Wrong image for pod: daemon-set-mgjj2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug  3 18:08:27.251: INFO: Pod daemon-set-mgjj2 is not available
Aug  3 18:08:28.253: INFO: Wrong image for pod: daemon-set-bc4dh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug  3 18:08:28.253: INFO: Wrong image for pod: daemon-set-mgjj2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug  3 18:08:28.253: INFO: Pod daemon-set-mgjj2 is not available
Aug  3 18:08:29.252: INFO: Wrong image for pod: daemon-set-bc4dh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug  3 18:08:29.252: INFO: Wrong image for pod: daemon-set-mgjj2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug  3 18:08:29.252: INFO: Pod daemon-set-mgjj2 is not available
Aug  3 18:08:30.252: INFO: Wrong image for pod: daemon-set-bc4dh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug  3 18:08:30.253: INFO: Wrong image for pod: daemon-set-mgjj2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug  3 18:08:30.253: INFO: Pod daemon-set-mgjj2 is not available
Aug  3 18:08:31.252: INFO: Wrong image for pod: daemon-set-bc4dh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug  3 18:08:31.252: INFO: Wrong image for pod: daemon-set-mgjj2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug  3 18:08:31.252: INFO: Pod daemon-set-mgjj2 is not available
Aug  3 18:08:32.251: INFO: Wrong image for pod: daemon-set-bc4dh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug  3 18:08:32.251: INFO: Pod daemon-set-jm8vh is not available
Aug  3 18:08:33.252: INFO: Wrong image for pod: daemon-set-bc4dh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug  3 18:08:33.252: INFO: Pod daemon-set-jm8vh is not available
Aug  3 18:08:34.262: INFO: Wrong image for pod: daemon-set-bc4dh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug  3 18:08:35.251: INFO: Wrong image for pod: daemon-set-bc4dh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug  3 18:08:35.251: INFO: Pod daemon-set-bc4dh is not available
Aug  3 18:08:36.251: INFO: Pod daemon-set-d7mtl is not available
STEP: Check that daemon pods are still running on every node of the cluster.
Aug  3 18:08:36.306: INFO: Number of nodes with available pods: 2
Aug  3 18:08:36.306: INFO: Node 10.188.31.24 is running more than one daemon pod
Aug  3 18:08:37.325: INFO: Number of nodes with available pods: 2
Aug  3 18:08:37.325: INFO: Node 10.188.31.24 is running more than one daemon pod
Aug  3 18:08:38.349: INFO: Number of nodes with available pods: 3
Aug  3 18:08:38.349: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-7927, will wait for the garbage collector to delete the pods
Aug  3 18:08:38.472: INFO: Deleting DaemonSet.extensions daemon-set took: 21.349952ms
Aug  3 18:08:38.672: INFO: Terminating DaemonSet.extensions daemon-set pods took: 200.294582ms
Aug  3 18:08:47.081: INFO: Number of nodes with available pods: 0
Aug  3 18:08:47.081: INFO: Number of running nodes: 0, number of available pods: 0
Aug  3 18:08:47.090: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-7927/daemonsets","resourceVersion":"37600"},"items":null}

Aug  3 18:08:47.097: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-7927/pods","resourceVersion":"37600"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 18:08:47.133: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-7927" for this suite.
Aug  3 18:08:55.175: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 18:08:55.532: INFO: namespace daemonsets-7927 deletion completed in 8.387539922s

• [SLOW TEST:50.696 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 18:08:55.533: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-7649
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir volume type on node default medium
Aug  3 18:08:55.764: INFO: Waiting up to 5m0s for pod "pod-c8def6a0-9ba1-4cba-a5bc-2d516a09aa8d" in namespace "emptydir-7649" to be "success or failure"
Aug  3 18:08:55.772: INFO: Pod "pod-c8def6a0-9ba1-4cba-a5bc-2d516a09aa8d": Phase="Pending", Reason="", readiness=false. Elapsed: 7.472094ms
Aug  3 18:08:57.782: INFO: Pod "pod-c8def6a0-9ba1-4cba-a5bc-2d516a09aa8d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017510114s
Aug  3 18:08:59.790: INFO: Pod "pod-c8def6a0-9ba1-4cba-a5bc-2d516a09aa8d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.025639824s
STEP: Saw pod success
Aug  3 18:08:59.790: INFO: Pod "pod-c8def6a0-9ba1-4cba-a5bc-2d516a09aa8d" satisfied condition "success or failure"
Aug  3 18:08:59.798: INFO: Trying to get logs from node 10.188.31.32 pod pod-c8def6a0-9ba1-4cba-a5bc-2d516a09aa8d container test-container: <nil>
STEP: delete the pod
Aug  3 18:08:59.841: INFO: Waiting for pod pod-c8def6a0-9ba1-4cba-a5bc-2d516a09aa8d to disappear
Aug  3 18:08:59.856: INFO: Pod pod-c8def6a0-9ba1-4cba-a5bc-2d516a09aa8d no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 18:08:59.856: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7649" for this suite.
Aug  3 18:09:05.900: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 18:09:06.229: INFO: namespace emptydir-7649 deletion completed in 6.361197247s

• [SLOW TEST:10.697 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 18:09:06.231: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-4511
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-configmap-c5kt
STEP: Creating a pod to test atomic-volume-subpath
Aug  3 18:09:06.495: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-c5kt" in namespace "subpath-4511" to be "success or failure"
Aug  3 18:09:06.504: INFO: Pod "pod-subpath-test-configmap-c5kt": Phase="Pending", Reason="", readiness=false. Elapsed: 9.24187ms
Aug  3 18:09:08.514: INFO: Pod "pod-subpath-test-configmap-c5kt": Phase="Running", Reason="", readiness=true. Elapsed: 2.01886375s
Aug  3 18:09:10.522: INFO: Pod "pod-subpath-test-configmap-c5kt": Phase="Running", Reason="", readiness=true. Elapsed: 4.027116457s
Aug  3 18:09:12.532: INFO: Pod "pod-subpath-test-configmap-c5kt": Phase="Running", Reason="", readiness=true. Elapsed: 6.037143681s
Aug  3 18:09:14.541: INFO: Pod "pod-subpath-test-configmap-c5kt": Phase="Running", Reason="", readiness=true. Elapsed: 8.045756347s
Aug  3 18:09:16.551: INFO: Pod "pod-subpath-test-configmap-c5kt": Phase="Running", Reason="", readiness=true. Elapsed: 10.056354445s
Aug  3 18:09:18.562: INFO: Pod "pod-subpath-test-configmap-c5kt": Phase="Running", Reason="", readiness=true. Elapsed: 12.066859114s
Aug  3 18:09:20.571: INFO: Pod "pod-subpath-test-configmap-c5kt": Phase="Running", Reason="", readiness=true. Elapsed: 14.075580506s
Aug  3 18:09:22.579: INFO: Pod "pod-subpath-test-configmap-c5kt": Phase="Running", Reason="", readiness=true. Elapsed: 16.084064393s
Aug  3 18:09:24.589: INFO: Pod "pod-subpath-test-configmap-c5kt": Phase="Running", Reason="", readiness=true. Elapsed: 18.094028897s
Aug  3 18:09:26.609: INFO: Pod "pod-subpath-test-configmap-c5kt": Phase="Running", Reason="", readiness=true. Elapsed: 20.113965329s
Aug  3 18:09:28.619: INFO: Pod "pod-subpath-test-configmap-c5kt": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.124187194s
STEP: Saw pod success
Aug  3 18:09:28.619: INFO: Pod "pod-subpath-test-configmap-c5kt" satisfied condition "success or failure"
Aug  3 18:09:28.629: INFO: Trying to get logs from node 10.188.31.32 pod pod-subpath-test-configmap-c5kt container test-container-subpath-configmap-c5kt: <nil>
STEP: delete the pod
Aug  3 18:09:28.674: INFO: Waiting for pod pod-subpath-test-configmap-c5kt to disappear
Aug  3 18:09:28.682: INFO: Pod pod-subpath-test-configmap-c5kt no longer exists
STEP: Deleting pod pod-subpath-test-configmap-c5kt
Aug  3 18:09:28.682: INFO: Deleting pod "pod-subpath-test-configmap-c5kt" in namespace "subpath-4511"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 18:09:28.690: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-4511" for this suite.
Aug  3 18:09:34.733: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 18:09:35.046: INFO: namespace subpath-4511 deletion completed in 6.344568878s

• [SLOW TEST:28.815 seconds]
[sig-storage] Subpath
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
    /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 18:09:35.047: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-530
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Aug  3 18:09:35.310: INFO: Waiting up to 5m0s for pod "downwardapi-volume-afb3fde6-287e-42a4-bec9-b3c1ba353f96" in namespace "projected-530" to be "success or failure"
Aug  3 18:09:35.319: INFO: Pod "downwardapi-volume-afb3fde6-287e-42a4-bec9-b3c1ba353f96": Phase="Pending", Reason="", readiness=false. Elapsed: 8.183966ms
Aug  3 18:09:37.327: INFO: Pod "downwardapi-volume-afb3fde6-287e-42a4-bec9-b3c1ba353f96": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016136119s
STEP: Saw pod success
Aug  3 18:09:37.327: INFO: Pod "downwardapi-volume-afb3fde6-287e-42a4-bec9-b3c1ba353f96" satisfied condition "success or failure"
Aug  3 18:09:37.350: INFO: Trying to get logs from node 10.188.31.32 pod downwardapi-volume-afb3fde6-287e-42a4-bec9-b3c1ba353f96 container client-container: <nil>
STEP: delete the pod
Aug  3 18:09:37.392: INFO: Waiting for pod downwardapi-volume-afb3fde6-287e-42a4-bec9-b3c1ba353f96 to disappear
Aug  3 18:09:37.416: INFO: Pod downwardapi-volume-afb3fde6-287e-42a4-bec9-b3c1ba353f96 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 18:09:37.416: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-530" for this suite.
Aug  3 18:09:43.485: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 18:09:43.778: INFO: namespace projected-530 deletion completed in 6.333204215s

• [SLOW TEST:8.732 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 18:09:43.779: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2285
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Aug  3 18:09:44.013: INFO: Waiting up to 5m0s for pod "downwardapi-volume-56fcdb2a-8a73-4e95-a89e-d1b7942f07dd" in namespace "projected-2285" to be "success or failure"
Aug  3 18:09:44.024: INFO: Pod "downwardapi-volume-56fcdb2a-8a73-4e95-a89e-d1b7942f07dd": Phase="Pending", Reason="", readiness=false. Elapsed: 11.164749ms
Aug  3 18:09:46.033: INFO: Pod "downwardapi-volume-56fcdb2a-8a73-4e95-a89e-d1b7942f07dd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.019884563s
STEP: Saw pod success
Aug  3 18:09:46.033: INFO: Pod "downwardapi-volume-56fcdb2a-8a73-4e95-a89e-d1b7942f07dd" satisfied condition "success or failure"
Aug  3 18:09:46.057: INFO: Trying to get logs from node 10.188.31.24 pod downwardapi-volume-56fcdb2a-8a73-4e95-a89e-d1b7942f07dd container client-container: <nil>
STEP: delete the pod
Aug  3 18:09:46.101: INFO: Waiting for pod downwardapi-volume-56fcdb2a-8a73-4e95-a89e-d1b7942f07dd to disappear
Aug  3 18:09:46.111: INFO: Pod downwardapi-volume-56fcdb2a-8a73-4e95-a89e-d1b7942f07dd no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 18:09:46.112: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2285" for this suite.
Aug  3 18:09:52.152: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 18:09:52.463: INFO: namespace projected-2285 deletion completed in 6.340386677s

• [SLOW TEST:8.684 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 18:09:52.465: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-8870
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:81
Aug  3 18:09:52.686: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Aug  3 18:09:52.708: INFO: Waiting for terminating namespaces to be deleted...
Aug  3 18:09:52.717: INFO: 
Logging pods the kubelet thinks is on node 10.188.31.22 before test
Aug  3 18:09:52.765: INFO: calico-node-mc9wt from kube-system started at 2019-08-03 15:30:03 +0000 UTC (1 container statuses recorded)
Aug  3 18:09:52.765: INFO: 	Container calico-node ready: true, restart count 0
Aug  3 18:09:52.765: INFO: sonobuoy from heptio-sonobuoy started at 2019-08-03 17:36:53 +0000 UTC (1 container statuses recorded)
Aug  3 18:09:52.765: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Aug  3 18:09:52.765: INFO: sonobuoy-e2e-job-128cd56eea1c4929 from heptio-sonobuoy started at 2019-08-03 17:36:58 +0000 UTC (2 container statuses recorded)
Aug  3 18:09:52.765: INFO: 	Container e2e ready: true, restart count 0
Aug  3 18:09:52.765: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug  3 18:09:52.765: INFO: sonobuoy-systemd-logs-daemon-set-2824ab4c610f42f4-rvnnh from heptio-sonobuoy started at 2019-08-03 17:36:58 +0000 UTC (2 container statuses recorded)
Aug  3 18:09:52.765: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug  3 18:09:52.765: INFO: 	Container systemd-logs ready: true, restart count 0
Aug  3 18:09:52.765: INFO: ibm-master-proxy-static-10.188.31.22 from kube-system started at 2019-08-03 15:30:01 +0000 UTC (2 container statuses recorded)
Aug  3 18:09:52.765: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Aug  3 18:09:52.765: INFO: 	Container pause ready: true, restart count 0
Aug  3 18:09:52.765: INFO: ibm-kube-fluentd-25wz8 from kube-system started at 2019-08-03 15:30:14 +0000 UTC (1 container statuses recorded)
Aug  3 18:09:52.766: INFO: 	Container fluentd ready: true, restart count 0
Aug  3 18:09:52.766: INFO: ibm-keepalived-watcher-fkdg8 from kube-system started at 2019-08-03 15:30:03 +0000 UTC (1 container statuses recorded)
Aug  3 18:09:52.766: INFO: 	Container keepalived-watcher ready: true, restart count 0
Aug  3 18:09:52.766: INFO: 
Logging pods the kubelet thinks is on node 10.188.31.24 before test
Aug  3 18:09:52.804: INFO: calico-node-979kf from kube-system started at 2019-08-03 15:29:52 +0000 UTC (1 container statuses recorded)
Aug  3 18:09:52.804: INFO: 	Container calico-node ready: true, restart count 0
Aug  3 18:09:52.804: INFO: vpn-6554589999-thmhh from kube-system started at 2019-08-03 15:30:10 +0000 UTC (1 container statuses recorded)
Aug  3 18:09:52.804: INFO: 	Container vpn ready: true, restart count 0
Aug  3 18:09:52.804: INFO: sonobuoy-systemd-logs-daemon-set-2824ab4c610f42f4-5422v from heptio-sonobuoy started at 2019-08-03 17:36:58 +0000 UTC (2 container statuses recorded)
Aug  3 18:09:52.804: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug  3 18:09:52.804: INFO: 	Container systemd-logs ready: true, restart count 0
Aug  3 18:09:52.804: INFO: coredns-autoscaler-7fbd4fd998-4tdzn from kube-system started at 2019-08-03 15:30:10 +0000 UTC (1 container statuses recorded)
Aug  3 18:09:52.804: INFO: 	Container autoscaler ready: true, restart count 0
Aug  3 18:09:52.804: INFO: ibm-master-proxy-static-10.188.31.24 from kube-system started at 2019-08-03 15:29:45 +0000 UTC (2 container statuses recorded)
Aug  3 18:09:52.804: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Aug  3 18:09:52.804: INFO: 	Container pause ready: true, restart count 0
Aug  3 18:09:52.804: INFO: ibm-storage-watcher-5c75867c7-sns8d from kube-system started at 2019-08-03 15:30:10 +0000 UTC (1 container statuses recorded)
Aug  3 18:09:52.804: INFO: 	Container ibm-storage-watcher-container ready: true, restart count 0
Aug  3 18:09:52.804: INFO: ibm-keepalived-watcher-z8jrg from kube-system started at 2019-08-03 15:29:52 +0000 UTC (1 container statuses recorded)
Aug  3 18:09:52.804: INFO: 	Container keepalived-watcher ready: true, restart count 0
Aug  3 18:09:52.804: INFO: kubernetes-dashboard-7756dcb98b-pc5ss from kube-system started at 2019-08-03 15:30:10 +0000 UTC (1 container statuses recorded)
Aug  3 18:09:52.804: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Aug  3 18:09:52.804: INFO: ibm-file-plugin-7b7f6d7b59-7vn9h from kube-system started at 2019-08-03 15:30:10 +0000 UTC (1 container statuses recorded)
Aug  3 18:09:52.804: INFO: 	Container ibm-file-plugin-container ready: true, restart count 0
Aug  3 18:09:52.804: INFO: calico-kube-controllers-7497554b5f-qrxg2 from kube-system started at 2019-08-03 15:30:10 +0000 UTC (1 container statuses recorded)
Aug  3 18:09:52.804: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Aug  3 18:09:52.804: INFO: coredns-7789d4b879-drqmd from kube-system started at 2019-08-03 15:30:10 +0000 UTC (1 container statuses recorded)
Aug  3 18:09:52.804: INFO: 	Container coredns ready: true, restart count 0
Aug  3 18:09:52.804: INFO: ibm-kube-fluentd-ltrhd from kube-system started at 2019-08-03 15:30:14 +0000 UTC (1 container statuses recorded)
Aug  3 18:09:52.804: INFO: 	Container fluentd ready: true, restart count 0
Aug  3 18:09:52.804: INFO: 
Logging pods the kubelet thinks is on node 10.188.31.32 before test
Aug  3 18:09:52.825: INFO: metrics-server-66558f74f4-zfdzx from kube-system started at 2019-08-03 15:30:43 +0000 UTC (2 container statuses recorded)
Aug  3 18:09:52.825: INFO: 	Container metrics-server ready: true, restart count 0
Aug  3 18:09:52.825: INFO: 	Container metrics-server-nanny ready: true, restart count 0
Aug  3 18:09:52.825: INFO: ibm-keepalived-watcher-h74k2 from kube-system started at 2019-08-03 15:30:13 +0000 UTC (1 container statuses recorded)
Aug  3 18:09:52.825: INFO: 	Container keepalived-watcher ready: true, restart count 0
Aug  3 18:09:52.825: INFO: coredns-7789d4b879-46cbb from kube-system started at 2019-08-03 15:30:25 +0000 UTC (1 container statuses recorded)
Aug  3 18:09:52.825: INFO: 	Container coredns ready: true, restart count 0
Aug  3 18:09:52.826: INFO: calico-node-7mlcs from kube-system started at 2019-08-03 15:30:13 +0000 UTC (1 container statuses recorded)
Aug  3 18:09:52.826: INFO: 	Container calico-node ready: true, restart count 0
Aug  3 18:09:52.826: INFO: ibm-kube-fluentd-chr7d from kube-system started at 2019-08-03 15:30:14 +0000 UTC (1 container statuses recorded)
Aug  3 18:09:52.826: INFO: 	Container fluentd ready: true, restart count 0
Aug  3 18:09:52.826: INFO: sonobuoy-systemd-logs-daemon-set-2824ab4c610f42f4-945kd from heptio-sonobuoy started at 2019-08-03 17:36:58 +0000 UTC (2 container statuses recorded)
Aug  3 18:09:52.826: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug  3 18:09:52.826: INFO: 	Container systemd-logs ready: true, restart count 0
Aug  3 18:09:52.826: INFO: ibm-master-proxy-static-10.188.31.32 from kube-system started at 2019-08-03 15:30:07 +0000 UTC (2 container statuses recorded)
Aug  3 18:09:52.826: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Aug  3 18:09:52.826: INFO: 	Container pause ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.15b77c0d7b22ccfd], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 18:09:53.881: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-8870" for this suite.
Aug  3 18:09:59.934: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 18:10:00.248: INFO: namespace sched-pred-8870 deletion completed in 6.348534999s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:72

• [SLOW TEST:7.783 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 18:10:00.249: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-1637
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Aug  3 18:10:00.536: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"641c9f16-fe8c-4c67-bddf-94d711bc6361", Controller:(*bool)(0xc0021ab6fa), BlockOwnerDeletion:(*bool)(0xc0021ab6fb)}}
Aug  3 18:10:00.560: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"ab5edfa9-4322-4ba5-a556-a8f81b8a2491", Controller:(*bool)(0xc00207c9d6), BlockOwnerDeletion:(*bool)(0xc00207c9d7)}}
Aug  3 18:10:00.571: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"90541827-c71f-430b-9541-5a0067651428", Controller:(*bool)(0xc0021d46f6), BlockOwnerDeletion:(*bool)(0xc0021d46f7)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 18:10:05.595: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-1637" for this suite.
Aug  3 18:10:11.651: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 18:10:12.007: INFO: namespace gc-1637 deletion completed in 6.3921132s

• [SLOW TEST:11.758 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 18:10:12.007: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-8884
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Aug  3 18:10:12.393: INFO: Waiting up to 5m0s for pod "downwardapi-volume-bb3cf2eb-8d2b-47dd-b56b-0ae63b66a97b" in namespace "downward-api-8884" to be "success or failure"
Aug  3 18:10:12.407: INFO: Pod "downwardapi-volume-bb3cf2eb-8d2b-47dd-b56b-0ae63b66a97b": Phase="Pending", Reason="", readiness=false. Elapsed: 13.660844ms
Aug  3 18:10:14.418: INFO: Pod "downwardapi-volume-bb3cf2eb-8d2b-47dd-b56b-0ae63b66a97b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.024745669s
STEP: Saw pod success
Aug  3 18:10:14.418: INFO: Pod "downwardapi-volume-bb3cf2eb-8d2b-47dd-b56b-0ae63b66a97b" satisfied condition "success or failure"
Aug  3 18:10:14.425: INFO: Trying to get logs from node 10.188.31.32 pod downwardapi-volume-bb3cf2eb-8d2b-47dd-b56b-0ae63b66a97b container client-container: <nil>
STEP: delete the pod
Aug  3 18:10:14.486: INFO: Waiting for pod downwardapi-volume-bb3cf2eb-8d2b-47dd-b56b-0ae63b66a97b to disappear
Aug  3 18:10:14.496: INFO: Pod downwardapi-volume-bb3cf2eb-8d2b-47dd-b56b-0ae63b66a97b no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 18:10:14.496: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8884" for this suite.
Aug  3 18:10:20.540: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 18:10:20.906: INFO: namespace downward-api-8884 deletion completed in 6.398737702s

• [SLOW TEST:8.899 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 18:10:20.910: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-1352
STEP: Waiting for a default service account to be provisioned in namespace
[It] should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: starting a background goroutine to produce watch events
STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 18:10:26.558: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-1352" for this suite.
Aug  3 18:10:32.711: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 18:10:33.022: INFO: namespace watch-1352 deletion completed in 6.42181294s

• [SLOW TEST:12.112 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 18:10:33.023: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-163
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-54f70624-80b8-471f-a975-e59b1a40a5f4
STEP: Creating a pod to test consume configMaps
Aug  3 18:10:33.276: INFO: Waiting up to 5m0s for pod "pod-configmaps-866f5875-f1c7-48cb-8398-d6b2e1e2c958" in namespace "configmap-163" to be "success or failure"
Aug  3 18:10:33.284: INFO: Pod "pod-configmaps-866f5875-f1c7-48cb-8398-d6b2e1e2c958": Phase="Pending", Reason="", readiness=false. Elapsed: 8.064055ms
Aug  3 18:10:35.292: INFO: Pod "pod-configmaps-866f5875-f1c7-48cb-8398-d6b2e1e2c958": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016422005s
STEP: Saw pod success
Aug  3 18:10:35.292: INFO: Pod "pod-configmaps-866f5875-f1c7-48cb-8398-d6b2e1e2c958" satisfied condition "success or failure"
Aug  3 18:10:35.299: INFO: Trying to get logs from node 10.188.31.32 pod pod-configmaps-866f5875-f1c7-48cb-8398-d6b2e1e2c958 container configmap-volume-test: <nil>
STEP: delete the pod
Aug  3 18:10:35.337: INFO: Waiting for pod pod-configmaps-866f5875-f1c7-48cb-8398-d6b2e1e2c958 to disappear
Aug  3 18:10:35.344: INFO: Pod pod-configmaps-866f5875-f1c7-48cb-8398-d6b2e1e2c958 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 18:10:35.344: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-163" for this suite.
Aug  3 18:10:41.386: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 18:10:41.699: INFO: namespace configmap-163 deletion completed in 6.343638258s

• [SLOW TEST:8.676 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 18:10:41.699: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-4412
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Aug  3 18:10:46.488: INFO: Successfully updated pod "pod-update-41603e32-e794-463e-9169-a590cba67cf4"
STEP: verifying the updated pod is in kubernetes
Aug  3 18:10:46.505: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 18:10:46.505: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-4412" for this suite.
Aug  3 18:11:10.563: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 18:11:10.885: INFO: namespace pods-4412 deletion completed in 24.355547999s

• [SLOW TEST:29.186 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 18:11:10.886: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8721
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-map-81515b0f-11f7-4bc7-a21b-ccb8985b1e12
STEP: Creating a pod to test consume configMaps
Aug  3 18:11:11.306: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-d8076dfd-835c-409a-a07c-7046aa50493f" in namespace "projected-8721" to be "success or failure"
Aug  3 18:11:11.327: INFO: Pod "pod-projected-configmaps-d8076dfd-835c-409a-a07c-7046aa50493f": Phase="Pending", Reason="", readiness=false. Elapsed: 20.437252ms
Aug  3 18:11:13.337: INFO: Pod "pod-projected-configmaps-d8076dfd-835c-409a-a07c-7046aa50493f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.030365556s
STEP: Saw pod success
Aug  3 18:11:13.337: INFO: Pod "pod-projected-configmaps-d8076dfd-835c-409a-a07c-7046aa50493f" satisfied condition "success or failure"
Aug  3 18:11:13.357: INFO: Trying to get logs from node 10.188.31.32 pod pod-projected-configmaps-d8076dfd-835c-409a-a07c-7046aa50493f container projected-configmap-volume-test: <nil>
STEP: delete the pod
Aug  3 18:11:13.406: INFO: Waiting for pod pod-projected-configmaps-d8076dfd-835c-409a-a07c-7046aa50493f to disappear
Aug  3 18:11:13.413: INFO: Pod pod-projected-configmaps-d8076dfd-835c-409a-a07c-7046aa50493f no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 18:11:13.414: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8721" for this suite.
Aug  3 18:11:19.477: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 18:11:19.818: INFO: namespace projected-8721 deletion completed in 6.380293483s

• [SLOW TEST:8.933 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 18:11:19.819: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-7262
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod busybox-b845b5c5-e70c-4c07-97ed-81b2ae490a69 in namespace container-probe-7262
Aug  3 18:11:24.077: INFO: Started pod busybox-b845b5c5-e70c-4c07-97ed-81b2ae490a69 in namespace container-probe-7262
STEP: checking the pod's current state and verifying that restartCount is present
Aug  3 18:11:24.089: INFO: Initial restart count of pod busybox-b845b5c5-e70c-4c07-97ed-81b2ae490a69 is 0
Aug  3 18:12:12.328: INFO: Restart count of pod container-probe-7262/busybox-b845b5c5-e70c-4c07-97ed-81b2ae490a69 is now 1 (48.238486292s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 18:12:12.352: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-7262" for this suite.
Aug  3 18:12:18.406: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 18:12:18.724: INFO: namespace container-probe-7262 deletion completed in 6.352860455s

• [SLOW TEST:58.905 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 18:12:18.726: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-8740
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:63
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Aug  3 18:12:27.189: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug  3 18:12:27.204: INFO: Pod pod-with-poststart-exec-hook still exists
Aug  3 18:12:29.205: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug  3 18:12:29.214: INFO: Pod pod-with-poststart-exec-hook still exists
Aug  3 18:12:31.205: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug  3 18:12:31.229: INFO: Pod pod-with-poststart-exec-hook still exists
Aug  3 18:12:33.205: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug  3 18:12:33.212: INFO: Pod pod-with-poststart-exec-hook still exists
Aug  3 18:12:35.205: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug  3 18:12:35.214: INFO: Pod pod-with-poststart-exec-hook still exists
Aug  3 18:12:37.205: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug  3 18:12:37.213: INFO: Pod pod-with-poststart-exec-hook still exists
Aug  3 18:12:39.205: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug  3 18:12:39.229: INFO: Pod pod-with-poststart-exec-hook still exists
Aug  3 18:12:41.205: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug  3 18:12:41.213: INFO: Pod pod-with-poststart-exec-hook still exists
Aug  3 18:12:43.205: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug  3 18:12:43.213: INFO: Pod pod-with-poststart-exec-hook still exists
Aug  3 18:12:45.205: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug  3 18:12:45.212: INFO: Pod pod-with-poststart-exec-hook still exists
Aug  3 18:12:47.205: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug  3 18:12:47.214: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 18:12:47.214: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-8740" for this suite.
Aug  3 18:13:11.258: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 18:13:11.594: INFO: namespace container-lifecycle-hook-8740 deletion completed in 24.368706401s

• [SLOW TEST:52.868 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when create a pod with lifecycle hook
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 18:13:11.594: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1101
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-map-60e1af89-112b-4a2e-b806-0e61be998345
STEP: Creating a pod to test consume secrets
Aug  3 18:13:11.847: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-42b5a9b6-83b9-40a9-b599-65acce4a9027" in namespace "projected-1101" to be "success or failure"
Aug  3 18:13:11.855: INFO: Pod "pod-projected-secrets-42b5a9b6-83b9-40a9-b599-65acce4a9027": Phase="Pending", Reason="", readiness=false. Elapsed: 7.944035ms
Aug  3 18:13:13.864: INFO: Pod "pod-projected-secrets-42b5a9b6-83b9-40a9-b599-65acce4a9027": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.017064933s
STEP: Saw pod success
Aug  3 18:13:13.864: INFO: Pod "pod-projected-secrets-42b5a9b6-83b9-40a9-b599-65acce4a9027" satisfied condition "success or failure"
Aug  3 18:13:13.873: INFO: Trying to get logs from node 10.188.31.32 pod pod-projected-secrets-42b5a9b6-83b9-40a9-b599-65acce4a9027 container projected-secret-volume-test: <nil>
STEP: delete the pod
Aug  3 18:13:13.918: INFO: Waiting for pod pod-projected-secrets-42b5a9b6-83b9-40a9-b599-65acce4a9027 to disappear
Aug  3 18:13:13.926: INFO: Pod pod-projected-secrets-42b5a9b6-83b9-40a9-b599-65acce4a9027 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 18:13:13.926: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1101" for this suite.
Aug  3 18:13:19.985: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 18:13:20.368: INFO: namespace projected-1101 deletion completed in 6.418540387s

• [SLOW TEST:8.774 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 18:13:20.368: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-5159
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Aug  3 18:13:20.609: INFO: Pod name pod-release: Found 0 pods out of 1
Aug  3 18:13:25.618: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 18:13:26.652: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-5159" for this suite.
Aug  3 18:13:32.697: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 18:13:33.041: INFO: namespace replication-controller-5159 deletion completed in 6.376632696s

• [SLOW TEST:12.673 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 18:13:33.042: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-6669
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1293
STEP: creating an rc
Aug  3 18:13:33.274: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 create -f - --namespace=kubectl-6669'
Aug  3 18:13:33.662: INFO: stderr: ""
Aug  3 18:13:33.662: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Waiting for Redis master to start.
Aug  3 18:13:34.671: INFO: Selector matched 1 pods for map[app:redis]
Aug  3 18:13:34.671: INFO: Found 0 / 1
Aug  3 18:13:35.683: INFO: Selector matched 1 pods for map[app:redis]
Aug  3 18:13:35.683: INFO: Found 1 / 1
Aug  3 18:13:35.683: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Aug  3 18:13:35.692: INFO: Selector matched 1 pods for map[app:redis]
Aug  3 18:13:35.692: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
STEP: checking for a matching strings
Aug  3 18:13:35.692: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 logs redis-master-sz5fk redis-master --namespace=kubectl-6669'
Aug  3 18:13:35.827: INFO: stderr: ""
Aug  3 18:13:35.827: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 03 Aug 18:13:35.014 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 03 Aug 18:13:35.014 # Server started, Redis version 3.2.12\n1:M 03 Aug 18:13:35.014 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 03 Aug 18:13:35.014 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log lines
Aug  3 18:13:35.827: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 log redis-master-sz5fk redis-master --namespace=kubectl-6669 --tail=1'
Aug  3 18:13:36.003: INFO: stderr: ""
Aug  3 18:13:36.003: INFO: stdout: "1:M 03 Aug 18:13:35.014 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log bytes
Aug  3 18:13:36.003: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 log redis-master-sz5fk redis-master --namespace=kubectl-6669 --limit-bytes=1'
Aug  3 18:13:36.142: INFO: stderr: ""
Aug  3 18:13:36.142: INFO: stdout: " "
STEP: exposing timestamps
Aug  3 18:13:36.142: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 log redis-master-sz5fk redis-master --namespace=kubectl-6669 --tail=1 --timestamps'
Aug  3 18:13:36.273: INFO: stderr: ""
Aug  3 18:13:36.273: INFO: stdout: "2019-08-03T18:13:35.0150146Z 1:M 03 Aug 18:13:35.014 * The server is now ready to accept connections on port 6379\n"
STEP: restricting to a time range
Aug  3 18:13:38.773: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 log redis-master-sz5fk redis-master --namespace=kubectl-6669 --since=1s'
Aug  3 18:13:38.912: INFO: stderr: ""
Aug  3 18:13:38.912: INFO: stdout: ""
Aug  3 18:13:38.912: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 log redis-master-sz5fk redis-master --namespace=kubectl-6669 --since=24h'
Aug  3 18:13:39.051: INFO: stderr: ""
Aug  3 18:13:39.052: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 03 Aug 18:13:35.014 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 03 Aug 18:13:35.014 # Server started, Redis version 3.2.12\n1:M 03 Aug 18:13:35.014 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 03 Aug 18:13:35.014 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1299
STEP: using delete to clean up resources
Aug  3 18:13:39.052: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 delete --grace-period=0 --force -f - --namespace=kubectl-6669'
Aug  3 18:13:39.184: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug  3 18:13:39.184: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
Aug  3 18:13:39.184: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 get rc,svc -l name=nginx --no-headers --namespace=kubectl-6669'
Aug  3 18:13:39.308: INFO: stderr: "No resources found.\n"
Aug  3 18:13:39.308: INFO: stdout: ""
Aug  3 18:13:39.308: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 get pods -l name=nginx --namespace=kubectl-6669 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Aug  3 18:13:39.414: INFO: stderr: ""
Aug  3 18:13:39.414: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 18:13:39.414: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6669" for this suite.
Aug  3 18:13:45.475: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 18:13:45.762: INFO: namespace kubectl-6669 deletion completed in 6.31672554s

• [SLOW TEST:12.720 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl logs
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 18:13:45.763: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-8844
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
Aug  3 18:13:45.990: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 18:13:50.544: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-8844" for this suite.
Aug  3 18:14:14.592: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 18:14:14.973: INFO: namespace init-container-8844 deletion completed in 24.417063514s

• [SLOW TEST:29.210 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 18:14:14.973: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-7282
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 18:14:17.258: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-7282" for this suite.
Aug  3 18:14:59.303: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 18:14:59.632: INFO: namespace kubelet-test-7282 deletion completed in 42.361260138s

• [SLOW TEST:44.659 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when scheduling a busybox command in a pod
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:40
    should print the output to logs [NodeConformance] [Conformance]
    /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 18:14:59.635: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-1599
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test override all
Aug  3 18:14:59.866: INFO: Waiting up to 5m0s for pod "client-containers-9a2f80e3-778a-45d0-a998-e9276dcdb30e" in namespace "containers-1599" to be "success or failure"
Aug  3 18:14:59.873: INFO: Pod "client-containers-9a2f80e3-778a-45d0-a998-e9276dcdb30e": Phase="Pending", Reason="", readiness=false. Elapsed: 7.590387ms
Aug  3 18:15:01.886: INFO: Pod "client-containers-9a2f80e3-778a-45d0-a998-e9276dcdb30e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020375091s
STEP: Saw pod success
Aug  3 18:15:01.886: INFO: Pod "client-containers-9a2f80e3-778a-45d0-a998-e9276dcdb30e" satisfied condition "success or failure"
Aug  3 18:15:01.896: INFO: Trying to get logs from node 10.188.31.32 pod client-containers-9a2f80e3-778a-45d0-a998-e9276dcdb30e container test-container: <nil>
STEP: delete the pod
Aug  3 18:15:01.967: INFO: Waiting for pod client-containers-9a2f80e3-778a-45d0-a998-e9276dcdb30e to disappear
Aug  3 18:15:01.980: INFO: Pod client-containers-9a2f80e3-778a-45d0-a998-e9276dcdb30e no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 18:15:01.980: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-1599" for this suite.
Aug  3 18:15:08.027: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 18:15:08.514: INFO: namespace containers-1599 deletion completed in 6.521915416s

• [SLOW TEST:8.879 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 18:15:08.515: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-8490
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating replication controller my-hostname-basic-961693f1-6523-4739-8601-1f83923bd409
Aug  3 18:15:08.761: INFO: Pod name my-hostname-basic-961693f1-6523-4739-8601-1f83923bd409: Found 0 pods out of 1
Aug  3 18:15:13.771: INFO: Pod name my-hostname-basic-961693f1-6523-4739-8601-1f83923bd409: Found 1 pods out of 1
Aug  3 18:15:13.771: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-961693f1-6523-4739-8601-1f83923bd409" are running
Aug  3 18:15:13.779: INFO: Pod "my-hostname-basic-961693f1-6523-4739-8601-1f83923bd409-6pf8w" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-08-03 18:15:08 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-08-03 18:15:10 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-08-03 18:15:10 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-08-03 18:15:08 +0000 UTC Reason: Message:}])
Aug  3 18:15:13.779: INFO: Trying to dial the pod
Aug  3 18:15:18.815: INFO: Controller my-hostname-basic-961693f1-6523-4739-8601-1f83923bd409: Got expected result from replica 1 [my-hostname-basic-961693f1-6523-4739-8601-1f83923bd409-6pf8w]: "my-hostname-basic-961693f1-6523-4739-8601-1f83923bd409-6pf8w", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 18:15:18.815: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-8490" for this suite.
Aug  3 18:15:24.862: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 18:15:25.196: INFO: namespace replication-controller-8490 deletion completed in 6.369246539s

• [SLOW TEST:16.681 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 18:15:25.197: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-4813
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test override arguments
Aug  3 18:15:25.429: INFO: Waiting up to 5m0s for pod "client-containers-3deb5079-2e02-4b06-9224-69586773c9bf" in namespace "containers-4813" to be "success or failure"
Aug  3 18:15:25.438: INFO: Pod "client-containers-3deb5079-2e02-4b06-9224-69586773c9bf": Phase="Pending", Reason="", readiness=false. Elapsed: 9.050485ms
Aug  3 18:15:27.447: INFO: Pod "client-containers-3deb5079-2e02-4b06-9224-69586773c9bf": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017440435s
Aug  3 18:15:29.458: INFO: Pod "client-containers-3deb5079-2e02-4b06-9224-69586773c9bf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.028845243s
STEP: Saw pod success
Aug  3 18:15:29.458: INFO: Pod "client-containers-3deb5079-2e02-4b06-9224-69586773c9bf" satisfied condition "success or failure"
Aug  3 18:15:29.466: INFO: Trying to get logs from node 10.188.31.32 pod client-containers-3deb5079-2e02-4b06-9224-69586773c9bf container test-container: <nil>
STEP: delete the pod
Aug  3 18:15:29.508: INFO: Waiting for pod client-containers-3deb5079-2e02-4b06-9224-69586773c9bf to disappear
Aug  3 18:15:29.516: INFO: Pod client-containers-3deb5079-2e02-4b06-9224-69586773c9bf no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 18:15:29.516: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-4813" for this suite.
Aug  3 18:15:35.570: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 18:15:35.897: INFO: namespace containers-4813 deletion completed in 6.356582594s

• [SLOW TEST:10.700 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 18:15:35.897: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svcaccounts-7216
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: getting the auto-created API token
STEP: reading a file in the container
Aug  3 18:15:40.700: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-7216 pod-service-account-b8f45a5a-bb7e-4cb1-a70b-7f2a2b79d6b2 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
STEP: reading a file in the container
Aug  3 18:15:41.144: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-7216 pod-service-account-b8f45a5a-bb7e-4cb1-a70b-7f2a2b79d6b2 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
STEP: reading a file in the container
Aug  3 18:15:41.569: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-7216 pod-service-account-b8f45a5a-bb7e-4cb1-a70b-7f2a2b79d6b2 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 18:15:42.073: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-7216" for this suite.
Aug  3 18:15:48.129: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 18:15:48.427: INFO: namespace svcaccounts-7216 deletion completed in 6.342740655s

• [SLOW TEST:12.531 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:23
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 18:15:48.428: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-4019
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0644 on tmpfs
Aug  3 18:15:48.668: INFO: Waiting up to 5m0s for pod "pod-dd11a025-aa55-4dcb-82ce-461ff4cdd96e" in namespace "emptydir-4019" to be "success or failure"
Aug  3 18:15:48.681: INFO: Pod "pod-dd11a025-aa55-4dcb-82ce-461ff4cdd96e": Phase="Pending", Reason="", readiness=false. Elapsed: 12.500811ms
Aug  3 18:15:50.689: INFO: Pod "pod-dd11a025-aa55-4dcb-82ce-461ff4cdd96e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020816729s
Aug  3 18:15:52.709: INFO: Pod "pod-dd11a025-aa55-4dcb-82ce-461ff4cdd96e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.040750151s
STEP: Saw pod success
Aug  3 18:15:52.709: INFO: Pod "pod-dd11a025-aa55-4dcb-82ce-461ff4cdd96e" satisfied condition "success or failure"
Aug  3 18:15:52.717: INFO: Trying to get logs from node 10.188.31.32 pod pod-dd11a025-aa55-4dcb-82ce-461ff4cdd96e container test-container: <nil>
STEP: delete the pod
Aug  3 18:15:52.756: INFO: Waiting for pod pod-dd11a025-aa55-4dcb-82ce-461ff4cdd96e to disappear
Aug  3 18:15:52.764: INFO: Pod pod-dd11a025-aa55-4dcb-82ce-461ff4cdd96e no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 18:15:52.764: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4019" for this suite.
Aug  3 18:15:58.810: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 18:15:59.141: INFO: namespace emptydir-4019 deletion completed in 6.36606938s

• [SLOW TEST:10.713 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 18:15:59.142: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-4556
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Aug  3 18:15:59.362: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 create -f - --namespace=kubectl-4556'
Aug  3 18:15:59.688: INFO: stderr: ""
Aug  3 18:15:59.688: INFO: stdout: "replicationcontroller/redis-master created\n"
Aug  3 18:15:59.688: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 create -f - --namespace=kubectl-4556'
Aug  3 18:16:00.014: INFO: stderr: ""
Aug  3 18:16:00.014: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Aug  3 18:16:01.023: INFO: Selector matched 1 pods for map[app:redis]
Aug  3 18:16:01.023: INFO: Found 0 / 1
Aug  3 18:16:02.022: INFO: Selector matched 1 pods for map[app:redis]
Aug  3 18:16:02.022: INFO: Found 1 / 1
Aug  3 18:16:02.022: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Aug  3 18:16:02.030: INFO: Selector matched 1 pods for map[app:redis]
Aug  3 18:16:02.031: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Aug  3 18:16:02.031: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 describe pod redis-master-njncf --namespace=kubectl-4556'
Aug  3 18:16:02.202: INFO: stderr: ""
Aug  3 18:16:02.202: INFO: stdout: "Name:           redis-master-njncf\nNamespace:      kubectl-4556\nPriority:       0\nNode:           10.188.31.32/10.188.31.32\nStart Time:     Sat, 03 Aug 2019 18:15:59 +0000\nLabels:         app=redis\n                role=master\nAnnotations:    kubernetes.io/psp: e2e-test-privileged-psp\nStatus:         Running\nIP:             172.30.72.89\nControlled By:  ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   containerd://fce74c2a4eee9f627aca9d5e2e400d5613562b020daa4899b619db731b652ec4\n    Image:          gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Image ID:       gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Sat, 03 Aug 2019 18:16:01 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-hdm6q (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-hdm6q:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-hdm6q\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 600s\n                 node.kubernetes.io/unreachable:NoExecute for 600s\nEvents:\n  Type    Reason     Age   From                   Message\n  ----    ------     ----  ----                   -------\n  Normal  Scheduled  3s    default-scheduler      Successfully assigned kubectl-4556/redis-master-njncf to 10.188.31.32\n  Normal  Pulled     2s    kubelet, 10.188.31.32  Container image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\" already present on machine\n  Normal  Created    2s    kubelet, 10.188.31.32  Created container redis-master\n  Normal  Started    1s    kubelet, 10.188.31.32  Started container redis-master\n"
Aug  3 18:16:02.203: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 describe rc redis-master --namespace=kubectl-4556'
Aug  3 18:16:02.375: INFO: stderr: ""
Aug  3 18:16:02.375: INFO: stdout: "Name:         redis-master\nNamespace:    kubectl-4556\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  3s    replication-controller  Created pod: redis-master-njncf\n"
Aug  3 18:16:02.375: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 describe service redis-master --namespace=kubectl-4556'
Aug  3 18:16:02.524: INFO: stderr: ""
Aug  3 18:16:02.524: INFO: stdout: "Name:              redis-master\nNamespace:         kubectl-4556\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                172.21.136.38\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         172.30.72.89:6379\nSession Affinity:  None\nEvents:            <none>\n"
Aug  3 18:16:02.536: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 describe node 10.188.31.22'
Aug  3 18:16:02.711: INFO: stderr: ""
Aug  3 18:16:02.711: INFO: stdout: "Name:               10.188.31.22\nRoles:              <none>\nLabels:             arch=amd64\n                    beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/instance-type=b3c.4x16.encrypted\n                    beta.kubernetes.io/os=linux\n                    failure-domain.beta.kubernetes.io/region=us-east\n                    failure-domain.beta.kubernetes.io/zone=wdc06\n                    ibm-cloud.kubernetes.io/encrypted-docker-data=true\n                    ibm-cloud.kubernetes.io/external-ip=169.60.74.243\n                    ibm-cloud.kubernetes.io/ha-worker=true\n                    ibm-cloud.kubernetes.io/iaas-provider=softlayer\n                    ibm-cloud.kubernetes.io/internal-ip=10.188.31.22\n                    ibm-cloud.kubernetes.io/machine-type=b3c.4x16.encrypted\n                    ibm-cloud.kubernetes.io/os=UBUNTU_18_64\n                    ibm-cloud.kubernetes.io/region=us-east\n                    ibm-cloud.kubernetes.io/sgx-enabled=false\n                    ibm-cloud.kubernetes.io/worker-id=kube-bl2q5lrw0f9jjrcq6mfg-conformance-default-000001cc\n                    ibm-cloud.kubernetes.io/worker-pool-id=bl2q5lrw0f9jjrcq6mfg-6b44c1d\n                    ibm-cloud.kubernetes.io/worker-pool-name=default\n                    ibm-cloud.kubernetes.io/worker-version=1.15.1_1511\n                    ibm-cloud.kubernetes.io/zone=wdc06\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=10.188.31.22\n                    kubernetes.io/os=linux\n                    privateVLAN=2151065\n                    publicVLAN=2151063\nAnnotations:        node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Sat, 03 Aug 2019 15:30:03 +0000\nTaints:             <none>\nUnschedulable:      false\nConditions:\n  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----             ------  -----------------                 ------------------                ------                       -------\n  MemoryPressure   False   Sat, 03 Aug 2019 18:15:35 +0000   Sat, 03 Aug 2019 15:30:03 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure     False   Sat, 03 Aug 2019 18:15:35 +0000   Sat, 03 Aug 2019 15:30:03 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure      False   Sat, 03 Aug 2019 18:15:35 +0000   Sat, 03 Aug 2019 15:30:03 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready            True    Sat, 03 Aug 2019 18:15:35 +0000   Sat, 03 Aug 2019 15:30:13 +0000   KubeletReady                 kubelet is posting ready status. AppArmor enabled\nAddresses:\n  InternalIP:  10.188.31.22\n  ExternalIP:  169.60.74.243\n  Hostname:    10.188.31.22\nCapacity:\n cpu:                4\n ephemeral-storage:  102685624Ki\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             16419916Ki\n pods:               110\nAllocatable:\n cpu:                3910m\n ephemeral-storage:  99892574949\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             13627468Ki\n pods:               110\nSystem Info:\n Machine ID:                 bc90fb95000d442191599f97da14ec40\n System UUID:                F260C8DC-65DC-12B2-7A9B-399442A35ABD\n Boot ID:                    d34b14dc-81f9-4677-ac35-7aaaa76c8bdc\n Kernel Version:             4.15.0-55-generic\n OS Image:                   Ubuntu 18.04.2 LTS\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  containerd://1.2.7\n Kubelet Version:            v1.15.1+IKS\n Kube-Proxy Version:         v1.15.1+IKS\nProviderID:                  ibm://cc7530878c499d74ad77f31c918c626e///bl2q5lrw0f9jjrcq6mfg/kube-bl2q5lrw0f9jjrcq6mfg-conformance-default-000001cc\nNon-terminated Pods:         (7 in total)\n  Namespace                  Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                  ----                                                       ------------  ----------  ---------------  -------------  ---\n  heptio-sonobuoy            sonobuoy                                                   0 (0%)        0 (0%)      0 (0%)           0 (0%)         39m\n  heptio-sonobuoy            sonobuoy-e2e-job-128cd56eea1c4929                          0 (0%)        0 (0%)      0 (0%)           0 (0%)         39m\n  heptio-sonobuoy            sonobuoy-systemd-logs-daemon-set-2824ab4c610f42f4-rvnnh    0 (0%)        0 (0%)      0 (0%)           0 (0%)         39m\n  kube-system                calico-node-mc9wt                                          250m (6%)     0 (0%)      80Mi (0%)        0 (0%)         165m\n  kube-system                ibm-keepalived-watcher-fkdg8                               5m (0%)       0 (0%)      10Mi (0%)        0 (0%)         165m\n  kube-system                ibm-kube-fluentd-25wz8                                     25m (0%)      300m (7%)   150Mi (1%)       1600M (11%)    165m\n  kube-system                ibm-master-proxy-static-10.188.31.22                       25m (0%)      300m (7%)   32M (0%)         512M (3%)      165m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests       Limits\n  --------           --------       ------\n  cpu                305m (7%)      600m (15%)\n  memory             277010Ki (2%)  2112M (15%)\n  ephemeral-storage  0 (0%)         0 (0%)\nEvents:              <none>\n"
Aug  3 18:16:02.711: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 describe namespace kubectl-4556'
Aug  3 18:16:02.860: INFO: stderr: ""
Aug  3 18:16:02.860: INFO: stdout: "Name:         kubectl-4556\nLabels:       e2e-framework=kubectl\n              e2e-run=58b31e28-0c16-4685-8313-d0347234ae20\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 18:16:02.860: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4556" for this suite.
Aug  3 18:16:26.929: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 18:16:27.259: INFO: namespace kubectl-4556 deletion completed in 24.369899611s

• [SLOW TEST:28.117 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl describe
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 18:16:27.260: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-6032
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-6032.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-6032.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-6032.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-6032.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-6032.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-6032.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-6032.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-6032.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-6032.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-6032.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-6032.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-6032.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-6032.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 138.88.21.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.21.88.138_udp@PTR;check="$$(dig +tcp +noall +answer +search 138.88.21.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.21.88.138_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-6032.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-6032.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-6032.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-6032.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-6032.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-6032.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-6032.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-6032.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-6032.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-6032.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-6032.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-6032.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-6032.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 138.88.21.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.21.88.138_udp@PTR;check="$$(dig +tcp +noall +answer +search 138.88.21.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.21.88.138_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Aug  3 18:16:31.730: INFO: Unable to read wheezy_udp@dns-test-service.dns-6032.svc.cluster.local from pod dns-6032/dns-test-80fcbc78-6561-4b16-a7d8-b8eac2d1e4dc: the server could not find the requested resource (get pods dns-test-80fcbc78-6561-4b16-a7d8-b8eac2d1e4dc)
Aug  3 18:16:31.742: INFO: Unable to read wheezy_tcp@dns-test-service.dns-6032.svc.cluster.local from pod dns-6032/dns-test-80fcbc78-6561-4b16-a7d8-b8eac2d1e4dc: the server could not find the requested resource (get pods dns-test-80fcbc78-6561-4b16-a7d8-b8eac2d1e4dc)
Aug  3 18:16:31.753: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-6032.svc.cluster.local from pod dns-6032/dns-test-80fcbc78-6561-4b16-a7d8-b8eac2d1e4dc: the server could not find the requested resource (get pods dns-test-80fcbc78-6561-4b16-a7d8-b8eac2d1e4dc)
Aug  3 18:16:31.764: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-6032.svc.cluster.local from pod dns-6032/dns-test-80fcbc78-6561-4b16-a7d8-b8eac2d1e4dc: the server could not find the requested resource (get pods dns-test-80fcbc78-6561-4b16-a7d8-b8eac2d1e4dc)
Aug  3 18:16:31.849: INFO: Unable to read jessie_udp@dns-test-service.dns-6032.svc.cluster.local from pod dns-6032/dns-test-80fcbc78-6561-4b16-a7d8-b8eac2d1e4dc: the server could not find the requested resource (get pods dns-test-80fcbc78-6561-4b16-a7d8-b8eac2d1e4dc)
Aug  3 18:16:31.861: INFO: Unable to read jessie_tcp@dns-test-service.dns-6032.svc.cluster.local from pod dns-6032/dns-test-80fcbc78-6561-4b16-a7d8-b8eac2d1e4dc: the server could not find the requested resource (get pods dns-test-80fcbc78-6561-4b16-a7d8-b8eac2d1e4dc)
Aug  3 18:16:31.871: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-6032.svc.cluster.local from pod dns-6032/dns-test-80fcbc78-6561-4b16-a7d8-b8eac2d1e4dc: the server could not find the requested resource (get pods dns-test-80fcbc78-6561-4b16-a7d8-b8eac2d1e4dc)
Aug  3 18:16:31.894: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-6032.svc.cluster.local from pod dns-6032/dns-test-80fcbc78-6561-4b16-a7d8-b8eac2d1e4dc: the server could not find the requested resource (get pods dns-test-80fcbc78-6561-4b16-a7d8-b8eac2d1e4dc)
Aug  3 18:16:31.962: INFO: Lookups using dns-6032/dns-test-80fcbc78-6561-4b16-a7d8-b8eac2d1e4dc failed for: [wheezy_udp@dns-test-service.dns-6032.svc.cluster.local wheezy_tcp@dns-test-service.dns-6032.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-6032.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-6032.svc.cluster.local jessie_udp@dns-test-service.dns-6032.svc.cluster.local jessie_tcp@dns-test-service.dns-6032.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-6032.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-6032.svc.cluster.local]

Aug  3 18:16:36.978: INFO: Unable to read wheezy_udp@dns-test-service.dns-6032.svc.cluster.local from pod dns-6032/dns-test-80fcbc78-6561-4b16-a7d8-b8eac2d1e4dc: the server could not find the requested resource (get pods dns-test-80fcbc78-6561-4b16-a7d8-b8eac2d1e4dc)
Aug  3 18:16:36.993: INFO: Unable to read wheezy_tcp@dns-test-service.dns-6032.svc.cluster.local from pod dns-6032/dns-test-80fcbc78-6561-4b16-a7d8-b8eac2d1e4dc: the server could not find the requested resource (get pods dns-test-80fcbc78-6561-4b16-a7d8-b8eac2d1e4dc)
Aug  3 18:16:37.010: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-6032.svc.cluster.local from pod dns-6032/dns-test-80fcbc78-6561-4b16-a7d8-b8eac2d1e4dc: the server could not find the requested resource (get pods dns-test-80fcbc78-6561-4b16-a7d8-b8eac2d1e4dc)
Aug  3 18:16:37.024: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-6032.svc.cluster.local from pod dns-6032/dns-test-80fcbc78-6561-4b16-a7d8-b8eac2d1e4dc: the server could not find the requested resource (get pods dns-test-80fcbc78-6561-4b16-a7d8-b8eac2d1e4dc)
Aug  3 18:16:37.127: INFO: Unable to read jessie_udp@dns-test-service.dns-6032.svc.cluster.local from pod dns-6032/dns-test-80fcbc78-6561-4b16-a7d8-b8eac2d1e4dc: the server could not find the requested resource (get pods dns-test-80fcbc78-6561-4b16-a7d8-b8eac2d1e4dc)
Aug  3 18:16:37.142: INFO: Unable to read jessie_tcp@dns-test-service.dns-6032.svc.cluster.local from pod dns-6032/dns-test-80fcbc78-6561-4b16-a7d8-b8eac2d1e4dc: the server could not find the requested resource (get pods dns-test-80fcbc78-6561-4b16-a7d8-b8eac2d1e4dc)
Aug  3 18:16:37.154: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-6032.svc.cluster.local from pod dns-6032/dns-test-80fcbc78-6561-4b16-a7d8-b8eac2d1e4dc: the server could not find the requested resource (get pods dns-test-80fcbc78-6561-4b16-a7d8-b8eac2d1e4dc)
Aug  3 18:16:37.166: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-6032.svc.cluster.local from pod dns-6032/dns-test-80fcbc78-6561-4b16-a7d8-b8eac2d1e4dc: the server could not find the requested resource (get pods dns-test-80fcbc78-6561-4b16-a7d8-b8eac2d1e4dc)
Aug  3 18:16:37.235: INFO: Lookups using dns-6032/dns-test-80fcbc78-6561-4b16-a7d8-b8eac2d1e4dc failed for: [wheezy_udp@dns-test-service.dns-6032.svc.cluster.local wheezy_tcp@dns-test-service.dns-6032.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-6032.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-6032.svc.cluster.local jessie_udp@dns-test-service.dns-6032.svc.cluster.local jessie_tcp@dns-test-service.dns-6032.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-6032.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-6032.svc.cluster.local]

Aug  3 18:16:41.974: INFO: Unable to read wheezy_udp@dns-test-service.dns-6032.svc.cluster.local from pod dns-6032/dns-test-80fcbc78-6561-4b16-a7d8-b8eac2d1e4dc: the server could not find the requested resource (get pods dns-test-80fcbc78-6561-4b16-a7d8-b8eac2d1e4dc)
Aug  3 18:16:42.002: INFO: Unable to read wheezy_tcp@dns-test-service.dns-6032.svc.cluster.local from pod dns-6032/dns-test-80fcbc78-6561-4b16-a7d8-b8eac2d1e4dc: the server could not find the requested resource (get pods dns-test-80fcbc78-6561-4b16-a7d8-b8eac2d1e4dc)
Aug  3 18:16:42.014: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-6032.svc.cluster.local from pod dns-6032/dns-test-80fcbc78-6561-4b16-a7d8-b8eac2d1e4dc: the server could not find the requested resource (get pods dns-test-80fcbc78-6561-4b16-a7d8-b8eac2d1e4dc)
Aug  3 18:16:42.038: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-6032.svc.cluster.local from pod dns-6032/dns-test-80fcbc78-6561-4b16-a7d8-b8eac2d1e4dc: the server could not find the requested resource (get pods dns-test-80fcbc78-6561-4b16-a7d8-b8eac2d1e4dc)
Aug  3 18:16:42.136: INFO: Unable to read jessie_udp@dns-test-service.dns-6032.svc.cluster.local from pod dns-6032/dns-test-80fcbc78-6561-4b16-a7d8-b8eac2d1e4dc: the server could not find the requested resource (get pods dns-test-80fcbc78-6561-4b16-a7d8-b8eac2d1e4dc)
Aug  3 18:16:42.151: INFO: Unable to read jessie_tcp@dns-test-service.dns-6032.svc.cluster.local from pod dns-6032/dns-test-80fcbc78-6561-4b16-a7d8-b8eac2d1e4dc: the server could not find the requested resource (get pods dns-test-80fcbc78-6561-4b16-a7d8-b8eac2d1e4dc)
Aug  3 18:16:42.162: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-6032.svc.cluster.local from pod dns-6032/dns-test-80fcbc78-6561-4b16-a7d8-b8eac2d1e4dc: the server could not find the requested resource (get pods dns-test-80fcbc78-6561-4b16-a7d8-b8eac2d1e4dc)
Aug  3 18:16:42.173: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-6032.svc.cluster.local from pod dns-6032/dns-test-80fcbc78-6561-4b16-a7d8-b8eac2d1e4dc: the server could not find the requested resource (get pods dns-test-80fcbc78-6561-4b16-a7d8-b8eac2d1e4dc)
Aug  3 18:16:42.255: INFO: Lookups using dns-6032/dns-test-80fcbc78-6561-4b16-a7d8-b8eac2d1e4dc failed for: [wheezy_udp@dns-test-service.dns-6032.svc.cluster.local wheezy_tcp@dns-test-service.dns-6032.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-6032.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-6032.svc.cluster.local jessie_udp@dns-test-service.dns-6032.svc.cluster.local jessie_tcp@dns-test-service.dns-6032.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-6032.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-6032.svc.cluster.local]

Aug  3 18:16:46.974: INFO: Unable to read wheezy_udp@dns-test-service.dns-6032.svc.cluster.local from pod dns-6032/dns-test-80fcbc78-6561-4b16-a7d8-b8eac2d1e4dc: the server could not find the requested resource (get pods dns-test-80fcbc78-6561-4b16-a7d8-b8eac2d1e4dc)
Aug  3 18:16:46.989: INFO: Unable to read wheezy_tcp@dns-test-service.dns-6032.svc.cluster.local from pod dns-6032/dns-test-80fcbc78-6561-4b16-a7d8-b8eac2d1e4dc: the server could not find the requested resource (get pods dns-test-80fcbc78-6561-4b16-a7d8-b8eac2d1e4dc)
Aug  3 18:16:47.002: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-6032.svc.cluster.local from pod dns-6032/dns-test-80fcbc78-6561-4b16-a7d8-b8eac2d1e4dc: the server could not find the requested resource (get pods dns-test-80fcbc78-6561-4b16-a7d8-b8eac2d1e4dc)
Aug  3 18:16:47.014: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-6032.svc.cluster.local from pod dns-6032/dns-test-80fcbc78-6561-4b16-a7d8-b8eac2d1e4dc: the server could not find the requested resource (get pods dns-test-80fcbc78-6561-4b16-a7d8-b8eac2d1e4dc)
Aug  3 18:16:47.109: INFO: Unable to read jessie_udp@dns-test-service.dns-6032.svc.cluster.local from pod dns-6032/dns-test-80fcbc78-6561-4b16-a7d8-b8eac2d1e4dc: the server could not find the requested resource (get pods dns-test-80fcbc78-6561-4b16-a7d8-b8eac2d1e4dc)
Aug  3 18:16:47.123: INFO: Unable to read jessie_tcp@dns-test-service.dns-6032.svc.cluster.local from pod dns-6032/dns-test-80fcbc78-6561-4b16-a7d8-b8eac2d1e4dc: the server could not find the requested resource (get pods dns-test-80fcbc78-6561-4b16-a7d8-b8eac2d1e4dc)
Aug  3 18:16:47.134: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-6032.svc.cluster.local from pod dns-6032/dns-test-80fcbc78-6561-4b16-a7d8-b8eac2d1e4dc: the server could not find the requested resource (get pods dns-test-80fcbc78-6561-4b16-a7d8-b8eac2d1e4dc)
Aug  3 18:16:47.145: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-6032.svc.cluster.local from pod dns-6032/dns-test-80fcbc78-6561-4b16-a7d8-b8eac2d1e4dc: the server could not find the requested resource (get pods dns-test-80fcbc78-6561-4b16-a7d8-b8eac2d1e4dc)
Aug  3 18:16:47.219: INFO: Lookups using dns-6032/dns-test-80fcbc78-6561-4b16-a7d8-b8eac2d1e4dc failed for: [wheezy_udp@dns-test-service.dns-6032.svc.cluster.local wheezy_tcp@dns-test-service.dns-6032.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-6032.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-6032.svc.cluster.local jessie_udp@dns-test-service.dns-6032.svc.cluster.local jessie_tcp@dns-test-service.dns-6032.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-6032.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-6032.svc.cluster.local]

Aug  3 18:16:51.975: INFO: Unable to read wheezy_udp@dns-test-service.dns-6032.svc.cluster.local from pod dns-6032/dns-test-80fcbc78-6561-4b16-a7d8-b8eac2d1e4dc: the server could not find the requested resource (get pods dns-test-80fcbc78-6561-4b16-a7d8-b8eac2d1e4dc)
Aug  3 18:16:51.988: INFO: Unable to read wheezy_tcp@dns-test-service.dns-6032.svc.cluster.local from pod dns-6032/dns-test-80fcbc78-6561-4b16-a7d8-b8eac2d1e4dc: the server could not find the requested resource (get pods dns-test-80fcbc78-6561-4b16-a7d8-b8eac2d1e4dc)
Aug  3 18:16:51.999: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-6032.svc.cluster.local from pod dns-6032/dns-test-80fcbc78-6561-4b16-a7d8-b8eac2d1e4dc: the server could not find the requested resource (get pods dns-test-80fcbc78-6561-4b16-a7d8-b8eac2d1e4dc)
Aug  3 18:16:52.011: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-6032.svc.cluster.local from pod dns-6032/dns-test-80fcbc78-6561-4b16-a7d8-b8eac2d1e4dc: the server could not find the requested resource (get pods dns-test-80fcbc78-6561-4b16-a7d8-b8eac2d1e4dc)
Aug  3 18:16:52.115: INFO: Unable to read jessie_udp@dns-test-service.dns-6032.svc.cluster.local from pod dns-6032/dns-test-80fcbc78-6561-4b16-a7d8-b8eac2d1e4dc: the server could not find the requested resource (get pods dns-test-80fcbc78-6561-4b16-a7d8-b8eac2d1e4dc)
Aug  3 18:16:52.126: INFO: Unable to read jessie_tcp@dns-test-service.dns-6032.svc.cluster.local from pod dns-6032/dns-test-80fcbc78-6561-4b16-a7d8-b8eac2d1e4dc: the server could not find the requested resource (get pods dns-test-80fcbc78-6561-4b16-a7d8-b8eac2d1e4dc)
Aug  3 18:16:52.137: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-6032.svc.cluster.local from pod dns-6032/dns-test-80fcbc78-6561-4b16-a7d8-b8eac2d1e4dc: the server could not find the requested resource (get pods dns-test-80fcbc78-6561-4b16-a7d8-b8eac2d1e4dc)
Aug  3 18:16:52.153: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-6032.svc.cluster.local from pod dns-6032/dns-test-80fcbc78-6561-4b16-a7d8-b8eac2d1e4dc: the server could not find the requested resource (get pods dns-test-80fcbc78-6561-4b16-a7d8-b8eac2d1e4dc)
Aug  3 18:16:52.243: INFO: Lookups using dns-6032/dns-test-80fcbc78-6561-4b16-a7d8-b8eac2d1e4dc failed for: [wheezy_udp@dns-test-service.dns-6032.svc.cluster.local wheezy_tcp@dns-test-service.dns-6032.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-6032.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-6032.svc.cluster.local jessie_udp@dns-test-service.dns-6032.svc.cluster.local jessie_tcp@dns-test-service.dns-6032.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-6032.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-6032.svc.cluster.local]

Aug  3 18:16:57.120: INFO: Unable to read wheezy_udp@dns-test-service.dns-6032.svc.cluster.local from pod dns-6032/dns-test-80fcbc78-6561-4b16-a7d8-b8eac2d1e4dc: the server could not find the requested resource (get pods dns-test-80fcbc78-6561-4b16-a7d8-b8eac2d1e4dc)
Aug  3 18:16:57.132: INFO: Unable to read wheezy_tcp@dns-test-service.dns-6032.svc.cluster.local from pod dns-6032/dns-test-80fcbc78-6561-4b16-a7d8-b8eac2d1e4dc: the server could not find the requested resource (get pods dns-test-80fcbc78-6561-4b16-a7d8-b8eac2d1e4dc)
Aug  3 18:16:57.144: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-6032.svc.cluster.local from pod dns-6032/dns-test-80fcbc78-6561-4b16-a7d8-b8eac2d1e4dc: the server could not find the requested resource (get pods dns-test-80fcbc78-6561-4b16-a7d8-b8eac2d1e4dc)
Aug  3 18:16:57.158: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-6032.svc.cluster.local from pod dns-6032/dns-test-80fcbc78-6561-4b16-a7d8-b8eac2d1e4dc: the server could not find the requested resource (get pods dns-test-80fcbc78-6561-4b16-a7d8-b8eac2d1e4dc)
Aug  3 18:16:57.262: INFO: Unable to read jessie_udp@dns-test-service.dns-6032.svc.cluster.local from pod dns-6032/dns-test-80fcbc78-6561-4b16-a7d8-b8eac2d1e4dc: the server could not find the requested resource (get pods dns-test-80fcbc78-6561-4b16-a7d8-b8eac2d1e4dc)
Aug  3 18:16:57.273: INFO: Unable to read jessie_tcp@dns-test-service.dns-6032.svc.cluster.local from pod dns-6032/dns-test-80fcbc78-6561-4b16-a7d8-b8eac2d1e4dc: the server could not find the requested resource (get pods dns-test-80fcbc78-6561-4b16-a7d8-b8eac2d1e4dc)
Aug  3 18:16:57.284: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-6032.svc.cluster.local from pod dns-6032/dns-test-80fcbc78-6561-4b16-a7d8-b8eac2d1e4dc: the server could not find the requested resource (get pods dns-test-80fcbc78-6561-4b16-a7d8-b8eac2d1e4dc)
Aug  3 18:16:57.295: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-6032.svc.cluster.local from pod dns-6032/dns-test-80fcbc78-6561-4b16-a7d8-b8eac2d1e4dc: the server could not find the requested resource (get pods dns-test-80fcbc78-6561-4b16-a7d8-b8eac2d1e4dc)
Aug  3 18:16:57.367: INFO: Lookups using dns-6032/dns-test-80fcbc78-6561-4b16-a7d8-b8eac2d1e4dc failed for: [wheezy_udp@dns-test-service.dns-6032.svc.cluster.local wheezy_tcp@dns-test-service.dns-6032.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-6032.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-6032.svc.cluster.local jessie_udp@dns-test-service.dns-6032.svc.cluster.local jessie_tcp@dns-test-service.dns-6032.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-6032.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-6032.svc.cluster.local]

Aug  3 18:17:02.301: INFO: DNS probes using dns-6032/dns-test-80fcbc78-6561-4b16-a7d8-b8eac2d1e4dc succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 18:17:02.442: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-6032" for this suite.
Aug  3 18:17:08.500: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 18:17:08.858: INFO: namespace dns-6032 deletion completed in 6.403529476s

• [SLOW TEST:41.598 seconds]
[sig-network] DNS
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 18:17:08.858: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-6260
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-67f35aac-bf3c-42ab-8d89-8debef0ca187
STEP: Creating a pod to test consume configMaps
Aug  3 18:17:09.130: INFO: Waiting up to 5m0s for pod "pod-configmaps-3f297a86-aca1-4f93-b76d-17ea20c5eee5" in namespace "configmap-6260" to be "success or failure"
Aug  3 18:17:09.139: INFO: Pod "pod-configmaps-3f297a86-aca1-4f93-b76d-17ea20c5eee5": Phase="Pending", Reason="", readiness=false. Elapsed: 9.16845ms
Aug  3 18:17:11.148: INFO: Pod "pod-configmaps-3f297a86-aca1-4f93-b76d-17ea20c5eee5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.017643885s
STEP: Saw pod success
Aug  3 18:17:11.148: INFO: Pod "pod-configmaps-3f297a86-aca1-4f93-b76d-17ea20c5eee5" satisfied condition "success or failure"
Aug  3 18:17:11.158: INFO: Trying to get logs from node 10.188.31.32 pod pod-configmaps-3f297a86-aca1-4f93-b76d-17ea20c5eee5 container configmap-volume-test: <nil>
STEP: delete the pod
Aug  3 18:17:11.207: INFO: Waiting for pod pod-configmaps-3f297a86-aca1-4f93-b76d-17ea20c5eee5 to disappear
Aug  3 18:17:11.215: INFO: Pod pod-configmaps-3f297a86-aca1-4f93-b76d-17ea20c5eee5 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 18:17:11.215: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6260" for this suite.
Aug  3 18:17:17.257: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 18:17:17.567: INFO: namespace configmap-6260 deletion completed in 6.340699446s

• [SLOW TEST:8.709 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 18:17:17.569: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-2570
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test use defaults
Aug  3 18:17:17.811: INFO: Waiting up to 5m0s for pod "client-containers-6254fb54-9539-46da-a34e-11ea48649e6a" in namespace "containers-2570" to be "success or failure"
Aug  3 18:17:17.820: INFO: Pod "client-containers-6254fb54-9539-46da-a34e-11ea48649e6a": Phase="Pending", Reason="", readiness=false. Elapsed: 8.957472ms
Aug  3 18:17:19.831: INFO: Pod "client-containers-6254fb54-9539-46da-a34e-11ea48649e6a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020003047s
Aug  3 18:17:21.841: INFO: Pod "client-containers-6254fb54-9539-46da-a34e-11ea48649e6a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.029972148s
STEP: Saw pod success
Aug  3 18:17:21.841: INFO: Pod "client-containers-6254fb54-9539-46da-a34e-11ea48649e6a" satisfied condition "success or failure"
Aug  3 18:17:21.849: INFO: Trying to get logs from node 10.188.31.32 pod client-containers-6254fb54-9539-46da-a34e-11ea48649e6a container test-container: <nil>
STEP: delete the pod
Aug  3 18:17:21.900: INFO: Waiting for pod client-containers-6254fb54-9539-46da-a34e-11ea48649e6a to disappear
Aug  3 18:17:21.907: INFO: Pod client-containers-6254fb54-9539-46da-a34e-11ea48649e6a no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 18:17:21.907: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-2570" for this suite.
Aug  3 18:17:27.950: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 18:17:28.294: INFO: namespace containers-2570 deletion completed in 6.375730311s

• [SLOW TEST:10.725 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 18:17:28.294: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-2750
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: executing a command with run --rm and attach with stdin
Aug  3 18:17:28.508: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 --namespace=kubectl-2750 run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Aug  3 18:17:30.239: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Aug  3 18:17:30.239: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 18:17:32.258: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2750" for this suite.
Aug  3 18:17:38.304: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 18:17:38.641: INFO: namespace kubectl-2750 deletion completed in 6.369169655s

• [SLOW TEST:10.347 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run --rm job
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 18:17:38.643: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-7894
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod test-webserver-7f407372-70ee-4775-8d89-9d20235cb652 in namespace container-probe-7894
Aug  3 18:17:42.964: INFO: Started pod test-webserver-7f407372-70ee-4775-8d89-9d20235cb652 in namespace container-probe-7894
STEP: checking the pod's current state and verifying that restartCount is present
Aug  3 18:17:42.971: INFO: Initial restart count of pod test-webserver-7f407372-70ee-4775-8d89-9d20235cb652 is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 18:21:44.436: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-7894" for this suite.
Aug  3 18:21:50.479: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 18:21:50.836: INFO: namespace container-probe-7894 deletion completed in 6.38854642s

• [SLOW TEST:252.193 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 18:21:50.836: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svcaccounts-8199
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: getting the auto-created API token
Aug  3 18:21:51.612: INFO: created pod pod-service-account-defaultsa
Aug  3 18:21:51.612: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Aug  3 18:21:51.622: INFO: created pod pod-service-account-mountsa
Aug  3 18:21:51.622: INFO: pod pod-service-account-mountsa service account token volume mount: true
Aug  3 18:21:51.631: INFO: created pod pod-service-account-nomountsa
Aug  3 18:21:51.631: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Aug  3 18:21:51.642: INFO: created pod pod-service-account-defaultsa-mountspec
Aug  3 18:21:51.642: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Aug  3 18:21:51.653: INFO: created pod pod-service-account-mountsa-mountspec
Aug  3 18:21:51.653: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Aug  3 18:21:51.662: INFO: created pod pod-service-account-nomountsa-mountspec
Aug  3 18:21:51.662: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Aug  3 18:21:51.672: INFO: created pod pod-service-account-defaultsa-nomountspec
Aug  3 18:21:51.672: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Aug  3 18:21:51.687: INFO: created pod pod-service-account-mountsa-nomountspec
Aug  3 18:21:51.687: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Aug  3 18:21:51.696: INFO: created pod pod-service-account-nomountsa-nomountspec
Aug  3 18:21:51.696: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 18:21:51.697: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-8199" for this suite.
Aug  3 18:21:57.742: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 18:21:58.104: INFO: namespace svcaccounts-8199 deletion completed in 6.392982369s

• [SLOW TEST:7.267 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:23
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 18:21:58.108: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-5960
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:63
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Aug  3 18:22:04.443: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug  3 18:22:04.451: INFO: Pod pod-with-prestop-exec-hook still exists
Aug  3 18:22:06.451: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug  3 18:22:06.465: INFO: Pod pod-with-prestop-exec-hook still exists
Aug  3 18:22:08.451: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug  3 18:22:08.469: INFO: Pod pod-with-prestop-exec-hook still exists
Aug  3 18:22:10.451: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug  3 18:22:10.462: INFO: Pod pod-with-prestop-exec-hook still exists
Aug  3 18:22:12.451: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug  3 18:22:12.459: INFO: Pod pod-with-prestop-exec-hook still exists
Aug  3 18:22:14.451: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug  3 18:22:14.461: INFO: Pod pod-with-prestop-exec-hook still exists
Aug  3 18:22:16.451: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug  3 18:22:16.460: INFO: Pod pod-with-prestop-exec-hook still exists
Aug  3 18:22:18.451: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug  3 18:22:18.459: INFO: Pod pod-with-prestop-exec-hook still exists
Aug  3 18:22:20.451: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug  3 18:22:20.469: INFO: Pod pod-with-prestop-exec-hook still exists
Aug  3 18:22:22.451: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug  3 18:22:22.459: INFO: Pod pod-with-prestop-exec-hook still exists
Aug  3 18:22:24.451: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug  3 18:22:24.461: INFO: Pod pod-with-prestop-exec-hook still exists
Aug  3 18:22:26.451: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug  3 18:22:26.461: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 18:22:26.484: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-5960" for this suite.
Aug  3 18:22:50.551: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 18:22:50.885: INFO: namespace container-lifecycle-hook-5960 deletion completed in 24.37387804s

• [SLOW TEST:52.778 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when create a pod with lifecycle hook
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 18:22:50.886: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-8974
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
Aug  3 18:23:31.201: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W0803 18:23:31.201617      17 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 18:23:31.201: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-8974" for this suite.
Aug  3 18:23:39.278: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 18:23:39.600: INFO: namespace gc-8974 deletion completed in 8.360737583s

• [SLOW TEST:48.715 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 18:23:39.602: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2439
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Aug  3 18:23:39.840: INFO: Waiting up to 5m0s for pod "downwardapi-volume-62c65b1d-9708-4538-a303-98566cba4b3d" in namespace "projected-2439" to be "success or failure"
Aug  3 18:23:39.849: INFO: Pod "downwardapi-volume-62c65b1d-9708-4538-a303-98566cba4b3d": Phase="Pending", Reason="", readiness=false. Elapsed: 9.19125ms
Aug  3 18:23:41.859: INFO: Pod "downwardapi-volume-62c65b1d-9708-4538-a303-98566cba4b3d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.018470963s
STEP: Saw pod success
Aug  3 18:23:41.859: INFO: Pod "downwardapi-volume-62c65b1d-9708-4538-a303-98566cba4b3d" satisfied condition "success or failure"
Aug  3 18:23:41.866: INFO: Trying to get logs from node 10.188.31.32 pod downwardapi-volume-62c65b1d-9708-4538-a303-98566cba4b3d container client-container: <nil>
STEP: delete the pod
Aug  3 18:23:41.918: INFO: Waiting for pod downwardapi-volume-62c65b1d-9708-4538-a303-98566cba4b3d to disappear
Aug  3 18:23:41.930: INFO: Pod downwardapi-volume-62c65b1d-9708-4538-a303-98566cba4b3d no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 18:23:41.930: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2439" for this suite.
Aug  3 18:23:48.122: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 18:23:48.422: INFO: namespace projected-2439 deletion completed in 6.480099042s

• [SLOW TEST:8.820 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 18:23:48.423: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-1759
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Aug  3 18:23:48.651: INFO: Pod name rollover-pod: Found 0 pods out of 1
Aug  3 18:23:53.661: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Aug  3 18:23:53.661: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Aug  3 18:23:55.670: INFO: Creating deployment "test-rollover-deployment"
Aug  3 18:23:55.698: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Aug  3 18:23:57.713: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Aug  3 18:23:57.729: INFO: Ensure that both replica sets have 1 created replica
Aug  3 18:23:57.745: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Aug  3 18:23:57.763: INFO: Updating deployment test-rollover-deployment
Aug  3 18:23:57.763: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Aug  3 18:23:59.779: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Aug  3 18:23:59.796: INFO: Make sure deployment "test-rollover-deployment" is complete
Aug  3 18:23:59.818: INFO: all replica sets need to contain the pod-template-hash label
Aug  3 18:23:59.818: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700453435, loc:(*time.Location)(0x80c0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700453435, loc:(*time.Location)(0x80c0a20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700453437, loc:(*time.Location)(0x80c0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700453435, loc:(*time.Location)(0x80c0a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug  3 18:24:01.837: INFO: all replica sets need to contain the pod-template-hash label
Aug  3 18:24:01.837: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700453435, loc:(*time.Location)(0x80c0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700453435, loc:(*time.Location)(0x80c0a20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700453440, loc:(*time.Location)(0x80c0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700453435, loc:(*time.Location)(0x80c0a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug  3 18:24:03.839: INFO: all replica sets need to contain the pod-template-hash label
Aug  3 18:24:03.839: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700453435, loc:(*time.Location)(0x80c0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700453435, loc:(*time.Location)(0x80c0a20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700453440, loc:(*time.Location)(0x80c0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700453435, loc:(*time.Location)(0x80c0a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug  3 18:24:05.836: INFO: all replica sets need to contain the pod-template-hash label
Aug  3 18:24:05.836: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700453435, loc:(*time.Location)(0x80c0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700453435, loc:(*time.Location)(0x80c0a20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700453440, loc:(*time.Location)(0x80c0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700453435, loc:(*time.Location)(0x80c0a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug  3 18:24:07.838: INFO: all replica sets need to contain the pod-template-hash label
Aug  3 18:24:07.838: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700453435, loc:(*time.Location)(0x80c0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700453435, loc:(*time.Location)(0x80c0a20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700453440, loc:(*time.Location)(0x80c0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700453435, loc:(*time.Location)(0x80c0a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug  3 18:24:09.838: INFO: all replica sets need to contain the pod-template-hash label
Aug  3 18:24:09.838: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700453435, loc:(*time.Location)(0x80c0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700453435, loc:(*time.Location)(0x80c0a20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700453440, loc:(*time.Location)(0x80c0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700453435, loc:(*time.Location)(0x80c0a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug  3 18:24:11.838: INFO: 
Aug  3 18:24:11.838: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
Aug  3 18:24:11.862: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment,GenerateName:,Namespace:deployment-1759,SelfLink:/apis/apps/v1/namespaces/deployment-1759/deployments/test-rollover-deployment,UID:d9ddbff1-6028-42e1-859a-f2d78054f6bc,ResourceVersion:41048,Generation:2,CreationTimestamp:2019-08-03 18:23:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-08-03 18:23:55 +0000 UTC 2019-08-03 18:23:55 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-08-03 18:24:10 +0000 UTC 2019-08-03 18:23:55 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rollover-deployment-854595fc44" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Aug  3 18:24:11.871: INFO: New ReplicaSet "test-rollover-deployment-854595fc44" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-854595fc44,GenerateName:,Namespace:deployment-1759,SelfLink:/apis/apps/v1/namespaces/deployment-1759/replicasets/test-rollover-deployment-854595fc44,UID:bed5bd9e-e4c3-4b3a-920c-d98e189ef9cf,ResourceVersion:41037,Generation:2,CreationTimestamp:2019-08-03 18:23:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 854595fc44,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment d9ddbff1-6028-42e1-859a-f2d78054f6bc 0xc002ece1e7 0xc002ece1e8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 854595fc44,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 854595fc44,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Aug  3 18:24:11.871: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Aug  3 18:24:11.871: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-controller,GenerateName:,Namespace:deployment-1759,SelfLink:/apis/apps/v1/namespaces/deployment-1759/replicasets/test-rollover-controller,UID:71fef8ed-dfa1-4fb1-ad23-7ab9b0c85c19,ResourceVersion:41047,Generation:2,CreationTimestamp:2019-08-03 18:23:48 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment d9ddbff1-6028-42e1-859a-f2d78054f6bc 0xc002ece117 0xc002ece118}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Aug  3 18:24:11.872: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-9b8b997cf,GenerateName:,Namespace:deployment-1759,SelfLink:/apis/apps/v1/namespaces/deployment-1759/replicasets/test-rollover-deployment-9b8b997cf,UID:c72ba59d-2f10-4279-983d-9300a07c3b65,ResourceVersion:41001,Generation:2,CreationTimestamp:2019-08-03 18:23:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 9b8b997cf,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment d9ddbff1-6028-42e1-859a-f2d78054f6bc 0xc002ece2b0 0xc002ece2b1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 9b8b997cf,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 9b8b997cf,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Aug  3 18:24:11.880: INFO: Pod "test-rollover-deployment-854595fc44-pxlsm" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-854595fc44-pxlsm,GenerateName:test-rollover-deployment-854595fc44-,Namespace:deployment-1759,SelfLink:/api/v1/namespaces/deployment-1759/pods/test-rollover-deployment-854595fc44-pxlsm,UID:ade52312-62b9-421e-86ab-3588b44ede1d,ResourceVersion:41018,Generation:0,CreationTimestamp:2019-08-03 18:23:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 854595fc44,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-rollover-deployment-854595fc44 bed5bd9e-e4c3-4b3a-920c-d98e189ef9cf 0xc002f2ebb7 0xc002f2ebb8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-b8qbw {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-b8qbw,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-b8qbw true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.188.31.24,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002f2ec30} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002f2ec50}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-03 18:23:57 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-03 18:24:00 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-03 18:24:00 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-03 18:23:57 +0000 UTC  }],Message:,Reason:,HostIP:10.188.31.24,PodIP:172.30.44.87,StartTime:2019-08-03 18:23:57 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-08-03 18:23:59 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 containerd://6da2ea51f84bf0b8fb2ea7046caee74d40d51d1b53afd3b0e0632294a416db96}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 18:24:11.880: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-1759" for this suite.
Aug  3 18:24:19.945: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 18:24:20.352: INFO: namespace deployment-1759 deletion completed in 8.453431416s

• [SLOW TEST:31.930 seconds]
[sig-apps] Deployment
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support rollover [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 18:24:20.352: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-9206
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-376a419e-e3df-4811-a862-54630ba08506
STEP: Creating a pod to test consume secrets
Aug  3 18:24:20.623: INFO: Waiting up to 5m0s for pod "pod-secrets-1215840f-fc39-48bd-8b6c-e1d4f9172efd" in namespace "secrets-9206" to be "success or failure"
Aug  3 18:24:20.631: INFO: Pod "pod-secrets-1215840f-fc39-48bd-8b6c-e1d4f9172efd": Phase="Pending", Reason="", readiness=false. Elapsed: 7.501735ms
Aug  3 18:24:22.639: INFO: Pod "pod-secrets-1215840f-fc39-48bd-8b6c-e1d4f9172efd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015479215s
Aug  3 18:24:24.648: INFO: Pod "pod-secrets-1215840f-fc39-48bd-8b6c-e1d4f9172efd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.024413438s
STEP: Saw pod success
Aug  3 18:24:24.648: INFO: Pod "pod-secrets-1215840f-fc39-48bd-8b6c-e1d4f9172efd" satisfied condition "success or failure"
Aug  3 18:24:24.656: INFO: Trying to get logs from node 10.188.31.32 pod pod-secrets-1215840f-fc39-48bd-8b6c-e1d4f9172efd container secret-volume-test: <nil>
STEP: delete the pod
Aug  3 18:24:24.709: INFO: Waiting for pod pod-secrets-1215840f-fc39-48bd-8b6c-e1d4f9172efd to disappear
Aug  3 18:24:24.718: INFO: Pod pod-secrets-1215840f-fc39-48bd-8b6c-e1d4f9172efd no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 18:24:24.718: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9206" for this suite.
Aug  3 18:24:30.764: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 18:24:31.069: INFO: namespace secrets-9206 deletion completed in 6.33865733s

• [SLOW TEST:10.717 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] version v1
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 18:24:31.070: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-9678
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-9cnl9 in namespace proxy-9678
I0803 18:24:31.329419      17 runners.go:180] Created replication controller with name: proxy-service-9cnl9, namespace: proxy-9678, replica count: 1
I0803 18:24:32.379884      17 runners.go:180] proxy-service-9cnl9 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0803 18:24:33.380076      17 runners.go:180] proxy-service-9cnl9 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0803 18:24:34.380279      17 runners.go:180] proxy-service-9cnl9 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0803 18:24:35.380481      17 runners.go:180] proxy-service-9cnl9 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0803 18:24:36.380758      17 runners.go:180] proxy-service-9cnl9 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0803 18:24:37.381058      17 runners.go:180] proxy-service-9cnl9 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0803 18:24:38.381303      17 runners.go:180] proxy-service-9cnl9 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0803 18:24:39.381565      17 runners.go:180] proxy-service-9cnl9 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0803 18:24:40.381829      17 runners.go:180] proxy-service-9cnl9 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0803 18:24:41.382131      17 runners.go:180] proxy-service-9cnl9 Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Aug  3 18:24:41.393: INFO: setup took 10.108263379s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Aug  3 18:24:41.410: INFO: (0) /api/v1/namespaces/proxy-9678/pods/http:proxy-service-9cnl9-z9mds:162/proxy/: bar (200; 16.560852ms)
Aug  3 18:24:41.410: INFO: (0) /api/v1/namespaces/proxy-9678/pods/http:proxy-service-9cnl9-z9mds:160/proxy/: foo (200; 17.00699ms)
Aug  3 18:24:41.415: INFO: (0) /api/v1/namespaces/proxy-9678/pods/proxy-service-9cnl9-z9mds/proxy/: <a href="/api/v1/namespaces/proxy-9678/pods/proxy-service-9cnl9-z9mds/proxy/rewriteme">test</a> (200; 21.602282ms)
Aug  3 18:24:41.415: INFO: (0) /api/v1/namespaces/proxy-9678/pods/http:proxy-service-9cnl9-z9mds:1080/proxy/: <a href="/api/v1/namespaces/proxy-9678/pods/http:proxy-service-9cnl9-z9mds:1080/proxy/rewriteme">... (200; 21.770178ms)
Aug  3 18:24:41.415: INFO: (0) /api/v1/namespaces/proxy-9678/services/http:proxy-service-9cnl9:portname1/proxy/: foo (200; 21.839836ms)
Aug  3 18:24:41.415: INFO: (0) /api/v1/namespaces/proxy-9678/pods/proxy-service-9cnl9-z9mds:162/proxy/: bar (200; 21.807421ms)
Aug  3 18:24:41.415: INFO: (0) /api/v1/namespaces/proxy-9678/pods/proxy-service-9cnl9-z9mds:1080/proxy/: <a href="/api/v1/namespaces/proxy-9678/pods/proxy-service-9cnl9-z9mds:1080/proxy/rewriteme">test<... (200; 21.779223ms)
Aug  3 18:24:41.415: INFO: (0) /api/v1/namespaces/proxy-9678/pods/proxy-service-9cnl9-z9mds:160/proxy/: foo (200; 22.008726ms)
Aug  3 18:24:41.417: INFO: (0) /api/v1/namespaces/proxy-9678/services/http:proxy-service-9cnl9:portname2/proxy/: bar (200; 24.274037ms)
Aug  3 18:24:41.418: INFO: (0) /api/v1/namespaces/proxy-9678/services/proxy-service-9cnl9:portname1/proxy/: foo (200; 25.168194ms)
Aug  3 18:24:41.422: INFO: (0) /api/v1/namespaces/proxy-9678/pods/https:proxy-service-9cnl9-z9mds:462/proxy/: tls qux (200; 28.800361ms)
Aug  3 18:24:41.422: INFO: (0) /api/v1/namespaces/proxy-9678/pods/https:proxy-service-9cnl9-z9mds:443/proxy/: <a href="/api/v1/namespaces/proxy-9678/pods/https:proxy-service-9cnl9-z9mds:443/proxy/tlsrewritem... (200; 29.51564ms)
Aug  3 18:24:41.424: INFO: (0) /api/v1/namespaces/proxy-9678/services/proxy-service-9cnl9:portname2/proxy/: bar (200; 30.763941ms)
Aug  3 18:24:41.428: INFO: (0) /api/v1/namespaces/proxy-9678/pods/https:proxy-service-9cnl9-z9mds:460/proxy/: tls baz (200; 35.264262ms)
Aug  3 18:24:41.435: INFO: (0) /api/v1/namespaces/proxy-9678/services/https:proxy-service-9cnl9:tlsportname1/proxy/: tls baz (200; 41.630779ms)
Aug  3 18:24:41.444: INFO: (0) /api/v1/namespaces/proxy-9678/services/https:proxy-service-9cnl9:tlsportname2/proxy/: tls qux (200; 50.738106ms)
Aug  3 18:24:41.456: INFO: (1) /api/v1/namespaces/proxy-9678/pods/proxy-service-9cnl9-z9mds:162/proxy/: bar (200; 11.879291ms)
Aug  3 18:24:41.457: INFO: (1) /api/v1/namespaces/proxy-9678/pods/http:proxy-service-9cnl9-z9mds:162/proxy/: bar (200; 12.584325ms)
Aug  3 18:24:41.458: INFO: (1) /api/v1/namespaces/proxy-9678/pods/proxy-service-9cnl9-z9mds:1080/proxy/: <a href="/api/v1/namespaces/proxy-9678/pods/proxy-service-9cnl9-z9mds:1080/proxy/rewriteme">test<... (200; 13.692303ms)
Aug  3 18:24:41.458: INFO: (1) /api/v1/namespaces/proxy-9678/pods/https:proxy-service-9cnl9-z9mds:443/proxy/: <a href="/api/v1/namespaces/proxy-9678/pods/https:proxy-service-9cnl9-z9mds:443/proxy/tlsrewritem... (200; 14.311449ms)
Aug  3 18:24:41.458: INFO: (1) /api/v1/namespaces/proxy-9678/pods/http:proxy-service-9cnl9-z9mds:1080/proxy/: <a href="/api/v1/namespaces/proxy-9678/pods/http:proxy-service-9cnl9-z9mds:1080/proxy/rewriteme">... (200; 14.210764ms)
Aug  3 18:24:41.458: INFO: (1) /api/v1/namespaces/proxy-9678/pods/proxy-service-9cnl9-z9mds:160/proxy/: foo (200; 14.170624ms)
Aug  3 18:24:41.458: INFO: (1) /api/v1/namespaces/proxy-9678/pods/proxy-service-9cnl9-z9mds/proxy/: <a href="/api/v1/namespaces/proxy-9678/pods/proxy-service-9cnl9-z9mds/proxy/rewriteme">test</a> (200; 13.992864ms)
Aug  3 18:24:41.458: INFO: (1) /api/v1/namespaces/proxy-9678/pods/https:proxy-service-9cnl9-z9mds:460/proxy/: tls baz (200; 13.957637ms)
Aug  3 18:24:41.459: INFO: (1) /api/v1/namespaces/proxy-9678/pods/https:proxy-service-9cnl9-z9mds:462/proxy/: tls qux (200; 14.6542ms)
Aug  3 18:24:41.459: INFO: (1) /api/v1/namespaces/proxy-9678/pods/http:proxy-service-9cnl9-z9mds:160/proxy/: foo (200; 13.760776ms)
Aug  3 18:24:41.463: INFO: (1) /api/v1/namespaces/proxy-9678/services/https:proxy-service-9cnl9:tlsportname2/proxy/: tls qux (200; 18.288218ms)
Aug  3 18:24:41.466: INFO: (1) /api/v1/namespaces/proxy-9678/services/https:proxy-service-9cnl9:tlsportname1/proxy/: tls baz (200; 21.358786ms)
Aug  3 18:24:41.466: INFO: (1) /api/v1/namespaces/proxy-9678/services/http:proxy-service-9cnl9:portname2/proxy/: bar (200; 21.542416ms)
Aug  3 18:24:41.466: INFO: (1) /api/v1/namespaces/proxy-9678/services/http:proxy-service-9cnl9:portname1/proxy/: foo (200; 21.413867ms)
Aug  3 18:24:41.466: INFO: (1) /api/v1/namespaces/proxy-9678/services/proxy-service-9cnl9:portname1/proxy/: foo (200; 22.128417ms)
Aug  3 18:24:41.466: INFO: (1) /api/v1/namespaces/proxy-9678/services/proxy-service-9cnl9:portname2/proxy/: bar (200; 21.937716ms)
Aug  3 18:24:41.478: INFO: (2) /api/v1/namespaces/proxy-9678/pods/https:proxy-service-9cnl9-z9mds:462/proxy/: tls qux (200; 11.485213ms)
Aug  3 18:24:41.480: INFO: (2) /api/v1/namespaces/proxy-9678/pods/proxy-service-9cnl9-z9mds/proxy/: <a href="/api/v1/namespaces/proxy-9678/pods/proxy-service-9cnl9-z9mds/proxy/rewriteme">test</a> (200; 13.394168ms)
Aug  3 18:24:41.480: INFO: (2) /api/v1/namespaces/proxy-9678/pods/https:proxy-service-9cnl9-z9mds:443/proxy/: <a href="/api/v1/namespaces/proxy-9678/pods/https:proxy-service-9cnl9-z9mds:443/proxy/tlsrewritem... (200; 13.583079ms)
Aug  3 18:24:41.480: INFO: (2) /api/v1/namespaces/proxy-9678/pods/http:proxy-service-9cnl9-z9mds:162/proxy/: bar (200; 13.922026ms)
Aug  3 18:24:41.480: INFO: (2) /api/v1/namespaces/proxy-9678/pods/proxy-service-9cnl9-z9mds:160/proxy/: foo (200; 13.735458ms)
Aug  3 18:24:41.481: INFO: (2) /api/v1/namespaces/proxy-9678/pods/https:proxy-service-9cnl9-z9mds:460/proxy/: tls baz (200; 13.45ms)
Aug  3 18:24:41.481: INFO: (2) /api/v1/namespaces/proxy-9678/pods/http:proxy-service-9cnl9-z9mds:1080/proxy/: <a href="/api/v1/namespaces/proxy-9678/pods/http:proxy-service-9cnl9-z9mds:1080/proxy/rewriteme">... (200; 13.562789ms)
Aug  3 18:24:41.481: INFO: (2) /api/v1/namespaces/proxy-9678/pods/proxy-service-9cnl9-z9mds:1080/proxy/: <a href="/api/v1/namespaces/proxy-9678/pods/proxy-service-9cnl9-z9mds:1080/proxy/rewriteme">test<... (200; 14.162446ms)
Aug  3 18:24:41.481: INFO: (2) /api/v1/namespaces/proxy-9678/pods/proxy-service-9cnl9-z9mds:162/proxy/: bar (200; 13.866079ms)
Aug  3 18:24:41.481: INFO: (2) /api/v1/namespaces/proxy-9678/pods/http:proxy-service-9cnl9-z9mds:160/proxy/: foo (200; 13.999532ms)
Aug  3 18:24:41.484: INFO: (2) /api/v1/namespaces/proxy-9678/services/https:proxy-service-9cnl9:tlsportname1/proxy/: tls baz (200; 17.561908ms)
Aug  3 18:24:41.487: INFO: (2) /api/v1/namespaces/proxy-9678/services/proxy-service-9cnl9:portname2/proxy/: bar (200; 19.484257ms)
Aug  3 18:24:41.491: INFO: (2) /api/v1/namespaces/proxy-9678/services/http:proxy-service-9cnl9:portname2/proxy/: bar (200; 24.69057ms)
Aug  3 18:24:41.491: INFO: (2) /api/v1/namespaces/proxy-9678/services/http:proxy-service-9cnl9:portname1/proxy/: foo (200; 24.506647ms)
Aug  3 18:24:41.491: INFO: (2) /api/v1/namespaces/proxy-9678/services/https:proxy-service-9cnl9:tlsportname2/proxy/: tls qux (200; 24.858831ms)
Aug  3 18:24:41.491: INFO: (2) /api/v1/namespaces/proxy-9678/services/proxy-service-9cnl9:portname1/proxy/: foo (200; 24.516506ms)
Aug  3 18:24:41.503: INFO: (3) /api/v1/namespaces/proxy-9678/pods/https:proxy-service-9cnl9-z9mds:443/proxy/: <a href="/api/v1/namespaces/proxy-9678/pods/https:proxy-service-9cnl9-z9mds:443/proxy/tlsrewritem... (200; 10.867065ms)
Aug  3 18:24:41.503: INFO: (3) /api/v1/namespaces/proxy-9678/pods/proxy-service-9cnl9-z9mds:162/proxy/: bar (200; 10.960977ms)
Aug  3 18:24:41.504: INFO: (3) /api/v1/namespaces/proxy-9678/pods/http:proxy-service-9cnl9-z9mds:1080/proxy/: <a href="/api/v1/namespaces/proxy-9678/pods/http:proxy-service-9cnl9-z9mds:1080/proxy/rewriteme">... (200; 12.860702ms)
Aug  3 18:24:41.505: INFO: (3) /api/v1/namespaces/proxy-9678/pods/http:proxy-service-9cnl9-z9mds:162/proxy/: bar (200; 13.102882ms)
Aug  3 18:24:41.505: INFO: (3) /api/v1/namespaces/proxy-9678/pods/http:proxy-service-9cnl9-z9mds:160/proxy/: foo (200; 13.501887ms)
Aug  3 18:24:41.505: INFO: (3) /api/v1/namespaces/proxy-9678/pods/proxy-service-9cnl9-z9mds:1080/proxy/: <a href="/api/v1/namespaces/proxy-9678/pods/proxy-service-9cnl9-z9mds:1080/proxy/rewriteme">test<... (200; 13.312408ms)
Aug  3 18:24:41.506: INFO: (3) /api/v1/namespaces/proxy-9678/pods/https:proxy-service-9cnl9-z9mds:462/proxy/: tls qux (200; 13.884432ms)
Aug  3 18:24:41.507: INFO: (3) /api/v1/namespaces/proxy-9678/pods/proxy-service-9cnl9-z9mds/proxy/: <a href="/api/v1/namespaces/proxy-9678/pods/proxy-service-9cnl9-z9mds/proxy/rewriteme">test</a> (200; 15.566488ms)
Aug  3 18:24:41.507: INFO: (3) /api/v1/namespaces/proxy-9678/pods/https:proxy-service-9cnl9-z9mds:460/proxy/: tls baz (200; 15.633187ms)
Aug  3 18:24:41.507: INFO: (3) /api/v1/namespaces/proxy-9678/pods/proxy-service-9cnl9-z9mds:160/proxy/: foo (200; 15.770151ms)
Aug  3 18:24:41.510: INFO: (3) /api/v1/namespaces/proxy-9678/services/proxy-service-9cnl9:portname2/proxy/: bar (200; 18.182525ms)
Aug  3 18:24:41.513: INFO: (3) /api/v1/namespaces/proxy-9678/services/http:proxy-service-9cnl9:portname1/proxy/: foo (200; 20.932993ms)
Aug  3 18:24:41.515: INFO: (3) /api/v1/namespaces/proxy-9678/services/proxy-service-9cnl9:portname1/proxy/: foo (200; 23.171215ms)
Aug  3 18:24:41.515: INFO: (3) /api/v1/namespaces/proxy-9678/services/http:proxy-service-9cnl9:portname2/proxy/: bar (200; 23.454874ms)
Aug  3 18:24:41.515: INFO: (3) /api/v1/namespaces/proxy-9678/services/https:proxy-service-9cnl9:tlsportname1/proxy/: tls baz (200; 23.381009ms)
Aug  3 18:24:41.515: INFO: (3) /api/v1/namespaces/proxy-9678/services/https:proxy-service-9cnl9:tlsportname2/proxy/: tls qux (200; 23.370002ms)
Aug  3 18:24:41.533: INFO: (4) /api/v1/namespaces/proxy-9678/pods/https:proxy-service-9cnl9-z9mds:460/proxy/: tls baz (200; 17.126469ms)
Aug  3 18:24:41.535: INFO: (4) /api/v1/namespaces/proxy-9678/pods/proxy-service-9cnl9-z9mds:1080/proxy/: <a href="/api/v1/namespaces/proxy-9678/pods/proxy-service-9cnl9-z9mds:1080/proxy/rewriteme">test<... (200; 19.328053ms)
Aug  3 18:24:41.535: INFO: (4) /api/v1/namespaces/proxy-9678/pods/http:proxy-service-9cnl9-z9mds:160/proxy/: foo (200; 19.416607ms)
Aug  3 18:24:41.536: INFO: (4) /api/v1/namespaces/proxy-9678/pods/http:proxy-service-9cnl9-z9mds:162/proxy/: bar (200; 19.48637ms)
Aug  3 18:24:41.537: INFO: (4) /api/v1/namespaces/proxy-9678/pods/http:proxy-service-9cnl9-z9mds:1080/proxy/: <a href="/api/v1/namespaces/proxy-9678/pods/http:proxy-service-9cnl9-z9mds:1080/proxy/rewriteme">... (200; 21.705192ms)
Aug  3 18:24:41.537: INFO: (4) /api/v1/namespaces/proxy-9678/pods/proxy-service-9cnl9-z9mds:160/proxy/: foo (200; 21.680915ms)
Aug  3 18:24:41.538: INFO: (4) /api/v1/namespaces/proxy-9678/pods/proxy-service-9cnl9-z9mds/proxy/: <a href="/api/v1/namespaces/proxy-9678/pods/proxy-service-9cnl9-z9mds/proxy/rewriteme">test</a> (200; 22.33113ms)
Aug  3 18:24:41.538: INFO: (4) /api/v1/namespaces/proxy-9678/pods/https:proxy-service-9cnl9-z9mds:462/proxy/: tls qux (200; 23.123704ms)
Aug  3 18:24:41.538: INFO: (4) /api/v1/namespaces/proxy-9678/pods/https:proxy-service-9cnl9-z9mds:443/proxy/: <a href="/api/v1/namespaces/proxy-9678/pods/https:proxy-service-9cnl9-z9mds:443/proxy/tlsrewritem... (200; 22.766152ms)
Aug  3 18:24:41.538: INFO: (4) /api/v1/namespaces/proxy-9678/pods/proxy-service-9cnl9-z9mds:162/proxy/: bar (200; 22.864996ms)
Aug  3 18:24:41.540: INFO: (4) /api/v1/namespaces/proxy-9678/services/proxy-service-9cnl9:portname1/proxy/: foo (200; 24.971502ms)
Aug  3 18:24:41.543: INFO: (4) /api/v1/namespaces/proxy-9678/services/https:proxy-service-9cnl9:tlsportname2/proxy/: tls qux (200; 27.399256ms)
Aug  3 18:24:41.545: INFO: (4) /api/v1/namespaces/proxy-9678/services/proxy-service-9cnl9:portname2/proxy/: bar (200; 29.047195ms)
Aug  3 18:24:41.545: INFO: (4) /api/v1/namespaces/proxy-9678/services/http:proxy-service-9cnl9:portname1/proxy/: foo (200; 29.214908ms)
Aug  3 18:24:41.545: INFO: (4) /api/v1/namespaces/proxy-9678/services/https:proxy-service-9cnl9:tlsportname1/proxy/: tls baz (200; 29.542702ms)
Aug  3 18:24:41.545: INFO: (4) /api/v1/namespaces/proxy-9678/services/http:proxy-service-9cnl9:portname2/proxy/: bar (200; 29.533521ms)
Aug  3 18:24:41.557: INFO: (5) /api/v1/namespaces/proxy-9678/pods/https:proxy-service-9cnl9-z9mds:460/proxy/: tls baz (200; 11.504688ms)
Aug  3 18:24:41.559: INFO: (5) /api/v1/namespaces/proxy-9678/pods/http:proxy-service-9cnl9-z9mds:1080/proxy/: <a href="/api/v1/namespaces/proxy-9678/pods/http:proxy-service-9cnl9-z9mds:1080/proxy/rewriteme">... (200; 12.826895ms)
Aug  3 18:24:41.562: INFO: (5) /api/v1/namespaces/proxy-9678/pods/http:proxy-service-9cnl9-z9mds:160/proxy/: foo (200; 16.498671ms)
Aug  3 18:24:41.563: INFO: (5) /api/v1/namespaces/proxy-9678/pods/proxy-service-9cnl9-z9mds:162/proxy/: bar (200; 16.685391ms)
Aug  3 18:24:41.563: INFO: (5) /api/v1/namespaces/proxy-9678/pods/proxy-service-9cnl9-z9mds:160/proxy/: foo (200; 16.748825ms)
Aug  3 18:24:41.562: INFO: (5) /api/v1/namespaces/proxy-9678/pods/http:proxy-service-9cnl9-z9mds:162/proxy/: bar (200; 16.475357ms)
Aug  3 18:24:41.564: INFO: (5) /api/v1/namespaces/proxy-9678/pods/proxy-service-9cnl9-z9mds:1080/proxy/: <a href="/api/v1/namespaces/proxy-9678/pods/proxy-service-9cnl9-z9mds:1080/proxy/rewriteme">test<... (200; 17.816161ms)
Aug  3 18:24:41.564: INFO: (5) /api/v1/namespaces/proxy-9678/pods/proxy-service-9cnl9-z9mds/proxy/: <a href="/api/v1/namespaces/proxy-9678/pods/proxy-service-9cnl9-z9mds/proxy/rewriteme">test</a> (200; 17.778861ms)
Aug  3 18:24:41.564: INFO: (5) /api/v1/namespaces/proxy-9678/pods/https:proxy-service-9cnl9-z9mds:462/proxy/: tls qux (200; 18.220732ms)
Aug  3 18:24:41.565: INFO: (5) /api/v1/namespaces/proxy-9678/services/http:proxy-service-9cnl9:portname2/proxy/: bar (200; 19.426156ms)
Aug  3 18:24:41.566: INFO: (5) /api/v1/namespaces/proxy-9678/pods/https:proxy-service-9cnl9-z9mds:443/proxy/: <a href="/api/v1/namespaces/proxy-9678/pods/https:proxy-service-9cnl9-z9mds:443/proxy/tlsrewritem... (200; 20.12782ms)
Aug  3 18:24:41.566: INFO: (5) /api/v1/namespaces/proxy-9678/services/proxy-service-9cnl9:portname1/proxy/: foo (200; 20.827045ms)
Aug  3 18:24:41.570: INFO: (5) /api/v1/namespaces/proxy-9678/services/https:proxy-service-9cnl9:tlsportname1/proxy/: tls baz (200; 24.528439ms)
Aug  3 18:24:41.573: INFO: (5) /api/v1/namespaces/proxy-9678/services/https:proxy-service-9cnl9:tlsportname2/proxy/: tls qux (200; 27.22937ms)
Aug  3 18:24:41.581: INFO: (5) /api/v1/namespaces/proxy-9678/services/http:proxy-service-9cnl9:portname1/proxy/: foo (200; 35.150839ms)
Aug  3 18:24:41.582: INFO: (5) /api/v1/namespaces/proxy-9678/services/proxy-service-9cnl9:portname2/proxy/: bar (200; 35.726555ms)
Aug  3 18:24:41.594: INFO: (6) /api/v1/namespaces/proxy-9678/pods/https:proxy-service-9cnl9-z9mds:460/proxy/: tls baz (200; 12.639114ms)
Aug  3 18:24:41.599: INFO: (6) /api/v1/namespaces/proxy-9678/pods/http:proxy-service-9cnl9-z9mds:160/proxy/: foo (200; 16.75224ms)
Aug  3 18:24:41.599: INFO: (6) /api/v1/namespaces/proxy-9678/pods/http:proxy-service-9cnl9-z9mds:162/proxy/: bar (200; 16.805583ms)
Aug  3 18:24:41.599: INFO: (6) /api/v1/namespaces/proxy-9678/pods/proxy-service-9cnl9-z9mds:162/proxy/: bar (200; 17.066601ms)
Aug  3 18:24:41.599: INFO: (6) /api/v1/namespaces/proxy-9678/pods/http:proxy-service-9cnl9-z9mds:1080/proxy/: <a href="/api/v1/namespaces/proxy-9678/pods/http:proxy-service-9cnl9-z9mds:1080/proxy/rewriteme">... (200; 17.336257ms)
Aug  3 18:24:41.599: INFO: (6) /api/v1/namespaces/proxy-9678/pods/proxy-service-9cnl9-z9mds/proxy/: <a href="/api/v1/namespaces/proxy-9678/pods/proxy-service-9cnl9-z9mds/proxy/rewriteme">test</a> (200; 17.089115ms)
Aug  3 18:24:41.599: INFO: (6) /api/v1/namespaces/proxy-9678/pods/https:proxy-service-9cnl9-z9mds:462/proxy/: tls qux (200; 17.020616ms)
Aug  3 18:24:41.599: INFO: (6) /api/v1/namespaces/proxy-9678/pods/https:proxy-service-9cnl9-z9mds:443/proxy/: <a href="/api/v1/namespaces/proxy-9678/pods/https:proxy-service-9cnl9-z9mds:443/proxy/tlsrewritem... (200; 17.253869ms)
Aug  3 18:24:41.599: INFO: (6) /api/v1/namespaces/proxy-9678/pods/proxy-service-9cnl9-z9mds:160/proxy/: foo (200; 17.387852ms)
Aug  3 18:24:41.599: INFO: (6) /api/v1/namespaces/proxy-9678/pods/proxy-service-9cnl9-z9mds:1080/proxy/: <a href="/api/v1/namespaces/proxy-9678/pods/proxy-service-9cnl9-z9mds:1080/proxy/rewriteme">test<... (200; 17.249104ms)
Aug  3 18:24:41.604: INFO: (6) /api/v1/namespaces/proxy-9678/services/http:proxy-service-9cnl9:portname2/proxy/: bar (200; 21.766003ms)
Aug  3 18:24:41.604: INFO: (6) /api/v1/namespaces/proxy-9678/services/proxy-service-9cnl9:portname1/proxy/: foo (200; 21.733001ms)
Aug  3 18:24:41.604: INFO: (6) /api/v1/namespaces/proxy-9678/services/https:proxy-service-9cnl9:tlsportname1/proxy/: tls baz (200; 21.509461ms)
Aug  3 18:24:41.604: INFO: (6) /api/v1/namespaces/proxy-9678/services/proxy-service-9cnl9:portname2/proxy/: bar (200; 21.790695ms)
Aug  3 18:24:41.605: INFO: (6) /api/v1/namespaces/proxy-9678/services/https:proxy-service-9cnl9:tlsportname2/proxy/: tls qux (200; 23.037829ms)
Aug  3 18:24:41.605: INFO: (6) /api/v1/namespaces/proxy-9678/services/http:proxy-service-9cnl9:portname1/proxy/: foo (200; 22.885066ms)
Aug  3 18:24:41.618: INFO: (7) /api/v1/namespaces/proxy-9678/pods/proxy-service-9cnl9-z9mds:162/proxy/: bar (200; 12.2992ms)
Aug  3 18:24:41.625: INFO: (7) /api/v1/namespaces/proxy-9678/pods/http:proxy-service-9cnl9-z9mds:162/proxy/: bar (200; 19.144939ms)
Aug  3 18:24:41.625: INFO: (7) /api/v1/namespaces/proxy-9678/pods/http:proxy-service-9cnl9-z9mds:160/proxy/: foo (200; 19.276457ms)
Aug  3 18:24:41.625: INFO: (7) /api/v1/namespaces/proxy-9678/pods/proxy-service-9cnl9-z9mds/proxy/: <a href="/api/v1/namespaces/proxy-9678/pods/proxy-service-9cnl9-z9mds/proxy/rewriteme">test</a> (200; 19.266082ms)
Aug  3 18:24:41.625: INFO: (7) /api/v1/namespaces/proxy-9678/pods/http:proxy-service-9cnl9-z9mds:1080/proxy/: <a href="/api/v1/namespaces/proxy-9678/pods/http:proxy-service-9cnl9-z9mds:1080/proxy/rewriteme">... (200; 19.490143ms)
Aug  3 18:24:41.625: INFO: (7) /api/v1/namespaces/proxy-9678/pods/proxy-service-9cnl9-z9mds:160/proxy/: foo (200; 19.506921ms)
Aug  3 18:24:41.625: INFO: (7) /api/v1/namespaces/proxy-9678/pods/https:proxy-service-9cnl9-z9mds:462/proxy/: tls qux (200; 19.204274ms)
Aug  3 18:24:41.625: INFO: (7) /api/v1/namespaces/proxy-9678/pods/https:proxy-service-9cnl9-z9mds:460/proxy/: tls baz (200; 19.269446ms)
Aug  3 18:24:41.632: INFO: (7) /api/v1/namespaces/proxy-9678/services/proxy-service-9cnl9:portname2/proxy/: bar (200; 26.985491ms)
Aug  3 18:24:41.632: INFO: (7) /api/v1/namespaces/proxy-9678/pods/https:proxy-service-9cnl9-z9mds:443/proxy/: <a href="/api/v1/namespaces/proxy-9678/pods/https:proxy-service-9cnl9-z9mds:443/proxy/tlsrewritem... (200; 26.776776ms)
Aug  3 18:24:41.633: INFO: (7) /api/v1/namespaces/proxy-9678/services/http:proxy-service-9cnl9:portname2/proxy/: bar (200; 27.254902ms)
Aug  3 18:24:41.633: INFO: (7) /api/v1/namespaces/proxy-9678/services/proxy-service-9cnl9:portname1/proxy/: foo (200; 27.659309ms)
Aug  3 18:24:41.633: INFO: (7) /api/v1/namespaces/proxy-9678/services/http:proxy-service-9cnl9:portname1/proxy/: foo (200; 27.997249ms)
Aug  3 18:24:41.633: INFO: (7) /api/v1/namespaces/proxy-9678/pods/proxy-service-9cnl9-z9mds:1080/proxy/: <a href="/api/v1/namespaces/proxy-9678/pods/proxy-service-9cnl9-z9mds:1080/proxy/rewriteme">test<... (200; 27.959702ms)
Aug  3 18:24:41.634: INFO: (7) /api/v1/namespaces/proxy-9678/services/https:proxy-service-9cnl9:tlsportname2/proxy/: tls qux (200; 28.190372ms)
Aug  3 18:24:41.633: INFO: (7) /api/v1/namespaces/proxy-9678/services/https:proxy-service-9cnl9:tlsportname1/proxy/: tls baz (200; 27.776873ms)
Aug  3 18:24:41.645: INFO: (8) /api/v1/namespaces/proxy-9678/pods/http:proxy-service-9cnl9-z9mds:160/proxy/: foo (200; 11.28902ms)
Aug  3 18:24:41.645: INFO: (8) /api/v1/namespaces/proxy-9678/pods/https:proxy-service-9cnl9-z9mds:443/proxy/: <a href="/api/v1/namespaces/proxy-9678/pods/https:proxy-service-9cnl9-z9mds:443/proxy/tlsrewritem... (200; 11.501669ms)
Aug  3 18:24:41.649: INFO: (8) /api/v1/namespaces/proxy-9678/pods/proxy-service-9cnl9-z9mds:1080/proxy/: <a href="/api/v1/namespaces/proxy-9678/pods/proxy-service-9cnl9-z9mds:1080/proxy/rewriteme">test<... (200; 14.835823ms)
Aug  3 18:24:41.649: INFO: (8) /api/v1/namespaces/proxy-9678/pods/http:proxy-service-9cnl9-z9mds:1080/proxy/: <a href="/api/v1/namespaces/proxy-9678/pods/http:proxy-service-9cnl9-z9mds:1080/proxy/rewriteme">... (200; 14.989045ms)
Aug  3 18:24:41.649: INFO: (8) /api/v1/namespaces/proxy-9678/pods/https:proxy-service-9cnl9-z9mds:462/proxy/: tls qux (200; 15.024908ms)
Aug  3 18:24:41.649: INFO: (8) /api/v1/namespaces/proxy-9678/pods/proxy-service-9cnl9-z9mds:160/proxy/: foo (200; 15.010623ms)
Aug  3 18:24:41.649: INFO: (8) /api/v1/namespaces/proxy-9678/pods/proxy-service-9cnl9-z9mds:162/proxy/: bar (200; 15.000157ms)
Aug  3 18:24:41.649: INFO: (8) /api/v1/namespaces/proxy-9678/pods/http:proxy-service-9cnl9-z9mds:162/proxy/: bar (200; 15.134691ms)
Aug  3 18:24:41.649: INFO: (8) /api/v1/namespaces/proxy-9678/pods/https:proxy-service-9cnl9-z9mds:460/proxy/: tls baz (200; 15.262406ms)
Aug  3 18:24:41.649: INFO: (8) /api/v1/namespaces/proxy-9678/pods/proxy-service-9cnl9-z9mds/proxy/: <a href="/api/v1/namespaces/proxy-9678/pods/proxy-service-9cnl9-z9mds/proxy/rewriteme">test</a> (200; 15.064301ms)
Aug  3 18:24:41.651: INFO: (8) /api/v1/namespaces/proxy-9678/services/https:proxy-service-9cnl9:tlsportname2/proxy/: tls qux (200; 17.130302ms)
Aug  3 18:24:41.654: INFO: (8) /api/v1/namespaces/proxy-9678/services/https:proxy-service-9cnl9:tlsportname1/proxy/: tls baz (200; 20.516624ms)
Aug  3 18:24:41.657: INFO: (8) /api/v1/namespaces/proxy-9678/services/proxy-service-9cnl9:portname1/proxy/: foo (200; 22.479856ms)
Aug  3 18:24:41.657: INFO: (8) /api/v1/namespaces/proxy-9678/services/http:proxy-service-9cnl9:portname1/proxy/: foo (200; 22.779577ms)
Aug  3 18:24:41.657: INFO: (8) /api/v1/namespaces/proxy-9678/services/proxy-service-9cnl9:portname2/proxy/: bar (200; 22.715771ms)
Aug  3 18:24:41.657: INFO: (8) /api/v1/namespaces/proxy-9678/services/http:proxy-service-9cnl9:portname2/proxy/: bar (200; 23.272693ms)
Aug  3 18:24:41.671: INFO: (9) /api/v1/namespaces/proxy-9678/pods/https:proxy-service-9cnl9-z9mds:460/proxy/: tls baz (200; 13.660256ms)
Aug  3 18:24:41.673: INFO: (9) /api/v1/namespaces/proxy-9678/pods/http:proxy-service-9cnl9-z9mds:160/proxy/: foo (200; 15.434522ms)
Aug  3 18:24:41.673: INFO: (9) /api/v1/namespaces/proxy-9678/pods/proxy-service-9cnl9-z9mds:162/proxy/: bar (200; 15.291193ms)
Aug  3 18:24:41.673: INFO: (9) /api/v1/namespaces/proxy-9678/pods/proxy-service-9cnl9-z9mds/proxy/: <a href="/api/v1/namespaces/proxy-9678/pods/proxy-service-9cnl9-z9mds/proxy/rewriteme">test</a> (200; 15.155204ms)
Aug  3 18:24:41.673: INFO: (9) /api/v1/namespaces/proxy-9678/pods/http:proxy-service-9cnl9-z9mds:1080/proxy/: <a href="/api/v1/namespaces/proxy-9678/pods/http:proxy-service-9cnl9-z9mds:1080/proxy/rewriteme">... (200; 15.489914ms)
Aug  3 18:24:41.673: INFO: (9) /api/v1/namespaces/proxy-9678/pods/proxy-service-9cnl9-z9mds:1080/proxy/: <a href="/api/v1/namespaces/proxy-9678/pods/proxy-service-9cnl9-z9mds:1080/proxy/rewriteme">test<... (200; 15.935414ms)
Aug  3 18:24:41.674: INFO: (9) /api/v1/namespaces/proxy-9678/pods/http:proxy-service-9cnl9-z9mds:162/proxy/: bar (200; 16.008408ms)
Aug  3 18:24:41.674: INFO: (9) /api/v1/namespaces/proxy-9678/pods/https:proxy-service-9cnl9-z9mds:462/proxy/: tls qux (200; 15.989391ms)
Aug  3 18:24:41.674: INFO: (9) /api/v1/namespaces/proxy-9678/pods/https:proxy-service-9cnl9-z9mds:443/proxy/: <a href="/api/v1/namespaces/proxy-9678/pods/https:proxy-service-9cnl9-z9mds:443/proxy/tlsrewritem... (200; 15.753603ms)
Aug  3 18:24:41.674: INFO: (9) /api/v1/namespaces/proxy-9678/pods/proxy-service-9cnl9-z9mds:160/proxy/: foo (200; 15.998195ms)
Aug  3 18:24:41.676: INFO: (9) /api/v1/namespaces/proxy-9678/services/http:proxy-service-9cnl9:portname2/proxy/: bar (200; 18.850367ms)
Aug  3 18:24:41.681: INFO: (9) /api/v1/namespaces/proxy-9678/services/http:proxy-service-9cnl9:portname1/proxy/: foo (200; 23.518021ms)
Aug  3 18:24:41.683: INFO: (9) /api/v1/namespaces/proxy-9678/services/https:proxy-service-9cnl9:tlsportname2/proxy/: tls qux (200; 25.4405ms)
Aug  3 18:24:41.683: INFO: (9) /api/v1/namespaces/proxy-9678/services/https:proxy-service-9cnl9:tlsportname1/proxy/: tls baz (200; 24.84793ms)
Aug  3 18:24:41.683: INFO: (9) /api/v1/namespaces/proxy-9678/services/proxy-service-9cnl9:portname2/proxy/: bar (200; 24.944895ms)
Aug  3 18:24:41.683: INFO: (9) /api/v1/namespaces/proxy-9678/services/proxy-service-9cnl9:portname1/proxy/: foo (200; 25.456122ms)
Aug  3 18:24:41.714: INFO: (10) /api/v1/namespaces/proxy-9678/pods/proxy-service-9cnl9-z9mds:1080/proxy/: <a href="/api/v1/namespaces/proxy-9678/pods/proxy-service-9cnl9-z9mds:1080/proxy/rewriteme">test<... (200; 30.377211ms)
Aug  3 18:24:41.714: INFO: (10) /api/v1/namespaces/proxy-9678/pods/http:proxy-service-9cnl9-z9mds:160/proxy/: foo (200; 30.241862ms)
Aug  3 18:24:41.714: INFO: (10) /api/v1/namespaces/proxy-9678/pods/proxy-service-9cnl9-z9mds/proxy/: <a href="/api/v1/namespaces/proxy-9678/pods/proxy-service-9cnl9-z9mds/proxy/rewriteme">test</a> (200; 29.480321ms)
Aug  3 18:24:41.714: INFO: (10) /api/v1/namespaces/proxy-9678/pods/http:proxy-service-9cnl9-z9mds:1080/proxy/: <a href="/api/v1/namespaces/proxy-9678/pods/http:proxy-service-9cnl9-z9mds:1080/proxy/rewriteme">... (200; 30.069281ms)
Aug  3 18:24:41.715: INFO: (10) /api/v1/namespaces/proxy-9678/pods/http:proxy-service-9cnl9-z9mds:162/proxy/: bar (200; 31.110088ms)
Aug  3 18:24:41.715: INFO: (10) /api/v1/namespaces/proxy-9678/services/https:proxy-service-9cnl9:tlsportname2/proxy/: tls qux (200; 31.473302ms)
Aug  3 18:24:41.715: INFO: (10) /api/v1/namespaces/proxy-9678/pods/https:proxy-service-9cnl9-z9mds:462/proxy/: tls qux (200; 31.071594ms)
Aug  3 18:24:41.715: INFO: (10) /api/v1/namespaces/proxy-9678/services/https:proxy-service-9cnl9:tlsportname1/proxy/: tls baz (200; 30.531732ms)
Aug  3 18:24:41.715: INFO: (10) /api/v1/namespaces/proxy-9678/pods/https:proxy-service-9cnl9-z9mds:460/proxy/: tls baz (200; 31.741034ms)
Aug  3 18:24:41.715: INFO: (10) /api/v1/namespaces/proxy-9678/pods/https:proxy-service-9cnl9-z9mds:443/proxy/: <a href="/api/v1/namespaces/proxy-9678/pods/https:proxy-service-9cnl9-z9mds:443/proxy/tlsrewritem... (200; 30.703488ms)
Aug  3 18:24:41.715: INFO: (10) /api/v1/namespaces/proxy-9678/pods/proxy-service-9cnl9-z9mds:162/proxy/: bar (200; 30.791817ms)
Aug  3 18:24:41.715: INFO: (10) /api/v1/namespaces/proxy-9678/pods/proxy-service-9cnl9-z9mds:160/proxy/: foo (200; 31.305876ms)
Aug  3 18:24:41.717: INFO: (10) /api/v1/namespaces/proxy-9678/services/proxy-service-9cnl9:portname2/proxy/: bar (200; 32.913043ms)
Aug  3 18:24:41.717: INFO: (10) /api/v1/namespaces/proxy-9678/services/http:proxy-service-9cnl9:portname1/proxy/: foo (200; 33.717191ms)
Aug  3 18:24:41.718: INFO: (10) /api/v1/namespaces/proxy-9678/services/http:proxy-service-9cnl9:portname2/proxy/: bar (200; 34.828482ms)
Aug  3 18:24:41.718: INFO: (10) /api/v1/namespaces/proxy-9678/services/proxy-service-9cnl9:portname1/proxy/: foo (200; 34.59239ms)
Aug  3 18:24:41.731: INFO: (11) /api/v1/namespaces/proxy-9678/pods/proxy-service-9cnl9-z9mds:1080/proxy/: <a href="/api/v1/namespaces/proxy-9678/pods/proxy-service-9cnl9-z9mds:1080/proxy/rewriteme">test<... (200; 11.943413ms)
Aug  3 18:24:41.731: INFO: (11) /api/v1/namespaces/proxy-9678/pods/proxy-service-9cnl9-z9mds:162/proxy/: bar (200; 11.587911ms)
Aug  3 18:24:41.745: INFO: (11) /api/v1/namespaces/proxy-9678/pods/proxy-service-9cnl9-z9mds/proxy/: <a href="/api/v1/namespaces/proxy-9678/pods/proxy-service-9cnl9-z9mds/proxy/rewriteme">test</a> (200; 25.780231ms)
Aug  3 18:24:41.745: INFO: (11) /api/v1/namespaces/proxy-9678/pods/http:proxy-service-9cnl9-z9mds:1080/proxy/: <a href="/api/v1/namespaces/proxy-9678/pods/http:proxy-service-9cnl9-z9mds:1080/proxy/rewriteme">... (200; 26.180246ms)
Aug  3 18:24:41.745: INFO: (11) /api/v1/namespaces/proxy-9678/pods/http:proxy-service-9cnl9-z9mds:162/proxy/: bar (200; 26.352326ms)
Aug  3 18:24:41.745: INFO: (11) /api/v1/namespaces/proxy-9678/pods/https:proxy-service-9cnl9-z9mds:460/proxy/: tls baz (200; 26.768187ms)
Aug  3 18:24:41.745: INFO: (11) /api/v1/namespaces/proxy-9678/pods/https:proxy-service-9cnl9-z9mds:462/proxy/: tls qux (200; 26.334849ms)
Aug  3 18:24:41.745: INFO: (11) /api/v1/namespaces/proxy-9678/pods/https:proxy-service-9cnl9-z9mds:443/proxy/: <a href="/api/v1/namespaces/proxy-9678/pods/https:proxy-service-9cnl9-z9mds:443/proxy/tlsrewritem... (200; 26.260229ms)
Aug  3 18:24:41.750: INFO: (11) /api/v1/namespaces/proxy-9678/pods/proxy-service-9cnl9-z9mds:160/proxy/: foo (200; 30.868454ms)
Aug  3 18:24:41.750: INFO: (11) /api/v1/namespaces/proxy-9678/services/https:proxy-service-9cnl9:tlsportname1/proxy/: tls baz (200; 31.238088ms)
Aug  3 18:24:41.751: INFO: (11) /api/v1/namespaces/proxy-9678/services/http:proxy-service-9cnl9:portname2/proxy/: bar (200; 31.992095ms)
Aug  3 18:24:41.751: INFO: (11) /api/v1/namespaces/proxy-9678/services/https:proxy-service-9cnl9:tlsportname2/proxy/: tls qux (200; 32.128057ms)
Aug  3 18:24:41.751: INFO: (11) /api/v1/namespaces/proxy-9678/pods/http:proxy-service-9cnl9-z9mds:160/proxy/: foo (200; 32.059153ms)
Aug  3 18:24:41.752: INFO: (11) /api/v1/namespaces/proxy-9678/services/proxy-service-9cnl9:portname2/proxy/: bar (200; 32.478404ms)
Aug  3 18:24:41.756: INFO: (11) /api/v1/namespaces/proxy-9678/services/proxy-service-9cnl9:portname1/proxy/: foo (200; 37.120124ms)
Aug  3 18:24:41.756: INFO: (11) /api/v1/namespaces/proxy-9678/services/http:proxy-service-9cnl9:portname1/proxy/: foo (200; 37.644737ms)
Aug  3 18:24:41.769: INFO: (12) /api/v1/namespaces/proxy-9678/pods/https:proxy-service-9cnl9-z9mds:443/proxy/: <a href="/api/v1/namespaces/proxy-9678/pods/https:proxy-service-9cnl9-z9mds:443/proxy/tlsrewritem... (200; 11.986022ms)
Aug  3 18:24:41.771: INFO: (12) /api/v1/namespaces/proxy-9678/pods/http:proxy-service-9cnl9-z9mds:1080/proxy/: <a href="/api/v1/namespaces/proxy-9678/pods/http:proxy-service-9cnl9-z9mds:1080/proxy/rewriteme">... (200; 14.512117ms)
Aug  3 18:24:41.771: INFO: (12) /api/v1/namespaces/proxy-9678/pods/proxy-service-9cnl9-z9mds:162/proxy/: bar (200; 14.570009ms)
Aug  3 18:24:41.772: INFO: (12) /api/v1/namespaces/proxy-9678/pods/https:proxy-service-9cnl9-z9mds:460/proxy/: tls baz (200; 15.845938ms)
Aug  3 18:24:41.772: INFO: (12) /api/v1/namespaces/proxy-9678/pods/proxy-service-9cnl9-z9mds/proxy/: <a href="/api/v1/namespaces/proxy-9678/pods/proxy-service-9cnl9-z9mds/proxy/rewriteme">test</a> (200; 15.64096ms)
Aug  3 18:24:41.772: INFO: (12) /api/v1/namespaces/proxy-9678/pods/http:proxy-service-9cnl9-z9mds:160/proxy/: foo (200; 15.56526ms)
Aug  3 18:24:41.772: INFO: (12) /api/v1/namespaces/proxy-9678/pods/https:proxy-service-9cnl9-z9mds:462/proxy/: tls qux (200; 15.567892ms)
Aug  3 18:24:41.772: INFO: (12) /api/v1/namespaces/proxy-9678/pods/proxy-service-9cnl9-z9mds:1080/proxy/: <a href="/api/v1/namespaces/proxy-9678/pods/proxy-service-9cnl9-z9mds:1080/proxy/rewriteme">test<... (200; 15.58523ms)
Aug  3 18:24:41.772: INFO: (12) /api/v1/namespaces/proxy-9678/pods/proxy-service-9cnl9-z9mds:160/proxy/: foo (200; 15.831854ms)
Aug  3 18:24:41.773: INFO: (12) /api/v1/namespaces/proxy-9678/pods/http:proxy-service-9cnl9-z9mds:162/proxy/: bar (200; 15.896648ms)
Aug  3 18:24:41.774: INFO: (12) /api/v1/namespaces/proxy-9678/services/proxy-service-9cnl9:portname2/proxy/: bar (200; 17.613653ms)
Aug  3 18:24:41.775: INFO: (12) /api/v1/namespaces/proxy-9678/services/http:proxy-service-9cnl9:portname1/proxy/: foo (200; 18.519808ms)
Aug  3 18:24:41.779: INFO: (12) /api/v1/namespaces/proxy-9678/services/https:proxy-service-9cnl9:tlsportname2/proxy/: tls qux (200; 22.293035ms)
Aug  3 18:24:41.780: INFO: (12) /api/v1/namespaces/proxy-9678/services/proxy-service-9cnl9:portname1/proxy/: foo (200; 23.774674ms)
Aug  3 18:24:41.782: INFO: (12) /api/v1/namespaces/proxy-9678/services/https:proxy-service-9cnl9:tlsportname1/proxy/: tls baz (200; 25.80155ms)
Aug  3 18:24:41.783: INFO: (12) /api/v1/namespaces/proxy-9678/services/http:proxy-service-9cnl9:portname2/proxy/: bar (200; 25.855493ms)
Aug  3 18:24:41.793: INFO: (13) /api/v1/namespaces/proxy-9678/pods/proxy-service-9cnl9-z9mds:1080/proxy/: <a href="/api/v1/namespaces/proxy-9678/pods/proxy-service-9cnl9-z9mds:1080/proxy/rewriteme">test<... (200; 10.759901ms)
Aug  3 18:24:41.796: INFO: (13) /api/v1/namespaces/proxy-9678/pods/http:proxy-service-9cnl9-z9mds:162/proxy/: bar (200; 12.665421ms)
Aug  3 18:24:41.796: INFO: (13) /api/v1/namespaces/proxy-9678/pods/proxy-service-9cnl9-z9mds:162/proxy/: bar (200; 12.40699ms)
Aug  3 18:24:41.796: INFO: (13) /api/v1/namespaces/proxy-9678/pods/http:proxy-service-9cnl9-z9mds:160/proxy/: foo (200; 13.06142ms)
Aug  3 18:24:41.796: INFO: (13) /api/v1/namespaces/proxy-9678/pods/https:proxy-service-9cnl9-z9mds:443/proxy/: <a href="/api/v1/namespaces/proxy-9678/pods/https:proxy-service-9cnl9-z9mds:443/proxy/tlsrewritem... (200; 12.723116ms)
Aug  3 18:24:41.797: INFO: (13) /api/v1/namespaces/proxy-9678/pods/http:proxy-service-9cnl9-z9mds:1080/proxy/: <a href="/api/v1/namespaces/proxy-9678/pods/http:proxy-service-9cnl9-z9mds:1080/proxy/rewriteme">... (200; 14.41485ms)
Aug  3 18:24:41.798: INFO: (13) /api/v1/namespaces/proxy-9678/pods/https:proxy-service-9cnl9-z9mds:462/proxy/: tls qux (200; 14.595417ms)
Aug  3 18:24:41.798: INFO: (13) /api/v1/namespaces/proxy-9678/pods/proxy-service-9cnl9-z9mds:160/proxy/: foo (200; 15.124867ms)
Aug  3 18:24:41.798: INFO: (13) /api/v1/namespaces/proxy-9678/pods/proxy-service-9cnl9-z9mds/proxy/: <a href="/api/v1/namespaces/proxy-9678/pods/proxy-service-9cnl9-z9mds/proxy/rewriteme">test</a> (200; 14.880189ms)
Aug  3 18:24:41.799: INFO: (13) /api/v1/namespaces/proxy-9678/pods/https:proxy-service-9cnl9-z9mds:460/proxy/: tls baz (200; 15.567445ms)
Aug  3 18:24:41.805: INFO: (13) /api/v1/namespaces/proxy-9678/services/http:proxy-service-9cnl9:portname1/proxy/: foo (200; 22.449601ms)
Aug  3 18:24:41.810: INFO: (13) /api/v1/namespaces/proxy-9678/services/proxy-service-9cnl9:portname1/proxy/: foo (200; 26.498485ms)
Aug  3 18:24:41.812: INFO: (13) /api/v1/namespaces/proxy-9678/services/https:proxy-service-9cnl9:tlsportname2/proxy/: tls qux (200; 27.999988ms)
Aug  3 18:24:41.812: INFO: (13) /api/v1/namespaces/proxy-9678/services/proxy-service-9cnl9:portname2/proxy/: bar (200; 28.29359ms)
Aug  3 18:24:41.812: INFO: (13) /api/v1/namespaces/proxy-9678/services/https:proxy-service-9cnl9:tlsportname1/proxy/: tls baz (200; 28.264513ms)
Aug  3 18:24:41.812: INFO: (13) /api/v1/namespaces/proxy-9678/services/http:proxy-service-9cnl9:portname2/proxy/: bar (200; 28.138916ms)
Aug  3 18:24:41.829: INFO: (14) /api/v1/namespaces/proxy-9678/pods/http:proxy-service-9cnl9-z9mds:160/proxy/: foo (200; 17.133815ms)
Aug  3 18:24:41.829: INFO: (14) /api/v1/namespaces/proxy-9678/pods/proxy-service-9cnl9-z9mds/proxy/: <a href="/api/v1/namespaces/proxy-9678/pods/proxy-service-9cnl9-z9mds/proxy/rewriteme">test</a> (200; 17.114508ms)
Aug  3 18:24:41.829: INFO: (14) /api/v1/namespaces/proxy-9678/services/proxy-service-9cnl9:portname2/proxy/: bar (200; 17.192012ms)
Aug  3 18:24:41.829: INFO: (14) /api/v1/namespaces/proxy-9678/pods/https:proxy-service-9cnl9-z9mds:462/proxy/: tls qux (200; 17.296116ms)
Aug  3 18:24:41.829: INFO: (14) /api/v1/namespaces/proxy-9678/pods/https:proxy-service-9cnl9-z9mds:443/proxy/: <a href="/api/v1/namespaces/proxy-9678/pods/https:proxy-service-9cnl9-z9mds:443/proxy/tlsrewritem... (200; 17.354029ms)
Aug  3 18:24:41.829: INFO: (14) /api/v1/namespaces/proxy-9678/pods/http:proxy-service-9cnl9-z9mds:162/proxy/: bar (200; 17.18677ms)
Aug  3 18:24:41.829: INFO: (14) /api/v1/namespaces/proxy-9678/pods/proxy-service-9cnl9-z9mds:1080/proxy/: <a href="/api/v1/namespaces/proxy-9678/pods/proxy-service-9cnl9-z9mds:1080/proxy/rewriteme">test<... (200; 17.450915ms)
Aug  3 18:24:41.833: INFO: (14) /api/v1/namespaces/proxy-9678/services/https:proxy-service-9cnl9:tlsportname2/proxy/: tls qux (200; 21.117556ms)
Aug  3 18:24:41.834: INFO: (14) /api/v1/namespaces/proxy-9678/services/http:proxy-service-9cnl9:portname1/proxy/: foo (200; 21.762484ms)
Aug  3 18:24:41.834: INFO: (14) /api/v1/namespaces/proxy-9678/services/https:proxy-service-9cnl9:tlsportname1/proxy/: tls baz (200; 22.313317ms)
Aug  3 18:24:41.841: INFO: (14) /api/v1/namespaces/proxy-9678/pods/https:proxy-service-9cnl9-z9mds:460/proxy/: tls baz (200; 28.909559ms)
Aug  3 18:24:41.842: INFO: (14) /api/v1/namespaces/proxy-9678/pods/proxy-service-9cnl9-z9mds:160/proxy/: foo (200; 29.836971ms)
Aug  3 18:24:41.842: INFO: (14) /api/v1/namespaces/proxy-9678/pods/proxy-service-9cnl9-z9mds:162/proxy/: bar (200; 30.197738ms)
Aug  3 18:24:41.842: INFO: (14) /api/v1/namespaces/proxy-9678/pods/http:proxy-service-9cnl9-z9mds:1080/proxy/: <a href="/api/v1/namespaces/proxy-9678/pods/http:proxy-service-9cnl9-z9mds:1080/proxy/rewriteme">... (200; 30.398375ms)
Aug  3 18:24:41.846: INFO: (14) /api/v1/namespaces/proxy-9678/services/http:proxy-service-9cnl9:portname2/proxy/: bar (200; 34.59432ms)
Aug  3 18:24:41.850: INFO: (14) /api/v1/namespaces/proxy-9678/services/proxy-service-9cnl9:portname1/proxy/: foo (200; 37.848326ms)
Aug  3 18:24:41.862: INFO: (15) /api/v1/namespaces/proxy-9678/pods/proxy-service-9cnl9-z9mds:1080/proxy/: <a href="/api/v1/namespaces/proxy-9678/pods/proxy-service-9cnl9-z9mds:1080/proxy/rewriteme">test<... (200; 11.289321ms)
Aug  3 18:24:41.865: INFO: (15) /api/v1/namespaces/proxy-9678/pods/https:proxy-service-9cnl9-z9mds:460/proxy/: tls baz (200; 15.010002ms)
Aug  3 18:24:41.865: INFO: (15) /api/v1/namespaces/proxy-9678/pods/proxy-service-9cnl9-z9mds/proxy/: <a href="/api/v1/namespaces/proxy-9678/pods/proxy-service-9cnl9-z9mds/proxy/rewriteme">test</a> (200; 14.808934ms)
Aug  3 18:24:41.865: INFO: (15) /api/v1/namespaces/proxy-9678/pods/proxy-service-9cnl9-z9mds:160/proxy/: foo (200; 14.820776ms)
Aug  3 18:24:41.865: INFO: (15) /api/v1/namespaces/proxy-9678/pods/http:proxy-service-9cnl9-z9mds:162/proxy/: bar (200; 15.059874ms)
Aug  3 18:24:41.865: INFO: (15) /api/v1/namespaces/proxy-9678/pods/http:proxy-service-9cnl9-z9mds:160/proxy/: foo (200; 15.352737ms)
Aug  3 18:24:41.866: INFO: (15) /api/v1/namespaces/proxy-9678/pods/https:proxy-service-9cnl9-z9mds:462/proxy/: tls qux (200; 15.466787ms)
Aug  3 18:24:41.866: INFO: (15) /api/v1/namespaces/proxy-9678/pods/https:proxy-service-9cnl9-z9mds:443/proxy/: <a href="/api/v1/namespaces/proxy-9678/pods/https:proxy-service-9cnl9-z9mds:443/proxy/tlsrewritem... (200; 15.473275ms)
Aug  3 18:24:41.866: INFO: (15) /api/v1/namespaces/proxy-9678/pods/proxy-service-9cnl9-z9mds:162/proxy/: bar (200; 15.739884ms)
Aug  3 18:24:41.866: INFO: (15) /api/v1/namespaces/proxy-9678/pods/http:proxy-service-9cnl9-z9mds:1080/proxy/: <a href="/api/v1/namespaces/proxy-9678/pods/http:proxy-service-9cnl9-z9mds:1080/proxy/rewriteme">... (200; 15.853545ms)
Aug  3 18:24:41.869: INFO: (15) /api/v1/namespaces/proxy-9678/services/proxy-service-9cnl9:portname2/proxy/: bar (200; 18.533511ms)
Aug  3 18:24:41.869: INFO: (15) /api/v1/namespaces/proxy-9678/services/proxy-service-9cnl9:portname1/proxy/: foo (200; 18.681308ms)
Aug  3 18:24:41.871: INFO: (15) /api/v1/namespaces/proxy-9678/services/http:proxy-service-9cnl9:portname2/proxy/: bar (200; 20.500072ms)
Aug  3 18:24:41.871: INFO: (15) /api/v1/namespaces/proxy-9678/services/http:proxy-service-9cnl9:portname1/proxy/: foo (200; 20.957929ms)
Aug  3 18:24:41.871: INFO: (15) /api/v1/namespaces/proxy-9678/services/https:proxy-service-9cnl9:tlsportname2/proxy/: tls qux (200; 20.888458ms)
Aug  3 18:24:41.871: INFO: (15) /api/v1/namespaces/proxy-9678/services/https:proxy-service-9cnl9:tlsportname1/proxy/: tls baz (200; 20.980065ms)
Aug  3 18:24:41.890: INFO: (16) /api/v1/namespaces/proxy-9678/pods/proxy-service-9cnl9-z9mds:160/proxy/: foo (200; 18.247314ms)
Aug  3 18:24:41.890: INFO: (16) /api/v1/namespaces/proxy-9678/pods/https:proxy-service-9cnl9-z9mds:443/proxy/: <a href="/api/v1/namespaces/proxy-9678/pods/https:proxy-service-9cnl9-z9mds:443/proxy/tlsrewritem... (200; 18.500523ms)
Aug  3 18:24:41.890: INFO: (16) /api/v1/namespaces/proxy-9678/pods/https:proxy-service-9cnl9-z9mds:462/proxy/: tls qux (200; 18.350237ms)
Aug  3 18:24:41.890: INFO: (16) /api/v1/namespaces/proxy-9678/pods/http:proxy-service-9cnl9-z9mds:162/proxy/: bar (200; 18.393751ms)
Aug  3 18:24:41.890: INFO: (16) /api/v1/namespaces/proxy-9678/pods/http:proxy-service-9cnl9-z9mds:160/proxy/: foo (200; 18.398638ms)
Aug  3 18:24:41.890: INFO: (16) /api/v1/namespaces/proxy-9678/pods/proxy-service-9cnl9-z9mds:162/proxy/: bar (200; 18.586059ms)
Aug  3 18:24:41.890: INFO: (16) /api/v1/namespaces/proxy-9678/pods/proxy-service-9cnl9-z9mds:1080/proxy/: <a href="/api/v1/namespaces/proxy-9678/pods/proxy-service-9cnl9-z9mds:1080/proxy/rewriteme">test<... (200; 18.682637ms)
Aug  3 18:24:41.890: INFO: (16) /api/v1/namespaces/proxy-9678/pods/proxy-service-9cnl9-z9mds/proxy/: <a href="/api/v1/namespaces/proxy-9678/pods/proxy-service-9cnl9-z9mds/proxy/rewriteme">test</a> (200; 18.650676ms)
Aug  3 18:24:41.890: INFO: (16) /api/v1/namespaces/proxy-9678/pods/http:proxy-service-9cnl9-z9mds:1080/proxy/: <a href="/api/v1/namespaces/proxy-9678/pods/http:proxy-service-9cnl9-z9mds:1080/proxy/rewriteme">... (200; 18.916598ms)
Aug  3 18:24:41.891: INFO: (16) /api/v1/namespaces/proxy-9678/pods/https:proxy-service-9cnl9-z9mds:460/proxy/: tls baz (200; 19.770298ms)
Aug  3 18:24:41.894: INFO: (16) /api/v1/namespaces/proxy-9678/services/http:proxy-service-9cnl9:portname1/proxy/: foo (200; 22.587645ms)
Aug  3 18:24:41.894: INFO: (16) /api/v1/namespaces/proxy-9678/services/https:proxy-service-9cnl9:tlsportname1/proxy/: tls baz (200; 22.970482ms)
Aug  3 18:24:41.895: INFO: (16) /api/v1/namespaces/proxy-9678/services/http:proxy-service-9cnl9:portname2/proxy/: bar (200; 23.913283ms)
Aug  3 18:24:41.896: INFO: (16) /api/v1/namespaces/proxy-9678/services/proxy-service-9cnl9:portname2/proxy/: bar (200; 24.464646ms)
Aug  3 18:24:41.896: INFO: (16) /api/v1/namespaces/proxy-9678/services/proxy-service-9cnl9:portname1/proxy/: foo (200; 24.574838ms)
Aug  3 18:24:41.897: INFO: (16) /api/v1/namespaces/proxy-9678/services/https:proxy-service-9cnl9:tlsportname2/proxy/: tls qux (200; 25.894902ms)
Aug  3 18:24:41.909: INFO: (17) /api/v1/namespaces/proxy-9678/pods/https:proxy-service-9cnl9-z9mds:443/proxy/: <a href="/api/v1/namespaces/proxy-9678/pods/https:proxy-service-9cnl9-z9mds:443/proxy/tlsrewritem... (200; 11.590636ms)
Aug  3 18:24:41.913: INFO: (17) /api/v1/namespaces/proxy-9678/pods/https:proxy-service-9cnl9-z9mds:462/proxy/: tls qux (200; 14.884625ms)
Aug  3 18:24:41.914: INFO: (17) /api/v1/namespaces/proxy-9678/pods/http:proxy-service-9cnl9-z9mds:160/proxy/: foo (200; 16.638848ms)
Aug  3 18:24:41.914: INFO: (17) /api/v1/namespaces/proxy-9678/pods/http:proxy-service-9cnl9-z9mds:1080/proxy/: <a href="/api/v1/namespaces/proxy-9678/pods/http:proxy-service-9cnl9-z9mds:1080/proxy/rewriteme">... (200; 16.531464ms)
Aug  3 18:24:41.915: INFO: (17) /api/v1/namespaces/proxy-9678/pods/proxy-service-9cnl9-z9mds:162/proxy/: bar (200; 16.821517ms)
Aug  3 18:24:41.915: INFO: (17) /api/v1/namespaces/proxy-9678/pods/https:proxy-service-9cnl9-z9mds:460/proxy/: tls baz (200; 17.094294ms)
Aug  3 18:24:41.915: INFO: (17) /api/v1/namespaces/proxy-9678/pods/proxy-service-9cnl9-z9mds/proxy/: <a href="/api/v1/namespaces/proxy-9678/pods/proxy-service-9cnl9-z9mds/proxy/rewriteme">test</a> (200; 16.947639ms)
Aug  3 18:24:41.915: INFO: (17) /api/v1/namespaces/proxy-9678/pods/proxy-service-9cnl9-z9mds:1080/proxy/: <a href="/api/v1/namespaces/proxy-9678/pods/proxy-service-9cnl9-z9mds:1080/proxy/rewriteme">test<... (200; 16.849113ms)
Aug  3 18:24:41.915: INFO: (17) /api/v1/namespaces/proxy-9678/pods/http:proxy-service-9cnl9-z9mds:162/proxy/: bar (200; 17.008203ms)
Aug  3 18:24:41.915: INFO: (17) /api/v1/namespaces/proxy-9678/pods/proxy-service-9cnl9-z9mds:160/proxy/: foo (200; 16.93776ms)
Aug  3 18:24:41.920: INFO: (17) /api/v1/namespaces/proxy-9678/services/proxy-service-9cnl9:portname1/proxy/: foo (200; 22.007926ms)
Aug  3 18:24:41.920: INFO: (17) /api/v1/namespaces/proxy-9678/services/proxy-service-9cnl9:portname2/proxy/: bar (200; 22.370059ms)
Aug  3 18:24:41.920: INFO: (17) /api/v1/namespaces/proxy-9678/services/http:proxy-service-9cnl9:portname1/proxy/: foo (200; 22.799ms)
Aug  3 18:24:41.923: INFO: (17) /api/v1/namespaces/proxy-9678/services/http:proxy-service-9cnl9:portname2/proxy/: bar (200; 25.315101ms)
Aug  3 18:24:41.925: INFO: (17) /api/v1/namespaces/proxy-9678/services/https:proxy-service-9cnl9:tlsportname2/proxy/: tls qux (200; 27.568133ms)
Aug  3 18:24:41.926: INFO: (17) /api/v1/namespaces/proxy-9678/services/https:proxy-service-9cnl9:tlsportname1/proxy/: tls baz (200; 28.467008ms)
Aug  3 18:24:41.945: INFO: (18) /api/v1/namespaces/proxy-9678/pods/proxy-service-9cnl9-z9mds:1080/proxy/: <a href="/api/v1/namespaces/proxy-9678/pods/proxy-service-9cnl9-z9mds:1080/proxy/rewriteme">test<... (200; 18.334482ms)
Aug  3 18:24:41.946: INFO: (18) /api/v1/namespaces/proxy-9678/pods/https:proxy-service-9cnl9-z9mds:443/proxy/: <a href="/api/v1/namespaces/proxy-9678/pods/https:proxy-service-9cnl9-z9mds:443/proxy/tlsrewritem... (200; 19.375194ms)
Aug  3 18:24:41.948: INFO: (18) /api/v1/namespaces/proxy-9678/pods/proxy-service-9cnl9-z9mds:162/proxy/: bar (200; 21.352483ms)
Aug  3 18:24:41.948: INFO: (18) /api/v1/namespaces/proxy-9678/pods/proxy-service-9cnl9-z9mds:160/proxy/: foo (200; 21.678549ms)
Aug  3 18:24:41.949: INFO: (18) /api/v1/namespaces/proxy-9678/pods/http:proxy-service-9cnl9-z9mds:162/proxy/: bar (200; 22.049128ms)
Aug  3 18:24:41.949: INFO: (18) /api/v1/namespaces/proxy-9678/pods/http:proxy-service-9cnl9-z9mds:160/proxy/: foo (200; 22.007571ms)
Aug  3 18:24:41.949: INFO: (18) /api/v1/namespaces/proxy-9678/pods/https:proxy-service-9cnl9-z9mds:462/proxy/: tls qux (200; 22.092992ms)
Aug  3 18:24:41.949: INFO: (18) /api/v1/namespaces/proxy-9678/pods/https:proxy-service-9cnl9-z9mds:460/proxy/: tls baz (200; 21.850269ms)
Aug  3 18:24:41.949: INFO: (18) /api/v1/namespaces/proxy-9678/pods/http:proxy-service-9cnl9-z9mds:1080/proxy/: <a href="/api/v1/namespaces/proxy-9678/pods/http:proxy-service-9cnl9-z9mds:1080/proxy/rewriteme">... (200; 22.319414ms)
Aug  3 18:24:41.949: INFO: (18) /api/v1/namespaces/proxy-9678/pods/proxy-service-9cnl9-z9mds/proxy/: <a href="/api/v1/namespaces/proxy-9678/pods/proxy-service-9cnl9-z9mds/proxy/rewriteme">test</a> (200; 22.319016ms)
Aug  3 18:24:41.953: INFO: (18) /api/v1/namespaces/proxy-9678/services/http:proxy-service-9cnl9:portname1/proxy/: foo (200; 27.065368ms)
Aug  3 18:24:41.953: INFO: (18) /api/v1/namespaces/proxy-9678/services/http:proxy-service-9cnl9:portname2/proxy/: bar (200; 26.946555ms)
Aug  3 18:24:41.955: INFO: (18) /api/v1/namespaces/proxy-9678/services/https:proxy-service-9cnl9:tlsportname2/proxy/: tls qux (200; 28.581035ms)
Aug  3 18:24:41.955: INFO: (18) /api/v1/namespaces/proxy-9678/services/proxy-service-9cnl9:portname1/proxy/: foo (200; 28.522217ms)
Aug  3 18:24:41.957: INFO: (18) /api/v1/namespaces/proxy-9678/services/proxy-service-9cnl9:portname2/proxy/: bar (200; 30.589775ms)
Aug  3 18:24:41.968: INFO: (18) /api/v1/namespaces/proxy-9678/services/https:proxy-service-9cnl9:tlsportname1/proxy/: tls baz (200; 41.428726ms)
Aug  3 18:24:41.982: INFO: (19) /api/v1/namespaces/proxy-9678/pods/http:proxy-service-9cnl9-z9mds:162/proxy/: bar (200; 13.460144ms)
Aug  3 18:24:41.984: INFO: (19) /api/v1/namespaces/proxy-9678/pods/proxy-service-9cnl9-z9mds:1080/proxy/: <a href="/api/v1/namespaces/proxy-9678/pods/proxy-service-9cnl9-z9mds:1080/proxy/rewriteme">test<... (200; 15.527357ms)
Aug  3 18:24:41.984: INFO: (19) /api/v1/namespaces/proxy-9678/pods/https:proxy-service-9cnl9-z9mds:462/proxy/: tls qux (200; 15.738163ms)
Aug  3 18:24:41.984: INFO: (19) /api/v1/namespaces/proxy-9678/pods/proxy-service-9cnl9-z9mds:162/proxy/: bar (200; 15.607595ms)
Aug  3 18:24:41.984: INFO: (19) /api/v1/namespaces/proxy-9678/pods/proxy-service-9cnl9-z9mds:160/proxy/: foo (200; 15.651175ms)
Aug  3 18:24:41.984: INFO: (19) /api/v1/namespaces/proxy-9678/pods/https:proxy-service-9cnl9-z9mds:443/proxy/: <a href="/api/v1/namespaces/proxy-9678/pods/https:proxy-service-9cnl9-z9mds:443/proxy/tlsrewritem... (200; 15.708942ms)
Aug  3 18:24:41.984: INFO: (19) /api/v1/namespaces/proxy-9678/pods/proxy-service-9cnl9-z9mds/proxy/: <a href="/api/v1/namespaces/proxy-9678/pods/proxy-service-9cnl9-z9mds/proxy/rewriteme">test</a> (200; 15.654205ms)
Aug  3 18:24:41.984: INFO: (19) /api/v1/namespaces/proxy-9678/pods/https:proxy-service-9cnl9-z9mds:460/proxy/: tls baz (200; 15.927571ms)
Aug  3 18:24:41.984: INFO: (19) /api/v1/namespaces/proxy-9678/pods/http:proxy-service-9cnl9-z9mds:1080/proxy/: <a href="/api/v1/namespaces/proxy-9678/pods/http:proxy-service-9cnl9-z9mds:1080/proxy/rewriteme">... (200; 15.829956ms)
Aug  3 18:24:41.986: INFO: (19) /api/v1/namespaces/proxy-9678/pods/http:proxy-service-9cnl9-z9mds:160/proxy/: foo (200; 17.346599ms)
Aug  3 18:24:41.991: INFO: (19) /api/v1/namespaces/proxy-9678/services/proxy-service-9cnl9:portname2/proxy/: bar (200; 22.820571ms)
Aug  3 18:24:41.991: INFO: (19) /api/v1/namespaces/proxy-9678/services/proxy-service-9cnl9:portname1/proxy/: foo (200; 22.972095ms)
Aug  3 18:24:41.996: INFO: (19) /api/v1/namespaces/proxy-9678/services/http:proxy-service-9cnl9:portname2/proxy/: bar (200; 27.558298ms)
Aug  3 18:24:41.996: INFO: (19) /api/v1/namespaces/proxy-9678/services/https:proxy-service-9cnl9:tlsportname2/proxy/: tls qux (200; 27.654145ms)
Aug  3 18:24:41.996: INFO: (19) /api/v1/namespaces/proxy-9678/services/https:proxy-service-9cnl9:tlsportname1/proxy/: tls baz (200; 27.724234ms)
Aug  3 18:24:41.996: INFO: (19) /api/v1/namespaces/proxy-9678/services/http:proxy-service-9cnl9:portname1/proxy/: foo (200; 27.857845ms)
STEP: deleting ReplicationController proxy-service-9cnl9 in namespace proxy-9678, will wait for the garbage collector to delete the pods
Aug  3 18:24:42.078: INFO: Deleting ReplicationController proxy-service-9cnl9 took: 21.660582ms
Aug  3 18:24:42.178: INFO: Terminating ReplicationController proxy-service-9cnl9 pods took: 100.213701ms
[AfterEach] version v1
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 18:24:47.078: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-9678" for this suite.
Aug  3 18:24:53.127: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 18:24:53.432: INFO: namespace proxy-9678 deletion completed in 6.339962471s

• [SLOW TEST:22.362 seconds]
[sig-network] Proxy
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:58
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 18:24:53.433: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-4090
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating the pod
Aug  3 18:24:58.232: INFO: Successfully updated pod "labelsupdatec0ef4094-7bfc-44bf-8dd8-01fdc5df690c"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 18:25:00.268: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4090" for this suite.
Aug  3 18:25:24.313: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 18:25:24.672: INFO: namespace projected-4090 deletion completed in 24.390586196s

• [SLOW TEST:31.240 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 18:25:24.673: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-5974
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating Redis RC
Aug  3 18:25:24.885: INFO: namespace kubectl-5974
Aug  3 18:25:24.885: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 create -f - --namespace=kubectl-5974'
Aug  3 18:25:25.262: INFO: stderr: ""
Aug  3 18:25:25.262: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Aug  3 18:25:26.270: INFO: Selector matched 1 pods for map[app:redis]
Aug  3 18:25:26.270: INFO: Found 0 / 1
Aug  3 18:25:27.282: INFO: Selector matched 1 pods for map[app:redis]
Aug  3 18:25:27.283: INFO: Found 1 / 1
Aug  3 18:25:27.283: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Aug  3 18:25:27.309: INFO: Selector matched 1 pods for map[app:redis]
Aug  3 18:25:27.309: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Aug  3 18:25:27.310: INFO: wait on redis-master startup in kubectl-5974 
Aug  3 18:25:27.310: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 logs redis-master-qsqv2 redis-master --namespace=kubectl-5974'
Aug  3 18:25:27.448: INFO: stderr: ""
Aug  3 18:25:27.448: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 03 Aug 18:25:26.599 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 03 Aug 18:25:26.599 # Server started, Redis version 3.2.12\n1:M 03 Aug 18:25:26.599 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 03 Aug 18:25:26.599 * The server is now ready to accept connections on port 6379\n"
STEP: exposing RC
Aug  3 18:25:27.449: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=kubectl-5974'
Aug  3 18:25:27.598: INFO: stderr: ""
Aug  3 18:25:27.598: INFO: stdout: "service/rm2 exposed\n"
Aug  3 18:25:27.608: INFO: Service rm2 in namespace kubectl-5974 found.
STEP: exposing service
Aug  3 18:25:29.629: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=kubectl-5974'
Aug  3 18:25:29.763: INFO: stderr: ""
Aug  3 18:25:29.763: INFO: stdout: "service/rm3 exposed\n"
Aug  3 18:25:29.771: INFO: Service rm3 in namespace kubectl-5974 found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 18:25:31.797: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5974" for this suite.
Aug  3 18:25:55.842: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 18:25:56.168: INFO: namespace kubectl-5974 deletion completed in 24.360009029s

• [SLOW TEST:31.495 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl expose
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create services for rc  [Conformance]
    /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 18:25:56.169: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-187
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-eba946c6-2d92-434a-8529-4a044b4b3f50
STEP: Creating a pod to test consume configMaps
Aug  3 18:25:56.442: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-ed05236f-b1e1-491c-ae84-1189db0f792c" in namespace "projected-187" to be "success or failure"
Aug  3 18:25:56.450: INFO: Pod "pod-projected-configmaps-ed05236f-b1e1-491c-ae84-1189db0f792c": Phase="Pending", Reason="", readiness=false. Elapsed: 8.470556ms
Aug  3 18:25:58.458: INFO: Pod "pod-projected-configmaps-ed05236f-b1e1-491c-ae84-1189db0f792c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016485048s
STEP: Saw pod success
Aug  3 18:25:58.458: INFO: Pod "pod-projected-configmaps-ed05236f-b1e1-491c-ae84-1189db0f792c" satisfied condition "success or failure"
Aug  3 18:25:58.466: INFO: Trying to get logs from node 10.188.31.32 pod pod-projected-configmaps-ed05236f-b1e1-491c-ae84-1189db0f792c container projected-configmap-volume-test: <nil>
STEP: delete the pod
Aug  3 18:25:58.519: INFO: Waiting for pod pod-projected-configmaps-ed05236f-b1e1-491c-ae84-1189db0f792c to disappear
Aug  3 18:25:58.526: INFO: Pod pod-projected-configmaps-ed05236f-b1e1-491c-ae84-1189db0f792c no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 18:25:58.526: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-187" for this suite.
Aug  3 18:26:04.569: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 18:26:04.914: INFO: namespace projected-187 deletion completed in 6.377312011s

• [SLOW TEST:8.745 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 18:26:04.914: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-7110
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-configmap-x2dg
STEP: Creating a pod to test atomic-volume-subpath
Aug  3 18:26:05.191: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-x2dg" in namespace "subpath-7110" to be "success or failure"
Aug  3 18:26:05.198: INFO: Pod "pod-subpath-test-configmap-x2dg": Phase="Pending", Reason="", readiness=false. Elapsed: 6.993848ms
Aug  3 18:26:07.207: INFO: Pod "pod-subpath-test-configmap-x2dg": Phase="Running", Reason="", readiness=true. Elapsed: 2.015224125s
Aug  3 18:26:09.215: INFO: Pod "pod-subpath-test-configmap-x2dg": Phase="Running", Reason="", readiness=true. Elapsed: 4.023785445s
Aug  3 18:26:11.227: INFO: Pod "pod-subpath-test-configmap-x2dg": Phase="Running", Reason="", readiness=true. Elapsed: 6.035301869s
Aug  3 18:26:13.235: INFO: Pod "pod-subpath-test-configmap-x2dg": Phase="Running", Reason="", readiness=true. Elapsed: 8.044048442s
Aug  3 18:26:15.249: INFO: Pod "pod-subpath-test-configmap-x2dg": Phase="Running", Reason="", readiness=true. Elapsed: 10.057724808s
Aug  3 18:26:17.269: INFO: Pod "pod-subpath-test-configmap-x2dg": Phase="Running", Reason="", readiness=true. Elapsed: 12.07779627s
Aug  3 18:26:19.278: INFO: Pod "pod-subpath-test-configmap-x2dg": Phase="Running", Reason="", readiness=true. Elapsed: 14.086807336s
Aug  3 18:26:21.287: INFO: Pod "pod-subpath-test-configmap-x2dg": Phase="Running", Reason="", readiness=true. Elapsed: 16.096019356s
Aug  3 18:26:23.300: INFO: Pod "pod-subpath-test-configmap-x2dg": Phase="Running", Reason="", readiness=true. Elapsed: 18.108793161s
Aug  3 18:26:25.310: INFO: Pod "pod-subpath-test-configmap-x2dg": Phase="Running", Reason="", readiness=true. Elapsed: 20.11816701s
Aug  3 18:26:27.329: INFO: Pod "pod-subpath-test-configmap-x2dg": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.137820392s
STEP: Saw pod success
Aug  3 18:26:27.329: INFO: Pod "pod-subpath-test-configmap-x2dg" satisfied condition "success or failure"
Aug  3 18:26:27.337: INFO: Trying to get logs from node 10.188.31.32 pod pod-subpath-test-configmap-x2dg container test-container-subpath-configmap-x2dg: <nil>
STEP: delete the pod
Aug  3 18:26:27.381: INFO: Waiting for pod pod-subpath-test-configmap-x2dg to disappear
Aug  3 18:26:27.390: INFO: Pod pod-subpath-test-configmap-x2dg no longer exists
STEP: Deleting pod pod-subpath-test-configmap-x2dg
Aug  3 18:26:27.390: INFO: Deleting pod "pod-subpath-test-configmap-x2dg" in namespace "subpath-7110"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 18:26:27.397: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-7110" for this suite.
Aug  3 18:26:33.440: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 18:26:33.775: INFO: namespace subpath-7110 deletion completed in 6.367437002s

• [SLOW TEST:28.861 seconds]
[sig-storage] Subpath
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with configmap pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 18:26:33.776: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-1804
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:81
Aug  3 18:26:33.990: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Aug  3 18:26:34.016: INFO: Waiting for terminating namespaces to be deleted...
Aug  3 18:26:34.029: INFO: 
Logging pods the kubelet thinks is on node 10.188.31.22 before test
Aug  3 18:26:34.060: INFO: ibm-keepalived-watcher-fkdg8 from kube-system started at 2019-08-03 15:30:03 +0000 UTC (1 container statuses recorded)
Aug  3 18:26:34.060: INFO: 	Container keepalived-watcher ready: true, restart count 0
Aug  3 18:26:34.060: INFO: sonobuoy from heptio-sonobuoy started at 2019-08-03 17:36:53 +0000 UTC (1 container statuses recorded)
Aug  3 18:26:34.060: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Aug  3 18:26:34.060: INFO: sonobuoy-e2e-job-128cd56eea1c4929 from heptio-sonobuoy started at 2019-08-03 17:36:58 +0000 UTC (2 container statuses recorded)
Aug  3 18:26:34.060: INFO: 	Container e2e ready: true, restart count 0
Aug  3 18:26:34.060: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug  3 18:26:34.060: INFO: sonobuoy-systemd-logs-daemon-set-2824ab4c610f42f4-rvnnh from heptio-sonobuoy started at 2019-08-03 17:36:58 +0000 UTC (2 container statuses recorded)
Aug  3 18:26:34.060: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug  3 18:26:34.060: INFO: 	Container systemd-logs ready: true, restart count 0
Aug  3 18:26:34.060: INFO: ibm-master-proxy-static-10.188.31.22 from kube-system started at 2019-08-03 15:30:01 +0000 UTC (2 container statuses recorded)
Aug  3 18:26:34.060: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Aug  3 18:26:34.060: INFO: 	Container pause ready: true, restart count 0
Aug  3 18:26:34.060: INFO: ibm-kube-fluentd-25wz8 from kube-system started at 2019-08-03 15:30:14 +0000 UTC (1 container statuses recorded)
Aug  3 18:26:34.060: INFO: 	Container fluentd ready: true, restart count 0
Aug  3 18:26:34.060: INFO: calico-node-mc9wt from kube-system started at 2019-08-03 15:30:03 +0000 UTC (1 container statuses recorded)
Aug  3 18:26:34.060: INFO: 	Container calico-node ready: true, restart count 0
Aug  3 18:26:34.060: INFO: 
Logging pods the kubelet thinks is on node 10.188.31.24 before test
Aug  3 18:26:34.104: INFO: coredns-autoscaler-7fbd4fd998-4tdzn from kube-system started at 2019-08-03 15:30:10 +0000 UTC (1 container statuses recorded)
Aug  3 18:26:34.104: INFO: 	Container autoscaler ready: true, restart count 0
Aug  3 18:26:34.104: INFO: ibm-master-proxy-static-10.188.31.24 from kube-system started at 2019-08-03 15:29:45 +0000 UTC (2 container statuses recorded)
Aug  3 18:26:34.104: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Aug  3 18:26:34.104: INFO: 	Container pause ready: true, restart count 0
Aug  3 18:26:34.104: INFO: ibm-storage-watcher-5c75867c7-sns8d from kube-system started at 2019-08-03 15:30:10 +0000 UTC (1 container statuses recorded)
Aug  3 18:26:34.104: INFO: 	Container ibm-storage-watcher-container ready: true, restart count 0
Aug  3 18:26:34.104: INFO: coredns-7789d4b879-drqmd from kube-system started at 2019-08-03 15:30:10 +0000 UTC (1 container statuses recorded)
Aug  3 18:26:34.104: INFO: 	Container coredns ready: true, restart count 0
Aug  3 18:26:34.104: INFO: ibm-kube-fluentd-ltrhd from kube-system started at 2019-08-03 15:30:14 +0000 UTC (1 container statuses recorded)
Aug  3 18:26:34.104: INFO: 	Container fluentd ready: true, restart count 0
Aug  3 18:26:34.104: INFO: ibm-keepalived-watcher-z8jrg from kube-system started at 2019-08-03 15:29:52 +0000 UTC (1 container statuses recorded)
Aug  3 18:26:34.104: INFO: 	Container keepalived-watcher ready: true, restart count 0
Aug  3 18:26:34.104: INFO: kubernetes-dashboard-7756dcb98b-pc5ss from kube-system started at 2019-08-03 15:30:10 +0000 UTC (1 container statuses recorded)
Aug  3 18:26:34.104: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Aug  3 18:26:34.104: INFO: ibm-file-plugin-7b7f6d7b59-7vn9h from kube-system started at 2019-08-03 15:30:10 +0000 UTC (1 container statuses recorded)
Aug  3 18:26:34.104: INFO: 	Container ibm-file-plugin-container ready: true, restart count 0
Aug  3 18:26:34.104: INFO: calico-kube-controllers-7497554b5f-qrxg2 from kube-system started at 2019-08-03 15:30:10 +0000 UTC (1 container statuses recorded)
Aug  3 18:26:34.104: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Aug  3 18:26:34.104: INFO: calico-node-979kf from kube-system started at 2019-08-03 15:29:52 +0000 UTC (1 container statuses recorded)
Aug  3 18:26:34.104: INFO: 	Container calico-node ready: true, restart count 0
Aug  3 18:26:34.104: INFO: vpn-6554589999-thmhh from kube-system started at 2019-08-03 15:30:10 +0000 UTC (1 container statuses recorded)
Aug  3 18:26:34.104: INFO: 	Container vpn ready: true, restart count 0
Aug  3 18:26:34.104: INFO: sonobuoy-systemd-logs-daemon-set-2824ab4c610f42f4-5422v from heptio-sonobuoy started at 2019-08-03 17:36:58 +0000 UTC (2 container statuses recorded)
Aug  3 18:26:34.104: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug  3 18:26:34.104: INFO: 	Container systemd-logs ready: true, restart count 0
Aug  3 18:26:34.104: INFO: 
Logging pods the kubelet thinks is on node 10.188.31.32 before test
Aug  3 18:26:34.127: INFO: metrics-server-66558f74f4-zfdzx from kube-system started at 2019-08-03 15:30:43 +0000 UTC (2 container statuses recorded)
Aug  3 18:26:34.127: INFO: 	Container metrics-server ready: true, restart count 0
Aug  3 18:26:34.127: INFO: 	Container metrics-server-nanny ready: true, restart count 0
Aug  3 18:26:34.127: INFO: ibm-kube-fluentd-chr7d from kube-system started at 2019-08-03 15:30:14 +0000 UTC (1 container statuses recorded)
Aug  3 18:26:34.127: INFO: 	Container fluentd ready: true, restart count 0
Aug  3 18:26:34.127: INFO: sonobuoy-systemd-logs-daemon-set-2824ab4c610f42f4-945kd from heptio-sonobuoy started at 2019-08-03 17:36:58 +0000 UTC (2 container statuses recorded)
Aug  3 18:26:34.127: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug  3 18:26:34.127: INFO: 	Container systemd-logs ready: true, restart count 0
Aug  3 18:26:34.127: INFO: ibm-keepalived-watcher-h74k2 from kube-system started at 2019-08-03 15:30:13 +0000 UTC (1 container statuses recorded)
Aug  3 18:26:34.127: INFO: 	Container keepalived-watcher ready: true, restart count 0
Aug  3 18:26:34.127: INFO: coredns-7789d4b879-46cbb from kube-system started at 2019-08-03 15:30:25 +0000 UTC (1 container statuses recorded)
Aug  3 18:26:34.127: INFO: 	Container coredns ready: true, restart count 0
Aug  3 18:26:34.127: INFO: calico-node-7mlcs from kube-system started at 2019-08-03 15:30:13 +0000 UTC (1 container statuses recorded)
Aug  3 18:26:34.127: INFO: 	Container calico-node ready: true, restart count 0
Aug  3 18:26:34.127: INFO: ibm-master-proxy-static-10.188.31.32 from kube-system started at 2019-08-03 15:30:07 +0000 UTC (2 container statuses recorded)
Aug  3 18:26:34.127: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Aug  3 18:26:34.127: INFO: 	Container pause ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-443367b3-56a7-4b04-93bd-fa8de0108189 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-443367b3-56a7-4b04-93bd-fa8de0108189 off the node 10.188.31.32
STEP: verifying the node doesn't have the label kubernetes.io/e2e-443367b3-56a7-4b04-93bd-fa8de0108189
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 18:26:38.476: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-1804" for this suite.
Aug  3 18:27:00.523: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 18:27:00.880: INFO: namespace sched-pred-1804 deletion completed in 22.393231352s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:72

• [SLOW TEST:27.104 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 18:27:00.881: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-9775
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:273
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a replication controller
Aug  3 18:27:01.114: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 create -f - --namespace=kubectl-9775'
Aug  3 18:27:01.469: INFO: stderr: ""
Aug  3 18:27:01.469: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Aug  3 18:27:01.469: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9775'
Aug  3 18:27:01.599: INFO: stderr: ""
Aug  3 18:27:01.599: INFO: stdout: "update-demo-nautilus-9gndf update-demo-nautilus-c5m7s "
Aug  3 18:27:01.599: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 get pods update-demo-nautilus-9gndf -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9775'
Aug  3 18:27:01.760: INFO: stderr: ""
Aug  3 18:27:01.760: INFO: stdout: ""
Aug  3 18:27:01.760: INFO: update-demo-nautilus-9gndf is created but not running
Aug  3 18:27:06.761: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9775'
Aug  3 18:27:06.877: INFO: stderr: ""
Aug  3 18:27:06.877: INFO: stdout: "update-demo-nautilus-9gndf update-demo-nautilus-c5m7s "
Aug  3 18:27:06.877: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 get pods update-demo-nautilus-9gndf -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9775'
Aug  3 18:27:07.000: INFO: stderr: ""
Aug  3 18:27:07.000: INFO: stdout: "true"
Aug  3 18:27:07.000: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 get pods update-demo-nautilus-9gndf -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9775'
Aug  3 18:27:07.112: INFO: stderr: ""
Aug  3 18:27:07.112: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Aug  3 18:27:07.112: INFO: validating pod update-demo-nautilus-9gndf
Aug  3 18:27:07.137: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug  3 18:27:07.137: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug  3 18:27:07.137: INFO: update-demo-nautilus-9gndf is verified up and running
Aug  3 18:27:07.137: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 get pods update-demo-nautilus-c5m7s -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9775'
Aug  3 18:27:07.248: INFO: stderr: ""
Aug  3 18:27:07.248: INFO: stdout: "true"
Aug  3 18:27:07.248: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 get pods update-demo-nautilus-c5m7s -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9775'
Aug  3 18:27:07.360: INFO: stderr: ""
Aug  3 18:27:07.360: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Aug  3 18:27:07.360: INFO: validating pod update-demo-nautilus-c5m7s
Aug  3 18:27:07.376: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug  3 18:27:07.376: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug  3 18:27:07.376: INFO: update-demo-nautilus-c5m7s is verified up and running
STEP: using delete to clean up resources
Aug  3 18:27:07.376: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 delete --grace-period=0 --force -f - --namespace=kubectl-9775'
Aug  3 18:27:07.500: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug  3 18:27:07.500: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Aug  3 18:27:07.500: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-9775'
Aug  3 18:27:07.640: INFO: stderr: "No resources found.\n"
Aug  3 18:27:07.640: INFO: stdout: ""
Aug  3 18:27:07.640: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 get pods -l name=update-demo --namespace=kubectl-9775 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Aug  3 18:27:07.771: INFO: stderr: ""
Aug  3 18:27:07.771: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 18:27:07.771: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9775" for this suite.
Aug  3 18:27:31.816: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 18:27:32.186: INFO: namespace kubectl-9775 deletion completed in 24.403187813s

• [SLOW TEST:31.305 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 18:27:32.188: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-5209
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Aug  3 18:27:32.425: INFO: Waiting up to 5m0s for pod "downward-api-a5a93f08-acaa-45c0-ad6f-48e5a9add50f" in namespace "downward-api-5209" to be "success or failure"
Aug  3 18:27:32.432: INFO: Pod "downward-api-a5a93f08-acaa-45c0-ad6f-48e5a9add50f": Phase="Pending", Reason="", readiness=false. Elapsed: 7.443217ms
Aug  3 18:27:34.442: INFO: Pod "downward-api-a5a93f08-acaa-45c0-ad6f-48e5a9add50f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016840607s
Aug  3 18:27:36.451: INFO: Pod "downward-api-a5a93f08-acaa-45c0-ad6f-48e5a9add50f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02555165s
STEP: Saw pod success
Aug  3 18:27:36.451: INFO: Pod "downward-api-a5a93f08-acaa-45c0-ad6f-48e5a9add50f" satisfied condition "success or failure"
Aug  3 18:27:36.461: INFO: Trying to get logs from node 10.188.31.24 pod downward-api-a5a93f08-acaa-45c0-ad6f-48e5a9add50f container dapi-container: <nil>
STEP: delete the pod
Aug  3 18:27:36.501: INFO: Waiting for pod downward-api-a5a93f08-acaa-45c0-ad6f-48e5a9add50f to disappear
Aug  3 18:27:36.508: INFO: Pod downward-api-a5a93f08-acaa-45c0-ad6f-48e5a9add50f no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 18:27:36.508: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5209" for this suite.
Aug  3 18:27:42.569: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 18:27:42.856: INFO: namespace downward-api-5209 deletion completed in 6.326915988s

• [SLOW TEST:10.669 seconds]
[sig-node] Downward API
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 18:27:42.857: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-2307
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl label
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1211
STEP: creating the pod
Aug  3 18:27:43.074: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 create -f - --namespace=kubectl-2307'
Aug  3 18:27:43.425: INFO: stderr: ""
Aug  3 18:27:43.425: INFO: stdout: "pod/pause created\n"
Aug  3 18:27:43.425: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Aug  3 18:27:43.425: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-2307" to be "running and ready"
Aug  3 18:27:43.432: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 6.832603ms
Aug  3 18:27:45.449: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.023804685s
Aug  3 18:27:45.449: INFO: Pod "pause" satisfied condition "running and ready"
Aug  3 18:27:45.449: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: adding the label testing-label with value testing-label-value to a pod
Aug  3 18:27:45.449: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 label pods pause testing-label=testing-label-value --namespace=kubectl-2307'
Aug  3 18:27:45.560: INFO: stderr: ""
Aug  3 18:27:45.560: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Aug  3 18:27:45.560: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 get pod pause -L testing-label --namespace=kubectl-2307'
Aug  3 18:27:45.665: INFO: stderr: ""
Aug  3 18:27:45.665: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Aug  3 18:27:45.665: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 label pods pause testing-label- --namespace=kubectl-2307'
Aug  3 18:27:45.793: INFO: stderr: ""
Aug  3 18:27:45.793: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Aug  3 18:27:45.793: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 get pod pause -L testing-label --namespace=kubectl-2307'
Aug  3 18:27:45.911: INFO: stderr: ""
Aug  3 18:27:45.911: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    \n"
[AfterEach] [k8s.io] Kubectl label
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1218
STEP: using delete to clean up resources
Aug  3 18:27:45.911: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 delete --grace-period=0 --force -f - --namespace=kubectl-2307'
Aug  3 18:27:46.052: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug  3 18:27:46.052: INFO: stdout: "pod \"pause\" force deleted\n"
Aug  3 18:27:46.052: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 get rc,svc -l name=pause --no-headers --namespace=kubectl-2307'
Aug  3 18:27:46.192: INFO: stderr: "No resources found.\n"
Aug  3 18:27:46.192: INFO: stdout: ""
Aug  3 18:27:46.192: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 get pods -l name=pause --namespace=kubectl-2307 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Aug  3 18:27:46.292: INFO: stderr: ""
Aug  3 18:27:46.292: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 18:27:46.292: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2307" for this suite.
Aug  3 18:27:52.338: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 18:27:52.654: INFO: namespace kubectl-2307 deletion completed in 6.349822346s

• [SLOW TEST:9.797 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl label
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 18:27:52.654: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-6379
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-map-6e9ac220-a3fd-4e23-815f-7912b832edc6
STEP: Creating a pod to test consume secrets
Aug  3 18:27:52.918: INFO: Waiting up to 5m0s for pod "pod-secrets-06a370d6-2f16-43c1-ac19-0f2c765f7315" in namespace "secrets-6379" to be "success or failure"
Aug  3 18:27:52.927: INFO: Pod "pod-secrets-06a370d6-2f16-43c1-ac19-0f2c765f7315": Phase="Pending", Reason="", readiness=false. Elapsed: 8.428216ms
Aug  3 18:27:54.949: INFO: Pod "pod-secrets-06a370d6-2f16-43c1-ac19-0f2c765f7315": Phase="Pending", Reason="", readiness=false. Elapsed: 2.03081498s
Aug  3 18:27:56.957: INFO: Pod "pod-secrets-06a370d6-2f16-43c1-ac19-0f2c765f7315": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.039124233s
STEP: Saw pod success
Aug  3 18:27:56.957: INFO: Pod "pod-secrets-06a370d6-2f16-43c1-ac19-0f2c765f7315" satisfied condition "success or failure"
Aug  3 18:27:56.967: INFO: Trying to get logs from node 10.188.31.32 pod pod-secrets-06a370d6-2f16-43c1-ac19-0f2c765f7315 container secret-volume-test: <nil>
STEP: delete the pod
Aug  3 18:27:57.034: INFO: Waiting for pod pod-secrets-06a370d6-2f16-43c1-ac19-0f2c765f7315 to disappear
Aug  3 18:27:57.044: INFO: Pod pod-secrets-06a370d6-2f16-43c1-ac19-0f2c765f7315 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 18:27:57.044: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6379" for this suite.
Aug  3 18:28:03.090: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 18:28:03.449: INFO: namespace secrets-6379 deletion completed in 6.392803754s

• [SLOW TEST:10.796 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 18:28:03.451: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-3649
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 18:28:03.686: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-3649" for this suite.
Aug  3 18:28:09.732: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 18:28:10.073: INFO: namespace services-3649 deletion completed in 6.375127352s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:92

• [SLOW TEST:6.622 seconds]
[sig-network] Services
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide secure master service  [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 18:28:10.074: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-3640
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0644 on tmpfs
Aug  3 18:28:10.297: INFO: Waiting up to 5m0s for pod "pod-a5499415-bef0-4196-8df4-e846dcbb81cd" in namespace "emptydir-3640" to be "success or failure"
Aug  3 18:28:10.306: INFO: Pod "pod-a5499415-bef0-4196-8df4-e846dcbb81cd": Phase="Pending", Reason="", readiness=false. Elapsed: 7.915426ms
Aug  3 18:28:12.314: INFO: Pod "pod-a5499415-bef0-4196-8df4-e846dcbb81cd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016123278s
STEP: Saw pod success
Aug  3 18:28:12.314: INFO: Pod "pod-a5499415-bef0-4196-8df4-e846dcbb81cd" satisfied condition "success or failure"
Aug  3 18:28:12.324: INFO: Trying to get logs from node 10.188.31.32 pod pod-a5499415-bef0-4196-8df4-e846dcbb81cd container test-container: <nil>
STEP: delete the pod
Aug  3 18:28:12.367: INFO: Waiting for pod pod-a5499415-bef0-4196-8df4-e846dcbb81cd to disappear
Aug  3 18:28:12.375: INFO: Pod pod-a5499415-bef0-4196-8df4-e846dcbb81cd no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 18:28:12.375: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3640" for this suite.
Aug  3 18:28:18.425: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 18:28:18.759: INFO: namespace emptydir-3640 deletion completed in 6.371186143s

• [SLOW TEST:8.686 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 18:28:18.759: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-4252
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Aug  3 18:28:18.977: INFO: Creating deployment "nginx-deployment"
Aug  3 18:28:18.987: INFO: Waiting for observed generation 1
Aug  3 18:28:21.003: INFO: Waiting for all required pods to come up
Aug  3 18:28:21.014: INFO: Pod name nginx: Found 10 pods out of 10
STEP: ensuring each pod is running
Aug  3 18:28:23.049: INFO: Waiting for deployment "nginx-deployment" to complete
Aug  3 18:28:23.066: INFO: Updating deployment "nginx-deployment" with a non-existent image
Aug  3 18:28:23.084: INFO: Updating deployment nginx-deployment
Aug  3 18:28:23.084: INFO: Waiting for observed generation 2
Aug  3 18:28:25.099: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Aug  3 18:28:25.110: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Aug  3 18:28:25.119: INFO: Waiting for the first rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Aug  3 18:28:25.147: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Aug  3 18:28:25.147: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Aug  3 18:28:25.156: INFO: Waiting for the second rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Aug  3 18:28:25.184: INFO: Verifying that deployment "nginx-deployment" has minimum required number of available replicas
Aug  3 18:28:25.184: INFO: Scaling up the deployment "nginx-deployment" from 10 to 30
Aug  3 18:28:25.201: INFO: Updating deployment nginx-deployment
Aug  3 18:28:25.201: INFO: Waiting for the replicasets of deployment "nginx-deployment" to have desired number of replicas
Aug  3 18:28:25.221: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Aug  3 18:28:25.229: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
Aug  3 18:28:25.249: INFO: Deployment "nginx-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment,GenerateName:,Namespace:deployment-4252,SelfLink:/apis/apps/v1/namespaces/deployment-4252/deployments/nginx-deployment,UID:df97380e-4a79-4fbc-b5d1-4073ebbbe8f0,ResourceVersion:42331,Generation:3,CreationTimestamp:2019-08-03 18:28:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*30,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:13,UpdatedReplicas:5,AvailableReplicas:8,UnavailableReplicas:5,Conditions:[{Progressing True 2019-08-03 18:28:23 +0000 UTC 2019-08-03 18:28:18 +0000 UTC ReplicaSetUpdated ReplicaSet "nginx-deployment-55fb7cb77f" is progressing.} {Available False 2019-08-03 18:28:25 +0000 UTC 2019-08-03 18:28:25 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}],ReadyReplicas:8,CollisionCount:nil,},}

Aug  3 18:28:25.261: INFO: New ReplicaSet "nginx-deployment-55fb7cb77f" of Deployment "nginx-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f,GenerateName:,Namespace:deployment-4252,SelfLink:/apis/apps/v1/namespaces/deployment-4252/replicasets/nginx-deployment-55fb7cb77f,UID:809cc757-c339-40e3-9cb3-bde71233e85c,ResourceVersion:42328,Generation:3,CreationTimestamp:2019-08-03 18:28:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment nginx-deployment df97380e-4a79-4fbc-b5d1-4073ebbbe8f0 0xc003835907 0xc003835908}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*13,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:5,FullyLabeledReplicas:5,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Aug  3 18:28:25.261: INFO: All old ReplicaSets of Deployment "nginx-deployment":
Aug  3 18:28:25.262: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498,GenerateName:,Namespace:deployment-4252,SelfLink:/apis/apps/v1/namespaces/deployment-4252/replicasets/nginx-deployment-7b8c6f4498,UID:9b06261b-7e47-4174-854d-baa19f9a5a80,ResourceVersion:42326,Generation:3,CreationTimestamp:2019-08-03 18:28:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment nginx-deployment df97380e-4a79-4fbc-b5d1-4073ebbbe8f0 0xc0038359d7 0xc0038359d8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*20,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:8,FullyLabeledReplicas:8,ObservedGeneration:2,ReadyReplicas:8,AvailableReplicas:8,Conditions:[],},}
Aug  3 18:28:25.278: INFO: Pod "nginx-deployment-55fb7cb77f-26n68" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-26n68,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-4252,SelfLink:/api/v1/namespaces/deployment-4252/pods/nginx-deployment-55fb7cb77f-26n68,UID:6e3edd22-c724-484e-bc56-61a716fe08e4,ResourceVersion:42319,Generation:0,CreationTimestamp:2019-08-03 18:28:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 809cc757-c339-40e3-9cb3-bde71233e85c 0xc0036ddef7 0xc0036ddef8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-jgg8m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jgg8m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-jgg8m true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.188.31.22,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0036ddf70} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0036ddf90}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-03 18:28:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-03 18:28:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-03 18:28:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-03 18:28:23 +0000 UTC  }],Message:,Reason:,HostIP:10.188.31.22,PodIP:172.30.199.72,StartTime:2019-08-03 18:28:23 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to resolve image "docker.io/library/nginx:404": no available registry endpoint: docker.io/library/nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug  3 18:28:25.278: INFO: Pod "nginx-deployment-55fb7cb77f-4cv24" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-4cv24,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-4252,SelfLink:/api/v1/namespaces/deployment-4252/pods/nginx-deployment-55fb7cb77f-4cv24,UID:eab60f9f-8077-4b33-bf06-a9eac0f6a9f1,ResourceVersion:42356,Generation:0,CreationTimestamp:2019-08-03 18:28:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 809cc757-c339-40e3-9cb3-bde71233e85c 0xc0034d6080 0xc0034d6081}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-jgg8m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jgg8m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-jgg8m true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0034d60f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0034d6110}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug  3 18:28:25.278: INFO: Pod "nginx-deployment-55fb7cb77f-d2qvj" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-d2qvj,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-4252,SelfLink:/api/v1/namespaces/deployment-4252/pods/nginx-deployment-55fb7cb77f-d2qvj,UID:a60c7c01-2600-4dae-8c2b-688736fe5c67,ResourceVersion:42368,Generation:0,CreationTimestamp:2019-08-03 18:28:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 809cc757-c339-40e3-9cb3-bde71233e85c 0xc0034d6177 0xc0034d6178}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-jgg8m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jgg8m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-jgg8m true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.188.31.24,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0034d61f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0034d6210}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-03 18:28:25 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug  3 18:28:25.278: INFO: Pod "nginx-deployment-55fb7cb77f-fh42c" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-fh42c,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-4252,SelfLink:/api/v1/namespaces/deployment-4252/pods/nginx-deployment-55fb7cb77f-fh42c,UID:ef0a2bbf-304b-4c91-9d83-eb44163af95b,ResourceVersion:42274,Generation:0,CreationTimestamp:2019-08-03 18:28:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 809cc757-c339-40e3-9cb3-bde71233e85c 0xc0034d6290 0xc0034d6291}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-jgg8m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jgg8m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-jgg8m true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.188.31.24,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0034d6310} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0034d6330}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-03 18:28:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-03 18:28:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-03 18:28:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-03 18:28:23 +0000 UTC  }],Message:,Reason:,HostIP:10.188.31.24,PodIP:,StartTime:2019-08-03 18:28:23 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug  3 18:28:25.279: INFO: Pod "nginx-deployment-55fb7cb77f-lcqh9" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-lcqh9,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-4252,SelfLink:/api/v1/namespaces/deployment-4252/pods/nginx-deployment-55fb7cb77f-lcqh9,UID:32249c15-5650-4a3c-bac5-0b01f6a2a0aa,ResourceVersion:42272,Generation:0,CreationTimestamp:2019-08-03 18:28:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 809cc757-c339-40e3-9cb3-bde71233e85c 0xc0034d6400 0xc0034d6401}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-jgg8m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jgg8m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-jgg8m true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.188.31.32,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0034d6480} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0034d64a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-03 18:28:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-03 18:28:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-03 18:28:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-03 18:28:23 +0000 UTC  }],Message:,Reason:,HostIP:10.188.31.32,PodIP:,StartTime:2019-08-03 18:28:23 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug  3 18:28:25.279: INFO: Pod "nginx-deployment-55fb7cb77f-m9q2w" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-m9q2w,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-4252,SelfLink:/api/v1/namespaces/deployment-4252/pods/nginx-deployment-55fb7cb77f-m9q2w,UID:6748f45c-355d-4e50-82e9-d3489c2c0e29,ResourceVersion:42338,Generation:0,CreationTimestamp:2019-08-03 18:28:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 809cc757-c339-40e3-9cb3-bde71233e85c 0xc0034d6570 0xc0034d6571}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-jgg8m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jgg8m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-jgg8m true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.188.31.22,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0034d65f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0034d6610}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-03 18:28:25 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug  3 18:28:25.279: INFO: Pod "nginx-deployment-55fb7cb77f-nr75s" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-nr75s,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-4252,SelfLink:/api/v1/namespaces/deployment-4252/pods/nginx-deployment-55fb7cb77f-nr75s,UID:58e66ffb-f51e-4df9-bc75-bc1b622764b0,ResourceVersion:42349,Generation:0,CreationTimestamp:2019-08-03 18:28:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 809cc757-c339-40e3-9cb3-bde71233e85c 0xc0034d6690 0xc0034d6691}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-jgg8m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jgg8m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-jgg8m true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.188.31.32,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0034d6710} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0034d6730}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-03 18:28:25 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug  3 18:28:25.279: INFO: Pod "nginx-deployment-55fb7cb77f-pv4xr" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-pv4xr,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-4252,SelfLink:/api/v1/namespaces/deployment-4252/pods/nginx-deployment-55fb7cb77f-pv4xr,UID:c96c8c30-6d5e-4f6e-9945-f24250dc14d2,ResourceVersion:42371,Generation:0,CreationTimestamp:2019-08-03 18:28:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 809cc757-c339-40e3-9cb3-bde71233e85c 0xc0034d67b0 0xc0034d67b1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-jgg8m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jgg8m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-jgg8m true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.188.31.32,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0034d6830} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0034d6850}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-03 18:28:25 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug  3 18:28:25.279: INFO: Pod "nginx-deployment-55fb7cb77f-q89bn" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-q89bn,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-4252,SelfLink:/api/v1/namespaces/deployment-4252/pods/nginx-deployment-55fb7cb77f-q89bn,UID:b16cdde5-7a06-4875-8b0c-77fc050eb0e5,ResourceVersion:42370,Generation:0,CreationTimestamp:2019-08-03 18:28:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 809cc757-c339-40e3-9cb3-bde71233e85c 0xc0034d68d0 0xc0034d68d1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-jgg8m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jgg8m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-jgg8m true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.188.31.24,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0034d6950} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0034d6970}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-03 18:28:25 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug  3 18:28:25.279: INFO: Pod "nginx-deployment-55fb7cb77f-tghk9" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-tghk9,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-4252,SelfLink:/api/v1/namespaces/deployment-4252/pods/nginx-deployment-55fb7cb77f-tghk9,UID:48ef4a33-662e-4104-9584-1d47cf1b6a83,ResourceVersion:42350,Generation:0,CreationTimestamp:2019-08-03 18:28:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 809cc757-c339-40e3-9cb3-bde71233e85c 0xc0034d69f0 0xc0034d69f1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-jgg8m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jgg8m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-jgg8m true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.188.31.22,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0034d6a70} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0034d6a90}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-03 18:28:25 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug  3 18:28:25.279: INFO: Pod "nginx-deployment-55fb7cb77f-tprxm" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-tprxm,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-4252,SelfLink:/api/v1/namespaces/deployment-4252/pods/nginx-deployment-55fb7cb77f-tprxm,UID:c8403b25-d3e7-4595-9505-d943e5b7be0c,ResourceVersion:42245,Generation:0,CreationTimestamp:2019-08-03 18:28:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 809cc757-c339-40e3-9cb3-bde71233e85c 0xc0034d6b10 0xc0034d6b11}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-jgg8m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jgg8m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-jgg8m true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.188.31.32,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0034d6b90} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0034d6bb0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-03 18:28:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-03 18:28:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-03 18:28:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-03 18:28:23 +0000 UTC  }],Message:,Reason:,HostIP:10.188.31.32,PodIP:,StartTime:2019-08-03 18:28:23 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug  3 18:28:25.279: INFO: Pod "nginx-deployment-55fb7cb77f-wb2gj" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-wb2gj,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-4252,SelfLink:/api/v1/namespaces/deployment-4252/pods/nginx-deployment-55fb7cb77f-wb2gj,UID:25ba82c4-b2e6-4bf3-b0f4-5d9cf352be4f,ResourceVersion:42322,Generation:0,CreationTimestamp:2019-08-03 18:28:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 809cc757-c339-40e3-9cb3-bde71233e85c 0xc0034d6c80 0xc0034d6c81}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-jgg8m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jgg8m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-jgg8m true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.188.31.24,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0034d6d00} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0034d6d20}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-03 18:28:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-03 18:28:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-03 18:28:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-03 18:28:23 +0000 UTC  }],Message:,Reason:,HostIP:10.188.31.24,PodIP:172.30.44.94,StartTime:2019-08-03 18:28:23 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to resolve image "docker.io/library/nginx:404": no available registry endpoint: docker.io/library/nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug  3 18:28:25.279: INFO: Pod "nginx-deployment-7b8c6f4498-4qvqq" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-4qvqq,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-4252,SelfLink:/api/v1/namespaces/deployment-4252/pods/nginx-deployment-7b8c6f4498-4qvqq,UID:0a8ca904-25e0-4bd7-afb4-223e29a2af7d,ResourceVersion:42173,Generation:0,CreationTimestamp:2019-08-03 18:28:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 9b06261b-7e47-4174-854d-baa19f9a5a80 0xc0034d6e10 0xc0034d6e11}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-jgg8m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jgg8m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-jgg8m true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.188.31.24,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0034d6e80} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0034d6ea0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-03 18:28:19 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-03 18:28:20 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-03 18:28:20 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-03 18:28:19 +0000 UTC  }],Message:,Reason:,HostIP:10.188.31.24,PodIP:172.30.44.89,StartTime:2019-08-03 18:28:19 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-08-03 18:28:20 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 containerd://319c4c3b486bdfd8f735194be5347f06db428ab1e7de43a03798dfbc3fcfb0b4}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug  3 18:28:25.280: INFO: Pod "nginx-deployment-7b8c6f4498-7d7rl" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-7d7rl,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-4252,SelfLink:/api/v1/namespaces/deployment-4252/pods/nginx-deployment-7b8c6f4498-7d7rl,UID:365cdc39-20e4-4b27-851e-26d5b93225be,ResourceVersion:42364,Generation:0,CreationTimestamp:2019-08-03 18:28:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 9b06261b-7e47-4174-854d-baa19f9a5a80 0xc0034d6f77 0xc0034d6f78}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-jgg8m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jgg8m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-jgg8m true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0034d6fe0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0034d7000}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug  3 18:28:25.280: INFO: Pod "nginx-deployment-7b8c6f4498-7gqv6" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-7gqv6,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-4252,SelfLink:/api/v1/namespaces/deployment-4252/pods/nginx-deployment-7b8c6f4498-7gqv6,UID:1dfa261e-3067-4e45-a2ac-63f08877d90b,ResourceVersion:42203,Generation:0,CreationTimestamp:2019-08-03 18:28:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 9b06261b-7e47-4174-854d-baa19f9a5a80 0xc0034d7067 0xc0034d7068}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-jgg8m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jgg8m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-jgg8m true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.188.31.22,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0034d70e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0034d7100}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-03 18:28:19 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-03 18:28:21 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-03 18:28:21 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-03 18:28:19 +0000 UTC  }],Message:,Reason:,HostIP:10.188.31.22,PodIP:172.30.199.124,StartTime:2019-08-03 18:28:19 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-08-03 18:28:20 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 containerd://f93186133ffc784f22b198fcd02c5d23ef0d624519919024eb66999ae929e9a5}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug  3 18:28:25.280: INFO: Pod "nginx-deployment-7b8c6f4498-7jwf7" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-7jwf7,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-4252,SelfLink:/api/v1/namespaces/deployment-4252/pods/nginx-deployment-7b8c6f4498-7jwf7,UID:97092502-e7ab-4e2e-a62b-98ac0eb88ae6,ResourceVersion:42212,Generation:0,CreationTimestamp:2019-08-03 18:28:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 9b06261b-7e47-4174-854d-baa19f9a5a80 0xc0034d71d7 0xc0034d71d8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-jgg8m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jgg8m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-jgg8m true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.188.31.24,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0034d7250} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0034d7270}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-03 18:28:19 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-03 18:28:21 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-03 18:28:21 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-03 18:28:19 +0000 UTC  }],Message:,Reason:,HostIP:10.188.31.24,PodIP:172.30.44.91,StartTime:2019-08-03 18:28:19 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-08-03 18:28:20 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 containerd://a6b4e1603afff12ef39a7a5ed60f945199d5a148882e66799b13ca665accb1b6}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug  3 18:28:25.280: INFO: Pod "nginx-deployment-7b8c6f4498-7q5qp" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-7q5qp,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-4252,SelfLink:/api/v1/namespaces/deployment-4252/pods/nginx-deployment-7b8c6f4498-7q5qp,UID:1becaa01-996d-4b84-98cf-bea16ee06eee,ResourceVersion:42197,Generation:0,CreationTimestamp:2019-08-03 18:28:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 9b06261b-7e47-4174-854d-baa19f9a5a80 0xc0034d7347 0xc0034d7348}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-jgg8m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jgg8m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-jgg8m true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.188.31.32,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0034d73c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0034d73e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-03 18:28:19 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-03 18:28:21 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-03 18:28:21 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-03 18:28:19 +0000 UTC  }],Message:,Reason:,HostIP:10.188.31.32,PodIP:172.30.72.117,StartTime:2019-08-03 18:28:19 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-08-03 18:28:20 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 containerd://d5536db9258a0d4bd9e7dc379a6bbb6ac84b9ac5f65170771481d3ebeb7a9cf8}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug  3 18:28:25.280: INFO: Pod "nginx-deployment-7b8c6f4498-8cjzn" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-8cjzn,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-4252,SelfLink:/api/v1/namespaces/deployment-4252/pods/nginx-deployment-7b8c6f4498-8cjzn,UID:7a417f3f-dcd5-4fcb-b777-ef64485880c7,ResourceVersion:42206,Generation:0,CreationTimestamp:2019-08-03 18:28:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 9b06261b-7e47-4174-854d-baa19f9a5a80 0xc0034d74b7 0xc0034d74b8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-jgg8m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jgg8m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-jgg8m true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.188.31.24,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0034d7530} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0034d7550}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-03 18:28:19 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-03 18:28:21 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-03 18:28:21 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-03 18:28:19 +0000 UTC  }],Message:,Reason:,HostIP:10.188.31.24,PodIP:172.30.44.90,StartTime:2019-08-03 18:28:19 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-08-03 18:28:20 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 containerd://03fa94747aa54ae6fa313d0d5820c0980add9745f6cc6c9c2a788d22a40d591d}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug  3 18:28:25.280: INFO: Pod "nginx-deployment-7b8c6f4498-9cl8g" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-9cl8g,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-4252,SelfLink:/api/v1/namespaces/deployment-4252/pods/nginx-deployment-7b8c6f4498-9cl8g,UID:c307312f-ef37-4eee-aed2-fbfc056fe32d,ResourceVersion:42360,Generation:0,CreationTimestamp:2019-08-03 18:28:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 9b06261b-7e47-4174-854d-baa19f9a5a80 0xc0034d7627 0xc0034d7628}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-jgg8m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jgg8m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-jgg8m true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.188.31.24,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0034d76a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0034d76c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-03 18:28:25 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug  3 18:28:25.280: INFO: Pod "nginx-deployment-7b8c6f4498-9ldrg" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-9ldrg,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-4252,SelfLink:/api/v1/namespaces/deployment-4252/pods/nginx-deployment-7b8c6f4498-9ldrg,UID:2f165536-3172-4bbe-bdbd-31a005e90ba7,ResourceVersion:42191,Generation:0,CreationTimestamp:2019-08-03 18:28:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 9b06261b-7e47-4174-854d-baa19f9a5a80 0xc0034d7740 0xc0034d7741}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-jgg8m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jgg8m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-jgg8m true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.188.31.32,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0034d77b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0034d77d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-03 18:28:19 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-03 18:28:21 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-03 18:28:21 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-03 18:28:19 +0000 UTC  }],Message:,Reason:,HostIP:10.188.31.32,PodIP:172.30.72.114,StartTime:2019-08-03 18:28:19 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-08-03 18:28:20 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 containerd://ae7dc5ad454b9a6f03963e4be19645eec901962a35198816fbca9e8c48264d4e}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug  3 18:28:25.280: INFO: Pod "nginx-deployment-7b8c6f4498-d6lh7" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-d6lh7,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-4252,SelfLink:/api/v1/namespaces/deployment-4252/pods/nginx-deployment-7b8c6f4498-d6lh7,UID:ed05f0d5-90ee-4854-a96c-8744ae10d62f,ResourceVersion:42340,Generation:0,CreationTimestamp:2019-08-03 18:28:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 9b06261b-7e47-4174-854d-baa19f9a5a80 0xc0034d78a7 0xc0034d78a8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-jgg8m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jgg8m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-jgg8m true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.188.31.32,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0034d7920} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0034d7940}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-03 18:28:25 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug  3 18:28:25.281: INFO: Pod "nginx-deployment-7b8c6f4498-ffdjb" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-ffdjb,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-4252,SelfLink:/api/v1/namespaces/deployment-4252/pods/nginx-deployment-7b8c6f4498-ffdjb,UID:2ee062df-d8ed-46c9-98f3-4d37eb276b7b,ResourceVersion:42207,Generation:0,CreationTimestamp:2019-08-03 18:28:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 9b06261b-7e47-4174-854d-baa19f9a5a80 0xc0034d79c0 0xc0034d79c1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-jgg8m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jgg8m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-jgg8m true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.188.31.22,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0034d7a30} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0034d7a50}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-03 18:28:19 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-03 18:28:21 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-03 18:28:21 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-03 18:28:19 +0000 UTC  }],Message:,Reason:,HostIP:10.188.31.22,PodIP:172.30.199.125,StartTime:2019-08-03 18:28:19 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-08-03 18:28:21 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 containerd://3d703fba1bf9626554eba3af6f5c441a276818cec48c5268ad62264dfd417eac}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug  3 18:28:25.281: INFO: Pod "nginx-deployment-7b8c6f4498-n82pm" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-n82pm,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-4252,SelfLink:/api/v1/namespaces/deployment-4252/pods/nginx-deployment-7b8c6f4498-n82pm,UID:89470d1b-5f3c-406b-be31-1dd38b717900,ResourceVersion:42357,Generation:0,CreationTimestamp:2019-08-03 18:28:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 9b06261b-7e47-4174-854d-baa19f9a5a80 0xc0034d7b27 0xc0034d7b28}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-jgg8m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jgg8m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-jgg8m true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.188.31.22,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0034d7ba0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0034d7bc0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-03 18:28:25 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug  3 18:28:25.281: INFO: Pod "nginx-deployment-7b8c6f4498-nrlsf" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-nrlsf,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-4252,SelfLink:/api/v1/namespaces/deployment-4252/pods/nginx-deployment-7b8c6f4498-nrlsf,UID:8fe643da-7a75-44a3-964e-d4a4c0b386ba,ResourceVersion:42211,Generation:0,CreationTimestamp:2019-08-03 18:28:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 9b06261b-7e47-4174-854d-baa19f9a5a80 0xc0034d7c40 0xc0034d7c41}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-jgg8m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jgg8m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-jgg8m true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.188.31.22,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0034d7cb0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0034d7cd0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-03 18:28:19 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-03 18:28:21 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-03 18:28:21 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-03 18:28:19 +0000 UTC  }],Message:,Reason:,HostIP:10.188.31.22,PodIP:172.30.199.123,StartTime:2019-08-03 18:28:19 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-08-03 18:28:20 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 containerd://9889506a39c8067a760de29c89f0309129a3a473ff1cf71ba445d82b9b3bf85b}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug  3 18:28:25.281: INFO: Pod "nginx-deployment-7b8c6f4498-ppr8c" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-ppr8c,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-4252,SelfLink:/api/v1/namespaces/deployment-4252/pods/nginx-deployment-7b8c6f4498-ppr8c,UID:15b4076b-9489-4c76-a6a0-3868f685aa3a,ResourceVersion:42367,Generation:0,CreationTimestamp:2019-08-03 18:28:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 9b06261b-7e47-4174-854d-baa19f9a5a80 0xc0034d7da7 0xc0034d7da8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-jgg8m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jgg8m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-jgg8m true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0034d7e10} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0034d7e30}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug  3 18:28:25.282: INFO: Pod "nginx-deployment-7b8c6f4498-rzb8n" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-rzb8n,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-4252,SelfLink:/api/v1/namespaces/deployment-4252/pods/nginx-deployment-7b8c6f4498-rzb8n,UID:56c89686-aac8-4b9f-b13f-d4082e4b73dc,ResourceVersion:42363,Generation:0,CreationTimestamp:2019-08-03 18:28:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 9b06261b-7e47-4174-854d-baa19f9a5a80 0xc0034d7e97 0xc0034d7e98}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-jgg8m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jgg8m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-jgg8m true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0034d7f00} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0034d7f20}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug  3 18:28:25.282: INFO: Pod "nginx-deployment-7b8c6f4498-sq5km" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-sq5km,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-4252,SelfLink:/api/v1/namespaces/deployment-4252/pods/nginx-deployment-7b8c6f4498-sq5km,UID:19c6a98a-889d-4aea-9732-09a18cb4b76e,ResourceVersion:42366,Generation:0,CreationTimestamp:2019-08-03 18:28:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 9b06261b-7e47-4174-854d-baa19f9a5a80 0xc0034d7f87 0xc0034d7f88}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-jgg8m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jgg8m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-jgg8m true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0034d7ff0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003810010}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug  3 18:28:25.282: INFO: Pod "nginx-deployment-7b8c6f4498-tp4l9" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-tp4l9,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-4252,SelfLink:/api/v1/namespaces/deployment-4252/pods/nginx-deployment-7b8c6f4498-tp4l9,UID:a8e96e92-86dc-42c5-9d27-86c5f501f7f3,ResourceVersion:42365,Generation:0,CreationTimestamp:2019-08-03 18:28:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 9b06261b-7e47-4174-854d-baa19f9a5a80 0xc003810077 0xc003810078}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-jgg8m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jgg8m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-jgg8m true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0038100e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003810100}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug  3 18:28:25.282: INFO: Pod "nginx-deployment-7b8c6f4498-ttv6s" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-ttv6s,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-4252,SelfLink:/api/v1/namespaces/deployment-4252/pods/nginx-deployment-7b8c6f4498-ttv6s,UID:79786040-31b6-4ad7-b15d-162a032f7543,ResourceVersion:42359,Generation:0,CreationTimestamp:2019-08-03 18:28:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 9b06261b-7e47-4174-854d-baa19f9a5a80 0xc003810167 0xc003810168}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-jgg8m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jgg8m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-jgg8m true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.188.31.32,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0038101e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003810200}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-03 18:28:25 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug  3 18:28:25.282: INFO: Pod "nginx-deployment-7b8c6f4498-vhw8t" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-vhw8t,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-4252,SelfLink:/api/v1/namespaces/deployment-4252/pods/nginx-deployment-7b8c6f4498-vhw8t,UID:3025c119-1487-4e8c-b41b-a498e23c4a3b,ResourceVersion:42355,Generation:0,CreationTimestamp:2019-08-03 18:28:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 9b06261b-7e47-4174-854d-baa19f9a5a80 0xc003810280 0xc003810281}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-jgg8m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jgg8m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-jgg8m true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.188.31.32,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0038102f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003810310}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-03 18:28:25 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-03 18:28:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-03 18:28:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-03 18:28:25 +0000 UTC  }],Message:,Reason:,HostIP:10.188.31.32,PodIP:,StartTime:2019-08-03 18:28:25 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug  3 18:28:25.282: INFO: Pod "nginx-deployment-7b8c6f4498-vvbmd" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-vvbmd,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-4252,SelfLink:/api/v1/namespaces/deployment-4252/pods/nginx-deployment-7b8c6f4498-vvbmd,UID:a6baf556-0038-4946-a657-a592519b779f,ResourceVersion:42343,Generation:0,CreationTimestamp:2019-08-03 18:28:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 9b06261b-7e47-4174-854d-baa19f9a5a80 0xc0038103d7 0xc0038103d8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-jgg8m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jgg8m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-jgg8m true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.188.31.24,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003810450} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003810470}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-03 18:28:25 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug  3 18:28:25.283: INFO: Pod "nginx-deployment-7b8c6f4498-xfv4q" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-xfv4q,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-4252,SelfLink:/api/v1/namespaces/deployment-4252/pods/nginx-deployment-7b8c6f4498-xfv4q,UID:18295632-eb42-4237-a3bc-5982413678ff,ResourceVersion:42358,Generation:0,CreationTimestamp:2019-08-03 18:28:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 9b06261b-7e47-4174-854d-baa19f9a5a80 0xc0038104f0 0xc0038104f1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-jgg8m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jgg8m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-jgg8m true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.188.31.32,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003810560} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003810580}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-03 18:28:25 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 18:28:25.283: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-4252" for this suite.
Aug  3 18:28:33.333: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 18:28:33.667: INFO: namespace deployment-4252 deletion completed in 8.368486575s

• [SLOW TEST:14.907 seconds]
[sig-apps] Deployment
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 18:28:33.667: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-1848
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-upd-40a86cae-0a17-447a-a97a-1c57bfc4c040
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 18:28:37.999: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1848" for this suite.
Aug  3 18:29:02.045: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 18:29:02.553: INFO: namespace configmap-1848 deletion completed in 24.539718802s

• [SLOW TEST:28.886 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 18:29:02.553: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-582
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
Aug  3 18:29:12.966: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
W0803 18:29:12.966564      17 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Aug  3 18:29:12.966: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-582" for this suite.
Aug  3 18:29:21.011: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 18:29:21.348: INFO: namespace gc-582 deletion completed in 8.370284847s

• [SLOW TEST:18.795 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 18:29:21.348: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-807
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-7cb80577-f44b-4974-a81d-ac9fa5c7a8a9
STEP: Creating a pod to test consume configMaps
Aug  3 18:29:21.637: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-5108c10f-f01d-4314-abb4-d2e2c919d9ee" in namespace "projected-807" to be "success or failure"
Aug  3 18:29:21.645: INFO: Pod "pod-projected-configmaps-5108c10f-f01d-4314-abb4-d2e2c919d9ee": Phase="Pending", Reason="", readiness=false. Elapsed: 7.53012ms
Aug  3 18:29:23.655: INFO: Pod "pod-projected-configmaps-5108c10f-f01d-4314-abb4-d2e2c919d9ee": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.017966006s
STEP: Saw pod success
Aug  3 18:29:23.656: INFO: Pod "pod-projected-configmaps-5108c10f-f01d-4314-abb4-d2e2c919d9ee" satisfied condition "success or failure"
Aug  3 18:29:23.664: INFO: Trying to get logs from node 10.188.31.32 pod pod-projected-configmaps-5108c10f-f01d-4314-abb4-d2e2c919d9ee container projected-configmap-volume-test: <nil>
STEP: delete the pod
Aug  3 18:29:23.709: INFO: Waiting for pod pod-projected-configmaps-5108c10f-f01d-4314-abb4-d2e2c919d9ee to disappear
Aug  3 18:29:23.716: INFO: Pod pod-projected-configmaps-5108c10f-f01d-4314-abb4-d2e2c919d9ee no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 18:29:23.716: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-807" for this suite.
Aug  3 18:29:29.762: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 18:29:30.089: INFO: namespace projected-807 deletion completed in 6.361547431s

• [SLOW TEST:8.741 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 18:29:30.094: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-9688
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod liveness-e8d506c1-dbfc-4aea-8c84-29990dde48c6 in namespace container-probe-9688
Aug  3 18:29:34.344: INFO: Started pod liveness-e8d506c1-dbfc-4aea-8c84-29990dde48c6 in namespace container-probe-9688
STEP: checking the pod's current state and verifying that restartCount is present
Aug  3 18:29:34.352: INFO: Initial restart count of pod liveness-e8d506c1-dbfc-4aea-8c84-29990dde48c6 is 0
Aug  3 18:29:44.407: INFO: Restart count of pod container-probe-9688/liveness-e8d506c1-dbfc-4aea-8c84-29990dde48c6 is now 1 (10.055606992s elapsed)
Aug  3 18:30:04.495: INFO: Restart count of pod container-probe-9688/liveness-e8d506c1-dbfc-4aea-8c84-29990dde48c6 is now 2 (30.143451651s elapsed)
Aug  3 18:30:24.589: INFO: Restart count of pod container-probe-9688/liveness-e8d506c1-dbfc-4aea-8c84-29990dde48c6 is now 3 (50.237420766s elapsed)
Aug  3 18:30:44.679: INFO: Restart count of pod container-probe-9688/liveness-e8d506c1-dbfc-4aea-8c84-29990dde48c6 is now 4 (1m10.327427787s elapsed)
Aug  3 18:31:46.973: INFO: Restart count of pod container-probe-9688/liveness-e8d506c1-dbfc-4aea-8c84-29990dde48c6 is now 5 (2m12.621378096s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 18:31:46.995: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-9688" for this suite.
Aug  3 18:31:53.053: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 18:31:53.377: INFO: namespace container-probe-9688 deletion completed in 6.356828735s

• [SLOW TEST:143.283 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 18:31:53.378: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replicaset-9632
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Aug  3 18:31:58.716: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 18:31:59.778: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-9632" for this suite.
Aug  3 18:32:33.840: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 18:32:34.145: INFO: namespace replicaset-9632 deletion completed in 34.355662279s

• [SLOW TEST:40.768 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 18:32:34.146: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-3065
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:81
Aug  3 18:32:34.357: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Aug  3 18:32:34.380: INFO: Waiting for terminating namespaces to be deleted...
Aug  3 18:32:34.389: INFO: 
Logging pods the kubelet thinks is on node 10.188.31.22 before test
Aug  3 18:32:34.418: INFO: sonobuoy-e2e-job-128cd56eea1c4929 from heptio-sonobuoy started at 2019-08-03 17:36:58 +0000 UTC (2 container statuses recorded)
Aug  3 18:32:34.418: INFO: 	Container e2e ready: true, restart count 0
Aug  3 18:32:34.418: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug  3 18:32:34.418: INFO: sonobuoy-systemd-logs-daemon-set-2824ab4c610f42f4-rvnnh from heptio-sonobuoy started at 2019-08-03 17:36:58 +0000 UTC (2 container statuses recorded)
Aug  3 18:32:34.418: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug  3 18:32:34.418: INFO: 	Container systemd-logs ready: true, restart count 0
Aug  3 18:32:34.418: INFO: ibm-master-proxy-static-10.188.31.22 from kube-system started at 2019-08-03 15:30:01 +0000 UTC (2 container statuses recorded)
Aug  3 18:32:34.418: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Aug  3 18:32:34.418: INFO: 	Container pause ready: true, restart count 0
Aug  3 18:32:34.418: INFO: ibm-kube-fluentd-25wz8 from kube-system started at 2019-08-03 15:30:14 +0000 UTC (1 container statuses recorded)
Aug  3 18:32:34.418: INFO: 	Container fluentd ready: true, restart count 0
Aug  3 18:32:34.418: INFO: calico-node-mc9wt from kube-system started at 2019-08-03 15:30:03 +0000 UTC (1 container statuses recorded)
Aug  3 18:32:34.418: INFO: 	Container calico-node ready: true, restart count 0
Aug  3 18:32:34.418: INFO: sonobuoy from heptio-sonobuoy started at 2019-08-03 17:36:53 +0000 UTC (1 container statuses recorded)
Aug  3 18:32:34.418: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Aug  3 18:32:34.418: INFO: ibm-keepalived-watcher-fkdg8 from kube-system started at 2019-08-03 15:30:03 +0000 UTC (1 container statuses recorded)
Aug  3 18:32:34.418: INFO: 	Container keepalived-watcher ready: true, restart count 0
Aug  3 18:32:34.419: INFO: 
Logging pods the kubelet thinks is on node 10.188.31.24 before test
Aug  3 18:32:34.460: INFO: ibm-master-proxy-static-10.188.31.24 from kube-system started at 2019-08-03 15:29:45 +0000 UTC (2 container statuses recorded)
Aug  3 18:32:34.460: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Aug  3 18:32:34.460: INFO: 	Container pause ready: true, restart count 0
Aug  3 18:32:34.460: INFO: ibm-storage-watcher-5c75867c7-sns8d from kube-system started at 2019-08-03 15:30:10 +0000 UTC (1 container statuses recorded)
Aug  3 18:32:34.460: INFO: 	Container ibm-storage-watcher-container ready: true, restart count 0
Aug  3 18:32:34.460: INFO: ibm-file-plugin-7b7f6d7b59-7vn9h from kube-system started at 2019-08-03 15:30:10 +0000 UTC (1 container statuses recorded)
Aug  3 18:32:34.460: INFO: 	Container ibm-file-plugin-container ready: true, restart count 0
Aug  3 18:32:34.460: INFO: calico-kube-controllers-7497554b5f-qrxg2 from kube-system started at 2019-08-03 15:30:10 +0000 UTC (1 container statuses recorded)
Aug  3 18:32:34.460: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Aug  3 18:32:34.460: INFO: coredns-7789d4b879-drqmd from kube-system started at 2019-08-03 15:30:10 +0000 UTC (1 container statuses recorded)
Aug  3 18:32:34.460: INFO: 	Container coredns ready: true, restart count 0
Aug  3 18:32:34.460: INFO: ibm-kube-fluentd-ltrhd from kube-system started at 2019-08-03 15:30:14 +0000 UTC (1 container statuses recorded)
Aug  3 18:32:34.460: INFO: 	Container fluentd ready: true, restart count 0
Aug  3 18:32:34.460: INFO: ibm-keepalived-watcher-z8jrg from kube-system started at 2019-08-03 15:29:52 +0000 UTC (1 container statuses recorded)
Aug  3 18:32:34.460: INFO: 	Container keepalived-watcher ready: true, restart count 0
Aug  3 18:32:34.460: INFO: kubernetes-dashboard-7756dcb98b-pc5ss from kube-system started at 2019-08-03 15:30:10 +0000 UTC (1 container statuses recorded)
Aug  3 18:32:34.460: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Aug  3 18:32:34.460: INFO: sonobuoy-systemd-logs-daemon-set-2824ab4c610f42f4-5422v from heptio-sonobuoy started at 2019-08-03 17:36:58 +0000 UTC (2 container statuses recorded)
Aug  3 18:32:34.460: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug  3 18:32:34.460: INFO: 	Container systemd-logs ready: true, restart count 0
Aug  3 18:32:34.460: INFO: calico-node-979kf from kube-system started at 2019-08-03 15:29:52 +0000 UTC (1 container statuses recorded)
Aug  3 18:32:34.460: INFO: 	Container calico-node ready: true, restart count 0
Aug  3 18:32:34.460: INFO: vpn-6554589999-thmhh from kube-system started at 2019-08-03 15:30:10 +0000 UTC (1 container statuses recorded)
Aug  3 18:32:34.460: INFO: 	Container vpn ready: true, restart count 0
Aug  3 18:32:34.460: INFO: coredns-autoscaler-7fbd4fd998-4tdzn from kube-system started at 2019-08-03 15:30:10 +0000 UTC (1 container statuses recorded)
Aug  3 18:32:34.461: INFO: 	Container autoscaler ready: true, restart count 0
Aug  3 18:32:34.461: INFO: 
Logging pods the kubelet thinks is on node 10.188.31.32 before test
Aug  3 18:32:34.484: INFO: ibm-master-proxy-static-10.188.31.32 from kube-system started at 2019-08-03 15:30:07 +0000 UTC (2 container statuses recorded)
Aug  3 18:32:34.484: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Aug  3 18:32:34.484: INFO: 	Container pause ready: true, restart count 0
Aug  3 18:32:34.484: INFO: metrics-server-66558f74f4-zfdzx from kube-system started at 2019-08-03 15:30:43 +0000 UTC (2 container statuses recorded)
Aug  3 18:32:34.484: INFO: 	Container metrics-server ready: true, restart count 0
Aug  3 18:32:34.484: INFO: 	Container metrics-server-nanny ready: true, restart count 0
Aug  3 18:32:34.484: INFO: ibm-kube-fluentd-chr7d from kube-system started at 2019-08-03 15:30:14 +0000 UTC (1 container statuses recorded)
Aug  3 18:32:34.484: INFO: 	Container fluentd ready: true, restart count 0
Aug  3 18:32:34.484: INFO: sonobuoy-systemd-logs-daemon-set-2824ab4c610f42f4-945kd from heptio-sonobuoy started at 2019-08-03 17:36:58 +0000 UTC (2 container statuses recorded)
Aug  3 18:32:34.484: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug  3 18:32:34.484: INFO: 	Container systemd-logs ready: true, restart count 0
Aug  3 18:32:34.484: INFO: ibm-keepalived-watcher-h74k2 from kube-system started at 2019-08-03 15:30:13 +0000 UTC (1 container statuses recorded)
Aug  3 18:32:34.484: INFO: 	Container keepalived-watcher ready: true, restart count 0
Aug  3 18:32:34.484: INFO: coredns-7789d4b879-46cbb from kube-system started at 2019-08-03 15:30:25 +0000 UTC (1 container statuses recorded)
Aug  3 18:32:34.484: INFO: 	Container coredns ready: true, restart count 0
Aug  3 18:32:34.484: INFO: calico-node-7mlcs from kube-system started at 2019-08-03 15:30:13 +0000 UTC (1 container statuses recorded)
Aug  3 18:32:34.484: INFO: 	Container calico-node ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: verifying the node has the label node 10.188.31.22
STEP: verifying the node has the label node 10.188.31.24
STEP: verifying the node has the label node 10.188.31.32
Aug  3 18:32:34.593: INFO: Pod sonobuoy requesting resource cpu=0m on Node 10.188.31.22
Aug  3 18:32:34.593: INFO: Pod sonobuoy-e2e-job-128cd56eea1c4929 requesting resource cpu=0m on Node 10.188.31.22
Aug  3 18:32:34.593: INFO: Pod sonobuoy-systemd-logs-daemon-set-2824ab4c610f42f4-5422v requesting resource cpu=0m on Node 10.188.31.24
Aug  3 18:32:34.593: INFO: Pod sonobuoy-systemd-logs-daemon-set-2824ab4c610f42f4-945kd requesting resource cpu=0m on Node 10.188.31.32
Aug  3 18:32:34.593: INFO: Pod sonobuoy-systemd-logs-daemon-set-2824ab4c610f42f4-rvnnh requesting resource cpu=0m on Node 10.188.31.22
Aug  3 18:32:34.593: INFO: Pod calico-kube-controllers-7497554b5f-qrxg2 requesting resource cpu=10m on Node 10.188.31.24
Aug  3 18:32:34.593: INFO: Pod calico-node-7mlcs requesting resource cpu=250m on Node 10.188.31.32
Aug  3 18:32:34.593: INFO: Pod calico-node-979kf requesting resource cpu=250m on Node 10.188.31.24
Aug  3 18:32:34.593: INFO: Pod calico-node-mc9wt requesting resource cpu=250m on Node 10.188.31.22
Aug  3 18:32:34.593: INFO: Pod coredns-7789d4b879-46cbb requesting resource cpu=100m on Node 10.188.31.32
Aug  3 18:32:34.593: INFO: Pod coredns-7789d4b879-drqmd requesting resource cpu=100m on Node 10.188.31.24
Aug  3 18:32:34.593: INFO: Pod coredns-autoscaler-7fbd4fd998-4tdzn requesting resource cpu=20m on Node 10.188.31.24
Aug  3 18:32:34.593: INFO: Pod ibm-file-plugin-7b7f6d7b59-7vn9h requesting resource cpu=50m on Node 10.188.31.24
Aug  3 18:32:34.593: INFO: Pod ibm-keepalived-watcher-fkdg8 requesting resource cpu=5m on Node 10.188.31.22
Aug  3 18:32:34.593: INFO: Pod ibm-keepalived-watcher-h74k2 requesting resource cpu=5m on Node 10.188.31.32
Aug  3 18:32:34.594: INFO: Pod ibm-keepalived-watcher-z8jrg requesting resource cpu=5m on Node 10.188.31.24
Aug  3 18:32:34.594: INFO: Pod ibm-kube-fluentd-25wz8 requesting resource cpu=25m on Node 10.188.31.22
Aug  3 18:32:34.594: INFO: Pod ibm-kube-fluentd-chr7d requesting resource cpu=25m on Node 10.188.31.32
Aug  3 18:32:34.594: INFO: Pod ibm-kube-fluentd-ltrhd requesting resource cpu=25m on Node 10.188.31.24
Aug  3 18:32:34.594: INFO: Pod ibm-master-proxy-static-10.188.31.22 requesting resource cpu=25m on Node 10.188.31.22
Aug  3 18:32:34.594: INFO: Pod ibm-master-proxy-static-10.188.31.24 requesting resource cpu=25m on Node 10.188.31.24
Aug  3 18:32:34.594: INFO: Pod ibm-master-proxy-static-10.188.31.32 requesting resource cpu=25m on Node 10.188.31.32
Aug  3 18:32:34.594: INFO: Pod ibm-storage-watcher-5c75867c7-sns8d requesting resource cpu=50m on Node 10.188.31.24
Aug  3 18:32:34.594: INFO: Pod kubernetes-dashboard-7756dcb98b-pc5ss requesting resource cpu=50m on Node 10.188.31.24
Aug  3 18:32:34.594: INFO: Pod metrics-server-66558f74f4-zfdzx requesting resource cpu=53m on Node 10.188.31.32
Aug  3 18:32:34.594: INFO: Pod vpn-6554589999-thmhh requesting resource cpu=5m on Node 10.188.31.24
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-08404629-a3fe-467d-a5dd-c6d2bd0f3ffc.15b77d4a8bbfe9e0], Reason = [Scheduled], Message = [Successfully assigned sched-pred-3065/filler-pod-08404629-a3fe-467d-a5dd-c6d2bd0f3ffc to 10.188.31.32]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-08404629-a3fe-467d-a5dd-c6d2bd0f3ffc.15b77d4acae9dc5f], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-08404629-a3fe-467d-a5dd-c6d2bd0f3ffc.15b77d4acef912d8], Reason = [Created], Message = [Created container filler-pod-08404629-a3fe-467d-a5dd-c6d2bd0f3ffc]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-08404629-a3fe-467d-a5dd-c6d2bd0f3ffc.15b77d4ada7e4e5c], Reason = [Started], Message = [Started container filler-pod-08404629-a3fe-467d-a5dd-c6d2bd0f3ffc]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-69000d57-808a-4f1b-9039-7d2a014cbc4b.15b77d4a8aad7137], Reason = [Scheduled], Message = [Successfully assigned sched-pred-3065/filler-pod-69000d57-808a-4f1b-9039-7d2a014cbc4b to 10.188.31.24]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-69000d57-808a-4f1b-9039-7d2a014cbc4b.15b77d4acae41eb5], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-69000d57-808a-4f1b-9039-7d2a014cbc4b.15b77d4acf453f15], Reason = [Created], Message = [Created container filler-pod-69000d57-808a-4f1b-9039-7d2a014cbc4b]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-69000d57-808a-4f1b-9039-7d2a014cbc4b.15b77d4adc437c14], Reason = [Started], Message = [Started container filler-pod-69000d57-808a-4f1b-9039-7d2a014cbc4b]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-85576441-5980-4aca-b8ab-a6e2d28eb25f.15b77d4a89b94b9b], Reason = [Scheduled], Message = [Successfully assigned sched-pred-3065/filler-pod-85576441-5980-4aca-b8ab-a6e2d28eb25f to 10.188.31.22]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-85576441-5980-4aca-b8ab-a6e2d28eb25f.15b77d4ac7abddc0], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-85576441-5980-4aca-b8ab-a6e2d28eb25f.15b77d4acc071e71], Reason = [Created], Message = [Created container filler-pod-85576441-5980-4aca-b8ab-a6e2d28eb25f]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-85576441-5980-4aca-b8ab-a6e2d28eb25f.15b77d4ad88447cc], Reason = [Started], Message = [Started container filler-pod-85576441-5980-4aca-b8ab-a6e2d28eb25f]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.15b77d4b7e79da2c], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 Insufficient cpu.]
STEP: removing the label node off the node 10.188.31.22
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node 10.188.31.24
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node 10.188.31.32
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 18:32:39.832: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-3065" for this suite.
Aug  3 18:32:45.879: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 18:32:46.202: INFO: namespace sched-pred-3065 deletion completed in 6.358677215s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:72

• [SLOW TEST:12.057 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 18:32:46.203: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename svc-latency
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svc-latency-3234
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating replication controller svc-latency-rc in namespace svc-latency-3234
I0803 18:32:46.633710      17 runners.go:180] Created replication controller with name: svc-latency-rc, namespace: svc-latency-3234, replica count: 1
I0803 18:32:47.684267      17 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0803 18:32:48.684488      17 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0803 18:32:49.684720      17 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Aug  3 18:32:49.809: INFO: Created: latency-svc-ntcj4
Aug  3 18:32:49.818: INFO: Got endpoints: latency-svc-ntcj4 [33.11237ms]
Aug  3 18:32:49.846: INFO: Created: latency-svc-p6qcl
Aug  3 18:32:49.854: INFO: Got endpoints: latency-svc-p6qcl [35.801813ms]
Aug  3 18:32:49.874: INFO: Created: latency-svc-fn6nq
Aug  3 18:32:49.887: INFO: Got endpoints: latency-svc-fn6nq [68.68404ms]
Aug  3 18:32:49.894: INFO: Created: latency-svc-djw99
Aug  3 18:32:49.902: INFO: Got endpoints: latency-svc-djw99 [83.692909ms]
Aug  3 18:32:49.903: INFO: Created: latency-svc-98sj2
Aug  3 18:32:49.911: INFO: Got endpoints: latency-svc-98sj2 [92.908862ms]
Aug  3 18:32:49.917: INFO: Created: latency-svc-pdhzc
Aug  3 18:32:49.926: INFO: Got endpoints: latency-svc-pdhzc [107.666007ms]
Aug  3 18:32:49.969: INFO: Created: latency-svc-l7s58
Aug  3 18:32:49.969: INFO: Created: latency-svc-fbb7v
Aug  3 18:32:49.969: INFO: Created: latency-svc-9jqpm
Aug  3 18:32:49.969: INFO: Got endpoints: latency-svc-fbb7v [150.564193ms]
Aug  3 18:32:49.969: INFO: Got endpoints: latency-svc-9jqpm [151.055142ms]
Aug  3 18:32:49.970: INFO: Got endpoints: latency-svc-l7s58 [150.670722ms]
Aug  3 18:32:49.979: INFO: Created: latency-svc-ts4xt
Aug  3 18:32:49.985: INFO: Got endpoints: latency-svc-ts4xt [165.851067ms]
Aug  3 18:32:49.992: INFO: Created: latency-svc-bvs4n
Aug  3 18:32:50.001: INFO: Got endpoints: latency-svc-bvs4n [182.382321ms]
Aug  3 18:32:50.007: INFO: Created: latency-svc-lnz88
Aug  3 18:32:50.017: INFO: Got endpoints: latency-svc-lnz88 [197.403174ms]
Aug  3 18:32:50.040: INFO: Created: latency-svc-4q9tz
Aug  3 18:32:50.053: INFO: Got endpoints: latency-svc-4q9tz [233.261911ms]
Aug  3 18:32:50.107: INFO: Created: latency-svc-fkvht
Aug  3 18:32:50.113: INFO: Got endpoints: latency-svc-fkvht [294.382316ms]
Aug  3 18:32:50.119: INFO: Created: latency-svc-kzsmz
Aug  3 18:32:50.126: INFO: Got endpoints: latency-svc-kzsmz [306.740763ms]
Aug  3 18:32:50.136: INFO: Created: latency-svc-qn6gq
Aug  3 18:32:50.144: INFO: Got endpoints: latency-svc-qn6gq [324.384505ms]
Aug  3 18:32:50.150: INFO: Created: latency-svc-tpq67
Aug  3 18:32:50.158: INFO: Got endpoints: latency-svc-tpq67 [304.261928ms]
Aug  3 18:32:50.163: INFO: Created: latency-svc-ggzn2
Aug  3 18:32:50.171: INFO: Got endpoints: latency-svc-ggzn2 [284.370533ms]
Aug  3 18:32:50.179: INFO: Created: latency-svc-p86x7
Aug  3 18:32:50.187: INFO: Got endpoints: latency-svc-p86x7 [285.170339ms]
Aug  3 18:32:50.192: INFO: Created: latency-svc-m47wk
Aug  3 18:32:50.205: INFO: Created: latency-svc-8h5bq
Aug  3 18:32:50.207: INFO: Got endpoints: latency-svc-m47wk [295.313884ms]
Aug  3 18:32:50.213: INFO: Got endpoints: latency-svc-8h5bq [286.347549ms]
Aug  3 18:32:50.221: INFO: Created: latency-svc-qpxzn
Aug  3 18:32:50.228: INFO: Got endpoints: latency-svc-qpxzn [258.914988ms]
Aug  3 18:32:50.234: INFO: Created: latency-svc-szgzs
Aug  3 18:32:50.245: INFO: Got endpoints: latency-svc-szgzs [275.116659ms]
Aug  3 18:32:50.251: INFO: Created: latency-svc-wt547
Aug  3 18:32:50.264: INFO: Got endpoints: latency-svc-wt547 [294.465346ms]
Aug  3 18:32:50.270: INFO: Created: latency-svc-g27hh
Aug  3 18:32:50.279: INFO: Got endpoints: latency-svc-g27hh [293.980334ms]
Aug  3 18:32:50.288: INFO: Created: latency-svc-8wnxm
Aug  3 18:32:50.295: INFO: Got endpoints: latency-svc-8wnxm [293.821234ms]
Aug  3 18:32:50.305: INFO: Created: latency-svc-qz8cg
Aug  3 18:32:50.315: INFO: Got endpoints: latency-svc-qz8cg [298.850158ms]
Aug  3 18:32:50.321: INFO: Created: latency-svc-grkvr
Aug  3 18:32:50.331: INFO: Got endpoints: latency-svc-grkvr [278.645798ms]
Aug  3 18:32:50.341: INFO: Created: latency-svc-vnqrf
Aug  3 18:32:50.349: INFO: Got endpoints: latency-svc-vnqrf [235.457331ms]
Aug  3 18:32:50.359: INFO: Created: latency-svc-jvxd8
Aug  3 18:32:50.364: INFO: Got endpoints: latency-svc-jvxd8 [32.201622ms]
Aug  3 18:32:50.372: INFO: Created: latency-svc-rq8mx
Aug  3 18:32:50.382: INFO: Got endpoints: latency-svc-rq8mx [255.2874ms]
Aug  3 18:32:50.386: INFO: Created: latency-svc-wn6hw
Aug  3 18:32:50.393: INFO: Got endpoints: latency-svc-wn6hw [248.748941ms]
Aug  3 18:32:50.399: INFO: Created: latency-svc-pqsdn
Aug  3 18:32:50.407: INFO: Got endpoints: latency-svc-pqsdn [248.680145ms]
Aug  3 18:32:50.414: INFO: Created: latency-svc-zlgmk
Aug  3 18:32:50.422: INFO: Got endpoints: latency-svc-zlgmk [250.394173ms]
Aug  3 18:32:50.428: INFO: Created: latency-svc-nlhtd
Aug  3 18:32:50.434: INFO: Got endpoints: latency-svc-nlhtd [246.504363ms]
Aug  3 18:32:50.440: INFO: Created: latency-svc-f8wl6
Aug  3 18:32:50.447: INFO: Got endpoints: latency-svc-f8wl6 [240.697161ms]
Aug  3 18:32:50.453: INFO: Created: latency-svc-xcssb
Aug  3 18:32:50.462: INFO: Got endpoints: latency-svc-xcssb [248.93236ms]
Aug  3 18:32:50.467: INFO: Created: latency-svc-84tgk
Aug  3 18:32:50.476: INFO: Got endpoints: latency-svc-84tgk [247.657616ms]
Aug  3 18:32:50.484: INFO: Created: latency-svc-7l8dl
Aug  3 18:32:50.492: INFO: Got endpoints: latency-svc-7l8dl [246.887156ms]
Aug  3 18:32:50.500: INFO: Created: latency-svc-5bd5r
Aug  3 18:32:50.507: INFO: Got endpoints: latency-svc-5bd5r [243.059638ms]
Aug  3 18:32:50.516: INFO: Created: latency-svc-4kfj5
Aug  3 18:32:50.527: INFO: Created: latency-svc-wmmfc
Aug  3 18:32:50.527: INFO: Got endpoints: latency-svc-4kfj5 [248.437235ms]
Aug  3 18:32:50.535: INFO: Got endpoints: latency-svc-wmmfc [239.199113ms]
Aug  3 18:32:50.553: INFO: Created: latency-svc-cm8qw
Aug  3 18:32:50.563: INFO: Got endpoints: latency-svc-cm8qw [247.944607ms]
Aug  3 18:32:50.571: INFO: Created: latency-svc-zw6cc
Aug  3 18:32:50.578: INFO: Got endpoints: latency-svc-zw6cc [229.203116ms]
Aug  3 18:32:50.583: INFO: Created: latency-svc-kbmsr
Aug  3 18:32:50.598: INFO: Got endpoints: latency-svc-kbmsr [234.382918ms]
Aug  3 18:32:50.600: INFO: Created: latency-svc-kdhpw
Aug  3 18:32:50.610: INFO: Got endpoints: latency-svc-kdhpw [228.043934ms]
Aug  3 18:32:50.613: INFO: Created: latency-svc-qrstt
Aug  3 18:32:50.621: INFO: Got endpoints: latency-svc-qrstt [228.68908ms]
Aug  3 18:32:50.628: INFO: Created: latency-svc-bk4s4
Aug  3 18:32:50.636: INFO: Got endpoints: latency-svc-bk4s4 [228.956596ms]
Aug  3 18:32:50.645: INFO: Created: latency-svc-rzf7f
Aug  3 18:32:50.654: INFO: Got endpoints: latency-svc-rzf7f [232.483694ms]
Aug  3 18:32:50.659: INFO: Created: latency-svc-st7wm
Aug  3 18:32:50.667: INFO: Got endpoints: latency-svc-st7wm [232.868979ms]
Aug  3 18:32:50.671: INFO: Created: latency-svc-55nw7
Aug  3 18:32:50.681: INFO: Got endpoints: latency-svc-55nw7 [233.465388ms]
Aug  3 18:32:50.685: INFO: Created: latency-svc-kc4qc
Aug  3 18:32:50.694: INFO: Got endpoints: latency-svc-kc4qc [232.256258ms]
Aug  3 18:32:50.700: INFO: Created: latency-svc-7fsxc
Aug  3 18:32:50.710: INFO: Got endpoints: latency-svc-7fsxc [234.302104ms]
Aug  3 18:32:50.718: INFO: Created: latency-svc-ljbrk
Aug  3 18:32:50.728: INFO: Got endpoints: latency-svc-ljbrk [236.424255ms]
Aug  3 18:32:50.734: INFO: Created: latency-svc-n2lj8
Aug  3 18:32:50.745: INFO: Got endpoints: latency-svc-n2lj8 [237.481849ms]
Aug  3 18:32:50.756: INFO: Created: latency-svc-679tz
Aug  3 18:32:50.760: INFO: Got endpoints: latency-svc-679tz [232.955796ms]
Aug  3 18:32:50.766: INFO: Created: latency-svc-bqx2f
Aug  3 18:32:50.776: INFO: Got endpoints: latency-svc-bqx2f [241.549025ms]
Aug  3 18:32:50.782: INFO: Created: latency-svc-znn7w
Aug  3 18:32:50.793: INFO: Got endpoints: latency-svc-znn7w [229.633224ms]
Aug  3 18:32:50.799: INFO: Created: latency-svc-rhhf9
Aug  3 18:32:50.807: INFO: Got endpoints: latency-svc-rhhf9 [228.87405ms]
Aug  3 18:32:50.813: INFO: Created: latency-svc-h4kqw
Aug  3 18:32:50.821: INFO: Got endpoints: latency-svc-h4kqw [223.16796ms]
Aug  3 18:32:50.829: INFO: Created: latency-svc-wn97z
Aug  3 18:32:50.835: INFO: Got endpoints: latency-svc-wn97z [225.072286ms]
Aug  3 18:32:50.842: INFO: Created: latency-svc-jrdcv
Aug  3 18:32:50.850: INFO: Got endpoints: latency-svc-jrdcv [228.458556ms]
Aug  3 18:32:50.855: INFO: Created: latency-svc-fhlj5
Aug  3 18:32:50.864: INFO: Got endpoints: latency-svc-fhlj5 [228.022941ms]
Aug  3 18:32:50.870: INFO: Created: latency-svc-vgzph
Aug  3 18:32:50.878: INFO: Got endpoints: latency-svc-vgzph [224.187744ms]
Aug  3 18:32:50.886: INFO: Created: latency-svc-vmrlr
Aug  3 18:32:50.895: INFO: Got endpoints: latency-svc-vmrlr [227.838602ms]
Aug  3 18:32:50.897: INFO: Created: latency-svc-k5p2h
Aug  3 18:32:50.911: INFO: Got endpoints: latency-svc-k5p2h [229.646004ms]
Aug  3 18:32:50.912: INFO: Created: latency-svc-6cpjx
Aug  3 18:32:50.920: INFO: Got endpoints: latency-svc-6cpjx [226.268308ms]
Aug  3 18:32:50.926: INFO: Created: latency-svc-c6g7f
Aug  3 18:32:50.934: INFO: Got endpoints: latency-svc-c6g7f [223.008532ms]
Aug  3 18:32:50.939: INFO: Created: latency-svc-r7pkq
Aug  3 18:32:50.948: INFO: Got endpoints: latency-svc-r7pkq [220.260755ms]
Aug  3 18:32:50.954: INFO: Created: latency-svc-pq425
Aug  3 18:32:50.961: INFO: Got endpoints: latency-svc-pq425 [216.330893ms]
Aug  3 18:32:50.968: INFO: Created: latency-svc-kw7tv
Aug  3 18:32:50.985: INFO: Got endpoints: latency-svc-kw7tv [224.963735ms]
Aug  3 18:32:50.998: INFO: Created: latency-svc-96tdk
Aug  3 18:32:51.005: INFO: Got endpoints: latency-svc-96tdk [228.281029ms]
Aug  3 18:32:51.011: INFO: Created: latency-svc-r9ksn
Aug  3 18:32:51.018: INFO: Got endpoints: latency-svc-r9ksn [224.336493ms]
Aug  3 18:32:51.025: INFO: Created: latency-svc-mnjcn
Aug  3 18:32:51.033: INFO: Got endpoints: latency-svc-mnjcn [226.056021ms]
Aug  3 18:32:51.040: INFO: Created: latency-svc-qb2mk
Aug  3 18:32:51.046: INFO: Got endpoints: latency-svc-qb2mk [225.132894ms]
Aug  3 18:32:51.054: INFO: Created: latency-svc-vw2wz
Aug  3 18:32:51.061: INFO: Got endpoints: latency-svc-vw2wz [226.452053ms]
Aug  3 18:32:51.069: INFO: Created: latency-svc-8mzdb
Aug  3 18:32:51.076: INFO: Got endpoints: latency-svc-8mzdb [226.089611ms]
Aug  3 18:32:51.084: INFO: Created: latency-svc-xk6wn
Aug  3 18:32:51.091: INFO: Got endpoints: latency-svc-xk6wn [227.101646ms]
Aug  3 18:32:51.097: INFO: Created: latency-svc-qn6bj
Aug  3 18:32:51.105: INFO: Got endpoints: latency-svc-qn6bj [226.357419ms]
Aug  3 18:32:51.111: INFO: Created: latency-svc-xpxmg
Aug  3 18:32:51.119: INFO: Got endpoints: latency-svc-xpxmg [224.478288ms]
Aug  3 18:32:51.125: INFO: Created: latency-svc-wf45x
Aug  3 18:32:51.138: INFO: Got endpoints: latency-svc-wf45x [227.796102ms]
Aug  3 18:32:51.140: INFO: Created: latency-svc-ghsgf
Aug  3 18:32:51.148: INFO: Got endpoints: latency-svc-ghsgf [228.127868ms]
Aug  3 18:32:51.156: INFO: Created: latency-svc-ph87v
Aug  3 18:32:51.166: INFO: Got endpoints: latency-svc-ph87v [232.123631ms]
Aug  3 18:32:51.169: INFO: Created: latency-svc-xwwgt
Aug  3 18:32:51.179: INFO: Got endpoints: latency-svc-xwwgt [230.551402ms]
Aug  3 18:32:51.182: INFO: Created: latency-svc-8jgml
Aug  3 18:32:51.197: INFO: Created: latency-svc-g5kf8
Aug  3 18:32:51.197: INFO: Got endpoints: latency-svc-8jgml [235.894777ms]
Aug  3 18:32:51.205: INFO: Got endpoints: latency-svc-g5kf8 [220.254899ms]
Aug  3 18:32:51.212: INFO: Created: latency-svc-vnskz
Aug  3 18:32:51.227: INFO: Got endpoints: latency-svc-vnskz [222.058526ms]
Aug  3 18:32:51.232: INFO: Created: latency-svc-7t4tg
Aug  3 18:32:51.241: INFO: Got endpoints: latency-svc-7t4tg [223.390116ms]
Aug  3 18:32:51.247: INFO: Created: latency-svc-fzfm4
Aug  3 18:32:51.256: INFO: Got endpoints: latency-svc-fzfm4 [222.832919ms]
Aug  3 18:32:51.263: INFO: Created: latency-svc-7stpb
Aug  3 18:32:51.271: INFO: Got endpoints: latency-svc-7stpb [224.407654ms]
Aug  3 18:32:51.277: INFO: Created: latency-svc-786mp
Aug  3 18:32:51.284: INFO: Got endpoints: latency-svc-786mp [222.49351ms]
Aug  3 18:32:51.290: INFO: Created: latency-svc-65j2j
Aug  3 18:32:51.297: INFO: Got endpoints: latency-svc-65j2j [221.404388ms]
Aug  3 18:32:51.303: INFO: Created: latency-svc-42vcr
Aug  3 18:32:51.312: INFO: Got endpoints: latency-svc-42vcr [220.856709ms]
Aug  3 18:32:51.319: INFO: Created: latency-svc-pxngb
Aug  3 18:32:51.327: INFO: Got endpoints: latency-svc-pxngb [221.659677ms]
Aug  3 18:32:51.335: INFO: Created: latency-svc-4bn5z
Aug  3 18:32:51.343: INFO: Got endpoints: latency-svc-4bn5z [223.897735ms]
Aug  3 18:32:51.354: INFO: Created: latency-svc-jt694
Aug  3 18:32:51.358: INFO: Got endpoints: latency-svc-jt694 [219.086501ms]
Aug  3 18:32:51.367: INFO: Created: latency-svc-kmlx2
Aug  3 18:32:51.372: INFO: Got endpoints: latency-svc-kmlx2 [223.925656ms]
Aug  3 18:32:51.379: INFO: Created: latency-svc-fq85n
Aug  3 18:32:51.393: INFO: Got endpoints: latency-svc-fq85n [227.394861ms]
Aug  3 18:32:51.398: INFO: Created: latency-svc-x552j
Aug  3 18:32:51.409: INFO: Got endpoints: latency-svc-x552j [229.799404ms]
Aug  3 18:32:51.418: INFO: Created: latency-svc-49w5l
Aug  3 18:32:51.426: INFO: Got endpoints: latency-svc-49w5l [228.953016ms]
Aug  3 18:32:51.431: INFO: Created: latency-svc-76658
Aug  3 18:32:51.442: INFO: Got endpoints: latency-svc-76658 [236.128092ms]
Aug  3 18:32:51.444: INFO: Created: latency-svc-29x5l
Aug  3 18:32:51.453: INFO: Got endpoints: latency-svc-29x5l [226.474334ms]
Aug  3 18:32:51.460: INFO: Created: latency-svc-kf792
Aug  3 18:32:51.468: INFO: Got endpoints: latency-svc-kf792 [227.036005ms]
Aug  3 18:32:51.473: INFO: Created: latency-svc-6bhqj
Aug  3 18:32:51.485: INFO: Got endpoints: latency-svc-6bhqj [228.76151ms]
Aug  3 18:32:51.486: INFO: Created: latency-svc-ssdvx
Aug  3 18:32:51.493: INFO: Got endpoints: latency-svc-ssdvx [221.839594ms]
Aug  3 18:32:51.499: INFO: Created: latency-svc-zn7zj
Aug  3 18:32:51.509: INFO: Got endpoints: latency-svc-zn7zj [225.042459ms]
Aug  3 18:32:51.515: INFO: Created: latency-svc-czc2r
Aug  3 18:32:51.526: INFO: Got endpoints: latency-svc-czc2r [228.539838ms]
Aug  3 18:32:51.528: INFO: Created: latency-svc-hdkxh
Aug  3 18:32:51.536: INFO: Got endpoints: latency-svc-hdkxh [224.085911ms]
Aug  3 18:32:51.542: INFO: Created: latency-svc-v7l8d
Aug  3 18:32:51.554: INFO: Got endpoints: latency-svc-v7l8d [227.088533ms]
Aug  3 18:32:51.559: INFO: Created: latency-svc-nllh8
Aug  3 18:32:51.574: INFO: Created: latency-svc-nt28q
Aug  3 18:32:51.574: INFO: Got endpoints: latency-svc-nllh8 [230.605556ms]
Aug  3 18:32:51.580: INFO: Got endpoints: latency-svc-nt28q [222.232777ms]
Aug  3 18:32:51.587: INFO: Created: latency-svc-7fxd7
Aug  3 18:32:51.594: INFO: Got endpoints: latency-svc-7fxd7 [221.252838ms]
Aug  3 18:32:51.609: INFO: Created: latency-svc-78pvv
Aug  3 18:32:51.616: INFO: Got endpoints: latency-svc-78pvv [222.929539ms]
Aug  3 18:32:51.617: INFO: Created: latency-svc-pn582
Aug  3 18:32:51.622: INFO: Got endpoints: latency-svc-pn582 [212.893447ms]
Aug  3 18:32:51.629: INFO: Created: latency-svc-895jh
Aug  3 18:32:51.635: INFO: Got endpoints: latency-svc-895jh [208.949404ms]
Aug  3 18:32:51.643: INFO: Created: latency-svc-6hcn8
Aug  3 18:32:51.652: INFO: Got endpoints: latency-svc-6hcn8 [210.750927ms]
Aug  3 18:32:51.656: INFO: Created: latency-svc-h9gz2
Aug  3 18:32:51.665: INFO: Got endpoints: latency-svc-h9gz2 [211.246408ms]
Aug  3 18:32:51.671: INFO: Created: latency-svc-ggxn7
Aug  3 18:32:51.679: INFO: Got endpoints: latency-svc-ggxn7 [210.764705ms]
Aug  3 18:32:51.692: INFO: Created: latency-svc-w5cvh
Aug  3 18:32:51.694: INFO: Got endpoints: latency-svc-w5cvh [209.280545ms]
Aug  3 18:32:51.701: INFO: Created: latency-svc-kgz4w
Aug  3 18:32:51.708: INFO: Got endpoints: latency-svc-kgz4w [214.806825ms]
Aug  3 18:32:51.714: INFO: Created: latency-svc-h5pbh
Aug  3 18:32:51.722: INFO: Got endpoints: latency-svc-h5pbh [212.900445ms]
Aug  3 18:32:51.728: INFO: Created: latency-svc-48k6x
Aug  3 18:32:51.736: INFO: Got endpoints: latency-svc-48k6x [210.357251ms]
Aug  3 18:32:51.743: INFO: Created: latency-svc-f9c5z
Aug  3 18:32:51.753: INFO: Got endpoints: latency-svc-f9c5z [216.963547ms]
Aug  3 18:32:51.757: INFO: Created: latency-svc-5mlxh
Aug  3 18:32:51.768: INFO: Got endpoints: latency-svc-5mlxh [214.745187ms]
Aug  3 18:32:51.771: INFO: Created: latency-svc-rcx4h
Aug  3 18:32:51.779: INFO: Got endpoints: latency-svc-rcx4h [204.973128ms]
Aug  3 18:32:51.785: INFO: Created: latency-svc-gk4fs
Aug  3 18:32:51.793: INFO: Got endpoints: latency-svc-gk4fs [213.363689ms]
Aug  3 18:32:51.800: INFO: Created: latency-svc-d9d5w
Aug  3 18:32:51.808: INFO: Got endpoints: latency-svc-d9d5w [214.696001ms]
Aug  3 18:32:51.814: INFO: Created: latency-svc-hcx58
Aug  3 18:32:51.822: INFO: Got endpoints: latency-svc-hcx58 [205.958772ms]
Aug  3 18:32:51.829: INFO: Created: latency-svc-zzxq5
Aug  3 18:32:51.838: INFO: Got endpoints: latency-svc-zzxq5 [216.315646ms]
Aug  3 18:32:51.848: INFO: Created: latency-svc-f9xcm
Aug  3 18:32:51.851: INFO: Got endpoints: latency-svc-f9xcm [215.721726ms]
Aug  3 18:32:51.856: INFO: Created: latency-svc-fdzbp
Aug  3 18:32:51.865: INFO: Got endpoints: latency-svc-fdzbp [212.567168ms]
Aug  3 18:32:51.870: INFO: Created: latency-svc-ptr6d
Aug  3 18:32:51.879: INFO: Got endpoints: latency-svc-ptr6d [214.744229ms]
Aug  3 18:32:51.888: INFO: Created: latency-svc-xctmp
Aug  3 18:32:51.895: INFO: Got endpoints: latency-svc-xctmp [215.589586ms]
Aug  3 18:32:51.900: INFO: Created: latency-svc-clc4l
Aug  3 18:32:51.912: INFO: Got endpoints: latency-svc-clc4l [217.844674ms]
Aug  3 18:32:51.918: INFO: Created: latency-svc-7bvvf
Aug  3 18:32:51.925: INFO: Got endpoints: latency-svc-7bvvf [217.751354ms]
Aug  3 18:32:51.933: INFO: Created: latency-svc-ct98x
Aug  3 18:32:51.941: INFO: Got endpoints: latency-svc-ct98x [219.123962ms]
Aug  3 18:32:51.949: INFO: Created: latency-svc-pksks
Aug  3 18:32:51.955: INFO: Got endpoints: latency-svc-pksks [218.403504ms]
Aug  3 18:32:51.962: INFO: Created: latency-svc-nx244
Aug  3 18:32:51.969: INFO: Got endpoints: latency-svc-nx244 [216.073925ms]
Aug  3 18:32:51.977: INFO: Created: latency-svc-g8f8p
Aug  3 18:32:51.984: INFO: Got endpoints: latency-svc-g8f8p [215.217992ms]
Aug  3 18:32:51.994: INFO: Created: latency-svc-rnkmm
Aug  3 18:32:52.004: INFO: Got endpoints: latency-svc-rnkmm [225.268703ms]
Aug  3 18:32:52.012: INFO: Created: latency-svc-64wpt
Aug  3 18:32:52.022: INFO: Got endpoints: latency-svc-64wpt [228.987476ms]
Aug  3 18:32:52.031: INFO: Created: latency-svc-nztmc
Aug  3 18:32:52.042: INFO: Got endpoints: latency-svc-nztmc [233.617102ms]
Aug  3 18:32:52.046: INFO: Created: latency-svc-d6dkk
Aug  3 18:32:52.055: INFO: Got endpoints: latency-svc-d6dkk [233.152628ms]
Aug  3 18:32:52.062: INFO: Created: latency-svc-kdfg2
Aug  3 18:32:52.070: INFO: Got endpoints: latency-svc-kdfg2 [231.250311ms]
Aug  3 18:32:52.089: INFO: Created: latency-svc-hwqcz
Aug  3 18:32:52.090: INFO: Got endpoints: latency-svc-hwqcz [238.724818ms]
Aug  3 18:32:52.104: INFO: Created: latency-svc-99mjj
Aug  3 18:32:52.106: INFO: Got endpoints: latency-svc-99mjj [240.627584ms]
Aug  3 18:32:52.112: INFO: Created: latency-svc-qvpln
Aug  3 18:32:52.119: INFO: Got endpoints: latency-svc-qvpln [239.362318ms]
Aug  3 18:32:52.127: INFO: Created: latency-svc-l8q5j
Aug  3 18:32:52.134: INFO: Got endpoints: latency-svc-l8q5j [239.715134ms]
Aug  3 18:32:52.142: INFO: Created: latency-svc-r84bk
Aug  3 18:32:52.148: INFO: Got endpoints: latency-svc-r84bk [235.809864ms]
Aug  3 18:32:52.153: INFO: Created: latency-svc-pbcr9
Aug  3 18:32:52.163: INFO: Got endpoints: latency-svc-pbcr9 [237.990681ms]
Aug  3 18:32:52.167: INFO: Created: latency-svc-vl46t
Aug  3 18:32:52.175: INFO: Got endpoints: latency-svc-vl46t [233.389452ms]
Aug  3 18:32:52.180: INFO: Created: latency-svc-n6tqs
Aug  3 18:32:52.189: INFO: Got endpoints: latency-svc-n6tqs [234.339974ms]
Aug  3 18:32:52.194: INFO: Created: latency-svc-bmjwl
Aug  3 18:32:52.204: INFO: Got endpoints: latency-svc-bmjwl [234.921549ms]
Aug  3 18:32:52.208: INFO: Created: latency-svc-vxnl2
Aug  3 18:32:52.215: INFO: Got endpoints: latency-svc-vxnl2 [230.860654ms]
Aug  3 18:32:52.220: INFO: Created: latency-svc-77v9q
Aug  3 18:32:52.230: INFO: Got endpoints: latency-svc-77v9q [225.888704ms]
Aug  3 18:32:52.239: INFO: Created: latency-svc-k4p8b
Aug  3 18:32:52.244: INFO: Got endpoints: latency-svc-k4p8b [222.01361ms]
Aug  3 18:32:52.247: INFO: Created: latency-svc-bpwqh
Aug  3 18:32:52.257: INFO: Got endpoints: latency-svc-bpwqh [214.359486ms]
Aug  3 18:32:52.264: INFO: Created: latency-svc-b984k
Aug  3 18:32:52.272: INFO: Got endpoints: latency-svc-b984k [216.202877ms]
Aug  3 18:32:52.277: INFO: Created: latency-svc-ghq6g
Aug  3 18:32:52.284: INFO: Got endpoints: latency-svc-ghq6g [214.480175ms]
Aug  3 18:32:52.302: INFO: Created: latency-svc-mqwkq
Aug  3 18:32:52.306: INFO: Got endpoints: latency-svc-mqwkq [216.385782ms]
Aug  3 18:32:52.307: INFO: Created: latency-svc-fdz4x
Aug  3 18:32:52.316: INFO: Got endpoints: latency-svc-fdz4x [209.96736ms]
Aug  3 18:32:52.319: INFO: Created: latency-svc-96cwk
Aug  3 18:32:52.330: INFO: Got endpoints: latency-svc-96cwk [211.4198ms]
Aug  3 18:32:52.335: INFO: Created: latency-svc-jwt77
Aug  3 18:32:52.345: INFO: Got endpoints: latency-svc-jwt77 [210.874756ms]
Aug  3 18:32:52.353: INFO: Created: latency-svc-t8h26
Aug  3 18:32:52.359: INFO: Got endpoints: latency-svc-t8h26 [211.305052ms]
Aug  3 18:32:52.370: INFO: Created: latency-svc-nxxhr
Aug  3 18:32:52.376: INFO: Got endpoints: latency-svc-nxxhr [212.268537ms]
Aug  3 18:32:52.381: INFO: Created: latency-svc-94mjf
Aug  3 18:32:52.390: INFO: Got endpoints: latency-svc-94mjf [215.746571ms]
Aug  3 18:32:52.405: INFO: Created: latency-svc-57fjx
Aug  3 18:32:52.413: INFO: Created: latency-svc-bcl72
Aug  3 18:32:52.414: INFO: Got endpoints: latency-svc-57fjx [225.007654ms]
Aug  3 18:32:52.429: INFO: Got endpoints: latency-svc-bcl72 [225.178696ms]
Aug  3 18:32:52.433: INFO: Created: latency-svc-bnpxp
Aug  3 18:32:52.441: INFO: Got endpoints: latency-svc-bnpxp [226.415156ms]
Aug  3 18:32:52.448: INFO: Created: latency-svc-c7dmf
Aug  3 18:32:52.462: INFO: Created: latency-svc-7rt6m
Aug  3 18:32:52.463: INFO: Got endpoints: latency-svc-c7dmf [232.406663ms]
Aug  3 18:32:52.469: INFO: Got endpoints: latency-svc-7rt6m [224.112582ms]
Aug  3 18:32:52.475: INFO: Created: latency-svc-zrcss
Aug  3 18:32:52.481: INFO: Got endpoints: latency-svc-zrcss [224.615819ms]
Aug  3 18:32:52.488: INFO: Created: latency-svc-8px56
Aug  3 18:32:52.496: INFO: Got endpoints: latency-svc-8px56 [223.88194ms]
Aug  3 18:32:52.500: INFO: Created: latency-svc-grljz
Aug  3 18:32:52.509: INFO: Got endpoints: latency-svc-grljz [224.577728ms]
Aug  3 18:32:52.514: INFO: Created: latency-svc-db9fs
Aug  3 18:32:52.525: INFO: Got endpoints: latency-svc-db9fs [218.696224ms]
Aug  3 18:32:52.527: INFO: Created: latency-svc-57pqb
Aug  3 18:32:52.534: INFO: Got endpoints: latency-svc-57pqb [218.045749ms]
Aug  3 18:32:52.544: INFO: Created: latency-svc-htd25
Aug  3 18:32:52.553: INFO: Got endpoints: latency-svc-htd25 [223.183959ms]
Aug  3 18:32:52.557: INFO: Created: latency-svc-lswll
Aug  3 18:32:52.564: INFO: Got endpoints: latency-svc-lswll [218.691036ms]
Aug  3 18:32:52.570: INFO: Created: latency-svc-rj7n8
Aug  3 18:32:52.579: INFO: Got endpoints: latency-svc-rj7n8 [218.939319ms]
Aug  3 18:32:52.582: INFO: Created: latency-svc-7z8xv
Aug  3 18:32:52.591: INFO: Got endpoints: latency-svc-7z8xv [214.942485ms]
Aug  3 18:32:52.602: INFO: Created: latency-svc-q5zt6
Aug  3 18:32:52.606: INFO: Got endpoints: latency-svc-q5zt6 [215.103197ms]
Aug  3 18:32:52.612: INFO: Created: latency-svc-fjdrd
Aug  3 18:32:52.618: INFO: Got endpoints: latency-svc-fjdrd [203.499979ms]
Aug  3 18:32:52.628: INFO: Created: latency-svc-dllt9
Aug  3 18:32:52.644: INFO: Got endpoints: latency-svc-dllt9 [214.77788ms]
Aug  3 18:32:52.645: INFO: Created: latency-svc-2jscm
Aug  3 18:32:52.653: INFO: Got endpoints: latency-svc-2jscm [212.012984ms]
Aug  3 18:32:52.662: INFO: Created: latency-svc-m44m9
Aug  3 18:32:52.669: INFO: Got endpoints: latency-svc-m44m9 [206.561007ms]
Aug  3 18:32:52.675: INFO: Created: latency-svc-hxf29
Aug  3 18:32:52.683: INFO: Got endpoints: latency-svc-hxf29 [214.001435ms]
Aug  3 18:32:52.694: INFO: Created: latency-svc-5vbfw
Aug  3 18:32:52.697: INFO: Got endpoints: latency-svc-5vbfw [215.411775ms]
Aug  3 18:32:52.711: INFO: Created: latency-svc-5hqxq
Aug  3 18:32:52.719: INFO: Got endpoints: latency-svc-5hqxq [223.565069ms]
Aug  3 18:32:52.725: INFO: Created: latency-svc-xgljd
Aug  3 18:32:52.735: INFO: Got endpoints: latency-svc-xgljd [226.477178ms]
Aug  3 18:32:52.741: INFO: Created: latency-svc-8nxfc
Aug  3 18:32:52.751: INFO: Got endpoints: latency-svc-8nxfc [225.905636ms]
Aug  3 18:32:52.758: INFO: Created: latency-svc-lgc5n
Aug  3 18:32:52.767: INFO: Got endpoints: latency-svc-lgc5n [232.880946ms]
Aug  3 18:32:52.772: INFO: Created: latency-svc-8dbvh
Aug  3 18:32:52.780: INFO: Got endpoints: latency-svc-8dbvh [226.821057ms]
Aug  3 18:32:52.786: INFO: Created: latency-svc-tm5wt
Aug  3 18:32:52.795: INFO: Got endpoints: latency-svc-tm5wt [230.993399ms]
Aug  3 18:32:52.803: INFO: Created: latency-svc-qzg6s
Aug  3 18:32:52.812: INFO: Got endpoints: latency-svc-qzg6s [233.270606ms]
Aug  3 18:32:52.819: INFO: Created: latency-svc-prh9k
Aug  3 18:32:52.829: INFO: Got endpoints: latency-svc-prh9k [238.354875ms]
Aug  3 18:32:52.839: INFO: Created: latency-svc-9fx6j
Aug  3 18:32:52.850: INFO: Got endpoints: latency-svc-9fx6j [244.646167ms]
Aug  3 18:32:52.855: INFO: Created: latency-svc-f7c6d
Aug  3 18:32:52.866: INFO: Got endpoints: latency-svc-f7c6d [248.080653ms]
Aug  3 18:32:52.870: INFO: Created: latency-svc-pmmsm
Aug  3 18:32:52.878: INFO: Got endpoints: latency-svc-pmmsm [234.082405ms]
Aug  3 18:32:52.886: INFO: Created: latency-svc-7ln2q
Aug  3 18:32:52.894: INFO: Got endpoints: latency-svc-7ln2q [241.161594ms]
Aug  3 18:32:52.902: INFO: Created: latency-svc-xxm6h
Aug  3 18:32:52.908: INFO: Got endpoints: latency-svc-xxm6h [238.735298ms]
Aug  3 18:32:52.915: INFO: Created: latency-svc-9tslr
Aug  3 18:32:52.923: INFO: Got endpoints: latency-svc-9tslr [240.081603ms]
Aug  3 18:32:52.923: INFO: Latencies: [32.201622ms 35.801813ms 68.68404ms 83.692909ms 92.908862ms 107.666007ms 150.564193ms 150.670722ms 151.055142ms 165.851067ms 182.382321ms 197.403174ms 203.499979ms 204.973128ms 205.958772ms 206.561007ms 208.949404ms 209.280545ms 209.96736ms 210.357251ms 210.750927ms 210.764705ms 210.874756ms 211.246408ms 211.305052ms 211.4198ms 212.012984ms 212.268537ms 212.567168ms 212.893447ms 212.900445ms 213.363689ms 214.001435ms 214.359486ms 214.480175ms 214.696001ms 214.744229ms 214.745187ms 214.77788ms 214.806825ms 214.942485ms 215.103197ms 215.217992ms 215.411775ms 215.589586ms 215.721726ms 215.746571ms 216.073925ms 216.202877ms 216.315646ms 216.330893ms 216.385782ms 216.963547ms 217.751354ms 217.844674ms 218.045749ms 218.403504ms 218.691036ms 218.696224ms 218.939319ms 219.086501ms 219.123962ms 220.254899ms 220.260755ms 220.856709ms 221.252838ms 221.404388ms 221.659677ms 221.839594ms 222.01361ms 222.058526ms 222.232777ms 222.49351ms 222.832919ms 222.929539ms 223.008532ms 223.16796ms 223.183959ms 223.390116ms 223.565069ms 223.88194ms 223.897735ms 223.925656ms 224.085911ms 224.112582ms 224.187744ms 224.336493ms 224.407654ms 224.478288ms 224.577728ms 224.615819ms 224.963735ms 225.007654ms 225.042459ms 225.072286ms 225.132894ms 225.178696ms 225.268703ms 225.888704ms 225.905636ms 226.056021ms 226.089611ms 226.268308ms 226.357419ms 226.415156ms 226.452053ms 226.474334ms 226.477178ms 226.821057ms 227.036005ms 227.088533ms 227.101646ms 227.394861ms 227.796102ms 227.838602ms 228.022941ms 228.043934ms 228.127868ms 228.281029ms 228.458556ms 228.539838ms 228.68908ms 228.76151ms 228.87405ms 228.953016ms 228.956596ms 228.987476ms 229.203116ms 229.633224ms 229.646004ms 229.799404ms 230.551402ms 230.605556ms 230.860654ms 230.993399ms 231.250311ms 232.123631ms 232.256258ms 232.406663ms 232.483694ms 232.868979ms 232.880946ms 232.955796ms 233.152628ms 233.261911ms 233.270606ms 233.389452ms 233.465388ms 233.617102ms 234.082405ms 234.302104ms 234.339974ms 234.382918ms 234.921549ms 235.457331ms 235.809864ms 235.894777ms 236.128092ms 236.424255ms 237.481849ms 237.990681ms 238.354875ms 238.724818ms 238.735298ms 239.199113ms 239.362318ms 239.715134ms 240.081603ms 240.627584ms 240.697161ms 241.161594ms 241.549025ms 243.059638ms 244.646167ms 246.504363ms 246.887156ms 247.657616ms 247.944607ms 248.080653ms 248.437235ms 248.680145ms 248.748941ms 248.93236ms 250.394173ms 255.2874ms 258.914988ms 275.116659ms 278.645798ms 284.370533ms 285.170339ms 286.347549ms 293.821234ms 293.980334ms 294.382316ms 294.465346ms 295.313884ms 298.850158ms 304.261928ms 306.740763ms 324.384505ms]
Aug  3 18:32:52.923: INFO: 50 %ile: 226.056021ms
Aug  3 18:32:52.923: INFO: 90 %ile: 248.680145ms
Aug  3 18:32:52.923: INFO: 99 %ile: 306.740763ms
Aug  3 18:32:52.923: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 18:32:52.923: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svc-latency-3234" for this suite.
Aug  3 18:33:10.965: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 18:33:11.288: INFO: namespace svc-latency-3234 deletion completed in 18.353918026s

• [SLOW TEST:25.085 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should not be very high  [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 18:33:11.289: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7853
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-projected-all-test-volume-9edaa111-f1bf-4797-8d62-7ee1ef0c535f
STEP: Creating secret with name secret-projected-all-test-volume-6942610f-db7a-43cc-a07a-960aae8038a1
STEP: Creating a pod to test Check all projections for projected volume plugin
Aug  3 18:33:11.541: INFO: Waiting up to 5m0s for pod "projected-volume-d25dbfba-928f-49b0-86c8-4cf15af87444" in namespace "projected-7853" to be "success or failure"
Aug  3 18:33:11.549: INFO: Pod "projected-volume-d25dbfba-928f-49b0-86c8-4cf15af87444": Phase="Pending", Reason="", readiness=false. Elapsed: 7.402602ms
Aug  3 18:33:13.557: INFO: Pod "projected-volume-d25dbfba-928f-49b0-86c8-4cf15af87444": Phase="Running", Reason="", readiness=true. Elapsed: 2.015842392s
Aug  3 18:33:15.566: INFO: Pod "projected-volume-d25dbfba-928f-49b0-86c8-4cf15af87444": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.024850947s
STEP: Saw pod success
Aug  3 18:33:15.566: INFO: Pod "projected-volume-d25dbfba-928f-49b0-86c8-4cf15af87444" satisfied condition "success or failure"
Aug  3 18:33:15.574: INFO: Trying to get logs from node 10.188.31.32 pod projected-volume-d25dbfba-928f-49b0-86c8-4cf15af87444 container projected-all-volume-test: <nil>
STEP: delete the pod
Aug  3 18:33:15.635: INFO: Waiting for pod projected-volume-d25dbfba-928f-49b0-86c8-4cf15af87444 to disappear
Aug  3 18:33:15.642: INFO: Pod projected-volume-d25dbfba-928f-49b0-86c8-4cf15af87444 no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 18:33:15.642: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7853" for this suite.
Aug  3 18:33:21.689: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 18:33:22.013: INFO: namespace projected-7853 deletion completed in 6.358986308s

• [SLOW TEST:10.725 seconds]
[sig-storage] Projected combined
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_combined.go:31
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 18:33:22.014: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-9605
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating secret secrets-9605/secret-test-cfa5fa72-e434-4365-b80a-6314d3080c0f
STEP: Creating a pod to test consume secrets
Aug  3 18:33:22.258: INFO: Waiting up to 5m0s for pod "pod-configmaps-7cc1b2b4-355d-4e7b-8c11-59591a0da98a" in namespace "secrets-9605" to be "success or failure"
Aug  3 18:33:22.271: INFO: Pod "pod-configmaps-7cc1b2b4-355d-4e7b-8c11-59591a0da98a": Phase="Pending", Reason="", readiness=false. Elapsed: 12.862874ms
Aug  3 18:33:24.289: INFO: Pod "pod-configmaps-7cc1b2b4-355d-4e7b-8c11-59591a0da98a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.030730819s
STEP: Saw pod success
Aug  3 18:33:24.289: INFO: Pod "pod-configmaps-7cc1b2b4-355d-4e7b-8c11-59591a0da98a" satisfied condition "success or failure"
Aug  3 18:33:24.297: INFO: Trying to get logs from node 10.188.31.32 pod pod-configmaps-7cc1b2b4-355d-4e7b-8c11-59591a0da98a container env-test: <nil>
STEP: delete the pod
Aug  3 18:33:24.340: INFO: Waiting for pod pod-configmaps-7cc1b2b4-355d-4e7b-8c11-59591a0da98a to disappear
Aug  3 18:33:24.347: INFO: Pod pod-configmaps-7cc1b2b4-355d-4e7b-8c11-59591a0da98a no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 18:33:24.347: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9605" for this suite.
Aug  3 18:33:30.392: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 18:33:30.707: INFO: namespace secrets-9605 deletion completed in 6.34917084s

• [SLOW TEST:8.693 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 18:33:30.711: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-9142
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Performing setup for networking test in namespace pod-network-test-9142
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Aug  3 18:33:30.919: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Aug  3 18:33:57.124: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 172.30.199.80 8081 | grep -v '^\s*$'] Namespace:pod-network-test-9142 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug  3 18:33:57.124: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
Aug  3 18:33:58.409: INFO: Found all expected endpoints: [netserver-0]
Aug  3 18:33:58.417: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 172.30.72.80 8081 | grep -v '^\s*$'] Namespace:pod-network-test-9142 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug  3 18:33:58.417: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
Aug  3 18:33:59.735: INFO: Found all expected endpoints: [netserver-1]
Aug  3 18:33:59.742: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 172.30.44.103 8081 | grep -v '^\s*$'] Namespace:pod-network-test-9142 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug  3 18:33:59.742: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
Aug  3 18:34:01.040: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 18:34:01.040: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-9142" for this suite.
Aug  3 18:34:25.096: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 18:34:25.440: INFO: namespace pod-network-test-9142 deletion completed in 24.377859865s

• [SLOW TEST:54.730 seconds]
[sig-network] Networking
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 18:34:25.444: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Aug  3 18:34:25.685: INFO: Waiting up to 5m0s for pod "downwardapi-volume-db11b813-e0ca-4478-a706-5e230c8861de" in namespace "projected-3" to be "success or failure"
Aug  3 18:34:25.695: INFO: Pod "downwardapi-volume-db11b813-e0ca-4478-a706-5e230c8861de": Phase="Pending", Reason="", readiness=false. Elapsed: 9.842095ms
Aug  3 18:34:27.706: INFO: Pod "downwardapi-volume-db11b813-e0ca-4478-a706-5e230c8861de": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020594291s
STEP: Saw pod success
Aug  3 18:34:27.706: INFO: Pod "downwardapi-volume-db11b813-e0ca-4478-a706-5e230c8861de" satisfied condition "success or failure"
Aug  3 18:34:27.713: INFO: Trying to get logs from node 10.188.31.32 pod downwardapi-volume-db11b813-e0ca-4478-a706-5e230c8861de container client-container: <nil>
STEP: delete the pod
Aug  3 18:34:27.769: INFO: Waiting for pod downwardapi-volume-db11b813-e0ca-4478-a706-5e230c8861de to disappear
Aug  3 18:34:27.778: INFO: Pod downwardapi-volume-db11b813-e0ca-4478-a706-5e230c8861de no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 18:34:27.779: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3" for this suite.
Aug  3 18:34:33.826: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 18:34:34.160: INFO: namespace projected-3 deletion completed in 6.365952629s

• [SLOW TEST:8.716 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 18:34:34.160: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-2297
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Performing setup for networking test in namespace pod-network-test-2297
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Aug  3 18:34:34.374: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Aug  3 18:34:54.562: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://172.30.72.83:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-2297 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug  3 18:34:54.562: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
Aug  3 18:34:54.845: INFO: Found all expected endpoints: [netserver-0]
Aug  3 18:34:54.853: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://172.30.199.81:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-2297 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug  3 18:34:54.853: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
Aug  3 18:34:55.194: INFO: Found all expected endpoints: [netserver-1]
Aug  3 18:34:55.204: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://172.30.44.104:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-2297 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug  3 18:34:55.204: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
Aug  3 18:34:55.498: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 18:34:55.498: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-2297" for this suite.
Aug  3 18:35:19.545: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 18:35:19.884: INFO: namespace pod-network-test-2297 deletion completed in 24.373052689s

• [SLOW TEST:45.724 seconds]
[sig-network] Networking
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 18:35:19.885: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-7073
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Aug  3 18:35:20.165: INFO: Waiting up to 5m0s for pod "downward-api-12d7c1ab-2d81-48d6-a5f7-2d8f10eec0fa" in namespace "downward-api-7073" to be "success or failure"
Aug  3 18:35:20.172: INFO: Pod "downward-api-12d7c1ab-2d81-48d6-a5f7-2d8f10eec0fa": Phase="Pending", Reason="", readiness=false. Elapsed: 7.499006ms
Aug  3 18:35:22.183: INFO: Pod "downward-api-12d7c1ab-2d81-48d6-a5f7-2d8f10eec0fa": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018220675s
Aug  3 18:35:24.192: INFO: Pod "downward-api-12d7c1ab-2d81-48d6-a5f7-2d8f10eec0fa": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.027289085s
STEP: Saw pod success
Aug  3 18:35:24.192: INFO: Pod "downward-api-12d7c1ab-2d81-48d6-a5f7-2d8f10eec0fa" satisfied condition "success or failure"
Aug  3 18:35:24.200: INFO: Trying to get logs from node 10.188.31.32 pod downward-api-12d7c1ab-2d81-48d6-a5f7-2d8f10eec0fa container dapi-container: <nil>
STEP: delete the pod
Aug  3 18:35:24.246: INFO: Waiting for pod downward-api-12d7c1ab-2d81-48d6-a5f7-2d8f10eec0fa to disappear
Aug  3 18:35:24.254: INFO: Pod downward-api-12d7c1ab-2d81-48d6-a5f7-2d8f10eec0fa no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 18:35:24.254: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7073" for this suite.
Aug  3 18:35:30.298: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 18:35:30.602: INFO: namespace downward-api-7073 deletion completed in 6.336761091s

• [SLOW TEST:10.718 seconds]
[sig-node] Downward API
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 18:35:30.606: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-4669
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: validating api versions
Aug  3 18:35:30.824: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 api-versions'
Aug  3 18:35:30.944: INFO: stderr: ""
Aug  3 18:35:30.944: INFO: stdout: "admissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\napps/v1beta1\napps/v1beta2\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\nbatch/v2alpha1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1\ncoordination.k8s.io/v1beta1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nmetrics.k8s.io/v1beta1\nnetworking.k8s.io/v1\nnetworking.k8s.io/v1beta1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 18:35:30.944: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4669" for this suite.
Aug  3 18:35:36.988: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 18:35:37.535: INFO: namespace kubectl-4669 deletion completed in 6.578568555s

• [SLOW TEST:6.928 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl api-versions
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 18:35:37.535: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3398
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-9a307b71-4389-48ea-b3c6-f51deeb969c1
STEP: Creating a pod to test consume configMaps
Aug  3 18:35:37.772: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-dd5e6a47-14ff-4fbe-82ef-0d3033f6f262" in namespace "projected-3398" to be "success or failure"
Aug  3 18:35:37.779: INFO: Pod "pod-projected-configmaps-dd5e6a47-14ff-4fbe-82ef-0d3033f6f262": Phase="Pending", Reason="", readiness=false. Elapsed: 7.522492ms
Aug  3 18:35:39.787: INFO: Pod "pod-projected-configmaps-dd5e6a47-14ff-4fbe-82ef-0d3033f6f262": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015393172s
STEP: Saw pod success
Aug  3 18:35:39.787: INFO: Pod "pod-projected-configmaps-dd5e6a47-14ff-4fbe-82ef-0d3033f6f262" satisfied condition "success or failure"
Aug  3 18:35:39.797: INFO: Trying to get logs from node 10.188.31.32 pod pod-projected-configmaps-dd5e6a47-14ff-4fbe-82ef-0d3033f6f262 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Aug  3 18:35:39.836: INFO: Waiting for pod pod-projected-configmaps-dd5e6a47-14ff-4fbe-82ef-0d3033f6f262 to disappear
Aug  3 18:35:39.843: INFO: Pod pod-projected-configmaps-dd5e6a47-14ff-4fbe-82ef-0d3033f6f262 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 18:35:39.843: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3398" for this suite.
Aug  3 18:35:45.891: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 18:35:46.201: INFO: namespace projected-3398 deletion completed in 6.345847581s

• [SLOW TEST:8.666 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 18:35:46.201: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-6213
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-6213
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a new StatefulSet
Aug  3 18:35:46.452: INFO: Found 0 stateful pods, waiting for 3
Aug  3 18:35:56.462: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Aug  3 18:35:56.462: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Aug  3 18:35:56.462: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Aug  3 18:35:56.490: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 exec --namespace=statefulset-6213 ss2-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Aug  3 18:35:57.070: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Aug  3 18:35:57.070: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Aug  3 18:35:57.070: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Aug  3 18:36:07.146: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Aug  3 18:36:17.191: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 exec --namespace=statefulset-6213 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  3 18:36:17.613: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Aug  3 18:36:17.613: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Aug  3 18:36:17.613: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Aug  3 18:36:17.647: INFO: Waiting for StatefulSet statefulset-6213/ss2 to complete update
Aug  3 18:36:17.647: INFO: Waiting for Pod statefulset-6213/ss2-0 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Aug  3 18:36:17.647: INFO: Waiting for Pod statefulset-6213/ss2-1 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Aug  3 18:36:17.647: INFO: Waiting for Pod statefulset-6213/ss2-2 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Aug  3 18:36:27.676: INFO: Waiting for StatefulSet statefulset-6213/ss2 to complete update
Aug  3 18:36:27.677: INFO: Waiting for Pod statefulset-6213/ss2-0 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Aug  3 18:36:27.677: INFO: Waiting for Pod statefulset-6213/ss2-1 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Aug  3 18:36:37.665: INFO: Waiting for StatefulSet statefulset-6213/ss2 to complete update
Aug  3 18:36:37.665: INFO: Waiting for Pod statefulset-6213/ss2-0 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Aug  3 18:36:47.664: INFO: Waiting for StatefulSet statefulset-6213/ss2 to complete update
STEP: Rolling back to a previous revision
Aug  3 18:36:57.666: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 exec --namespace=statefulset-6213 ss2-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Aug  3 18:36:58.087: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Aug  3 18:36:58.087: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Aug  3 18:36:58.087: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Aug  3 18:36:58.135: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Aug  3 18:37:08.186: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 exec --namespace=statefulset-6213 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  3 18:37:08.629: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Aug  3 18:37:08.629: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Aug  3 18:37:08.629: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Aug  3 18:37:18.708: INFO: Waiting for StatefulSet statefulset-6213/ss2 to complete update
Aug  3 18:37:18.709: INFO: Waiting for Pod statefulset-6213/ss2-0 to have revision ss2-7c9b54fd4c update revision ss2-6c5cd755cd
Aug  3 18:37:18.709: INFO: Waiting for Pod statefulset-6213/ss2-1 to have revision ss2-7c9b54fd4c update revision ss2-6c5cd755cd
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Aug  3 18:37:28.729: INFO: Deleting all statefulset in ns statefulset-6213
Aug  3 18:37:28.738: INFO: Scaling statefulset ss2 to 0
Aug  3 18:37:48.776: INFO: Waiting for statefulset status.replicas updated to 0
Aug  3 18:37:48.789: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 18:37:48.843: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-6213" for this suite.
Aug  3 18:37:56.892: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 18:37:57.250: INFO: namespace statefulset-6213 deletion completed in 8.395135932s

• [SLOW TEST:131.049 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 18:37:57.251: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-504
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Aug  3 18:37:57.525: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:watch-504,SelfLink:/api/v1/namespaces/watch-504/configmaps/e2e-watch-test-resource-version,UID:c948ec27-84dd-481a-a01f-0045951e2aac,ResourceVersion:46460,Generation:0,CreationTimestamp:2019-08-03 18:37:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Aug  3 18:37:57.526: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:watch-504,SelfLink:/api/v1/namespaces/watch-504/configmaps/e2e-watch-test-resource-version,UID:c948ec27-84dd-481a-a01f-0045951e2aac,ResourceVersion:46461,Generation:0,CreationTimestamp:2019-08-03 18:37:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 18:37:57.526: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-504" for this suite.
Aug  3 18:38:03.568: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 18:38:03.903: INFO: namespace watch-504 deletion completed in 6.36828268s

• [SLOW TEST:6.653 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 18:38:03.904: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-8386
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test substitution in container's command
Aug  3 18:38:04.164: INFO: Waiting up to 5m0s for pod "var-expansion-13febc8d-b63e-4029-b8be-1a04e9434913" in namespace "var-expansion-8386" to be "success or failure"
Aug  3 18:38:04.174: INFO: Pod "var-expansion-13febc8d-b63e-4029-b8be-1a04e9434913": Phase="Pending", Reason="", readiness=false. Elapsed: 9.518707ms
Aug  3 18:38:06.182: INFO: Pod "var-expansion-13febc8d-b63e-4029-b8be-1a04e9434913": Phase="Running", Reason="", readiness=true. Elapsed: 2.017903903s
Aug  3 18:38:08.190: INFO: Pod "var-expansion-13febc8d-b63e-4029-b8be-1a04e9434913": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.026377233s
STEP: Saw pod success
Aug  3 18:38:08.191: INFO: Pod "var-expansion-13febc8d-b63e-4029-b8be-1a04e9434913" satisfied condition "success or failure"
Aug  3 18:38:08.198: INFO: Trying to get logs from node 10.188.31.32 pod var-expansion-13febc8d-b63e-4029-b8be-1a04e9434913 container dapi-container: <nil>
STEP: delete the pod
Aug  3 18:38:08.251: INFO: Waiting for pod var-expansion-13febc8d-b63e-4029-b8be-1a04e9434913 to disappear
Aug  3 18:38:08.259: INFO: Pod var-expansion-13febc8d-b63e-4029-b8be-1a04e9434913 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 18:38:08.259: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-8386" for this suite.
Aug  3 18:38:14.302: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 18:38:14.836: INFO: namespace var-expansion-8386 deletion completed in 6.565320103s

• [SLOW TEST:10.933 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 18:38:14.837: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-6660
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating Redis RC
Aug  3 18:38:15.089: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 create -f - --namespace=kubectl-6660'
Aug  3 18:38:15.349: INFO: stderr: ""
Aug  3 18:38:15.349: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Aug  3 18:38:16.357: INFO: Selector matched 1 pods for map[app:redis]
Aug  3 18:38:16.357: INFO: Found 0 / 1
Aug  3 18:38:17.358: INFO: Selector matched 1 pods for map[app:redis]
Aug  3 18:38:17.358: INFO: Found 0 / 1
Aug  3 18:38:18.357: INFO: Selector matched 1 pods for map[app:redis]
Aug  3 18:38:18.357: INFO: Found 1 / 1
Aug  3 18:38:18.357: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Aug  3 18:38:18.365: INFO: Selector matched 1 pods for map[app:redis]
Aug  3 18:38:18.365: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Aug  3 18:38:18.365: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 patch pod redis-master-bvtrs --namespace=kubectl-6660 -p {"metadata":{"annotations":{"x":"y"}}}'
Aug  3 18:38:18.495: INFO: stderr: ""
Aug  3 18:38:18.495: INFO: stdout: "pod/redis-master-bvtrs patched\n"
STEP: checking annotations
Aug  3 18:38:18.503: INFO: Selector matched 1 pods for map[app:redis]
Aug  3 18:38:18.503: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 18:38:18.503: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6660" for this suite.
Aug  3 18:38:42.547: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 18:38:42.893: INFO: namespace kubectl-6660 deletion completed in 24.377589791s

• [SLOW TEST:28.056 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl patch
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] Job 
  should delete a job [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 18:38:42.894: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename job
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in job-2381
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete a job [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: delete a job
STEP: deleting Job.batch foo in namespace job-2381, will wait for the garbage collector to delete the pods
Aug  3 18:38:45.290: INFO: Deleting Job.batch foo took: 21.618707ms
Aug  3 18:38:45.491: INFO: Terminating Job.batch foo pods took: 200.264741ms
STEP: Ensuring job was deleted
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 18:39:27.100: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-2381" for this suite.
Aug  3 18:39:33.146: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 18:39:33.475: INFO: namespace job-2381 deletion completed in 6.364844782s

• [SLOW TEST:50.581 seconds]
[sig-apps] Job
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should delete a job [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 18:39:33.476: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-983
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Aug  3 18:39:33.713: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6c972f97-4a1c-4fd9-a3ee-eccd389b6a61" in namespace "downward-api-983" to be "success or failure"
Aug  3 18:39:33.721: INFO: Pod "downwardapi-volume-6c972f97-4a1c-4fd9-a3ee-eccd389b6a61": Phase="Pending", Reason="", readiness=false. Elapsed: 7.792383ms
Aug  3 18:39:35.729: INFO: Pod "downwardapi-volume-6c972f97-4a1c-4fd9-a3ee-eccd389b6a61": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016030992s
Aug  3 18:39:37.739: INFO: Pod "downwardapi-volume-6c972f97-4a1c-4fd9-a3ee-eccd389b6a61": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.025951098s
STEP: Saw pod success
Aug  3 18:39:37.739: INFO: Pod "downwardapi-volume-6c972f97-4a1c-4fd9-a3ee-eccd389b6a61" satisfied condition "success or failure"
Aug  3 18:39:37.746: INFO: Trying to get logs from node 10.188.31.32 pod downwardapi-volume-6c972f97-4a1c-4fd9-a3ee-eccd389b6a61 container client-container: <nil>
STEP: delete the pod
Aug  3 18:39:37.795: INFO: Waiting for pod downwardapi-volume-6c972f97-4a1c-4fd9-a3ee-eccd389b6a61 to disappear
Aug  3 18:39:37.803: INFO: Pod downwardapi-volume-6c972f97-4a1c-4fd9-a3ee-eccd389b6a61 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 18:39:37.804: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-983" for this suite.
Aug  3 18:39:43.859: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 18:39:44.203: INFO: namespace downward-api-983 deletion completed in 6.386413692s

• [SLOW TEST:10.727 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 18:39:44.206: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-1895
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Aug  3 18:39:44.438: INFO: Waiting up to 5m0s for pod "downward-api-44afdcbc-e152-4b08-93a2-12c3564c4466" in namespace "downward-api-1895" to be "success or failure"
Aug  3 18:39:44.458: INFO: Pod "downward-api-44afdcbc-e152-4b08-93a2-12c3564c4466": Phase="Pending", Reason="", readiness=false. Elapsed: 19.5572ms
Aug  3 18:39:46.467: INFO: Pod "downward-api-44afdcbc-e152-4b08-93a2-12c3564c4466": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.02825923s
STEP: Saw pod success
Aug  3 18:39:46.467: INFO: Pod "downward-api-44afdcbc-e152-4b08-93a2-12c3564c4466" satisfied condition "success or failure"
Aug  3 18:39:46.477: INFO: Trying to get logs from node 10.188.31.24 pod downward-api-44afdcbc-e152-4b08-93a2-12c3564c4466 container dapi-container: <nil>
STEP: delete the pod
Aug  3 18:39:46.537: INFO: Waiting for pod downward-api-44afdcbc-e152-4b08-93a2-12c3564c4466 to disappear
Aug  3 18:39:46.545: INFO: Pod downward-api-44afdcbc-e152-4b08-93a2-12c3564c4466 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 18:39:46.545: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1895" for this suite.
Aug  3 18:39:52.587: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 18:39:52.899: INFO: namespace downward-api-1895 deletion completed in 6.343040492s

• [SLOW TEST:8.693 seconds]
[sig-node] Downward API
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 18:39:52.899: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-4033
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating the pod
Aug  3 18:39:55.713: INFO: Successfully updated pod "annotationupdatea278903e-89e3-41ca-a134-05d5fb44cb72"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 18:39:57.756: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4033" for this suite.
Aug  3 18:40:21.804: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 18:40:22.152: INFO: namespace projected-4033 deletion completed in 24.381660669s

• [SLOW TEST:29.253 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 18:40:22.153: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8975
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with configMap that has name projected-configmap-test-upd-09fc333b-d1c1-4ce2-9105-60da5ea055a9
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-09fc333b-d1c1-4ce2-9105-60da5ea055a9
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 18:40:26.492: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8975" for this suite.
Aug  3 18:40:50.537: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 18:40:50.932: INFO: namespace projected-8975 deletion completed in 24.426246799s

• [SLOW TEST:28.779 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 18:40:50.933: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2690
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Aug  3 18:40:51.171: INFO: Waiting up to 5m0s for pod "downwardapi-volume-14984721-ce16-4132-86ab-1cacdef3f5fc" in namespace "projected-2690" to be "success or failure"
Aug  3 18:40:51.189: INFO: Pod "downwardapi-volume-14984721-ce16-4132-86ab-1cacdef3f5fc": Phase="Pending", Reason="", readiness=false. Elapsed: 18.509436ms
Aug  3 18:40:53.198: INFO: Pod "downwardapi-volume-14984721-ce16-4132-86ab-1cacdef3f5fc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.02700942s
STEP: Saw pod success
Aug  3 18:40:53.198: INFO: Pod "downwardapi-volume-14984721-ce16-4132-86ab-1cacdef3f5fc" satisfied condition "success or failure"
Aug  3 18:40:53.205: INFO: Trying to get logs from node 10.188.31.32 pod downwardapi-volume-14984721-ce16-4132-86ab-1cacdef3f5fc container client-container: <nil>
STEP: delete the pod
Aug  3 18:40:53.246: INFO: Waiting for pod downwardapi-volume-14984721-ce16-4132-86ab-1cacdef3f5fc to disappear
Aug  3 18:40:53.253: INFO: Pod downwardapi-volume-14984721-ce16-4132-86ab-1cacdef3f5fc no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 18:40:53.253: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2690" for this suite.
Aug  3 18:40:59.296: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 18:40:59.588: INFO: namespace projected-2690 deletion completed in 6.322909576s

• [SLOW TEST:8.655 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 18:40:59.588: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-9076
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Aug  3 18:41:02.882: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 18:41:02.915: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-9076" for this suite.
Aug  3 18:41:08.964: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 18:41:09.283: INFO: namespace container-runtime-9076 deletion completed in 6.351877827s

• [SLOW TEST:9.695 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  blackbox test
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
    on terminated container
    /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:129
      should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
      /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 18:41:09.283: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-5219
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:273
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a replication controller
Aug  3 18:41:09.527: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 create -f - --namespace=kubectl-5219'
Aug  3 18:41:09.763: INFO: stderr: ""
Aug  3 18:41:09.764: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Aug  3 18:41:09.764: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-5219'
Aug  3 18:41:09.887: INFO: stderr: ""
Aug  3 18:41:09.887: INFO: stdout: "update-demo-nautilus-4plhz update-demo-nautilus-vd88x "
Aug  3 18:41:09.887: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 get pods update-demo-nautilus-4plhz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-5219'
Aug  3 18:41:10.005: INFO: stderr: ""
Aug  3 18:41:10.005: INFO: stdout: ""
Aug  3 18:41:10.005: INFO: update-demo-nautilus-4plhz is created but not running
Aug  3 18:41:15.005: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-5219'
Aug  3 18:41:15.133: INFO: stderr: ""
Aug  3 18:41:15.133: INFO: stdout: "update-demo-nautilus-4plhz update-demo-nautilus-vd88x "
Aug  3 18:41:15.133: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 get pods update-demo-nautilus-4plhz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-5219'
Aug  3 18:41:15.264: INFO: stderr: ""
Aug  3 18:41:15.265: INFO: stdout: "true"
Aug  3 18:41:15.265: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 get pods update-demo-nautilus-4plhz -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-5219'
Aug  3 18:41:15.379: INFO: stderr: ""
Aug  3 18:41:15.379: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Aug  3 18:41:15.379: INFO: validating pod update-demo-nautilus-4plhz
Aug  3 18:41:15.394: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug  3 18:41:15.394: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug  3 18:41:15.394: INFO: update-demo-nautilus-4plhz is verified up and running
Aug  3 18:41:15.394: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 get pods update-demo-nautilus-vd88x -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-5219'
Aug  3 18:41:15.525: INFO: stderr: ""
Aug  3 18:41:15.525: INFO: stdout: "true"
Aug  3 18:41:15.526: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 get pods update-demo-nautilus-vd88x -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-5219'
Aug  3 18:41:15.641: INFO: stderr: ""
Aug  3 18:41:15.641: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Aug  3 18:41:15.641: INFO: validating pod update-demo-nautilus-vd88x
Aug  3 18:41:15.660: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug  3 18:41:15.660: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug  3 18:41:15.660: INFO: update-demo-nautilus-vd88x is verified up and running
STEP: scaling down the replication controller
Aug  3 18:41:15.661: INFO: scanned /root for discovery docs: <nil>
Aug  3 18:41:15.661: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=kubectl-5219'
Aug  3 18:41:16.835: INFO: stderr: ""
Aug  3 18:41:16.835: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Aug  3 18:41:16.835: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-5219'
Aug  3 18:41:16.960: INFO: stderr: ""
Aug  3 18:41:16.960: INFO: stdout: "update-demo-nautilus-4plhz update-demo-nautilus-vd88x "
STEP: Replicas for name=update-demo: expected=1 actual=2
Aug  3 18:41:21.961: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-5219'
Aug  3 18:41:22.078: INFO: stderr: ""
Aug  3 18:41:22.078: INFO: stdout: "update-demo-nautilus-4plhz "
Aug  3 18:41:22.078: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 get pods update-demo-nautilus-4plhz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-5219'
Aug  3 18:41:22.208: INFO: stderr: ""
Aug  3 18:41:22.208: INFO: stdout: "true"
Aug  3 18:41:22.208: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 get pods update-demo-nautilus-4plhz -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-5219'
Aug  3 18:41:22.320: INFO: stderr: ""
Aug  3 18:41:22.320: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Aug  3 18:41:22.320: INFO: validating pod update-demo-nautilus-4plhz
Aug  3 18:41:22.331: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug  3 18:41:22.331: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug  3 18:41:22.331: INFO: update-demo-nautilus-4plhz is verified up and running
STEP: scaling up the replication controller
Aug  3 18:41:22.333: INFO: scanned /root for discovery docs: <nil>
Aug  3 18:41:22.333: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=kubectl-5219'
Aug  3 18:41:23.472: INFO: stderr: ""
Aug  3 18:41:23.472: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Aug  3 18:41:23.472: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-5219'
Aug  3 18:41:23.617: INFO: stderr: ""
Aug  3 18:41:23.617: INFO: stdout: "update-demo-nautilus-4plhz update-demo-nautilus-dgr6p "
Aug  3 18:41:23.617: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 get pods update-demo-nautilus-4plhz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-5219'
Aug  3 18:41:23.763: INFO: stderr: ""
Aug  3 18:41:23.763: INFO: stdout: "true"
Aug  3 18:41:23.763: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 get pods update-demo-nautilus-4plhz -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-5219'
Aug  3 18:41:23.886: INFO: stderr: ""
Aug  3 18:41:23.886: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Aug  3 18:41:23.886: INFO: validating pod update-demo-nautilus-4plhz
Aug  3 18:41:23.899: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug  3 18:41:23.899: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug  3 18:41:23.899: INFO: update-demo-nautilus-4plhz is verified up and running
Aug  3 18:41:23.899: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 get pods update-demo-nautilus-dgr6p -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-5219'
Aug  3 18:41:24.007: INFO: stderr: ""
Aug  3 18:41:24.007: INFO: stdout: "true"
Aug  3 18:41:24.007: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 get pods update-demo-nautilus-dgr6p -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-5219'
Aug  3 18:41:24.131: INFO: stderr: ""
Aug  3 18:41:24.131: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Aug  3 18:41:24.131: INFO: validating pod update-demo-nautilus-dgr6p
Aug  3 18:41:24.151: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug  3 18:41:24.151: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug  3 18:41:24.151: INFO: update-demo-nautilus-dgr6p is verified up and running
STEP: using delete to clean up resources
Aug  3 18:41:24.151: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 delete --grace-period=0 --force -f - --namespace=kubectl-5219'
Aug  3 18:41:24.293: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug  3 18:41:24.293: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Aug  3 18:41:24.293: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-5219'
Aug  3 18:41:24.430: INFO: stderr: "No resources found.\n"
Aug  3 18:41:24.430: INFO: stdout: ""
Aug  3 18:41:24.430: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 get pods -l name=update-demo --namespace=kubectl-5219 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Aug  3 18:41:24.543: INFO: stderr: ""
Aug  3 18:41:24.543: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 18:41:24.543: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5219" for this suite.
Aug  3 18:41:48.590: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 18:41:48.904: INFO: namespace kubectl-5219 deletion completed in 24.344521455s

• [SLOW TEST:39.621 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 18:41:48.905: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-3110
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating service multi-endpoint-test in namespace services-3110
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-3110 to expose endpoints map[]
Aug  3 18:41:49.165: INFO: successfully validated that service multi-endpoint-test in namespace services-3110 exposes endpoints map[] (10.239279ms elapsed)
STEP: Creating pod pod1 in namespace services-3110
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-3110 to expose endpoints map[pod1:[100]]
Aug  3 18:41:51.246: INFO: successfully validated that service multi-endpoint-test in namespace services-3110 exposes endpoints map[pod1:[100]] (2.056262587s elapsed)
STEP: Creating pod pod2 in namespace services-3110
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-3110 to expose endpoints map[pod1:[100] pod2:[101]]
Aug  3 18:41:53.334: INFO: successfully validated that service multi-endpoint-test in namespace services-3110 exposes endpoints map[pod1:[100] pod2:[101]] (2.076339413s elapsed)
STEP: Deleting pod pod1 in namespace services-3110
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-3110 to expose endpoints map[pod2:[101]]
Aug  3 18:41:53.365: INFO: successfully validated that service multi-endpoint-test in namespace services-3110 exposes endpoints map[pod2:[101]] (16.234028ms elapsed)
STEP: Deleting pod pod2 in namespace services-3110
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-3110 to expose endpoints map[]
Aug  3 18:41:54.403: INFO: successfully validated that service multi-endpoint-test in namespace services-3110 exposes endpoints map[] (1.025691657s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 18:41:54.454: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-3110" for this suite.
Aug  3 18:42:18.509: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 18:42:18.828: INFO: namespace services-3110 deletion completed in 24.360995691s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:92

• [SLOW TEST:29.923 seconds]
[sig-network] Services
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 18:42:18.828: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-9133
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0803 18:42:25.144478      17 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Aug  3 18:42:25.144: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 18:42:25.144: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-9133" for this suite.
Aug  3 18:42:33.190: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 18:42:33.537: INFO: namespace gc-9133 deletion completed in 8.382981209s

• [SLOW TEST:14.709 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 18:42:33.538: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-8064
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Aug  3 18:42:33.774: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Aug  3 18:42:38.783: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Aug  3 18:42:38.783: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
Aug  3 18:42:40.853: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment,GenerateName:,Namespace:deployment-8064,SelfLink:/apis/apps/v1/namespaces/deployment-8064/deployments/test-cleanup-deployment,UID:5aab98f8-c50d-40ee-8e0d-967f4ffe102d,ResourceVersion:47818,Generation:1,CreationTimestamp:2019-08-03 18:42:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 1,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-08-03 18:42:38 +0000 UTC 2019-08-03 18:42:38 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-08-03 18:42:40 +0000 UTC 2019-08-03 18:42:38 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-cleanup-deployment-55bbcbc84c" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Aug  3 18:42:40.869: INFO: New ReplicaSet "test-cleanup-deployment-55bbcbc84c" of Deployment "test-cleanup-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-55bbcbc84c,GenerateName:,Namespace:deployment-8064,SelfLink:/apis/apps/v1/namespaces/deployment-8064/replicasets/test-cleanup-deployment-55bbcbc84c,UID:f6f399fb-3472-4135-87ef-ed244689c3af,ResourceVersion:47808,Generation:1,CreationTimestamp:2019-08-03 18:42:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 55bbcbc84c,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment 5aab98f8-c50d-40ee-8e0d-967f4ffe102d 0xc002ad3d37 0xc002ad3d38}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: 55bbcbc84c,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 55bbcbc84c,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Aug  3 18:42:40.878: INFO: Pod "test-cleanup-deployment-55bbcbc84c-v6z2x" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-55bbcbc84c-v6z2x,GenerateName:test-cleanup-deployment-55bbcbc84c-,Namespace:deployment-8064,SelfLink:/api/v1/namespaces/deployment-8064/pods/test-cleanup-deployment-55bbcbc84c-v6z2x,UID:601c085c-7668-40af-826e-e9a592d00a80,ResourceVersion:47807,Generation:0,CreationTimestamp:2019-08-03 18:42:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 55bbcbc84c,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-deployment-55bbcbc84c f6f399fb-3472-4135-87ef-ed244689c3af 0xc002570ff7 0xc002570ff8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-s45fq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-s45fq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-s45fq true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.188.31.24,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002571070} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002571090}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-03 18:42:38 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-03 18:42:40 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-03 18:42:40 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-03 18:42:38 +0000 UTC  }],Message:,Reason:,HostIP:10.188.31.24,PodIP:172.30.44.114,StartTime:2019-08-03 18:42:38 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-08-03 18:42:40 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 containerd://d720b27481c103bfa0e45a7093bec3c25e6a31b2b2e001928011f2788b7ba75f}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 18:42:40.878: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-8064" for this suite.
Aug  3 18:42:46.927: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 18:42:47.569: INFO: namespace deployment-8064 deletion completed in 6.678192678s

• [SLOW TEST:14.031 seconds]
[sig-apps] Deployment
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 18:42:47.577: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9026
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-map-a75f2fda-5198-43e0-a023-1c18a705ab55
STEP: Creating a pod to test consume configMaps
Aug  3 18:42:47.819: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-07b8b587-49b5-41a4-a5f3-3e6adb4df8da" in namespace "projected-9026" to be "success or failure"
Aug  3 18:42:47.829: INFO: Pod "pod-projected-configmaps-07b8b587-49b5-41a4-a5f3-3e6adb4df8da": Phase="Pending", Reason="", readiness=false. Elapsed: 9.774017ms
Aug  3 18:42:49.838: INFO: Pod "pod-projected-configmaps-07b8b587-49b5-41a4-a5f3-3e6adb4df8da": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018943892s
Aug  3 18:42:51.850: INFO: Pod "pod-projected-configmaps-07b8b587-49b5-41a4-a5f3-3e6adb4df8da": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.030298662s
STEP: Saw pod success
Aug  3 18:42:51.850: INFO: Pod "pod-projected-configmaps-07b8b587-49b5-41a4-a5f3-3e6adb4df8da" satisfied condition "success or failure"
Aug  3 18:42:51.858: INFO: Trying to get logs from node 10.188.31.32 pod pod-projected-configmaps-07b8b587-49b5-41a4-a5f3-3e6adb4df8da container projected-configmap-volume-test: <nil>
STEP: delete the pod
Aug  3 18:42:51.920: INFO: Waiting for pod pod-projected-configmaps-07b8b587-49b5-41a4-a5f3-3e6adb4df8da to disappear
Aug  3 18:42:51.927: INFO: Pod pod-projected-configmaps-07b8b587-49b5-41a4-a5f3-3e6adb4df8da no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 18:42:51.928: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9026" for this suite.
Aug  3 18:42:57.972: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 18:42:58.311: INFO: namespace projected-9026 deletion completed in 6.371449896s

• [SLOW TEST:10.734 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 18:42:58.313: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-5921
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating service endpoint-test2 in namespace services-5921
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-5921 to expose endpoints map[]
Aug  3 18:42:58.570: INFO: Get endpoints failed (9.453606ms elapsed, ignoring for 5s): endpoints "endpoint-test2" not found
Aug  3 18:42:59.581: INFO: successfully validated that service endpoint-test2 in namespace services-5921 exposes endpoints map[] (1.020253623s elapsed)
STEP: Creating pod pod1 in namespace services-5921
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-5921 to expose endpoints map[pod1:[80]]
Aug  3 18:43:01.655: INFO: successfully validated that service endpoint-test2 in namespace services-5921 exposes endpoints map[pod1:[80]] (2.056736903s elapsed)
STEP: Creating pod pod2 in namespace services-5921
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-5921 to expose endpoints map[pod1:[80] pod2:[80]]
Aug  3 18:43:03.757: INFO: successfully validated that service endpoint-test2 in namespace services-5921 exposes endpoints map[pod1:[80] pod2:[80]] (2.083185046s elapsed)
STEP: Deleting pod pod1 in namespace services-5921
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-5921 to expose endpoints map[pod2:[80]]
Aug  3 18:43:04.808: INFO: successfully validated that service endpoint-test2 in namespace services-5921 exposes endpoints map[pod2:[80]] (1.036813248s elapsed)
STEP: Deleting pod pod2 in namespace services-5921
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-5921 to expose endpoints map[]
Aug  3 18:43:05.851: INFO: successfully validated that service endpoint-test2 in namespace services-5921 exposes endpoints map[] (1.028712632s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 18:43:05.909: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-5921" for this suite.
Aug  3 18:43:29.956: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 18:43:30.277: INFO: namespace services-5921 deletion completed in 24.354362081s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:92

• [SLOW TEST:31.965 seconds]
[sig-network] Services
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 18:43:30.279: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-7287
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod busybox-83dfa47d-1367-409a-a9b5-06191d1b8bd1 in namespace container-probe-7287
Aug  3 18:43:32.519: INFO: Started pod busybox-83dfa47d-1367-409a-a9b5-06191d1b8bd1 in namespace container-probe-7287
STEP: checking the pod's current state and verifying that restartCount is present
Aug  3 18:43:32.527: INFO: Initial restart count of pod busybox-83dfa47d-1367-409a-a9b5-06191d1b8bd1 is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 18:47:33.707: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-7287" for this suite.
Aug  3 18:47:39.752: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 18:47:40.098: INFO: namespace container-probe-7287 deletion completed in 6.378716474s

• [SLOW TEST:249.819 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 18:47:40.098: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-5704
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Starting the proxy
Aug  3 18:47:40.318: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-322553265 proxy --unix-socket=/tmp/kubectl-proxy-unix612688976/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 18:47:40.399: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5704" for this suite.
Aug  3 18:47:46.453: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 18:47:46.811: INFO: namespace kubectl-5704 deletion completed in 6.389390657s

• [SLOW TEST:6.713 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Proxy server
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 18:47:46.812: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-5548
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Performing setup for networking test in namespace pod-network-test-5548
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Aug  3 18:47:47.023: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Aug  3 18:48:07.240: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.72.106:8080/dial?request=hostName&protocol=udp&host=172.30.44.117&port=8081&tries=1'] Namespace:pod-network-test-5548 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug  3 18:48:07.240: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
Aug  3 18:48:07.565: INFO: Waiting for endpoints: map[]
Aug  3 18:48:07.579: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.72.106:8080/dial?request=hostName&protocol=udp&host=172.30.199.92&port=8081&tries=1'] Namespace:pod-network-test-5548 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug  3 18:48:07.579: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
Aug  3 18:48:07.903: INFO: Waiting for endpoints: map[]
Aug  3 18:48:07.911: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.72.106:8080/dial?request=hostName&protocol=udp&host=172.30.72.105&port=8081&tries=1'] Namespace:pod-network-test-5548 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug  3 18:48:07.911: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
Aug  3 18:48:08.218: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 18:48:08.219: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-5548" for this suite.
Aug  3 18:48:32.269: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 18:48:32.608: INFO: namespace pod-network-test-5548 deletion completed in 24.37702178s

• [SLOW TEST:45.797 seconds]
[sig-network] Networking
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 18:48:32.609: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-409
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Aug  3 18:48:32.846: INFO: Waiting up to 5m0s for pod "downwardapi-volume-fb12c341-c01c-45b5-82cf-224217da95dd" in namespace "projected-409" to be "success or failure"
Aug  3 18:48:32.853: INFO: Pod "downwardapi-volume-fb12c341-c01c-45b5-82cf-224217da95dd": Phase="Pending", Reason="", readiness=false. Elapsed: 7.202041ms
Aug  3 18:48:34.864: INFO: Pod "downwardapi-volume-fb12c341-c01c-45b5-82cf-224217da95dd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017659261s
Aug  3 18:48:36.872: INFO: Pod "downwardapi-volume-fb12c341-c01c-45b5-82cf-224217da95dd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.025570291s
STEP: Saw pod success
Aug  3 18:48:36.872: INFO: Pod "downwardapi-volume-fb12c341-c01c-45b5-82cf-224217da95dd" satisfied condition "success or failure"
Aug  3 18:48:36.880: INFO: Trying to get logs from node 10.188.31.24 pod downwardapi-volume-fb12c341-c01c-45b5-82cf-224217da95dd container client-container: <nil>
STEP: delete the pod
Aug  3 18:48:36.933: INFO: Waiting for pod downwardapi-volume-fb12c341-c01c-45b5-82cf-224217da95dd to disappear
Aug  3 18:48:36.940: INFO: Pod downwardapi-volume-fb12c341-c01c-45b5-82cf-224217da95dd no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 18:48:36.941: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-409" for this suite.
Aug  3 18:48:42.994: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 18:48:43.325: INFO: namespace projected-409 deletion completed in 6.371544115s

• [SLOW TEST:10.715 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 18:48:43.326: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-8194
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: starting the proxy server
Aug  3 18:48:43.553: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-322553265 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 18:48:43.654: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8194" for this suite.
Aug  3 18:48:49.702: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 18:48:50.127: INFO: namespace kubectl-8194 deletion completed in 6.461576788s

• [SLOW TEST:6.802 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Proxy server
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 18:48:50.128: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3870
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Aug  3 18:48:50.356: INFO: Waiting up to 5m0s for pod "downwardapi-volume-78c7268f-99f7-402a-a18d-6ae3cd5f4619" in namespace "projected-3870" to be "success or failure"
Aug  3 18:48:50.364: INFO: Pod "downwardapi-volume-78c7268f-99f7-402a-a18d-6ae3cd5f4619": Phase="Pending", Reason="", readiness=false. Elapsed: 7.552666ms
Aug  3 18:48:52.373: INFO: Pod "downwardapi-volume-78c7268f-99f7-402a-a18d-6ae3cd5f4619": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016798072s
STEP: Saw pod success
Aug  3 18:48:52.373: INFO: Pod "downwardapi-volume-78c7268f-99f7-402a-a18d-6ae3cd5f4619" satisfied condition "success or failure"
Aug  3 18:48:52.402: INFO: Trying to get logs from node 10.188.31.32 pod downwardapi-volume-78c7268f-99f7-402a-a18d-6ae3cd5f4619 container client-container: <nil>
STEP: delete the pod
Aug  3 18:48:52.448: INFO: Waiting for pod downwardapi-volume-78c7268f-99f7-402a-a18d-6ae3cd5f4619 to disappear
Aug  3 18:48:52.456: INFO: Pod downwardapi-volume-78c7268f-99f7-402a-a18d-6ae3cd5f4619 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 18:48:52.456: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3870" for this suite.
Aug  3 18:48:58.503: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 18:48:58.821: INFO: namespace projected-3870 deletion completed in 6.35327801s

• [SLOW TEST:8.694 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] version v1
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 18:48:58.821: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-587
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Aug  3 18:48:59.070: INFO: (0) /api/v1/nodes/10.188.31.22/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="alternatives.log.1">alternatives.l... (200; 18.675579ms)
Aug  3 18:48:59.085: INFO: (1) /api/v1/nodes/10.188.31.22/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="alternatives.log.1">alternatives.l... (200; 14.991322ms)
Aug  3 18:48:59.098: INFO: (2) /api/v1/nodes/10.188.31.22/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="alternatives.log.1">alternatives.l... (200; 13.23332ms)
Aug  3 18:48:59.110: INFO: (3) /api/v1/nodes/10.188.31.22/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="alternatives.log.1">alternatives.l... (200; 11.690191ms)
Aug  3 18:48:59.122: INFO: (4) /api/v1/nodes/10.188.31.22/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="alternatives.log.1">alternatives.l... (200; 12.349429ms)
Aug  3 18:48:59.137: INFO: (5) /api/v1/nodes/10.188.31.22/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="alternatives.log.1">alternatives.l... (200; 14.95613ms)
Aug  3 18:48:59.153: INFO: (6) /api/v1/nodes/10.188.31.22/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="alternatives.log.1">alternatives.l... (200; 15.820731ms)
Aug  3 18:48:59.170: INFO: (7) /api/v1/nodes/10.188.31.22/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="alternatives.log.1">alternatives.l... (200; 16.308127ms)
Aug  3 18:48:59.185: INFO: (8) /api/v1/nodes/10.188.31.22/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="alternatives.log.1">alternatives.l... (200; 15.061196ms)
Aug  3 18:48:59.197: INFO: (9) /api/v1/nodes/10.188.31.22/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="alternatives.log.1">alternatives.l... (200; 12.13821ms)
Aug  3 18:48:59.210: INFO: (10) /api/v1/nodes/10.188.31.22/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="alternatives.log.1">alternatives.l... (200; 13.076582ms)
Aug  3 18:48:59.222: INFO: (11) /api/v1/nodes/10.188.31.22/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="alternatives.log.1">alternatives.l... (200; 11.650834ms)
Aug  3 18:48:59.234: INFO: (12) /api/v1/nodes/10.188.31.22/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="alternatives.log.1">alternatives.l... (200; 12.143017ms)
Aug  3 18:48:59.247: INFO: (13) /api/v1/nodes/10.188.31.22/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="alternatives.log.1">alternatives.l... (200; 13.020315ms)
Aug  3 18:48:59.259: INFO: (14) /api/v1/nodes/10.188.31.22/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="alternatives.log.1">alternatives.l... (200; 12.016594ms)
Aug  3 18:48:59.271: INFO: (15) /api/v1/nodes/10.188.31.22/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="alternatives.log.1">alternatives.l... (200; 12.068057ms)
Aug  3 18:48:59.283: INFO: (16) /api/v1/nodes/10.188.31.22/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="alternatives.log.1">alternatives.l... (200; 12.100586ms)
Aug  3 18:48:59.299: INFO: (17) /api/v1/nodes/10.188.31.22/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="alternatives.log.1">alternatives.l... (200; 15.445199ms)
Aug  3 18:48:59.313: INFO: (18) /api/v1/nodes/10.188.31.22/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="alternatives.log.1">alternatives.l... (200; 14.263492ms)
Aug  3 18:48:59.325: INFO: (19) /api/v1/nodes/10.188.31.22/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="alternatives.log.1">alternatives.l... (200; 11.514275ms)
[AfterEach] version v1
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 18:48:59.325: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-587" for this suite.
Aug  3 18:49:05.363: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 18:49:05.837: INFO: namespace proxy-587 deletion completed in 6.50346641s

• [SLOW TEST:7.016 seconds]
[sig-network] Proxy
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:58
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 18:49:05.838: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replicaset-3262
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Aug  3 18:49:06.053: INFO: Creating ReplicaSet my-hostname-basic-727a9f47-a983-4dbc-bde7-579eaf2060bc
Aug  3 18:49:06.072: INFO: Pod name my-hostname-basic-727a9f47-a983-4dbc-bde7-579eaf2060bc: Found 0 pods out of 1
Aug  3 18:49:11.083: INFO: Pod name my-hostname-basic-727a9f47-a983-4dbc-bde7-579eaf2060bc: Found 1 pods out of 1
Aug  3 18:49:11.083: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-727a9f47-a983-4dbc-bde7-579eaf2060bc" is running
Aug  3 18:49:11.090: INFO: Pod "my-hostname-basic-727a9f47-a983-4dbc-bde7-579eaf2060bc-brn95" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-08-03 18:49:06 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-08-03 18:49:07 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-08-03 18:49:07 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-08-03 18:49:06 +0000 UTC Reason: Message:}])
Aug  3 18:49:11.090: INFO: Trying to dial the pod
Aug  3 18:49:16.126: INFO: Controller my-hostname-basic-727a9f47-a983-4dbc-bde7-579eaf2060bc: Got expected result from replica 1 [my-hostname-basic-727a9f47-a983-4dbc-bde7-579eaf2060bc-brn95]: "my-hostname-basic-727a9f47-a983-4dbc-bde7-579eaf2060bc-brn95", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 18:49:16.126: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-3262" for this suite.
Aug  3 18:49:22.189: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 18:49:22.525: INFO: namespace replicaset-3262 deletion completed in 6.386894904s

• [SLOW TEST:16.687 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 18:49:22.526: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-kubelet-etc-hosts-5401
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Aug  3 18:49:28.829: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-5401 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug  3 18:49:28.829: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
Aug  3 18:49:29.163: INFO: Exec stderr: ""
Aug  3 18:49:29.163: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-5401 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug  3 18:49:29.163: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
Aug  3 18:49:29.443: INFO: Exec stderr: ""
Aug  3 18:49:29.443: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-5401 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug  3 18:49:29.443: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
Aug  3 18:49:29.817: INFO: Exec stderr: ""
Aug  3 18:49:29.817: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-5401 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug  3 18:49:29.817: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
Aug  3 18:49:30.127: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Aug  3 18:49:30.127: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-5401 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug  3 18:49:30.127: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
Aug  3 18:49:30.445: INFO: Exec stderr: ""
Aug  3 18:49:30.445: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-5401 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug  3 18:49:30.445: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
Aug  3 18:49:30.769: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Aug  3 18:49:30.769: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-5401 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug  3 18:49:30.769: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
Aug  3 18:49:31.097: INFO: Exec stderr: ""
Aug  3 18:49:31.097: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-5401 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug  3 18:49:31.097: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
Aug  3 18:49:31.410: INFO: Exec stderr: ""
Aug  3 18:49:31.410: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-5401 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug  3 18:49:31.410: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
Aug  3 18:49:31.732: INFO: Exec stderr: ""
Aug  3 18:49:31.732: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-5401 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug  3 18:49:31.732: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
Aug  3 18:49:32.047: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 18:49:32.047: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-kubelet-etc-hosts-5401" for this suite.
Aug  3 18:50:18.091: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 18:50:18.447: INFO: namespace e2e-kubelet-etc-hosts-5401 deletion completed in 46.388109104s

• [SLOW TEST:55.921 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 18:50:18.450: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-4743
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 18:51:18.709: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-4743" for this suite.
Aug  3 18:51:42.753: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 18:51:43.110: INFO: namespace container-probe-4743 deletion completed in 24.389032356s

• [SLOW TEST:84.660 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 18:51:43.110: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename hostpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in hostpath-2837
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test hostPath mode
Aug  3 18:51:43.341: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "hostpath-2837" to be "success or failure"
Aug  3 18:51:43.350: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 8.946509ms
Aug  3 18:51:45.359: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.018266573s
STEP: Saw pod success
Aug  3 18:51:45.359: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Aug  3 18:51:45.368: INFO: Trying to get logs from node 10.188.31.22 pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Aug  3 18:51:45.414: INFO: Waiting for pod pod-host-path-test to disappear
Aug  3 18:51:45.430: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 18:51:45.430: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "hostpath-2837" for this suite.
Aug  3 18:51:51.480: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 18:51:51.764: INFO: namespace hostpath-2837 deletion completed in 6.322127292s

• [SLOW TEST:8.654 seconds]
[sig-storage] HostPath
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 18:51:51.764: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-3500
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Aug  3 18:51:52.010: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b589728c-f386-4a22-8b6f-f096bd4ce621" in namespace "downward-api-3500" to be "success or failure"
Aug  3 18:51:52.019: INFO: Pod "downwardapi-volume-b589728c-f386-4a22-8b6f-f096bd4ce621": Phase="Pending", Reason="", readiness=false. Elapsed: 8.565308ms
Aug  3 18:51:54.033: INFO: Pod "downwardapi-volume-b589728c-f386-4a22-8b6f-f096bd4ce621": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022606649s
Aug  3 18:51:56.043: INFO: Pod "downwardapi-volume-b589728c-f386-4a22-8b6f-f096bd4ce621": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.032172893s
STEP: Saw pod success
Aug  3 18:51:56.043: INFO: Pod "downwardapi-volume-b589728c-f386-4a22-8b6f-f096bd4ce621" satisfied condition "success or failure"
Aug  3 18:51:56.052: INFO: Trying to get logs from node 10.188.31.32 pod downwardapi-volume-b589728c-f386-4a22-8b6f-f096bd4ce621 container client-container: <nil>
STEP: delete the pod
Aug  3 18:51:56.098: INFO: Waiting for pod downwardapi-volume-b589728c-f386-4a22-8b6f-f096bd4ce621 to disappear
Aug  3 18:51:56.105: INFO: Pod downwardapi-volume-b589728c-f386-4a22-8b6f-f096bd4ce621 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 18:51:56.106: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3500" for this suite.
Aug  3 18:52:02.150: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 18:52:02.490: INFO: namespace downward-api-3500 deletion completed in 6.372495762s

• [SLOW TEST:10.726 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 18:52:02.490: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-957
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Aug  3 18:52:02.725: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 18:52:03.854: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-957" for this suite.
Aug  3 18:52:09.899: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 18:52:10.432: INFO: namespace custom-resource-definition-957 deletion completed in 6.565712016s

• [SLOW TEST:7.941 seconds]
[sig-api-machinery] CustomResourceDefinition resources
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:35
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 18:52:10.432: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2072
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name cm-test-opt-del-fc608c90-25b2-47aa-bc5d-ff05abcb9ff1
STEP: Creating configMap with name cm-test-opt-upd-169ecdf8-6fa5-401f-9353-9013abbf1a30
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-fc608c90-25b2-47aa-bc5d-ff05abcb9ff1
STEP: Updating configmap cm-test-opt-upd-169ecdf8-6fa5-401f-9353-9013abbf1a30
STEP: Creating configMap with name cm-test-opt-create-c513009c-f67f-4838-9c97-33822f8cc9ae
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 18:53:35.898: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2072" for this suite.
Aug  3 18:53:59.944: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 18:54:00.306: INFO: namespace projected-2072 deletion completed in 24.397183012s

• [SLOW TEST:109.874 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-network] DNS 
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 18:54:00.307: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-7551
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a test externalName service
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-7551.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-7551.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-7551.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-7551.svc.cluster.local; sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Aug  3 18:54:04.601: INFO: DNS probes using dns-test-ee9ddca3-c3a1-4b22-9c03-4d2376275c37 succeeded

STEP: deleting the pod
STEP: changing the externalName to bar.example.com
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-7551.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-7551.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-7551.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-7551.svc.cluster.local; sleep 1; done

STEP: creating a second pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Aug  3 18:54:08.716: INFO: File wheezy_udp@dns-test-service-3.dns-7551.svc.cluster.local from pod  dns-7551/dns-test-0960eab2-8884-44f7-9df8-054687635662 contains 'foo.example.com.
' instead of 'bar.example.com.'
Aug  3 18:54:08.727: INFO: File jessie_udp@dns-test-service-3.dns-7551.svc.cluster.local from pod  dns-7551/dns-test-0960eab2-8884-44f7-9df8-054687635662 contains 'foo.example.com.
' instead of 'bar.example.com.'
Aug  3 18:54:08.727: INFO: Lookups using dns-7551/dns-test-0960eab2-8884-44f7-9df8-054687635662 failed for: [wheezy_udp@dns-test-service-3.dns-7551.svc.cluster.local jessie_udp@dns-test-service-3.dns-7551.svc.cluster.local]

Aug  3 18:54:13.749: INFO: File wheezy_udp@dns-test-service-3.dns-7551.svc.cluster.local from pod  dns-7551/dns-test-0960eab2-8884-44f7-9df8-054687635662 contains 'foo.example.com.
' instead of 'bar.example.com.'
Aug  3 18:54:13.760: INFO: File jessie_udp@dns-test-service-3.dns-7551.svc.cluster.local from pod  dns-7551/dns-test-0960eab2-8884-44f7-9df8-054687635662 contains 'foo.example.com.
' instead of 'bar.example.com.'
Aug  3 18:54:13.760: INFO: Lookups using dns-7551/dns-test-0960eab2-8884-44f7-9df8-054687635662 failed for: [wheezy_udp@dns-test-service-3.dns-7551.svc.cluster.local jessie_udp@dns-test-service-3.dns-7551.svc.cluster.local]

Aug  3 18:54:18.744: INFO: File wheezy_udp@dns-test-service-3.dns-7551.svc.cluster.local from pod  dns-7551/dns-test-0960eab2-8884-44f7-9df8-054687635662 contains 'foo.example.com.
' instead of 'bar.example.com.'
Aug  3 18:54:18.761: INFO: File jessie_udp@dns-test-service-3.dns-7551.svc.cluster.local from pod  dns-7551/dns-test-0960eab2-8884-44f7-9df8-054687635662 contains 'foo.example.com.
' instead of 'bar.example.com.'
Aug  3 18:54:18.761: INFO: Lookups using dns-7551/dns-test-0960eab2-8884-44f7-9df8-054687635662 failed for: [wheezy_udp@dns-test-service-3.dns-7551.svc.cluster.local jessie_udp@dns-test-service-3.dns-7551.svc.cluster.local]

Aug  3 18:54:23.740: INFO: File wheezy_udp@dns-test-service-3.dns-7551.svc.cluster.local from pod  dns-7551/dns-test-0960eab2-8884-44f7-9df8-054687635662 contains 'foo.example.com.
' instead of 'bar.example.com.'
Aug  3 18:54:23.753: INFO: File jessie_udp@dns-test-service-3.dns-7551.svc.cluster.local from pod  dns-7551/dns-test-0960eab2-8884-44f7-9df8-054687635662 contains 'foo.example.com.
' instead of 'bar.example.com.'
Aug  3 18:54:23.753: INFO: Lookups using dns-7551/dns-test-0960eab2-8884-44f7-9df8-054687635662 failed for: [wheezy_udp@dns-test-service-3.dns-7551.svc.cluster.local jessie_udp@dns-test-service-3.dns-7551.svc.cluster.local]

Aug  3 18:54:28.739: INFO: File wheezy_udp@dns-test-service-3.dns-7551.svc.cluster.local from pod  dns-7551/dns-test-0960eab2-8884-44f7-9df8-054687635662 contains 'foo.example.com.
' instead of 'bar.example.com.'
Aug  3 18:54:28.749: INFO: File jessie_udp@dns-test-service-3.dns-7551.svc.cluster.local from pod  dns-7551/dns-test-0960eab2-8884-44f7-9df8-054687635662 contains 'foo.example.com.
' instead of 'bar.example.com.'
Aug  3 18:54:28.749: INFO: Lookups using dns-7551/dns-test-0960eab2-8884-44f7-9df8-054687635662 failed for: [wheezy_udp@dns-test-service-3.dns-7551.svc.cluster.local jessie_udp@dns-test-service-3.dns-7551.svc.cluster.local]

Aug  3 18:54:33.750: INFO: DNS probes using dns-test-0960eab2-8884-44f7-9df8-054687635662 succeeded

STEP: deleting the pod
STEP: changing the service to type=ClusterIP
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-7551.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-7551.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-7551.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-7551.svc.cluster.local; sleep 1; done

STEP: creating a third pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Aug  3 18:54:37.905: INFO: DNS probes using dns-test-20ae9a73-7e1a-40c5-8420-82b181708411 succeeded

STEP: deleting the pod
STEP: deleting the test externalName service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 18:54:37.975: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-7551" for this suite.
Aug  3 18:54:46.022: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 18:54:46.323: INFO: namespace dns-7551 deletion completed in 8.332624228s

• [SLOW TEST:46.016 seconds]
[sig-network] DNS
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 18:54:46.324: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-8389
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating the pod
Aug  3 18:54:49.252: INFO: Successfully updated pod "annotationupdatea3f671d6-29d4-4575-9d0d-683fb8b6bd16"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 18:54:51.288: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8389" for this suite.
Aug  3 18:55:15.349: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 18:55:15.832: INFO: namespace downward-api-8389 deletion completed in 24.532688475s

• [SLOW TEST:29.509 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 18:55:15.833: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-9836
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name s-test-opt-del-ae2981a1-0adf-4d91-8cfb-644b313657b9
STEP: Creating secret with name s-test-opt-upd-d7ac4c56-7ae2-41bd-86e1-9c481d64bd65
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-ae2981a1-0adf-4d91-8cfb-644b313657b9
STEP: Updating secret s-test-opt-upd-d7ac4c56-7ae2-41bd-86e1-9c481d64bd65
STEP: Creating secret with name s-test-opt-create-dd9f7f74-bc62-48ec-b26c-00d7e30939da
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 18:56:29.305: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9836" for this suite.
Aug  3 18:56:53.352: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 18:56:53.673: INFO: namespace secrets-9836 deletion completed in 24.356778741s

• [SLOW TEST:97.841 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 18:56:53.674: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-7913
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1722
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Aug  3 18:56:53.913: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 run e2e-test-nginx-pod --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --labels=run=e2e-test-nginx-pod --namespace=kubectl-7913'
Aug  3 18:56:54.135: INFO: stderr: ""
Aug  3 18:56:54.135: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod is running
STEP: verifying the pod e2e-test-nginx-pod was created
Aug  3 18:56:59.186: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 get pod e2e-test-nginx-pod --namespace=kubectl-7913 -o json'
Aug  3 18:56:59.288: INFO: stderr: ""
Aug  3 18:56:59.288: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"annotations\": {\n            \"kubernetes.io/psp\": \"e2e-test-privileged-psp\"\n        },\n        \"creationTimestamp\": \"2019-08-03T18:56:54Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"kubectl-7913\",\n        \"resourceVersion\": \"50186\",\n        \"selfLink\": \"/api/v1/namespaces/kubectl-7913/pods/e2e-test-nginx-pod\",\n        \"uid\": \"a222e282-18d7-413f-bde2-1d3f716a0596\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-r85ml\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"10.188.31.32\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 600\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 600\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-r85ml\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-r85ml\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-08-03T18:56:54Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-08-03T18:56:55Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-08-03T18:56:55Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-08-03T18:56:54Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"containerd://987bb68eca46d9a3313c7bc0d0786386689be63e8a46518ef534296674195b5e\",\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imageID\": \"docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2019-08-03T18:56:55Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.188.31.32\",\n        \"phase\": \"Running\",\n        \"podIP\": \"172.30.72.111\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2019-08-03T18:56:54Z\"\n    }\n}\n"
STEP: replace the image in the pod
Aug  3 18:56:59.288: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 replace -f - --namespace=kubectl-7913'
Aug  3 18:56:59.662: INFO: stderr: ""
Aug  3 18:56:59.662: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
STEP: verifying the pod e2e-test-nginx-pod has the right image docker.io/library/busybox:1.29
[AfterEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1727
Aug  3 18:56:59.669: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 delete pods e2e-test-nginx-pod --namespace=kubectl-7913'
Aug  3 18:57:01.752: INFO: stderr: ""
Aug  3 18:57:01.752: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 18:57:01.753: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7913" for this suite.
Aug  3 18:57:07.801: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 18:57:08.131: INFO: namespace kubectl-7913 deletion completed in 6.365711588s

• [SLOW TEST:14.457 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl replace
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 18:57:08.131: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-1574
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-map-59c2e1ed-4beb-4542-bc08-057a34c4ebf7
STEP: Creating a pod to test consume configMaps
Aug  3 18:57:08.381: INFO: Waiting up to 5m0s for pod "pod-configmaps-499b978a-0ad2-4c20-ab4c-a60fe0772385" in namespace "configmap-1574" to be "success or failure"
Aug  3 18:57:08.389: INFO: Pod "pod-configmaps-499b978a-0ad2-4c20-ab4c-a60fe0772385": Phase="Pending", Reason="", readiness=false. Elapsed: 8.115503ms
Aug  3 18:57:10.409: INFO: Pod "pod-configmaps-499b978a-0ad2-4c20-ab4c-a60fe0772385": Phase="Pending", Reason="", readiness=false. Elapsed: 2.028589858s
Aug  3 18:57:12.419: INFO: Pod "pod-configmaps-499b978a-0ad2-4c20-ab4c-a60fe0772385": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.038739262s
STEP: Saw pod success
Aug  3 18:57:12.419: INFO: Pod "pod-configmaps-499b978a-0ad2-4c20-ab4c-a60fe0772385" satisfied condition "success or failure"
Aug  3 18:57:12.429: INFO: Trying to get logs from node 10.188.31.32 pod pod-configmaps-499b978a-0ad2-4c20-ab4c-a60fe0772385 container configmap-volume-test: <nil>
STEP: delete the pod
Aug  3 18:57:12.480: INFO: Waiting for pod pod-configmaps-499b978a-0ad2-4c20-ab4c-a60fe0772385 to disappear
Aug  3 18:57:12.487: INFO: Pod pod-configmaps-499b978a-0ad2-4c20-ab4c-a60fe0772385 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 18:57:12.487: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1574" for this suite.
Aug  3 18:57:18.569: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 18:57:18.914: INFO: namespace configmap-1574 deletion completed in 6.395434558s

• [SLOW TEST:10.783 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 18:57:18.914: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-5339
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: validating cluster-info
Aug  3 18:57:19.138: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 cluster-info'
Aug  3 18:57:19.268: INFO: stderr: ""
Aug  3 18:57:19.268: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://172.21.0.1:443\x1b[0m\n\x1b[0;32mCoreDNS\x1b[0m is running at \x1b[0;33mhttps://172.21.0.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\x1b[0;32mkubernetes-dashboard\x1b[0m is running at \x1b[0;33mhttps://172.21.0.1:443/api/v1/namespaces/kube-system/services/https:kubernetes-dashboard:/proxy\x1b[0m\n\x1b[0;32mMetrics-server\x1b[0m is running at \x1b[0;33mhttps://172.21.0.1:443/api/v1/namespaces/kube-system/services/https:metrics-server:/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 18:57:19.269: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5339" for this suite.
Aug  3 18:57:25.308: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 18:57:25.620: INFO: namespace kubectl-5339 deletion completed in 6.341341076s

• [SLOW TEST:6.706 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl cluster-info
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 18:57:25.621: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-4186
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name cm-test-opt-del-70365d64-3bf5-4184-aeec-5b30a748173f
STEP: Creating configMap with name cm-test-opt-upd-0b8e44a7-0824-4230-a3a0-e2b1b1b76fda
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-70365d64-3bf5-4184-aeec-5b30a748173f
STEP: Updating configmap cm-test-opt-upd-0b8e44a7-0824-4230-a3a0-e2b1b1b76fda
STEP: Creating configMap with name cm-test-opt-create-c6c15d52-726a-4777-a7ce-002ca1ac75dd
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 18:58:32.745: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4186" for this suite.
Aug  3 18:58:56.795: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 18:58:57.099: INFO: namespace configmap-4186 deletion completed in 24.342719809s

• [SLOW TEST:91.478 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 18:58:57.099: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9119
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name s-test-opt-del-e16630a2-af47-47e5-b7f4-a18be5c08e30
STEP: Creating secret with name s-test-opt-upd-5f211301-be54-4760-9939-ed572dc0a81b
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-e16630a2-af47-47e5-b7f4-a18be5c08e30
STEP: Updating secret s-test-opt-upd-5f211301-be54-4760-9939-ed572dc0a81b
STEP: Creating secret with name s-test-opt-create-78711f80-b8c0-4f98-8cb5-5f4da3f4d319
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 19:00:08.338: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9119" for this suite.
Aug  3 19:00:32.407: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 19:00:32.726: INFO: namespace projected-9119 deletion completed in 24.356504753s

• [SLOW TEST:95.627 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 19:00:32.727: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-6169
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-42685ddc-3baf-4c5d-b2ee-86000a91fdfc
STEP: Creating a pod to test consume configMaps
Aug  3 19:00:32.968: INFO: Waiting up to 5m0s for pod "pod-configmaps-3fd1d0ac-117d-485c-b7ed-6d302e2d578d" in namespace "configmap-6169" to be "success or failure"
Aug  3 19:00:32.976: INFO: Pod "pod-configmaps-3fd1d0ac-117d-485c-b7ed-6d302e2d578d": Phase="Pending", Reason="", readiness=false. Elapsed: 7.733367ms
Aug  3 19:00:34.985: INFO: Pod "pod-configmaps-3fd1d0ac-117d-485c-b7ed-6d302e2d578d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016607179s
Aug  3 19:00:36.993: INFO: Pod "pod-configmaps-3fd1d0ac-117d-485c-b7ed-6d302e2d578d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02531431s
STEP: Saw pod success
Aug  3 19:00:36.993: INFO: Pod "pod-configmaps-3fd1d0ac-117d-485c-b7ed-6d302e2d578d" satisfied condition "success or failure"
Aug  3 19:00:37.009: INFO: Trying to get logs from node 10.188.31.32 pod pod-configmaps-3fd1d0ac-117d-485c-b7ed-6d302e2d578d container configmap-volume-test: <nil>
STEP: delete the pod
Aug  3 19:00:37.061: INFO: Waiting for pod pod-configmaps-3fd1d0ac-117d-485c-b7ed-6d302e2d578d to disappear
Aug  3 19:00:37.068: INFO: Pod pod-configmaps-3fd1d0ac-117d-485c-b7ed-6d302e2d578d no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 19:00:37.068: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6169" for this suite.
Aug  3 19:00:43.127: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 19:00:43.433: INFO: namespace configmap-6169 deletion completed in 6.351772069s

• [SLOW TEST:10.706 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 19:00:43.433: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-8585
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating the pod
Aug  3 19:00:46.291: INFO: Successfully updated pod "labelsupdate04c8e11f-8ce0-4fa9-bd9a-2d1d22739908"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 19:00:50.349: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8585" for this suite.
Aug  3 19:01:14.591: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 19:01:14.888: INFO: namespace downward-api-8585 deletion completed in 24.524502298s

• [SLOW TEST:31.455 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 19:01:14.890: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-4385
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
Aug  3 19:01:25.183: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W0803 19:01:25.183024      17 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 19:01:25.183: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-4385" for this suite.
Aug  3 19:01:31.224: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 19:01:31.532: INFO: namespace gc-4385 deletion completed in 6.339120695s

• [SLOW TEST:16.641 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 19:01:31.532: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-8164
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Aug  3 19:01:31.761: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c7d5e25e-a0df-4946-a201-86c965206a57" in namespace "downward-api-8164" to be "success or failure"
Aug  3 19:01:31.770: INFO: Pod "downwardapi-volume-c7d5e25e-a0df-4946-a201-86c965206a57": Phase="Pending", Reason="", readiness=false. Elapsed: 8.551261ms
Aug  3 19:01:33.789: INFO: Pod "downwardapi-volume-c7d5e25e-a0df-4946-a201-86c965206a57": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.027855693s
STEP: Saw pod success
Aug  3 19:01:33.789: INFO: Pod "downwardapi-volume-c7d5e25e-a0df-4946-a201-86c965206a57" satisfied condition "success or failure"
Aug  3 19:01:33.797: INFO: Trying to get logs from node 10.188.31.24 pod downwardapi-volume-c7d5e25e-a0df-4946-a201-86c965206a57 container client-container: <nil>
STEP: delete the pod
Aug  3 19:01:33.836: INFO: Waiting for pod downwardapi-volume-c7d5e25e-a0df-4946-a201-86c965206a57 to disappear
Aug  3 19:01:33.843: INFO: Pod downwardapi-volume-c7d5e25e-a0df-4946-a201-86c965206a57 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 19:01:33.843: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8164" for this suite.
Aug  3 19:01:39.889: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 19:01:40.234: INFO: namespace downward-api-8164 deletion completed in 6.380235883s

• [SLOW TEST:8.702 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 19:01:40.235: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-3239
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Aug  3 19:01:40.450: INFO: Creating deployment "test-recreate-deployment"
Aug  3 19:01:40.460: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Aug  3 19:01:40.480: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
Aug  3 19:01:42.497: INFO: Waiting deployment "test-recreate-deployment" to complete
Aug  3 19:01:42.506: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Aug  3 19:01:42.529: INFO: Updating deployment test-recreate-deployment
Aug  3 19:01:42.529: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
Aug  3 19:01:42.651: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment,GenerateName:,Namespace:deployment-3239,SelfLink:/apis/apps/v1/namespaces/deployment-3239/deployments/test-recreate-deployment,UID:a2db261a-28af-43a5-9f39-e07778fb97b0,ResourceVersion:51076,Generation:2,CreationTimestamp:2019-08-03 19:01:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[{Available False 2019-08-03 19:01:42 +0000 UTC 2019-08-03 19:01:42 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-08-03 19:01:42 +0000 UTC 2019-08-03 19:01:40 +0000 UTC ReplicaSetUpdated ReplicaSet "test-recreate-deployment-5c8c9cc69d" is progressing.}],ReadyReplicas:0,CollisionCount:nil,},}

Aug  3 19:01:42.660: INFO: New ReplicaSet "test-recreate-deployment-5c8c9cc69d" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-5c8c9cc69d,GenerateName:,Namespace:deployment-3239,SelfLink:/apis/apps/v1/namespaces/deployment-3239/replicasets/test-recreate-deployment-5c8c9cc69d,UID:07f2465d-af10-4946-998f-4272aa3c2219,ResourceVersion:51074,Generation:1,CreationTimestamp:2019-08-03 19:01:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5c8c9cc69d,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment a2db261a-28af-43a5-9f39-e07778fb97b0 0xc001fc6497 0xc001fc6498}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 5c8c9cc69d,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5c8c9cc69d,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Aug  3 19:01:42.660: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Aug  3 19:01:42.660: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-6df85df6b9,GenerateName:,Namespace:deployment-3239,SelfLink:/apis/apps/v1/namespaces/deployment-3239/replicasets/test-recreate-deployment-6df85df6b9,UID:53f8dc8d-02a7-491d-9293-4f6db10758bd,ResourceVersion:51065,Generation:2,CreationTimestamp:2019-08-03 19:01:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 6df85df6b9,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment a2db261a-28af-43a5-9f39-e07778fb97b0 0xc001fc6667 0xc001fc6668}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 6df85df6b9,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 6df85df6b9,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Aug  3 19:01:42.668: INFO: Pod "test-recreate-deployment-5c8c9cc69d-fvr4c" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-5c8c9cc69d-fvr4c,GenerateName:test-recreate-deployment-5c8c9cc69d-,Namespace:deployment-3239,SelfLink:/api/v1/namespaces/deployment-3239/pods/test-recreate-deployment-5c8c9cc69d-fvr4c,UID:98f278b6-8109-4163-92aa-6237fbcf778a,ResourceVersion:51077,Generation:0,CreationTimestamp:2019-08-03 19:01:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5c8c9cc69d,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-recreate-deployment-5c8c9cc69d 07f2465d-af10-4946-998f-4272aa3c2219 0xc001fc71d7 0xc001fc71d8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-2zsp9 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-2zsp9,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-2zsp9 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.188.31.32,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001fc7250} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001fc7270}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-03 19:01:42 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-03 19:01:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-03 19:01:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-03 19:01:42 +0000 UTC  }],Message:,Reason:,HostIP:10.188.31.32,PodIP:,StartTime:2019-08-03 19:01:42 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 19:01:42.668: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-3239" for this suite.
Aug  3 19:01:48.710: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 19:01:49.046: INFO: namespace deployment-3239 deletion completed in 6.366175448s

• [SLOW TEST:8.811 seconds]
[sig-apps] Deployment
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 19:01:49.048: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-2753
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-2753
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace statefulset-2753
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-2753
Aug  3 19:01:49.307: INFO: Found 0 stateful pods, waiting for 1
Aug  3 19:01:59.317: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Aug  3 19:01:59.325: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 exec --namespace=statefulset-2753 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Aug  3 19:01:59.781: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Aug  3 19:01:59.781: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Aug  3 19:01:59.781: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Aug  3 19:01:59.789: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Aug  3 19:02:09.804: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Aug  3 19:02:09.804: INFO: Waiting for statefulset status.replicas updated to 0
Aug  3 19:02:09.843: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999998514s
Aug  3 19:02:10.855: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.992358627s
Aug  3 19:02:11.863: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.980428818s
Aug  3 19:02:12.872: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.971852482s
Aug  3 19:02:13.882: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.963227056s
Aug  3 19:02:14.890: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.953461447s
Aug  3 19:02:15.909: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.944911829s
Aug  3 19:02:16.918: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.926074513s
Aug  3 19:02:17.927: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.917298676s
Aug  3 19:02:18.936: INFO: Verifying statefulset ss doesn't scale past 1 for another 908.101522ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-2753
Aug  3 19:02:19.946: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 exec --namespace=statefulset-2753 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  3 19:02:20.381: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Aug  3 19:02:20.381: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Aug  3 19:02:20.381: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Aug  3 19:02:20.390: INFO: Found 1 stateful pods, waiting for 3
Aug  3 19:02:30.409: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Aug  3 19:02:30.409: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Aug  3 19:02:30.409: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Aug  3 19:02:30.422: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 exec --namespace=statefulset-2753 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Aug  3 19:02:30.874: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Aug  3 19:02:30.874: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Aug  3 19:02:30.874: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Aug  3 19:02:30.874: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 exec --namespace=statefulset-2753 ss-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Aug  3 19:02:31.315: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Aug  3 19:02:31.315: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Aug  3 19:02:31.315: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Aug  3 19:02:31.315: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 exec --namespace=statefulset-2753 ss-2 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Aug  3 19:02:31.765: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Aug  3 19:02:31.766: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Aug  3 19:02:31.766: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Aug  3 19:02:31.766: INFO: Waiting for statefulset status.replicas updated to 0
Aug  3 19:02:31.774: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 1
Aug  3 19:02:41.792: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Aug  3 19:02:41.792: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Aug  3 19:02:41.792: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Aug  3 19:02:41.826: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.99999836s
Aug  3 19:02:42.835: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.991829984s
Aug  3 19:02:43.844: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.98283784s
Aug  3 19:02:44.853: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.974310968s
Aug  3 19:02:45.864: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.965096831s
Aug  3 19:02:46.875: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.953812291s
Aug  3 19:02:47.882: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.943374239s
Aug  3 19:02:48.891: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.935774073s
Aug  3 19:02:49.909: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.926894218s
Aug  3 19:02:50.919: INFO: Verifying statefulset ss doesn't scale past 3 for another 908.721635ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-2753
Aug  3 19:02:51.930: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 exec --namespace=statefulset-2753 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  3 19:02:52.350: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Aug  3 19:02:52.350: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Aug  3 19:02:52.350: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Aug  3 19:02:52.350: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 exec --namespace=statefulset-2753 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  3 19:02:52.758: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Aug  3 19:02:52.758: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Aug  3 19:02:52.758: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Aug  3 19:02:52.758: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 exec --namespace=statefulset-2753 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  3 19:02:53.094: INFO: rc: 1
Aug  3 19:02:53.094: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-322553265 exec --namespace=statefulset-2753 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  error: Internal error occurred: error executing command in container: failed to exec in container: failed to create exec "c6207e976537eade89e1d1f3d01fbb595bc22a483764f3eb0aa7c946d0d6c272": cannot exec in a stopped state: unknown
 [] <nil> 0xc001508180 exit status 1 <nil> <nil> true [0xc0024e8a78 0xc0024e8b40 0xc0024e8bc0] [0xc0024e8a78 0xc0024e8b40 0xc0024e8bc0] [0xc0024e8b00 0xc0024e8bb0] [0x9d17b0 0x9d17b0] 0xc002d84ae0 <nil>}:
Command stdout:

stderr:
error: Internal error occurred: error executing command in container: failed to exec in container: failed to create exec "c6207e976537eade89e1d1f3d01fbb595bc22a483764f3eb0aa7c946d0d6c272": cannot exec in a stopped state: unknown

error:
exit status 1
Aug  3 19:03:03.095: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 exec --namespace=statefulset-2753 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  3 19:03:03.226: INFO: rc: 1
Aug  3 19:03:03.226: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-322553265 exec --namespace=statefulset-2753 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc003725ef0 exit status 1 <nil> <nil> true [0xc0004b33b0 0xc0004b3468 0xc0004b3600] [0xc0004b33b0 0xc0004b3468 0xc0004b3600] [0xc0004b3458 0xc0004b35b0] [0x9d17b0 0x9d17b0] 0xc0034eed20 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Aug  3 19:03:13.226: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 exec --namespace=statefulset-2753 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  3 19:03:13.352: INFO: rc: 1
Aug  3 19:03:13.352: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-322553265 exec --namespace=statefulset-2753 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc003464690 exit status 1 <nil> <nil> true [0xc003722078 0xc0037220a0 0xc0037220c8] [0xc003722078 0xc0037220a0 0xc0037220c8] [0xc003722088 0xc0037220c0] [0x9d17b0 0x9d17b0] 0xc00321e780 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Aug  3 19:03:23.352: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 exec --namespace=statefulset-2753 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  3 19:03:23.471: INFO: rc: 1
Aug  3 19:03:23.472: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-322553265 exec --namespace=statefulset-2753 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc003464a50 exit status 1 <nil> <nil> true [0xc0037220d8 0xc003722118 0xc003722148] [0xc0037220d8 0xc003722118 0xc003722148] [0xc003722100 0xc003722130] [0x9d17b0 0x9d17b0] 0xc00321ef60 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Aug  3 19:03:33.472: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 exec --namespace=statefulset-2753 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  3 19:03:33.585: INFO: rc: 1
Aug  3 19:03:33.585: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-322553265 exec --namespace=statefulset-2753 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc003464de0 exit status 1 <nil> <nil> true [0xc0037221a8 0xc0037221f0 0xc003722240] [0xc0037221a8 0xc0037221f0 0xc003722240] [0xc0037221d8 0xc003722228] [0x9d17b0 0x9d17b0] 0xc00321f3e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Aug  3 19:03:43.586: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 exec --namespace=statefulset-2753 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  3 19:03:43.709: INFO: rc: 1
Aug  3 19:03:43.709: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-322553265 exec --namespace=statefulset-2753 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0024dd5c0 exit status 1 <nil> <nil> true [0xc001a16780 0xc001a16818 0xc001a16968] [0xc001a16780 0xc001a16818 0xc001a16968] [0xc001a16810 0xc001a16948] [0x9d17b0 0x9d17b0] 0xc0035f10e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Aug  3 19:03:53.709: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 exec --namespace=statefulset-2753 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  3 19:03:53.848: INFO: rc: 1
Aug  3 19:03:53.848: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-322553265 exec --namespace=statefulset-2753 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc003465140 exit status 1 <nil> <nil> true [0xc003722248 0xc003722270 0xc0037222c8] [0xc003722248 0xc003722270 0xc0037222c8] [0xc003722268 0xc0037222b0] [0x9d17b0 0x9d17b0] 0xc00321f740 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Aug  3 19:04:03.848: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 exec --namespace=statefulset-2753 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  3 19:04:03.989: INFO: rc: 1
Aug  3 19:04:03.989: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-322553265 exec --namespace=statefulset-2753 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0034654a0 exit status 1 <nil> <nil> true [0xc0037222e8 0xc003722310 0xc003722328] [0xc0037222e8 0xc003722310 0xc003722328] [0xc003722308 0xc003722320] [0x9d17b0 0x9d17b0] 0xc00321faa0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Aug  3 19:04:13.989: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 exec --namespace=statefulset-2753 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  3 19:04:14.122: INFO: rc: 1
Aug  3 19:04:14.122: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-322553265 exec --namespace=statefulset-2753 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0024dd920 exit status 1 <nil> <nil> true [0xc001a16988 0xc001a16a30 0xc001a16b20] [0xc001a16988 0xc001a16a30 0xc001a16b20] [0xc001a169f8 0xc001a16ab0] [0x9d17b0 0x9d17b0] 0xc0035f1440 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Aug  3 19:04:24.122: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 exec --namespace=statefulset-2753 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  3 19:04:24.247: INFO: rc: 1
Aug  3 19:04:24.247: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-322553265 exec --namespace=statefulset-2753 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0022f8480 exit status 1 <nil> <nil> true [0xc0004b3618 0xc0004b3670 0xc0004b3748] [0xc0004b3618 0xc0004b3670 0xc0004b3748] [0xc0004b3658 0xc0004b36b8] [0x9d17b0 0x9d17b0] 0xc0034ef0e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Aug  3 19:04:34.248: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 exec --namespace=statefulset-2753 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  3 19:04:34.359: INFO: rc: 1
Aug  3 19:04:34.359: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-322553265 exec --namespace=statefulset-2753 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001908300 exit status 1 <nil> <nil> true [0xc0004b2168 0xc0004b24c0 0xc0004b2678] [0xc0004b2168 0xc0004b24c0 0xc0004b2678] [0xc0004b2318 0xc0004b2558] [0x9d17b0 0x9d17b0] 0xc00239e480 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Aug  3 19:04:44.359: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 exec --namespace=statefulset-2753 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  3 19:04:44.494: INFO: rc: 1
Aug  3 19:04:44.494: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-322553265 exec --namespace=statefulset-2753 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc003724330 exit status 1 <nil> <nil> true [0xc001a16048 0xc001a161a0 0xc001a162b0] [0xc001a16048 0xc001a161a0 0xc001a162b0] [0xc001a16180 0xc001a16238] [0x9d17b0 0x9d17b0] 0xc00251e8a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Aug  3 19:04:54.494: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 exec --namespace=statefulset-2753 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  3 19:04:54.619: INFO: rc: 1
Aug  3 19:04:54.619: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-322553265 exec --namespace=statefulset-2753 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0037246c0 exit status 1 <nil> <nil> true [0xc001a162c8 0xc001a16350 0xc001a163e8] [0xc001a162c8 0xc001a16350 0xc001a163e8] [0xc001a162e0 0xc001a163c8] [0x9d17b0 0x9d17b0] 0xc00251efc0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Aug  3 19:05:04.619: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 exec --namespace=statefulset-2753 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  3 19:05:04.738: INFO: rc: 1
Aug  3 19:05:04.738: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-322553265 exec --namespace=statefulset-2753 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc003724a20 exit status 1 <nil> <nil> true [0xc001a16448 0xc001a16588 0xc001a166f0] [0xc001a16448 0xc001a16588 0xc001a166f0] [0xc001a16540 0xc001a166b0] [0x9d17b0 0x9d17b0] 0xc00251fbc0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Aug  3 19:05:14.738: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 exec --namespace=statefulset-2753 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  3 19:05:14.858: INFO: rc: 1
Aug  3 19:05:14.858: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-322553265 exec --namespace=statefulset-2753 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0028c8300 exit status 1 <nil> <nil> true [0xc0024e8018 0xc0024e80b8 0xc0024e80f0] [0xc0024e8018 0xc0024e80b8 0xc0024e80f0] [0xc0024e80a8 0xc0024e80e0] [0x9d17b0 0x9d17b0] 0xc0034ee360 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Aug  3 19:05:24.858: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 exec --namespace=statefulset-2753 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  3 19:05:24.973: INFO: rc: 1
Aug  3 19:05:24.973: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-322553265 exec --namespace=statefulset-2753 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0028c8690 exit status 1 <nil> <nil> true [0xc0024e8120 0xc0024e8180 0xc0024e8200] [0xc0024e8120 0xc0024e8180 0xc0024e8200] [0xc0024e8170 0xc0024e81e8] [0x9d17b0 0x9d17b0] 0xc0034ee6c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Aug  3 19:05:34.973: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 exec --namespace=statefulset-2753 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  3 19:05:35.100: INFO: rc: 1
Aug  3 19:05:35.100: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-322553265 exec --namespace=statefulset-2753 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002fb4390 exit status 1 <nil> <nil> true [0xc003722008 0xc003722050 0xc003722080] [0xc003722008 0xc003722050 0xc003722080] [0xc003722048 0xc003722078] [0x9d17b0 0x9d17b0] 0xc0035f03c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Aug  3 19:05:45.100: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 exec --namespace=statefulset-2753 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  3 19:05:45.251: INFO: rc: 1
Aug  3 19:05:45.251: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-322553265 exec --namespace=statefulset-2753 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0028c89f0 exit status 1 <nil> <nil> true [0xc0024e8210 0xc0024e8258 0xc0024e82a0] [0xc0024e8210 0xc0024e8258 0xc0024e82a0] [0xc0024e8230 0xc0024e8290] [0x9d17b0 0x9d17b0] 0xc0034eea80 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Aug  3 19:05:55.251: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 exec --namespace=statefulset-2753 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  3 19:05:55.399: INFO: rc: 1
Aug  3 19:05:55.399: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-322553265 exec --namespace=statefulset-2753 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001908630 exit status 1 <nil> <nil> true [0xc0004b2888 0xc0004b2b00 0xc0004b2ca8] [0xc0004b2888 0xc0004b2b00 0xc0004b2ca8] [0xc0004b2aa8 0xc0004b2c48] [0x9d17b0 0x9d17b0] 0xc00239e9c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Aug  3 19:06:05.399: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 exec --namespace=statefulset-2753 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  3 19:06:05.530: INFO: rc: 1
Aug  3 19:06:05.530: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-322553265 exec --namespace=statefulset-2753 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0019089c0 exit status 1 <nil> <nil> true [0xc0004b2ec0 0xc0004b3148 0xc0004b32e8] [0xc0004b2ec0 0xc0004b3148 0xc0004b32e8] [0xc0004b3118 0xc0004b3210] [0x9d17b0 0x9d17b0] 0xc00239f3e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Aug  3 19:06:15.530: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 exec --namespace=statefulset-2753 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  3 19:06:15.653: INFO: rc: 1
Aug  3 19:06:15.653: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-322553265 exec --namespace=statefulset-2753 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0028c8d80 exit status 1 <nil> <nil> true [0xc0024e82b0 0xc0024e8348 0xc0024e8400] [0xc0024e82b0 0xc0024e8348 0xc0024e8400] [0xc0024e8340 0xc0024e83c8] [0x9d17b0 0x9d17b0] 0xc0034eef00 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Aug  3 19:06:25.653: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 exec --namespace=statefulset-2753 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  3 19:06:25.793: INFO: rc: 1
Aug  3 19:06:25.793: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-322553265 exec --namespace=statefulset-2753 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002fb46f0 exit status 1 <nil> <nil> true [0xc003722088 0xc0037220c0 0xc0037220f8] [0xc003722088 0xc0037220c0 0xc0037220f8] [0xc0037220b8 0xc0037220d8] [0x9d17b0 0x9d17b0] 0xc0035f0720 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Aug  3 19:06:35.794: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 exec --namespace=statefulset-2753 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  3 19:06:35.922: INFO: rc: 1
Aug  3 19:06:35.922: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-322553265 exec --namespace=statefulset-2753 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc003724300 exit status 1 <nil> <nil> true [0xc001a160f8 0xc001a161c0 0xc001a162c8] [0xc001a160f8 0xc001a161c0 0xc001a162c8] [0xc001a161a0 0xc001a162b0] [0x9d17b0 0x9d17b0] 0xc00251e8a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Aug  3 19:06:45.922: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 exec --namespace=statefulset-2753 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  3 19:06:46.058: INFO: rc: 1
Aug  3 19:06:46.058: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-322553265 exec --namespace=statefulset-2753 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0028c8330 exit status 1 <nil> <nil> true [0xc003722008 0xc003722050 0xc003722080] [0xc003722008 0xc003722050 0xc003722080] [0xc003722048 0xc003722078] [0x9d17b0 0x9d17b0] 0xc0035f03c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Aug  3 19:06:56.059: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 exec --namespace=statefulset-2753 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  3 19:06:56.315: INFO: rc: 1
Aug  3 19:06:56.316: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-322553265 exec --namespace=statefulset-2753 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0028c86c0 exit status 1 <nil> <nil> true [0xc003722088 0xc0037220c0 0xc0037220f8] [0xc003722088 0xc0037220c0 0xc0037220f8] [0xc0037220b8 0xc0037220d8] [0x9d17b0 0x9d17b0] 0xc0035f0720 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Aug  3 19:07:06.316: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 exec --namespace=statefulset-2753 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  3 19:07:06.442: INFO: rc: 1
Aug  3 19:07:06.442: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-322553265 exec --namespace=statefulset-2753 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0028c8a20 exit status 1 <nil> <nil> true [0xc003722100 0xc003722130 0xc0037221b0] [0xc003722100 0xc003722130 0xc0037221b0] [0xc003722120 0xc0037221a8] [0x9d17b0 0x9d17b0] 0xc0035f0a80 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Aug  3 19:07:16.442: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 exec --namespace=statefulset-2753 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  3 19:07:16.568: INFO: rc: 1
Aug  3 19:07:16.568: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-322553265 exec --namespace=statefulset-2753 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001908360 exit status 1 <nil> <nil> true [0xc0024e8018 0xc0024e80b8 0xc0024e80f0] [0xc0024e8018 0xc0024e80b8 0xc0024e80f0] [0xc0024e80a8 0xc0024e80e0] [0x9d17b0 0x9d17b0] 0xc0034ee360 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Aug  3 19:07:26.568: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 exec --namespace=statefulset-2753 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  3 19:07:26.698: INFO: rc: 1
Aug  3 19:07:26.698: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-322553265 exec --namespace=statefulset-2753 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0028c8db0 exit status 1 <nil> <nil> true [0xc0037221d8 0xc003722228 0xc003722260] [0xc0037221d8 0xc003722228 0xc003722260] [0xc003722208 0xc003722248] [0x9d17b0 0x9d17b0] 0xc0035f0f00 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Aug  3 19:07:36.699: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 exec --namespace=statefulset-2753 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  3 19:07:36.838: INFO: rc: 1
Aug  3 19:07:36.838: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-322553265 exec --namespace=statefulset-2753 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0028c90e0 exit status 1 <nil> <nil> true [0xc003722268 0xc0037222b0 0xc003722300] [0xc003722268 0xc0037222b0 0xc003722300] [0xc003722290 0xc0037222e8] [0x9d17b0 0x9d17b0] 0xc0035f12c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Aug  3 19:07:46.838: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 exec --namespace=statefulset-2753 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  3 19:07:46.974: INFO: rc: 1
Aug  3 19:07:46.974: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-322553265 exec --namespace=statefulset-2753 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001908750 exit status 1 <nil> <nil> true [0xc0024e8120 0xc0024e8180 0xc0024e8200] [0xc0024e8120 0xc0024e8180 0xc0024e8200] [0xc0024e8170 0xc0024e81e8] [0x9d17b0 0x9d17b0] 0xc0034ee6c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Aug  3 19:07:56.975: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 exec --namespace=statefulset-2753 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  3 19:07:57.097: INFO: rc: 1
Aug  3 19:07:57.097: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: 
Aug  3 19:07:57.097: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Aug  3 19:07:57.153: INFO: Deleting all statefulset in ns statefulset-2753
Aug  3 19:07:57.162: INFO: Scaling statefulset ss to 0
Aug  3 19:07:57.195: INFO: Waiting for statefulset status.replicas updated to 0
Aug  3 19:07:57.203: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 19:07:57.249: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-2753" for this suite.
Aug  3 19:08:03.309: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 19:08:03.657: INFO: namespace statefulset-2753 deletion completed in 6.395586594s

• [SLOW TEST:374.610 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 19:08:03.658: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-3254
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Aug  3 19:08:21.930: INFO: Container started at 2019-08-03 19:08:05 +0000 UTC, pod became ready at 2019-08-03 19:08:21 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 19:08:21.930: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-3254" for this suite.
Aug  3 19:08:45.975: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 19:08:46.349: INFO: namespace container-probe-3254 deletion completed in 24.407799478s

• [SLOW TEST:42.692 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 19:08:46.350: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-6085
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-6085
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a new StatefulSet
Aug  3 19:08:46.662: INFO: Found 0 stateful pods, waiting for 3
Aug  3 19:08:56.672: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Aug  3 19:08:56.672: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Aug  3 19:08:56.672: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Aug  3 19:08:56.728: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Aug  3 19:09:06.798: INFO: Updating stateful set ss2
Aug  3 19:09:06.852: INFO: Waiting for Pod statefulset-6085/ss2-2 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
STEP: Restoring Pods to the correct revision when they are deleted
Aug  3 19:09:16.941: INFO: Found 1 stateful pods, waiting for 3
Aug  3 19:09:26.952: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Aug  3 19:09:26.952: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Aug  3 19:09:26.952: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Aug  3 19:09:27.015: INFO: Updating stateful set ss2
Aug  3 19:09:27.038: INFO: Waiting for Pod statefulset-6085/ss2-1 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Aug  3 19:09:37.086: INFO: Updating stateful set ss2
Aug  3 19:09:37.104: INFO: Waiting for StatefulSet statefulset-6085/ss2 to complete update
Aug  3 19:09:37.104: INFO: Waiting for Pod statefulset-6085/ss2-0 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Aug  3 19:09:47.122: INFO: Waiting for StatefulSet statefulset-6085/ss2 to complete update
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Aug  3 19:09:57.132: INFO: Deleting all statefulset in ns statefulset-6085
Aug  3 19:09:57.140: INFO: Scaling statefulset ss2 to 0
Aug  3 19:10:17.180: INFO: Waiting for statefulset status.replicas updated to 0
Aug  3 19:10:17.189: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 19:10:17.229: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-6085" for this suite.
Aug  3 19:10:25.299: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 19:10:25.636: INFO: namespace statefulset-6085 deletion completed in 8.373750125s

• [SLOW TEST:99.286 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 19:10:25.641: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-4658
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Aug  3 19:10:25.879: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0a96b1ec-87bb-4435-8bb7-5d689f663873" in namespace "downward-api-4658" to be "success or failure"
Aug  3 19:10:25.894: INFO: Pod "downwardapi-volume-0a96b1ec-87bb-4435-8bb7-5d689f663873": Phase="Pending", Reason="", readiness=false. Elapsed: 15.261133ms
Aug  3 19:10:27.904: INFO: Pod "downwardapi-volume-0a96b1ec-87bb-4435-8bb7-5d689f663873": Phase="Running", Reason="", readiness=true. Elapsed: 2.024881751s
Aug  3 19:10:29.912: INFO: Pod "downwardapi-volume-0a96b1ec-87bb-4435-8bb7-5d689f663873": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.032682106s
STEP: Saw pod success
Aug  3 19:10:29.912: INFO: Pod "downwardapi-volume-0a96b1ec-87bb-4435-8bb7-5d689f663873" satisfied condition "success or failure"
Aug  3 19:10:29.919: INFO: Trying to get logs from node 10.188.31.32 pod downwardapi-volume-0a96b1ec-87bb-4435-8bb7-5d689f663873 container client-container: <nil>
STEP: delete the pod
Aug  3 19:10:29.962: INFO: Waiting for pod downwardapi-volume-0a96b1ec-87bb-4435-8bb7-5d689f663873 to disappear
Aug  3 19:10:29.970: INFO: Pod downwardapi-volume-0a96b1ec-87bb-4435-8bb7-5d689f663873 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 19:10:29.970: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4658" for this suite.
Aug  3 19:10:36.029: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 19:10:36.319: INFO: namespace downward-api-4658 deletion completed in 6.337990425s

• [SLOW TEST:10.679 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 19:10:36.321: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-7180
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Aug  3 19:10:36.530: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 version'
Aug  3 19:10:36.629: INFO: stderr: ""
Aug  3 19:10:36.629: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"15\", GitVersion:\"v1.15.1\", GitCommit:\"4485c6f18cee9a5d3c3b4e523bd27972b1b53892\", GitTreeState:\"clean\", BuildDate:\"2019-07-18T09:18:22Z\", GoVersion:\"go1.12.5\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"15\", GitVersion:\"v1.15.1+IKS\", GitCommit:\"936e0b7aec70b045339240cc594bb3d6c1c6f06a\", GitTreeState:\"clean\", BuildDate:\"2019-07-30T10:06:34Z\", GoVersion:\"go1.12.5\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 19:10:36.629: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7180" for this suite.
Aug  3 19:10:42.671: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 19:10:42.975: INFO: namespace kubectl-7180 deletion completed in 6.335181178s

• [SLOW TEST:6.654 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl version
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 19:10:42.976: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-6477
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:63
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Aug  3 19:10:49.309: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Aug  3 19:10:49.318: INFO: Pod pod-with-poststart-http-hook still exists
Aug  3 19:10:51.318: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Aug  3 19:10:51.328: INFO: Pod pod-with-poststart-http-hook still exists
Aug  3 19:10:53.318: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Aug  3 19:10:53.327: INFO: Pod pod-with-poststart-http-hook still exists
Aug  3 19:10:55.318: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Aug  3 19:10:55.326: INFO: Pod pod-with-poststart-http-hook still exists
Aug  3 19:10:57.318: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Aug  3 19:10:57.327: INFO: Pod pod-with-poststart-http-hook still exists
Aug  3 19:10:59.318: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Aug  3 19:10:59.328: INFO: Pod pod-with-poststart-http-hook still exists
Aug  3 19:11:01.318: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Aug  3 19:11:01.352: INFO: Pod pod-with-poststart-http-hook still exists
Aug  3 19:11:03.318: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Aug  3 19:11:03.329: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 19:11:03.329: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-6477" for this suite.
Aug  3 19:11:27.375: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 19:11:27.702: INFO: namespace container-lifecycle-hook-6477 deletion completed in 24.360967523s

• [SLOW TEST:44.727 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when create a pod with lifecycle hook
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 19:11:27.703: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-9271
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-projected-ltbq
STEP: Creating a pod to test atomic-volume-subpath
Aug  3 19:11:27.980: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-ltbq" in namespace "subpath-9271" to be "success or failure"
Aug  3 19:11:27.988: INFO: Pod "pod-subpath-test-projected-ltbq": Phase="Pending", Reason="", readiness=false. Elapsed: 7.370341ms
Aug  3 19:11:29.996: INFO: Pod "pod-subpath-test-projected-ltbq": Phase="Running", Reason="", readiness=true. Elapsed: 2.015639192s
Aug  3 19:11:32.008: INFO: Pod "pod-subpath-test-projected-ltbq": Phase="Running", Reason="", readiness=true. Elapsed: 4.027486866s
Aug  3 19:11:34.022: INFO: Pod "pod-subpath-test-projected-ltbq": Phase="Running", Reason="", readiness=true. Elapsed: 6.04134277s
Aug  3 19:11:36.031: INFO: Pod "pod-subpath-test-projected-ltbq": Phase="Running", Reason="", readiness=true. Elapsed: 8.050175977s
Aug  3 19:11:38.040: INFO: Pod "pod-subpath-test-projected-ltbq": Phase="Running", Reason="", readiness=true. Elapsed: 10.059635311s
Aug  3 19:11:40.048: INFO: Pod "pod-subpath-test-projected-ltbq": Phase="Running", Reason="", readiness=true. Elapsed: 12.067960166s
Aug  3 19:11:42.058: INFO: Pod "pod-subpath-test-projected-ltbq": Phase="Running", Reason="", readiness=true. Elapsed: 14.077626536s
Aug  3 19:11:44.066: INFO: Pod "pod-subpath-test-projected-ltbq": Phase="Running", Reason="", readiness=true. Elapsed: 16.086104933s
Aug  3 19:11:46.075: INFO: Pod "pod-subpath-test-projected-ltbq": Phase="Running", Reason="", readiness=true. Elapsed: 18.09416096s
Aug  3 19:11:48.089: INFO: Pod "pod-subpath-test-projected-ltbq": Phase="Running", Reason="", readiness=true. Elapsed: 20.108716583s
Aug  3 19:11:50.109: INFO: Pod "pod-subpath-test-projected-ltbq": Phase="Running", Reason="", readiness=true. Elapsed: 22.128748836s
Aug  3 19:11:52.118: INFO: Pod "pod-subpath-test-projected-ltbq": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.13768163s
STEP: Saw pod success
Aug  3 19:11:52.118: INFO: Pod "pod-subpath-test-projected-ltbq" satisfied condition "success or failure"
Aug  3 19:11:52.127: INFO: Trying to get logs from node 10.188.31.32 pod pod-subpath-test-projected-ltbq container test-container-subpath-projected-ltbq: <nil>
STEP: delete the pod
Aug  3 19:11:52.181: INFO: Waiting for pod pod-subpath-test-projected-ltbq to disappear
Aug  3 19:11:52.191: INFO: Pod pod-subpath-test-projected-ltbq no longer exists
STEP: Deleting pod pod-subpath-test-projected-ltbq
Aug  3 19:11:52.191: INFO: Deleting pod "pod-subpath-test-projected-ltbq" in namespace "subpath-9271"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 19:11:52.200: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-9271" for this suite.
Aug  3 19:11:58.243: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 19:11:58.663: INFO: namespace subpath-9271 deletion completed in 6.451526603s

• [SLOW TEST:30.961 seconds]
[sig-storage] Subpath
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with projected pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 19:11:58.664: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-3651
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:63
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Aug  3 19:12:04.983: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Aug  3 19:12:04.993: INFO: Pod pod-with-prestop-http-hook still exists
Aug  3 19:12:06.993: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Aug  3 19:12:07.018: INFO: Pod pod-with-prestop-http-hook still exists
Aug  3 19:12:08.993: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Aug  3 19:12:09.002: INFO: Pod pod-with-prestop-http-hook still exists
Aug  3 19:12:10.993: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Aug  3 19:12:11.002: INFO: Pod pod-with-prestop-http-hook still exists
Aug  3 19:12:12.993: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Aug  3 19:12:13.009: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 19:12:13.027: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-3651" for this suite.
Aug  3 19:12:37.069: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 19:12:37.377: INFO: namespace container-lifecycle-hook-3651 deletion completed in 24.338193488s

• [SLOW TEST:38.713 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when create a pod with lifecycle hook
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 19:12:37.380: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-1663
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 pods, got 2 pods
STEP: expected 0 rs, got 1 rs
STEP: Gathering metrics
Aug  3 19:12:38.709: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W0803 19:12:38.709803      17 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 19:12:38.709: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-1663" for this suite.
Aug  3 19:12:44.757: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 19:12:45.077: INFO: namespace gc-1663 deletion completed in 6.357044133s

• [SLOW TEST:7.698 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 19:12:45.078: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-9470
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-secret-6dg4
STEP: Creating a pod to test atomic-volume-subpath
Aug  3 19:12:45.338: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-6dg4" in namespace "subpath-9470" to be "success or failure"
Aug  3 19:12:45.345: INFO: Pod "pod-subpath-test-secret-6dg4": Phase="Pending", Reason="", readiness=false. Elapsed: 7.471018ms
Aug  3 19:12:47.354: INFO: Pod "pod-subpath-test-secret-6dg4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016234267s
Aug  3 19:12:49.369: INFO: Pod "pod-subpath-test-secret-6dg4": Phase="Running", Reason="", readiness=true. Elapsed: 4.031286729s
Aug  3 19:12:51.378: INFO: Pod "pod-subpath-test-secret-6dg4": Phase="Running", Reason="", readiness=true. Elapsed: 6.040310557s
Aug  3 19:12:53.387: INFO: Pod "pod-subpath-test-secret-6dg4": Phase="Running", Reason="", readiness=true. Elapsed: 8.049552195s
Aug  3 19:12:55.397: INFO: Pod "pod-subpath-test-secret-6dg4": Phase="Running", Reason="", readiness=true. Elapsed: 10.059519036s
Aug  3 19:12:57.409: INFO: Pod "pod-subpath-test-secret-6dg4": Phase="Running", Reason="", readiness=true. Elapsed: 12.071062256s
Aug  3 19:12:59.418: INFO: Pod "pod-subpath-test-secret-6dg4": Phase="Running", Reason="", readiness=true. Elapsed: 14.080152606s
Aug  3 19:13:01.426: INFO: Pod "pod-subpath-test-secret-6dg4": Phase="Running", Reason="", readiness=true. Elapsed: 16.088329977s
Aug  3 19:13:03.434: INFO: Pod "pod-subpath-test-secret-6dg4": Phase="Running", Reason="", readiness=true. Elapsed: 18.096501353s
Aug  3 19:13:05.447: INFO: Pod "pod-subpath-test-secret-6dg4": Phase="Running", Reason="", readiness=true. Elapsed: 20.109733321s
Aug  3 19:13:07.458: INFO: Pod "pod-subpath-test-secret-6dg4": Phase="Running", Reason="", readiness=true. Elapsed: 22.120534557s
Aug  3 19:13:09.466: INFO: Pod "pod-subpath-test-secret-6dg4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.128676547s
STEP: Saw pod success
Aug  3 19:13:09.466: INFO: Pod "pod-subpath-test-secret-6dg4" satisfied condition "success or failure"
Aug  3 19:13:09.474: INFO: Trying to get logs from node 10.188.31.32 pod pod-subpath-test-secret-6dg4 container test-container-subpath-secret-6dg4: <nil>
STEP: delete the pod
Aug  3 19:13:09.521: INFO: Waiting for pod pod-subpath-test-secret-6dg4 to disappear
Aug  3 19:13:09.529: INFO: Pod pod-subpath-test-secret-6dg4 no longer exists
STEP: Deleting pod pod-subpath-test-secret-6dg4
Aug  3 19:13:09.529: INFO: Deleting pod "pod-subpath-test-secret-6dg4" in namespace "subpath-9470"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 19:13:09.536: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-9470" for this suite.
Aug  3 19:13:15.585: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 19:13:15.893: INFO: namespace subpath-9470 deletion completed in 6.344101921s

• [SLOW TEST:30.815 seconds]
[sig-storage] Subpath
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with secret pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 19:13:15.893: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8463
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-map-5409624f-a826-4b44-bbf2-8d0c3fb35b88
STEP: Creating a pod to test consume secrets
Aug  3 19:13:16.153: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-f694670e-08f8-4f4e-b954-a9d3e441a0de" in namespace "projected-8463" to be "success or failure"
Aug  3 19:13:16.161: INFO: Pod "pod-projected-secrets-f694670e-08f8-4f4e-b954-a9d3e441a0de": Phase="Pending", Reason="", readiness=false. Elapsed: 8.150477ms
Aug  3 19:13:18.170: INFO: Pod "pod-projected-secrets-f694670e-08f8-4f4e-b954-a9d3e441a0de": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017164811s
Aug  3 19:13:20.189: INFO: Pod "pod-projected-secrets-f694670e-08f8-4f4e-b954-a9d3e441a0de": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.03579411s
STEP: Saw pod success
Aug  3 19:13:20.189: INFO: Pod "pod-projected-secrets-f694670e-08f8-4f4e-b954-a9d3e441a0de" satisfied condition "success or failure"
Aug  3 19:13:20.197: INFO: Trying to get logs from node 10.188.31.32 pod pod-projected-secrets-f694670e-08f8-4f4e-b954-a9d3e441a0de container projected-secret-volume-test: <nil>
STEP: delete the pod
Aug  3 19:13:20.239: INFO: Waiting for pod pod-projected-secrets-f694670e-08f8-4f4e-b954-a9d3e441a0de to disappear
Aug  3 19:13:20.246: INFO: Pod pod-projected-secrets-f694670e-08f8-4f4e-b954-a9d3e441a0de no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 19:13:20.246: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8463" for this suite.
Aug  3 19:13:26.292: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 19:13:26.816: INFO: namespace projected-8463 deletion completed in 6.554625909s

• [SLOW TEST:10.923 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 19:13:26.819: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-6573
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Aug  3 19:13:27.049: INFO: Waiting up to 5m0s for pod "downwardapi-volume-8380dfc5-8d15-4981-8205-44a92f2f3b43" in namespace "downward-api-6573" to be "success or failure"
Aug  3 19:13:27.056: INFO: Pod "downwardapi-volume-8380dfc5-8d15-4981-8205-44a92f2f3b43": Phase="Pending", Reason="", readiness=false. Elapsed: 7.16017ms
Aug  3 19:13:29.065: INFO: Pod "downwardapi-volume-8380dfc5-8d15-4981-8205-44a92f2f3b43": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015844396s
STEP: Saw pod success
Aug  3 19:13:29.065: INFO: Pod "downwardapi-volume-8380dfc5-8d15-4981-8205-44a92f2f3b43" satisfied condition "success or failure"
Aug  3 19:13:29.073: INFO: Trying to get logs from node 10.188.31.32 pod downwardapi-volume-8380dfc5-8d15-4981-8205-44a92f2f3b43 container client-container: <nil>
STEP: delete the pod
Aug  3 19:13:29.135: INFO: Waiting for pod downwardapi-volume-8380dfc5-8d15-4981-8205-44a92f2f3b43 to disappear
Aug  3 19:13:29.143: INFO: Pod downwardapi-volume-8380dfc5-8d15-4981-8205-44a92f2f3b43 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 19:13:29.144: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6573" for this suite.
Aug  3 19:13:35.193: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 19:13:35.497: INFO: namespace downward-api-6573 deletion completed in 6.337219816s

• [SLOW TEST:8.678 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 19:13:35.497: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7156
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-82ffbaf7-4e4b-4b78-9d5b-5a431b1ddb8b
STEP: Creating a pod to test consume secrets
Aug  3 19:13:35.741: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-cabcc025-0e9b-47a8-9735-4d0bd7fd9e11" in namespace "projected-7156" to be "success or failure"
Aug  3 19:13:35.748: INFO: Pod "pod-projected-secrets-cabcc025-0e9b-47a8-9735-4d0bd7fd9e11": Phase="Pending", Reason="", readiness=false. Elapsed: 7.342946ms
Aug  3 19:13:37.759: INFO: Pod "pod-projected-secrets-cabcc025-0e9b-47a8-9735-4d0bd7fd9e11": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.017437447s
STEP: Saw pod success
Aug  3 19:13:37.759: INFO: Pod "pod-projected-secrets-cabcc025-0e9b-47a8-9735-4d0bd7fd9e11" satisfied condition "success or failure"
Aug  3 19:13:37.769: INFO: Trying to get logs from node 10.188.31.32 pod pod-projected-secrets-cabcc025-0e9b-47a8-9735-4d0bd7fd9e11 container projected-secret-volume-test: <nil>
STEP: delete the pod
Aug  3 19:13:37.809: INFO: Waiting for pod pod-projected-secrets-cabcc025-0e9b-47a8-9735-4d0bd7fd9e11 to disappear
Aug  3 19:13:37.836: INFO: Pod pod-projected-secrets-cabcc025-0e9b-47a8-9735-4d0bd7fd9e11 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 19:13:37.836: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7156" for this suite.
Aug  3 19:13:43.879: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 19:13:44.390: INFO: namespace projected-7156 deletion completed in 6.542937878s

• [SLOW TEST:8.893 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 19:13:44.390: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-5465
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Performing setup for networking test in namespace pod-network-test-5465
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Aug  3 19:13:44.608: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Aug  3 19:14:03.023: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.72.72:8080/dial?request=hostName&protocol=http&host=172.30.199.105&port=8080&tries=1'] Namespace:pod-network-test-5465 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug  3 19:14:03.023: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
Aug  3 19:14:03.399: INFO: Waiting for endpoints: map[]
Aug  3 19:14:03.407: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.72.72:8080/dial?request=hostName&protocol=http&host=172.30.44.118&port=8080&tries=1'] Namespace:pod-network-test-5465 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug  3 19:14:03.407: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
Aug  3 19:14:03.716: INFO: Waiting for endpoints: map[]
Aug  3 19:14:03.724: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.72.72:8080/dial?request=hostName&protocol=http&host=172.30.72.75&port=8080&tries=1'] Namespace:pod-network-test-5465 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug  3 19:14:03.724: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
Aug  3 19:14:04.059: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 19:14:04.059: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-5465" for this suite.
Aug  3 19:14:28.124: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 19:14:28.426: INFO: namespace pod-network-test-5465 deletion completed in 24.336755679s

• [SLOW TEST:44.036 seconds]
[sig-network] Networking
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 19:14:28.428: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-5709
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-upd-fa98a110-2cdf-4cec-993d-74352f39d1d1
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-fa98a110-2cdf-4cec-993d-74352f39d1d1
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 19:15:39.461: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5709" for this suite.
Aug  3 19:16:03.505: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 19:16:04.020: INFO: namespace configmap-5709 deletion completed in 24.54708841s

• [SLOW TEST:95.593 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 19:16:04.022: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1908
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-68a3973a-fed2-4bf7-8b68-63d9398934d7
STEP: Creating a pod to test consume secrets
Aug  3 19:16:04.266: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-3c362a7a-ecbd-4ae6-a1f4-7b3265db3a4d" in namespace "projected-1908" to be "success or failure"
Aug  3 19:16:04.275: INFO: Pod "pod-projected-secrets-3c362a7a-ecbd-4ae6-a1f4-7b3265db3a4d": Phase="Pending", Reason="", readiness=false. Elapsed: 8.857316ms
Aug  3 19:16:06.286: INFO: Pod "pod-projected-secrets-3c362a7a-ecbd-4ae6-a1f4-7b3265db3a4d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.019010183s
STEP: Saw pod success
Aug  3 19:16:06.286: INFO: Pod "pod-projected-secrets-3c362a7a-ecbd-4ae6-a1f4-7b3265db3a4d" satisfied condition "success or failure"
Aug  3 19:16:06.293: INFO: Trying to get logs from node 10.188.31.32 pod pod-projected-secrets-3c362a7a-ecbd-4ae6-a1f4-7b3265db3a4d container projected-secret-volume-test: <nil>
STEP: delete the pod
Aug  3 19:16:06.331: INFO: Waiting for pod pod-projected-secrets-3c362a7a-ecbd-4ae6-a1f4-7b3265db3a4d to disappear
Aug  3 19:16:06.340: INFO: Pod pod-projected-secrets-3c362a7a-ecbd-4ae6-a1f4-7b3265db3a4d no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 19:16:06.340: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1908" for this suite.
Aug  3 19:16:12.381: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 19:16:12.765: INFO: namespace projected-1908 deletion completed in 6.413653627s

• [SLOW TEST:8.743 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 19:16:12.765: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-4140
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:273
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the initial replication controller
Aug  3 19:16:13.127: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 create -f - --namespace=kubectl-4140'
Aug  3 19:16:13.435: INFO: stderr: ""
Aug  3 19:16:13.435: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Aug  3 19:16:13.435: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-4140'
Aug  3 19:16:13.566: INFO: stderr: ""
Aug  3 19:16:13.566: INFO: stdout: "update-demo-nautilus-57mbt update-demo-nautilus-r8fl2 "
Aug  3 19:16:13.566: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 get pods update-demo-nautilus-57mbt -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4140'
Aug  3 19:16:13.675: INFO: stderr: ""
Aug  3 19:16:13.675: INFO: stdout: ""
Aug  3 19:16:13.675: INFO: update-demo-nautilus-57mbt is created but not running
Aug  3 19:16:18.676: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-4140'
Aug  3 19:16:18.791: INFO: stderr: ""
Aug  3 19:16:18.791: INFO: stdout: "update-demo-nautilus-57mbt update-demo-nautilus-r8fl2 "
Aug  3 19:16:18.791: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 get pods update-demo-nautilus-57mbt -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4140'
Aug  3 19:16:18.912: INFO: stderr: ""
Aug  3 19:16:18.912: INFO: stdout: "true"
Aug  3 19:16:18.912: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 get pods update-demo-nautilus-57mbt -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-4140'
Aug  3 19:16:19.026: INFO: stderr: ""
Aug  3 19:16:19.026: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Aug  3 19:16:19.026: INFO: validating pod update-demo-nautilus-57mbt
Aug  3 19:16:19.042: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug  3 19:16:19.042: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug  3 19:16:19.042: INFO: update-demo-nautilus-57mbt is verified up and running
Aug  3 19:16:19.042: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 get pods update-demo-nautilus-r8fl2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4140'
Aug  3 19:16:19.169: INFO: stderr: ""
Aug  3 19:16:19.169: INFO: stdout: "true"
Aug  3 19:16:19.169: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 get pods update-demo-nautilus-r8fl2 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-4140'
Aug  3 19:16:19.282: INFO: stderr: ""
Aug  3 19:16:19.282: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Aug  3 19:16:19.282: INFO: validating pod update-demo-nautilus-r8fl2
Aug  3 19:16:19.295: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug  3 19:16:19.295: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug  3 19:16:19.295: INFO: update-demo-nautilus-r8fl2 is verified up and running
STEP: rolling-update to new replication controller
Aug  3 19:16:19.297: INFO: scanned /root for discovery docs: <nil>
Aug  3 19:16:19.297: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=kubectl-4140'
Aug  3 19:16:42.108: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Aug  3 19:16:42.108: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Aug  3 19:16:42.108: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-4140'
Aug  3 19:16:42.232: INFO: stderr: ""
Aug  3 19:16:42.232: INFO: stdout: "update-demo-kitten-g52dm update-demo-kitten-lcjdz "
Aug  3 19:16:42.232: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 get pods update-demo-kitten-g52dm -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4140'
Aug  3 19:16:42.333: INFO: stderr: ""
Aug  3 19:16:42.333: INFO: stdout: "true"
Aug  3 19:16:42.333: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 get pods update-demo-kitten-g52dm -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-4140'
Aug  3 19:16:42.439: INFO: stderr: ""
Aug  3 19:16:42.439: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Aug  3 19:16:42.439: INFO: validating pod update-demo-kitten-g52dm
Aug  3 19:16:42.455: INFO: got data: {
  "image": "kitten.jpg"
}

Aug  3 19:16:42.455: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Aug  3 19:16:42.455: INFO: update-demo-kitten-g52dm is verified up and running
Aug  3 19:16:42.455: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 get pods update-demo-kitten-lcjdz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4140'
Aug  3 19:16:42.580: INFO: stderr: ""
Aug  3 19:16:42.580: INFO: stdout: "true"
Aug  3 19:16:42.580: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 get pods update-demo-kitten-lcjdz -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-4140'
Aug  3 19:16:42.703: INFO: stderr: ""
Aug  3 19:16:42.703: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Aug  3 19:16:42.703: INFO: validating pod update-demo-kitten-lcjdz
Aug  3 19:16:42.719: INFO: got data: {
  "image": "kitten.jpg"
}

Aug  3 19:16:42.719: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Aug  3 19:16:42.719: INFO: update-demo-kitten-lcjdz is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 19:16:42.719: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4140" for this suite.
Aug  3 19:17:06.789: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 19:17:07.203: INFO: namespace kubectl-4140 deletion completed in 24.453529708s

• [SLOW TEST:54.438 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 19:17:07.204: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename prestop
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in prestop-9895
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pre_stop.go:167
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating server pod server in namespace prestop-9895
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace prestop-9895
STEP: Deleting pre-stop pod
Aug  3 19:17:18.537: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 19:17:18.550: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "prestop-9895" for this suite.
Aug  3 19:17:58.614: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 19:17:58.966: INFO: namespace prestop-9895 deletion completed in 40.404936867s

• [SLOW TEST:51.763 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 19:17:58.967: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-7274
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-map-0429edad-d49b-4363-becf-97237298725a
STEP: Creating a pod to test consume secrets
Aug  3 19:17:59.220: INFO: Waiting up to 5m0s for pod "pod-secrets-7a500269-f225-4396-8881-e426fc419982" in namespace "secrets-7274" to be "success or failure"
Aug  3 19:17:59.229: INFO: Pod "pod-secrets-7a500269-f225-4396-8881-e426fc419982": Phase="Pending", Reason="", readiness=false. Elapsed: 8.9333ms
Aug  3 19:18:01.238: INFO: Pod "pod-secrets-7a500269-f225-4396-8881-e426fc419982": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.017090247s
STEP: Saw pod success
Aug  3 19:18:01.238: INFO: Pod "pod-secrets-7a500269-f225-4396-8881-e426fc419982" satisfied condition "success or failure"
Aug  3 19:18:01.246: INFO: Trying to get logs from node 10.188.31.32 pod pod-secrets-7a500269-f225-4396-8881-e426fc419982 container secret-volume-test: <nil>
STEP: delete the pod
Aug  3 19:18:01.308: INFO: Waiting for pod pod-secrets-7a500269-f225-4396-8881-e426fc419982 to disappear
Aug  3 19:18:01.316: INFO: Pod pod-secrets-7a500269-f225-4396-8881-e426fc419982 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 19:18:01.316: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7274" for this suite.
Aug  3 19:18:07.358: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 19:18:07.651: INFO: namespace secrets-7274 deletion completed in 6.324814036s

• [SLOW TEST:8.685 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 19:18:07.653: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-wrapper-9061
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 19:18:12.001: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-9061" for this suite.
Aug  3 19:18:18.060: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 19:18:18.387: INFO: namespace emptydir-wrapper-9061 deletion completed in 6.357530449s

• [SLOW TEST:10.734 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not conflict [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 19:18:18.388: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-3559
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name secret-emptykey-test-3260eeeb-18c9-4ca7-8a04-816c1e95e1c2
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 19:18:18.617: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3559" for this suite.
Aug  3 19:18:24.669: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 19:18:25.006: INFO: namespace secrets-3559 deletion completed in 6.378372993s

• [SLOW TEST:6.618 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 19:18:25.006: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-7869
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap that has name configmap-test-emptyKey-877d59f5-1a1b-4087-86d0-7f0859edba5f
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 19:18:25.227: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7869" for this suite.
Aug  3 19:18:31.278: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 19:18:31.595: INFO: namespace configmap-7869 deletion completed in 6.357711696s

• [SLOW TEST:6.589 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 19:18:31.597: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9909
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-da420479-752c-446c-ae43-49b472b8bba7
STEP: Creating a pod to test consume configMaps
Aug  3 19:18:31.849: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-575e941e-2937-4845-9e60-b05d655260a4" in namespace "projected-9909" to be "success or failure"
Aug  3 19:18:31.869: INFO: Pod "pod-projected-configmaps-575e941e-2937-4845-9e60-b05d655260a4": Phase="Pending", Reason="", readiness=false. Elapsed: 20.544836ms
Aug  3 19:18:33.889: INFO: Pod "pod-projected-configmaps-575e941e-2937-4845-9e60-b05d655260a4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.040792422s
Aug  3 19:18:35.901: INFO: Pod "pod-projected-configmaps-575e941e-2937-4845-9e60-b05d655260a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.051987757s
STEP: Saw pod success
Aug  3 19:18:35.901: INFO: Pod "pod-projected-configmaps-575e941e-2937-4845-9e60-b05d655260a4" satisfied condition "success or failure"
Aug  3 19:18:35.908: INFO: Trying to get logs from node 10.188.31.32 pod pod-projected-configmaps-575e941e-2937-4845-9e60-b05d655260a4 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Aug  3 19:18:35.966: INFO: Waiting for pod pod-projected-configmaps-575e941e-2937-4845-9e60-b05d655260a4 to disappear
Aug  3 19:18:35.977: INFO: Pod pod-projected-configmaps-575e941e-2937-4845-9e60-b05d655260a4 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 19:18:35.977: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9909" for this suite.
Aug  3 19:18:42.022: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 19:18:42.313: INFO: namespace projected-9909 deletion completed in 6.323670812s

• [SLOW TEST:10.717 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 19:18:42.314: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-9736
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
Aug  3 19:18:42.527: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 19:18:46.256: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-9736" for this suite.
Aug  3 19:18:52.309: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 19:18:52.646: INFO: namespace init-container-9736 deletion completed in 6.374495265s

• [SLOW TEST:10.333 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 19:18:52.646: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-1589
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Aug  3 19:18:52.908: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-1589,SelfLink:/api/v1/namespaces/watch-1589/configmaps/e2e-watch-test-label-changed,UID:86592b13-b716-46a2-bd12-bcb86a6fd3af,ResourceVersion:54396,Generation:0,CreationTimestamp:2019-08-03 19:18:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Aug  3 19:18:52.908: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-1589,SelfLink:/api/v1/namespaces/watch-1589/configmaps/e2e-watch-test-label-changed,UID:86592b13-b716-46a2-bd12-bcb86a6fd3af,ResourceVersion:54397,Generation:0,CreationTimestamp:2019-08-03 19:18:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Aug  3 19:18:52.908: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-1589,SelfLink:/api/v1/namespaces/watch-1589/configmaps/e2e-watch-test-label-changed,UID:86592b13-b716-46a2-bd12-bcb86a6fd3af,ResourceVersion:54398,Generation:0,CreationTimestamp:2019-08-03 19:18:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Aug  3 19:19:02.984: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-1589,SelfLink:/api/v1/namespaces/watch-1589/configmaps/e2e-watch-test-label-changed,UID:86592b13-b716-46a2-bd12-bcb86a6fd3af,ResourceVersion:54416,Generation:0,CreationTimestamp:2019-08-03 19:18:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Aug  3 19:19:02.985: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-1589,SelfLink:/api/v1/namespaces/watch-1589/configmaps/e2e-watch-test-label-changed,UID:86592b13-b716-46a2-bd12-bcb86a6fd3af,ResourceVersion:54417,Generation:0,CreationTimestamp:2019-08-03 19:18:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Aug  3 19:19:02.985: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-1589,SelfLink:/api/v1/namespaces/watch-1589/configmaps/e2e-watch-test-label-changed,UID:86592b13-b716-46a2-bd12-bcb86a6fd3af,ResourceVersion:54418,Generation:0,CreationTimestamp:2019-08-03 19:18:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 19:19:02.985: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-1589" for this suite.
Aug  3 19:19:09.030: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 19:19:09.439: INFO: namespace watch-1589 deletion completed in 6.442765629s

• [SLOW TEST:16.793 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-network] DNS 
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 19:19:09.441: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-6199
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-6199.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-6199.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-6199.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-6199.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-6199.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-6199.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe /etc/hosts
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Aug  3 19:19:13.814: INFO: DNS probes using dns-6199/dns-test-d98ec4c2-5568-45b1-acd0-d386f864ab03 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 19:19:13.849: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-6199" for this suite.
Aug  3 19:19:19.911: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 19:19:20.235: INFO: namespace dns-6199 deletion completed in 6.354262388s

• [SLOW TEST:10.794 seconds]
[sig-network] DNS
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 19:19:20.235: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-7892
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1457
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Aug  3 19:19:20.468: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=kubectl-7892'
Aug  3 19:19:20.726: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Aug  3 19:19:20.726: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: verifying the pod controlled by rc e2e-test-nginx-rc was created
STEP: confirm that you can get logs from an rc
Aug  3 19:19:20.757: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-hs26q]
Aug  3 19:19:20.757: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-hs26q" in namespace "kubectl-7892" to be "running and ready"
Aug  3 19:19:20.765: INFO: Pod "e2e-test-nginx-rc-hs26q": Phase="Pending", Reason="", readiness=false. Elapsed: 7.560623ms
Aug  3 19:19:22.773: INFO: Pod "e2e-test-nginx-rc-hs26q": Phase="Running", Reason="", readiness=true. Elapsed: 2.015698932s
Aug  3 19:19:22.773: INFO: Pod "e2e-test-nginx-rc-hs26q" satisfied condition "running and ready"
Aug  3 19:19:22.773: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-hs26q]
Aug  3 19:19:22.773: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 logs rc/e2e-test-nginx-rc --namespace=kubectl-7892'
Aug  3 19:19:22.915: INFO: stderr: ""
Aug  3 19:19:22.915: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1462
Aug  3 19:19:22.915: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 delete rc e2e-test-nginx-rc --namespace=kubectl-7892'
Aug  3 19:19:23.049: INFO: stderr: ""
Aug  3 19:19:23.049: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 19:19:23.049: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7892" for this suite.
Aug  3 19:19:47.091: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 19:19:47.435: INFO: namespace kubectl-7892 deletion completed in 24.374351305s

• [SLOW TEST:27.200 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run rc
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 19:19:47.435: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-9371
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1558
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Aug  3 19:19:47.655: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --generator=deployment/apps.v1 --namespace=kubectl-9371'
Aug  3 19:19:47.800: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Aug  3 19:19:47.800: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the deployment e2e-test-nginx-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1563
Aug  3 19:19:51.824: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322553265 delete deployment e2e-test-nginx-deployment --namespace=kubectl-9371'
Aug  3 19:19:51.966: INFO: stderr: ""
Aug  3 19:19:51.966: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 19:19:51.966: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9371" for this suite.
Aug  3 19:19:58.017: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 19:19:58.357: INFO: namespace kubectl-9371 deletion completed in 6.376491601s

• [SLOW TEST:10.922 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run deployment
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] version v1
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 19:19:58.358: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-8076
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Aug  3 19:19:58.602: INFO: (0) /api/v1/nodes/10.188.31.22:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="alternatives.log.1">alternatives.l... (200; 21.874445ms)
Aug  3 19:19:58.614: INFO: (1) /api/v1/nodes/10.188.31.22:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="alternatives.log.1">alternatives.l... (200; 11.977552ms)
Aug  3 19:19:58.626: INFO: (2) /api/v1/nodes/10.188.31.22:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="alternatives.log.1">alternatives.l... (200; 12.327392ms)
Aug  3 19:19:58.641: INFO: (3) /api/v1/nodes/10.188.31.22:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="alternatives.log.1">alternatives.l... (200; 14.756261ms)
Aug  3 19:19:58.656: INFO: (4) /api/v1/nodes/10.188.31.22:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="alternatives.log.1">alternatives.l... (200; 14.768109ms)
Aug  3 19:19:58.669: INFO: (5) /api/v1/nodes/10.188.31.22:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="alternatives.log.1">alternatives.l... (200; 12.873749ms)
Aug  3 19:19:58.683: INFO: (6) /api/v1/nodes/10.188.31.22:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="alternatives.log.1">alternatives.l... (200; 13.824455ms)
Aug  3 19:19:58.694: INFO: (7) /api/v1/nodes/10.188.31.22:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="alternatives.log.1">alternatives.l... (200; 11.193073ms)
Aug  3 19:19:58.706: INFO: (8) /api/v1/nodes/10.188.31.22:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="alternatives.log.1">alternatives.l... (200; 11.839809ms)
Aug  3 19:19:58.721: INFO: (9) /api/v1/nodes/10.188.31.22:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="alternatives.log.1">alternatives.l... (200; 15.636056ms)
Aug  3 19:19:58.734: INFO: (10) /api/v1/nodes/10.188.31.22:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="alternatives.log.1">alternatives.l... (200; 12.347881ms)
Aug  3 19:19:58.746: INFO: (11) /api/v1/nodes/10.188.31.22:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="alternatives.log.1">alternatives.l... (200; 12.145771ms)
Aug  3 19:19:58.759: INFO: (12) /api/v1/nodes/10.188.31.22:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="alternatives.log.1">alternatives.l... (200; 12.519192ms)
Aug  3 19:19:58.774: INFO: (13) /api/v1/nodes/10.188.31.22:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="alternatives.log.1">alternatives.l... (200; 15.098573ms)
Aug  3 19:19:58.787: INFO: (14) /api/v1/nodes/10.188.31.22:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="alternatives.log.1">alternatives.l... (200; 13.095411ms)
Aug  3 19:19:58.801: INFO: (15) /api/v1/nodes/10.188.31.22:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="alternatives.log.1">alternatives.l... (200; 13.23988ms)
Aug  3 19:19:58.814: INFO: (16) /api/v1/nodes/10.188.31.22:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="alternatives.log.1">alternatives.l... (200; 13.700168ms)
Aug  3 19:19:58.828: INFO: (17) /api/v1/nodes/10.188.31.22:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="alternatives.log.1">alternatives.l... (200; 13.255873ms)
Aug  3 19:19:58.840: INFO: (18) /api/v1/nodes/10.188.31.22:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="alternatives.log.1">alternatives.l... (200; 12.676779ms)
Aug  3 19:19:58.853: INFO: (19) /api/v1/nodes/10.188.31.22:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="alternatives.log.1">alternatives.l... (200; 12.576177ms)
[AfterEach] version v1
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 19:19:58.853: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-8076" for this suite.
Aug  3 19:20:04.894: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 19:20:05.250: INFO: namespace proxy-8076 deletion completed in 6.388022625s

• [SLOW TEST:6.893 seconds]
[sig-network] Proxy
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:58
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 19:20:05.254: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-6406
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-6406
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace statefulset-6406
STEP: Creating statefulset with conflicting port in namespace statefulset-6406
STEP: Waiting until pod test-pod will start running in namespace statefulset-6406
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-6406
Aug  3 19:20:07.573: INFO: Observed stateful pod in namespace: statefulset-6406, name: ss-0, uid: 78e1c315-8c9d-4d2d-ac73-a79413aee753, status phase: Pending. Waiting for statefulset controller to delete.
Aug  3 19:20:11.860: INFO: Observed stateful pod in namespace: statefulset-6406, name: ss-0, uid: 78e1c315-8c9d-4d2d-ac73-a79413aee753, status phase: Failed. Waiting for statefulset controller to delete.
Aug  3 19:20:11.876: INFO: Observed stateful pod in namespace: statefulset-6406, name: ss-0, uid: 78e1c315-8c9d-4d2d-ac73-a79413aee753, status phase: Failed. Waiting for statefulset controller to delete.
Aug  3 19:20:11.888: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-6406
STEP: Removing pod with conflicting port in namespace statefulset-6406
STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-6406 and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Aug  3 19:20:15.941: INFO: Deleting all statefulset in ns statefulset-6406
Aug  3 19:20:15.950: INFO: Scaling statefulset ss to 0
Aug  3 19:20:25.988: INFO: Waiting for statefulset status.replicas updated to 0
Aug  3 19:20:25.997: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 19:20:26.041: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-6406" for this suite.
Aug  3 19:20:32.085: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 19:20:32.406: INFO: namespace statefulset-6406 deletion completed in 6.353844191s

• [SLOW TEST:27.153 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 19:20:32.412: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-5514
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod liveness-245e9c9b-77b0-461f-9fb5-9e2bc3735ce5 in namespace container-probe-5514
Aug  3 19:20:34.655: INFO: Started pod liveness-245e9c9b-77b0-461f-9fb5-9e2bc3735ce5 in namespace container-probe-5514
STEP: checking the pod's current state and verifying that restartCount is present
Aug  3 19:20:34.662: INFO: Initial restart count of pod liveness-245e9c9b-77b0-461f-9fb5-9e2bc3735ce5 is 0
Aug  3 19:20:54.762: INFO: Restart count of pod container-probe-5514/liveness-245e9c9b-77b0-461f-9fb5-9e2bc3735ce5 is now 1 (20.100082488s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 19:20:54.786: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-5514" for this suite.
Aug  3 19:21:00.829: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 19:21:01.144: INFO: namespace container-probe-5514 deletion completed in 6.344771259s

• [SLOW TEST:28.732 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 19:21:01.144: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-2423
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0777 on tmpfs
Aug  3 19:21:01.382: INFO: Waiting up to 5m0s for pod "pod-2c8f3cda-ca99-4ebe-b457-512d392b4917" in namespace "emptydir-2423" to be "success or failure"
Aug  3 19:21:01.391: INFO: Pod "pod-2c8f3cda-ca99-4ebe-b457-512d392b4917": Phase="Pending", Reason="", readiness=false. Elapsed: 9.428992ms
Aug  3 19:21:03.399: INFO: Pod "pod-2c8f3cda-ca99-4ebe-b457-512d392b4917": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017731749s
Aug  3 19:21:05.409: INFO: Pod "pod-2c8f3cda-ca99-4ebe-b457-512d392b4917": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.027356802s
STEP: Saw pod success
Aug  3 19:21:05.409: INFO: Pod "pod-2c8f3cda-ca99-4ebe-b457-512d392b4917" satisfied condition "success or failure"
Aug  3 19:21:05.417: INFO: Trying to get logs from node 10.188.31.32 pod pod-2c8f3cda-ca99-4ebe-b457-512d392b4917 container test-container: <nil>
STEP: delete the pod
Aug  3 19:21:05.463: INFO: Waiting for pod pod-2c8f3cda-ca99-4ebe-b457-512d392b4917 to disappear
Aug  3 19:21:05.470: INFO: Pod pod-2c8f3cda-ca99-4ebe-b457-512d392b4917 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 19:21:05.470: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2423" for this suite.
Aug  3 19:21:11.520: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 19:21:11.910: INFO: namespace emptydir-2423 deletion completed in 6.424923335s

• [SLOW TEST:10.767 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 19:21:11.911: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6833
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Aug  3 19:21:12.488: INFO: Waiting up to 5m0s for pod "downwardapi-volume-1c4d35cf-00a8-403d-9d53-513e8662923c" in namespace "projected-6833" to be "success or failure"
Aug  3 19:21:12.497: INFO: Pod "downwardapi-volume-1c4d35cf-00a8-403d-9d53-513e8662923c": Phase="Pending", Reason="", readiness=false. Elapsed: 8.90161ms
Aug  3 19:21:14.509: INFO: Pod "downwardapi-volume-1c4d35cf-00a8-403d-9d53-513e8662923c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02129392s
Aug  3 19:21:16.518: INFO: Pod "downwardapi-volume-1c4d35cf-00a8-403d-9d53-513e8662923c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.030095063s
STEP: Saw pod success
Aug  3 19:21:16.518: INFO: Pod "downwardapi-volume-1c4d35cf-00a8-403d-9d53-513e8662923c" satisfied condition "success or failure"
Aug  3 19:21:16.525: INFO: Trying to get logs from node 10.188.31.32 pod downwardapi-volume-1c4d35cf-00a8-403d-9d53-513e8662923c container client-container: <nil>
STEP: delete the pod
Aug  3 19:21:16.565: INFO: Waiting for pod downwardapi-volume-1c4d35cf-00a8-403d-9d53-513e8662923c to disappear
Aug  3 19:21:16.577: INFO: Pod downwardapi-volume-1c4d35cf-00a8-403d-9d53-513e8662923c no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 19:21:16.577: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6833" for this suite.
Aug  3 19:21:22.681: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 19:21:23.112: INFO: namespace projected-6833 deletion completed in 6.523822993s

• [SLOW TEST:11.201 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 19:21:23.112: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-77
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-map-8580fa90-c258-4347-b638-48acafe3393e
STEP: Creating a pod to test consume configMaps
Aug  3 19:21:23.379: INFO: Waiting up to 5m0s for pod "pod-configmaps-9cdc66bd-c793-446d-b2c7-b269979465df" in namespace "configmap-77" to be "success or failure"
Aug  3 19:21:23.386: INFO: Pod "pod-configmaps-9cdc66bd-c793-446d-b2c7-b269979465df": Phase="Pending", Reason="", readiness=false. Elapsed: 6.739296ms
Aug  3 19:21:25.394: INFO: Pod "pod-configmaps-9cdc66bd-c793-446d-b2c7-b269979465df": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014882314s
Aug  3 19:21:27.403: INFO: Pod "pod-configmaps-9cdc66bd-c793-446d-b2c7-b269979465df": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023252061s
STEP: Saw pod success
Aug  3 19:21:27.403: INFO: Pod "pod-configmaps-9cdc66bd-c793-446d-b2c7-b269979465df" satisfied condition "success or failure"
Aug  3 19:21:27.410: INFO: Trying to get logs from node 10.188.31.32 pod pod-configmaps-9cdc66bd-c793-446d-b2c7-b269979465df container configmap-volume-test: <nil>
STEP: delete the pod
Aug  3 19:21:27.454: INFO: Waiting for pod pod-configmaps-9cdc66bd-c793-446d-b2c7-b269979465df to disappear
Aug  3 19:21:27.463: INFO: Pod pod-configmaps-9cdc66bd-c793-446d-b2c7-b269979465df no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 19:21:27.463: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-77" for this suite.
Aug  3 19:21:33.511: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 19:21:33.824: INFO: namespace configmap-77 deletion completed in 6.34965066s

• [SLOW TEST:10.712 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 19:21:33.824: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in namespaces-95
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-1356
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-9078
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 19:21:40.544: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-95" for this suite.
Aug  3 19:21:46.599: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 19:21:46.905: INFO: namespace namespaces-95 deletion completed in 6.349655763s
STEP: Destroying namespace "nsdeletetest-1356" for this suite.
Aug  3 19:21:46.914: INFO: Namespace nsdeletetest-1356 was already deleted
STEP: Destroying namespace "nsdeletetest-9078" for this suite.
Aug  3 19:21:52.969: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 19:21:53.271: INFO: namespace nsdeletetest-9078 deletion completed in 6.357114954s

• [SLOW TEST:19.447 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 19:21:53.272: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-6982
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Aug  3 19:21:53.507: INFO: Waiting up to 5m0s for pod "downward-api-9359d41c-ead9-4fad-844b-3eb22c49216d" in namespace "downward-api-6982" to be "success or failure"
Aug  3 19:21:53.515: INFO: Pod "downward-api-9359d41c-ead9-4fad-844b-3eb22c49216d": Phase="Pending", Reason="", readiness=false. Elapsed: 7.658643ms
Aug  3 19:21:55.523: INFO: Pod "downward-api-9359d41c-ead9-4fad-844b-3eb22c49216d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016115694s
STEP: Saw pod success
Aug  3 19:21:55.523: INFO: Pod "downward-api-9359d41c-ead9-4fad-844b-3eb22c49216d" satisfied condition "success or failure"
Aug  3 19:21:55.531: INFO: Trying to get logs from node 10.188.31.24 pod downward-api-9359d41c-ead9-4fad-844b-3eb22c49216d container dapi-container: <nil>
STEP: delete the pod
Aug  3 19:21:55.609: INFO: Waiting for pod downward-api-9359d41c-ead9-4fad-844b-3eb22c49216d to disappear
Aug  3 19:21:55.619: INFO: Pod downward-api-9359d41c-ead9-4fad-844b-3eb22c49216d no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 19:21:55.619: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6982" for this suite.
Aug  3 19:22:01.676: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 19:22:02.046: INFO: namespace downward-api-6982 deletion completed in 6.414761979s

• [SLOW TEST:8.775 seconds]
[sig-node] Downward API
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 19:22:02.047: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-9915
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0777 on node default medium
Aug  3 19:22:02.274: INFO: Waiting up to 5m0s for pod "pod-83720316-2f29-4902-8071-9c59a18af381" in namespace "emptydir-9915" to be "success or failure"
Aug  3 19:22:02.299: INFO: Pod "pod-83720316-2f29-4902-8071-9c59a18af381": Phase="Pending", Reason="", readiness=false. Elapsed: 24.885647ms
Aug  3 19:22:04.307: INFO: Pod "pod-83720316-2f29-4902-8071-9c59a18af381": Phase="Pending", Reason="", readiness=false. Elapsed: 2.03302191s
Aug  3 19:22:06.315: INFO: Pod "pod-83720316-2f29-4902-8071-9c59a18af381": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.040926562s
STEP: Saw pod success
Aug  3 19:22:06.315: INFO: Pod "pod-83720316-2f29-4902-8071-9c59a18af381" satisfied condition "success or failure"
Aug  3 19:22:06.323: INFO: Trying to get logs from node 10.188.31.32 pod pod-83720316-2f29-4902-8071-9c59a18af381 container test-container: <nil>
STEP: delete the pod
Aug  3 19:22:06.365: INFO: Waiting for pod pod-83720316-2f29-4902-8071-9c59a18af381 to disappear
Aug  3 19:22:06.372: INFO: Pod pod-83720316-2f29-4902-8071-9c59a18af381 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 19:22:06.372: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9915" for this suite.
Aug  3 19:22:12.434: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 19:22:12.996: INFO: namespace emptydir-9915 deletion completed in 6.595856062s

• [SLOW TEST:10.949 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 19:22:12.996: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-9659
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Aug  3 19:22:13.215: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 19:22:15.584: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-9659" for this suite.
Aug  3 19:22:59.699: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 19:22:59.991: INFO: namespace pods-9659 deletion completed in 44.341687184s

• [SLOW TEST:46.995 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 19:22:59.992: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-2313
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Aug  3 19:23:00.260: INFO: Create a RollingUpdate DaemonSet
Aug  3 19:23:00.270: INFO: Check that daemon pods launch on every node of the cluster
Aug  3 19:23:00.287: INFO: Number of nodes with available pods: 0
Aug  3 19:23:00.287: INFO: Node 10.188.31.22 is running more than one daemon pod
Aug  3 19:23:01.309: INFO: Number of nodes with available pods: 0
Aug  3 19:23:01.309: INFO: Node 10.188.31.22 is running more than one daemon pod
Aug  3 19:23:02.322: INFO: Number of nodes with available pods: 1
Aug  3 19:23:02.322: INFO: Node 10.188.31.22 is running more than one daemon pod
Aug  3 19:23:03.308: INFO: Number of nodes with available pods: 3
Aug  3 19:23:03.308: INFO: Number of running nodes: 3, number of available pods: 3
Aug  3 19:23:03.308: INFO: Update the DaemonSet to trigger a rollout
Aug  3 19:23:03.344: INFO: Updating DaemonSet daemon-set
Aug  3 19:23:16.391: INFO: Roll back the DaemonSet before rollout is complete
Aug  3 19:23:16.636: INFO: Updating DaemonSet daemon-set
Aug  3 19:23:16.636: INFO: Make sure DaemonSet rollback is complete
Aug  3 19:23:16.645: INFO: Wrong image for pod: daemon-set-g8mf6. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Aug  3 19:23:16.645: INFO: Pod daemon-set-g8mf6 is not available
Aug  3 19:23:17.664: INFO: Pod daemon-set-dln5w is not available
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-2313, will wait for the garbage collector to delete the pods
Aug  3 19:23:17.788: INFO: Deleting DaemonSet.extensions daemon-set took: 20.031279ms
Aug  3 19:23:17.989: INFO: Terminating DaemonSet.extensions daemon-set pods took: 200.408641ms
Aug  3 19:23:26.998: INFO: Number of nodes with available pods: 0
Aug  3 19:23:26.998: INFO: Number of running nodes: 0, number of available pods: 0
Aug  3 19:23:27.006: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-2313/daemonsets","resourceVersion":"55566"},"items":null}

Aug  3 19:23:27.015: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-2313/pods","resourceVersion":"55566"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 19:23:27.055: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-2313" for this suite.
Aug  3 19:23:35.096: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 19:23:35.429: INFO: namespace daemonsets-2313 deletion completed in 8.364773835s

• [SLOW TEST:35.438 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 19:23:35.430: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-9924
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-9924.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-9924.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Aug  3 19:23:39.801: INFO: DNS probes using dns-9924/dns-test-0c57df15-363d-474b-b97e-98f05201d917 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 19:23:39.826: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-9924" for this suite.
Aug  3 19:23:45.869: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 19:23:46.166: INFO: namespace dns-9924 deletion completed in 6.327247569s

• [SLOW TEST:10.736 seconds]
[sig-network] DNS
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  3 19:23:46.166: INFO: >>> kubeConfig: /tmp/kubeconfig-322553265
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-4538
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Aug  3 19:23:48.961: INFO: Successfully updated pod "pod-update-activedeadlineseconds-a0f50a9e-2265-46e6-96da-66b55d2b4932"
Aug  3 19:23:48.961: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-a0f50a9e-2265-46e6-96da-66b55d2b4932" in namespace "pods-4538" to be "terminated due to deadline exceeded"
Aug  3 19:23:48.968: INFO: Pod "pod-update-activedeadlineseconds-a0f50a9e-2265-46e6-96da-66b55d2b4932": Phase="Running", Reason="", readiness=true. Elapsed: 7.597696ms
Aug  3 19:23:50.976: INFO: Pod "pod-update-activedeadlineseconds-a0f50a9e-2265-46e6-96da-66b55d2b4932": Phase="Running", Reason="", readiness=true. Elapsed: 2.015200123s
Aug  3 19:23:52.989: INFO: Pod "pod-update-activedeadlineseconds-a0f50a9e-2265-46e6-96da-66b55d2b4932": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 4.028463592s
Aug  3 19:23:52.989: INFO: Pod "pod-update-activedeadlineseconds-a0f50a9e-2265-46e6-96da-66b55d2b4932" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  3 19:23:52.989: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-4538" for this suite.
Aug  3 19:23:59.049: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  3 19:23:59.364: INFO: namespace pods-4538 deletion completed in 6.362642081s

• [SLOW TEST:13.198 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.1-beta.0.48+4485c6f18cee9a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSAug  3 19:23:59.364: INFO: Running AfterSuite actions on all nodes
Aug  3 19:23:59.364: INFO: Running AfterSuite actions on node 1
Aug  3 19:23:59.364: INFO: Skipping dumping logs from cluster

Ran 215 of 4413 Specs in 6403.098 seconds
SUCCESS! -- 215 Passed | 0 Failed | 0 Pending | 4198 Skipped
PASS

Ginkgo ran 1 suite in 1h46m44.544524919s
Test Suite Passed
