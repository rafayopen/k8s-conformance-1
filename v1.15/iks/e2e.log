I0217 16:14:46.442302      16 test_context.go:406] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-079603707
I0217 16:14:46.442451      16 e2e.go:243] Starting e2e run "ad72ae7d-ff88-4d2e-a1e4-61dfbb87c8e8" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1581956085 - Will randomize all specs
Will run 215 of 4412 specs

Feb 17 16:14:46.663: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
Feb 17 16:14:46.665: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Feb 17 16:14:46.725: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Feb 17 16:14:46.800: INFO: 19 / 19 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Feb 17 16:14:46.800: INFO: expected 9 pod replicas in namespace 'kube-system', 9 are Running and Ready.
Feb 17 16:14:46.800: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Feb 17 16:14:46.820: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'calico-node' (0 seconds elapsed)
Feb 17 16:14:46.820: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'ibm-master-proxy' (0 seconds elapsed)
Feb 17 16:14:46.820: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'ibm-vpc-block-csi-node' (0 seconds elapsed)
Feb 17 16:14:46.820: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'node-local-dns' (0 seconds elapsed)
Feb 17 16:14:46.820: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'nvidia-driver-installer' (0 seconds elapsed)
Feb 17 16:14:46.820: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'nvidia-gpu-device-plugin' (0 seconds elapsed)
Feb 17 16:14:46.820: INFO: e2e test version: v1.15.10
Feb 17 16:14:46.825: INFO: kube-apiserver version: v1.15.10+IKS
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 16:14:46.831: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename projected
Feb 17 16:14:46.967: INFO: Found PodSecurityPolicies; assuming PodSecurityPolicy is enabled.
Feb 17 16:14:47.007: INFO: Found ClusterRoles; assuming RBAC is enabled.
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6557
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-7dbb2fe8-8031-40b6-acf3-b5c0d1b721ad
STEP: Creating a pod to test consume secrets
Feb 17 16:14:47.184: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-c18e8120-ddb2-4e6e-bef8-b16206657222" in namespace "projected-6557" to be "success or failure"
Feb 17 16:14:47.196: INFO: Pod "pod-projected-secrets-c18e8120-ddb2-4e6e-bef8-b16206657222": Phase="Pending", Reason="", readiness=false. Elapsed: 12.407554ms
Feb 17 16:14:49.212: INFO: Pod "pod-projected-secrets-c18e8120-ddb2-4e6e-bef8-b16206657222": Phase="Pending", Reason="", readiness=false. Elapsed: 2.027988103s
Feb 17 16:14:51.224: INFO: Pod "pod-projected-secrets-c18e8120-ddb2-4e6e-bef8-b16206657222": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.039839036s
STEP: Saw pod success
Feb 17 16:14:51.226: INFO: Pod "pod-projected-secrets-c18e8120-ddb2-4e6e-bef8-b16206657222" satisfied condition "success or failure"
Feb 17 16:14:51.237: INFO: Trying to get logs from node 10.242.0.59 pod pod-projected-secrets-c18e8120-ddb2-4e6e-bef8-b16206657222 container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb 17 16:14:51.314: INFO: Waiting for pod pod-projected-secrets-c18e8120-ddb2-4e6e-bef8-b16206657222 to disappear
Feb 17 16:14:51.325: INFO: Pod pod-projected-secrets-c18e8120-ddb2-4e6e-bef8-b16206657222 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 16:14:51.325: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6557" for this suite.
Feb 17 16:14:57.398: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:14:57.811: INFO: namespace projected-6557 deletion completed in 6.464822849s

• [SLOW TEST:10.980 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 16:14:57.811: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-3082
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-f49d6878-9898-4bef-b1eb-70142490a73b
STEP: Creating a pod to test consume secrets
Feb 17 16:14:58.179: INFO: Waiting up to 5m0s for pod "pod-secrets-87a4f1f9-1063-4e19-b678-4dfc2ba8e7d6" in namespace "secrets-3082" to be "success or failure"
Feb 17 16:14:58.190: INFO: Pod "pod-secrets-87a4f1f9-1063-4e19-b678-4dfc2ba8e7d6": Phase="Pending", Reason="", readiness=false. Elapsed: 11.186778ms
Feb 17 16:15:00.203: INFO: Pod "pod-secrets-87a4f1f9-1063-4e19-b678-4dfc2ba8e7d6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024147132s
Feb 17 16:15:02.215: INFO: Pod "pod-secrets-87a4f1f9-1063-4e19-b678-4dfc2ba8e7d6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.036246242s
STEP: Saw pod success
Feb 17 16:15:02.215: INFO: Pod "pod-secrets-87a4f1f9-1063-4e19-b678-4dfc2ba8e7d6" satisfied condition "success or failure"
Feb 17 16:15:02.225: INFO: Trying to get logs from node 10.242.0.98 pod pod-secrets-87a4f1f9-1063-4e19-b678-4dfc2ba8e7d6 container secret-volume-test: <nil>
STEP: delete the pod
Feb 17 16:15:02.303: INFO: Waiting for pod pod-secrets-87a4f1f9-1063-4e19-b678-4dfc2ba8e7d6 to disappear
Feb 17 16:15:02.317: INFO: Pod pod-secrets-87a4f1f9-1063-4e19-b678-4dfc2ba8e7d6 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 16:15:02.317: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3082" for this suite.
Feb 17 16:15:10.388: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:15:10.790: INFO: namespace secrets-3082 deletion completed in 8.452126497s

• [SLOW TEST:12.979 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 16:15:10.791: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-4677
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
Feb 17 16:15:11.047: INFO: PodSpec: initContainers in spec.initContainers
Feb 17 16:16:00.045: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-40e515fa-ecf4-4fd6-a358-adfebf74df4a", GenerateName:"", Namespace:"init-container-4677", SelfLink:"/api/v1/namespaces/init-container-4677/pods/pod-init-40e515fa-ecf4-4fd6-a358-adfebf74df4a", UID:"ff18db3b-f083-4aea-b8ea-8437a68f3dee", ResourceVersion:"18342", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63717552911, loc:(*time.Location)(0x7ed4a20)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"47346321"}, Annotations:map[string]string{"kubernetes.io/psp":"e2e-test-privileged-psp"}, OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-nf794", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc002479f80), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-nf794", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-nf794", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-nf794", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc002b803a8), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"10.242.0.59", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc0028ac480), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc002b80430)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc002b80450)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc002b80458), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc002b8045c), PreemptionPolicy:(*v1.PreemptionPolicy)(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717552911, loc:(*time.Location)(0x7ed4a20)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717552911, loc:(*time.Location)(0x7ed4a20)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717552911, loc:(*time.Location)(0x7ed4a20)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717552911, loc:(*time.Location)(0x7ed4a20)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.242.0.59", PodIP:"172.30.94.49", StartTime:(*v1.Time)(0xc0026937c0), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc000e6e000)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc000e6e070)}, Ready:false, RestartCount:3, Image:"docker.io/library/busybox:1.29", ImageID:"docker.io/library/busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"containerd://442951f47bb678ba8f5a224f678f1df74bbc345bf626ba49f9ce3c09d8410e45"}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc002693800), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:""}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0026937e0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:""}}, QOSClass:"Guaranteed"}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 16:16:00.046: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-4677" for this suite.
Feb 17 16:16:24.118: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:16:24.509: INFO: namespace init-container-4677 deletion completed in 24.443405867s

• [SLOW TEST:73.718 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 16:16:24.509: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-7998
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 16:16:50.453: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-7998" for this suite.
Feb 17 16:16:56.524: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:16:56.939: INFO: namespace container-runtime-7998 deletion completed in 6.467580208s

• [SLOW TEST:32.430 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  blackbox test
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
    when starting a container that exits
    /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 16:16:56.941: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-5600
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0777 on node default medium
Feb 17 16:16:57.226: INFO: Waiting up to 5m0s for pod "pod-a063df01-4810-4f90-a4a6-a0a499715a9d" in namespace "emptydir-5600" to be "success or failure"
Feb 17 16:16:57.236: INFO: Pod "pod-a063df01-4810-4f90-a4a6-a0a499715a9d": Phase="Pending", Reason="", readiness=false. Elapsed: 10.607961ms
Feb 17 16:16:59.249: INFO: Pod "pod-a063df01-4810-4f90-a4a6-a0a499715a9d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022789673s
Feb 17 16:17:01.261: INFO: Pod "pod-a063df01-4810-4f90-a4a6-a0a499715a9d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.035495386s
STEP: Saw pod success
Feb 17 16:17:01.262: INFO: Pod "pod-a063df01-4810-4f90-a4a6-a0a499715a9d" satisfied condition "success or failure"
Feb 17 16:17:01.274: INFO: Trying to get logs from node 10.242.0.59 pod pod-a063df01-4810-4f90-a4a6-a0a499715a9d container test-container: <nil>
STEP: delete the pod
Feb 17 16:17:01.343: INFO: Waiting for pod pod-a063df01-4810-4f90-a4a6-a0a499715a9d to disappear
Feb 17 16:17:01.354: INFO: Pod pod-a063df01-4810-4f90-a4a6-a0a499715a9d no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 16:17:01.355: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5600" for this suite.
Feb 17 16:17:07.430: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:17:07.829: INFO: namespace emptydir-5600 deletion completed in 6.454399997s

• [SLOW TEST:10.889 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 16:17:07.830: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5535
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-map-87ea54b8-cb36-42bb-943f-b7cc96ff4f44
STEP: Creating a pod to test consume secrets
Feb 17 16:17:08.141: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-3c561e76-21df-411d-a3e0-0e185fff53e1" in namespace "projected-5535" to be "success or failure"
Feb 17 16:17:08.156: INFO: Pod "pod-projected-secrets-3c561e76-21df-411d-a3e0-0e185fff53e1": Phase="Pending", Reason="", readiness=false. Elapsed: 14.983449ms
Feb 17 16:17:10.172: INFO: Pod "pod-projected-secrets-3c561e76-21df-411d-a3e0-0e185fff53e1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.03029407s
Feb 17 16:17:12.184: INFO: Pod "pod-projected-secrets-3c561e76-21df-411d-a3e0-0e185fff53e1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.042588459s
STEP: Saw pod success
Feb 17 16:17:12.184: INFO: Pod "pod-projected-secrets-3c561e76-21df-411d-a3e0-0e185fff53e1" satisfied condition "success or failure"
Feb 17 16:17:12.195: INFO: Trying to get logs from node 10.242.0.98 pod pod-projected-secrets-3c561e76-21df-411d-a3e0-0e185fff53e1 container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb 17 16:17:12.259: INFO: Waiting for pod pod-projected-secrets-3c561e76-21df-411d-a3e0-0e185fff53e1 to disappear
Feb 17 16:17:12.270: INFO: Pod pod-projected-secrets-3c561e76-21df-411d-a3e0-0e185fff53e1 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 16:17:12.270: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5535" for this suite.
Feb 17 16:17:18.344: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:17:18.758: INFO: namespace projected-5535 deletion completed in 6.467637701s

• [SLOW TEST:10.929 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 16:17:18.760: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-4470
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:63
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Feb 17 16:17:29.165: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 17 16:17:29.177: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 17 16:17:31.177: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 17 16:17:31.190: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 17 16:17:33.177: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 17 16:17:33.190: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 17 16:17:35.177: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 17 16:17:35.190: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 17 16:17:37.177: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 17 16:17:37.192: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 17 16:17:39.179: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 17 16:17:39.191: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 17 16:17:41.177: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 17 16:17:41.189: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 17 16:17:43.177: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 17 16:17:43.189: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 17 16:17:45.177: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 17 16:17:45.189: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 17 16:17:47.177: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 17 16:17:47.192: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 17 16:17:49.179: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 17 16:17:49.191: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 17 16:17:51.177: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 17 16:17:51.190: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 17 16:17:53.177: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 17 16:17:53.190: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 16:17:53.220: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-4470" for this suite.
Feb 17 16:18:17.291: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:18:17.687: INFO: namespace container-lifecycle-hook-4470 deletion completed in 24.447708729s

• [SLOW TEST:58.927 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when create a pod with lifecycle hook
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 16:18:17.698: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-891
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Feb 17 16:18:18.197: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b19b4c79-4c1d-40e4-9a9e-1e6dc0018e7c" in namespace "projected-891" to be "success or failure"
Feb 17 16:18:18.207: INFO: Pod "downwardapi-volume-b19b4c79-4c1d-40e4-9a9e-1e6dc0018e7c": Phase="Pending", Reason="", readiness=false. Elapsed: 10.766431ms
Feb 17 16:18:20.219: INFO: Pod "downwardapi-volume-b19b4c79-4c1d-40e4-9a9e-1e6dc0018e7c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022357905s
Feb 17 16:18:22.231: INFO: Pod "downwardapi-volume-b19b4c79-4c1d-40e4-9a9e-1e6dc0018e7c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.034134783s
STEP: Saw pod success
Feb 17 16:18:22.231: INFO: Pod "downwardapi-volume-b19b4c79-4c1d-40e4-9a9e-1e6dc0018e7c" satisfied condition "success or failure"
Feb 17 16:18:22.241: INFO: Trying to get logs from node 10.242.0.59 pod downwardapi-volume-b19b4c79-4c1d-40e4-9a9e-1e6dc0018e7c container client-container: <nil>
STEP: delete the pod
Feb 17 16:18:22.309: INFO: Waiting for pod downwardapi-volume-b19b4c79-4c1d-40e4-9a9e-1e6dc0018e7c to disappear
Feb 17 16:18:22.320: INFO: Pod downwardapi-volume-b19b4c79-4c1d-40e4-9a9e-1e6dc0018e7c no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 16:18:22.320: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-891" for this suite.
Feb 17 16:18:28.390: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:18:28.805: INFO: namespace projected-891 deletion completed in 6.466740518s

• [SLOW TEST:11.106 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 16:18:28.806: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-4588
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Feb 17 16:18:29.082: INFO: Waiting up to 5m0s for pod "downward-api-4d5aaff5-d36e-4512-b76d-92656b112924" in namespace "downward-api-4588" to be "success or failure"
Feb 17 16:18:29.094: INFO: Pod "downward-api-4d5aaff5-d36e-4512-b76d-92656b112924": Phase="Pending", Reason="", readiness=false. Elapsed: 11.739833ms
Feb 17 16:18:31.110: INFO: Pod "downward-api-4d5aaff5-d36e-4512-b76d-92656b112924": Phase="Pending", Reason="", readiness=false. Elapsed: 2.027328197s
Feb 17 16:18:33.122: INFO: Pod "downward-api-4d5aaff5-d36e-4512-b76d-92656b112924": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.039631319s
STEP: Saw pod success
Feb 17 16:18:33.122: INFO: Pod "downward-api-4d5aaff5-d36e-4512-b76d-92656b112924" satisfied condition "success or failure"
Feb 17 16:18:33.133: INFO: Trying to get logs from node 10.242.0.98 pod downward-api-4d5aaff5-d36e-4512-b76d-92656b112924 container dapi-container: <nil>
STEP: delete the pod
Feb 17 16:18:33.202: INFO: Waiting for pod downward-api-4d5aaff5-d36e-4512-b76d-92656b112924 to disappear
Feb 17 16:18:33.213: INFO: Pod downward-api-4d5aaff5-d36e-4512-b76d-92656b112924 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 16:18:33.213: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4588" for this suite.
Feb 17 16:18:39.277: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:18:39.688: INFO: namespace downward-api-4588 deletion completed in 6.458147781s

• [SLOW TEST:10.882 seconds]
[sig-node] Downward API
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 16:18:39.690: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7203
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Feb 17 16:18:39.970: INFO: Waiting up to 5m0s for pod "downwardapi-volume-4c0f219e-e3d5-4efe-9413-ba27499a8fa1" in namespace "projected-7203" to be "success or failure"
Feb 17 16:18:39.983: INFO: Pod "downwardapi-volume-4c0f219e-e3d5-4efe-9413-ba27499a8fa1": Phase="Pending", Reason="", readiness=false. Elapsed: 13.110158ms
Feb 17 16:18:41.994: INFO: Pod "downwardapi-volume-4c0f219e-e3d5-4efe-9413-ba27499a8fa1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.024147495s
STEP: Saw pod success
Feb 17 16:18:41.994: INFO: Pod "downwardapi-volume-4c0f219e-e3d5-4efe-9413-ba27499a8fa1" satisfied condition "success or failure"
Feb 17 16:18:42.006: INFO: Trying to get logs from node 10.242.0.59 pod downwardapi-volume-4c0f219e-e3d5-4efe-9413-ba27499a8fa1 container client-container: <nil>
STEP: delete the pod
Feb 17 16:18:42.071: INFO: Waiting for pod downwardapi-volume-4c0f219e-e3d5-4efe-9413-ba27499a8fa1 to disappear
Feb 17 16:18:42.083: INFO: Pod downwardapi-volume-4c0f219e-e3d5-4efe-9413-ba27499a8fa1 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 16:18:42.083: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7203" for this suite.
Feb 17 16:18:48.154: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:18:48.544: INFO: namespace projected-7203 deletion completed in 6.440265222s

• [SLOW TEST:8.855 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 16:18:48.545: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-8477
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Feb 17 16:18:48.943: INFO: Create a RollingUpdate DaemonSet
Feb 17 16:18:48.957: INFO: Check that daemon pods launch on every node of the cluster
Feb 17 16:18:48.984: INFO: Number of nodes with available pods: 0
Feb 17 16:18:48.984: INFO: Node 10.242.0.59 is running more than one daemon pod
Feb 17 16:18:50.015: INFO: Number of nodes with available pods: 0
Feb 17 16:18:50.015: INFO: Node 10.242.0.59 is running more than one daemon pod
Feb 17 16:18:51.031: INFO: Number of nodes with available pods: 0
Feb 17 16:18:51.031: INFO: Node 10.242.0.59 is running more than one daemon pod
Feb 17 16:18:52.017: INFO: Number of nodes with available pods: 0
Feb 17 16:18:52.017: INFO: Node 10.242.0.59 is running more than one daemon pod
Feb 17 16:18:53.022: INFO: Number of nodes with available pods: 1
Feb 17 16:18:53.022: INFO: Node 10.242.0.59 is running more than one daemon pod
Feb 17 16:18:54.015: INFO: Number of nodes with available pods: 3
Feb 17 16:18:54.015: INFO: Number of running nodes: 3, number of available pods: 3
Feb 17 16:18:54.015: INFO: Update the DaemonSet to trigger a rollout
Feb 17 16:18:54.038: INFO: Updating DaemonSet daemon-set
Feb 17 16:18:59.094: INFO: Roll back the DaemonSet before rollout is complete
Feb 17 16:18:59.123: INFO: Updating DaemonSet daemon-set
Feb 17 16:18:59.123: INFO: Make sure DaemonSet rollback is complete
Feb 17 16:18:59.135: INFO: Wrong image for pod: daemon-set-x5475. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Feb 17 16:18:59.135: INFO: Pod daemon-set-x5475 is not available
Feb 17 16:19:00.163: INFO: Wrong image for pod: daemon-set-x5475. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Feb 17 16:19:00.163: INFO: Pod daemon-set-x5475 is not available
Feb 17 16:19:01.166: INFO: Wrong image for pod: daemon-set-x5475. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Feb 17 16:19:01.166: INFO: Pod daemon-set-x5475 is not available
Feb 17 16:19:02.171: INFO: Wrong image for pod: daemon-set-x5475. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Feb 17 16:19:02.171: INFO: Pod daemon-set-x5475 is not available
Feb 17 16:19:03.166: INFO: Wrong image for pod: daemon-set-x5475. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Feb 17 16:19:03.166: INFO: Pod daemon-set-x5475 is not available
Feb 17 16:19:04.163: INFO: Wrong image for pod: daemon-set-x5475. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Feb 17 16:19:04.163: INFO: Pod daemon-set-x5475 is not available
Feb 17 16:19:05.163: INFO: Wrong image for pod: daemon-set-x5475. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Feb 17 16:19:05.163: INFO: Pod daemon-set-x5475 is not available
Feb 17 16:19:06.167: INFO: Wrong image for pod: daemon-set-x5475. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Feb 17 16:19:06.167: INFO: Pod daemon-set-x5475 is not available
Feb 17 16:19:07.164: INFO: Wrong image for pod: daemon-set-x5475. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Feb 17 16:19:07.164: INFO: Pod daemon-set-x5475 is not available
Feb 17 16:19:08.164: INFO: Wrong image for pod: daemon-set-x5475. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Feb 17 16:19:08.164: INFO: Pod daemon-set-x5475 is not available
Feb 17 16:19:09.171: INFO: Pod daemon-set-lkrpr is not available
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-8477, will wait for the garbage collector to delete the pods
Feb 17 16:19:09.310: INFO: Deleting DaemonSet.extensions daemon-set took: 25.726558ms
Feb 17 16:19:09.511: INFO: Terminating DaemonSet.extensions daemon-set pods took: 200.257411ms
Feb 17 16:19:17.422: INFO: Number of nodes with available pods: 0
Feb 17 16:19:17.422: INFO: Number of running nodes: 0, number of available pods: 0
Feb 17 16:19:17.435: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-8477/daemonsets","resourceVersion":"19149"},"items":null}

Feb 17 16:19:17.446: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-8477/pods","resourceVersion":"19149"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 16:19:17.506: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-8477" for this suite.
Feb 17 16:19:25.570: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:19:25.956: INFO: namespace daemonsets-8477 deletion completed in 8.434380268s

• [SLOW TEST:37.411 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 16:19:25.956: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-5797
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-8fa4e940-0926-4709-978b-aaaa12915e8d
STEP: Creating a pod to test consume secrets
Feb 17 16:19:26.286: INFO: Waiting up to 5m0s for pod "pod-secrets-04793c37-c0f8-49b8-b0e3-1edae2216c8a" in namespace "secrets-5797" to be "success or failure"
Feb 17 16:19:26.297: INFO: Pod "pod-secrets-04793c37-c0f8-49b8-b0e3-1edae2216c8a": Phase="Pending", Reason="", readiness=false. Elapsed: 10.908213ms
Feb 17 16:19:28.310: INFO: Pod "pod-secrets-04793c37-c0f8-49b8-b0e3-1edae2216c8a": Phase="Running", Reason="", readiness=true. Elapsed: 2.024164245s
Feb 17 16:19:30.322: INFO: Pod "pod-secrets-04793c37-c0f8-49b8-b0e3-1edae2216c8a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.035454001s
STEP: Saw pod success
Feb 17 16:19:30.322: INFO: Pod "pod-secrets-04793c37-c0f8-49b8-b0e3-1edae2216c8a" satisfied condition "success or failure"
Feb 17 16:19:30.334: INFO: Trying to get logs from node 10.242.0.98 pod pod-secrets-04793c37-c0f8-49b8-b0e3-1edae2216c8a container secret-volume-test: <nil>
STEP: delete the pod
Feb 17 16:19:30.401: INFO: Waiting for pod pod-secrets-04793c37-c0f8-49b8-b0e3-1edae2216c8a to disappear
Feb 17 16:19:30.412: INFO: Pod pod-secrets-04793c37-c0f8-49b8-b0e3-1edae2216c8a no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 16:19:30.412: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5797" for this suite.
Feb 17 16:19:36.481: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:19:37.018: INFO: namespace secrets-5797 deletion completed in 6.584345096s

• [SLOW TEST:11.062 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 16:19:37.022: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-2544
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0777 on tmpfs
Feb 17 16:19:37.307: INFO: Waiting up to 5m0s for pod "pod-010bf130-a346-499c-ad75-b4affd7bcd50" in namespace "emptydir-2544" to be "success or failure"
Feb 17 16:19:37.319: INFO: Pod "pod-010bf130-a346-499c-ad75-b4affd7bcd50": Phase="Pending", Reason="", readiness=false. Elapsed: 11.170848ms
Feb 17 16:19:39.336: INFO: Pod "pod-010bf130-a346-499c-ad75-b4affd7bcd50": Phase="Pending", Reason="", readiness=false. Elapsed: 2.028049113s
Feb 17 16:19:41.347: INFO: Pod "pod-010bf130-a346-499c-ad75-b4affd7bcd50": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.039657637s
STEP: Saw pod success
Feb 17 16:19:41.347: INFO: Pod "pod-010bf130-a346-499c-ad75-b4affd7bcd50" satisfied condition "success or failure"
Feb 17 16:19:41.360: INFO: Trying to get logs from node 10.242.0.59 pod pod-010bf130-a346-499c-ad75-b4affd7bcd50 container test-container: <nil>
STEP: delete the pod
Feb 17 16:19:41.424: INFO: Waiting for pod pod-010bf130-a346-499c-ad75-b4affd7bcd50 to disappear
Feb 17 16:19:41.435: INFO: Pod pod-010bf130-a346-499c-ad75-b4affd7bcd50 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 16:19:41.435: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2544" for this suite.
Feb 17 16:19:49.506: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:19:49.900: INFO: namespace emptydir-2544 deletion completed in 8.448111804s

• [SLOW TEST:12.879 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 16:19:49.900: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-4096
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-bce7bed2-46d0-4ad4-99d3-645d303689b0
STEP: Creating a pod to test consume configMaps
Feb 17 16:19:50.206: INFO: Waiting up to 5m0s for pod "pod-configmaps-071bb30f-4caf-4920-b89f-3078a7451740" in namespace "configmap-4096" to be "success or failure"
Feb 17 16:19:50.218: INFO: Pod "pod-configmaps-071bb30f-4caf-4920-b89f-3078a7451740": Phase="Pending", Reason="", readiness=false. Elapsed: 12.115353ms
Feb 17 16:19:52.230: INFO: Pod "pod-configmaps-071bb30f-4caf-4920-b89f-3078a7451740": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.023483376s
STEP: Saw pod success
Feb 17 16:19:52.230: INFO: Pod "pod-configmaps-071bb30f-4caf-4920-b89f-3078a7451740" satisfied condition "success or failure"
Feb 17 16:19:52.241: INFO: Trying to get logs from node 10.242.0.98 pod pod-configmaps-071bb30f-4caf-4920-b89f-3078a7451740 container configmap-volume-test: <nil>
STEP: delete the pod
Feb 17 16:19:52.306: INFO: Waiting for pod pod-configmaps-071bb30f-4caf-4920-b89f-3078a7451740 to disappear
Feb 17 16:19:52.317: INFO: Pod pod-configmaps-071bb30f-4caf-4920-b89f-3078a7451740 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 16:19:52.317: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4096" for this suite.
Feb 17 16:19:58.388: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:19:58.806: INFO: namespace configmap-4096 deletion completed in 6.469259646s

• [SLOW TEST:8.905 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-apps] ReplicationController 
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 16:19:58.806: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-5872
STEP: Waiting for a default service account to be provisioned in namespace
[It] should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Feb 17 16:19:59.067: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
STEP: Creating rc "condition-test" that asks for more than the allowed pod quota
STEP: Checking rc "condition-test" has the desired failure condition set
STEP: Scaling down rc "condition-test" to satisfy pod quota
Feb 17 16:20:01.191: INFO: Updating replication controller "condition-test"
STEP: Checking rc "condition-test" has no failure condition set
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 16:20:02.218: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-5872" for this suite.
Feb 17 16:20:10.290: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:20:10.795: INFO: namespace replication-controller-5872 deletion completed in 8.559104441s

• [SLOW TEST:11.989 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 16:20:10.796: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-3407
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-3407
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a new StatefulSet
Feb 17 16:20:11.099: INFO: Found 0 stateful pods, waiting for 3
Feb 17 16:20:21.113: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Feb 17 16:20:21.113: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Feb 17 16:20:21.113: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Feb 17 16:20:21.150: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-079603707 exec --namespace=statefulset-3407 ss2-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 17 16:20:21.755: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Feb 17 16:20:21.755: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 17 16:20:21.755: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Feb 17 16:20:31.843: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Feb 17 16:20:41.911: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-079603707 exec --namespace=statefulset-3407 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 17 16:20:42.367: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Feb 17 16:20:42.367: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb 17 16:20:42.367: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb 17 16:20:52.448: INFO: Waiting for StatefulSet statefulset-3407/ss2 to complete update
Feb 17 16:20:52.448: INFO: Waiting for Pod statefulset-3407/ss2-0 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Feb 17 16:20:52.448: INFO: Waiting for Pod statefulset-3407/ss2-1 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Feb 17 16:20:52.448: INFO: Waiting for Pod statefulset-3407/ss2-2 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Feb 17 16:21:02.474: INFO: Waiting for StatefulSet statefulset-3407/ss2 to complete update
Feb 17 16:21:02.475: INFO: Waiting for Pod statefulset-3407/ss2-0 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Feb 17 16:21:02.475: INFO: Waiting for Pod statefulset-3407/ss2-1 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Feb 17 16:21:12.477: INFO: Waiting for StatefulSet statefulset-3407/ss2 to complete update
Feb 17 16:21:12.477: INFO: Waiting for Pod statefulset-3407/ss2-0 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Feb 17 16:21:22.473: INFO: Waiting for StatefulSet statefulset-3407/ss2 to complete update
Feb 17 16:21:22.473: INFO: Waiting for Pod statefulset-3407/ss2-0 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
STEP: Rolling back to a previous revision
Feb 17 16:21:32.477: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-079603707 exec --namespace=statefulset-3407 ss2-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 17 16:21:32.893: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Feb 17 16:21:32.893: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 17 16:21:32.893: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 17 16:21:42.987: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Feb 17 16:21:53.054: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-079603707 exec --namespace=statefulset-3407 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 17 16:21:53.540: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Feb 17 16:21:53.540: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb 17 16:21:53.540: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb 17 16:21:53.590: INFO: Waiting for StatefulSet statefulset-3407/ss2 to complete update
Feb 17 16:21:53.590: INFO: Waiting for Pod statefulset-3407/ss2-0 to have revision ss2-7c9b54fd4c update revision ss2-6c5cd755cd
Feb 17 16:21:53.590: INFO: Waiting for Pod statefulset-3407/ss2-1 to have revision ss2-7c9b54fd4c update revision ss2-6c5cd755cd
Feb 17 16:21:53.590: INFO: Waiting for Pod statefulset-3407/ss2-2 to have revision ss2-7c9b54fd4c update revision ss2-6c5cd755cd
Feb 17 16:22:03.615: INFO: Waiting for StatefulSet statefulset-3407/ss2 to complete update
Feb 17 16:22:03.615: INFO: Waiting for Pod statefulset-3407/ss2-0 to have revision ss2-7c9b54fd4c update revision ss2-6c5cd755cd
Feb 17 16:22:03.615: INFO: Waiting for Pod statefulset-3407/ss2-1 to have revision ss2-7c9b54fd4c update revision ss2-6c5cd755cd
Feb 17 16:22:13.616: INFO: Waiting for StatefulSet statefulset-3407/ss2 to complete update
Feb 17 16:22:13.616: INFO: Waiting for Pod statefulset-3407/ss2-0 to have revision ss2-7c9b54fd4c update revision ss2-6c5cd755cd
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Feb 17 16:22:23.615: INFO: Deleting all statefulset in ns statefulset-3407
Feb 17 16:22:23.627: INFO: Scaling statefulset ss2 to 0
Feb 17 16:22:43.681: INFO: Waiting for statefulset status.replicas updated to 0
Feb 17 16:22:43.694: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 16:22:43.747: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-3407" for this suite.
Feb 17 16:22:51.815: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:22:52.217: INFO: namespace statefulset-3407 deletion completed in 8.451047687s

• [SLOW TEST:161.421 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 16:22:52.217: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-169
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-169
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a new StatefulSet
Feb 17 16:22:52.509: INFO: Found 0 stateful pods, waiting for 3
Feb 17 16:23:02.522: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Feb 17 16:23:02.522: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Feb 17 16:23:02.522: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Feb 17 16:23:02.601: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Feb 17 16:23:12.699: INFO: Updating stateful set ss2
Feb 17 16:23:12.729: INFO: Waiting for Pod statefulset-169/ss2-2 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Feb 17 16:23:22.761: INFO: Waiting for Pod statefulset-169/ss2-2 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
STEP: Restoring Pods to the correct revision when they are deleted
Feb 17 16:23:32.843: INFO: Found 2 stateful pods, waiting for 3
Feb 17 16:23:42.856: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Feb 17 16:23:42.856: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Feb 17 16:23:42.856: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Feb 17 16:23:42.925: INFO: Updating stateful set ss2
Feb 17 16:23:42.958: INFO: Waiting for Pod statefulset-169/ss2-1 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Feb 17 16:23:53.030: INFO: Updating stateful set ss2
Feb 17 16:23:53.058: INFO: Waiting for StatefulSet statefulset-169/ss2 to complete update
Feb 17 16:23:53.058: INFO: Waiting for Pod statefulset-169/ss2-0 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Feb 17 16:24:03.083: INFO: Deleting all statefulset in ns statefulset-169
Feb 17 16:24:03.095: INFO: Scaling statefulset ss2 to 0
Feb 17 16:24:23.155: INFO: Waiting for statefulset status.replicas updated to 0
Feb 17 16:24:23.168: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 16:24:23.229: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-169" for this suite.
Feb 17 16:24:31.304: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:24:31.701: INFO: namespace statefulset-169 deletion completed in 8.451671676s

• [SLOW TEST:99.484 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 16:24:31.703: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-5486
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating Redis RC
Feb 17 16:24:31.959: INFO: namespace kubectl-5486
Feb 17 16:24:31.959: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-079603707 create -f - --namespace=kubectl-5486'
Feb 17 16:24:32.434: INFO: stderr: ""
Feb 17 16:24:32.434: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Feb 17 16:24:33.448: INFO: Selector matched 1 pods for map[app:redis]
Feb 17 16:24:33.448: INFO: Found 0 / 1
Feb 17 16:24:34.446: INFO: Selector matched 1 pods for map[app:redis]
Feb 17 16:24:34.446: INFO: Found 0 / 1
Feb 17 16:24:35.446: INFO: Selector matched 1 pods for map[app:redis]
Feb 17 16:24:35.446: INFO: Found 0 / 1
Feb 17 16:24:36.445: INFO: Selector matched 1 pods for map[app:redis]
Feb 17 16:24:36.445: INFO: Found 1 / 1
Feb 17 16:24:36.445: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Feb 17 16:24:36.461: INFO: Selector matched 1 pods for map[app:redis]
Feb 17 16:24:36.461: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Feb 17 16:24:36.461: INFO: wait on redis-master startup in kubectl-5486 
Feb 17 16:24:36.461: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-079603707 logs redis-master-82znl redis-master --namespace=kubectl-5486'
Feb 17 16:24:36.666: INFO: stderr: ""
Feb 17 16:24:36.666: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 17 Feb 16:24:35.650 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 17 Feb 16:24:35.651 # Server started, Redis version 3.2.12\n1:M 17 Feb 16:24:35.651 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 17 Feb 16:24:35.651 * The server is now ready to accept connections on port 6379\n"
STEP: exposing RC
Feb 17 16:24:36.666: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-079603707 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=kubectl-5486'
Feb 17 16:24:36.857: INFO: stderr: ""
Feb 17 16:24:36.857: INFO: stdout: "service/rm2 exposed\n"
Feb 17 16:24:36.870: INFO: Service rm2 in namespace kubectl-5486 found.
STEP: exposing service
Feb 17 16:24:38.895: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-079603707 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=kubectl-5486'
Feb 17 16:24:39.059: INFO: stderr: ""
Feb 17 16:24:39.059: INFO: stdout: "service/rm3 exposed\n"
Feb 17 16:24:39.073: INFO: Service rm3 in namespace kubectl-5486 found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 16:24:41.098: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5486" for this suite.
Feb 17 16:25:05.167: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:25:05.573: INFO: namespace kubectl-5486 deletion completed in 24.457592673s

• [SLOW TEST:33.870 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl expose
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create services for rc  [Conformance]
    /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 16:25:05.574: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-235
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Feb 17 16:25:05.855: INFO: Waiting up to 5m0s for pod "downwardapi-volume-73be9674-58d6-4619-ad7b-3746c5e42e5f" in namespace "downward-api-235" to be "success or failure"
Feb 17 16:25:05.866: INFO: Pod "downwardapi-volume-73be9674-58d6-4619-ad7b-3746c5e42e5f": Phase="Pending", Reason="", readiness=false. Elapsed: 11.521197ms
Feb 17 16:25:07.878: INFO: Pod "downwardapi-volume-73be9674-58d6-4619-ad7b-3746c5e42e5f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023169352s
Feb 17 16:25:09.889: INFO: Pod "downwardapi-volume-73be9674-58d6-4619-ad7b-3746c5e42e5f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.034619306s
STEP: Saw pod success
Feb 17 16:25:09.889: INFO: Pod "downwardapi-volume-73be9674-58d6-4619-ad7b-3746c5e42e5f" satisfied condition "success or failure"
Feb 17 16:25:09.901: INFO: Trying to get logs from node 10.242.0.59 pod downwardapi-volume-73be9674-58d6-4619-ad7b-3746c5e42e5f container client-container: <nil>
STEP: delete the pod
Feb 17 16:25:09.976: INFO: Waiting for pod downwardapi-volume-73be9674-58d6-4619-ad7b-3746c5e42e5f to disappear
Feb 17 16:25:09.988: INFO: Pod downwardapi-volume-73be9674-58d6-4619-ad7b-3746c5e42e5f no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 16:25:09.988: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-235" for this suite.
Feb 17 16:25:16.057: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:25:16.461: INFO: namespace downward-api-235 deletion completed in 6.453596748s

• [SLOW TEST:10.887 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 16:25:16.464: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-8957
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-182b7c77-a651-4545-bf91-fc4dd15ebb8b
STEP: Creating a pod to test consume secrets
Feb 17 16:25:16.773: INFO: Waiting up to 5m0s for pod "pod-secrets-882832ec-4148-4aa1-807d-cc740a4b3d7e" in namespace "secrets-8957" to be "success or failure"
Feb 17 16:25:16.784: INFO: Pod "pod-secrets-882832ec-4148-4aa1-807d-cc740a4b3d7e": Phase="Pending", Reason="", readiness=false. Elapsed: 10.915292ms
Feb 17 16:25:18.796: INFO: Pod "pod-secrets-882832ec-4148-4aa1-807d-cc740a4b3d7e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.022601408s
STEP: Saw pod success
Feb 17 16:25:18.796: INFO: Pod "pod-secrets-882832ec-4148-4aa1-807d-cc740a4b3d7e" satisfied condition "success or failure"
Feb 17 16:25:18.807: INFO: Trying to get logs from node 10.242.0.98 pod pod-secrets-882832ec-4148-4aa1-807d-cc740a4b3d7e container secret-volume-test: <nil>
STEP: delete the pod
Feb 17 16:25:18.872: INFO: Waiting for pod pod-secrets-882832ec-4148-4aa1-807d-cc740a4b3d7e to disappear
Feb 17 16:25:18.883: INFO: Pod pod-secrets-882832ec-4148-4aa1-807d-cc740a4b3d7e no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 16:25:18.883: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8957" for this suite.
Feb 17 16:25:24.959: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:25:25.367: INFO: namespace secrets-8957 deletion completed in 6.462129117s

• [SLOW TEST:8.903 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 16:25:25.367: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-5698
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-map-c53bf87f-cbda-480c-aa07-ef677e03b58d
STEP: Creating a pod to test consume configMaps
Feb 17 16:25:25.656: INFO: Waiting up to 5m0s for pod "pod-configmaps-8ec2a32c-7af1-4d60-a046-644371eb0a50" in namespace "configmap-5698" to be "success or failure"
Feb 17 16:25:25.669: INFO: Pod "pod-configmaps-8ec2a32c-7af1-4d60-a046-644371eb0a50": Phase="Pending", Reason="", readiness=false. Elapsed: 12.965828ms
Feb 17 16:25:27.681: INFO: Pod "pod-configmaps-8ec2a32c-7af1-4d60-a046-644371eb0a50": Phase="Running", Reason="", readiness=true. Elapsed: 2.024647737s
Feb 17 16:25:29.693: INFO: Pod "pod-configmaps-8ec2a32c-7af1-4d60-a046-644371eb0a50": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.036877678s
STEP: Saw pod success
Feb 17 16:25:29.693: INFO: Pod "pod-configmaps-8ec2a32c-7af1-4d60-a046-644371eb0a50" satisfied condition "success or failure"
Feb 17 16:25:29.709: INFO: Trying to get logs from node 10.242.0.59 pod pod-configmaps-8ec2a32c-7af1-4d60-a046-644371eb0a50 container configmap-volume-test: <nil>
STEP: delete the pod
Feb 17 16:25:29.832: INFO: Waiting for pod pod-configmaps-8ec2a32c-7af1-4d60-a046-644371eb0a50 to disappear
Feb 17 16:25:29.843: INFO: Pod pod-configmaps-8ec2a32c-7af1-4d60-a046-644371eb0a50 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 16:25:29.843: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5698" for this suite.
Feb 17 16:25:35.920: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:25:36.323: INFO: namespace configmap-5698 deletion completed in 6.457273808s

• [SLOW TEST:10.956 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 16:25:36.325: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-5207
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Feb 17 16:25:36.601: INFO: Waiting up to 5m0s for pod "downward-api-a6203a58-30ae-499a-92df-37cf787ca0cd" in namespace "downward-api-5207" to be "success or failure"
Feb 17 16:25:36.616: INFO: Pod "downward-api-a6203a58-30ae-499a-92df-37cf787ca0cd": Phase="Pending", Reason="", readiness=false. Elapsed: 14.696146ms
Feb 17 16:25:38.628: INFO: Pod "downward-api-a6203a58-30ae-499a-92df-37cf787ca0cd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.02655986s
STEP: Saw pod success
Feb 17 16:25:38.628: INFO: Pod "downward-api-a6203a58-30ae-499a-92df-37cf787ca0cd" satisfied condition "success or failure"
Feb 17 16:25:38.640: INFO: Trying to get logs from node 10.242.0.98 pod downward-api-a6203a58-30ae-499a-92df-37cf787ca0cd container dapi-container: <nil>
STEP: delete the pod
Feb 17 16:25:38.716: INFO: Waiting for pod downward-api-a6203a58-30ae-499a-92df-37cf787ca0cd to disappear
Feb 17 16:25:38.729: INFO: Pod downward-api-a6203a58-30ae-499a-92df-37cf787ca0cd no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 16:25:38.729: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5207" for this suite.
Feb 17 16:25:44.804: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:25:45.186: INFO: namespace downward-api-5207 deletion completed in 6.431196503s

• [SLOW TEST:8.861 seconds]
[sig-node] Downward API
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 16:25:45.190: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-wrapper-2723
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 16:25:49.662: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-2723" for this suite.
Feb 17 16:25:55.729: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:25:56.135: INFO: namespace emptydir-wrapper-2723 deletion completed in 6.454732353s

• [SLOW TEST:10.945 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not conflict [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 16:25:56.136: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-3784
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating service endpoint-test2 in namespace services-3784
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-3784 to expose endpoints map[]
Feb 17 16:25:56.436: INFO: successfully validated that service endpoint-test2 in namespace services-3784 exposes endpoints map[] (13.43872ms elapsed)
STEP: Creating pod pod1 in namespace services-3784
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-3784 to expose endpoints map[pod1:[80]]
Feb 17 16:25:58.543: INFO: successfully validated that service endpoint-test2 in namespace services-3784 exposes endpoints map[pod1:[80]] (2.075708452s elapsed)
STEP: Creating pod pod2 in namespace services-3784
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-3784 to expose endpoints map[pod1:[80] pod2:[80]]
Feb 17 16:26:00.664: INFO: successfully validated that service endpoint-test2 in namespace services-3784 exposes endpoints map[pod1:[80] pod2:[80]] (2.107311538s elapsed)
STEP: Deleting pod pod1 in namespace services-3784
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-3784 to expose endpoints map[pod2:[80]]
Feb 17 16:26:00.711: INFO: successfully validated that service endpoint-test2 in namespace services-3784 exposes endpoints map[pod2:[80]] (26.611744ms elapsed)
STEP: Deleting pod pod2 in namespace services-3784
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-3784 to expose endpoints map[]
Feb 17 16:26:00.744: INFO: successfully validated that service endpoint-test2 in namespace services-3784 exposes endpoints map[] (13.329583ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 16:26:00.817: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-3784" for this suite.
Feb 17 16:26:24.895: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:26:25.319: INFO: namespace services-3784 deletion completed in 24.484910402s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:92

• [SLOW TEST:29.184 seconds]
[sig-network] Services
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 16:26:25.324: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-2877
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0217 16:26:35.806060      16 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb 17 16:26:35.806: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 16:26:35.806: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-2877" for this suite.
Feb 17 16:26:43.873: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:26:44.270: INFO: namespace gc-2877 deletion completed in 8.447263504s

• [SLOW TEST:18.945 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 16:26:44.270: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-7156
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Feb 17 16:26:44.547: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e44809ec-6cec-4a07-a346-3c8ea88abef1" in namespace "downward-api-7156" to be "success or failure"
Feb 17 16:26:44.560: INFO: Pod "downwardapi-volume-e44809ec-6cec-4a07-a346-3c8ea88abef1": Phase="Pending", Reason="", readiness=false. Elapsed: 12.715953ms
Feb 17 16:26:46.571: INFO: Pod "downwardapi-volume-e44809ec-6cec-4a07-a346-3c8ea88abef1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.02416821s
STEP: Saw pod success
Feb 17 16:26:46.572: INFO: Pod "downwardapi-volume-e44809ec-6cec-4a07-a346-3c8ea88abef1" satisfied condition "success or failure"
Feb 17 16:26:46.583: INFO: Trying to get logs from node 10.242.0.98 pod downwardapi-volume-e44809ec-6cec-4a07-a346-3c8ea88abef1 container client-container: <nil>
STEP: delete the pod
Feb 17 16:26:46.660: INFO: Waiting for pod downwardapi-volume-e44809ec-6cec-4a07-a346-3c8ea88abef1 to disappear
Feb 17 16:26:46.670: INFO: Pod downwardapi-volume-e44809ec-6cec-4a07-a346-3c8ea88abef1 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 16:26:46.670: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7156" for this suite.
Feb 17 16:26:52.738: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:26:53.167: INFO: namespace downward-api-7156 deletion completed in 6.477750059s

• [SLOW TEST:8.897 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 16:26:53.168: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-6447
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Feb 17 16:26:53.508: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Feb 17 16:26:53.556: INFO: Number of nodes with available pods: 0
Feb 17 16:26:53.556: INFO: Node 10.242.0.59 is running more than one daemon pod
Feb 17 16:26:54.586: INFO: Number of nodes with available pods: 0
Feb 17 16:26:54.586: INFO: Node 10.242.0.59 is running more than one daemon pod
Feb 17 16:26:55.587: INFO: Number of nodes with available pods: 2
Feb 17 16:26:55.587: INFO: Node 10.242.0.63 is running more than one daemon pod
Feb 17 16:26:56.586: INFO: Number of nodes with available pods: 3
Feb 17 16:26:56.586: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Feb 17 16:26:56.676: INFO: Wrong image for pod: daemon-set-9glp2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Feb 17 16:26:56.676: INFO: Wrong image for pod: daemon-set-rrhmd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Feb 17 16:26:56.676: INFO: Wrong image for pod: daemon-set-xfdll. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Feb 17 16:26:57.703: INFO: Wrong image for pod: daemon-set-9glp2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Feb 17 16:26:57.703: INFO: Wrong image for pod: daemon-set-rrhmd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Feb 17 16:26:57.703: INFO: Wrong image for pod: daemon-set-xfdll. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Feb 17 16:26:58.706: INFO: Wrong image for pod: daemon-set-9glp2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Feb 17 16:26:58.706: INFO: Wrong image for pod: daemon-set-rrhmd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Feb 17 16:26:58.706: INFO: Pod daemon-set-rrhmd is not available
Feb 17 16:26:58.706: INFO: Wrong image for pod: daemon-set-xfdll. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Feb 17 16:26:59.703: INFO: Pod daemon-set-87gvn is not available
Feb 17 16:26:59.703: INFO: Wrong image for pod: daemon-set-9glp2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Feb 17 16:26:59.703: INFO: Wrong image for pod: daemon-set-xfdll. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Feb 17 16:27:00.704: INFO: Pod daemon-set-87gvn is not available
Feb 17 16:27:00.704: INFO: Wrong image for pod: daemon-set-9glp2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Feb 17 16:27:00.704: INFO: Wrong image for pod: daemon-set-xfdll. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Feb 17 16:27:01.703: INFO: Pod daemon-set-87gvn is not available
Feb 17 16:27:01.703: INFO: Wrong image for pod: daemon-set-9glp2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Feb 17 16:27:01.703: INFO: Wrong image for pod: daemon-set-xfdll. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Feb 17 16:27:02.712: INFO: Pod daemon-set-87gvn is not available
Feb 17 16:27:02.712: INFO: Wrong image for pod: daemon-set-9glp2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Feb 17 16:27:02.712: INFO: Wrong image for pod: daemon-set-xfdll. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Feb 17 16:27:03.703: INFO: Wrong image for pod: daemon-set-9glp2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Feb 17 16:27:03.703: INFO: Wrong image for pod: daemon-set-xfdll. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Feb 17 16:27:04.703: INFO: Wrong image for pod: daemon-set-9glp2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Feb 17 16:27:04.703: INFO: Wrong image for pod: daemon-set-xfdll. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Feb 17 16:27:05.703: INFO: Wrong image for pod: daemon-set-9glp2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Feb 17 16:27:05.703: INFO: Pod daemon-set-9glp2 is not available
Feb 17 16:27:05.703: INFO: Wrong image for pod: daemon-set-xfdll. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Feb 17 16:27:06.710: INFO: Wrong image for pod: daemon-set-9glp2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Feb 17 16:27:06.710: INFO: Pod daemon-set-9glp2 is not available
Feb 17 16:27:06.710: INFO: Wrong image for pod: daemon-set-xfdll. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Feb 17 16:27:07.704: INFO: Pod daemon-set-2dn99 is not available
Feb 17 16:27:07.704: INFO: Wrong image for pod: daemon-set-xfdll. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Feb 17 16:27:08.703: INFO: Pod daemon-set-2dn99 is not available
Feb 17 16:27:08.703: INFO: Wrong image for pod: daemon-set-xfdll. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Feb 17 16:27:09.704: INFO: Pod daemon-set-2dn99 is not available
Feb 17 16:27:09.704: INFO: Wrong image for pod: daemon-set-xfdll. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Feb 17 16:27:10.712: INFO: Pod daemon-set-2dn99 is not available
Feb 17 16:27:10.712: INFO: Wrong image for pod: daemon-set-xfdll. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Feb 17 16:27:11.703: INFO: Wrong image for pod: daemon-set-xfdll. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Feb 17 16:27:11.703: INFO: Pod daemon-set-xfdll is not available
Feb 17 16:27:12.704: INFO: Wrong image for pod: daemon-set-xfdll. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Feb 17 16:27:12.704: INFO: Pod daemon-set-xfdll is not available
Feb 17 16:27:13.703: INFO: Wrong image for pod: daemon-set-xfdll. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Feb 17 16:27:13.703: INFO: Pod daemon-set-xfdll is not available
Feb 17 16:27:14.704: INFO: Wrong image for pod: daemon-set-xfdll. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Feb 17 16:27:14.704: INFO: Pod daemon-set-xfdll is not available
Feb 17 16:27:15.707: INFO: Wrong image for pod: daemon-set-xfdll. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Feb 17 16:27:15.707: INFO: Pod daemon-set-xfdll is not available
Feb 17 16:27:16.703: INFO: Wrong image for pod: daemon-set-xfdll. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Feb 17 16:27:16.703: INFO: Pod daemon-set-xfdll is not available
Feb 17 16:27:17.704: INFO: Wrong image for pod: daemon-set-xfdll. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Feb 17 16:27:17.704: INFO: Pod daemon-set-xfdll is not available
Feb 17 16:27:18.704: INFO: Wrong image for pod: daemon-set-xfdll. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Feb 17 16:27:18.704: INFO: Pod daemon-set-xfdll is not available
Feb 17 16:27:19.706: INFO: Pod daemon-set-wqqf6 is not available
STEP: Check that daemon pods are still running on every node of the cluster.
Feb 17 16:27:19.755: INFO: Number of nodes with available pods: 2
Feb 17 16:27:19.755: INFO: Node 10.242.0.98 is running more than one daemon pod
Feb 17 16:27:20.790: INFO: Number of nodes with available pods: 3
Feb 17 16:27:20.790: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-6447, will wait for the garbage collector to delete the pods
Feb 17 16:27:20.940: INFO: Deleting DaemonSet.extensions daemon-set took: 25.999597ms
Feb 17 16:27:21.140: INFO: Terminating DaemonSet.extensions daemon-set pods took: 200.243742ms
Feb 17 16:27:28.951: INFO: Number of nodes with available pods: 0
Feb 17 16:27:28.951: INFO: Number of running nodes: 0, number of available pods: 0
Feb 17 16:27:28.967: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-6447/daemonsets","resourceVersion":"21701"},"items":null}

Feb 17 16:27:28.977: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-6447/pods","resourceVersion":"21701"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 16:27:29.037: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-6447" for this suite.
Feb 17 16:27:37.106: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:27:37.505: INFO: namespace daemonsets-6447 deletion completed in 8.449388979s

• [SLOW TEST:44.337 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 16:27:37.505: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-1719
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating service multi-endpoint-test in namespace services-1719
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-1719 to expose endpoints map[]
Feb 17 16:27:37.803: INFO: successfully validated that service multi-endpoint-test in namespace services-1719 exposes endpoints map[] (12.294192ms elapsed)
STEP: Creating pod pod1 in namespace services-1719
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-1719 to expose endpoints map[pod1:[100]]
Feb 17 16:27:39.899: INFO: successfully validated that service multi-endpoint-test in namespace services-1719 exposes endpoints map[pod1:[100]] (2.075346818s elapsed)
STEP: Creating pod pod2 in namespace services-1719
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-1719 to expose endpoints map[pod1:[100] pod2:[101]]
Feb 17 16:27:42.030: INFO: successfully validated that service multi-endpoint-test in namespace services-1719 exposes endpoints map[pod1:[100] pod2:[101]] (2.117566289s elapsed)
STEP: Deleting pod pod1 in namespace services-1719
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-1719 to expose endpoints map[pod2:[101]]
Feb 17 16:27:42.078: INFO: successfully validated that service multi-endpoint-test in namespace services-1719 exposes endpoints map[pod2:[101]] (28.248157ms elapsed)
STEP: Deleting pod pod2 in namespace services-1719
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-1719 to expose endpoints map[]
Feb 17 16:27:42.114: INFO: successfully validated that service multi-endpoint-test in namespace services-1719 exposes endpoints map[] (13.885918ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 16:27:42.185: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-1719" for this suite.
Feb 17 16:28:06.253: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:28:06.685: INFO: namespace services-1719 deletion completed in 24.480840439s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:92

• [SLOW TEST:29.180 seconds]
[sig-network] Services
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 16:28:06.687: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-151
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-configmap-hcpm
STEP: Creating a pod to test atomic-volume-subpath
Feb 17 16:28:06.998: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-hcpm" in namespace "subpath-151" to be "success or failure"
Feb 17 16:28:07.010: INFO: Pod "pod-subpath-test-configmap-hcpm": Phase="Pending", Reason="", readiness=false. Elapsed: 11.913929ms
Feb 17 16:28:09.022: INFO: Pod "pod-subpath-test-configmap-hcpm": Phase="Running", Reason="", readiness=true. Elapsed: 2.02370313s
Feb 17 16:28:11.033: INFO: Pod "pod-subpath-test-configmap-hcpm": Phase="Running", Reason="", readiness=true. Elapsed: 4.035166129s
Feb 17 16:28:13.045: INFO: Pod "pod-subpath-test-configmap-hcpm": Phase="Running", Reason="", readiness=true. Elapsed: 6.046843461s
Feb 17 16:28:15.059: INFO: Pod "pod-subpath-test-configmap-hcpm": Phase="Running", Reason="", readiness=true. Elapsed: 8.060777446s
Feb 17 16:28:17.071: INFO: Pod "pod-subpath-test-configmap-hcpm": Phase="Running", Reason="", readiness=true. Elapsed: 10.073378828s
Feb 17 16:28:19.089: INFO: Pod "pod-subpath-test-configmap-hcpm": Phase="Running", Reason="", readiness=true. Elapsed: 12.091308717s
Feb 17 16:28:21.101: INFO: Pod "pod-subpath-test-configmap-hcpm": Phase="Running", Reason="", readiness=true. Elapsed: 14.102851299s
Feb 17 16:28:23.113: INFO: Pod "pod-subpath-test-configmap-hcpm": Phase="Running", Reason="", readiness=true. Elapsed: 16.115499644s
Feb 17 16:28:25.125: INFO: Pod "pod-subpath-test-configmap-hcpm": Phase="Running", Reason="", readiness=true. Elapsed: 18.127303804s
Feb 17 16:28:27.138: INFO: Pod "pod-subpath-test-configmap-hcpm": Phase="Running", Reason="", readiness=true. Elapsed: 20.14044126s
Feb 17 16:28:29.157: INFO: Pod "pod-subpath-test-configmap-hcpm": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.159536419s
STEP: Saw pod success
Feb 17 16:28:29.158: INFO: Pod "pod-subpath-test-configmap-hcpm" satisfied condition "success or failure"
Feb 17 16:28:29.170: INFO: Trying to get logs from node 10.242.0.59 pod pod-subpath-test-configmap-hcpm container test-container-subpath-configmap-hcpm: <nil>
STEP: delete the pod
Feb 17 16:28:29.242: INFO: Waiting for pod pod-subpath-test-configmap-hcpm to disappear
Feb 17 16:28:29.253: INFO: Pod pod-subpath-test-configmap-hcpm no longer exists
STEP: Deleting pod pod-subpath-test-configmap-hcpm
Feb 17 16:28:29.253: INFO: Deleting pod "pod-subpath-test-configmap-hcpm" in namespace "subpath-151"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 16:28:29.264: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-151" for this suite.
Feb 17 16:28:35.332: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:28:35.720: INFO: namespace subpath-151 deletion completed in 6.438328558s

• [SLOW TEST:29.033 seconds]
[sig-storage] Subpath
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
    /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-api-machinery] Secrets 
  should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 16:28:35.720: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-6469
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name secret-emptykey-test-6a9d7cb4-86a2-41ff-9ec5-cb7e2da035e6
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 16:28:35.989: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6469" for this suite.
Feb 17 16:28:42.058: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:28:42.474: INFO: namespace secrets-6469 deletion completed in 6.470240917s

• [SLOW TEST:6.754 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 16:28:42.476: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-5555
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0666 on node default medium
Feb 17 16:28:42.758: INFO: Waiting up to 5m0s for pod "pod-22424064-b3ed-4a49-8440-6ee1a90dc867" in namespace "emptydir-5555" to be "success or failure"
Feb 17 16:28:42.770: INFO: Pod "pod-22424064-b3ed-4a49-8440-6ee1a90dc867": Phase="Pending", Reason="", readiness=false. Elapsed: 11.70135ms
Feb 17 16:28:44.781: INFO: Pod "pod-22424064-b3ed-4a49-8440-6ee1a90dc867": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022616368s
Feb 17 16:28:46.793: INFO: Pod "pod-22424064-b3ed-4a49-8440-6ee1a90dc867": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.034692368s
STEP: Saw pod success
Feb 17 16:28:46.793: INFO: Pod "pod-22424064-b3ed-4a49-8440-6ee1a90dc867" satisfied condition "success or failure"
Feb 17 16:28:46.807: INFO: Trying to get logs from node 10.242.0.98 pod pod-22424064-b3ed-4a49-8440-6ee1a90dc867 container test-container: <nil>
STEP: delete the pod
Feb 17 16:28:46.874: INFO: Waiting for pod pod-22424064-b3ed-4a49-8440-6ee1a90dc867 to disappear
Feb 17 16:28:46.885: INFO: Pod pod-22424064-b3ed-4a49-8440-6ee1a90dc867 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 16:28:46.885: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5555" for this suite.
Feb 17 16:28:52.959: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:28:53.598: INFO: namespace emptydir-5555 deletion completed in 6.69518523s

• [SLOW TEST:11.121 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 16:28:53.601: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-4368
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test override command
Feb 17 16:28:53.885: INFO: Waiting up to 5m0s for pod "client-containers-f61d396a-5caa-4759-86f2-d3d22a467568" in namespace "containers-4368" to be "success or failure"
Feb 17 16:28:53.896: INFO: Pod "client-containers-f61d396a-5caa-4759-86f2-d3d22a467568": Phase="Pending", Reason="", readiness=false. Elapsed: 10.531243ms
Feb 17 16:28:55.908: INFO: Pod "client-containers-f61d396a-5caa-4759-86f2-d3d22a467568": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022594559s
Feb 17 16:28:57.921: INFO: Pod "client-containers-f61d396a-5caa-4759-86f2-d3d22a467568": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.035318019s
STEP: Saw pod success
Feb 17 16:28:57.921: INFO: Pod "client-containers-f61d396a-5caa-4759-86f2-d3d22a467568" satisfied condition "success or failure"
Feb 17 16:28:57.932: INFO: Trying to get logs from node 10.242.0.59 pod client-containers-f61d396a-5caa-4759-86f2-d3d22a467568 container test-container: <nil>
STEP: delete the pod
Feb 17 16:28:58.001: INFO: Waiting for pod client-containers-f61d396a-5caa-4759-86f2-d3d22a467568 to disappear
Feb 17 16:28:58.013: INFO: Pod client-containers-f61d396a-5caa-4759-86f2-d3d22a467568 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 16:28:58.013: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-4368" for this suite.
Feb 17 16:29:04.100: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:29:04.511: INFO: namespace containers-4368 deletion completed in 6.46750968s

• [SLOW TEST:10.910 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 16:29:04.513: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-9781
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Feb 17 16:29:10.871: INFO: Waiting up to 5m0s for pod "client-envvars-0be8d8d0-8e8a-46a5-83c0-3c811f8cb5d0" in namespace "pods-9781" to be "success or failure"
Feb 17 16:29:10.887: INFO: Pod "client-envvars-0be8d8d0-8e8a-46a5-83c0-3c811f8cb5d0": Phase="Pending", Reason="", readiness=false. Elapsed: 15.44227ms
Feb 17 16:29:12.899: INFO: Pod "client-envvars-0be8d8d0-8e8a-46a5-83c0-3c811f8cb5d0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.027074091s
STEP: Saw pod success
Feb 17 16:29:12.899: INFO: Pod "client-envvars-0be8d8d0-8e8a-46a5-83c0-3c811f8cb5d0" satisfied condition "success or failure"
Feb 17 16:29:12.913: INFO: Trying to get logs from node 10.242.0.59 pod client-envvars-0be8d8d0-8e8a-46a5-83c0-3c811f8cb5d0 container env3cont: <nil>
STEP: delete the pod
Feb 17 16:29:12.982: INFO: Waiting for pod client-envvars-0be8d8d0-8e8a-46a5-83c0-3c811f8cb5d0 to disappear
Feb 17 16:29:12.995: INFO: Pod client-envvars-0be8d8d0-8e8a-46a5-83c0-3c811f8cb5d0 no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 16:29:12.995: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-9781" for this suite.
Feb 17 16:30:01.066: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:30:01.492: INFO: namespace pods-9781 deletion completed in 48.47781875s

• [SLOW TEST:56.979 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 16:30:01.492: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-4643
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-secret-cnkc
STEP: Creating a pod to test atomic-volume-subpath
Feb 17 16:30:01.799: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-cnkc" in namespace "subpath-4643" to be "success or failure"
Feb 17 16:30:01.814: INFO: Pod "pod-subpath-test-secret-cnkc": Phase="Pending", Reason="", readiness=false. Elapsed: 14.716428ms
Feb 17 16:30:03.825: INFO: Pod "pod-subpath-test-secret-cnkc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025909781s
Feb 17 16:30:05.838: INFO: Pod "pod-subpath-test-secret-cnkc": Phase="Running", Reason="", readiness=true. Elapsed: 4.038031395s
Feb 17 16:30:07.849: INFO: Pod "pod-subpath-test-secret-cnkc": Phase="Running", Reason="", readiness=true. Elapsed: 6.049699963s
Feb 17 16:30:09.862: INFO: Pod "pod-subpath-test-secret-cnkc": Phase="Running", Reason="", readiness=true. Elapsed: 8.062199789s
Feb 17 16:30:11.873: INFO: Pod "pod-subpath-test-secret-cnkc": Phase="Running", Reason="", readiness=true. Elapsed: 10.073381667s
Feb 17 16:30:13.884: INFO: Pod "pod-subpath-test-secret-cnkc": Phase="Running", Reason="", readiness=true. Elapsed: 12.084422263s
Feb 17 16:30:15.898: INFO: Pod "pod-subpath-test-secret-cnkc": Phase="Running", Reason="", readiness=true. Elapsed: 14.098057879s
Feb 17 16:30:17.909: INFO: Pod "pod-subpath-test-secret-cnkc": Phase="Running", Reason="", readiness=true. Elapsed: 16.10986931s
Feb 17 16:30:19.922: INFO: Pod "pod-subpath-test-secret-cnkc": Phase="Running", Reason="", readiness=true. Elapsed: 18.122267314s
Feb 17 16:30:21.939: INFO: Pod "pod-subpath-test-secret-cnkc": Phase="Running", Reason="", readiness=true. Elapsed: 20.1398932s
Feb 17 16:30:23.951: INFO: Pod "pod-subpath-test-secret-cnkc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.151058855s
STEP: Saw pod success
Feb 17 16:30:23.951: INFO: Pod "pod-subpath-test-secret-cnkc" satisfied condition "success or failure"
Feb 17 16:30:23.964: INFO: Trying to get logs from node 10.242.0.98 pod pod-subpath-test-secret-cnkc container test-container-subpath-secret-cnkc: <nil>
STEP: delete the pod
Feb 17 16:30:24.059: INFO: Waiting for pod pod-subpath-test-secret-cnkc to disappear
Feb 17 16:30:24.071: INFO: Pod pod-subpath-test-secret-cnkc no longer exists
STEP: Deleting pod pod-subpath-test-secret-cnkc
Feb 17 16:30:24.071: INFO: Deleting pod "pod-subpath-test-secret-cnkc" in namespace "subpath-4643"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 16:30:24.082: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-4643" for this suite.
Feb 17 16:30:30.158: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:30:30.555: INFO: namespace subpath-4643 deletion completed in 6.453408872s

• [SLOW TEST:29.063 seconds]
[sig-storage] Subpath
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with secret pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 16:30:30.555: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-9354
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Feb 17 16:30:30.846: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e1c7d9f3-8383-45fe-8a5b-7bab844eb82c" in namespace "downward-api-9354" to be "success or failure"
Feb 17 16:30:30.856: INFO: Pod "downwardapi-volume-e1c7d9f3-8383-45fe-8a5b-7bab844eb82c": Phase="Pending", Reason="", readiness=false. Elapsed: 10.546452ms
Feb 17 16:30:32.868: INFO: Pod "downwardapi-volume-e1c7d9f3-8383-45fe-8a5b-7bab844eb82c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.022210769s
STEP: Saw pod success
Feb 17 16:30:32.868: INFO: Pod "downwardapi-volume-e1c7d9f3-8383-45fe-8a5b-7bab844eb82c" satisfied condition "success or failure"
Feb 17 16:30:32.884: INFO: Trying to get logs from node 10.242.0.59 pod downwardapi-volume-e1c7d9f3-8383-45fe-8a5b-7bab844eb82c container client-container: <nil>
STEP: delete the pod
Feb 17 16:30:32.982: INFO: Waiting for pod downwardapi-volume-e1c7d9f3-8383-45fe-8a5b-7bab844eb82c to disappear
Feb 17 16:30:32.994: INFO: Pod downwardapi-volume-e1c7d9f3-8383-45fe-8a5b-7bab844eb82c no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 16:30:32.994: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9354" for this suite.
Feb 17 16:30:39.068: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:30:39.485: INFO: namespace downward-api-9354 deletion completed in 6.47001767s

• [SLOW TEST:8.929 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 16:30:39.485: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-2222
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap configmap-2222/configmap-test-0c025f78-18a8-405a-bb1a-820b944c7006
STEP: Creating a pod to test consume configMaps
Feb 17 16:30:39.778: INFO: Waiting up to 5m0s for pod "pod-configmaps-f979e85a-804b-4337-bdfa-6f6f84e82360" in namespace "configmap-2222" to be "success or failure"
Feb 17 16:30:39.789: INFO: Pod "pod-configmaps-f979e85a-804b-4337-bdfa-6f6f84e82360": Phase="Pending", Reason="", readiness=false. Elapsed: 10.660791ms
Feb 17 16:30:41.799: INFO: Pod "pod-configmaps-f979e85a-804b-4337-bdfa-6f6f84e82360": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021562441s
STEP: Saw pod success
Feb 17 16:30:41.800: INFO: Pod "pod-configmaps-f979e85a-804b-4337-bdfa-6f6f84e82360" satisfied condition "success or failure"
Feb 17 16:30:41.812: INFO: Trying to get logs from node 10.242.0.59 pod pod-configmaps-f979e85a-804b-4337-bdfa-6f6f84e82360 container env-test: <nil>
STEP: delete the pod
Feb 17 16:30:41.875: INFO: Waiting for pod pod-configmaps-f979e85a-804b-4337-bdfa-6f6f84e82360 to disappear
Feb 17 16:30:41.886: INFO: Pod pod-configmaps-f979e85a-804b-4337-bdfa-6f6f84e82360 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 16:30:41.886: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2222" for this suite.
Feb 17 16:30:47.954: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:30:48.365: INFO: namespace configmap-2222 deletion completed in 6.461676478s

• [SLOW TEST:8.880 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 16:30:48.366: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-2369
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1516
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb 17 16:30:48.617: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-079603707 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=kubectl-2369'
Feb 17 16:30:49.025: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Feb 17 16:30:49.025: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
Feb 17 16:30:49.042: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 0 spec.replicas 1 status.replicas 0
Feb 17 16:30:49.054: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 1 spec.replicas 1 status.replicas 0
STEP: rolling-update to same image controller
Feb 17 16:30:49.070: INFO: scanned /root for discovery docs: <nil>
Feb 17 16:30:49.070: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-079603707 rolling-update e2e-test-nginx-rc --update-period=1s --image=docker.io/library/nginx:1.14-alpine --image-pull-policy=IfNotPresent --namespace=kubectl-2369'
Feb 17 16:31:05.288: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Feb 17 16:31:05.288: INFO: stdout: "Created e2e-test-nginx-rc-fcae44c348889e22daebc5019deb03b7\nScaling up e2e-test-nginx-rc-fcae44c348889e22daebc5019deb03b7 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-fcae44c348889e22daebc5019deb03b7 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-fcae44c348889e22daebc5019deb03b7 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
Feb 17 16:31:05.288: INFO: stdout: "Created e2e-test-nginx-rc-fcae44c348889e22daebc5019deb03b7\nScaling up e2e-test-nginx-rc-fcae44c348889e22daebc5019deb03b7 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-fcae44c348889e22daebc5019deb03b7 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-fcae44c348889e22daebc5019deb03b7 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
Feb 17 16:31:05.288: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-079603707 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=kubectl-2369'
Feb 17 16:31:05.424: INFO: stderr: ""
Feb 17 16:31:05.424: INFO: stdout: "e2e-test-nginx-rc-fcae44c348889e22daebc5019deb03b7-zlnhf "
Feb 17 16:31:05.424: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-079603707 get pods e2e-test-nginx-rc-fcae44c348889e22daebc5019deb03b7-zlnhf -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2369'
Feb 17 16:31:05.553: INFO: stderr: ""
Feb 17 16:31:05.553: INFO: stdout: "true"
Feb 17 16:31:05.553: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-079603707 get pods e2e-test-nginx-rc-fcae44c348889e22daebc5019deb03b7-zlnhf -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-2369'
Feb 17 16:31:05.670: INFO: stderr: ""
Feb 17 16:31:05.670: INFO: stdout: "docker.io/library/nginx:1.14-alpine"
Feb 17 16:31:05.670: INFO: e2e-test-nginx-rc-fcae44c348889e22daebc5019deb03b7-zlnhf is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1522
Feb 17 16:31:05.670: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-079603707 delete rc e2e-test-nginx-rc --namespace=kubectl-2369'
Feb 17 16:31:05.828: INFO: stderr: ""
Feb 17 16:31:05.828: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 16:31:05.828: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2369" for this suite.
Feb 17 16:31:29.897: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:31:30.299: INFO: namespace kubectl-2369 deletion completed in 24.449740945s

• [SLOW TEST:41.933 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 16:31:30.299: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-1614
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Performing setup for networking test in namespace pod-network-test-1614
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Feb 17 16:31:30.551: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Feb 17 16:31:54.813: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 172.30.197.142 8081 | grep -v '^\s*$'] Namespace:pod-network-test-1614 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 17 16:31:54.813: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
Feb 17 16:31:56.086: INFO: Found all expected endpoints: [netserver-0]
Feb 17 16:31:56.098: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 172.30.112.93 8081 | grep -v '^\s*$'] Namespace:pod-network-test-1614 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 17 16:31:56.098: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
Feb 17 16:31:57.394: INFO: Found all expected endpoints: [netserver-1]
Feb 17 16:31:57.405: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 172.30.94.29 8081 | grep -v '^\s*$'] Namespace:pod-network-test-1614 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 17 16:31:57.405: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
Feb 17 16:31:58.680: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 16:31:58.680: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-1614" for this suite.
Feb 17 16:32:22.753: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:32:23.150: INFO: namespace pod-network-test-1614 deletion completed in 24.451829628s

• [SLOW TEST:52.851 seconds]
[sig-network] Networking
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 16:32:23.150: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-223
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 16:32:25.509: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-223" for this suite.
Feb 17 16:33:13.579: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:33:13.988: INFO: namespace kubelet-test-223 deletion completed in 48.45914479s

• [SLOW TEST:50.838 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when scheduling a read only busybox container
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:187
    should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 16:33:13.989: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-4990
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Feb 17 16:33:34.305: INFO: Container started at 2020-02-17 16:33:17 +0000 UTC, pod became ready at 2020-02-17 16:33:33 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 16:33:34.305: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-4990" for this suite.
Feb 17 16:33:58.371: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:33:58.794: INFO: namespace container-probe-4990 deletion completed in 24.471420055s

• [SLOW TEST:44.805 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 16:33:58.796: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8293
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Feb 17 16:33:59.070: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9535ae19-1551-461d-bdf6-4a9c808be063" in namespace "projected-8293" to be "success or failure"
Feb 17 16:33:59.084: INFO: Pod "downwardapi-volume-9535ae19-1551-461d-bdf6-4a9c808be063": Phase="Pending", Reason="", readiness=false. Elapsed: 13.12676ms
Feb 17 16:34:01.096: INFO: Pod "downwardapi-volume-9535ae19-1551-461d-bdf6-4a9c808be063": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025309406s
Feb 17 16:34:03.116: INFO: Pod "downwardapi-volume-9535ae19-1551-461d-bdf6-4a9c808be063": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.044931682s
STEP: Saw pod success
Feb 17 16:34:03.116: INFO: Pod "downwardapi-volume-9535ae19-1551-461d-bdf6-4a9c808be063" satisfied condition "success or failure"
Feb 17 16:34:03.129: INFO: Trying to get logs from node 10.242.0.98 pod downwardapi-volume-9535ae19-1551-461d-bdf6-4a9c808be063 container client-container: <nil>
STEP: delete the pod
Feb 17 16:34:03.198: INFO: Waiting for pod downwardapi-volume-9535ae19-1551-461d-bdf6-4a9c808be063 to disappear
Feb 17 16:34:03.209: INFO: Pod downwardapi-volume-9535ae19-1551-461d-bdf6-4a9c808be063 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 16:34:03.209: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8293" for this suite.
Feb 17 16:34:09.277: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:34:09.690: INFO: namespace projected-8293 deletion completed in 6.462315755s

• [SLOW TEST:10.894 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 16:34:09.691: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-3088
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:273
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a replication controller
Feb 17 16:34:09.943: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-079603707 create -f - --namespace=kubectl-3088'
Feb 17 16:34:10.364: INFO: stderr: ""
Feb 17 16:34:10.364: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb 17 16:34:10.364: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-079603707 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-3088'
Feb 17 16:34:10.497: INFO: stderr: ""
Feb 17 16:34:10.497: INFO: stdout: "update-demo-nautilus-7sjnm update-demo-nautilus-zqjxz "
Feb 17 16:34:10.497: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-079603707 get pods update-demo-nautilus-7sjnm -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3088'
Feb 17 16:34:10.628: INFO: stderr: ""
Feb 17 16:34:10.629: INFO: stdout: ""
Feb 17 16:34:10.629: INFO: update-demo-nautilus-7sjnm is created but not running
Feb 17 16:34:15.629: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-079603707 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-3088'
Feb 17 16:34:15.778: INFO: stderr: ""
Feb 17 16:34:15.778: INFO: stdout: "update-demo-nautilus-7sjnm update-demo-nautilus-zqjxz "
Feb 17 16:34:15.778: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-079603707 get pods update-demo-nautilus-7sjnm -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3088'
Feb 17 16:34:15.910: INFO: stderr: ""
Feb 17 16:34:15.910: INFO: stdout: "true"
Feb 17 16:34:15.910: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-079603707 get pods update-demo-nautilus-7sjnm -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-3088'
Feb 17 16:34:16.050: INFO: stderr: ""
Feb 17 16:34:16.050: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 17 16:34:16.050: INFO: validating pod update-demo-nautilus-7sjnm
Feb 17 16:34:16.079: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 17 16:34:16.079: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 17 16:34:16.079: INFO: update-demo-nautilus-7sjnm is verified up and running
Feb 17 16:34:16.079: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-079603707 get pods update-demo-nautilus-zqjxz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3088'
Feb 17 16:34:16.200: INFO: stderr: ""
Feb 17 16:34:16.200: INFO: stdout: "true"
Feb 17 16:34:16.200: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-079603707 get pods update-demo-nautilus-zqjxz -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-3088'
Feb 17 16:34:16.318: INFO: stderr: ""
Feb 17 16:34:16.318: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 17 16:34:16.318: INFO: validating pod update-demo-nautilus-zqjxz
Feb 17 16:34:16.349: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 17 16:34:16.349: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 17 16:34:16.349: INFO: update-demo-nautilus-zqjxz is verified up and running
STEP: scaling down the replication controller
Feb 17 16:34:16.351: INFO: scanned /root for discovery docs: <nil>
Feb 17 16:34:16.351: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-079603707 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=kubectl-3088'
Feb 17 16:34:17.535: INFO: stderr: ""
Feb 17 16:34:17.535: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb 17 16:34:17.535: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-079603707 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-3088'
Feb 17 16:34:17.680: INFO: stderr: ""
Feb 17 16:34:17.680: INFO: stdout: "update-demo-nautilus-7sjnm update-demo-nautilus-zqjxz "
STEP: Replicas for name=update-demo: expected=1 actual=2
Feb 17 16:34:22.680: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-079603707 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-3088'
Feb 17 16:34:22.817: INFO: stderr: ""
Feb 17 16:34:22.817: INFO: stdout: "update-demo-nautilus-7sjnm update-demo-nautilus-zqjxz "
STEP: Replicas for name=update-demo: expected=1 actual=2
Feb 17 16:34:27.818: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-079603707 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-3088'
Feb 17 16:34:27.933: INFO: stderr: ""
Feb 17 16:34:27.933: INFO: stdout: "update-demo-nautilus-zqjxz "
Feb 17 16:34:27.933: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-079603707 get pods update-demo-nautilus-zqjxz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3088'
Feb 17 16:34:28.120: INFO: stderr: ""
Feb 17 16:34:28.120: INFO: stdout: "true"
Feb 17 16:34:28.120: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-079603707 get pods update-demo-nautilus-zqjxz -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-3088'
Feb 17 16:34:28.264: INFO: stderr: ""
Feb 17 16:34:28.264: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 17 16:34:28.264: INFO: validating pod update-demo-nautilus-zqjxz
Feb 17 16:34:28.286: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 17 16:34:28.286: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 17 16:34:28.286: INFO: update-demo-nautilus-zqjxz is verified up and running
STEP: scaling up the replication controller
Feb 17 16:34:28.288: INFO: scanned /root for discovery docs: <nil>
Feb 17 16:34:28.288: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-079603707 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=kubectl-3088'
Feb 17 16:34:29.489: INFO: stderr: ""
Feb 17 16:34:29.489: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb 17 16:34:29.489: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-079603707 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-3088'
Feb 17 16:34:29.635: INFO: stderr: ""
Feb 17 16:34:29.635: INFO: stdout: "update-demo-nautilus-56v98 update-demo-nautilus-zqjxz "
Feb 17 16:34:29.635: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-079603707 get pods update-demo-nautilus-56v98 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3088'
Feb 17 16:34:29.774: INFO: stderr: ""
Feb 17 16:34:29.774: INFO: stdout: ""
Feb 17 16:34:29.774: INFO: update-demo-nautilus-56v98 is created but not running
Feb 17 16:34:34.774: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-079603707 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-3088'
Feb 17 16:34:34.897: INFO: stderr: ""
Feb 17 16:34:34.897: INFO: stdout: "update-demo-nautilus-56v98 update-demo-nautilus-zqjxz "
Feb 17 16:34:34.897: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-079603707 get pods update-demo-nautilus-56v98 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3088'
Feb 17 16:34:35.030: INFO: stderr: ""
Feb 17 16:34:35.030: INFO: stdout: "true"
Feb 17 16:34:35.030: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-079603707 get pods update-demo-nautilus-56v98 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-3088'
Feb 17 16:34:35.153: INFO: stderr: ""
Feb 17 16:34:35.153: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 17 16:34:35.153: INFO: validating pod update-demo-nautilus-56v98
Feb 17 16:34:35.182: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 17 16:34:35.182: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 17 16:34:35.182: INFO: update-demo-nautilus-56v98 is verified up and running
Feb 17 16:34:35.182: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-079603707 get pods update-demo-nautilus-zqjxz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3088'
Feb 17 16:34:35.297: INFO: stderr: ""
Feb 17 16:34:35.297: INFO: stdout: "true"
Feb 17 16:34:35.297: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-079603707 get pods update-demo-nautilus-zqjxz -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-3088'
Feb 17 16:34:35.424: INFO: stderr: ""
Feb 17 16:34:35.424: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 17 16:34:35.424: INFO: validating pod update-demo-nautilus-zqjxz
Feb 17 16:34:35.445: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 17 16:34:35.445: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 17 16:34:35.445: INFO: update-demo-nautilus-zqjxz is verified up and running
STEP: using delete to clean up resources
Feb 17 16:34:35.445: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-079603707 delete --grace-period=0 --force -f - --namespace=kubectl-3088'
Feb 17 16:34:35.642: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 17 16:34:35.642: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Feb 17 16:34:35.643: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-079603707 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-3088'
Feb 17 16:34:35.782: INFO: stderr: "No resources found.\n"
Feb 17 16:34:35.783: INFO: stdout: ""
Feb 17 16:34:35.783: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-079603707 get pods -l name=update-demo --namespace=kubectl-3088 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Feb 17 16:34:35.945: INFO: stderr: ""
Feb 17 16:34:35.945: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 16:34:35.945: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3088" for this suite.
Feb 17 16:35:00.012: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:35:00.423: INFO: namespace kubectl-3088 deletion completed in 24.458926177s

• [SLOW TEST:50.732 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 16:35:00.423: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-9259
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Feb 17 16:35:00.702: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-9259,SelfLink:/api/v1/namespaces/watch-9259/configmaps/e2e-watch-test-configmap-a,UID:1fa6e111-d3f6-4d41-938c-40d8ccfb62e2,ResourceVersion:23317,Generation:0,CreationTimestamp:2020-02-17 16:35:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Feb 17 16:35:00.703: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-9259,SelfLink:/api/v1/namespaces/watch-9259/configmaps/e2e-watch-test-configmap-a,UID:1fa6e111-d3f6-4d41-938c-40d8ccfb62e2,ResourceVersion:23317,Generation:0,CreationTimestamp:2020-02-17 16:35:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Feb 17 16:35:10.732: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-9259,SelfLink:/api/v1/namespaces/watch-9259/configmaps/e2e-watch-test-configmap-a,UID:1fa6e111-d3f6-4d41-938c-40d8ccfb62e2,ResourceVersion:23334,Generation:0,CreationTimestamp:2020-02-17 16:35:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Feb 17 16:35:10.732: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-9259,SelfLink:/api/v1/namespaces/watch-9259/configmaps/e2e-watch-test-configmap-a,UID:1fa6e111-d3f6-4d41-938c-40d8ccfb62e2,ResourceVersion:23334,Generation:0,CreationTimestamp:2020-02-17 16:35:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Feb 17 16:35:20.759: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-9259,SelfLink:/api/v1/namespaces/watch-9259/configmaps/e2e-watch-test-configmap-a,UID:1fa6e111-d3f6-4d41-938c-40d8ccfb62e2,ResourceVersion:23351,Generation:0,CreationTimestamp:2020-02-17 16:35:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Feb 17 16:35:20.759: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-9259,SelfLink:/api/v1/namespaces/watch-9259/configmaps/e2e-watch-test-configmap-a,UID:1fa6e111-d3f6-4d41-938c-40d8ccfb62e2,ResourceVersion:23351,Generation:0,CreationTimestamp:2020-02-17 16:35:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Feb 17 16:35:30.788: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-9259,SelfLink:/api/v1/namespaces/watch-9259/configmaps/e2e-watch-test-configmap-a,UID:1fa6e111-d3f6-4d41-938c-40d8ccfb62e2,ResourceVersion:23368,Generation:0,CreationTimestamp:2020-02-17 16:35:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Feb 17 16:35:30.788: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-9259,SelfLink:/api/v1/namespaces/watch-9259/configmaps/e2e-watch-test-configmap-a,UID:1fa6e111-d3f6-4d41-938c-40d8ccfb62e2,ResourceVersion:23368,Generation:0,CreationTimestamp:2020-02-17 16:35:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Feb 17 16:35:40.809: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-9259,SelfLink:/api/v1/namespaces/watch-9259/configmaps/e2e-watch-test-configmap-b,UID:e180e035-cbf6-4f19-b4fc-552a6bb81cf2,ResourceVersion:23385,Generation:0,CreationTimestamp:2020-02-17 16:35:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Feb 17 16:35:40.809: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-9259,SelfLink:/api/v1/namespaces/watch-9259/configmaps/e2e-watch-test-configmap-b,UID:e180e035-cbf6-4f19-b4fc-552a6bb81cf2,ResourceVersion:23385,Generation:0,CreationTimestamp:2020-02-17 16:35:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Feb 17 16:35:50.836: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-9259,SelfLink:/api/v1/namespaces/watch-9259/configmaps/e2e-watch-test-configmap-b,UID:e180e035-cbf6-4f19-b4fc-552a6bb81cf2,ResourceVersion:23404,Generation:0,CreationTimestamp:2020-02-17 16:35:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Feb 17 16:35:50.836: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-9259,SelfLink:/api/v1/namespaces/watch-9259/configmaps/e2e-watch-test-configmap-b,UID:e180e035-cbf6-4f19-b4fc-552a6bb81cf2,ResourceVersion:23404,Generation:0,CreationTimestamp:2020-02-17 16:35:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 16:36:00.836: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-9259" for this suite.
Feb 17 16:36:06.903: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:36:07.323: INFO: namespace watch-9259 deletion completed in 6.468024696s

• [SLOW TEST:66.900 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 16:36:07.325: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-1387
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Feb 17 16:36:07.585: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-079603707 create -f - --namespace=kubectl-1387'
Feb 17 16:36:07.858: INFO: stderr: ""
Feb 17 16:36:07.858: INFO: stdout: "replicationcontroller/redis-master created\n"
Feb 17 16:36:07.858: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-079603707 create -f - --namespace=kubectl-1387'
Feb 17 16:36:08.244: INFO: stderr: ""
Feb 17 16:36:08.244: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Feb 17 16:36:09.256: INFO: Selector matched 1 pods for map[app:redis]
Feb 17 16:36:09.256: INFO: Found 0 / 1
Feb 17 16:36:10.256: INFO: Selector matched 1 pods for map[app:redis]
Feb 17 16:36:10.256: INFO: Found 1 / 1
Feb 17 16:36:10.256: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Feb 17 16:36:10.270: INFO: Selector matched 1 pods for map[app:redis]
Feb 17 16:36:10.270: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Feb 17 16:36:10.270: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-079603707 describe pod redis-master-nc6ht --namespace=kubectl-1387'
Feb 17 16:36:10.437: INFO: stderr: ""
Feb 17 16:36:10.437: INFO: stdout: "Name:           redis-master-nc6ht\nNamespace:      kubectl-1387\nPriority:       0\nNode:           10.242.0.59/10.242.0.59\nStart Time:     Mon, 17 Feb 2020 16:36:07 +0000\nLabels:         app=redis\n                role=master\nAnnotations:    kubernetes.io/psp: e2e-test-privileged-psp\nStatus:         Running\nIP:             172.30.94.33\nControlled By:  ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   containerd://c5eb88e1f6f14cabbeb78605ddf7961755e6695abbbc7ad906831aeca506bb1a\n    Image:          gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Image ID:       gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Mon, 17 Feb 2020 16:36:09 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-zndkl (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-zndkl:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-zndkl\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 600s\n                 node.kubernetes.io/unreachable:NoExecute for 600s\nEvents:\n  Type    Reason     Age   From                  Message\n  ----    ------     ----  ----                  -------\n  Normal  Scheduled  3s    default-scheduler     Successfully assigned kubectl-1387/redis-master-nc6ht to 10.242.0.59\n  Normal  Pulled     2s    kubelet, 10.242.0.59  Container image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\" already present on machine\n  Normal  Created    2s    kubelet, 10.242.0.59  Created container redis-master\n  Normal  Started    1s    kubelet, 10.242.0.59  Started container redis-master\n"
Feb 17 16:36:10.437: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-079603707 describe rc redis-master --namespace=kubectl-1387'
Feb 17 16:36:10.642: INFO: stderr: ""
Feb 17 16:36:10.642: INFO: stdout: "Name:         redis-master\nNamespace:    kubectl-1387\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  3s    replication-controller  Created pod: redis-master-nc6ht\n"
Feb 17 16:36:10.642: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-079603707 describe service redis-master --namespace=kubectl-1387'
Feb 17 16:36:10.810: INFO: stderr: ""
Feb 17 16:36:10.810: INFO: stdout: "Name:              redis-master\nNamespace:         kubectl-1387\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                172.21.86.206\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         172.30.94.33:6379\nSession Affinity:  None\nEvents:            <none>\n"
Feb 17 16:36:10.830: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-079603707 describe node 10.242.0.59'
Feb 17 16:36:11.045: INFO: stderr: ""
Feb 17 16:36:11.045: INFO: stdout: "Name:               10.242.0.59\nRoles:              <none>\nLabels:             arch=amd64\n                    beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/instance-type=c2.2x4\n                    beta.kubernetes.io/os=linux\n                    failure-domain.beta.kubernetes.io/region=eu-gb\n                    failure-domain.beta.kubernetes.io/zone=eu-gb-1\n                    ibm-cloud.kubernetes.io/ha-worker=true\n                    ibm-cloud.kubernetes.io/iaas-provider=gc\n                    ibm-cloud.kubernetes.io/internal-ip=10.242.0.59\n                    ibm-cloud.kubernetes.io/machine-type=c2.2x4\n                    ibm-cloud.kubernetes.io/os=UBUNTU_18_64\n                    ibm-cloud.kubernetes.io/region=eu-gb\n                    ibm-cloud.kubernetes.io/sgx-enabled=false\n                    ibm-cloud.kubernetes.io/subnet-id=d2e52bfd-6922-446a-b229-898e2d9b39df\n                    ibm-cloud.kubernetes.io/worker-id=kube-bp5a1mjl0i8s7ceo0p0g-kubee2epvgl-default-000001c0\n                    ibm-cloud.kubernetes.io/worker-pool-id=bp5a1mjl0i8s7ceo0p0g-6055b01\n                    ibm-cloud.kubernetes.io/worker-pool-name=default\n                    ibm-cloud.kubernetes.io/worker-version=1.15.8_1530\n                    ibm-cloud.kubernetes.io/zone=eu-gb-1\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=10.242.0.59\n                    kubernetes.io/os=linux\nAnnotations:        csi.volume.kubernetes.io/nodeid: {\"vpc.block.csi.ibm.io\":\"kube-bp5a1mjl0i8s7ceo0p0g-kubee2epvgl-default-000001c0\"}\n                    node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Mon, 17 Feb 2020 14:46:00 +0000\nTaints:             <none>\nUnschedulable:      false\nConditions:\n  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----             ------  -----------------                 ------------------                ------                       -------\n  MemoryPressure   False   Mon, 17 Feb 2020 16:35:42 +0000   Mon, 17 Feb 2020 14:46:00 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure     False   Mon, 17 Feb 2020 16:35:42 +0000   Mon, 17 Feb 2020 14:46:00 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure      False   Mon, 17 Feb 2020 16:35:42 +0000   Mon, 17 Feb 2020 14:46:00 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready            True    Mon, 17 Feb 2020 16:35:42 +0000   Mon, 17 Feb 2020 14:46:10 +0000   KubeletReady                 kubelet is posting ready status. AppArmor enabled\nAddresses:\n  InternalIP:  10.242.0.59\n  ExternalIP:  10.242.0.59\n  Hostname:    10.242.0.59\nCapacity:\n attachable-volumes-csi-vpc.block.csi.ibm.io:  4\n cpu:                                          2\n ephemeral-storage:                            102821812Ki\n hugepages-1Gi:                                0\n hugepages-2Mi:                                0\n memory:                                       4033396Ki\n pods:                                         110\nAllocatable:\n attachable-volumes-csi-vpc.block.csi.ibm.io:  4\n cpu:                                          1920m\n ephemeral-storage:                            100025058636\n hugepages-1Gi:                                0\n hugepages-2Mi:                                0\n memory:                                       2923380Ki\n pods:                                         110\nSystem Info:\n Machine ID:                 61d03bfcaee045b78078c95fd6473f15\n System UUID:                A595BC95-A7A5-B2E7-528D-2AEC254A37E2\n Boot ID:                    fc278258-aa8b-4cef-87e7-2d686703f7d7\n Kernel Version:             4.15.0-76-generic\n OS Image:                   Ubuntu 18.04.4 LTS\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  containerd://1.2.11\n Kubelet Version:            v1.15.8+IKS\n Kube-Proxy Version:         v1.15.8+IKS\nProviderID:                  ibm://89064b69455a476583d12df4524b099b///bp5a1mjl0i8s7ceo0p0g/kube-bp5a1mjl0i8s7ceo0p0g-kubee2epvgl-default-000001c0\nNon-terminated Pods:         (7 in total)\n  Namespace                  Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                  ----                                                       ------------  ----------  ---------------  -------------  ---\n  kube-system                calico-node-nt7xm                                          250m (13%)    0 (0%)      80Mi (2%)        0 (0%)         110m\n  kube-system                coredns-c6797c986-cc2j9                                    100m (5%)     0 (0%)      70Mi (2%)        400Mi (14%)    100m\n  kube-system                ibm-master-proxy-static-10.242.0.59                        25m (1%)      300m (15%)  32M (1%)         512M (17%)     109m\n  kube-system                ibm-vpc-block-csi-node-t57kv                               0 (0%)        0 (0%)      0 (0%)           0 (0%)         110m\n  kube-system                public-crbp5a1mjl0i8s7ceo0p0g-alb1-9c9db77cc-652w8         10m (0%)      0 (0%)      100Mi (3%)       0 (0%)         120m\n  kubectl-1387               redis-master-nc6ht                                         0 (0%)        0 (0%)      0 (0%)           0 (0%)         4s\n  sonobuoy                   sonobuoy-systemd-logs-daemon-set-6f65da6b108e4900-wmp7s    0 (0%)        0 (0%)      0 (0%)           0 (0%)         21m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource                                     Requests       Limits\n  --------                                     --------       ------\n  cpu                                          385m (20%)     300m (15%)\n  memory                                       287250Ki (9%)  909600Ki (31%)\n  ephemeral-storage                            0 (0%)         0 (0%)\n  attachable-volumes-csi-vpc.block.csi.ibm.io  0              0\nEvents:                                        <none>\n"
Feb 17 16:36:11.045: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-079603707 describe namespace kubectl-1387'
Feb 17 16:36:11.224: INFO: stderr: ""
Feb 17 16:36:11.224: INFO: stdout: "Name:         kubectl-1387\nLabels:       e2e-framework=kubectl\n              e2e-run=ad72ae7d-ff88-4d2e-a1e4-61dfbb87c8e8\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 16:36:11.225: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1387" for this suite.
Feb 17 16:36:35.303: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:36:35.716: INFO: namespace kubectl-1387 deletion completed in 24.46937125s

• [SLOW TEST:28.391 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl describe
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 16:36:35.717: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-9030
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating replication controller my-hostname-basic-88c292dc-fb0e-4392-ac16-540de5decfe5
Feb 17 16:36:36.009: INFO: Pod name my-hostname-basic-88c292dc-fb0e-4392-ac16-540de5decfe5: Found 0 pods out of 1
Feb 17 16:36:41.020: INFO: Pod name my-hostname-basic-88c292dc-fb0e-4392-ac16-540de5decfe5: Found 1 pods out of 1
Feb 17 16:36:41.020: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-88c292dc-fb0e-4392-ac16-540de5decfe5" are running
Feb 17 16:36:41.031: INFO: Pod "my-hostname-basic-88c292dc-fb0e-4392-ac16-540de5decfe5-4m8cn" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-02-17 16:36:36 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-02-17 16:36:37 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-02-17 16:36:37 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-02-17 16:36:36 +0000 UTC Reason: Message:}])
Feb 17 16:36:41.031: INFO: Trying to dial the pod
Feb 17 16:36:46.084: INFO: Controller my-hostname-basic-88c292dc-fb0e-4392-ac16-540de5decfe5: Got expected result from replica 1 [my-hostname-basic-88c292dc-fb0e-4392-ac16-540de5decfe5-4m8cn]: "my-hostname-basic-88c292dc-fb0e-4392-ac16-540de5decfe5-4m8cn", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 16:36:46.084: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-9030" for this suite.
Feb 17 16:36:52.317: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:36:52.718: INFO: namespace replication-controller-9030 deletion completed in 6.457139996s

• [SLOW TEST:17.002 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 16:36:52.719: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-3014
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-map-4b126324-a6ce-45ee-95b2-6cc642af7f14
STEP: Creating a pod to test consume configMaps
Feb 17 16:36:53.018: INFO: Waiting up to 5m0s for pod "pod-configmaps-e996b67c-95c9-4502-9adf-7f5c2cb3b9d7" in namespace "configmap-3014" to be "success or failure"
Feb 17 16:36:53.029: INFO: Pod "pod-configmaps-e996b67c-95c9-4502-9adf-7f5c2cb3b9d7": Phase="Pending", Reason="", readiness=false. Elapsed: 10.814921ms
Feb 17 16:36:55.041: INFO: Pod "pod-configmaps-e996b67c-95c9-4502-9adf-7f5c2cb3b9d7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.02280705s
STEP: Saw pod success
Feb 17 16:36:55.041: INFO: Pod "pod-configmaps-e996b67c-95c9-4502-9adf-7f5c2cb3b9d7" satisfied condition "success or failure"
Feb 17 16:36:55.055: INFO: Trying to get logs from node 10.242.0.59 pod pod-configmaps-e996b67c-95c9-4502-9adf-7f5c2cb3b9d7 container configmap-volume-test: <nil>
STEP: delete the pod
Feb 17 16:36:55.130: INFO: Waiting for pod pod-configmaps-e996b67c-95c9-4502-9adf-7f5c2cb3b9d7 to disappear
Feb 17 16:36:55.141: INFO: Pod pod-configmaps-e996b67c-95c9-4502-9adf-7f5c2cb3b9d7 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 16:36:55.141: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3014" for this suite.
Feb 17 16:37:01.212: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:37:01.613: INFO: namespace configmap-3014 deletion completed in 6.450430604s

• [SLOW TEST:8.895 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 16:37:01.616: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-2592
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Feb 17 16:37:01.899: INFO: Waiting up to 5m0s for pod "downwardapi-volume-66389597-52e2-452d-9015-72a009315886" in namespace "downward-api-2592" to be "success or failure"
Feb 17 16:37:01.910: INFO: Pod "downwardapi-volume-66389597-52e2-452d-9015-72a009315886": Phase="Pending", Reason="", readiness=false. Elapsed: 11.183793ms
Feb 17 16:37:03.921: INFO: Pod "downwardapi-volume-66389597-52e2-452d-9015-72a009315886": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.022256159s
STEP: Saw pod success
Feb 17 16:37:03.921: INFO: Pod "downwardapi-volume-66389597-52e2-452d-9015-72a009315886" satisfied condition "success or failure"
Feb 17 16:37:03.941: INFO: Trying to get logs from node 10.242.0.98 pod downwardapi-volume-66389597-52e2-452d-9015-72a009315886 container client-container: <nil>
STEP: delete the pod
Feb 17 16:37:04.015: INFO: Waiting for pod downwardapi-volume-66389597-52e2-452d-9015-72a009315886 to disappear
Feb 17 16:37:04.025: INFO: Pod downwardapi-volume-66389597-52e2-452d-9015-72a009315886 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 16:37:04.025: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2592" for this suite.
Feb 17 16:37:10.225: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:37:10.624: INFO: namespace downward-api-2592 deletion completed in 6.574372943s

• [SLOW TEST:9.008 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 16:37:10.624: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-4117
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-67eb4a88-d2ee-42cf-9954-299a9a86c32f
STEP: Creating a pod to test consume secrets
Feb 17 16:37:10.926: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-c10128cd-1711-4c31-8846-b05ecc38be50" in namespace "projected-4117" to be "success or failure"
Feb 17 16:37:10.939: INFO: Pod "pod-projected-secrets-c10128cd-1711-4c31-8846-b05ecc38be50": Phase="Pending", Reason="", readiness=false. Elapsed: 13.03324ms
Feb 17 16:37:12.956: INFO: Pod "pod-projected-secrets-c10128cd-1711-4c31-8846-b05ecc38be50": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.029827875s
STEP: Saw pod success
Feb 17 16:37:12.956: INFO: Pod "pod-projected-secrets-c10128cd-1711-4c31-8846-b05ecc38be50" satisfied condition "success or failure"
Feb 17 16:37:12.967: INFO: Trying to get logs from node 10.242.0.59 pod pod-projected-secrets-c10128cd-1711-4c31-8846-b05ecc38be50 container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb 17 16:37:13.038: INFO: Waiting for pod pod-projected-secrets-c10128cd-1711-4c31-8846-b05ecc38be50 to disappear
Feb 17 16:37:13.049: INFO: Pod pod-projected-secrets-c10128cd-1711-4c31-8846-b05ecc38be50 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 16:37:13.049: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4117" for this suite.
Feb 17 16:37:19.123: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:37:19.567: INFO: namespace projected-4117 deletion completed in 6.497186086s

• [SLOW TEST:8.942 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 16:37:19.569: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-3239
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Feb 17 16:37:19.900: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"f353c78d-8417-4383-941e-84788a8e43f9", Controller:(*bool)(0xc0029691c6), BlockOwnerDeletion:(*bool)(0xc0029691c7)}}
Feb 17 16:37:19.914: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"e16dc399-a778-4965-a4e6-722aaef75711", Controller:(*bool)(0xc00242f33e), BlockOwnerDeletion:(*bool)(0xc00242f33f)}}
Feb 17 16:37:19.928: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"fde79384-f639-4af1-b271-20a8b6e2be3d", Controller:(*bool)(0xc002969396), BlockOwnerDeletion:(*bool)(0xc002969397)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 16:37:24.959: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-3239" for this suite.
Feb 17 16:37:31.028: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:37:31.430: INFO: namespace gc-3239 deletion completed in 6.452260232s

• [SLOW TEST:11.861 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 16:37:31.431: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-2986
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
Feb 17 16:38:02.364: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W0217 16:38:02.364671      16 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 16:38:02.364: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-2986" for this suite.
Feb 17 16:38:10.431: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:38:11.046: INFO: namespace gc-2986 deletion completed in 8.666459939s

• [SLOW TEST:39.616 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 16:38:11.047: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-1074
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-1074
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating stateful set ss in namespace statefulset-1074
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-1074
Feb 17 16:38:11.356: INFO: Found 0 stateful pods, waiting for 1
Feb 17 16:38:21.369: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Feb 17 16:38:21.381: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-079603707 exec --namespace=statefulset-1074 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 17 16:38:21.830: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Feb 17 16:38:21.830: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 17 16:38:21.830: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 17 16:38:21.842: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Feb 17 16:38:31.854: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Feb 17 16:38:31.854: INFO: Waiting for statefulset status.replicas updated to 0
Feb 17 16:38:31.909: INFO: POD   NODE         PHASE    GRACE  CONDITIONS
Feb 17 16:38:31.909: INFO: ss-0  10.242.0.59  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:38:11 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:38:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:38:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:38:11 +0000 UTC  }]
Feb 17 16:38:31.909: INFO: ss-1               Pending         []
Feb 17 16:38:31.909: INFO: 
Feb 17 16:38:31.909: INFO: StatefulSet ss has not reached scale 3, at 2
Feb 17 16:38:32.923: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.987355606s
Feb 17 16:38:33.936: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.972748138s
Feb 17 16:38:34.951: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.960080204s
Feb 17 16:38:35.967: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.945440763s
Feb 17 16:38:36.980: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.929470039s
Feb 17 16:38:37.992: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.916454479s
Feb 17 16:38:39.004: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.904681941s
Feb 17 16:38:40.017: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.892525731s
Feb 17 16:38:41.030: INFO: Verifying statefulset ss doesn't scale past 3 for another 879.578261ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-1074
Feb 17 16:38:42.043: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-079603707 exec --namespace=statefulset-1074 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 17 16:38:42.530: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Feb 17 16:38:42.530: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb 17 16:38:42.530: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb 17 16:38:42.530: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-079603707 exec --namespace=statefulset-1074 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 17 16:38:42.994: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Feb 17 16:38:42.994: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb 17 16:38:42.994: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb 17 16:38:42.994: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-079603707 exec --namespace=statefulset-1074 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 17 16:38:43.404: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Feb 17 16:38:43.404: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb 17 16:38:43.404: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb 17 16:38:43.416: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Feb 17 16:38:43.416: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Feb 17 16:38:43.416: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Feb 17 16:38:43.428: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-079603707 exec --namespace=statefulset-1074 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 17 16:38:43.936: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Feb 17 16:38:43.936: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 17 16:38:43.936: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 17 16:38:43.936: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-079603707 exec --namespace=statefulset-1074 ss-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 17 16:38:44.349: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Feb 17 16:38:44.349: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 17 16:38:44.349: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 17 16:38:44.349: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-079603707 exec --namespace=statefulset-1074 ss-2 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 17 16:38:44.797: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Feb 17 16:38:44.797: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 17 16:38:44.797: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 17 16:38:44.797: INFO: Waiting for statefulset status.replicas updated to 0
Feb 17 16:38:44.810: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 1
Feb 17 16:38:54.923: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Feb 17 16:38:54.923: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Feb 17 16:38:54.923: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Feb 17 16:38:54.963: INFO: POD   NODE         PHASE    GRACE  CONDITIONS
Feb 17 16:38:54.963: INFO: ss-0  10.242.0.59  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:38:11 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:38:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:38:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:38:11 +0000 UTC  }]
Feb 17 16:38:54.963: INFO: ss-1  10.242.0.98  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:38:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:38:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:38:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:38:31 +0000 UTC  }]
Feb 17 16:38:54.963: INFO: ss-2  10.242.0.59  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:38:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:38:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:38:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:38:31 +0000 UTC  }]
Feb 17 16:38:54.963: INFO: 
Feb 17 16:38:54.963: INFO: StatefulSet ss has not reached scale 0, at 3
Feb 17 16:38:55.975: INFO: POD   NODE         PHASE    GRACE  CONDITIONS
Feb 17 16:38:55.975: INFO: ss-0  10.242.0.59  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:38:11 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:38:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:38:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:38:11 +0000 UTC  }]
Feb 17 16:38:55.975: INFO: ss-1  10.242.0.98  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:38:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:38:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:38:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:38:31 +0000 UTC  }]
Feb 17 16:38:55.975: INFO: ss-2  10.242.0.59  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:38:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:38:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:38:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:38:31 +0000 UTC  }]
Feb 17 16:38:55.975: INFO: 
Feb 17 16:38:55.975: INFO: StatefulSet ss has not reached scale 0, at 3
Feb 17 16:38:56.988: INFO: POD   NODE         PHASE    GRACE  CONDITIONS
Feb 17 16:38:56.988: INFO: ss-0  10.242.0.59  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:38:11 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:38:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:38:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:38:11 +0000 UTC  }]
Feb 17 16:38:56.988: INFO: ss-2  10.242.0.59  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:38:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:38:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:38:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:38:31 +0000 UTC  }]
Feb 17 16:38:56.988: INFO: 
Feb 17 16:38:56.988: INFO: StatefulSet ss has not reached scale 0, at 2
Feb 17 16:38:58.000: INFO: POD   NODE         PHASE    GRACE  CONDITIONS
Feb 17 16:38:58.000: INFO: ss-2  10.242.0.59  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:38:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:38:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:38:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:38:31 +0000 UTC  }]
Feb 17 16:38:58.000: INFO: 
Feb 17 16:38:58.000: INFO: StatefulSet ss has not reached scale 0, at 1
Feb 17 16:38:59.011: INFO: POD   NODE         PHASE    GRACE  CONDITIONS
Feb 17 16:38:59.011: INFO: ss-2  10.242.0.59  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:38:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:38:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:38:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:38:31 +0000 UTC  }]
Feb 17 16:38:59.011: INFO: 
Feb 17 16:38:59.011: INFO: StatefulSet ss has not reached scale 0, at 1
Feb 17 16:39:00.024: INFO: POD   NODE         PHASE    GRACE  CONDITIONS
Feb 17 16:39:00.024: INFO: ss-2  10.242.0.59  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:38:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:38:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:38:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:38:31 +0000 UTC  }]
Feb 17 16:39:00.024: INFO: 
Feb 17 16:39:00.024: INFO: StatefulSet ss has not reached scale 0, at 1
Feb 17 16:39:01.037: INFO: POD   NODE         PHASE    GRACE  CONDITIONS
Feb 17 16:39:01.037: INFO: ss-2  10.242.0.59  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:38:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:38:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:38:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:38:31 +0000 UTC  }]
Feb 17 16:39:01.037: INFO: 
Feb 17 16:39:01.037: INFO: StatefulSet ss has not reached scale 0, at 1
Feb 17 16:39:02.059: INFO: POD   NODE         PHASE    GRACE  CONDITIONS
Feb 17 16:39:02.059: INFO: ss-2  10.242.0.59  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:38:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:38:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:38:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:38:31 +0000 UTC  }]
Feb 17 16:39:02.060: INFO: 
Feb 17 16:39:02.060: INFO: StatefulSet ss has not reached scale 0, at 1
Feb 17 16:39:03.072: INFO: Verifying statefulset ss doesn't scale past 0 for another 1.891381689s
Feb 17 16:39:04.083: INFO: Verifying statefulset ss doesn't scale past 0 for another 879.265374ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-1074
Feb 17 16:39:05.096: INFO: Scaling statefulset ss to 0
Feb 17 16:39:05.137: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Feb 17 16:39:05.149: INFO: Deleting all statefulset in ns statefulset-1074
Feb 17 16:39:05.163: INFO: Scaling statefulset ss to 0
Feb 17 16:39:05.200: INFO: Waiting for statefulset status.replicas updated to 0
Feb 17 16:39:05.214: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 16:39:05.268: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-1074" for this suite.
Feb 17 16:39:13.336: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:39:13.729: INFO: namespace statefulset-1074 deletion completed in 8.442168228s

• [SLOW TEST:62.682 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 16:39:13.730: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-4201
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name s-test-opt-del-b9136bfb-985e-434a-9529-e387a8d5c268
STEP: Creating secret with name s-test-opt-upd-a578e46f-a28c-4f34-9acd-9e59e3ad5715
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-b9136bfb-985e-434a-9529-e387a8d5c268
STEP: Updating secret s-test-opt-upd-a578e46f-a28c-4f34-9acd-9e59e3ad5715
STEP: Creating secret with name s-test-opt-create-e3b984b1-61b1-495a-8b7f-420f34ddf751
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 16:40:35.712: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4201" for this suite.
Feb 17 16:40:59.793: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:41:00.324: INFO: namespace projected-4201 deletion completed in 24.588970763s

• [SLOW TEST:106.595 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 16:41:00.328: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-7241
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod liveness-5595298f-01cb-44f3-ad7e-53bcba963f27 in namespace container-probe-7241
Feb 17 16:41:06.629: INFO: Started pod liveness-5595298f-01cb-44f3-ad7e-53bcba963f27 in namespace container-probe-7241
STEP: checking the pod's current state and verifying that restartCount is present
Feb 17 16:41:06.641: INFO: Initial restart count of pod liveness-5595298f-01cb-44f3-ad7e-53bcba963f27 is 0
Feb 17 16:41:22.775: INFO: Restart count of pod container-probe-7241/liveness-5595298f-01cb-44f3-ad7e-53bcba963f27 is now 1 (16.133840914s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 16:41:22.809: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-7241" for this suite.
Feb 17 16:41:28.880: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:41:29.292: INFO: namespace container-probe-7241 deletion completed in 6.463696291s

• [SLOW TEST:28.964 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 16:41:29.294: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-347
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-map-ace5066a-26cf-40be-bd43-4bf5101fa12d
STEP: Creating a pod to test consume configMaps
Feb 17 16:41:29.635: INFO: Waiting up to 5m0s for pod "pod-configmaps-f3afb0f6-a66b-403c-afa7-516e56ec1aef" in namespace "configmap-347" to be "success or failure"
Feb 17 16:41:29.649: INFO: Pod "pod-configmaps-f3afb0f6-a66b-403c-afa7-516e56ec1aef": Phase="Pending", Reason="", readiness=false. Elapsed: 12.902333ms
Feb 17 16:41:31.660: INFO: Pod "pod-configmaps-f3afb0f6-a66b-403c-afa7-516e56ec1aef": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.024624074s
STEP: Saw pod success
Feb 17 16:41:31.660: INFO: Pod "pod-configmaps-f3afb0f6-a66b-403c-afa7-516e56ec1aef" satisfied condition "success or failure"
Feb 17 16:41:31.672: INFO: Trying to get logs from node 10.242.0.98 pod pod-configmaps-f3afb0f6-a66b-403c-afa7-516e56ec1aef container configmap-volume-test: <nil>
STEP: delete the pod
Feb 17 16:41:31.744: INFO: Waiting for pod pod-configmaps-f3afb0f6-a66b-403c-afa7-516e56ec1aef to disappear
Feb 17 16:41:31.754: INFO: Pod pod-configmaps-f3afb0f6-a66b-403c-afa7-516e56ec1aef no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 16:41:31.755: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-347" for this suite.
Feb 17 16:41:37.830: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:41:38.249: INFO: namespace configmap-347 deletion completed in 6.469843399s

• [SLOW TEST:8.955 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 16:41:38.252: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-3506
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test substitution in container's command
Feb 17 16:41:38.516: INFO: Waiting up to 5m0s for pod "var-expansion-b598f5fb-3bb1-4023-8ac0-bbe5fb0e68c8" in namespace "var-expansion-3506" to be "success or failure"
Feb 17 16:41:38.528: INFO: Pod "var-expansion-b598f5fb-3bb1-4023-8ac0-bbe5fb0e68c8": Phase="Pending", Reason="", readiness=false. Elapsed: 11.289889ms
Feb 17 16:41:40.539: INFO: Pod "var-expansion-b598f5fb-3bb1-4023-8ac0-bbe5fb0e68c8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.022348822s
STEP: Saw pod success
Feb 17 16:41:40.539: INFO: Pod "var-expansion-b598f5fb-3bb1-4023-8ac0-bbe5fb0e68c8" satisfied condition "success or failure"
Feb 17 16:41:40.553: INFO: Trying to get logs from node 10.242.0.59 pod var-expansion-b598f5fb-3bb1-4023-8ac0-bbe5fb0e68c8 container dapi-container: <nil>
STEP: delete the pod
Feb 17 16:41:40.619: INFO: Waiting for pod var-expansion-b598f5fb-3bb1-4023-8ac0-bbe5fb0e68c8 to disappear
Feb 17 16:41:40.629: INFO: Pod var-expansion-b598f5fb-3bb1-4023-8ac0-bbe5fb0e68c8 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 16:41:40.629: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-3506" for this suite.
Feb 17 16:41:46.701: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:41:47.092: INFO: namespace var-expansion-3506 deletion completed in 6.440337675s

• [SLOW TEST:8.841 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 16:41:47.092: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5826
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name projected-secret-test-6e3314b5-988c-4205-a1d0-7dc9cd72a290
STEP: Creating a pod to test consume secrets
Feb 17 16:41:47.389: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-6be754e2-5a35-4c09-b830-6c4e19e59e06" in namespace "projected-5826" to be "success or failure"
Feb 17 16:41:47.399: INFO: Pod "pod-projected-secrets-6be754e2-5a35-4c09-b830-6c4e19e59e06": Phase="Pending", Reason="", readiness=false. Elapsed: 9.80587ms
Feb 17 16:41:49.412: INFO: Pod "pod-projected-secrets-6be754e2-5a35-4c09-b830-6c4e19e59e06": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.022729151s
STEP: Saw pod success
Feb 17 16:41:49.412: INFO: Pod "pod-projected-secrets-6be754e2-5a35-4c09-b830-6c4e19e59e06" satisfied condition "success or failure"
Feb 17 16:41:49.423: INFO: Trying to get logs from node 10.242.0.59 pod pod-projected-secrets-6be754e2-5a35-4c09-b830-6c4e19e59e06 container secret-volume-test: <nil>
STEP: delete the pod
Feb 17 16:41:49.502: INFO: Waiting for pod pod-projected-secrets-6be754e2-5a35-4c09-b830-6c4e19e59e06 to disappear
Feb 17 16:41:49.513: INFO: Pod pod-projected-secrets-6be754e2-5a35-4c09-b830-6c4e19e59e06 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 16:41:49.513: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5826" for this suite.
Feb 17 16:41:55.587: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:41:55.977: INFO: namespace projected-5826 deletion completed in 6.442917717s

• [SLOW TEST:8.885 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] version v1
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 16:41:55.977: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-4220
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Feb 17 16:41:56.279: INFO: (0) /api/v1/nodes/10.242.0.59:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 32.814211ms)
Feb 17 16:41:56.301: INFO: (1) /api/v1/nodes/10.242.0.59:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 22.6005ms)
Feb 17 16:41:56.330: INFO: (2) /api/v1/nodes/10.242.0.59:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 28.767505ms)
Feb 17 16:41:56.353: INFO: (3) /api/v1/nodes/10.242.0.59:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 23.216978ms)
Feb 17 16:41:56.380: INFO: (4) /api/v1/nodes/10.242.0.59:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 26.571381ms)
Feb 17 16:41:56.403: INFO: (5) /api/v1/nodes/10.242.0.59:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 22.699912ms)
Feb 17 16:41:56.427: INFO: (6) /api/v1/nodes/10.242.0.59:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 23.914779ms)
Feb 17 16:41:56.450: INFO: (7) /api/v1/nodes/10.242.0.59:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 22.775284ms)
Feb 17 16:41:56.474: INFO: (8) /api/v1/nodes/10.242.0.59:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 23.948382ms)
Feb 17 16:41:56.495: INFO: (9) /api/v1/nodes/10.242.0.59:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 21.596038ms)
Feb 17 16:41:56.517: INFO: (10) /api/v1/nodes/10.242.0.59:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 21.884005ms)
Feb 17 16:41:56.540: INFO: (11) /api/v1/nodes/10.242.0.59:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 22.400654ms)
Feb 17 16:41:56.563: INFO: (12) /api/v1/nodes/10.242.0.59:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 23.09385ms)
Feb 17 16:41:56.588: INFO: (13) /api/v1/nodes/10.242.0.59:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 25.163594ms)
Feb 17 16:41:56.611: INFO: (14) /api/v1/nodes/10.242.0.59:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 22.722335ms)
Feb 17 16:41:56.634: INFO: (15) /api/v1/nodes/10.242.0.59:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 22.628922ms)
Feb 17 16:41:56.665: INFO: (16) /api/v1/nodes/10.242.0.59:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 31.146481ms)
Feb 17 16:41:56.688: INFO: (17) /api/v1/nodes/10.242.0.59:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 23.197366ms)
Feb 17 16:41:56.851: INFO: (18) /api/v1/nodes/10.242.0.59:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 162.600282ms)
Feb 17 16:41:56.875: INFO: (19) /api/v1/nodes/10.242.0.59:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 23.318151ms)
[AfterEach] version v1
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 16:41:56.875: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-4220" for this suite.
Feb 17 16:42:02.942: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:42:03.352: INFO: namespace proxy-4220 deletion completed in 6.460291005s

• [SLOW TEST:7.375 seconds]
[sig-network] Proxy
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:58
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 16:42:03.355: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-3532
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0644 on node default medium
Feb 17 16:42:03.637: INFO: Waiting up to 5m0s for pod "pod-96e7ed5b-aa6a-421e-a17d-4d21bfd78416" in namespace "emptydir-3532" to be "success or failure"
Feb 17 16:42:03.650: INFO: Pod "pod-96e7ed5b-aa6a-421e-a17d-4d21bfd78416": Phase="Pending", Reason="", readiness=false. Elapsed: 12.350776ms
Feb 17 16:42:05.662: INFO: Pod "pod-96e7ed5b-aa6a-421e-a17d-4d21bfd78416": Phase="Running", Reason="", readiness=true. Elapsed: 2.025206173s
Feb 17 16:42:07.673: INFO: Pod "pod-96e7ed5b-aa6a-421e-a17d-4d21bfd78416": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.036200199s
STEP: Saw pod success
Feb 17 16:42:07.674: INFO: Pod "pod-96e7ed5b-aa6a-421e-a17d-4d21bfd78416" satisfied condition "success or failure"
Feb 17 16:42:07.685: INFO: Trying to get logs from node 10.242.0.59 pod pod-96e7ed5b-aa6a-421e-a17d-4d21bfd78416 container test-container: <nil>
STEP: delete the pod
Feb 17 16:42:07.762: INFO: Waiting for pod pod-96e7ed5b-aa6a-421e-a17d-4d21bfd78416 to disappear
Feb 17 16:42:07.772: INFO: Pod pod-96e7ed5b-aa6a-421e-a17d-4d21bfd78416 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 16:42:07.772: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3532" for this suite.
Feb 17 16:42:13.841: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:42:14.249: INFO: namespace emptydir-3532 deletion completed in 6.458064002s

• [SLOW TEST:10.895 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] version v1
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 16:42:14.251: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-4830
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-2txl9 in namespace proxy-4830
I0217 16:42:14.548347      16 runners.go:180] Created replication controller with name: proxy-service-2txl9, namespace: proxy-4830, replica count: 1
I0217 16:42:15.599292      16 runners.go:180] proxy-service-2txl9 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0217 16:42:16.599554      16 runners.go:180] proxy-service-2txl9 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0217 16:42:17.599803      16 runners.go:180] proxy-service-2txl9 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0217 16:42:18.600250      16 runners.go:180] proxy-service-2txl9 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0217 16:42:19.600514      16 runners.go:180] proxy-service-2txl9 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0217 16:42:20.600789      16 runners.go:180] proxy-service-2txl9 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0217 16:42:21.601153      16 runners.go:180] proxy-service-2txl9 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0217 16:42:22.601419      16 runners.go:180] proxy-service-2txl9 Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Feb 17 16:42:22.615: INFO: setup took 8.112789825s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Feb 17 16:42:22.651: INFO: (0) /api/v1/namespaces/proxy-4830/pods/proxy-service-2txl9-4j5r2:1080/proxy/: <a href="/api/v1/namespaces/proxy-4830/pods/proxy-service-2txl9-4j5r2:1080/proxy/rewriteme">test<... (200; 35.059635ms)
Feb 17 16:42:22.651: INFO: (0) /api/v1/namespaces/proxy-4830/pods/http:proxy-service-2txl9-4j5r2:160/proxy/: foo (200; 34.979999ms)
Feb 17 16:42:22.658: INFO: (0) /api/v1/namespaces/proxy-4830/pods/http:proxy-service-2txl9-4j5r2:1080/proxy/: <a href="/api/v1/namespaces/proxy-4830/pods/http:proxy-service-2txl9-4j5r2:1080/proxy/rewriteme">... (200; 41.968241ms)
Feb 17 16:42:22.658: INFO: (0) /api/v1/namespaces/proxy-4830/pods/proxy-service-2txl9-4j5r2/proxy/: <a href="/api/v1/namespaces/proxy-4830/pods/proxy-service-2txl9-4j5r2/proxy/rewriteme">test</a> (200; 42.404573ms)
Feb 17 16:42:22.658: INFO: (0) /api/v1/namespaces/proxy-4830/pods/proxy-service-2txl9-4j5r2:160/proxy/: foo (200; 42.521938ms)
Feb 17 16:42:22.659: INFO: (0) /api/v1/namespaces/proxy-4830/services/proxy-service-2txl9:portname1/proxy/: foo (200; 43.463221ms)
Feb 17 16:42:22.660: INFO: (0) /api/v1/namespaces/proxy-4830/pods/http:proxy-service-2txl9-4j5r2:162/proxy/: bar (200; 44.496577ms)
Feb 17 16:42:22.660: INFO: (0) /api/v1/namespaces/proxy-4830/services/proxy-service-2txl9:portname2/proxy/: bar (200; 44.289856ms)
Feb 17 16:42:22.660: INFO: (0) /api/v1/namespaces/proxy-4830/pods/proxy-service-2txl9-4j5r2:162/proxy/: bar (200; 43.841388ms)
Feb 17 16:42:22.662: INFO: (0) /api/v1/namespaces/proxy-4830/services/http:proxy-service-2txl9:portname1/proxy/: foo (200; 46.181618ms)
Feb 17 16:42:22.663: INFO: (0) /api/v1/namespaces/proxy-4830/services/http:proxy-service-2txl9:portname2/proxy/: bar (200; 46.812485ms)
Feb 17 16:42:22.675: INFO: (0) /api/v1/namespaces/proxy-4830/pods/https:proxy-service-2txl9-4j5r2:460/proxy/: tls baz (200; 60.145896ms)
Feb 17 16:42:22.678: INFO: (0) /api/v1/namespaces/proxy-4830/pods/https:proxy-service-2txl9-4j5r2:462/proxy/: tls qux (200; 63.127265ms)
Feb 17 16:42:22.679: INFO: (0) /api/v1/namespaces/proxy-4830/pods/https:proxy-service-2txl9-4j5r2:443/proxy/: <a href="/api/v1/namespaces/proxy-4830/pods/https:proxy-service-2txl9-4j5r2:443/proxy/tlsrewritem... (200; 62.814321ms)
Feb 17 16:42:22.683: INFO: (0) /api/v1/namespaces/proxy-4830/services/https:proxy-service-2txl9:tlsportname1/proxy/: tls baz (200; 67.847437ms)
Feb 17 16:42:22.686: INFO: (0) /api/v1/namespaces/proxy-4830/services/https:proxy-service-2txl9:tlsportname2/proxy/: tls qux (200; 70.217676ms)
Feb 17 16:42:22.709: INFO: (1) /api/v1/namespaces/proxy-4830/pods/http:proxy-service-2txl9-4j5r2:160/proxy/: foo (200; 22.697189ms)
Feb 17 16:42:22.714: INFO: (1) /api/v1/namespaces/proxy-4830/pods/proxy-service-2txl9-4j5r2:162/proxy/: bar (200; 26.311943ms)
Feb 17 16:42:22.715: INFO: (1) /api/v1/namespaces/proxy-4830/pods/proxy-service-2txl9-4j5r2:1080/proxy/: <a href="/api/v1/namespaces/proxy-4830/pods/proxy-service-2txl9-4j5r2:1080/proxy/rewriteme">test<... (200; 27.836877ms)
Feb 17 16:42:22.715: INFO: (1) /api/v1/namespaces/proxy-4830/pods/proxy-service-2txl9-4j5r2:160/proxy/: foo (200; 28.793806ms)
Feb 17 16:42:22.715: INFO: (1) /api/v1/namespaces/proxy-4830/pods/http:proxy-service-2txl9-4j5r2:162/proxy/: bar (200; 28.516199ms)
Feb 17 16:42:22.715: INFO: (1) /api/v1/namespaces/proxy-4830/pods/https:proxy-service-2txl9-4j5r2:460/proxy/: tls baz (200; 28.448217ms)
Feb 17 16:42:22.716: INFO: (1) /api/v1/namespaces/proxy-4830/pods/proxy-service-2txl9-4j5r2/proxy/: <a href="/api/v1/namespaces/proxy-4830/pods/proxy-service-2txl9-4j5r2/proxy/rewriteme">test</a> (200; 29.528503ms)
Feb 17 16:42:22.716: INFO: (1) /api/v1/namespaces/proxy-4830/pods/https:proxy-service-2txl9-4j5r2:443/proxy/: <a href="/api/v1/namespaces/proxy-4830/pods/https:proxy-service-2txl9-4j5r2:443/proxy/tlsrewritem... (200; 28.424097ms)
Feb 17 16:42:22.716: INFO: (1) /api/v1/namespaces/proxy-4830/pods/https:proxy-service-2txl9-4j5r2:462/proxy/: tls qux (200; 27.911997ms)
Feb 17 16:42:22.716: INFO: (1) /api/v1/namespaces/proxy-4830/pods/http:proxy-service-2txl9-4j5r2:1080/proxy/: <a href="/api/v1/namespaces/proxy-4830/pods/http:proxy-service-2txl9-4j5r2:1080/proxy/rewriteme">... (200; 28.253308ms)
Feb 17 16:42:22.719: INFO: (1) /api/v1/namespaces/proxy-4830/services/http:proxy-service-2txl9:portname1/proxy/: foo (200; 31.581273ms)
Feb 17 16:42:22.728: INFO: (1) /api/v1/namespaces/proxy-4830/services/http:proxy-service-2txl9:portname2/proxy/: bar (200; 41.056623ms)
Feb 17 16:42:22.729: INFO: (1) /api/v1/namespaces/proxy-4830/services/https:proxy-service-2txl9:tlsportname1/proxy/: tls baz (200; 41.95019ms)
Feb 17 16:42:22.729: INFO: (1) /api/v1/namespaces/proxy-4830/services/proxy-service-2txl9:portname2/proxy/: bar (200; 42.245899ms)
Feb 17 16:42:22.729: INFO: (1) /api/v1/namespaces/proxy-4830/services/proxy-service-2txl9:portname1/proxy/: foo (200; 40.662416ms)
Feb 17 16:42:22.729: INFO: (1) /api/v1/namespaces/proxy-4830/services/https:proxy-service-2txl9:tlsportname2/proxy/: tls qux (200; 42.876121ms)
Feb 17 16:42:22.752: INFO: (2) /api/v1/namespaces/proxy-4830/pods/proxy-service-2txl9-4j5r2:1080/proxy/: <a href="/api/v1/namespaces/proxy-4830/pods/proxy-service-2txl9-4j5r2:1080/proxy/rewriteme">test<... (200; 22.705765ms)
Feb 17 16:42:22.762: INFO: (2) /api/v1/namespaces/proxy-4830/pods/https:proxy-service-2txl9-4j5r2:443/proxy/: <a href="/api/v1/namespaces/proxy-4830/pods/https:proxy-service-2txl9-4j5r2:443/proxy/tlsrewritem... (200; 32.717092ms)
Feb 17 16:42:22.763: INFO: (2) /api/v1/namespaces/proxy-4830/pods/http:proxy-service-2txl9-4j5r2:160/proxy/: foo (200; 32.942403ms)
Feb 17 16:42:22.763: INFO: (2) /api/v1/namespaces/proxy-4830/pods/proxy-service-2txl9-4j5r2:162/proxy/: bar (200; 33.003581ms)
Feb 17 16:42:22.763: INFO: (2) /api/v1/namespaces/proxy-4830/pods/https:proxy-service-2txl9-4j5r2:460/proxy/: tls baz (200; 33.496492ms)
Feb 17 16:42:22.763: INFO: (2) /api/v1/namespaces/proxy-4830/pods/proxy-service-2txl9-4j5r2/proxy/: <a href="/api/v1/namespaces/proxy-4830/pods/proxy-service-2txl9-4j5r2/proxy/rewriteme">test</a> (200; 32.83619ms)
Feb 17 16:42:22.763: INFO: (2) /api/v1/namespaces/proxy-4830/pods/https:proxy-service-2txl9-4j5r2:462/proxy/: tls qux (200; 33.149277ms)
Feb 17 16:42:22.763: INFO: (2) /api/v1/namespaces/proxy-4830/pods/http:proxy-service-2txl9-4j5r2:162/proxy/: bar (200; 33.819593ms)
Feb 17 16:42:22.763: INFO: (2) /api/v1/namespaces/proxy-4830/pods/proxy-service-2txl9-4j5r2:160/proxy/: foo (200; 33.11856ms)
Feb 17 16:42:22.763: INFO: (2) /api/v1/namespaces/proxy-4830/pods/http:proxy-service-2txl9-4j5r2:1080/proxy/: <a href="/api/v1/namespaces/proxy-4830/pods/http:proxy-service-2txl9-4j5r2:1080/proxy/rewriteme">... (200; 33.726806ms)
Feb 17 16:42:22.771: INFO: (2) /api/v1/namespaces/proxy-4830/services/http:proxy-service-2txl9:portname2/proxy/: bar (200; 41.397476ms)
Feb 17 16:42:22.771: INFO: (2) /api/v1/namespaces/proxy-4830/services/proxy-service-2txl9:portname1/proxy/: foo (200; 41.565379ms)
Feb 17 16:42:22.771: INFO: (2) /api/v1/namespaces/proxy-4830/services/proxy-service-2txl9:portname2/proxy/: bar (200; 41.431755ms)
Feb 17 16:42:22.771: INFO: (2) /api/v1/namespaces/proxy-4830/services/http:proxy-service-2txl9:portname1/proxy/: foo (200; 41.752318ms)
Feb 17 16:42:22.771: INFO: (2) /api/v1/namespaces/proxy-4830/services/https:proxy-service-2txl9:tlsportname2/proxy/: tls qux (200; 41.34392ms)
Feb 17 16:42:22.772: INFO: (2) /api/v1/namespaces/proxy-4830/services/https:proxy-service-2txl9:tlsportname1/proxy/: tls baz (200; 41.83192ms)
Feb 17 16:42:22.798: INFO: (3) /api/v1/namespaces/proxy-4830/pods/http:proxy-service-2txl9-4j5r2:162/proxy/: bar (200; 25.446222ms)
Feb 17 16:42:22.809: INFO: (3) /api/v1/namespaces/proxy-4830/pods/https:proxy-service-2txl9-4j5r2:462/proxy/: tls qux (200; 36.003187ms)
Feb 17 16:42:22.809: INFO: (3) /api/v1/namespaces/proxy-4830/pods/https:proxy-service-2txl9-4j5r2:443/proxy/: <a href="/api/v1/namespaces/proxy-4830/pods/https:proxy-service-2txl9-4j5r2:443/proxy/tlsrewritem... (200; 36.651225ms)
Feb 17 16:42:22.810: INFO: (3) /api/v1/namespaces/proxy-4830/pods/https:proxy-service-2txl9-4j5r2:460/proxy/: tls baz (200; 36.698763ms)
Feb 17 16:42:22.810: INFO: (3) /api/v1/namespaces/proxy-4830/pods/proxy-service-2txl9-4j5r2:160/proxy/: foo (200; 37.899177ms)
Feb 17 16:42:22.812: INFO: (3) /api/v1/namespaces/proxy-4830/pods/http:proxy-service-2txl9-4j5r2:160/proxy/: foo (200; 38.725998ms)
Feb 17 16:42:22.812: INFO: (3) /api/v1/namespaces/proxy-4830/pods/proxy-service-2txl9-4j5r2:162/proxy/: bar (200; 38.633708ms)
Feb 17 16:42:22.812: INFO: (3) /api/v1/namespaces/proxy-4830/pods/http:proxy-service-2txl9-4j5r2:1080/proxy/: <a href="/api/v1/namespaces/proxy-4830/pods/http:proxy-service-2txl9-4j5r2:1080/proxy/rewriteme">... (200; 39.048471ms)
Feb 17 16:42:22.812: INFO: (3) /api/v1/namespaces/proxy-4830/pods/proxy-service-2txl9-4j5r2/proxy/: <a href="/api/v1/namespaces/proxy-4830/pods/proxy-service-2txl9-4j5r2/proxy/rewriteme">test</a> (200; 39.498893ms)
Feb 17 16:42:22.812: INFO: (3) /api/v1/namespaces/proxy-4830/services/https:proxy-service-2txl9:tlsportname2/proxy/: tls qux (200; 39.705767ms)
Feb 17 16:42:22.812: INFO: (3) /api/v1/namespaces/proxy-4830/services/https:proxy-service-2txl9:tlsportname1/proxy/: tls baz (200; 39.931615ms)
Feb 17 16:42:22.818: INFO: (3) /api/v1/namespaces/proxy-4830/services/proxy-service-2txl9:portname2/proxy/: bar (200; 46.090456ms)
Feb 17 16:42:22.819: INFO: (3) /api/v1/namespaces/proxy-4830/services/proxy-service-2txl9:portname1/proxy/: foo (200; 45.583405ms)
Feb 17 16:42:22.820: INFO: (3) /api/v1/namespaces/proxy-4830/services/http:proxy-service-2txl9:portname1/proxy/: foo (200; 46.913419ms)
Feb 17 16:42:22.822: INFO: (3) /api/v1/namespaces/proxy-4830/pods/proxy-service-2txl9-4j5r2:1080/proxy/: <a href="/api/v1/namespaces/proxy-4830/pods/proxy-service-2txl9-4j5r2:1080/proxy/rewriteme">test<... (200; 49.604103ms)
Feb 17 16:42:22.823: INFO: (3) /api/v1/namespaces/proxy-4830/services/http:proxy-service-2txl9:portname2/proxy/: bar (200; 50.048051ms)
Feb 17 16:42:22.842: INFO: (4) /api/v1/namespaces/proxy-4830/pods/http:proxy-service-2txl9-4j5r2:160/proxy/: foo (200; 18.880587ms)
Feb 17 16:42:22.854: INFO: (4) /api/v1/namespaces/proxy-4830/pods/proxy-service-2txl9-4j5r2:160/proxy/: foo (200; 30.948817ms)
Feb 17 16:42:22.854: INFO: (4) /api/v1/namespaces/proxy-4830/pods/http:proxy-service-2txl9-4j5r2:1080/proxy/: <a href="/api/v1/namespaces/proxy-4830/pods/http:proxy-service-2txl9-4j5r2:1080/proxy/rewriteme">... (200; 30.63072ms)
Feb 17 16:42:22.854: INFO: (4) /api/v1/namespaces/proxy-4830/pods/proxy-service-2txl9-4j5r2:1080/proxy/: <a href="/api/v1/namespaces/proxy-4830/pods/proxy-service-2txl9-4j5r2:1080/proxy/rewriteme">test<... (200; 30.861636ms)
Feb 17 16:42:22.854: INFO: (4) /api/v1/namespaces/proxy-4830/pods/http:proxy-service-2txl9-4j5r2:162/proxy/: bar (200; 31.057202ms)
Feb 17 16:42:22.854: INFO: (4) /api/v1/namespaces/proxy-4830/pods/https:proxy-service-2txl9-4j5r2:443/proxy/: <a href="/api/v1/namespaces/proxy-4830/pods/https:proxy-service-2txl9-4j5r2:443/proxy/tlsrewritem... (200; 31.672589ms)
Feb 17 16:42:22.854: INFO: (4) /api/v1/namespaces/proxy-4830/pods/https:proxy-service-2txl9-4j5r2:462/proxy/: tls qux (200; 31.229228ms)
Feb 17 16:42:22.855: INFO: (4) /api/v1/namespaces/proxy-4830/pods/proxy-service-2txl9-4j5r2:162/proxy/: bar (200; 31.406987ms)
Feb 17 16:42:22.855: INFO: (4) /api/v1/namespaces/proxy-4830/pods/https:proxy-service-2txl9-4j5r2:460/proxy/: tls baz (200; 31.083394ms)
Feb 17 16:42:22.855: INFO: (4) /api/v1/namespaces/proxy-4830/pods/proxy-service-2txl9-4j5r2/proxy/: <a href="/api/v1/namespaces/proxy-4830/pods/proxy-service-2txl9-4j5r2/proxy/rewriteme">test</a> (200; 32.364954ms)
Feb 17 16:42:22.855: INFO: (4) /api/v1/namespaces/proxy-4830/services/https:proxy-service-2txl9:tlsportname2/proxy/: tls qux (200; 32.621686ms)
Feb 17 16:42:22.861: INFO: (4) /api/v1/namespaces/proxy-4830/services/http:proxy-service-2txl9:portname2/proxy/: bar (200; 37.898287ms)
Feb 17 16:42:22.862: INFO: (4) /api/v1/namespaces/proxy-4830/services/proxy-service-2txl9:portname1/proxy/: foo (200; 38.813938ms)
Feb 17 16:42:22.862: INFO: (4) /api/v1/namespaces/proxy-4830/services/proxy-service-2txl9:portname2/proxy/: bar (200; 38.586029ms)
Feb 17 16:42:22.862: INFO: (4) /api/v1/namespaces/proxy-4830/services/http:proxy-service-2txl9:portname1/proxy/: foo (200; 38.424089ms)
Feb 17 16:42:22.863: INFO: (4) /api/v1/namespaces/proxy-4830/services/https:proxy-service-2txl9:tlsportname1/proxy/: tls baz (200; 39.151184ms)
Feb 17 16:42:22.885: INFO: (5) /api/v1/namespaces/proxy-4830/pods/http:proxy-service-2txl9-4j5r2:160/proxy/: foo (200; 22.21258ms)
Feb 17 16:42:22.890: INFO: (5) /api/v1/namespaces/proxy-4830/pods/https:proxy-service-2txl9-4j5r2:443/proxy/: <a href="/api/v1/namespaces/proxy-4830/pods/https:proxy-service-2txl9-4j5r2:443/proxy/tlsrewritem... (200; 26.049531ms)
Feb 17 16:42:22.891: INFO: (5) /api/v1/namespaces/proxy-4830/pods/http:proxy-service-2txl9-4j5r2:162/proxy/: bar (200; 26.547981ms)
Feb 17 16:42:22.891: INFO: (5) /api/v1/namespaces/proxy-4830/pods/https:proxy-service-2txl9-4j5r2:462/proxy/: tls qux (200; 27.486664ms)
Feb 17 16:42:22.891: INFO: (5) /api/v1/namespaces/proxy-4830/pods/proxy-service-2txl9-4j5r2:160/proxy/: foo (200; 28.027451ms)
Feb 17 16:42:22.891: INFO: (5) /api/v1/namespaces/proxy-4830/pods/http:proxy-service-2txl9-4j5r2:1080/proxy/: <a href="/api/v1/namespaces/proxy-4830/pods/http:proxy-service-2txl9-4j5r2:1080/proxy/rewriteme">... (200; 26.53661ms)
Feb 17 16:42:22.891: INFO: (5) /api/v1/namespaces/proxy-4830/pods/proxy-service-2txl9-4j5r2:1080/proxy/: <a href="/api/v1/namespaces/proxy-4830/pods/proxy-service-2txl9-4j5r2:1080/proxy/rewriteme">test<... (200; 26.732144ms)
Feb 17 16:42:22.891: INFO: (5) /api/v1/namespaces/proxy-4830/pods/proxy-service-2txl9-4j5r2:162/proxy/: bar (200; 27.524084ms)
Feb 17 16:42:22.891: INFO: (5) /api/v1/namespaces/proxy-4830/pods/https:proxy-service-2txl9-4j5r2:460/proxy/: tls baz (200; 27.26568ms)
Feb 17 16:42:22.892: INFO: (5) /api/v1/namespaces/proxy-4830/pods/proxy-service-2txl9-4j5r2/proxy/: <a href="/api/v1/namespaces/proxy-4830/pods/proxy-service-2txl9-4j5r2/proxy/rewriteme">test</a> (200; 28.058911ms)
Feb 17 16:42:22.894: INFO: (5) /api/v1/namespaces/proxy-4830/services/proxy-service-2txl9:portname1/proxy/: foo (200; 31.094571ms)
Feb 17 16:42:22.901: INFO: (5) /api/v1/namespaces/proxy-4830/services/https:proxy-service-2txl9:tlsportname2/proxy/: tls qux (200; 37.020741ms)
Feb 17 16:42:22.901: INFO: (5) /api/v1/namespaces/proxy-4830/services/http:proxy-service-2txl9:portname1/proxy/: foo (200; 38.320214ms)
Feb 17 16:42:22.901: INFO: (5) /api/v1/namespaces/proxy-4830/services/http:proxy-service-2txl9:portname2/proxy/: bar (200; 37.161532ms)
Feb 17 16:42:22.901: INFO: (5) /api/v1/namespaces/proxy-4830/services/https:proxy-service-2txl9:tlsportname1/proxy/: tls baz (200; 37.867058ms)
Feb 17 16:42:22.902: INFO: (5) /api/v1/namespaces/proxy-4830/services/proxy-service-2txl9:portname2/proxy/: bar (200; 37.490732ms)
Feb 17 16:42:22.922: INFO: (6) /api/v1/namespaces/proxy-4830/pods/http:proxy-service-2txl9-4j5r2:160/proxy/: foo (200; 19.861315ms)
Feb 17 16:42:22.931: INFO: (6) /api/v1/namespaces/proxy-4830/pods/proxy-service-2txl9-4j5r2:162/proxy/: bar (200; 28.371109ms)
Feb 17 16:42:22.931: INFO: (6) /api/v1/namespaces/proxy-4830/pods/http:proxy-service-2txl9-4j5r2:1080/proxy/: <a href="/api/v1/namespaces/proxy-4830/pods/http:proxy-service-2txl9-4j5r2:1080/proxy/rewriteme">... (200; 28.358998ms)
Feb 17 16:42:22.931: INFO: (6) /api/v1/namespaces/proxy-4830/pods/proxy-service-2txl9-4j5r2:1080/proxy/: <a href="/api/v1/namespaces/proxy-4830/pods/proxy-service-2txl9-4j5r2:1080/proxy/rewriteme">test<... (200; 28.78988ms)
Feb 17 16:42:22.932: INFO: (6) /api/v1/namespaces/proxy-4830/pods/http:proxy-service-2txl9-4j5r2:162/proxy/: bar (200; 29.107468ms)
Feb 17 16:42:22.932: INFO: (6) /api/v1/namespaces/proxy-4830/pods/https:proxy-service-2txl9-4j5r2:462/proxy/: tls qux (200; 29.444087ms)
Feb 17 16:42:22.932: INFO: (6) /api/v1/namespaces/proxy-4830/pods/https:proxy-service-2txl9-4j5r2:460/proxy/: tls baz (200; 29.427413ms)
Feb 17 16:42:22.932: INFO: (6) /api/v1/namespaces/proxy-4830/pods/proxy-service-2txl9-4j5r2:160/proxy/: foo (200; 29.667002ms)
Feb 17 16:42:22.932: INFO: (6) /api/v1/namespaces/proxy-4830/pods/https:proxy-service-2txl9-4j5r2:443/proxy/: <a href="/api/v1/namespaces/proxy-4830/pods/https:proxy-service-2txl9-4j5r2:443/proxy/tlsrewritem... (200; 30.649879ms)
Feb 17 16:42:22.933: INFO: (6) /api/v1/namespaces/proxy-4830/pods/proxy-service-2txl9-4j5r2/proxy/: <a href="/api/v1/namespaces/proxy-4830/pods/proxy-service-2txl9-4j5r2/proxy/rewriteme">test</a> (200; 30.519922ms)
Feb 17 16:42:22.935: INFO: (6) /api/v1/namespaces/proxy-4830/services/proxy-service-2txl9:portname1/proxy/: foo (200; 32.86294ms)
Feb 17 16:42:22.942: INFO: (6) /api/v1/namespaces/proxy-4830/services/http:proxy-service-2txl9:portname1/proxy/: foo (200; 39.057688ms)
Feb 17 16:42:22.942: INFO: (6) /api/v1/namespaces/proxy-4830/services/https:proxy-service-2txl9:tlsportname2/proxy/: tls qux (200; 40.210791ms)
Feb 17 16:42:22.942: INFO: (6) /api/v1/namespaces/proxy-4830/services/proxy-service-2txl9:portname2/proxy/: bar (200; 39.495062ms)
Feb 17 16:42:22.942: INFO: (6) /api/v1/namespaces/proxy-4830/services/http:proxy-service-2txl9:portname2/proxy/: bar (200; 39.685388ms)
Feb 17 16:42:22.942: INFO: (6) /api/v1/namespaces/proxy-4830/services/https:proxy-service-2txl9:tlsportname1/proxy/: tls baz (200; 39.381434ms)
Feb 17 16:42:22.966: INFO: (7) /api/v1/namespaces/proxy-4830/pods/http:proxy-service-2txl9-4j5r2:1080/proxy/: <a href="/api/v1/namespaces/proxy-4830/pods/http:proxy-service-2txl9-4j5r2:1080/proxy/rewriteme">... (200; 23.338716ms)
Feb 17 16:42:22.967: INFO: (7) /api/v1/namespaces/proxy-4830/pods/http:proxy-service-2txl9-4j5r2:160/proxy/: foo (200; 23.778344ms)
Feb 17 16:42:22.967: INFO: (7) /api/v1/namespaces/proxy-4830/pods/proxy-service-2txl9-4j5r2/proxy/: <a href="/api/v1/namespaces/proxy-4830/pods/proxy-service-2txl9-4j5r2/proxy/rewriteme">test</a> (200; 23.438157ms)
Feb 17 16:42:22.967: INFO: (7) /api/v1/namespaces/proxy-4830/pods/https:proxy-service-2txl9-4j5r2:443/proxy/: <a href="/api/v1/namespaces/proxy-4830/pods/https:proxy-service-2txl9-4j5r2:443/proxy/tlsrewritem... (200; 23.792775ms)
Feb 17 16:42:22.967: INFO: (7) /api/v1/namespaces/proxy-4830/pods/https:proxy-service-2txl9-4j5r2:460/proxy/: tls baz (200; 24.030567ms)
Feb 17 16:42:22.967: INFO: (7) /api/v1/namespaces/proxy-4830/pods/proxy-service-2txl9-4j5r2:160/proxy/: foo (200; 24.750363ms)
Feb 17 16:42:22.967: INFO: (7) /api/v1/namespaces/proxy-4830/pods/http:proxy-service-2txl9-4j5r2:162/proxy/: bar (200; 24.310001ms)
Feb 17 16:42:22.967: INFO: (7) /api/v1/namespaces/proxy-4830/pods/proxy-service-2txl9-4j5r2:1080/proxy/: <a href="/api/v1/namespaces/proxy-4830/pods/proxy-service-2txl9-4j5r2:1080/proxy/rewriteme">test<... (200; 24.499714ms)
Feb 17 16:42:22.968: INFO: (7) /api/v1/namespaces/proxy-4830/pods/proxy-service-2txl9-4j5r2:162/proxy/: bar (200; 24.663928ms)
Feb 17 16:42:22.968: INFO: (7) /api/v1/namespaces/proxy-4830/pods/https:proxy-service-2txl9-4j5r2:462/proxy/: tls qux (200; 24.501587ms)
Feb 17 16:42:22.976: INFO: (7) /api/v1/namespaces/proxy-4830/services/http:proxy-service-2txl9:portname2/proxy/: bar (200; 33.681954ms)
Feb 17 16:42:22.984: INFO: (7) /api/v1/namespaces/proxy-4830/services/proxy-service-2txl9:portname2/proxy/: bar (200; 40.866056ms)
Feb 17 16:42:22.984: INFO: (7) /api/v1/namespaces/proxy-4830/services/https:proxy-service-2txl9:tlsportname2/proxy/: tls qux (200; 40.998531ms)
Feb 17 16:42:22.984: INFO: (7) /api/v1/namespaces/proxy-4830/services/https:proxy-service-2txl9:tlsportname1/proxy/: tls baz (200; 41.319945ms)
Feb 17 16:42:22.985: INFO: (7) /api/v1/namespaces/proxy-4830/services/proxy-service-2txl9:portname1/proxy/: foo (200; 42.076581ms)
Feb 17 16:42:22.985: INFO: (7) /api/v1/namespaces/proxy-4830/services/http:proxy-service-2txl9:portname1/proxy/: foo (200; 41.673275ms)
Feb 17 16:42:23.005: INFO: (8) /api/v1/namespaces/proxy-4830/pods/https:proxy-service-2txl9-4j5r2:443/proxy/: <a href="/api/v1/namespaces/proxy-4830/pods/https:proxy-service-2txl9-4j5r2:443/proxy/tlsrewritem... (200; 19.899953ms)
Feb 17 16:42:23.011: INFO: (8) /api/v1/namespaces/proxy-4830/pods/proxy-service-2txl9-4j5r2:162/proxy/: bar (200; 25.386593ms)
Feb 17 16:42:23.011: INFO: (8) /api/v1/namespaces/proxy-4830/pods/http:proxy-service-2txl9-4j5r2:162/proxy/: bar (200; 25.796098ms)
Feb 17 16:42:23.012: INFO: (8) /api/v1/namespaces/proxy-4830/pods/proxy-service-2txl9-4j5r2:1080/proxy/: <a href="/api/v1/namespaces/proxy-4830/pods/proxy-service-2txl9-4j5r2:1080/proxy/rewriteme">test<... (200; 26.203721ms)
Feb 17 16:42:23.012: INFO: (8) /api/v1/namespaces/proxy-4830/pods/proxy-service-2txl9-4j5r2:160/proxy/: foo (200; 26.475756ms)
Feb 17 16:42:23.012: INFO: (8) /api/v1/namespaces/proxy-4830/pods/http:proxy-service-2txl9-4j5r2:160/proxy/: foo (200; 26.358011ms)
Feb 17 16:42:23.013: INFO: (8) /api/v1/namespaces/proxy-4830/pods/http:proxy-service-2txl9-4j5r2:1080/proxy/: <a href="/api/v1/namespaces/proxy-4830/pods/http:proxy-service-2txl9-4j5r2:1080/proxy/rewriteme">... (200; 27.568807ms)
Feb 17 16:42:23.013: INFO: (8) /api/v1/namespaces/proxy-4830/pods/proxy-service-2txl9-4j5r2/proxy/: <a href="/api/v1/namespaces/proxy-4830/pods/proxy-service-2txl9-4j5r2/proxy/rewriteme">test</a> (200; 27.319508ms)
Feb 17 16:42:23.013: INFO: (8) /api/v1/namespaces/proxy-4830/pods/https:proxy-service-2txl9-4j5r2:460/proxy/: tls baz (200; 27.199264ms)
Feb 17 16:42:23.013: INFO: (8) /api/v1/namespaces/proxy-4830/pods/https:proxy-service-2txl9-4j5r2:462/proxy/: tls qux (200; 27.155714ms)
Feb 17 16:42:23.020: INFO: (8) /api/v1/namespaces/proxy-4830/services/http:proxy-service-2txl9:portname2/proxy/: bar (200; 34.952717ms)
Feb 17 16:42:23.023: INFO: (8) /api/v1/namespaces/proxy-4830/services/https:proxy-service-2txl9:tlsportname2/proxy/: tls qux (200; 37.673712ms)
Feb 17 16:42:23.023: INFO: (8) /api/v1/namespaces/proxy-4830/services/https:proxy-service-2txl9:tlsportname1/proxy/: tls baz (200; 37.56956ms)
Feb 17 16:42:23.023: INFO: (8) /api/v1/namespaces/proxy-4830/services/http:proxy-service-2txl9:portname1/proxy/: foo (200; 38.048169ms)
Feb 17 16:42:23.023: INFO: (8) /api/v1/namespaces/proxy-4830/services/proxy-service-2txl9:portname1/proxy/: foo (200; 37.651752ms)
Feb 17 16:42:23.024: INFO: (8) /api/v1/namespaces/proxy-4830/services/proxy-service-2txl9:portname2/proxy/: bar (200; 38.128387ms)
Feb 17 16:42:23.057: INFO: (9) /api/v1/namespaces/proxy-4830/pods/https:proxy-service-2txl9-4j5r2:462/proxy/: tls qux (200; 33.12983ms)
Feb 17 16:42:23.058: INFO: (9) /api/v1/namespaces/proxy-4830/pods/proxy-service-2txl9-4j5r2:160/proxy/: foo (200; 33.149912ms)
Feb 17 16:42:23.058: INFO: (9) /api/v1/namespaces/proxy-4830/pods/proxy-service-2txl9-4j5r2/proxy/: <a href="/api/v1/namespaces/proxy-4830/pods/proxy-service-2txl9-4j5r2/proxy/rewriteme">test</a> (200; 33.127394ms)
Feb 17 16:42:23.058: INFO: (9) /api/v1/namespaces/proxy-4830/pods/http:proxy-service-2txl9-4j5r2:1080/proxy/: <a href="/api/v1/namespaces/proxy-4830/pods/http:proxy-service-2txl9-4j5r2:1080/proxy/rewriteme">... (200; 33.424179ms)
Feb 17 16:42:23.058: INFO: (9) /api/v1/namespaces/proxy-4830/pods/https:proxy-service-2txl9-4j5r2:460/proxy/: tls baz (200; 33.599621ms)
Feb 17 16:42:23.058: INFO: (9) /api/v1/namespaces/proxy-4830/pods/proxy-service-2txl9-4j5r2:1080/proxy/: <a href="/api/v1/namespaces/proxy-4830/pods/proxy-service-2txl9-4j5r2:1080/proxy/rewriteme">test<... (200; 33.153894ms)
Feb 17 16:42:23.058: INFO: (9) /api/v1/namespaces/proxy-4830/pods/http:proxy-service-2txl9-4j5r2:160/proxy/: foo (200; 33.368027ms)
Feb 17 16:42:23.058: INFO: (9) /api/v1/namespaces/proxy-4830/pods/http:proxy-service-2txl9-4j5r2:162/proxy/: bar (200; 33.137817ms)
Feb 17 16:42:23.058: INFO: (9) /api/v1/namespaces/proxy-4830/pods/proxy-service-2txl9-4j5r2:162/proxy/: bar (200; 33.384324ms)
Feb 17 16:42:23.058: INFO: (9) /api/v1/namespaces/proxy-4830/pods/https:proxy-service-2txl9-4j5r2:443/proxy/: <a href="/api/v1/namespaces/proxy-4830/pods/https:proxy-service-2txl9-4j5r2:443/proxy/tlsrewritem... (200; 33.540315ms)
Feb 17 16:42:23.065: INFO: (9) /api/v1/namespaces/proxy-4830/services/proxy-service-2txl9:portname2/proxy/: bar (200; 40.824858ms)
Feb 17 16:42:23.065: INFO: (9) /api/v1/namespaces/proxy-4830/services/proxy-service-2txl9:portname1/proxy/: foo (200; 41.559945ms)
Feb 17 16:42:23.065: INFO: (9) /api/v1/namespaces/proxy-4830/services/https:proxy-service-2txl9:tlsportname1/proxy/: tls baz (200; 41.350752ms)
Feb 17 16:42:23.065: INFO: (9) /api/v1/namespaces/proxy-4830/services/http:proxy-service-2txl9:portname2/proxy/: bar (200; 41.352423ms)
Feb 17 16:42:23.066: INFO: (9) /api/v1/namespaces/proxy-4830/services/https:proxy-service-2txl9:tlsportname2/proxy/: tls qux (200; 41.110228ms)
Feb 17 16:42:23.066: INFO: (9) /api/v1/namespaces/proxy-4830/services/http:proxy-service-2txl9:portname1/proxy/: foo (200; 41.321733ms)
Feb 17 16:42:23.087: INFO: (10) /api/v1/namespaces/proxy-4830/pods/proxy-service-2txl9-4j5r2:160/proxy/: foo (200; 21.087874ms)
Feb 17 16:42:23.111: INFO: (10) /api/v1/namespaces/proxy-4830/pods/http:proxy-service-2txl9-4j5r2:160/proxy/: foo (200; 44.949011ms)
Feb 17 16:42:23.111: INFO: (10) /api/v1/namespaces/proxy-4830/pods/https:proxy-service-2txl9-4j5r2:462/proxy/: tls qux (200; 44.966535ms)
Feb 17 16:42:23.111: INFO: (10) /api/v1/namespaces/proxy-4830/pods/proxy-service-2txl9-4j5r2:162/proxy/: bar (200; 45.071769ms)
Feb 17 16:42:23.111: INFO: (10) /api/v1/namespaces/proxy-4830/pods/https:proxy-service-2txl9-4j5r2:443/proxy/: <a href="/api/v1/namespaces/proxy-4830/pods/https:proxy-service-2txl9-4j5r2:443/proxy/tlsrewritem... (200; 45.287535ms)
Feb 17 16:42:23.111: INFO: (10) /api/v1/namespaces/proxy-4830/pods/http:proxy-service-2txl9-4j5r2:162/proxy/: bar (200; 45.491096ms)
Feb 17 16:42:23.111: INFO: (10) /api/v1/namespaces/proxy-4830/pods/proxy-service-2txl9-4j5r2:1080/proxy/: <a href="/api/v1/namespaces/proxy-4830/pods/proxy-service-2txl9-4j5r2:1080/proxy/rewriteme">test<... (200; 45.619479ms)
Feb 17 16:42:23.111: INFO: (10) /api/v1/namespaces/proxy-4830/pods/https:proxy-service-2txl9-4j5r2:460/proxy/: tls baz (200; 45.558966ms)
Feb 17 16:42:23.112: INFO: (10) /api/v1/namespaces/proxy-4830/pods/http:proxy-service-2txl9-4j5r2:1080/proxy/: <a href="/api/v1/namespaces/proxy-4830/pods/http:proxy-service-2txl9-4j5r2:1080/proxy/rewriteme">... (200; 45.55153ms)
Feb 17 16:42:23.112: INFO: (10) /api/v1/namespaces/proxy-4830/pods/proxy-service-2txl9-4j5r2/proxy/: <a href="/api/v1/namespaces/proxy-4830/pods/proxy-service-2txl9-4j5r2/proxy/rewriteme">test</a> (200; 45.248116ms)
Feb 17 16:42:23.314: INFO: (10) /api/v1/namespaces/proxy-4830/services/http:proxy-service-2txl9:portname2/proxy/: bar (200; 248.068197ms)
Feb 17 16:42:23.317: INFO: (10) /api/v1/namespaces/proxy-4830/services/proxy-service-2txl9:portname1/proxy/: foo (200; 250.896031ms)
Feb 17 16:42:23.317: INFO: (10) /api/v1/namespaces/proxy-4830/services/proxy-service-2txl9:portname2/proxy/: bar (200; 251.348113ms)
Feb 17 16:42:23.317: INFO: (10) /api/v1/namespaces/proxy-4830/services/https:proxy-service-2txl9:tlsportname1/proxy/: tls baz (200; 250.932785ms)
Feb 17 16:42:23.318: INFO: (10) /api/v1/namespaces/proxy-4830/services/https:proxy-service-2txl9:tlsportname2/proxy/: tls qux (200; 251.253874ms)
Feb 17 16:42:23.318: INFO: (10) /api/v1/namespaces/proxy-4830/services/http:proxy-service-2txl9:portname1/proxy/: foo (200; 251.91976ms)
Feb 17 16:42:23.350: INFO: (11) /api/v1/namespaces/proxy-4830/pods/proxy-service-2txl9-4j5r2:160/proxy/: foo (200; 31.433321ms)
Feb 17 16:42:23.350: INFO: (11) /api/v1/namespaces/proxy-4830/pods/http:proxy-service-2txl9-4j5r2:160/proxy/: foo (200; 31.750094ms)
Feb 17 16:42:23.352: INFO: (11) /api/v1/namespaces/proxy-4830/pods/proxy-service-2txl9-4j5r2:1080/proxy/: <a href="/api/v1/namespaces/proxy-4830/pods/proxy-service-2txl9-4j5r2:1080/proxy/rewriteme">test<... (200; 34.664593ms)
Feb 17 16:42:23.353: INFO: (11) /api/v1/namespaces/proxy-4830/pods/proxy-service-2txl9-4j5r2:162/proxy/: bar (200; 34.478364ms)
Feb 17 16:42:23.353: INFO: (11) /api/v1/namespaces/proxy-4830/pods/proxy-service-2txl9-4j5r2/proxy/: <a href="/api/v1/namespaces/proxy-4830/pods/proxy-service-2txl9-4j5r2/proxy/rewriteme">test</a> (200; 34.710976ms)
Feb 17 16:42:23.353: INFO: (11) /api/v1/namespaces/proxy-4830/pods/https:proxy-service-2txl9-4j5r2:460/proxy/: tls baz (200; 35.414184ms)
Feb 17 16:42:23.355: INFO: (11) /api/v1/namespaces/proxy-4830/pods/https:proxy-service-2txl9-4j5r2:462/proxy/: tls qux (200; 36.746971ms)
Feb 17 16:42:23.355: INFO: (11) /api/v1/namespaces/proxy-4830/pods/https:proxy-service-2txl9-4j5r2:443/proxy/: <a href="/api/v1/namespaces/proxy-4830/pods/https:proxy-service-2txl9-4j5r2:443/proxy/tlsrewritem... (200; 36.582691ms)
Feb 17 16:42:23.355: INFO: (11) /api/v1/namespaces/proxy-4830/pods/http:proxy-service-2txl9-4j5r2:162/proxy/: bar (200; 36.791635ms)
Feb 17 16:42:23.355: INFO: (11) /api/v1/namespaces/proxy-4830/pods/http:proxy-service-2txl9-4j5r2:1080/proxy/: <a href="/api/v1/namespaces/proxy-4830/pods/http:proxy-service-2txl9-4j5r2:1080/proxy/rewriteme">... (200; 36.708946ms)
Feb 17 16:42:23.361: INFO: (11) /api/v1/namespaces/proxy-4830/services/https:proxy-service-2txl9:tlsportname2/proxy/: tls qux (200; 43.019324ms)
Feb 17 16:42:23.361: INFO: (11) /api/v1/namespaces/proxy-4830/services/https:proxy-service-2txl9:tlsportname1/proxy/: tls baz (200; 43.104237ms)
Feb 17 16:42:23.361: INFO: (11) /api/v1/namespaces/proxy-4830/services/proxy-service-2txl9:portname1/proxy/: foo (200; 43.380889ms)
Feb 17 16:42:23.362: INFO: (11) /api/v1/namespaces/proxy-4830/services/http:proxy-service-2txl9:portname1/proxy/: foo (200; 43.405847ms)
Feb 17 16:42:23.362: INFO: (11) /api/v1/namespaces/proxy-4830/services/http:proxy-service-2txl9:portname2/proxy/: bar (200; 43.286257ms)
Feb 17 16:42:23.362: INFO: (11) /api/v1/namespaces/proxy-4830/services/proxy-service-2txl9:portname2/proxy/: bar (200; 43.502427ms)
Feb 17 16:42:23.382: INFO: (12) /api/v1/namespaces/proxy-4830/pods/proxy-service-2txl9-4j5r2:162/proxy/: bar (200; 20.184309ms)
Feb 17 16:42:23.387: INFO: (12) /api/v1/namespaces/proxy-4830/pods/proxy-service-2txl9-4j5r2:160/proxy/: foo (200; 25.18952ms)
Feb 17 16:42:23.387: INFO: (12) /api/v1/namespaces/proxy-4830/pods/https:proxy-service-2txl9-4j5r2:462/proxy/: tls qux (200; 24.956504ms)
Feb 17 16:42:23.387: INFO: (12) /api/v1/namespaces/proxy-4830/pods/https:proxy-service-2txl9-4j5r2:460/proxy/: tls baz (200; 25.226277ms)
Feb 17 16:42:23.388: INFO: (12) /api/v1/namespaces/proxy-4830/pods/http:proxy-service-2txl9-4j5r2:162/proxy/: bar (200; 25.5904ms)
Feb 17 16:42:23.388: INFO: (12) /api/v1/namespaces/proxy-4830/pods/http:proxy-service-2txl9-4j5r2:160/proxy/: foo (200; 25.477319ms)
Feb 17 16:42:23.388: INFO: (12) /api/v1/namespaces/proxy-4830/pods/https:proxy-service-2txl9-4j5r2:443/proxy/: <a href="/api/v1/namespaces/proxy-4830/pods/https:proxy-service-2txl9-4j5r2:443/proxy/tlsrewritem... (200; 25.543605ms)
Feb 17 16:42:23.388: INFO: (12) /api/v1/namespaces/proxy-4830/pods/proxy-service-2txl9-4j5r2:1080/proxy/: <a href="/api/v1/namespaces/proxy-4830/pods/proxy-service-2txl9-4j5r2:1080/proxy/rewriteme">test<... (200; 26.216412ms)
Feb 17 16:42:23.388: INFO: (12) /api/v1/namespaces/proxy-4830/pods/proxy-service-2txl9-4j5r2/proxy/: <a href="/api/v1/namespaces/proxy-4830/pods/proxy-service-2txl9-4j5r2/proxy/rewriteme">test</a> (200; 26.146826ms)
Feb 17 16:42:23.387: INFO: (12) /api/v1/namespaces/proxy-4830/pods/http:proxy-service-2txl9-4j5r2:1080/proxy/: <a href="/api/v1/namespaces/proxy-4830/pods/http:proxy-service-2txl9-4j5r2:1080/proxy/rewriteme">... (200; 24.884554ms)
Feb 17 16:42:23.392: INFO: (12) /api/v1/namespaces/proxy-4830/services/https:proxy-service-2txl9:tlsportname1/proxy/: tls baz (200; 29.855585ms)
Feb 17 16:42:23.397: INFO: (12) /api/v1/namespaces/proxy-4830/services/http:proxy-service-2txl9:portname1/proxy/: foo (200; 35.302789ms)
Feb 17 16:42:23.398: INFO: (12) /api/v1/namespaces/proxy-4830/services/https:proxy-service-2txl9:tlsportname2/proxy/: tls qux (200; 35.451047ms)
Feb 17 16:42:23.398: INFO: (12) /api/v1/namespaces/proxy-4830/services/proxy-service-2txl9:portname2/proxy/: bar (200; 35.552649ms)
Feb 17 16:42:23.406: INFO: (12) /api/v1/namespaces/proxy-4830/services/http:proxy-service-2txl9:portname2/proxy/: bar (200; 43.52308ms)
Feb 17 16:42:23.406: INFO: (12) /api/v1/namespaces/proxy-4830/services/proxy-service-2txl9:portname1/proxy/: foo (200; 43.456162ms)
Feb 17 16:42:23.424: INFO: (13) /api/v1/namespaces/proxy-4830/pods/http:proxy-service-2txl9-4j5r2:160/proxy/: foo (200; 18.467316ms)
Feb 17 16:42:23.434: INFO: (13) /api/v1/namespaces/proxy-4830/pods/proxy-service-2txl9-4j5r2/proxy/: <a href="/api/v1/namespaces/proxy-4830/pods/proxy-service-2txl9-4j5r2/proxy/rewriteme">test</a> (200; 27.775636ms)
Feb 17 16:42:23.434: INFO: (13) /api/v1/namespaces/proxy-4830/pods/https:proxy-service-2txl9-4j5r2:443/proxy/: <a href="/api/v1/namespaces/proxy-4830/pods/https:proxy-service-2txl9-4j5r2:443/proxy/tlsrewritem... (200; 27.665638ms)
Feb 17 16:42:23.434: INFO: (13) /api/v1/namespaces/proxy-4830/pods/proxy-service-2txl9-4j5r2:1080/proxy/: <a href="/api/v1/namespaces/proxy-4830/pods/proxy-service-2txl9-4j5r2:1080/proxy/rewriteme">test<... (200; 28.005649ms)
Feb 17 16:42:23.434: INFO: (13) /api/v1/namespaces/proxy-4830/pods/proxy-service-2txl9-4j5r2:160/proxy/: foo (200; 27.68775ms)
Feb 17 16:42:23.434: INFO: (13) /api/v1/namespaces/proxy-4830/pods/https:proxy-service-2txl9-4j5r2:460/proxy/: tls baz (200; 28.133885ms)
Feb 17 16:42:23.435: INFO: (13) /api/v1/namespaces/proxy-4830/pods/http:proxy-service-2txl9-4j5r2:162/proxy/: bar (200; 28.387227ms)
Feb 17 16:42:23.435: INFO: (13) /api/v1/namespaces/proxy-4830/pods/http:proxy-service-2txl9-4j5r2:1080/proxy/: <a href="/api/v1/namespaces/proxy-4830/pods/http:proxy-service-2txl9-4j5r2:1080/proxy/rewriteme">... (200; 28.256204ms)
Feb 17 16:42:23.435: INFO: (13) /api/v1/namespaces/proxy-4830/pods/https:proxy-service-2txl9-4j5r2:462/proxy/: tls qux (200; 28.159643ms)
Feb 17 16:42:23.435: INFO: (13) /api/v1/namespaces/proxy-4830/pods/proxy-service-2txl9-4j5r2:162/proxy/: bar (200; 28.831159ms)
Feb 17 16:42:23.441: INFO: (13) /api/v1/namespaces/proxy-4830/services/proxy-service-2txl9:portname1/proxy/: foo (200; 35.206144ms)
Feb 17 16:42:23.446: INFO: (13) /api/v1/namespaces/proxy-4830/services/https:proxy-service-2txl9:tlsportname2/proxy/: tls qux (200; 38.861093ms)
Feb 17 16:42:23.446: INFO: (13) /api/v1/namespaces/proxy-4830/services/proxy-service-2txl9:portname2/proxy/: bar (200; 39.038235ms)
Feb 17 16:42:23.446: INFO: (13) /api/v1/namespaces/proxy-4830/services/http:proxy-service-2txl9:portname1/proxy/: foo (200; 39.282469ms)
Feb 17 16:42:23.446: INFO: (13) /api/v1/namespaces/proxy-4830/services/http:proxy-service-2txl9:portname2/proxy/: bar (200; 39.634213ms)
Feb 17 16:42:23.446: INFO: (13) /api/v1/namespaces/proxy-4830/services/https:proxy-service-2txl9:tlsportname1/proxy/: tls baz (200; 39.381651ms)
Feb 17 16:42:23.468: INFO: (14) /api/v1/namespaces/proxy-4830/pods/http:proxy-service-2txl9-4j5r2:162/proxy/: bar (200; 21.899699ms)
Feb 17 16:42:23.478: INFO: (14) /api/v1/namespaces/proxy-4830/pods/http:proxy-service-2txl9-4j5r2:1080/proxy/: <a href="/api/v1/namespaces/proxy-4830/pods/http:proxy-service-2txl9-4j5r2:1080/proxy/rewriteme">... (200; 31.040203ms)
Feb 17 16:42:23.478: INFO: (14) /api/v1/namespaces/proxy-4830/pods/https:proxy-service-2txl9-4j5r2:460/proxy/: tls baz (200; 31.594388ms)
Feb 17 16:42:23.478: INFO: (14) /api/v1/namespaces/proxy-4830/pods/proxy-service-2txl9-4j5r2:160/proxy/: foo (200; 31.469658ms)
Feb 17 16:42:23.478: INFO: (14) /api/v1/namespaces/proxy-4830/pods/proxy-service-2txl9-4j5r2:162/proxy/: bar (200; 31.105579ms)
Feb 17 16:42:23.478: INFO: (14) /api/v1/namespaces/proxy-4830/pods/http:proxy-service-2txl9-4j5r2:160/proxy/: foo (200; 31.257384ms)
Feb 17 16:42:23.478: INFO: (14) /api/v1/namespaces/proxy-4830/pods/https:proxy-service-2txl9-4j5r2:462/proxy/: tls qux (200; 32.020595ms)
Feb 17 16:42:23.478: INFO: (14) /api/v1/namespaces/proxy-4830/pods/proxy-service-2txl9-4j5r2:1080/proxy/: <a href="/api/v1/namespaces/proxy-4830/pods/proxy-service-2txl9-4j5r2:1080/proxy/rewriteme">test<... (200; 31.188423ms)
Feb 17 16:42:23.478: INFO: (14) /api/v1/namespaces/proxy-4830/pods/proxy-service-2txl9-4j5r2/proxy/: <a href="/api/v1/namespaces/proxy-4830/pods/proxy-service-2txl9-4j5r2/proxy/rewriteme">test</a> (200; 31.541889ms)
Feb 17 16:42:23.478: INFO: (14) /api/v1/namespaces/proxy-4830/pods/https:proxy-service-2txl9-4j5r2:443/proxy/: <a href="/api/v1/namespaces/proxy-4830/pods/https:proxy-service-2txl9-4j5r2:443/proxy/tlsrewritem... (200; 31.655916ms)
Feb 17 16:42:23.490: INFO: (14) /api/v1/namespaces/proxy-4830/services/proxy-service-2txl9:portname1/proxy/: foo (200; 43.083125ms)
Feb 17 16:42:23.490: INFO: (14) /api/v1/namespaces/proxy-4830/services/https:proxy-service-2txl9:tlsportname2/proxy/: tls qux (200; 43.653241ms)
Feb 17 16:42:23.490: INFO: (14) /api/v1/namespaces/proxy-4830/services/proxy-service-2txl9:portname2/proxy/: bar (200; 43.84612ms)
Feb 17 16:42:23.491: INFO: (14) /api/v1/namespaces/proxy-4830/services/http:proxy-service-2txl9:portname2/proxy/: bar (200; 43.619202ms)
Feb 17 16:42:23.491: INFO: (14) /api/v1/namespaces/proxy-4830/services/http:proxy-service-2txl9:portname1/proxy/: foo (200; 44.35291ms)
Feb 17 16:42:23.491: INFO: (14) /api/v1/namespaces/proxy-4830/services/https:proxy-service-2txl9:tlsportname1/proxy/: tls baz (200; 43.823702ms)
Feb 17 16:42:23.514: INFO: (15) /api/v1/namespaces/proxy-4830/pods/http:proxy-service-2txl9-4j5r2:1080/proxy/: <a href="/api/v1/namespaces/proxy-4830/pods/http:proxy-service-2txl9-4j5r2:1080/proxy/rewriteme">... (200; 22.797488ms)
Feb 17 16:42:23.518: INFO: (15) /api/v1/namespaces/proxy-4830/pods/proxy-service-2txl9-4j5r2:1080/proxy/: <a href="/api/v1/namespaces/proxy-4830/pods/proxy-service-2txl9-4j5r2:1080/proxy/rewriteme">test<... (200; 26.068849ms)
Feb 17 16:42:23.518: INFO: (15) /api/v1/namespaces/proxy-4830/pods/https:proxy-service-2txl9-4j5r2:443/proxy/: <a href="/api/v1/namespaces/proxy-4830/pods/https:proxy-service-2txl9-4j5r2:443/proxy/tlsrewritem... (200; 26.823558ms)
Feb 17 16:42:23.519: INFO: (15) /api/v1/namespaces/proxy-4830/pods/http:proxy-service-2txl9-4j5r2:162/proxy/: bar (200; 26.322192ms)
Feb 17 16:42:23.519: INFO: (15) /api/v1/namespaces/proxy-4830/pods/http:proxy-service-2txl9-4j5r2:160/proxy/: foo (200; 26.777504ms)
Feb 17 16:42:23.519: INFO: (15) /api/v1/namespaces/proxy-4830/pods/proxy-service-2txl9-4j5r2:162/proxy/: bar (200; 26.864648ms)
Feb 17 16:42:23.519: INFO: (15) /api/v1/namespaces/proxy-4830/pods/proxy-service-2txl9-4j5r2/proxy/: <a href="/api/v1/namespaces/proxy-4830/pods/proxy-service-2txl9-4j5r2/proxy/rewriteme">test</a> (200; 27.357121ms)
Feb 17 16:42:23.519: INFO: (15) /api/v1/namespaces/proxy-4830/pods/https:proxy-service-2txl9-4j5r2:462/proxy/: tls qux (200; 26.826625ms)
Feb 17 16:42:23.519: INFO: (15) /api/v1/namespaces/proxy-4830/pods/https:proxy-service-2txl9-4j5r2:460/proxy/: tls baz (200; 28.09483ms)
Feb 17 16:42:23.519: INFO: (15) /api/v1/namespaces/proxy-4830/pods/proxy-service-2txl9-4j5r2:160/proxy/: foo (200; 27.427779ms)
Feb 17 16:42:23.526: INFO: (15) /api/v1/namespaces/proxy-4830/services/proxy-service-2txl9:portname2/proxy/: bar (200; 35.151505ms)
Feb 17 16:42:23.528: INFO: (15) /api/v1/namespaces/proxy-4830/services/https:proxy-service-2txl9:tlsportname2/proxy/: tls qux (200; 36.832ms)
Feb 17 16:42:23.528: INFO: (15) /api/v1/namespaces/proxy-4830/services/https:proxy-service-2txl9:tlsportname1/proxy/: tls baz (200; 37.064805ms)
Feb 17 16:42:23.529: INFO: (15) /api/v1/namespaces/proxy-4830/services/http:proxy-service-2txl9:portname1/proxy/: foo (200; 37.710948ms)
Feb 17 16:42:23.529: INFO: (15) /api/v1/namespaces/proxy-4830/services/proxy-service-2txl9:portname1/proxy/: foo (200; 37.38021ms)
Feb 17 16:42:23.529: INFO: (15) /api/v1/namespaces/proxy-4830/services/http:proxy-service-2txl9:portname2/proxy/: bar (200; 37.348976ms)
Feb 17 16:42:23.552: INFO: (16) /api/v1/namespaces/proxy-4830/pods/http:proxy-service-2txl9-4j5r2:162/proxy/: bar (200; 22.363119ms)
Feb 17 16:42:23.557: INFO: (16) /api/v1/namespaces/proxy-4830/pods/proxy-service-2txl9-4j5r2:160/proxy/: foo (200; 26.897026ms)
Feb 17 16:42:23.557: INFO: (16) /api/v1/namespaces/proxy-4830/pods/http:proxy-service-2txl9-4j5r2:1080/proxy/: <a href="/api/v1/namespaces/proxy-4830/pods/http:proxy-service-2txl9-4j5r2:1080/proxy/rewriteme">... (200; 26.671109ms)
Feb 17 16:42:23.557: INFO: (16) /api/v1/namespaces/proxy-4830/pods/proxy-service-2txl9-4j5r2:1080/proxy/: <a href="/api/v1/namespaces/proxy-4830/pods/proxy-service-2txl9-4j5r2:1080/proxy/rewriteme">test<... (200; 27.422712ms)
Feb 17 16:42:23.558: INFO: (16) /api/v1/namespaces/proxy-4830/pods/http:proxy-service-2txl9-4j5r2:160/proxy/: foo (200; 27.232251ms)
Feb 17 16:42:23.558: INFO: (16) /api/v1/namespaces/proxy-4830/pods/https:proxy-service-2txl9-4j5r2:460/proxy/: tls baz (200; 27.471092ms)
Feb 17 16:42:23.558: INFO: (16) /api/v1/namespaces/proxy-4830/pods/proxy-service-2txl9-4j5r2:162/proxy/: bar (200; 27.264051ms)
Feb 17 16:42:23.558: INFO: (16) /api/v1/namespaces/proxy-4830/pods/https:proxy-service-2txl9-4j5r2:443/proxy/: <a href="/api/v1/namespaces/proxy-4830/pods/https:proxy-service-2txl9-4j5r2:443/proxy/tlsrewritem... (200; 27.726942ms)
Feb 17 16:42:23.558: INFO: (16) /api/v1/namespaces/proxy-4830/pods/https:proxy-service-2txl9-4j5r2:462/proxy/: tls qux (200; 28.33677ms)
Feb 17 16:42:23.559: INFO: (16) /api/v1/namespaces/proxy-4830/pods/proxy-service-2txl9-4j5r2/proxy/: <a href="/api/v1/namespaces/proxy-4830/pods/proxy-service-2txl9-4j5r2/proxy/rewriteme">test</a> (200; 29.071742ms)
Feb 17 16:42:23.565: INFO: (16) /api/v1/namespaces/proxy-4830/services/http:proxy-service-2txl9:portname1/proxy/: foo (200; 34.698056ms)
Feb 17 16:42:23.571: INFO: (16) /api/v1/namespaces/proxy-4830/services/http:proxy-service-2txl9:portname2/proxy/: bar (200; 40.74084ms)
Feb 17 16:42:23.571: INFO: (16) /api/v1/namespaces/proxy-4830/services/proxy-service-2txl9:portname2/proxy/: bar (200; 41.202627ms)
Feb 17 16:42:23.571: INFO: (16) /api/v1/namespaces/proxy-4830/services/proxy-service-2txl9:portname1/proxy/: foo (200; 40.705297ms)
Feb 17 16:42:23.571: INFO: (16) /api/v1/namespaces/proxy-4830/services/https:proxy-service-2txl9:tlsportname2/proxy/: tls qux (200; 41.325905ms)
Feb 17 16:42:23.571: INFO: (16) /api/v1/namespaces/proxy-4830/services/https:proxy-service-2txl9:tlsportname1/proxy/: tls baz (200; 41.599517ms)
Feb 17 16:42:23.592: INFO: (17) /api/v1/namespaces/proxy-4830/pods/proxy-service-2txl9-4j5r2:162/proxy/: bar (200; 20.136422ms)
Feb 17 16:42:23.601: INFO: (17) /api/v1/namespaces/proxy-4830/pods/proxy-service-2txl9-4j5r2/proxy/: <a href="/api/v1/namespaces/proxy-4830/pods/proxy-service-2txl9-4j5r2/proxy/rewriteme">test</a> (200; 29.419207ms)
Feb 17 16:42:23.601: INFO: (17) /api/v1/namespaces/proxy-4830/pods/proxy-service-2txl9-4j5r2:160/proxy/: foo (200; 29.235395ms)
Feb 17 16:42:23.602: INFO: (17) /api/v1/namespaces/proxy-4830/pods/https:proxy-service-2txl9-4j5r2:462/proxy/: tls qux (200; 29.853051ms)
Feb 17 16:42:23.602: INFO: (17) /api/v1/namespaces/proxy-4830/pods/https:proxy-service-2txl9-4j5r2:460/proxy/: tls baz (200; 29.732079ms)
Feb 17 16:42:23.602: INFO: (17) /api/v1/namespaces/proxy-4830/pods/proxy-service-2txl9-4j5r2:1080/proxy/: <a href="/api/v1/namespaces/proxy-4830/pods/proxy-service-2txl9-4j5r2:1080/proxy/rewriteme">test<... (200; 29.666711ms)
Feb 17 16:42:23.602: INFO: (17) /api/v1/namespaces/proxy-4830/pods/https:proxy-service-2txl9-4j5r2:443/proxy/: <a href="/api/v1/namespaces/proxy-4830/pods/https:proxy-service-2txl9-4j5r2:443/proxy/tlsrewritem... (200; 30.39992ms)
Feb 17 16:42:23.602: INFO: (17) /api/v1/namespaces/proxy-4830/pods/http:proxy-service-2txl9-4j5r2:1080/proxy/: <a href="/api/v1/namespaces/proxy-4830/pods/http:proxy-service-2txl9-4j5r2:1080/proxy/rewriteme">... (200; 29.879564ms)
Feb 17 16:42:23.602: INFO: (17) /api/v1/namespaces/proxy-4830/pods/http:proxy-service-2txl9-4j5r2:160/proxy/: foo (200; 30.483921ms)
Feb 17 16:42:23.603: INFO: (17) /api/v1/namespaces/proxy-4830/pods/http:proxy-service-2txl9-4j5r2:162/proxy/: bar (200; 31.361858ms)
Feb 17 16:42:23.604: INFO: (17) /api/v1/namespaces/proxy-4830/services/https:proxy-service-2txl9:tlsportname1/proxy/: tls baz (200; 31.738243ms)
Feb 17 16:42:23.609: INFO: (17) /api/v1/namespaces/proxy-4830/services/proxy-service-2txl9:portname1/proxy/: foo (200; 37.629326ms)
Feb 17 16:42:23.612: INFO: (17) /api/v1/namespaces/proxy-4830/services/http:proxy-service-2txl9:portname2/proxy/: bar (200; 39.652625ms)
Feb 17 16:42:23.612: INFO: (17) /api/v1/namespaces/proxy-4830/services/proxy-service-2txl9:portname2/proxy/: bar (200; 39.901694ms)
Feb 17 16:42:23.612: INFO: (17) /api/v1/namespaces/proxy-4830/services/https:proxy-service-2txl9:tlsportname2/proxy/: tls qux (200; 40.115645ms)
Feb 17 16:42:23.613: INFO: (17) /api/v1/namespaces/proxy-4830/services/http:proxy-service-2txl9:portname1/proxy/: foo (200; 40.152326ms)
Feb 17 16:42:23.634: INFO: (18) /api/v1/namespaces/proxy-4830/pods/http:proxy-service-2txl9-4j5r2:160/proxy/: foo (200; 21.374003ms)
Feb 17 16:42:23.640: INFO: (18) /api/v1/namespaces/proxy-4830/pods/https:proxy-service-2txl9-4j5r2:462/proxy/: tls qux (200; 26.599471ms)
Feb 17 16:42:23.640: INFO: (18) /api/v1/namespaces/proxy-4830/pods/https:proxy-service-2txl9-4j5r2:443/proxy/: <a href="/api/v1/namespaces/proxy-4830/pods/https:proxy-service-2txl9-4j5r2:443/proxy/tlsrewritem... (200; 27.477683ms)
Feb 17 16:42:23.640: INFO: (18) /api/v1/namespaces/proxy-4830/pods/https:proxy-service-2txl9-4j5r2:460/proxy/: tls baz (200; 26.631641ms)
Feb 17 16:42:23.641: INFO: (18) /api/v1/namespaces/proxy-4830/pods/http:proxy-service-2txl9-4j5r2:162/proxy/: bar (200; 27.063786ms)
Feb 17 16:42:23.641: INFO: (18) /api/v1/namespaces/proxy-4830/pods/proxy-service-2txl9-4j5r2:1080/proxy/: <a href="/api/v1/namespaces/proxy-4830/pods/proxy-service-2txl9-4j5r2:1080/proxy/rewriteme">test<... (200; 26.841661ms)
Feb 17 16:42:23.641: INFO: (18) /api/v1/namespaces/proxy-4830/pods/proxy-service-2txl9-4j5r2:162/proxy/: bar (200; 27.539836ms)
Feb 17 16:42:23.641: INFO: (18) /api/v1/namespaces/proxy-4830/pods/http:proxy-service-2txl9-4j5r2:1080/proxy/: <a href="/api/v1/namespaces/proxy-4830/pods/http:proxy-service-2txl9-4j5r2:1080/proxy/rewriteme">... (200; 27.211237ms)
Feb 17 16:42:23.642: INFO: (18) /api/v1/namespaces/proxy-4830/pods/proxy-service-2txl9-4j5r2:160/proxy/: foo (200; 28.517991ms)
Feb 17 16:42:23.642: INFO: (18) /api/v1/namespaces/proxy-4830/pods/proxy-service-2txl9-4j5r2/proxy/: <a href="/api/v1/namespaces/proxy-4830/pods/proxy-service-2txl9-4j5r2/proxy/rewriteme">test</a> (200; 28.333866ms)
Feb 17 16:42:23.648: INFO: (18) /api/v1/namespaces/proxy-4830/services/proxy-service-2txl9:portname1/proxy/: foo (200; 34.95178ms)
Feb 17 16:42:23.658: INFO: (18) /api/v1/namespaces/proxy-4830/services/https:proxy-service-2txl9:tlsportname2/proxy/: tls qux (200; 45.513689ms)
Feb 17 16:42:23.658: INFO: (18) /api/v1/namespaces/proxy-4830/services/https:proxy-service-2txl9:tlsportname1/proxy/: tls baz (200; 45.114132ms)
Feb 17 16:42:23.659: INFO: (18) /api/v1/namespaces/proxy-4830/services/http:proxy-service-2txl9:portname2/proxy/: bar (200; 44.973593ms)
Feb 17 16:42:23.659: INFO: (18) /api/v1/namespaces/proxy-4830/services/http:proxy-service-2txl9:portname1/proxy/: foo (200; 44.856343ms)
Feb 17 16:42:23.659: INFO: (18) /api/v1/namespaces/proxy-4830/services/proxy-service-2txl9:portname2/proxy/: bar (200; 45.519141ms)
Feb 17 16:42:23.679: INFO: (19) /api/v1/namespaces/proxy-4830/pods/http:proxy-service-2txl9-4j5r2:160/proxy/: foo (200; 19.983805ms)
Feb 17 16:42:23.686: INFO: (19) /api/v1/namespaces/proxy-4830/pods/http:proxy-service-2txl9-4j5r2:162/proxy/: bar (200; 25.517418ms)
Feb 17 16:42:23.687: INFO: (19) /api/v1/namespaces/proxy-4830/pods/http:proxy-service-2txl9-4j5r2:1080/proxy/: <a href="/api/v1/namespaces/proxy-4830/pods/http:proxy-service-2txl9-4j5r2:1080/proxy/rewriteme">... (200; 27.131007ms)
Feb 17 16:42:23.687: INFO: (19) /api/v1/namespaces/proxy-4830/pods/https:proxy-service-2txl9-4j5r2:460/proxy/: tls baz (200; 27.208533ms)
Feb 17 16:42:23.688: INFO: (19) /api/v1/namespaces/proxy-4830/pods/proxy-service-2txl9-4j5r2:162/proxy/: bar (200; 27.902759ms)
Feb 17 16:42:23.688: INFO: (19) /api/v1/namespaces/proxy-4830/pods/proxy-service-2txl9-4j5r2:1080/proxy/: <a href="/api/v1/namespaces/proxy-4830/pods/proxy-service-2txl9-4j5r2:1080/proxy/rewriteme">test<... (200; 28.515817ms)
Feb 17 16:42:23.688: INFO: (19) /api/v1/namespaces/proxy-4830/pods/proxy-service-2txl9-4j5r2:160/proxy/: foo (200; 27.983648ms)
Feb 17 16:42:23.689: INFO: (19) /api/v1/namespaces/proxy-4830/pods/https:proxy-service-2txl9-4j5r2:443/proxy/: <a href="/api/v1/namespaces/proxy-4830/pods/https:proxy-service-2txl9-4j5r2:443/proxy/tlsrewritem... (200; 29.265394ms)
Feb 17 16:42:23.689: INFO: (19) /api/v1/namespaces/proxy-4830/pods/https:proxy-service-2txl9-4j5r2:462/proxy/: tls qux (200; 28.786612ms)
Feb 17 16:42:23.689: INFO: (19) /api/v1/namespaces/proxy-4830/pods/proxy-service-2txl9-4j5r2/proxy/: <a href="/api/v1/namespaces/proxy-4830/pods/proxy-service-2txl9-4j5r2/proxy/rewriteme">test</a> (200; 29.15581ms)
Feb 17 16:42:23.693: INFO: (19) /api/v1/namespaces/proxy-4830/services/http:proxy-service-2txl9:portname2/proxy/: bar (200; 34.3973ms)
Feb 17 16:42:23.698: INFO: (19) /api/v1/namespaces/proxy-4830/services/https:proxy-service-2txl9:tlsportname2/proxy/: tls qux (200; 37.948847ms)
Feb 17 16:42:23.698: INFO: (19) /api/v1/namespaces/proxy-4830/services/http:proxy-service-2txl9:portname1/proxy/: foo (200; 38.339875ms)
Feb 17 16:42:23.699: INFO: (19) /api/v1/namespaces/proxy-4830/services/proxy-service-2txl9:portname2/proxy/: bar (200; 38.550824ms)
Feb 17 16:42:23.699: INFO: (19) /api/v1/namespaces/proxy-4830/services/https:proxy-service-2txl9:tlsportname1/proxy/: tls baz (200; 38.739508ms)
Feb 17 16:42:23.699: INFO: (19) /api/v1/namespaces/proxy-4830/services/proxy-service-2txl9:portname1/proxy/: foo (200; 38.714349ms)
STEP: deleting ReplicationController proxy-service-2txl9 in namespace proxy-4830, will wait for the garbage collector to delete the pods
Feb 17 16:42:23.796: INFO: Deleting ReplicationController proxy-service-2txl9 took: 35.258507ms
Feb 17 16:42:23.997: INFO: Terminating ReplicationController proxy-service-2txl9 pods took: 200.337333ms
[AfterEach] version v1
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 16:42:28.997: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-4830" for this suite.
Feb 17 16:42:35.066: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:42:35.486: INFO: namespace proxy-4830 deletion completed in 6.470549115s

• [SLOW TEST:21.235 seconds]
[sig-network] Proxy
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:58
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 16:42:35.488: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5099
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-map-2129e33e-dc14-4222-9a48-9bebfad8a2a1
STEP: Creating a pod to test consume secrets
Feb 17 16:42:35.782: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-f9ef9292-92cd-42d2-8c12-10abbe787d78" in namespace "projected-5099" to be "success or failure"
Feb 17 16:42:35.793: INFO: Pod "pod-projected-secrets-f9ef9292-92cd-42d2-8c12-10abbe787d78": Phase="Pending", Reason="", readiness=false. Elapsed: 11.411123ms
Feb 17 16:42:37.804: INFO: Pod "pod-projected-secrets-f9ef9292-92cd-42d2-8c12-10abbe787d78": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0227997s
Feb 17 16:42:39.816: INFO: Pod "pod-projected-secrets-f9ef9292-92cd-42d2-8c12-10abbe787d78": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.034671046s
STEP: Saw pod success
Feb 17 16:42:39.816: INFO: Pod "pod-projected-secrets-f9ef9292-92cd-42d2-8c12-10abbe787d78" satisfied condition "success or failure"
Feb 17 16:42:39.828: INFO: Trying to get logs from node 10.242.0.59 pod pod-projected-secrets-f9ef9292-92cd-42d2-8c12-10abbe787d78 container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb 17 16:42:39.892: INFO: Waiting for pod pod-projected-secrets-f9ef9292-92cd-42d2-8c12-10abbe787d78 to disappear
Feb 17 16:42:39.903: INFO: Pod pod-projected-secrets-f9ef9292-92cd-42d2-8c12-10abbe787d78 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 16:42:39.903: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5099" for this suite.
Feb 17 16:42:45.975: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:42:46.377: INFO: namespace projected-5099 deletion completed in 6.454722443s

• [SLOW TEST:10.889 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 16:42:46.379: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-7517
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-5c3b88fd-4545-495b-8c09-9b5e18416760
STEP: Creating a pod to test consume secrets
Feb 17 16:42:46.678: INFO: Waiting up to 5m0s for pod "pod-secrets-87a35de1-9a5e-4259-9d03-e54dd4ace316" in namespace "secrets-7517" to be "success or failure"
Feb 17 16:42:46.692: INFO: Pod "pod-secrets-87a35de1-9a5e-4259-9d03-e54dd4ace316": Phase="Pending", Reason="", readiness=false. Elapsed: 14.109009ms
Feb 17 16:42:48.705: INFO: Pod "pod-secrets-87a35de1-9a5e-4259-9d03-e54dd4ace316": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.026518721s
STEP: Saw pod success
Feb 17 16:42:48.705: INFO: Pod "pod-secrets-87a35de1-9a5e-4259-9d03-e54dd4ace316" satisfied condition "success or failure"
Feb 17 16:42:48.715: INFO: Trying to get logs from node 10.242.0.98 pod pod-secrets-87a35de1-9a5e-4259-9d03-e54dd4ace316 container secret-env-test: <nil>
STEP: delete the pod
Feb 17 16:42:48.790: INFO: Waiting for pod pod-secrets-87a35de1-9a5e-4259-9d03-e54dd4ace316 to disappear
Feb 17 16:42:48.801: INFO: Pod pod-secrets-87a35de1-9a5e-4259-9d03-e54dd4ace316 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 16:42:48.801: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7517" for this suite.
Feb 17 16:42:54.874: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:42:55.266: INFO: namespace secrets-7517 deletion completed in 6.44323078s

• [SLOW TEST:8.888 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 16:42:55.267: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-2425
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0666 on tmpfs
Feb 17 16:42:55.537: INFO: Waiting up to 5m0s for pod "pod-c4c5a64b-7c98-4c0b-819c-3ab90591206a" in namespace "emptydir-2425" to be "success or failure"
Feb 17 16:42:55.549: INFO: Pod "pod-c4c5a64b-7c98-4c0b-819c-3ab90591206a": Phase="Pending", Reason="", readiness=false. Elapsed: 11.666232ms
Feb 17 16:42:57.560: INFO: Pod "pod-c4c5a64b-7c98-4c0b-819c-3ab90591206a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.023332502s
STEP: Saw pod success
Feb 17 16:42:57.561: INFO: Pod "pod-c4c5a64b-7c98-4c0b-819c-3ab90591206a" satisfied condition "success or failure"
Feb 17 16:42:57.571: INFO: Trying to get logs from node 10.242.0.59 pod pod-c4c5a64b-7c98-4c0b-819c-3ab90591206a container test-container: <nil>
STEP: delete the pod
Feb 17 16:42:57.636: INFO: Waiting for pod pod-c4c5a64b-7c98-4c0b-819c-3ab90591206a to disappear
Feb 17 16:42:57.647: INFO: Pod pod-c4c5a64b-7c98-4c0b-819c-3ab90591206a no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 16:42:57.647: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2425" for this suite.
Feb 17 16:43:03.721: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:43:04.197: INFO: namespace emptydir-2425 deletion completed in 6.524107973s

• [SLOW TEST:8.930 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 16:43:04.198: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-8249
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1557
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb 17 16:43:04.462: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-079603707 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --generator=deployment/apps.v1 --namespace=kubectl-8249'
Feb 17 16:43:04.752: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Feb 17 16:43:04.752: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the deployment e2e-test-nginx-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1562
Feb 17 16:43:08.788: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-079603707 delete deployment e2e-test-nginx-deployment --namespace=kubectl-8249'
Feb 17 16:43:08.971: INFO: stderr: ""
Feb 17 16:43:08.971: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 16:43:08.971: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8249" for this suite.
Feb 17 16:43:33.037: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:43:33.433: INFO: namespace kubectl-8249 deletion completed in 24.444341221s

• [SLOW TEST:29.236 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run deployment
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 16:43:33.438: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7863
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-map-05df5b2f-5f64-4bc1-ad95-a5cd5aaeb1b5
STEP: Creating a pod to test consume configMaps
Feb 17 16:43:33.728: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-3b3e82c0-1710-43dd-980e-2e82e1022367" in namespace "projected-7863" to be "success or failure"
Feb 17 16:43:33.741: INFO: Pod "pod-projected-configmaps-3b3e82c0-1710-43dd-980e-2e82e1022367": Phase="Pending", Reason="", readiness=false. Elapsed: 12.717462ms
Feb 17 16:43:35.752: INFO: Pod "pod-projected-configmaps-3b3e82c0-1710-43dd-980e-2e82e1022367": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.023966286s
STEP: Saw pod success
Feb 17 16:43:35.752: INFO: Pod "pod-projected-configmaps-3b3e82c0-1710-43dd-980e-2e82e1022367" satisfied condition "success or failure"
Feb 17 16:43:35.764: INFO: Trying to get logs from node 10.242.0.59 pod pod-projected-configmaps-3b3e82c0-1710-43dd-980e-2e82e1022367 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 17 16:43:35.827: INFO: Waiting for pod pod-projected-configmaps-3b3e82c0-1710-43dd-980e-2e82e1022367 to disappear
Feb 17 16:43:35.838: INFO: Pod pod-projected-configmaps-3b3e82c0-1710-43dd-980e-2e82e1022367 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 16:43:35.838: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7863" for this suite.
Feb 17 16:43:41.915: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:43:42.320: INFO: namespace projected-7863 deletion completed in 6.454682188s

• [SLOW TEST:8.882 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 16:43:42.322: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-6218
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Feb 17 16:43:42.605: INFO: Pod name pod-release: Found 0 pods out of 1
Feb 17 16:43:47.617: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 16:43:47.660: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-6218" for this suite.
Feb 17 16:43:53.735: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:43:54.148: INFO: namespace replication-controller-6218 deletion completed in 6.467983986s

• [SLOW TEST:11.826 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 16:43:54.149: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-2124
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Feb 17 16:43:54.426: INFO: Creating deployment "nginx-deployment"
Feb 17 16:43:54.442: INFO: Waiting for observed generation 1
Feb 17 16:43:56.467: INFO: Waiting for all required pods to come up
Feb 17 16:43:56.481: INFO: Pod name nginx: Found 10 pods out of 10
STEP: ensuring each pod is running
Feb 17 16:43:58.518: INFO: Waiting for deployment "nginx-deployment" to complete
Feb 17 16:43:58.542: INFO: Updating deployment "nginx-deployment" with a non-existent image
Feb 17 16:43:58.570: INFO: Updating deployment nginx-deployment
Feb 17 16:43:58.570: INFO: Waiting for observed generation 2
Feb 17 16:44:00.596: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Feb 17 16:44:00.606: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Feb 17 16:44:00.616: INFO: Waiting for the first rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Feb 17 16:44:00.647: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Feb 17 16:44:00.647: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Feb 17 16:44:00.658: INFO: Waiting for the second rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Feb 17 16:44:00.678: INFO: Verifying that deployment "nginx-deployment" has minimum required number of available replicas
Feb 17 16:44:00.678: INFO: Scaling up the deployment "nginx-deployment" from 10 to 30
Feb 17 16:44:00.711: INFO: Updating deployment nginx-deployment
Feb 17 16:44:00.711: INFO: Waiting for the replicasets of deployment "nginx-deployment" to have desired number of replicas
Feb 17 16:44:00.732: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Feb 17 16:44:00.745: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
Feb 17 16:44:00.774: INFO: Deployment "nginx-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment,GenerateName:,Namespace:deployment-2124,SelfLink:/apis/apps/v1/namespaces/deployment-2124/deployments/nginx-deployment,UID:8aadb274-26da-4314-8ca7-595eb597b8d7,ResourceVersion:25569,Generation:3,CreationTimestamp:2020-02-17 16:43:54 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*30,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:13,UpdatedReplicas:5,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[{Progressing True 2020-02-17 16:43:58 +0000 UTC 2020-02-17 16:43:54 +0000 UTC ReplicaSetUpdated ReplicaSet "nginx-deployment-55fb7cb77f" is progressing.} {Available False 2020-02-17 16:44:00 +0000 UTC 2020-02-17 16:44:00 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}],ReadyReplicas:8,CollisionCount:nil,},}

Feb 17 16:44:00.790: INFO: New ReplicaSet "nginx-deployment-55fb7cb77f" of Deployment "nginx-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f,GenerateName:,Namespace:deployment-2124,SelfLink:/apis/apps/v1/namespaces/deployment-2124/replicasets/nginx-deployment-55fb7cb77f,UID:616d100b-65e3-4194-a4ba-937b9cd0c803,ResourceVersion:25550,Generation:3,CreationTimestamp:2020-02-17 16:43:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 8aadb274-26da-4314-8ca7-595eb597b8d7 0xc002d8f8d7 0xc002d8f8d8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*13,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:5,FullyLabeledReplicas:5,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Feb 17 16:44:00.790: INFO: All old ReplicaSets of Deployment "nginx-deployment":
Feb 17 16:44:00.790: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498,GenerateName:,Namespace:deployment-2124,SelfLink:/apis/apps/v1/namespaces/deployment-2124/replicasets/nginx-deployment-7b8c6f4498,UID:31a335ff-3928-438a-8368-6070b14ddce7,ResourceVersion:25549,Generation:3,CreationTimestamp:2020-02-17 16:43:54 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 8aadb274-26da-4314-8ca7-595eb597b8d7 0xc002d8f9a7 0xc002d8f9a8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*20,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:8,FullyLabeledReplicas:8,ObservedGeneration:2,ReadyReplicas:8,AvailableReplicas:8,Conditions:[],},}
Feb 17 16:44:00.815: INFO: Pod "nginx-deployment-55fb7cb77f-4njm8" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-4njm8,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-2124,SelfLink:/api/v1/namespaces/deployment-2124/pods/nginx-deployment-55fb7cb77f-4njm8,UID:b449e65b-6c0a-473a-9a25-2e9b95861e50,ResourceVersion:25486,Generation:0,CreationTimestamp:2020-02-17 16:43:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 616d100b-65e3-4194-a4ba-937b9cd0c803 0xc003f98337 0xc003f98338}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-tvc2g {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tvc2g,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-tvc2g true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.242.0.63,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003f983b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003f983d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:43:58 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:43:58 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:43:58 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:43:58 +0000 UTC  }],Message:,Reason:,HostIP:10.242.0.63,PodIP:,StartTime:2020-02-17 16:43:58 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 17 16:44:00.815: INFO: Pod "nginx-deployment-55fb7cb77f-4skz4" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-4skz4,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-2124,SelfLink:/api/v1/namespaces/deployment-2124/pods/nginx-deployment-55fb7cb77f-4skz4,UID:e54287cd-c65c-41ab-940a-5f9f53c883a2,ResourceVersion:25560,Generation:0,CreationTimestamp:2020-02-17 16:44:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 616d100b-65e3-4194-a4ba-937b9cd0c803 0xc003f984a0 0xc003f984a1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-tvc2g {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tvc2g,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-tvc2g true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.242.0.59,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003f98520} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003f98540}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:44:00 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 17 16:44:00.815: INFO: Pod "nginx-deployment-55fb7cb77f-5mpc9" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-5mpc9,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-2124,SelfLink:/api/v1/namespaces/deployment-2124/pods/nginx-deployment-55fb7cb77f-5mpc9,UID:7679a858-4190-4f09-bdc7-002e4c1bcb7a,ResourceVersion:25497,Generation:0,CreationTimestamp:2020-02-17 16:43:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 616d100b-65e3-4194-a4ba-937b9cd0c803 0xc003f985c0 0xc003f985c1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-tvc2g {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tvc2g,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-tvc2g true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.242.0.59,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003f98640} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003f98660}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:43:58 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:43:58 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:43:58 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:43:58 +0000 UTC  }],Message:,Reason:,HostIP:10.242.0.59,PodIP:,StartTime:2020-02-17 16:43:58 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 17 16:44:00.816: INFO: Pod "nginx-deployment-55fb7cb77f-8wjgb" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-8wjgb,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-2124,SelfLink:/api/v1/namespaces/deployment-2124/pods/nginx-deployment-55fb7cb77f-8wjgb,UID:19fcf7d6-89b7-40bf-8bf3-766a8ea2a279,ResourceVersion:25493,Generation:0,CreationTimestamp:2020-02-17 16:43:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 616d100b-65e3-4194-a4ba-937b9cd0c803 0xc003f98730 0xc003f98731}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-tvc2g {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tvc2g,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-tvc2g true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.242.0.98,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003f987b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003f987d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:43:58 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:43:58 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:43:58 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:43:58 +0000 UTC  }],Message:,Reason:,HostIP:10.242.0.98,PodIP:,StartTime:2020-02-17 16:43:58 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 17 16:44:00.816: INFO: Pod "nginx-deployment-55fb7cb77f-9ss67" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-9ss67,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-2124,SelfLink:/api/v1/namespaces/deployment-2124/pods/nginx-deployment-55fb7cb77f-9ss67,UID:5e019260-720c-4005-bfad-c0326e33fd02,ResourceVersion:25603,Generation:0,CreationTimestamp:2020-02-17 16:44:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 616d100b-65e3-4194-a4ba-937b9cd0c803 0xc003f988a0 0xc003f988a1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-tvc2g {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tvc2g,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-tvc2g true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.242.0.98,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003f98920} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003f98940}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:44:00 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 17 16:44:00.816: INFO: Pod "nginx-deployment-55fb7cb77f-fjndm" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-fjndm,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-2124,SelfLink:/api/v1/namespaces/deployment-2124/pods/nginx-deployment-55fb7cb77f-fjndm,UID:08504622-1634-42e8-b8c2-cd9359821483,ResourceVersion:25510,Generation:0,CreationTimestamp:2020-02-17 16:43:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 616d100b-65e3-4194-a4ba-937b9cd0c803 0xc003f989c0 0xc003f989c1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-tvc2g {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tvc2g,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-tvc2g true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.242.0.98,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003f98a40} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003f98a70}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:43:58 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:43:58 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:43:58 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:43:58 +0000 UTC  }],Message:,Reason:,HostIP:10.242.0.98,PodIP:,StartTime:2020-02-17 16:43:58 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 17 16:44:00.816: INFO: Pod "nginx-deployment-55fb7cb77f-gjh8b" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-gjh8b,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-2124,SelfLink:/api/v1/namespaces/deployment-2124/pods/nginx-deployment-55fb7cb77f-gjh8b,UID:f631814c-b159-438f-981b-a9d2f026b39c,ResourceVersion:25602,Generation:0,CreationTimestamp:2020-02-17 16:44:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 616d100b-65e3-4194-a4ba-937b9cd0c803 0xc003f98b40 0xc003f98b41}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-tvc2g {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tvc2g,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-tvc2g true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003f98bb0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003f98bd0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 17 16:44:00.816: INFO: Pod "nginx-deployment-55fb7cb77f-jwh24" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-jwh24,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-2124,SelfLink:/api/v1/namespaces/deployment-2124/pods/nginx-deployment-55fb7cb77f-jwh24,UID:bea4b067-dec2-41c5-b6b4-fe4096b46cd1,ResourceVersion:25604,Generation:0,CreationTimestamp:2020-02-17 16:44:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 616d100b-65e3-4194-a4ba-937b9cd0c803 0xc003f98c37 0xc003f98c38}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-tvc2g {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tvc2g,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-tvc2g true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.242.0.59,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003f98cb0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003f98cd0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:44:00 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 17 16:44:00.816: INFO: Pod "nginx-deployment-55fb7cb77f-rt9c8" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-rt9c8,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-2124,SelfLink:/api/v1/namespaces/deployment-2124/pods/nginx-deployment-55fb7cb77f-rt9c8,UID:127c2e03-9a93-460f-8121-860de52be472,ResourceVersion:25601,Generation:0,CreationTimestamp:2020-02-17 16:44:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 616d100b-65e3-4194-a4ba-937b9cd0c803 0xc003f98d50 0xc003f98d51}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-tvc2g {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tvc2g,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-tvc2g true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.242.0.63,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003f98dd0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003f98df0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:44:00 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 17 16:44:00.816: INFO: Pod "nginx-deployment-55fb7cb77f-sfwsj" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-sfwsj,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-2124,SelfLink:/api/v1/namespaces/deployment-2124/pods/nginx-deployment-55fb7cb77f-sfwsj,UID:4fdc82b3-9d4d-4836-b232-7e197292b55d,ResourceVersion:25572,Generation:0,CreationTimestamp:2020-02-17 16:44:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 616d100b-65e3-4194-a4ba-937b9cd0c803 0xc003f98e80 0xc003f98e81}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-tvc2g {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tvc2g,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-tvc2g true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.242.0.63,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003f98f00} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003f98f20}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:44:00 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 17 16:44:00.817: INFO: Pod "nginx-deployment-55fb7cb77f-t6jk2" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-t6jk2,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-2124,SelfLink:/api/v1/namespaces/deployment-2124/pods/nginx-deployment-55fb7cb77f-t6jk2,UID:47ee6ab5-874b-4f0d-9838-795310ef78eb,ResourceVersion:25574,Generation:0,CreationTimestamp:2020-02-17 16:44:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 616d100b-65e3-4194-a4ba-937b9cd0c803 0xc003f98fa0 0xc003f98fa1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-tvc2g {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tvc2g,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-tvc2g true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.242.0.98,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003f99020} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003f99040}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:44:00 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 17 16:44:00.817: INFO: Pod "nginx-deployment-55fb7cb77f-w5s9s" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-w5s9s,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-2124,SelfLink:/api/v1/namespaces/deployment-2124/pods/nginx-deployment-55fb7cb77f-w5s9s,UID:3148d35c-3b33-4ef9-b618-1af4706beea5,ResourceVersion:25595,Generation:0,CreationTimestamp:2020-02-17 16:44:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 616d100b-65e3-4194-a4ba-937b9cd0c803 0xc003f990c0 0xc003f990c1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-tvc2g {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tvc2g,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-tvc2g true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.242.0.59,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003f99140} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003f99160}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:44:00 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 17 16:44:00.817: INFO: Pod "nginx-deployment-55fb7cb77f-wbzrz" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-wbzrz,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-2124,SelfLink:/api/v1/namespaces/deployment-2124/pods/nginx-deployment-55fb7cb77f-wbzrz,UID:735e6f45-b7cb-4ebd-854e-8bca087affe9,ResourceVersion:25511,Generation:0,CreationTimestamp:2020-02-17 16:43:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 616d100b-65e3-4194-a4ba-937b9cd0c803 0xc003f991e0 0xc003f991e1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-tvc2g {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tvc2g,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-tvc2g true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.242.0.63,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003f99260} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003f99280}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:43:58 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:43:58 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:43:58 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:43:58 +0000 UTC  }],Message:,Reason:,HostIP:10.242.0.63,PodIP:,StartTime:2020-02-17 16:43:58 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 17 16:44:00.817: INFO: Pod "nginx-deployment-7b8c6f4498-5s58v" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-5s58v,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-2124,SelfLink:/api/v1/namespaces/deployment-2124/pods/nginx-deployment-7b8c6f4498-5s58v,UID:e9436898-154b-4e59-b60f-8aa403801f69,ResourceVersion:25429,Generation:0,CreationTimestamp:2020-02-17 16:43:54 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 31a335ff-3928-438a-8368-6070b14ddce7 0xc003f99350 0xc003f99351}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-tvc2g {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tvc2g,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-tvc2g true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.242.0.98,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003f993c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003f993e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:43:54 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:43:56 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:43:56 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:43:54 +0000 UTC  }],Message:,Reason:,HostIP:10.242.0.98,PodIP:172.30.197.160,StartTime:2020-02-17 16:43:54 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2020-02-17 16:43:56 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 containerd://3ef5901792daa95e7511628be2d3c4fb0e0aed12c8a342de28adf4760baca5d6}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 17 16:44:00.817: INFO: Pod "nginx-deployment-7b8c6f4498-6dpvj" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-6dpvj,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-2124,SelfLink:/api/v1/namespaces/deployment-2124/pods/nginx-deployment-7b8c6f4498-6dpvj,UID:7d958239-939e-447a-aa59-0660ab93b276,ResourceVersion:25570,Generation:0,CreationTimestamp:2020-02-17 16:44:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 31a335ff-3928-438a-8368-6070b14ddce7 0xc003f994b0 0xc003f994b1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-tvc2g {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tvc2g,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-tvc2g true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.242.0.59,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003f99520} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003f99550}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:44:00 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 17 16:44:00.818: INFO: Pod "nginx-deployment-7b8c6f4498-7l4r2" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-7l4r2,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-2124,SelfLink:/api/v1/namespaces/deployment-2124/pods/nginx-deployment-7b8c6f4498-7l4r2,UID:cd5f9075-81dc-48f7-8381-c92f2cd12cff,ResourceVersion:25593,Generation:0,CreationTimestamp:2020-02-17 16:44:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 31a335ff-3928-438a-8368-6070b14ddce7 0xc003f995d0 0xc003f995d1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-tvc2g {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tvc2g,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-tvc2g true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.242.0.98,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003f99640} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003f99660}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:44:00 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 17 16:44:00.818: INFO: Pod "nginx-deployment-7b8c6f4498-92zmg" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-92zmg,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-2124,SelfLink:/api/v1/namespaces/deployment-2124/pods/nginx-deployment-7b8c6f4498-92zmg,UID:0e58159c-1e7f-4894-9383-ba3016ff695d,ResourceVersion:25438,Generation:0,CreationTimestamp:2020-02-17 16:43:54 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 31a335ff-3928-438a-8368-6070b14ddce7 0xc003f996e0 0xc003f996e1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-tvc2g {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tvc2g,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-tvc2g true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.242.0.63,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003f99750} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003f99770}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:43:54 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:43:56 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:43:56 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:43:54 +0000 UTC  }],Message:,Reason:,HostIP:10.242.0.63,PodIP:172.30.112.94,StartTime:2020-02-17 16:43:54 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2020-02-17 16:43:55 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 containerd://894a43df515fcbdcc76626233cbce664a1bcc821d09cce322d4697af904fbdf8}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 17 16:44:00.818: INFO: Pod "nginx-deployment-7b8c6f4498-brl8w" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-brl8w,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-2124,SelfLink:/api/v1/namespaces/deployment-2124/pods/nginx-deployment-7b8c6f4498-brl8w,UID:5c5ab497-9762-4692-93f0-c329f81e0cb8,ResourceVersion:25578,Generation:0,CreationTimestamp:2020-02-17 16:44:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 31a335ff-3928-438a-8368-6070b14ddce7 0xc003f99840 0xc003f99841}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-tvc2g {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tvc2g,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-tvc2g true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.242.0.98,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003f998b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003f998d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:44:00 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 17 16:44:00.818: INFO: Pod "nginx-deployment-7b8c6f4498-fvcml" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-fvcml,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-2124,SelfLink:/api/v1/namespaces/deployment-2124/pods/nginx-deployment-7b8c6f4498-fvcml,UID:b2a7ca2c-9e63-4f97-a4e6-8436e0e302d5,ResourceVersion:25441,Generation:0,CreationTimestamp:2020-02-17 16:43:54 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 31a335ff-3928-438a-8368-6070b14ddce7 0xc003f99950 0xc003f99951}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-tvc2g {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tvc2g,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-tvc2g true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.242.0.63,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003f999c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003f999e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:43:54 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:43:56 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:43:56 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:43:54 +0000 UTC  }],Message:,Reason:,HostIP:10.242.0.63,PodIP:172.30.112.95,StartTime:2020-02-17 16:43:54 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2020-02-17 16:43:56 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 containerd://b129bb86b22101f74b0cdb1104abea95a5a3e6e4f81e565c05e461890caace95}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 17 16:44:00.818: INFO: Pod "nginx-deployment-7b8c6f4498-gl6mm" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-gl6mm,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-2124,SelfLink:/api/v1/namespaces/deployment-2124/pods/nginx-deployment-7b8c6f4498-gl6mm,UID:0334e782-be16-43d5-b0d8-a85738df304e,ResourceVersion:25597,Generation:0,CreationTimestamp:2020-02-17 16:44:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 31a335ff-3928-438a-8368-6070b14ddce7 0xc003f99ab0 0xc003f99ab1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-tvc2g {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tvc2g,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-tvc2g true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.242.0.98,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003f99b20} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003f99b40}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:44:00 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 17 16:44:00.818: INFO: Pod "nginx-deployment-7b8c6f4498-j967d" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-j967d,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-2124,SelfLink:/api/v1/namespaces/deployment-2124/pods/nginx-deployment-7b8c6f4498-j967d,UID:1465c878-6d19-4c03-a362-ed2d5d783835,ResourceVersion:25575,Generation:0,CreationTimestamp:2020-02-17 16:44:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 31a335ff-3928-438a-8368-6070b14ddce7 0xc003f99bc0 0xc003f99bc1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-tvc2g {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tvc2g,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-tvc2g true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.242.0.59,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003f99c30} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003f99c50}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:44:00 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 17 16:44:00.818: INFO: Pod "nginx-deployment-7b8c6f4498-kp76t" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-kp76t,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-2124,SelfLink:/api/v1/namespaces/deployment-2124/pods/nginx-deployment-7b8c6f4498-kp76t,UID:db09576f-63df-47ed-9ea1-8b87056fe233,ResourceVersion:25594,Generation:0,CreationTimestamp:2020-02-17 16:44:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 31a335ff-3928-438a-8368-6070b14ddce7 0xc003f99cd0 0xc003f99cd1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-tvc2g {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tvc2g,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-tvc2g true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.242.0.98,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003f99d40} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003f99d60}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:44:00 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 17 16:44:00.818: INFO: Pod "nginx-deployment-7b8c6f4498-l8l5g" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-l8l5g,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-2124,SelfLink:/api/v1/namespaces/deployment-2124/pods/nginx-deployment-7b8c6f4498-l8l5g,UID:7dc81c4e-0841-488f-9dc7-6b3c947e3d19,ResourceVersion:25561,Generation:0,CreationTimestamp:2020-02-17 16:44:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 31a335ff-3928-438a-8368-6070b14ddce7 0xc003f99de0 0xc003f99de1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-tvc2g {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tvc2g,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-tvc2g true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.242.0.98,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003f99e50} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003f99e70}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:44:00 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 17 16:44:00.819: INFO: Pod "nginx-deployment-7b8c6f4498-lzrnw" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-lzrnw,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-2124,SelfLink:/api/v1/namespaces/deployment-2124/pods/nginx-deployment-7b8c6f4498-lzrnw,UID:4b854621-e5a2-4b94-baaf-77b8a389923d,ResourceVersion:25420,Generation:0,CreationTimestamp:2020-02-17 16:43:54 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 31a335ff-3928-438a-8368-6070b14ddce7 0xc003f99ef0 0xc003f99ef1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-tvc2g {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tvc2g,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-tvc2g true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.242.0.98,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003f99f60} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003f99f80}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:43:54 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:43:56 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:43:56 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:43:54 +0000 UTC  }],Message:,Reason:,HostIP:10.242.0.98,PodIP:172.30.197.159,StartTime:2020-02-17 16:43:54 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2020-02-17 16:43:55 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 containerd://f0f7ed531fa5218c9db04ebec81b6cda52448041f5690657317de55be3ab653d}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 17 16:44:00.819: INFO: Pod "nginx-deployment-7b8c6f4498-mndgc" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-mndgc,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-2124,SelfLink:/api/v1/namespaces/deployment-2124/pods/nginx-deployment-7b8c6f4498-mndgc,UID:24604333-dfe0-40c0-9ff9-060cf45e4a64,ResourceVersion:25444,Generation:0,CreationTimestamp:2020-02-17 16:43:54 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 31a335ff-3928-438a-8368-6070b14ddce7 0xc002bce050 0xc002bce051}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-tvc2g {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tvc2g,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-tvc2g true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.242.0.59,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002bce0c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002bce0e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:43:54 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:43:57 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:43:57 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:43:54 +0000 UTC  }],Message:,Reason:,HostIP:10.242.0.59,PodIP:172.30.94.49,StartTime:2020-02-17 16:43:54 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2020-02-17 16:43:56 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 containerd://e1bf6ead812c2bb35c40f33f34ff154955ff4f4b2960d24dbc281ec063df8ecb}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 17 16:44:00.819: INFO: Pod "nginx-deployment-7b8c6f4498-n5xjb" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-n5xjb,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-2124,SelfLink:/api/v1/namespaces/deployment-2124/pods/nginx-deployment-7b8c6f4498-n5xjb,UID:05ddfbe0-03f6-4554-bd5c-994d0b6f25e9,ResourceVersion:25576,Generation:0,CreationTimestamp:2020-02-17 16:44:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 31a335ff-3928-438a-8368-6070b14ddce7 0xc002bce1b0 0xc002bce1b1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-tvc2g {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tvc2g,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-tvc2g true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.242.0.63,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002bce220} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002bce240}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:44:00 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 17 16:44:00.819: INFO: Pod "nginx-deployment-7b8c6f4498-p66cn" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-p66cn,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-2124,SelfLink:/api/v1/namespaces/deployment-2124/pods/nginx-deployment-7b8c6f4498-p66cn,UID:feeece98-a0a4-4649-acaa-c825afa1dab5,ResourceVersion:25426,Generation:0,CreationTimestamp:2020-02-17 16:43:54 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 31a335ff-3928-438a-8368-6070b14ddce7 0xc002bce2c0 0xc002bce2c1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-tvc2g {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tvc2g,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-tvc2g true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.242.0.98,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002bce330} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002bce350}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:43:54 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:43:56 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:43:56 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:43:54 +0000 UTC  }],Message:,Reason:,HostIP:10.242.0.98,PodIP:172.30.197.161,StartTime:2020-02-17 16:43:54 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2020-02-17 16:43:56 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 containerd://ef938909e3d1c0c0c4cec30df123d56fae908715ae01e7e0ffb957a97eaf2706}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 17 16:44:00.819: INFO: Pod "nginx-deployment-7b8c6f4498-pw7cr" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-pw7cr,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-2124,SelfLink:/api/v1/namespaces/deployment-2124/pods/nginx-deployment-7b8c6f4498-pw7cr,UID:86a3f80e-444d-4b34-891c-f3cf1ddae126,ResourceVersion:25450,Generation:0,CreationTimestamp:2020-02-17 16:43:54 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 31a335ff-3928-438a-8368-6070b14ddce7 0xc002bce420 0xc002bce421}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-tvc2g {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tvc2g,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-tvc2g true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.242.0.59,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002bce490} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002bce4b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:43:54 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:43:57 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:43:57 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:43:54 +0000 UTC  }],Message:,Reason:,HostIP:10.242.0.59,PodIP:172.30.94.52,StartTime:2020-02-17 16:43:54 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2020-02-17 16:43:56 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 containerd://65f3ff9493fc1e3d70a870d5aa0aa592832b8fb6f49c42c1117cc9b3e9ce11bb}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 17 16:44:00.819: INFO: Pod "nginx-deployment-7b8c6f4498-qfgxx" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-qfgxx,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-2124,SelfLink:/api/v1/namespaces/deployment-2124/pods/nginx-deployment-7b8c6f4498-qfgxx,UID:4680f651-53bd-4bed-90d9-81f93e7d9019,ResourceVersion:25592,Generation:0,CreationTimestamp:2020-02-17 16:44:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 31a335ff-3928-438a-8368-6070b14ddce7 0xc002bce580 0xc002bce581}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-tvc2g {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tvc2g,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-tvc2g true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.242.0.63,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002bce5f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002bce610}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:44:00 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 17 16:44:00.819: INFO: Pod "nginx-deployment-7b8c6f4498-sztpb" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-sztpb,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-2124,SelfLink:/api/v1/namespaces/deployment-2124/pods/nginx-deployment-7b8c6f4498-sztpb,UID:27a49340-82ce-40fb-9801-809ca9c28d5a,ResourceVersion:25579,Generation:0,CreationTimestamp:2020-02-17 16:44:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 31a335ff-3928-438a-8368-6070b14ddce7 0xc002bce690 0xc002bce691}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-tvc2g {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tvc2g,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-tvc2g true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.242.0.59,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002bce700} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002bce720}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:44:00 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 17 16:44:00.819: INFO: Pod "nginx-deployment-7b8c6f4498-t8z7f" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-t8z7f,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-2124,SelfLink:/api/v1/namespaces/deployment-2124/pods/nginx-deployment-7b8c6f4498-t8z7f,UID:cc729e75-bd5a-4e6b-acaa-bf068ebf3056,ResourceVersion:25598,Generation:0,CreationTimestamp:2020-02-17 16:44:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 31a335ff-3928-438a-8368-6070b14ddce7 0xc002bce7a0 0xc002bce7a1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-tvc2g {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tvc2g,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-tvc2g true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.242.0.63,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002bce810} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002bce830}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:44:00 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 17 16:44:00.820: INFO: Pod "nginx-deployment-7b8c6f4498-vrwgj" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-vrwgj,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-2124,SelfLink:/api/v1/namespaces/deployment-2124/pods/nginx-deployment-7b8c6f4498-vrwgj,UID:8976634d-67c9-461f-8edf-1e6da7e90e0f,ResourceVersion:25447,Generation:0,CreationTimestamp:2020-02-17 16:43:54 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 31a335ff-3928-438a-8368-6070b14ddce7 0xc002bce8b0 0xc002bce8b1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-tvc2g {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tvc2g,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-tvc2g true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.242.0.59,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002bce920} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002bce940}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:43:54 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:43:57 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:43:57 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:43:54 +0000 UTC  }],Message:,Reason:,HostIP:10.242.0.59,PodIP:172.30.94.51,StartTime:2020-02-17 16:43:54 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2020-02-17 16:43:56 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 containerd://6d67715a5442e59530f9553c06705e77e904767234c5c5955dd4e16890378d6c}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 17 16:44:00.820: INFO: Pod "nginx-deployment-7b8c6f4498-wbn62" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-wbn62,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-2124,SelfLink:/api/v1/namespaces/deployment-2124/pods/nginx-deployment-7b8c6f4498-wbn62,UID:43d3538c-4bc4-4e65-9b32-98169be0be87,ResourceVersion:25590,Generation:0,CreationTimestamp:2020-02-17 16:44:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 31a335ff-3928-438a-8368-6070b14ddce7 0xc002bcea10 0xc002bcea11}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-tvc2g {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tvc2g,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-tvc2g true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.242.0.63,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002bcea80} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002bceaa0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:44:00 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:44:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:44:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:44:00 +0000 UTC  }],Message:,Reason:,HostIP:10.242.0.63,PodIP:,StartTime:2020-02-17 16:44:00 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 16:44:00.820: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-2124" for this suite.
Feb 17 16:44:08.901: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:44:09.364: INFO: namespace deployment-2124 deletion completed in 8.526480741s

• [SLOW TEST:15.216 seconds]
[sig-apps] Deployment
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 16:44:09.365: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-9123
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
Feb 17 16:44:15.752: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W0217 16:44:15.752302      16 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 16:44:15.752: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-9123" for this suite.
Feb 17 16:44:23.817: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:44:24.223: INFO: namespace gc-9123 deletion completed in 8.454888769s

• [SLOW TEST:14.858 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 16:44:24.227: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svcaccounts-3703
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: getting the auto-created API token
STEP: reading a file in the container
Feb 17 16:44:29.067: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-3703 pod-service-account-a6443ff7-9efb-4a46-9cc0-dacfaaeae6c1 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
STEP: reading a file in the container
Feb 17 16:44:29.585: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-3703 pod-service-account-a6443ff7-9efb-4a46-9cc0-dacfaaeae6c1 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
STEP: reading a file in the container
Feb 17 16:44:30.026: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-3703 pod-service-account-a6443ff7-9efb-4a46-9cc0-dacfaaeae6c1 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 16:44:30.475: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-3703" for this suite.
Feb 17 16:44:36.543: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:44:37.125: INFO: namespace svcaccounts-3703 deletion completed in 6.631142787s

• [SLOW TEST:12.899 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:23
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 16:44:37.130: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-2113
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Feb 17 16:44:37.428: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-2113,SelfLink:/api/v1/namespaces/watch-2113/configmaps/e2e-watch-test-watch-closed,UID:c26b8816-9958-411f-a7c0-f2faeeff5a3c,ResourceVersion:26431,Generation:0,CreationTimestamp:2020-02-17 16:44:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Feb 17 16:44:37.429: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-2113,SelfLink:/api/v1/namespaces/watch-2113/configmaps/e2e-watch-test-watch-closed,UID:c26b8816-9958-411f-a7c0-f2faeeff5a3c,ResourceVersion:26432,Generation:0,CreationTimestamp:2020-02-17 16:44:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Feb 17 16:44:37.480: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-2113,SelfLink:/api/v1/namespaces/watch-2113/configmaps/e2e-watch-test-watch-closed,UID:c26b8816-9958-411f-a7c0-f2faeeff5a3c,ResourceVersion:26433,Generation:0,CreationTimestamp:2020-02-17 16:44:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Feb 17 16:44:37.481: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-2113,SelfLink:/api/v1/namespaces/watch-2113/configmaps/e2e-watch-test-watch-closed,UID:c26b8816-9958-411f-a7c0-f2faeeff5a3c,ResourceVersion:26434,Generation:0,CreationTimestamp:2020-02-17 16:44:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 16:44:37.481: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-2113" for this suite.
Feb 17 16:44:43.553: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:44:43.944: INFO: namespace watch-2113 deletion completed in 6.441292093s

• [SLOW TEST:6.814 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 16:44:43.945: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-kubelet-etc-hosts-6880
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Feb 17 16:44:50.313: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-6880 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 17 16:44:50.313: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
Feb 17 16:44:50.604: INFO: Exec stderr: ""
Feb 17 16:44:50.604: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-6880 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 17 16:44:50.604: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
Feb 17 16:44:50.880: INFO: Exec stderr: ""
Feb 17 16:44:50.880: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-6880 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 17 16:44:50.880: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
Feb 17 16:44:51.122: INFO: Exec stderr: ""
Feb 17 16:44:51.122: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-6880 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 17 16:44:51.122: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
Feb 17 16:44:51.409: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Feb 17 16:44:51.409: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-6880 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 17 16:44:51.409: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
Feb 17 16:44:51.711: INFO: Exec stderr: ""
Feb 17 16:44:51.712: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-6880 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 17 16:44:51.712: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
Feb 17 16:44:52.010: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Feb 17 16:44:52.010: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-6880 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 17 16:44:52.010: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
Feb 17 16:44:52.318: INFO: Exec stderr: ""
Feb 17 16:44:52.318: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-6880 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 17 16:44:52.318: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
Feb 17 16:44:52.603: INFO: Exec stderr: ""
Feb 17 16:44:52.603: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-6880 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 17 16:44:52.603: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
Feb 17 16:44:52.891: INFO: Exec stderr: ""
Feb 17 16:44:52.891: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-6880 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 17 16:44:52.891: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
Feb 17 16:44:53.183: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 16:44:53.183: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-kubelet-etc-hosts-6880" for this suite.
Feb 17 16:45:35.252: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:45:35.658: INFO: namespace e2e-kubelet-etc-hosts-6880 deletion completed in 42.455772465s

• [SLOW TEST:51.714 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 16:45:35.659: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-7193
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Feb 17 16:45:35.989: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-7193,SelfLink:/api/v1/namespaces/watch-7193/configmaps/e2e-watch-test-label-changed,UID:9d548bcf-fda1-4c20-b779-9ab413306d7e,ResourceVersion:26617,Generation:0,CreationTimestamp:2020-02-17 16:45:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Feb 17 16:45:35.989: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-7193,SelfLink:/api/v1/namespaces/watch-7193/configmaps/e2e-watch-test-label-changed,UID:9d548bcf-fda1-4c20-b779-9ab413306d7e,ResourceVersion:26618,Generation:0,CreationTimestamp:2020-02-17 16:45:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Feb 17 16:45:35.989: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-7193,SelfLink:/api/v1/namespaces/watch-7193/configmaps/e2e-watch-test-label-changed,UID:9d548bcf-fda1-4c20-b779-9ab413306d7e,ResourceVersion:26619,Generation:0,CreationTimestamp:2020-02-17 16:45:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Feb 17 16:45:46.085: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-7193,SelfLink:/api/v1/namespaces/watch-7193/configmaps/e2e-watch-test-label-changed,UID:9d548bcf-fda1-4c20-b779-9ab413306d7e,ResourceVersion:26639,Generation:0,CreationTimestamp:2020-02-17 16:45:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Feb 17 16:45:46.086: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-7193,SelfLink:/api/v1/namespaces/watch-7193/configmaps/e2e-watch-test-label-changed,UID:9d548bcf-fda1-4c20-b779-9ab413306d7e,ResourceVersion:26640,Generation:0,CreationTimestamp:2020-02-17 16:45:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Feb 17 16:45:46.086: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-7193,SelfLink:/api/v1/namespaces/watch-7193/configmaps/e2e-watch-test-label-changed,UID:9d548bcf-fda1-4c20-b779-9ab413306d7e,ResourceVersion:26641,Generation:0,CreationTimestamp:2020-02-17 16:45:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 16:45:46.086: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-7193" for this suite.
Feb 17 16:45:52.154: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:45:52.550: INFO: namespace watch-7193 deletion completed in 6.444279432s

• [SLOW TEST:16.891 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 16:45:52.551: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-9123
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name s-test-opt-del-9aeb3b79-7139-4e7c-9a63-e3392a5d205e
STEP: Creating secret with name s-test-opt-upd-6e885de2-0063-4b98-b91e-e769db7394c1
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-9aeb3b79-7139-4e7c-9a63-e3392a5d205e
STEP: Updating secret s-test-opt-upd-6e885de2-0063-4b98-b91e-e769db7394c1
STEP: Creating secret with name s-test-opt-create-184be4d7-7875-441b-8a22-aa5db1a6d098
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 16:47:04.372: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9123" for this suite.
Feb 17 16:47:28.444: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:47:28.886: INFO: namespace secrets-9123 deletion completed in 24.49328427s

• [SLOW TEST:96.336 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 16:47:28.887: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-1813
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-upd-c636ade1-8fbe-4ec1-836c-e4dfc95d8102
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-c636ade1-8fbe-4ec1-836c-e4dfc95d8102
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 16:47:33.333: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1813" for this suite.
Feb 17 16:47:57.402: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:47:57.790: INFO: namespace configmap-1813 deletion completed in 24.437467254s

• [SLOW TEST:28.904 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 16:47:57.792: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename prestop
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in prestop-4355
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pre_stop.go:167
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating server pod server in namespace prestop-4355
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace prestop-4355
STEP: Deleting pre-stop pod
Feb 17 16:48:09.218: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 16:48:09.241: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "prestop-4355" for this suite.
Feb 17 16:48:49.317: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:48:49.722: INFO: namespace prestop-4355 deletion completed in 40.457287954s

• [SLOW TEST:51.929 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 16:48:49.722: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-6814
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Feb 17 16:48:50.111: INFO: Number of nodes with available pods: 0
Feb 17 16:48:50.111: INFO: Node 10.242.0.59 is running more than one daemon pod
Feb 17 16:48:51.143: INFO: Number of nodes with available pods: 0
Feb 17 16:48:51.143: INFO: Node 10.242.0.59 is running more than one daemon pod
Feb 17 16:48:52.143: INFO: Number of nodes with available pods: 2
Feb 17 16:48:52.143: INFO: Node 10.242.0.63 is running more than one daemon pod
Feb 17 16:48:53.145: INFO: Number of nodes with available pods: 3
Feb 17 16:48:53.145: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Stop a daemon pod, check that the daemon pod is revived.
Feb 17 16:48:53.222: INFO: Number of nodes with available pods: 2
Feb 17 16:48:53.222: INFO: Node 10.242.0.98 is running more than one daemon pod
Feb 17 16:48:54.256: INFO: Number of nodes with available pods: 2
Feb 17 16:48:54.256: INFO: Node 10.242.0.98 is running more than one daemon pod
Feb 17 16:48:55.252: INFO: Number of nodes with available pods: 2
Feb 17 16:48:55.252: INFO: Node 10.242.0.98 is running more than one daemon pod
Feb 17 16:48:56.254: INFO: Number of nodes with available pods: 2
Feb 17 16:48:56.254: INFO: Node 10.242.0.98 is running more than one daemon pod
Feb 17 16:48:57.252: INFO: Number of nodes with available pods: 2
Feb 17 16:48:57.252: INFO: Node 10.242.0.98 is running more than one daemon pod
Feb 17 16:48:58.252: INFO: Number of nodes with available pods: 2
Feb 17 16:48:58.253: INFO: Node 10.242.0.98 is running more than one daemon pod
Feb 17 16:48:59.255: INFO: Number of nodes with available pods: 2
Feb 17 16:48:59.255: INFO: Node 10.242.0.98 is running more than one daemon pod
Feb 17 16:49:00.255: INFO: Number of nodes with available pods: 2
Feb 17 16:49:00.255: INFO: Node 10.242.0.98 is running more than one daemon pod
Feb 17 16:49:01.254: INFO: Number of nodes with available pods: 3
Feb 17 16:49:01.254: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-6814, will wait for the garbage collector to delete the pods
Feb 17 16:49:01.356: INFO: Deleting DaemonSet.extensions daemon-set took: 28.010263ms
Feb 17 16:49:01.556: INFO: Terminating DaemonSet.extensions daemon-set pods took: 200.396307ms
Feb 17 16:49:13.067: INFO: Number of nodes with available pods: 0
Feb 17 16:49:13.067: INFO: Number of running nodes: 0, number of available pods: 0
Feb 17 16:49:13.078: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-6814/daemonsets","resourceVersion":"27247"},"items":null}

Feb 17 16:49:13.088: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-6814/pods","resourceVersion":"27247"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 16:49:13.154: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-6814" for this suite.
Feb 17 16:49:21.221: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:49:21.637: INFO: namespace daemonsets-6814 deletion completed in 8.467355338s

• [SLOW TEST:31.915 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 16:49:21.638: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-8253
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test override arguments
Feb 17 16:49:21.915: INFO: Waiting up to 5m0s for pod "client-containers-4dcde4f2-cec8-4097-ab31-8b96a09bf2bd" in namespace "containers-8253" to be "success or failure"
Feb 17 16:49:21.927: INFO: Pod "client-containers-4dcde4f2-cec8-4097-ab31-8b96a09bf2bd": Phase="Pending", Reason="", readiness=false. Elapsed: 12.583473ms
Feb 17 16:49:23.943: INFO: Pod "client-containers-4dcde4f2-cec8-4097-ab31-8b96a09bf2bd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.028912824s
Feb 17 16:49:25.956: INFO: Pod "client-containers-4dcde4f2-cec8-4097-ab31-8b96a09bf2bd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.041083824s
STEP: Saw pod success
Feb 17 16:49:25.956: INFO: Pod "client-containers-4dcde4f2-cec8-4097-ab31-8b96a09bf2bd" satisfied condition "success or failure"
Feb 17 16:49:25.967: INFO: Trying to get logs from node 10.242.0.59 pod client-containers-4dcde4f2-cec8-4097-ab31-8b96a09bf2bd container test-container: <nil>
STEP: delete the pod
Feb 17 16:49:26.044: INFO: Waiting for pod client-containers-4dcde4f2-cec8-4097-ab31-8b96a09bf2bd to disappear
Feb 17 16:49:26.068: INFO: Pod client-containers-4dcde4f2-cec8-4097-ab31-8b96a09bf2bd no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 16:49:26.068: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-8253" for this suite.
Feb 17 16:49:32.137: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:49:32.539: INFO: namespace containers-8253 deletion completed in 6.452240525s

• [SLOW TEST:10.901 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 16:49:32.541: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-490
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1456
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb 17 16:49:32.795: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-079603707 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=kubectl-490'
Feb 17 16:49:32.933: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Feb 17 16:49:32.933: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: verifying the pod controlled by rc e2e-test-nginx-rc was created
STEP: confirm that you can get logs from an rc
Feb 17 16:49:32.957: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-t2h6s]
Feb 17 16:49:32.957: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-t2h6s" in namespace "kubectl-490" to be "running and ready"
Feb 17 16:49:32.967: INFO: Pod "e2e-test-nginx-rc-t2h6s": Phase="Pending", Reason="", readiness=false. Elapsed: 10.919467ms
Feb 17 16:49:34.979: INFO: Pod "e2e-test-nginx-rc-t2h6s": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022234168s
Feb 17 16:49:36.990: INFO: Pod "e2e-test-nginx-rc-t2h6s": Phase="Running", Reason="", readiness=true. Elapsed: 4.03317106s
Feb 17 16:49:36.990: INFO: Pod "e2e-test-nginx-rc-t2h6s" satisfied condition "running and ready"
Feb 17 16:49:36.990: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-t2h6s]
Feb 17 16:49:36.990: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-079603707 logs rc/e2e-test-nginx-rc --namespace=kubectl-490'
Feb 17 16:49:37.179: INFO: stderr: ""
Feb 17 16:49:37.179: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1461
Feb 17 16:49:37.179: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-079603707 delete rc e2e-test-nginx-rc --namespace=kubectl-490'
Feb 17 16:49:37.367: INFO: stderr: ""
Feb 17 16:49:37.367: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 16:49:37.367: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-490" for this suite.
Feb 17 16:50:01.438: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:50:01.877: INFO: namespace kubectl-490 deletion completed in 24.491562478s

• [SLOW TEST:29.337 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run rc
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 16:50:01.879: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-3361
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Performing setup for networking test in namespace pod-network-test-3361
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Feb 17 16:50:02.145: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Feb 17 16:50:22.421: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.94.12:8080/dial?request=hostName&protocol=http&host=172.30.112.108&port=8080&tries=1'] Namespace:pod-network-test-3361 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 17 16:50:22.421: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
Feb 17 16:50:22.709: INFO: Waiting for endpoints: map[]
Feb 17 16:50:22.726: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.94.12:8080/dial?request=hostName&protocol=http&host=172.30.94.8&port=8080&tries=1'] Namespace:pod-network-test-3361 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 17 16:50:22.726: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
Feb 17 16:50:23.040: INFO: Waiting for endpoints: map[]
Feb 17 16:50:23.063: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.94.12:8080/dial?request=hostName&protocol=http&host=172.30.197.181&port=8080&tries=1'] Namespace:pod-network-test-3361 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 17 16:50:23.063: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
Feb 17 16:50:23.368: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 16:50:23.368: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-3361" for this suite.
Feb 17 16:50:47.442: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:50:47.908: INFO: namespace pod-network-test-3361 deletion completed in 24.516715115s

• [SLOW TEST:46.030 seconds]
[sig-network] Networking
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 16:50:47.910: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-9613
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:179
[It] should be submitted and removed  [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 16:50:48.195: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-9613" for this suite.
Feb 17 16:51:12.265: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:51:12.657: INFO: namespace pods-9613 deletion completed in 24.442914803s

• [SLOW TEST:24.747 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should be submitted and removed  [Conformance]
    /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 16:51:12.657: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-1442
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0666 on node default medium
Feb 17 16:51:12.935: INFO: Waiting up to 5m0s for pod "pod-63e82f14-eb92-48f5-a2a1-f0def70bbdab" in namespace "emptydir-1442" to be "success or failure"
Feb 17 16:51:12.945: INFO: Pod "pod-63e82f14-eb92-48f5-a2a1-f0def70bbdab": Phase="Pending", Reason="", readiness=false. Elapsed: 10.481411ms
Feb 17 16:51:14.958: INFO: Pod "pod-63e82f14-eb92-48f5-a2a1-f0def70bbdab": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022815276s
Feb 17 16:51:16.970: INFO: Pod "pod-63e82f14-eb92-48f5-a2a1-f0def70bbdab": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.035580389s
STEP: Saw pod success
Feb 17 16:51:16.970: INFO: Pod "pod-63e82f14-eb92-48f5-a2a1-f0def70bbdab" satisfied condition "success or failure"
Feb 17 16:51:16.981: INFO: Trying to get logs from node 10.242.0.59 pod pod-63e82f14-eb92-48f5-a2a1-f0def70bbdab container test-container: <nil>
STEP: delete the pod
Feb 17 16:51:17.048: INFO: Waiting for pod pod-63e82f14-eb92-48f5-a2a1-f0def70bbdab to disappear
Feb 17 16:51:17.059: INFO: Pod pod-63e82f14-eb92-48f5-a2a1-f0def70bbdab no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 16:51:17.059: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1442" for this suite.
Feb 17 16:51:23.133: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:51:23.544: INFO: namespace emptydir-1442 deletion completed in 6.463076587s

• [SLOW TEST:10.887 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 16:51:23.544: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-9389
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: starting the proxy server
Feb 17 16:51:23.799: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-079603707 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 16:51:23.917: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9389" for this suite.
Feb 17 16:51:29.991: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:51:30.390: INFO: namespace kubectl-9389 deletion completed in 6.454988235s

• [SLOW TEST:6.845 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Proxy server
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 16:51:30.390: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-9860
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
Feb 17 16:51:30.636: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 16:51:34.254: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-9860" for this suite.
Feb 17 16:51:40.325: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:51:40.732: INFO: namespace init-container-9860 deletion completed in 6.460969259s

• [SLOW TEST:10.343 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 16:51:40.733: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-6599
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test override all
Feb 17 16:51:41.016: INFO: Waiting up to 5m0s for pod "client-containers-68cdd178-78bb-40da-969a-48bde5aea0a3" in namespace "containers-6599" to be "success or failure"
Feb 17 16:51:41.029: INFO: Pod "client-containers-68cdd178-78bb-40da-969a-48bde5aea0a3": Phase="Pending", Reason="", readiness=false. Elapsed: 12.244742ms
Feb 17 16:51:43.040: INFO: Pod "client-containers-68cdd178-78bb-40da-969a-48bde5aea0a3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023760472s
Feb 17 16:51:45.051: INFO: Pod "client-containers-68cdd178-78bb-40da-969a-48bde5aea0a3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.034579645s
STEP: Saw pod success
Feb 17 16:51:45.052: INFO: Pod "client-containers-68cdd178-78bb-40da-969a-48bde5aea0a3" satisfied condition "success or failure"
Feb 17 16:51:45.064: INFO: Trying to get logs from node 10.242.0.59 pod client-containers-68cdd178-78bb-40da-969a-48bde5aea0a3 container test-container: <nil>
STEP: delete the pod
Feb 17 16:51:45.129: INFO: Waiting for pod client-containers-68cdd178-78bb-40da-969a-48bde5aea0a3 to disappear
Feb 17 16:51:45.139: INFO: Pod client-containers-68cdd178-78bb-40da-969a-48bde5aea0a3 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 16:51:45.140: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-6599" for this suite.
Feb 17 16:51:51.206: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:51:51.603: INFO: namespace containers-6599 deletion completed in 6.444882807s

• [SLOW TEST:10.870 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Delete Grace Period 
  should be submitted and removed [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 16:51:51.604: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-1693
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Delete Grace Period
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:47
[It] should be submitted and removed [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: setting up selector
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
Feb 17 16:51:53.939: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-079603707 proxy -p 0'
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
Feb 17 16:51:59.120: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 16:51:59.132: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-1693" for this suite.
Feb 17 16:52:05.201: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:52:05.602: INFO: namespace pods-1693 deletion completed in 6.450640818s

• [SLOW TEST:13.998 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  [k8s.io] Delete Grace Period
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should be submitted and removed [Conformance]
    /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 16:52:05.604: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-602
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating the pod
Feb 17 16:52:08.499: INFO: Successfully updated pod "annotationupdated1a63e89-7588-48d2-b424-22bdd913110c"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 16:52:12.687: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-602" for this suite.
Feb 17 16:52:36.758: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:52:37.151: INFO: namespace downward-api-602 deletion completed in 24.444779205s

• [SLOW TEST:31.546 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 16:52:37.152: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in namespaces-7795
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-916
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-1442
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 16:52:43.986: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-7795" for this suite.
Feb 17 16:52:50.059: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:52:50.458: INFO: namespace namespaces-7795 deletion completed in 6.452434945s
STEP: Destroying namespace "nsdeletetest-916" for this suite.
Feb 17 16:52:50.471: INFO: Namespace nsdeletetest-916 was already deleted
STEP: Destroying namespace "nsdeletetest-1442" for this suite.
Feb 17 16:52:56.522: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:52:56.912: INFO: namespace nsdeletetest-1442 deletion completed in 6.440200331s

• [SLOW TEST:19.760 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 16:52:56.917: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-2882
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Performing setup for networking test in namespace pod-network-test-2882
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Feb 17 16:52:57.177: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Feb 17 16:53:23.442: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.94.17:8080/dial?request=hostName&protocol=udp&host=172.30.112.109&port=8081&tries=1'] Namespace:pod-network-test-2882 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 17 16:53:23.442: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
Feb 17 16:53:23.744: INFO: Waiting for endpoints: map[]
Feb 17 16:53:23.755: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.94.17:8080/dial?request=hostName&protocol=udp&host=172.30.197.183&port=8081&tries=1'] Namespace:pod-network-test-2882 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 17 16:53:23.755: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
Feb 17 16:53:24.060: INFO: Waiting for endpoints: map[]
Feb 17 16:53:24.071: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.94.17:8080/dial?request=hostName&protocol=udp&host=172.30.94.18&port=8081&tries=1'] Namespace:pod-network-test-2882 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 17 16:53:24.071: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
Feb 17 16:53:24.347: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 16:53:24.347: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-2882" for this suite.
Feb 17 16:53:48.416: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:53:48.813: INFO: namespace pod-network-test-2882 deletion completed in 24.447671667s

• [SLOW TEST:51.897 seconds]
[sig-network] Networking
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 16:53:48.817: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-4176
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod liveness-9ee3d154-f39b-4a30-b01a-2dc32e75f016 in namespace container-probe-4176
Feb 17 16:53:53.130: INFO: Started pod liveness-9ee3d154-f39b-4a30-b01a-2dc32e75f016 in namespace container-probe-4176
STEP: checking the pod's current state and verifying that restartCount is present
Feb 17 16:53:53.142: INFO: Initial restart count of pod liveness-9ee3d154-f39b-4a30-b01a-2dc32e75f016 is 0
Feb 17 16:54:07.247: INFO: Restart count of pod container-probe-4176/liveness-9ee3d154-f39b-4a30-b01a-2dc32e75f016 is now 1 (14.104117094s elapsed)
Feb 17 16:54:27.373: INFO: Restart count of pod container-probe-4176/liveness-9ee3d154-f39b-4a30-b01a-2dc32e75f016 is now 2 (34.230348508s elapsed)
Feb 17 16:54:47.494: INFO: Restart count of pod container-probe-4176/liveness-9ee3d154-f39b-4a30-b01a-2dc32e75f016 is now 3 (54.351643006s elapsed)
Feb 17 16:55:07.616: INFO: Restart count of pod container-probe-4176/liveness-9ee3d154-f39b-4a30-b01a-2dc32e75f016 is now 4 (1m14.473720486s elapsed)
Feb 17 16:56:07.990: INFO: Restart count of pod container-probe-4176/liveness-9ee3d154-f39b-4a30-b01a-2dc32e75f016 is now 5 (2m14.847396336s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 16:56:08.027: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-4176" for this suite.
Feb 17 16:56:14.102: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:56:14.510: INFO: namespace container-probe-4176 deletion completed in 6.464210591s

• [SLOW TEST:145.694 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 16:56:14.512: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-4328
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir volume type on node default medium
Feb 17 16:56:14.794: INFO: Waiting up to 5m0s for pod "pod-f4cefde1-ba30-48f8-b889-20a38a300582" in namespace "emptydir-4328" to be "success or failure"
Feb 17 16:56:14.807: INFO: Pod "pod-f4cefde1-ba30-48f8-b889-20a38a300582": Phase="Pending", Reason="", readiness=false. Elapsed: 12.788912ms
Feb 17 16:56:16.822: INFO: Pod "pod-f4cefde1-ba30-48f8-b889-20a38a300582": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.027842572s
STEP: Saw pod success
Feb 17 16:56:16.822: INFO: Pod "pod-f4cefde1-ba30-48f8-b889-20a38a300582" satisfied condition "success or failure"
Feb 17 16:56:16.833: INFO: Trying to get logs from node 10.242.0.59 pod pod-f4cefde1-ba30-48f8-b889-20a38a300582 container test-container: <nil>
STEP: delete the pod
Feb 17 16:56:16.912: INFO: Waiting for pod pod-f4cefde1-ba30-48f8-b889-20a38a300582 to disappear
Feb 17 16:56:16.925: INFO: Pod pod-f4cefde1-ba30-48f8-b889-20a38a300582 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 16:56:16.925: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4328" for this suite.
Feb 17 16:56:22.999: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:56:23.430: INFO: namespace emptydir-4328 deletion completed in 6.486580743s

• [SLOW TEST:8.917 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 16:56:23.430: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in namespaces-1187
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-4781
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-4068
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 16:56:49.300: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-1187" for this suite.
Feb 17 16:56:55.366: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:56:55.768: INFO: namespace namespaces-1187 deletion completed in 6.450907454s
STEP: Destroying namespace "nsdeletetest-4781" for this suite.
Feb 17 16:56:55.781: INFO: Namespace nsdeletetest-4781 was already deleted
STEP: Destroying namespace "nsdeletetest-4068" for this suite.
Feb 17 16:57:01.837: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:57:02.241: INFO: namespace nsdeletetest-4068 deletion completed in 6.459853658s

• [SLOW TEST:38.811 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 16:57:02.242: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5343
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name cm-test-opt-del-375f2b18-4b85-47ab-9e8b-5a574efaad3a
STEP: Creating configMap with name cm-test-opt-upd-fe256a0d-2570-4a4b-beb4-7517b5198042
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-375f2b18-4b85-47ab-9e8b-5a574efaad3a
STEP: Updating configmap cm-test-opt-upd-fe256a0d-2570-4a4b-beb4-7517b5198042
STEP: Creating configMap with name cm-test-opt-create-ed0f0c26-7d8a-4456-a39e-150a5e6c77a8
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 16:58:18.059: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5343" for this suite.
Feb 17 16:58:42.145: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:58:42.548: INFO: namespace projected-5343 deletion completed in 24.454300168s

• [SLOW TEST:100.306 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 16:58:42.549: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-5498
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:273
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a replication controller
Feb 17 16:58:42.806: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-079603707 create -f - --namespace=kubectl-5498'
Feb 17 16:58:43.221: INFO: stderr: ""
Feb 17 16:58:43.221: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb 17 16:58:43.221: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-079603707 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-5498'
Feb 17 16:58:43.369: INFO: stderr: ""
Feb 17 16:58:43.369: INFO: stdout: "update-demo-nautilus-8vkr5 update-demo-nautilus-95p6d "
Feb 17 16:58:43.369: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-079603707 get pods update-demo-nautilus-8vkr5 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-5498'
Feb 17 16:58:43.505: INFO: stderr: ""
Feb 17 16:58:43.505: INFO: stdout: ""
Feb 17 16:58:43.505: INFO: update-demo-nautilus-8vkr5 is created but not running
Feb 17 16:58:48.505: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-079603707 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-5498'
Feb 17 16:58:48.633: INFO: stderr: ""
Feb 17 16:58:48.634: INFO: stdout: "update-demo-nautilus-8vkr5 update-demo-nautilus-95p6d "
Feb 17 16:58:48.634: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-079603707 get pods update-demo-nautilus-8vkr5 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-5498'
Feb 17 16:58:48.762: INFO: stderr: ""
Feb 17 16:58:48.762: INFO: stdout: "true"
Feb 17 16:58:48.763: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-079603707 get pods update-demo-nautilus-8vkr5 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-5498'
Feb 17 16:58:48.903: INFO: stderr: ""
Feb 17 16:58:48.903: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 17 16:58:48.903: INFO: validating pod update-demo-nautilus-8vkr5
Feb 17 16:58:48.933: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 17 16:58:48.933: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 17 16:58:48.933: INFO: update-demo-nautilus-8vkr5 is verified up and running
Feb 17 16:58:48.933: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-079603707 get pods update-demo-nautilus-95p6d -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-5498'
Feb 17 16:58:49.073: INFO: stderr: ""
Feb 17 16:58:49.073: INFO: stdout: "true"
Feb 17 16:58:49.073: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-079603707 get pods update-demo-nautilus-95p6d -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-5498'
Feb 17 16:58:49.273: INFO: stderr: ""
Feb 17 16:58:49.273: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 17 16:58:49.273: INFO: validating pod update-demo-nautilus-95p6d
Feb 17 16:58:49.301: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 17 16:58:49.301: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 17 16:58:49.301: INFO: update-demo-nautilus-95p6d is verified up and running
STEP: using delete to clean up resources
Feb 17 16:58:49.301: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-079603707 delete --grace-period=0 --force -f - --namespace=kubectl-5498'
Feb 17 16:58:49.469: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 17 16:58:49.469: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Feb 17 16:58:49.469: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-079603707 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-5498'
Feb 17 16:58:49.606: INFO: stderr: "No resources found.\n"
Feb 17 16:58:49.606: INFO: stdout: ""
Feb 17 16:58:49.606: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-079603707 get pods -l name=update-demo --namespace=kubectl-5498 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Feb 17 16:58:49.770: INFO: stderr: ""
Feb 17 16:58:49.770: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 16:58:49.770: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5498" for this suite.
Feb 17 16:59:13.840: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:59:14.262: INFO: namespace kubectl-5498 deletion completed in 24.473741506s

• [SLOW TEST:31.714 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 16:59:14.263: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-3925
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-map-42971d4b-9cc5-4968-bef2-6c6cba1a1bd8
STEP: Creating a pod to test consume secrets
Feb 17 16:59:14.567: INFO: Waiting up to 5m0s for pod "pod-secrets-50817b3e-b999-421b-af8b-d13417e8d5e2" in namespace "secrets-3925" to be "success or failure"
Feb 17 16:59:14.578: INFO: Pod "pod-secrets-50817b3e-b999-421b-af8b-d13417e8d5e2": Phase="Pending", Reason="", readiness=false. Elapsed: 10.969762ms
Feb 17 16:59:16.590: INFO: Pod "pod-secrets-50817b3e-b999-421b-af8b-d13417e8d5e2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.023497237s
STEP: Saw pod success
Feb 17 16:59:16.590: INFO: Pod "pod-secrets-50817b3e-b999-421b-af8b-d13417e8d5e2" satisfied condition "success or failure"
Feb 17 16:59:16.601: INFO: Trying to get logs from node 10.242.0.98 pod pod-secrets-50817b3e-b999-421b-af8b-d13417e8d5e2 container secret-volume-test: <nil>
STEP: delete the pod
Feb 17 16:59:16.681: INFO: Waiting for pod pod-secrets-50817b3e-b999-421b-af8b-d13417e8d5e2 to disappear
Feb 17 16:59:16.693: INFO: Pod pod-secrets-50817b3e-b999-421b-af8b-d13417e8d5e2 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 16:59:16.693: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3925" for this suite.
Feb 17 16:59:22.770: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:59:23.181: INFO: namespace secrets-3925 deletion completed in 6.46360141s

• [SLOW TEST:8.918 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 16:59:23.182: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7973
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-map-070df928-ac6f-43a8-9af4-3694fb9ed2d6
STEP: Creating a pod to test consume configMaps
Feb 17 16:59:23.606: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-9d631e40-0992-4304-9c57-2d49a5b4f573" in namespace "projected-7973" to be "success or failure"
Feb 17 16:59:23.617: INFO: Pod "pod-projected-configmaps-9d631e40-0992-4304-9c57-2d49a5b4f573": Phase="Pending", Reason="", readiness=false. Elapsed: 10.690313ms
Feb 17 16:59:25.628: INFO: Pod "pod-projected-configmaps-9d631e40-0992-4304-9c57-2d49a5b4f573": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021801763s
STEP: Saw pod success
Feb 17 16:59:25.628: INFO: Pod "pod-projected-configmaps-9d631e40-0992-4304-9c57-2d49a5b4f573" satisfied condition "success or failure"
Feb 17 16:59:25.639: INFO: Trying to get logs from node 10.242.0.98 pod pod-projected-configmaps-9d631e40-0992-4304-9c57-2d49a5b4f573 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 17 16:59:25.705: INFO: Waiting for pod pod-projected-configmaps-9d631e40-0992-4304-9c57-2d49a5b4f573 to disappear
Feb 17 16:59:25.716: INFO: Pod pod-projected-configmaps-9d631e40-0992-4304-9c57-2d49a5b4f573 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 16:59:25.716: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7973" for this suite.
Feb 17 16:59:31.789: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:59:32.181: INFO: namespace projected-7973 deletion completed in 6.444279226s

• [SLOW TEST:9.000 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 16:59:32.182: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-5243
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-5243.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-5243.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Feb 17 16:59:46.672: INFO: DNS probes using dns-5243/dns-test-2971be9e-678e-4260-afe6-754f4ec01cbe succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 16:59:46.713: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-5243" for this suite.
Feb 17 16:59:54.780: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:59:55.180: INFO: namespace dns-5243 deletion completed in 8.448897826s

• [SLOW TEST:22.999 seconds]
[sig-network] DNS
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 16:59:55.191: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-1745
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: validating api versions
Feb 17 16:59:55.463: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-079603707 api-versions'
Feb 17 16:59:55.597: INFO: stderr: ""
Feb 17 16:59:55.597: INFO: stdout: "admissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\napps/v1beta1\napps/v1beta2\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\nbatch/v2alpha1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1\ncoordination.k8s.io/v1beta1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nmetrics.k8s.io/v1beta1\nnetworking.k8s.io/v1\nnetworking.k8s.io/v1beta1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 16:59:55.597: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1745" for this suite.
Feb 17 17:00:01.666: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:00:02.073: INFO: namespace kubectl-1745 deletion completed in 6.457627477s

• [SLOW TEST:6.882 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl api-versions
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 17:00:02.075: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-5411
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Performing setup for networking test in namespace pod-network-test-5411
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Feb 17 17:00:02.349: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Feb 17 17:00:20.642: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://172.30.112.110:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-5411 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 17 17:00:20.642: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
Feb 17 17:00:20.912: INFO: Found all expected endpoints: [netserver-0]
Feb 17 17:00:20.923: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://172.30.94.25:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-5411 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 17 17:00:20.923: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
Feb 17 17:00:21.244: INFO: Found all expected endpoints: [netserver-1]
Feb 17 17:00:21.256: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://172.30.197.188:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-5411 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 17 17:00:21.256: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
Feb 17 17:00:21.544: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 17:00:21.544: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-5411" for this suite.
Feb 17 17:00:45.616: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:00:46.000: INFO: namespace pod-network-test-5411 deletion completed in 24.434856402s

• [SLOW TEST:43.925 seconds]
[sig-network] Networking
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 17:00:46.001: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-182
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl label
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1210
STEP: creating the pod
Feb 17 17:00:46.262: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-079603707 create -f - --namespace=kubectl-182'
Feb 17 17:00:46.549: INFO: stderr: ""
Feb 17 17:00:46.549: INFO: stdout: "pod/pause created\n"
Feb 17 17:00:46.549: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Feb 17 17:00:46.549: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-182" to be "running and ready"
Feb 17 17:00:46.561: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 11.900615ms
Feb 17 17:00:48.572: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.023252111s
Feb 17 17:00:48.572: INFO: Pod "pause" satisfied condition "running and ready"
Feb 17 17:00:48.572: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: adding the label testing-label with value testing-label-value to a pod
Feb 17 17:00:48.572: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-079603707 label pods pause testing-label=testing-label-value --namespace=kubectl-182'
Feb 17 17:00:48.700: INFO: stderr: ""
Feb 17 17:00:48.700: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Feb 17 17:00:48.701: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-079603707 get pod pause -L testing-label --namespace=kubectl-182'
Feb 17 17:00:48.838: INFO: stderr: ""
Feb 17 17:00:48.838: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Feb 17 17:00:48.838: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-079603707 label pods pause testing-label- --namespace=kubectl-182'
Feb 17 17:00:48.993: INFO: stderr: ""
Feb 17 17:00:48.993: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Feb 17 17:00:48.993: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-079603707 get pod pause -L testing-label --namespace=kubectl-182'
Feb 17 17:00:49.127: INFO: stderr: ""
Feb 17 17:00:49.127: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          3s    \n"
[AfterEach] [k8s.io] Kubectl label
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1217
STEP: using delete to clean up resources
Feb 17 17:00:49.127: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-079603707 delete --grace-period=0 --force -f - --namespace=kubectl-182'
Feb 17 17:00:49.353: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 17 17:00:49.353: INFO: stdout: "pod \"pause\" force deleted\n"
Feb 17 17:00:49.353: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-079603707 get rc,svc -l name=pause --no-headers --namespace=kubectl-182'
Feb 17 17:00:49.498: INFO: stderr: "No resources found.\n"
Feb 17 17:00:49.498: INFO: stdout: ""
Feb 17 17:00:49.498: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-079603707 get pods -l name=pause --namespace=kubectl-182 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Feb 17 17:00:49.622: INFO: stderr: ""
Feb 17 17:00:49.622: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 17:00:49.622: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-182" for this suite.
Feb 17 17:00:55.691: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:00:56.101: INFO: namespace kubectl-182 deletion completed in 6.459879363s

• [SLOW TEST:10.100 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl label
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 17:00:56.101: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-3395
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 17:01:56.395: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-3395" for this suite.
Feb 17 17:02:20.468: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:02:20.910: INFO: namespace container-probe-3395 deletion completed in 24.496900977s

• [SLOW TEST:84.809 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 17:02:20.911: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2739
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-map-a0af663c-4c6d-4ef5-a937-cc74067adf4f
STEP: Creating a pod to test consume configMaps
Feb 17 17:02:21.203: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-a21bdf19-3a93-4e08-9d49-cf9c71a8f329" in namespace "projected-2739" to be "success or failure"
Feb 17 17:02:21.214: INFO: Pod "pod-projected-configmaps-a21bdf19-3a93-4e08-9d49-cf9c71a8f329": Phase="Pending", Reason="", readiness=false. Elapsed: 11.198065ms
Feb 17 17:02:23.227: INFO: Pod "pod-projected-configmaps-a21bdf19-3a93-4e08-9d49-cf9c71a8f329": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024422905s
Feb 17 17:02:25.240: INFO: Pod "pod-projected-configmaps-a21bdf19-3a93-4e08-9d49-cf9c71a8f329": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.036937924s
STEP: Saw pod success
Feb 17 17:02:25.240: INFO: Pod "pod-projected-configmaps-a21bdf19-3a93-4e08-9d49-cf9c71a8f329" satisfied condition "success or failure"
Feb 17 17:02:25.252: INFO: Trying to get logs from node 10.242.0.98 pod pod-projected-configmaps-a21bdf19-3a93-4e08-9d49-cf9c71a8f329 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 17 17:02:25.321: INFO: Waiting for pod pod-projected-configmaps-a21bdf19-3a93-4e08-9d49-cf9c71a8f329 to disappear
Feb 17 17:02:25.332: INFO: Pod pod-projected-configmaps-a21bdf19-3a93-4e08-9d49-cf9c71a8f329 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 17:02:25.332: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2739" for this suite.
Feb 17 17:02:31.406: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:02:31.809: INFO: namespace projected-2739 deletion completed in 6.453296574s

• [SLOW TEST:10.898 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 17:02:31.813: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-7165
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Feb 17 17:02:34.667: INFO: Successfully updated pod "pod-update-0792f4da-93d0-42dd-97e2-89e611fee1e1"
STEP: verifying the updated pod is in kubernetes
Feb 17 17:02:34.698: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 17:02:34.698: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-7165" for this suite.
Feb 17 17:02:58.775: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:02:59.183: INFO: namespace pods-7165 deletion completed in 24.466464173s

• [SLOW TEST:27.371 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-node] ConfigMap 
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 17:02:59.184: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-2257
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap that has name configmap-test-emptyKey-065c7a34-5b11-4063-ab1a-c99e30ce0aec
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 17:02:59.453: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2257" for this suite.
Feb 17 17:03:05.520: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:03:05.923: INFO: namespace configmap-2257 deletion completed in 6.452793977s

• [SLOW TEST:6.740 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 17:03:05.924: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-6539
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1612
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb 17 17:03:06.188: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-079603707 run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-6539'
Feb 17 17:03:06.346: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Feb 17 17:03:06.346: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
STEP: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1617
Feb 17 17:03:06.360: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-079603707 delete jobs e2e-test-nginx-job --namespace=kubectl-6539'
Feb 17 17:03:06.504: INFO: stderr: ""
Feb 17 17:03:06.504: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 17:03:06.504: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6539" for this suite.
Feb 17 17:03:30.570: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:03:31.011: INFO: namespace kubectl-6539 deletion completed in 24.49032692s

• [SLOW TEST:25.088 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run job
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 17:03:31.012: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-2378
STEP: Waiting for a default service account to be provisioned in namespace
[It] pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating Pod
STEP: Waiting for the pod running
STEP: Geting the pod
STEP: Reading file content from the nginx-container
Feb 17 17:03:35.348: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-079603707 exec pod-sharedvolume-d108d635-6af7-4511-9019-bac3292fbba1 -c busybox-main-container --namespace=emptydir-2378 -- cat /usr/share/volumeshare/shareddata.txt'
Feb 17 17:03:35.834: INFO: stderr: ""
Feb 17 17:03:35.834: INFO: stdout: "Hello from the busy-box sub-container\n"
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 17:03:35.834: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2378" for this suite.
Feb 17 17:03:41.906: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:03:42.300: INFO: namespace emptydir-2378 deletion completed in 6.446690581s

• [SLOW TEST:11.288 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 17:03:42.301: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6596
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-acb99665-a400-4a9d-a995-7f9225eb3d2a
STEP: Creating a pod to test consume configMaps
Feb 17 17:03:42.592: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-b5fd1563-4ca7-4e39-8797-6af218074141" in namespace "projected-6596" to be "success or failure"
Feb 17 17:03:42.605: INFO: Pod "pod-projected-configmaps-b5fd1563-4ca7-4e39-8797-6af218074141": Phase="Pending", Reason="", readiness=false. Elapsed: 12.292775ms
Feb 17 17:03:44.616: INFO: Pod "pod-projected-configmaps-b5fd1563-4ca7-4e39-8797-6af218074141": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.023732733s
STEP: Saw pod success
Feb 17 17:03:44.616: INFO: Pod "pod-projected-configmaps-b5fd1563-4ca7-4e39-8797-6af218074141" satisfied condition "success or failure"
Feb 17 17:03:44.627: INFO: Trying to get logs from node 10.242.0.59 pod pod-projected-configmaps-b5fd1563-4ca7-4e39-8797-6af218074141 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 17 17:03:44.700: INFO: Waiting for pod pod-projected-configmaps-b5fd1563-4ca7-4e39-8797-6af218074141 to disappear
Feb 17 17:03:44.711: INFO: Pod pod-projected-configmaps-b5fd1563-4ca7-4e39-8797-6af218074141 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 17:03:44.711: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6596" for this suite.
Feb 17 17:03:50.778: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:03:51.156: INFO: namespace projected-6596 deletion completed in 6.42750507s

• [SLOW TEST:8.855 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 17:03:51.157: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5725
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Feb 17 17:03:51.448: INFO: Waiting up to 5m0s for pod "downwardapi-volume-2bc03a6e-b7fd-4e59-9cd1-5f831ac44ca8" in namespace "projected-5725" to be "success or failure"
Feb 17 17:03:51.458: INFO: Pod "downwardapi-volume-2bc03a6e-b7fd-4e59-9cd1-5f831ac44ca8": Phase="Pending", Reason="", readiness=false. Elapsed: 9.924916ms
Feb 17 17:03:53.470: INFO: Pod "downwardapi-volume-2bc03a6e-b7fd-4e59-9cd1-5f831ac44ca8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021729869s
Feb 17 17:03:55.482: INFO: Pod "downwardapi-volume-2bc03a6e-b7fd-4e59-9cd1-5f831ac44ca8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.033547612s
STEP: Saw pod success
Feb 17 17:03:55.482: INFO: Pod "downwardapi-volume-2bc03a6e-b7fd-4e59-9cd1-5f831ac44ca8" satisfied condition "success or failure"
Feb 17 17:03:55.495: INFO: Trying to get logs from node 10.242.0.98 pod downwardapi-volume-2bc03a6e-b7fd-4e59-9cd1-5f831ac44ca8 container client-container: <nil>
STEP: delete the pod
Feb 17 17:03:55.563: INFO: Waiting for pod downwardapi-volume-2bc03a6e-b7fd-4e59-9cd1-5f831ac44ca8 to disappear
Feb 17 17:03:55.574: INFO: Pod downwardapi-volume-2bc03a6e-b7fd-4e59-9cd1-5f831ac44ca8 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 17:03:55.575: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5725" for this suite.
Feb 17 17:04:01.643: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:04:02.051: INFO: namespace projected-5725 deletion completed in 6.458035751s

• [SLOW TEST:10.895 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 17:04:02.058: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-4759
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Feb 17 17:04:02.378: INFO: Waiting up to 5m0s for pod "downward-api-922dd90a-2a39-41be-b86b-f09f5036315a" in namespace "downward-api-4759" to be "success or failure"
Feb 17 17:04:02.390: INFO: Pod "downward-api-922dd90a-2a39-41be-b86b-f09f5036315a": Phase="Pending", Reason="", readiness=false. Elapsed: 11.924202ms
Feb 17 17:04:04.402: INFO: Pod "downward-api-922dd90a-2a39-41be-b86b-f09f5036315a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023792411s
Feb 17 17:04:06.415: INFO: Pod "downward-api-922dd90a-2a39-41be-b86b-f09f5036315a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.036627757s
STEP: Saw pod success
Feb 17 17:04:06.415: INFO: Pod "downward-api-922dd90a-2a39-41be-b86b-f09f5036315a" satisfied condition "success or failure"
Feb 17 17:04:06.427: INFO: Trying to get logs from node 10.242.0.98 pod downward-api-922dd90a-2a39-41be-b86b-f09f5036315a container dapi-container: <nil>
STEP: delete the pod
Feb 17 17:04:06.504: INFO: Waiting for pod downward-api-922dd90a-2a39-41be-b86b-f09f5036315a to disappear
Feb 17 17:04:06.515: INFO: Pod downward-api-922dd90a-2a39-41be-b86b-f09f5036315a no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 17:04:06.515: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4759" for this suite.
Feb 17 17:04:12.589: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:04:13.005: INFO: namespace downward-api-4759 deletion completed in 6.465970657s

• [SLOW TEST:10.947 seconds]
[sig-node] Downward API
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 17:04:13.006: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-6936
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test substitution in container's args
Feb 17 17:04:13.284: INFO: Waiting up to 5m0s for pod "var-expansion-25cb3df2-1f04-4a4b-a46a-2add37087e3a" in namespace "var-expansion-6936" to be "success or failure"
Feb 17 17:04:13.299: INFO: Pod "var-expansion-25cb3df2-1f04-4a4b-a46a-2add37087e3a": Phase="Pending", Reason="", readiness=false. Elapsed: 14.674436ms
Feb 17 17:04:15.311: INFO: Pod "var-expansion-25cb3df2-1f04-4a4b-a46a-2add37087e3a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026938524s
Feb 17 17:04:17.322: INFO: Pod "var-expansion-25cb3df2-1f04-4a4b-a46a-2add37087e3a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.038638101s
STEP: Saw pod success
Feb 17 17:04:17.323: INFO: Pod "var-expansion-25cb3df2-1f04-4a4b-a46a-2add37087e3a" satisfied condition "success or failure"
Feb 17 17:04:17.334: INFO: Trying to get logs from node 10.242.0.98 pod var-expansion-25cb3df2-1f04-4a4b-a46a-2add37087e3a container dapi-container: <nil>
STEP: delete the pod
Feb 17 17:04:17.413: INFO: Waiting for pod var-expansion-25cb3df2-1f04-4a4b-a46a-2add37087e3a to disappear
Feb 17 17:04:17.424: INFO: Pod var-expansion-25cb3df2-1f04-4a4b-a46a-2add37087e3a no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 17:04:17.424: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-6936" for this suite.
Feb 17 17:04:23.494: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:04:23.903: INFO: namespace var-expansion-6936 deletion completed in 6.459299214s

• [SLOW TEST:10.897 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 17:04:23.904: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-1023
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Feb 17 17:04:24.183: INFO: Waiting up to 5m0s for pod "downward-api-44a9d123-9d3d-45d1-b2fe-cb7e89f4035b" in namespace "downward-api-1023" to be "success or failure"
Feb 17 17:04:24.194: INFO: Pod "downward-api-44a9d123-9d3d-45d1-b2fe-cb7e89f4035b": Phase="Pending", Reason="", readiness=false. Elapsed: 10.926857ms
Feb 17 17:04:26.207: INFO: Pod "downward-api-44a9d123-9d3d-45d1-b2fe-cb7e89f4035b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023871857s
Feb 17 17:04:28.220: INFO: Pod "downward-api-44a9d123-9d3d-45d1-b2fe-cb7e89f4035b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.037417938s
STEP: Saw pod success
Feb 17 17:04:28.220: INFO: Pod "downward-api-44a9d123-9d3d-45d1-b2fe-cb7e89f4035b" satisfied condition "success or failure"
Feb 17 17:04:28.234: INFO: Trying to get logs from node 10.242.0.59 pod downward-api-44a9d123-9d3d-45d1-b2fe-cb7e89f4035b container dapi-container: <nil>
STEP: delete the pod
Feb 17 17:04:28.303: INFO: Waiting for pod downward-api-44a9d123-9d3d-45d1-b2fe-cb7e89f4035b to disappear
Feb 17 17:04:28.315: INFO: Pod downward-api-44a9d123-9d3d-45d1-b2fe-cb7e89f4035b no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 17:04:28.315: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1023" for this suite.
Feb 17 17:04:34.433: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:04:34.829: INFO: namespace downward-api-1023 deletion completed in 6.490217894s

• [SLOW TEST:10.925 seconds]
[sig-node] Downward API
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 17:04:34.829: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svcaccounts-7219
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: getting the auto-created API token
Feb 17 17:04:35.656: INFO: created pod pod-service-account-defaultsa
Feb 17 17:04:35.656: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Feb 17 17:04:35.669: INFO: created pod pod-service-account-mountsa
Feb 17 17:04:35.670: INFO: pod pod-service-account-mountsa service account token volume mount: true
Feb 17 17:04:35.682: INFO: created pod pod-service-account-nomountsa
Feb 17 17:04:35.682: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Feb 17 17:04:35.702: INFO: created pod pod-service-account-defaultsa-mountspec
Feb 17 17:04:35.702: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Feb 17 17:04:35.714: INFO: created pod pod-service-account-mountsa-mountspec
Feb 17 17:04:35.715: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Feb 17 17:04:35.728: INFO: created pod pod-service-account-nomountsa-mountspec
Feb 17 17:04:35.728: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Feb 17 17:04:35.742: INFO: created pod pod-service-account-defaultsa-nomountspec
Feb 17 17:04:35.742: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Feb 17 17:04:35.757: INFO: created pod pod-service-account-mountsa-nomountspec
Feb 17 17:04:35.757: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Feb 17 17:04:35.779: INFO: created pod pod-service-account-nomountsa-nomountspec
Feb 17 17:04:35.779: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 17:04:35.779: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-7219" for this suite.
Feb 17 17:04:43.849: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:04:44.223: INFO: namespace svcaccounts-7219 deletion completed in 8.422127893s

• [SLOW TEST:9.394 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:23
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 17:04:44.224: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-8004
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Feb 17 17:04:47.560: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 17:04:47.607: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-8004" for this suite.
Feb 17 17:04:53.675: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:04:54.083: INFO: namespace container-runtime-8004 deletion completed in 6.458519152s

• [SLOW TEST:9.860 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  blackbox test
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
    on terminated container
    /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:129
      should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
      /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 17:04:54.085: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-2478
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-downwardapi-m982
STEP: Creating a pod to test atomic-volume-subpath
Feb 17 17:04:54.398: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-m982" in namespace "subpath-2478" to be "success or failure"
Feb 17 17:04:54.410: INFO: Pod "pod-subpath-test-downwardapi-m982": Phase="Pending", Reason="", readiness=false. Elapsed: 12.294778ms
Feb 17 17:04:56.422: INFO: Pod "pod-subpath-test-downwardapi-m982": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024018373s
Feb 17 17:04:58.433: INFO: Pod "pod-subpath-test-downwardapi-m982": Phase="Running", Reason="", readiness=true. Elapsed: 4.035521897s
Feb 17 17:05:00.445: INFO: Pod "pod-subpath-test-downwardapi-m982": Phase="Running", Reason="", readiness=true. Elapsed: 6.046975312s
Feb 17 17:05:02.456: INFO: Pod "pod-subpath-test-downwardapi-m982": Phase="Running", Reason="", readiness=true. Elapsed: 8.058107267s
Feb 17 17:05:04.469: INFO: Pod "pod-subpath-test-downwardapi-m982": Phase="Running", Reason="", readiness=true. Elapsed: 10.071136979s
Feb 17 17:05:06.480: INFO: Pod "pod-subpath-test-downwardapi-m982": Phase="Running", Reason="", readiness=true. Elapsed: 12.082439284s
Feb 17 17:05:08.492: INFO: Pod "pod-subpath-test-downwardapi-m982": Phase="Running", Reason="", readiness=true. Elapsed: 14.094397745s
Feb 17 17:05:10.504: INFO: Pod "pod-subpath-test-downwardapi-m982": Phase="Running", Reason="", readiness=true. Elapsed: 16.105840424s
Feb 17 17:05:12.515: INFO: Pod "pod-subpath-test-downwardapi-m982": Phase="Running", Reason="", readiness=true. Elapsed: 18.116966931s
Feb 17 17:05:14.527: INFO: Pod "pod-subpath-test-downwardapi-m982": Phase="Running", Reason="", readiness=true. Elapsed: 20.129483058s
Feb 17 17:05:16.539: INFO: Pod "pod-subpath-test-downwardapi-m982": Phase="Running", Reason="", readiness=true. Elapsed: 22.140810648s
Feb 17 17:05:18.553: INFO: Pod "pod-subpath-test-downwardapi-m982": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.155210465s
STEP: Saw pod success
Feb 17 17:05:18.553: INFO: Pod "pod-subpath-test-downwardapi-m982" satisfied condition "success or failure"
Feb 17 17:05:18.565: INFO: Trying to get logs from node 10.242.0.98 pod pod-subpath-test-downwardapi-m982 container test-container-subpath-downwardapi-m982: <nil>
STEP: delete the pod
Feb 17 17:05:18.685: INFO: Waiting for pod pod-subpath-test-downwardapi-m982 to disappear
Feb 17 17:05:18.707: INFO: Pod pod-subpath-test-downwardapi-m982 no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-m982
Feb 17 17:05:18.707: INFO: Deleting pod "pod-subpath-test-downwardapi-m982" in namespace "subpath-2478"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 17:05:18.719: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-2478" for this suite.
Feb 17 17:05:24.789: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:05:25.186: INFO: namespace subpath-2478 deletion completed in 6.445454083s

• [SLOW TEST:31.101 seconds]
[sig-storage] Subpath
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with downward pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 17:05:25.187: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-4361
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Feb 17 17:05:25.448: INFO: Creating deployment "test-recreate-deployment"
Feb 17 17:05:25.463: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Feb 17 17:05:25.490: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
Feb 17 17:05:27.513: INFO: Waiting deployment "test-recreate-deployment" to complete
Feb 17 17:05:27.526: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717555925, loc:(*time.Location)(0x7ed4a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717555925, loc:(*time.Location)(0x7ed4a20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717555925, loc:(*time.Location)(0x7ed4a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717555925, loc:(*time.Location)(0x7ed4a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-6df85df6b9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 17 17:05:29.540: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Feb 17 17:05:29.577: INFO: Updating deployment test-recreate-deployment
Feb 17 17:05:29.577: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
Feb 17 17:05:29.718: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment,GenerateName:,Namespace:deployment-4361,SelfLink:/apis/apps/v1/namespaces/deployment-4361/deployments/test-recreate-deployment,UID:084ecdd9-346a-4e08-8837-1b32f3ad3d55,ResourceVersion:30726,Generation:2,CreationTimestamp:2020-02-17 17:05:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[{Available False 2020-02-17 17:05:29 +0000 UTC 2020-02-17 17:05:29 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2020-02-17 17:05:29 +0000 UTC 2020-02-17 17:05:25 +0000 UTC ReplicaSetUpdated ReplicaSet "test-recreate-deployment-5c8c9cc69d" is progressing.}],ReadyReplicas:0,CollisionCount:nil,},}

Feb 17 17:05:29.729: INFO: New ReplicaSet "test-recreate-deployment-5c8c9cc69d" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-5c8c9cc69d,GenerateName:,Namespace:deployment-4361,SelfLink:/apis/apps/v1/namespaces/deployment-4361/replicasets/test-recreate-deployment-5c8c9cc69d,UID:06d08be1-39f2-4a36-bc63-262ad43fcec6,ResourceVersion:30725,Generation:1,CreationTimestamp:2020-02-17 17:05:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5c8c9cc69d,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 084ecdd9-346a-4e08-8837-1b32f3ad3d55 0xc000b136d7 0xc000b136d8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 5c8c9cc69d,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5c8c9cc69d,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Feb 17 17:05:29.729: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Feb 17 17:05:29.729: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-6df85df6b9,GenerateName:,Namespace:deployment-4361,SelfLink:/apis/apps/v1/namespaces/deployment-4361/replicasets/test-recreate-deployment-6df85df6b9,UID:4f7fbbdf-4dcb-4c40-9eb6-bb973e4859fe,ResourceVersion:30714,Generation:2,CreationTimestamp:2020-02-17 17:05:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 6df85df6b9,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 084ecdd9-346a-4e08-8837-1b32f3ad3d55 0xc000b137a7 0xc000b137a8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 6df85df6b9,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 6df85df6b9,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Feb 17 17:05:29.741: INFO: Pod "test-recreate-deployment-5c8c9cc69d-x8qzc" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-5c8c9cc69d-x8qzc,GenerateName:test-recreate-deployment-5c8c9cc69d-,Namespace:deployment-4361,SelfLink:/api/v1/namespaces/deployment-4361/pods/test-recreate-deployment-5c8c9cc69d-x8qzc,UID:3554864a-6748-4893-a142-3b7a6ce9350f,ResourceVersion:30727,Generation:0,CreationTimestamp:2020-02-17 17:05:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5c8c9cc69d,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-recreate-deployment-5c8c9cc69d 06d08be1-39f2-4a36-bc63-262ad43fcec6 0xc002b20167 0xc002b20168}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-cf7b4 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-cf7b4,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-cf7b4 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.242.0.98,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002b201e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002b20200}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-17 17:05:29 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-17 17:05:29 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-17 17:05:29 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-17 17:05:29 +0000 UTC  }],Message:,Reason:,HostIP:10.242.0.98,PodIP:,StartTime:2020-02-17 17:05:29 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 17:05:29.741: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-4361" for this suite.
Feb 17 17:05:37.928: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:05:38.381: INFO: namespace deployment-4361 deletion completed in 8.621319898s

• [SLOW TEST:13.194 seconds]
[sig-apps] Deployment
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 17:05:38.381: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-4712
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:81
Feb 17 17:05:38.640: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Feb 17 17:05:38.674: INFO: Waiting for terminating namespaces to be deleted...
Feb 17 17:05:38.688: INFO: 
Logging pods the kubelet thinks is on node 10.242.0.59 before test
Feb 17 17:05:38.738: INFO: ibm-master-proxy-static-10.242.0.59 from kube-system started at 2020-02-17 14:44:03 +0000 UTC (2 container statuses recorded)
Feb 17 17:05:38.738: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Feb 17 17:05:38.738: INFO: 	Container pause ready: true, restart count 0
Feb 17 17:05:38.738: INFO: coredns-c6797c986-cc2j9 from kube-system started at 2020-02-17 14:55:56 +0000 UTC (1 container statuses recorded)
Feb 17 17:05:38.738: INFO: 	Container coredns ready: true, restart count 0
Feb 17 17:05:38.738: INFO: sonobuoy-systemd-logs-daemon-set-6f65da6b108e4900-wmp7s from sonobuoy started at 2020-02-17 16:14:12 +0000 UTC (2 container statuses recorded)
Feb 17 17:05:38.738: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb 17 17:05:38.738: INFO: 	Container systemd-logs ready: true, restart count 0
Feb 17 17:05:38.738: INFO: public-crbp5a1mjl0i8s7ceo0p0g-alb1-9c9db77cc-652w8 from kube-system started at 2020-02-17 14:46:17 +0000 UTC (4 container statuses recorded)
Feb 17 17:05:38.738: INFO: 	Container ingress-auth-1 ready: true, restart count 0
Feb 17 17:05:38.738: INFO: 	Container ingress-auth-2 ready: true, restart count 1
Feb 17 17:05:38.738: INFO: 	Container ingress-auth-3 ready: true, restart count 1
Feb 17 17:05:38.738: INFO: 	Container nginx-ingress ready: true, restart count 0
Feb 17 17:05:38.738: INFO: ibm-vpc-block-csi-node-t57kv from kube-system started at 2020-02-17 14:46:10 +0000 UTC (2 container statuses recorded)
Feb 17 17:05:38.738: INFO: 	Container csi-driver-registrar ready: true, restart count 0
Feb 17 17:05:38.738: INFO: 	Container iks-vpc-block-node-driver ready: true, restart count 0
Feb 17 17:05:38.738: INFO: calico-node-nt7xm from kube-system started at 2020-02-17 14:46:00 +0000 UTC (1 container statuses recorded)
Feb 17 17:05:38.738: INFO: 	Container calico-node ready: true, restart count 0
Feb 17 17:05:38.738: INFO: 
Logging pods the kubelet thinks is on node 10.242.0.63 before test
Feb 17 17:05:38.856: INFO: calico-kube-controllers-b449456b9-7xvhd from kube-system started at 2020-02-17 14:46:06 +0000 UTC (1 container statuses recorded)
Feb 17 17:05:38.856: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Feb 17 17:05:38.856: INFO: metrics-server-5dfbdfb747-ttl59 from kube-system started at 2020-02-17 14:46:28 +0000 UTC (2 container statuses recorded)
Feb 17 17:05:38.856: INFO: 	Container metrics-server ready: true, restart count 0
Feb 17 17:05:38.856: INFO: 	Container metrics-server-nanny ready: true, restart count 0
Feb 17 17:05:38.856: INFO: sonobuoy-systemd-logs-daemon-set-6f65da6b108e4900-mvgt7 from sonobuoy started at 2020-02-17 16:14:12 +0000 UTC (2 container statuses recorded)
Feb 17 17:05:38.856: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb 17 17:05:38.856: INFO: 	Container systemd-logs ready: true, restart count 0
Feb 17 17:05:38.856: INFO: public-crbp5a1mjl0i8s7ceo0p0g-alb1-9c9db77cc-hb966 from kube-system started at 2020-02-17 14:46:06 +0000 UTC (4 container statuses recorded)
Feb 17 17:05:38.856: INFO: 	Container ingress-auth-1 ready: true, restart count 1
Feb 17 17:05:38.856: INFO: 	Container ingress-auth-2 ready: true, restart count 1
Feb 17 17:05:38.856: INFO: 	Container ingress-auth-3 ready: true, restart count 1
Feb 17 17:05:38.856: INFO: 	Container nginx-ingress ready: true, restart count 0
Feb 17 17:05:38.856: INFO: ibm-vpc-block-csi-controller-0 from kube-system started at 2020-02-17 14:46:06 +0000 UTC (3 container statuses recorded)
Feb 17 17:05:38.856: INFO: 	Container csi-attacher ready: true, restart count 0
Feb 17 17:05:38.856: INFO: 	Container csi-provisioner ready: true, restart count 0
Feb 17 17:05:38.856: INFO: 	Container iks-vpc-block-driver ready: true, restart count 0
Feb 17 17:05:38.856: INFO: ibm-vpc-block-csi-node-44qtk from kube-system started at 2020-02-17 14:45:58 +0000 UTC (2 container statuses recorded)
Feb 17 17:05:38.856: INFO: 	Container csi-driver-registrar ready: true, restart count 0
Feb 17 17:05:38.856: INFO: 	Container iks-vpc-block-node-driver ready: true, restart count 0
Feb 17 17:05:38.856: INFO: coredns-autoscaler-65bc7cb8b5-246qr from kube-system started at 2020-02-17 14:46:06 +0000 UTC (1 container statuses recorded)
Feb 17 17:05:38.856: INFO: 	Container autoscaler ready: true, restart count 0
Feb 17 17:05:38.856: INFO: kubernetes-dashboard-656d9457bf-2qq9c from kube-system started at 2020-02-17 14:46:06 +0000 UTC (1 container statuses recorded)
Feb 17 17:05:38.856: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Feb 17 17:05:38.856: INFO: ibm-master-proxy-static-10.242.0.63 from kube-system started at 2020-02-17 14:43:57 +0000 UTC (2 container statuses recorded)
Feb 17 17:05:38.856: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Feb 17 17:05:38.856: INFO: 	Container pause ready: true, restart count 0
Feb 17 17:05:38.856: INFO: calico-node-2wvjj from kube-system started at 2020-02-17 14:45:48 +0000 UTC (1 container statuses recorded)
Feb 17 17:05:38.856: INFO: 	Container calico-node ready: true, restart count 0
Feb 17 17:05:38.856: INFO: vpn-bd4d5cff7-5tpm4 from kube-system started at 2020-02-17 14:55:34 +0000 UTC (1 container statuses recorded)
Feb 17 17:05:38.856: INFO: 	Container vpn ready: true, restart count 0
Feb 17 17:05:38.856: INFO: 
Logging pods the kubelet thinks is on node 10.242.0.98 before test
Feb 17 17:05:38.898: INFO: ibm-master-proxy-static-10.242.0.98 from kube-system started at 2020-02-17 14:44:09 +0000 UTC (2 container statuses recorded)
Feb 17 17:05:38.898: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Feb 17 17:05:38.898: INFO: 	Container pause ready: true, restart count 0
Feb 17 17:05:38.898: INFO: coredns-c6797c986-rsp2r from kube-system started at 2020-02-17 14:55:56 +0000 UTC (1 container statuses recorded)
Feb 17 17:05:38.898: INFO: 	Container coredns ready: true, restart count 0
Feb 17 17:05:38.898: INFO: sonobuoy-systemd-logs-daemon-set-6f65da6b108e4900-fvg5d from sonobuoy started at 2020-02-17 16:14:12 +0000 UTC (2 container statuses recorded)
Feb 17 17:05:38.898: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb 17 17:05:38.898: INFO: 	Container systemd-logs ready: true, restart count 0
Feb 17 17:05:38.898: INFO: sonobuoy from sonobuoy started at 2020-02-17 16:14:06 +0000 UTC (1 container statuses recorded)
Feb 17 17:05:38.898: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Feb 17 17:05:38.898: INFO: ibm-vpc-block-csi-node-lnnpn from kube-system started at 2020-02-17 14:46:30 +0000 UTC (2 container statuses recorded)
Feb 17 17:05:38.898: INFO: 	Container csi-driver-registrar ready: true, restart count 0
Feb 17 17:05:38.898: INFO: 	Container iks-vpc-block-node-driver ready: true, restart count 0
Feb 17 17:05:38.898: INFO: calico-node-ch65n from kube-system started at 2020-02-17 14:46:20 +0000 UTC (1 container statuses recorded)
Feb 17 17:05:38.898: INFO: 	Container calico-node ready: true, restart count 0
Feb 17 17:05:38.898: INFO: test-k8s-e2e-pvg-master-verification from default started at 2020-02-17 14:50:10 +0000 UTC (1 container statuses recorded)
Feb 17 17:05:38.898: INFO: 	Container test-k8s-e2e-pvg-master-verification ready: true, restart count 0
Feb 17 17:05:38.898: INFO: sonobuoy-e2e-job-8b0d4acd71ee4040 from sonobuoy started at 2020-02-17 16:14:12 +0000 UTC (2 container statuses recorded)
Feb 17 17:05:38.898: INFO: 	Container e2e ready: true, restart count 0
Feb 17 17:05:38.898: INFO: 	Container sonobuoy-worker ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.15f43f748edcb79e], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 17:05:39.971: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-4712" for this suite.
Feb 17 17:05:46.046: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:05:46.558: INFO: namespace sched-pred-4712 deletion completed in 6.568224776s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:72

• [SLOW TEST:8.176 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 17:05:46.558: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-9358
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-774e5acf-3764-47b7-8dee-7cf9a01a6b4d
STEP: Creating a pod to test consume configMaps
Feb 17 17:05:46.856: INFO: Waiting up to 5m0s for pod "pod-configmaps-e662f6b2-d60b-4e8e-a871-6a87bea64701" in namespace "configmap-9358" to be "success or failure"
Feb 17 17:05:46.867: INFO: Pod "pod-configmaps-e662f6b2-d60b-4e8e-a871-6a87bea64701": Phase="Pending", Reason="", readiness=false. Elapsed: 10.777987ms
Feb 17 17:05:48.879: INFO: Pod "pod-configmaps-e662f6b2-d60b-4e8e-a871-6a87bea64701": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.023227189s
STEP: Saw pod success
Feb 17 17:05:48.879: INFO: Pod "pod-configmaps-e662f6b2-d60b-4e8e-a871-6a87bea64701" satisfied condition "success or failure"
Feb 17 17:05:48.892: INFO: Trying to get logs from node 10.242.0.59 pod pod-configmaps-e662f6b2-d60b-4e8e-a871-6a87bea64701 container configmap-volume-test: <nil>
STEP: delete the pod
Feb 17 17:05:48.976: INFO: Waiting for pod pod-configmaps-e662f6b2-d60b-4e8e-a871-6a87bea64701 to disappear
Feb 17 17:05:48.985: INFO: Pod pod-configmaps-e662f6b2-d60b-4e8e-a871-6a87bea64701 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 17:05:48.985: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9358" for this suite.
Feb 17 17:05:55.055: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:05:55.473: INFO: namespace configmap-9358 deletion completed in 6.467988434s

• [SLOW TEST:8.915 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 17:05:55.473: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-6817
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Feb 17 17:05:55.728: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Feb 17 17:05:55.751: INFO: Pod name sample-pod: Found 0 pods out of 1
Feb 17 17:06:00.766: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Feb 17 17:06:00.766: INFO: Creating deployment "test-rolling-update-deployment"
Feb 17 17:06:00.781: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Feb 17 17:06:00.808: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Feb 17 17:06:02.832: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Feb 17 17:06:02.846: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717555960, loc:(*time.Location)(0x7ed4a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717555960, loc:(*time.Location)(0x7ed4a20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717555960, loc:(*time.Location)(0x7ed4a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717555960, loc:(*time.Location)(0x7ed4a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-79f6b9d75c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 17 17:06:04.860: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
Feb 17 17:06:04.897: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment,GenerateName:,Namespace:deployment-6817,SelfLink:/apis/apps/v1/namespaces/deployment-6817/deployments/test-rolling-update-deployment,UID:af00b71c-2ca1-43bd-8b84-15403e48afe8,ResourceVersion:30931,Generation:1,CreationTimestamp:2020-02-17 17:06:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2020-02-17 17:06:00 +0000 UTC 2020-02-17 17:06:00 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2020-02-17 17:06:02 +0000 UTC 2020-02-17 17:06:00 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rolling-update-deployment-79f6b9d75c" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Feb 17 17:06:04.907: INFO: New ReplicaSet "test-rolling-update-deployment-79f6b9d75c" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-79f6b9d75c,GenerateName:,Namespace:deployment-6817,SelfLink:/apis/apps/v1/namespaces/deployment-6817/replicasets/test-rolling-update-deployment-79f6b9d75c,UID:d0eb634e-c6ef-4a83-ab8e-52268008eea9,ResourceVersion:30921,Generation:1,CreationTimestamp:2020-02-17 17:06:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 79f6b9d75c,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment af00b71c-2ca1-43bd-8b84-15403e48afe8 0xc001cd7e77 0xc001cd7e78}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 79f6b9d75c,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 79f6b9d75c,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Feb 17 17:06:04.907: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Feb 17 17:06:04.907: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-controller,GenerateName:,Namespace:deployment-6817,SelfLink:/apis/apps/v1/namespaces/deployment-6817/replicasets/test-rolling-update-controller,UID:f787b250-f33f-4880-ab86-34122930e72b,ResourceVersion:30930,Generation:2,CreationTimestamp:2020-02-17 17:05:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305832,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment af00b71c-2ca1-43bd-8b84-15403e48afe8 0xc001cd7da7 0xc001cd7da8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Feb 17 17:06:04.919: INFO: Pod "test-rolling-update-deployment-79f6b9d75c-47pf8" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-79f6b9d75c-47pf8,GenerateName:test-rolling-update-deployment-79f6b9d75c-,Namespace:deployment-6817,SelfLink:/api/v1/namespaces/deployment-6817/pods/test-rolling-update-deployment-79f6b9d75c-47pf8,UID:95f27152-9e73-4407-8eed-659edf369fc2,ResourceVersion:30920,Generation:0,CreationTimestamp:2020-02-17 17:06:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 79f6b9d75c,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-rolling-update-deployment-79f6b9d75c d0eb634e-c6ef-4a83-ab8e-52268008eea9 0xc00298e777 0xc00298e778}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-nxw7d {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-nxw7d,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-nxw7d true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.242.0.59,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00298e7f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00298e810}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-17 17:06:00 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2020-02-17 17:06:02 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2020-02-17 17:06:02 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-17 17:06:00 +0000 UTC  }],Message:,Reason:,HostIP:10.242.0.59,PodIP:172.30.94.38,StartTime:2020-02-17 17:06:00 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2020-02-17 17:06:02 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 containerd://ff73f60b9cc76d975aad4d99e07057a8deec7a0e9d155ede131d5ec488c5b59c}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 17:06:04.919: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-6817" for this suite.
Feb 17 17:06:12.985: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:06:13.385: INFO: namespace deployment-6817 deletion completed in 8.447848217s

• [SLOW TEST:17.912 seconds]
[sig-apps] Deployment
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 17:06:13.386: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-7480
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Feb 17 17:06:15.924: INFO: Expected: &{} to match Container's Termination Message:  --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 17:06:15.970: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-7480" for this suite.
Feb 17 17:06:22.042: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:06:22.489: INFO: namespace container-runtime-7480 deletion completed in 6.499700072s

• [SLOW TEST:9.103 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  blackbox test
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
    on terminated container
    /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:129
      should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 17:06:22.492: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-2807
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:81
Feb 17 17:06:22.741: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Feb 17 17:06:22.775: INFO: Waiting for terminating namespaces to be deleted...
Feb 17 17:06:22.789: INFO: 
Logging pods the kubelet thinks is on node 10.242.0.59 before test
Feb 17 17:06:22.830: INFO: coredns-c6797c986-cc2j9 from kube-system started at 2020-02-17 14:55:56 +0000 UTC (1 container statuses recorded)
Feb 17 17:06:22.830: INFO: 	Container coredns ready: true, restart count 0
Feb 17 17:06:22.830: INFO: sonobuoy-systemd-logs-daemon-set-6f65da6b108e4900-wmp7s from sonobuoy started at 2020-02-17 16:14:12 +0000 UTC (2 container statuses recorded)
Feb 17 17:06:22.830: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb 17 17:06:22.830: INFO: 	Container systemd-logs ready: true, restart count 0
Feb 17 17:06:22.830: INFO: public-crbp5a1mjl0i8s7ceo0p0g-alb1-9c9db77cc-652w8 from kube-system started at 2020-02-17 14:46:17 +0000 UTC (4 container statuses recorded)
Feb 17 17:06:22.830: INFO: 	Container ingress-auth-1 ready: true, restart count 0
Feb 17 17:06:22.830: INFO: 	Container ingress-auth-2 ready: true, restart count 1
Feb 17 17:06:22.830: INFO: 	Container ingress-auth-3 ready: true, restart count 1
Feb 17 17:06:22.830: INFO: 	Container nginx-ingress ready: true, restart count 0
Feb 17 17:06:22.830: INFO: ibm-vpc-block-csi-node-t57kv from kube-system started at 2020-02-17 14:46:10 +0000 UTC (2 container statuses recorded)
Feb 17 17:06:22.830: INFO: 	Container csi-driver-registrar ready: true, restart count 0
Feb 17 17:06:22.831: INFO: 	Container iks-vpc-block-node-driver ready: true, restart count 0
Feb 17 17:06:22.831: INFO: calico-node-nt7xm from kube-system started at 2020-02-17 14:46:00 +0000 UTC (1 container statuses recorded)
Feb 17 17:06:22.831: INFO: 	Container calico-node ready: true, restart count 0
Feb 17 17:06:22.831: INFO: ibm-master-proxy-static-10.242.0.59 from kube-system started at 2020-02-17 14:44:03 +0000 UTC (2 container statuses recorded)
Feb 17 17:06:22.831: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Feb 17 17:06:22.831: INFO: 	Container pause ready: true, restart count 0
Feb 17 17:06:22.831: INFO: 
Logging pods the kubelet thinks is on node 10.242.0.63 before test
Feb 17 17:06:22.881: INFO: public-crbp5a1mjl0i8s7ceo0p0g-alb1-9c9db77cc-hb966 from kube-system started at 2020-02-17 14:46:06 +0000 UTC (4 container statuses recorded)
Feb 17 17:06:22.881: INFO: 	Container ingress-auth-1 ready: true, restart count 1
Feb 17 17:06:22.881: INFO: 	Container ingress-auth-2 ready: true, restart count 1
Feb 17 17:06:22.881: INFO: 	Container ingress-auth-3 ready: true, restart count 1
Feb 17 17:06:22.881: INFO: 	Container nginx-ingress ready: true, restart count 0
Feb 17 17:06:22.881: INFO: ibm-vpc-block-csi-controller-0 from kube-system started at 2020-02-17 14:46:06 +0000 UTC (3 container statuses recorded)
Feb 17 17:06:22.881: INFO: 	Container csi-attacher ready: true, restart count 0
Feb 17 17:06:22.881: INFO: 	Container csi-provisioner ready: true, restart count 0
Feb 17 17:06:22.881: INFO: 	Container iks-vpc-block-driver ready: true, restart count 0
Feb 17 17:06:22.881: INFO: sonobuoy-systemd-logs-daemon-set-6f65da6b108e4900-mvgt7 from sonobuoy started at 2020-02-17 16:14:12 +0000 UTC (2 container statuses recorded)
Feb 17 17:06:22.881: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb 17 17:06:22.881: INFO: 	Container systemd-logs ready: true, restart count 0
Feb 17 17:06:22.881: INFO: coredns-autoscaler-65bc7cb8b5-246qr from kube-system started at 2020-02-17 14:46:06 +0000 UTC (1 container statuses recorded)
Feb 17 17:06:22.881: INFO: 	Container autoscaler ready: true, restart count 0
Feb 17 17:06:22.881: INFO: ibm-vpc-block-csi-node-44qtk from kube-system started at 2020-02-17 14:45:58 +0000 UTC (2 container statuses recorded)
Feb 17 17:06:22.882: INFO: 	Container csi-driver-registrar ready: true, restart count 0
Feb 17 17:06:22.882: INFO: 	Container iks-vpc-block-node-driver ready: true, restart count 0
Feb 17 17:06:22.882: INFO: calico-node-2wvjj from kube-system started at 2020-02-17 14:45:48 +0000 UTC (1 container statuses recorded)
Feb 17 17:06:22.882: INFO: 	Container calico-node ready: true, restart count 0
Feb 17 17:06:22.882: INFO: vpn-bd4d5cff7-5tpm4 from kube-system started at 2020-02-17 14:55:34 +0000 UTC (1 container statuses recorded)
Feb 17 17:06:22.882: INFO: 	Container vpn ready: true, restart count 0
Feb 17 17:06:22.882: INFO: kubernetes-dashboard-656d9457bf-2qq9c from kube-system started at 2020-02-17 14:46:06 +0000 UTC (1 container statuses recorded)
Feb 17 17:06:22.882: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Feb 17 17:06:22.882: INFO: ibm-master-proxy-static-10.242.0.63 from kube-system started at 2020-02-17 14:43:57 +0000 UTC (2 container statuses recorded)
Feb 17 17:06:22.882: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Feb 17 17:06:22.882: INFO: 	Container pause ready: true, restart count 0
Feb 17 17:06:22.882: INFO: metrics-server-5dfbdfb747-ttl59 from kube-system started at 2020-02-17 14:46:28 +0000 UTC (2 container statuses recorded)
Feb 17 17:06:22.882: INFO: 	Container metrics-server ready: true, restart count 0
Feb 17 17:06:22.882: INFO: 	Container metrics-server-nanny ready: true, restart count 0
Feb 17 17:06:22.882: INFO: calico-kube-controllers-b449456b9-7xvhd from kube-system started at 2020-02-17 14:46:06 +0000 UTC (1 container statuses recorded)
Feb 17 17:06:22.882: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Feb 17 17:06:22.882: INFO: 
Logging pods the kubelet thinks is on node 10.242.0.98 before test
Feb 17 17:06:22.926: INFO: sonobuoy from sonobuoy started at 2020-02-17 16:14:06 +0000 UTC (1 container statuses recorded)
Feb 17 17:06:22.926: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Feb 17 17:06:22.926: INFO: ibm-vpc-block-csi-node-lnnpn from kube-system started at 2020-02-17 14:46:30 +0000 UTC (2 container statuses recorded)
Feb 17 17:06:22.926: INFO: 	Container csi-driver-registrar ready: true, restart count 0
Feb 17 17:06:22.926: INFO: 	Container iks-vpc-block-node-driver ready: true, restart count 0
Feb 17 17:06:22.926: INFO: calico-node-ch65n from kube-system started at 2020-02-17 14:46:20 +0000 UTC (1 container statuses recorded)
Feb 17 17:06:22.926: INFO: 	Container calico-node ready: true, restart count 0
Feb 17 17:06:22.926: INFO: test-k8s-e2e-pvg-master-verification from default started at 2020-02-17 14:50:10 +0000 UTC (1 container statuses recorded)
Feb 17 17:06:22.926: INFO: 	Container test-k8s-e2e-pvg-master-verification ready: true, restart count 0
Feb 17 17:06:22.926: INFO: sonobuoy-e2e-job-8b0d4acd71ee4040 from sonobuoy started at 2020-02-17 16:14:12 +0000 UTC (2 container statuses recorded)
Feb 17 17:06:22.926: INFO: 	Container e2e ready: true, restart count 0
Feb 17 17:06:22.926: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb 17 17:06:22.926: INFO: ibm-master-proxy-static-10.242.0.98 from kube-system started at 2020-02-17 14:44:09 +0000 UTC (2 container statuses recorded)
Feb 17 17:06:22.926: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Feb 17 17:06:22.926: INFO: 	Container pause ready: true, restart count 0
Feb 17 17:06:22.926: INFO: coredns-c6797c986-rsp2r from kube-system started at 2020-02-17 14:55:56 +0000 UTC (1 container statuses recorded)
Feb 17 17:06:22.926: INFO: 	Container coredns ready: true, restart count 0
Feb 17 17:06:22.926: INFO: sonobuoy-systemd-logs-daemon-set-6f65da6b108e4900-fvg5d from sonobuoy started at 2020-02-17 16:14:12 +0000 UTC (2 container statuses recorded)
Feb 17 17:06:22.926: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb 17 17:06:22.926: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-8a686990-c499-4078-982c-a0900b5117d3 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-8a686990-c499-4078-982c-a0900b5117d3 off the node 10.242.0.59
STEP: verifying the node doesn't have the label kubernetes.io/e2e-8a686990-c499-4078-982c-a0900b5117d3
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 17:06:27.154: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-2807" for this suite.
Feb 17 17:06:37.223: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:06:37.633: INFO: namespace sched-pred-2807 deletion completed in 10.461385303s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:72

• [SLOW TEST:15.141 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 17:06:37.634: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-7208
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 17:06:42.987: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-7208" for this suite.
Feb 17 17:07:07.059: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:07:07.453: INFO: namespace replication-controller-7208 deletion completed in 24.446906061s

• [SLOW TEST:29.819 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 17:07:07.454: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-2257
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod busybox-45d14f44-488e-41ca-9726-daa4647819cb in namespace container-probe-2257
Feb 17 17:07:11.767: INFO: Started pod busybox-45d14f44-488e-41ca-9726-daa4647819cb in namespace container-probe-2257
STEP: checking the pod's current state and verifying that restartCount is present
Feb 17 17:07:11.777: INFO: Initial restart count of pod busybox-45d14f44-488e-41ca-9726-daa4647819cb is 0
Feb 17 17:07:58.095: INFO: Restart count of pod container-probe-2257/busybox-45d14f44-488e-41ca-9726-daa4647819cb is now 1 (46.317790292s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 17:07:58.130: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-2257" for this suite.
Feb 17 17:08:04.206: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:08:04.605: INFO: namespace container-probe-2257 deletion completed in 6.455203929s

• [SLOW TEST:57.152 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 17:08:04.606: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2290
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Feb 17 17:08:04.888: INFO: Waiting up to 5m0s for pod "downwardapi-volume-33471d4c-cd9c-4ebc-a240-957cd9c88daf" in namespace "projected-2290" to be "success or failure"
Feb 17 17:08:04.901: INFO: Pod "downwardapi-volume-33471d4c-cd9c-4ebc-a240-957cd9c88daf": Phase="Pending", Reason="", readiness=false. Elapsed: 12.850942ms
Feb 17 17:08:06.915: INFO: Pod "downwardapi-volume-33471d4c-cd9c-4ebc-a240-957cd9c88daf": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026532688s
Feb 17 17:08:08.928: INFO: Pod "downwardapi-volume-33471d4c-cd9c-4ebc-a240-957cd9c88daf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.039794454s
STEP: Saw pod success
Feb 17 17:08:08.928: INFO: Pod "downwardapi-volume-33471d4c-cd9c-4ebc-a240-957cd9c88daf" satisfied condition "success or failure"
Feb 17 17:08:08.940: INFO: Trying to get logs from node 10.242.0.98 pod downwardapi-volume-33471d4c-cd9c-4ebc-a240-957cd9c88daf container client-container: <nil>
STEP: delete the pod
Feb 17 17:08:09.007: INFO: Waiting for pod downwardapi-volume-33471d4c-cd9c-4ebc-a240-957cd9c88daf to disappear
Feb 17 17:08:09.022: INFO: Pod downwardapi-volume-33471d4c-cd9c-4ebc-a240-957cd9c88daf no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 17:08:09.022: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2290" for this suite.
Feb 17 17:08:15.108: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:08:15.521: INFO: namespace projected-2290 deletion completed in 6.478639362s

• [SLOW TEST:10.915 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 17:08:15.522: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-7698
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-0b011b8c-bb5c-4810-a8e8-c368acde51a8
STEP: Creating a pod to test consume configMaps
Feb 17 17:08:15.812: INFO: Waiting up to 5m0s for pod "pod-configmaps-7b0ce04e-578d-472a-bb31-8775b8ef6496" in namespace "configmap-7698" to be "success or failure"
Feb 17 17:08:15.823: INFO: Pod "pod-configmaps-7b0ce04e-578d-472a-bb31-8775b8ef6496": Phase="Pending", Reason="", readiness=false. Elapsed: 11.291819ms
Feb 17 17:08:17.835: INFO: Pod "pod-configmaps-7b0ce04e-578d-472a-bb31-8775b8ef6496": Phase="Running", Reason="", readiness=true. Elapsed: 2.022801783s
Feb 17 17:08:19.846: INFO: Pod "pod-configmaps-7b0ce04e-578d-472a-bb31-8775b8ef6496": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.034493555s
STEP: Saw pod success
Feb 17 17:08:19.846: INFO: Pod "pod-configmaps-7b0ce04e-578d-472a-bb31-8775b8ef6496" satisfied condition "success or failure"
Feb 17 17:08:19.857: INFO: Trying to get logs from node 10.242.0.59 pod pod-configmaps-7b0ce04e-578d-472a-bb31-8775b8ef6496 container configmap-volume-test: <nil>
STEP: delete the pod
Feb 17 17:08:19.919: INFO: Waiting for pod pod-configmaps-7b0ce04e-578d-472a-bb31-8775b8ef6496 to disappear
Feb 17 17:08:19.933: INFO: Pod pod-configmaps-7b0ce04e-578d-472a-bb31-8775b8ef6496 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 17:08:19.933: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7698" for this suite.
Feb 17 17:08:25.999: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:08:26.399: INFO: namespace configmap-7698 deletion completed in 6.448311188s

• [SLOW TEST:10.877 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 17:08:26.399: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-1785
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0777 on node default medium
Feb 17 17:08:26.677: INFO: Waiting up to 5m0s for pod "pod-83ee8979-e6be-4ba6-b3b1-921c88061328" in namespace "emptydir-1785" to be "success or failure"
Feb 17 17:08:26.691: INFO: Pod "pod-83ee8979-e6be-4ba6-b3b1-921c88061328": Phase="Pending", Reason="", readiness=false. Elapsed: 14.044138ms
Feb 17 17:08:28.704: INFO: Pod "pod-83ee8979-e6be-4ba6-b3b1-921c88061328": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.026760451s
STEP: Saw pod success
Feb 17 17:08:28.704: INFO: Pod "pod-83ee8979-e6be-4ba6-b3b1-921c88061328" satisfied condition "success or failure"
Feb 17 17:08:28.714: INFO: Trying to get logs from node 10.242.0.98 pod pod-83ee8979-e6be-4ba6-b3b1-921c88061328 container test-container: <nil>
STEP: delete the pod
Feb 17 17:08:28.779: INFO: Waiting for pod pod-83ee8979-e6be-4ba6-b3b1-921c88061328 to disappear
Feb 17 17:08:28.790: INFO: Pod pod-83ee8979-e6be-4ba6-b3b1-921c88061328 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 17:08:28.790: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1785" for this suite.
Feb 17 17:08:34.860: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:08:35.255: INFO: namespace emptydir-1785 deletion completed in 6.442820973s

• [SLOW TEST:8.856 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 17:08:35.255: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1814
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-projected-all-test-volume-ecc7f996-d80f-4d54-84b2-03a0ef568d0d
STEP: Creating secret with name secret-projected-all-test-volume-b7a6fc4c-cc57-4808-b901-71de950eaf24
STEP: Creating a pod to test Check all projections for projected volume plugin
Feb 17 17:08:35.552: INFO: Waiting up to 5m0s for pod "projected-volume-d2c1b45e-d33d-4975-bc91-df6c8cafb562" in namespace "projected-1814" to be "success or failure"
Feb 17 17:08:35.563: INFO: Pod "projected-volume-d2c1b45e-d33d-4975-bc91-df6c8cafb562": Phase="Pending", Reason="", readiness=false. Elapsed: 11.140845ms
Feb 17 17:08:37.575: INFO: Pod "projected-volume-d2c1b45e-d33d-4975-bc91-df6c8cafb562": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.023009828s
STEP: Saw pod success
Feb 17 17:08:37.575: INFO: Pod "projected-volume-d2c1b45e-d33d-4975-bc91-df6c8cafb562" satisfied condition "success or failure"
Feb 17 17:08:37.586: INFO: Trying to get logs from node 10.242.0.59 pod projected-volume-d2c1b45e-d33d-4975-bc91-df6c8cafb562 container projected-all-volume-test: <nil>
STEP: delete the pod
Feb 17 17:08:37.650: INFO: Waiting for pod projected-volume-d2c1b45e-d33d-4975-bc91-df6c8cafb562 to disappear
Feb 17 17:08:37.661: INFO: Pod projected-volume-d2c1b45e-d33d-4975-bc91-df6c8cafb562 no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 17:08:37.661: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1814" for this suite.
Feb 17 17:08:43.735: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:08:44.130: INFO: namespace projected-1814 deletion completed in 6.446172688s

• [SLOW TEST:8.874 seconds]
[sig-storage] Projected combined
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_combined.go:31
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 17:08:44.131: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-7173
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap configmap-7173/configmap-test-5ea52404-41da-4107-90ca-9a3b68303210
STEP: Creating a pod to test consume configMaps
Feb 17 17:08:44.431: INFO: Waiting up to 5m0s for pod "pod-configmaps-c6cfb955-d681-472a-9071-6b96f70f1f87" in namespace "configmap-7173" to be "success or failure"
Feb 17 17:08:44.444: INFO: Pod "pod-configmaps-c6cfb955-d681-472a-9071-6b96f70f1f87": Phase="Pending", Reason="", readiness=false. Elapsed: 12.503002ms
Feb 17 17:08:46.456: INFO: Pod "pod-configmaps-c6cfb955-d681-472a-9071-6b96f70f1f87": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0245927s
STEP: Saw pod success
Feb 17 17:08:46.456: INFO: Pod "pod-configmaps-c6cfb955-d681-472a-9071-6b96f70f1f87" satisfied condition "success or failure"
Feb 17 17:08:46.467: INFO: Trying to get logs from node 10.242.0.98 pod pod-configmaps-c6cfb955-d681-472a-9071-6b96f70f1f87 container env-test: <nil>
STEP: delete the pod
Feb 17 17:08:46.535: INFO: Waiting for pod pod-configmaps-c6cfb955-d681-472a-9071-6b96f70f1f87 to disappear
Feb 17 17:08:46.546: INFO: Pod pod-configmaps-c6cfb955-d681-472a-9071-6b96f70f1f87 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 17:08:46.546: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7173" for this suite.
Feb 17 17:08:52.621: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:08:53.028: INFO: namespace configmap-7173 deletion completed in 6.46066284s

• [SLOW TEST:8.897 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 17:08:53.029: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-6003
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir volume type on tmpfs
Feb 17 17:08:53.306: INFO: Waiting up to 5m0s for pod "pod-d59969cf-e949-4ef1-a122-673b06a0b01f" in namespace "emptydir-6003" to be "success or failure"
Feb 17 17:08:53.318: INFO: Pod "pod-d59969cf-e949-4ef1-a122-673b06a0b01f": Phase="Pending", Reason="", readiness=false. Elapsed: 11.3437ms
Feb 17 17:08:55.330: INFO: Pod "pod-d59969cf-e949-4ef1-a122-673b06a0b01f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.023653454s
STEP: Saw pod success
Feb 17 17:08:55.330: INFO: Pod "pod-d59969cf-e949-4ef1-a122-673b06a0b01f" satisfied condition "success or failure"
Feb 17 17:08:55.342: INFO: Trying to get logs from node 10.242.0.59 pod pod-d59969cf-e949-4ef1-a122-673b06a0b01f container test-container: <nil>
STEP: delete the pod
Feb 17 17:08:55.420: INFO: Waiting for pod pod-d59969cf-e949-4ef1-a122-673b06a0b01f to disappear
Feb 17 17:08:55.431: INFO: Pod pod-d59969cf-e949-4ef1-a122-673b06a0b01f no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 17:08:55.431: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6003" for this suite.
Feb 17 17:09:01.498: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:09:01.909: INFO: namespace emptydir-6003 deletion completed in 6.460879813s

• [SLOW TEST:8.880 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 17:09:01.911: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-7765
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Feb 17 17:09:02.187: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0e653176-454b-4b99-ba84-c5b6502bd624" in namespace "downward-api-7765" to be "success or failure"
Feb 17 17:09:02.198: INFO: Pod "downwardapi-volume-0e653176-454b-4b99-ba84-c5b6502bd624": Phase="Pending", Reason="", readiness=false. Elapsed: 11.551424ms
Feb 17 17:09:04.210: INFO: Pod "downwardapi-volume-0e653176-454b-4b99-ba84-c5b6502bd624": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.023623245s
STEP: Saw pod success
Feb 17 17:09:04.210: INFO: Pod "downwardapi-volume-0e653176-454b-4b99-ba84-c5b6502bd624" satisfied condition "success or failure"
Feb 17 17:09:04.221: INFO: Trying to get logs from node 10.242.0.98 pod downwardapi-volume-0e653176-454b-4b99-ba84-c5b6502bd624 container client-container: <nil>
STEP: delete the pod
Feb 17 17:09:04.284: INFO: Waiting for pod downwardapi-volume-0e653176-454b-4b99-ba84-c5b6502bd624 to disappear
Feb 17 17:09:04.295: INFO: Pod downwardapi-volume-0e653176-454b-4b99-ba84-c5b6502bd624 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 17:09:04.296: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7765" for this suite.
Feb 17 17:09:10.365: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:09:10.768: INFO: namespace downward-api-7765 deletion completed in 6.452254522s

• [SLOW TEST:8.857 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 17:09:10.769: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-1570
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Starting the proxy
Feb 17 17:09:11.027: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-079603707 proxy --unix-socket=/tmp/kubectl-proxy-unix546784030/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 17:09:11.093: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1570" for this suite.
Feb 17 17:09:17.160: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:09:17.554: INFO: namespace kubectl-1570 deletion completed in 6.443921787s

• [SLOW TEST:6.785 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Proxy server
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 17:09:17.555: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-9185
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:273
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the initial replication controller
Feb 17 17:09:17.822: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-079603707 create -f - --namespace=kubectl-9185'
Feb 17 17:09:18.398: INFO: stderr: ""
Feb 17 17:09:18.398: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb 17 17:09:18.398: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-079603707 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9185'
Feb 17 17:09:18.577: INFO: stderr: ""
Feb 17 17:09:18.577: INFO: stdout: "update-demo-nautilus-7hj68 update-demo-nautilus-zr2hb "
Feb 17 17:09:18.577: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-079603707 get pods update-demo-nautilus-7hj68 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9185'
Feb 17 17:09:18.702: INFO: stderr: ""
Feb 17 17:09:18.702: INFO: stdout: ""
Feb 17 17:09:18.702: INFO: update-demo-nautilus-7hj68 is created but not running
Feb 17 17:09:23.702: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-079603707 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9185'
Feb 17 17:09:23.832: INFO: stderr: ""
Feb 17 17:09:23.832: INFO: stdout: "update-demo-nautilus-7hj68 update-demo-nautilus-zr2hb "
Feb 17 17:09:23.832: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-079603707 get pods update-demo-nautilus-7hj68 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9185'
Feb 17 17:09:23.964: INFO: stderr: ""
Feb 17 17:09:23.964: INFO: stdout: "true"
Feb 17 17:09:23.964: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-079603707 get pods update-demo-nautilus-7hj68 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9185'
Feb 17 17:09:24.100: INFO: stderr: ""
Feb 17 17:09:24.100: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 17 17:09:24.100: INFO: validating pod update-demo-nautilus-7hj68
Feb 17 17:09:24.132: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 17 17:09:24.132: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 17 17:09:24.132: INFO: update-demo-nautilus-7hj68 is verified up and running
Feb 17 17:09:24.132: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-079603707 get pods update-demo-nautilus-zr2hb -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9185'
Feb 17 17:09:24.263: INFO: stderr: ""
Feb 17 17:09:24.263: INFO: stdout: "true"
Feb 17 17:09:24.263: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-079603707 get pods update-demo-nautilus-zr2hb -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9185'
Feb 17 17:09:24.401: INFO: stderr: ""
Feb 17 17:09:24.401: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 17 17:09:24.401: INFO: validating pod update-demo-nautilus-zr2hb
Feb 17 17:09:24.429: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 17 17:09:24.429: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 17 17:09:24.429: INFO: update-demo-nautilus-zr2hb is verified up and running
STEP: rolling-update to new replication controller
Feb 17 17:09:24.431: INFO: scanned /root for discovery docs: <nil>
Feb 17 17:09:24.431: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-079603707 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=kubectl-9185'
Feb 17 17:09:47.517: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Feb 17 17:09:47.517: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb 17 17:09:47.517: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-079603707 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9185'
Feb 17 17:09:47.655: INFO: stderr: ""
Feb 17 17:09:47.655: INFO: stdout: "update-demo-kitten-dtvhj update-demo-kitten-zw6j9 update-demo-nautilus-7hj68 "
STEP: Replicas for name=update-demo: expected=2 actual=3
Feb 17 17:09:52.655: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-079603707 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9185'
Feb 17 17:09:52.813: INFO: stderr: ""
Feb 17 17:09:52.813: INFO: stdout: "update-demo-kitten-dtvhj update-demo-kitten-zw6j9 "
Feb 17 17:09:52.814: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-079603707 get pods update-demo-kitten-dtvhj -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9185'
Feb 17 17:09:52.946: INFO: stderr: ""
Feb 17 17:09:52.946: INFO: stdout: "true"
Feb 17 17:09:52.946: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-079603707 get pods update-demo-kitten-dtvhj -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9185'
Feb 17 17:09:53.079: INFO: stderr: ""
Feb 17 17:09:53.079: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Feb 17 17:09:53.079: INFO: validating pod update-demo-kitten-dtvhj
Feb 17 17:09:54.122: INFO: got data: {
  "image": "kitten.jpg"
}

Feb 17 17:09:54.122: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Feb 17 17:09:54.122: INFO: update-demo-kitten-dtvhj is verified up and running
Feb 17 17:09:54.122: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-079603707 get pods update-demo-kitten-zw6j9 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9185'
Feb 17 17:09:54.250: INFO: stderr: ""
Feb 17 17:09:54.250: INFO: stdout: "true"
Feb 17 17:09:54.250: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-079603707 get pods update-demo-kitten-zw6j9 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9185'
Feb 17 17:09:54.377: INFO: stderr: ""
Feb 17 17:09:54.377: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Feb 17 17:09:54.377: INFO: validating pod update-demo-kitten-zw6j9
Feb 17 17:09:54.407: INFO: got data: {
  "image": "kitten.jpg"
}

Feb 17 17:09:54.407: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Feb 17 17:09:54.407: INFO: update-demo-kitten-zw6j9 is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 17:09:54.407: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9185" for this suite.
Feb 17 17:10:18.479: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:10:18.889: INFO: namespace kubectl-9185 deletion completed in 24.463725112s

• [SLOW TEST:61.334 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 17:10:18.890: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-6612
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Feb 17 17:10:19.178: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a774ff18-7d6e-442a-a5ca-959db66a20ef" in namespace "downward-api-6612" to be "success or failure"
Feb 17 17:10:19.191: INFO: Pod "downwardapi-volume-a774ff18-7d6e-442a-a5ca-959db66a20ef": Phase="Pending", Reason="", readiness=false. Elapsed: 13.075223ms
Feb 17 17:10:21.202: INFO: Pod "downwardapi-volume-a774ff18-7d6e-442a-a5ca-959db66a20ef": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024391755s
Feb 17 17:10:23.217: INFO: Pod "downwardapi-volume-a774ff18-7d6e-442a-a5ca-959db66a20ef": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.039603921s
STEP: Saw pod success
Feb 17 17:10:23.218: INFO: Pod "downwardapi-volume-a774ff18-7d6e-442a-a5ca-959db66a20ef" satisfied condition "success or failure"
Feb 17 17:10:23.229: INFO: Trying to get logs from node 10.242.0.59 pod downwardapi-volume-a774ff18-7d6e-442a-a5ca-959db66a20ef container client-container: <nil>
STEP: delete the pod
Feb 17 17:10:23.295: INFO: Waiting for pod downwardapi-volume-a774ff18-7d6e-442a-a5ca-959db66a20ef to disappear
Feb 17 17:10:23.305: INFO: Pod downwardapi-volume-a774ff18-7d6e-442a-a5ca-959db66a20ef no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 17:10:23.305: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6612" for this suite.
Feb 17 17:10:29.376: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:10:29.801: INFO: namespace downward-api-6612 deletion completed in 6.477059497s

• [SLOW TEST:10.911 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 17:10:29.801: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-9415
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 17:10:34.159: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-9415" for this suite.
Feb 17 17:11:20.228: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:11:20.615: INFO: namespace kubelet-test-9415 deletion completed in 46.437999258s

• [SLOW TEST:50.815 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when scheduling a busybox Pod with hostAliases
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:136
    should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 17:11:20.616: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-1932
STEP: Waiting for a default service account to be provisioned in namespace
[It] should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: starting a background goroutine to produce watch events
STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 17:11:26.279: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-1932" for this suite.
Feb 17 17:11:32.431: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:11:32.821: INFO: namespace watch-1932 deletion completed in 6.500649309s

• [SLOW TEST:12.205 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 17:11:32.821: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename events
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in events-1329
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Feb 17 17:11:37.183: INFO: &Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-659d7eaa-27a7-47e1-80d5-8d3ffe3b821f,GenerateName:,Namespace:events-1329,SelfLink:/api/v1/namespaces/events-1329/pods/send-events-659d7eaa-27a7-47e1-80d5-8d3ffe3b821f,UID:03e70d21-ee2c-4c88-8348-d99d57f90f89,ResourceVersion:32364,Generation:0,CreationTimestamp:2020-02-17 17:11:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 105663027,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-zng6s {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-zng6s,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-zng6s true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.242.0.59,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003abc340} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003abc360}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-17 17:11:33 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2020-02-17 17:11:36 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2020-02-17 17:11:36 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-17 17:11:33 +0000 UTC  }],Message:,Reason:,HostIP:10.242.0.59,PodIP:172.30.94.52,StartTime:2020-02-17 17:11:33 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2020-02-17 17:11:36 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 gcr.io/kubernetes-e2e-test-images/serve-hostname@sha256:bab70473a6d8ef65a22625dc9a1b0f0452e811530fdbe77e4408523460177ff1 containerd://6a072eae767d21b6daa7fb6166c965c68c495ee53b06c7894096661bc87ad94d}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}

STEP: checking for scheduler event about the pod
Feb 17 17:11:39.195: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Feb 17 17:11:41.207: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 17:11:41.227: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-1329" for this suite.
Feb 17 17:12:21.498: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:12:21.904: INFO: namespace events-1329 deletion completed in 40.6586866s

• [SLOW TEST:49.083 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 17:12:21.907: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-1494
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 17:12:24.248: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-1494" for this suite.
Feb 17 17:13:04.316: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:13:04.818: INFO: namespace kubelet-test-1494 deletion completed in 40.550818122s

• [SLOW TEST:42.911 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when scheduling a busybox command in a pod
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:40
    should print the output to logs [NodeConformance] [Conformance]
    /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 17:13:04.821: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-9970
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-configmap-c2tp
STEP: Creating a pod to test atomic-volume-subpath
Feb 17 17:13:05.127: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-c2tp" in namespace "subpath-9970" to be "success or failure"
Feb 17 17:13:05.141: INFO: Pod "pod-subpath-test-configmap-c2tp": Phase="Pending", Reason="", readiness=false. Elapsed: 13.336218ms
Feb 17 17:13:07.155: INFO: Pod "pod-subpath-test-configmap-c2tp": Phase="Running", Reason="", readiness=true. Elapsed: 2.027368608s
Feb 17 17:13:09.166: INFO: Pod "pod-subpath-test-configmap-c2tp": Phase="Running", Reason="", readiness=true. Elapsed: 4.038754137s
Feb 17 17:13:11.178: INFO: Pod "pod-subpath-test-configmap-c2tp": Phase="Running", Reason="", readiness=true. Elapsed: 6.050811245s
Feb 17 17:13:13.190: INFO: Pod "pod-subpath-test-configmap-c2tp": Phase="Running", Reason="", readiness=true. Elapsed: 8.062289495s
Feb 17 17:13:15.201: INFO: Pod "pod-subpath-test-configmap-c2tp": Phase="Running", Reason="", readiness=true. Elapsed: 10.073697065s
Feb 17 17:13:17.213: INFO: Pod "pod-subpath-test-configmap-c2tp": Phase="Running", Reason="", readiness=true. Elapsed: 12.08497973s
Feb 17 17:13:19.226: INFO: Pod "pod-subpath-test-configmap-c2tp": Phase="Running", Reason="", readiness=true. Elapsed: 14.098150224s
Feb 17 17:13:21.238: INFO: Pod "pod-subpath-test-configmap-c2tp": Phase="Running", Reason="", readiness=true. Elapsed: 16.110281815s
Feb 17 17:13:23.249: INFO: Pod "pod-subpath-test-configmap-c2tp": Phase="Running", Reason="", readiness=true. Elapsed: 18.121553635s
Feb 17 17:13:25.260: INFO: Pod "pod-subpath-test-configmap-c2tp": Phase="Running", Reason="", readiness=true. Elapsed: 20.13257076s
Feb 17 17:13:27.271: INFO: Pod "pod-subpath-test-configmap-c2tp": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.143592118s
STEP: Saw pod success
Feb 17 17:13:27.272: INFO: Pod "pod-subpath-test-configmap-c2tp" satisfied condition "success or failure"
Feb 17 17:13:27.282: INFO: Trying to get logs from node 10.242.0.59 pod pod-subpath-test-configmap-c2tp container test-container-subpath-configmap-c2tp: <nil>
STEP: delete the pod
Feb 17 17:13:27.346: INFO: Waiting for pod pod-subpath-test-configmap-c2tp to disappear
Feb 17 17:13:27.358: INFO: Pod pod-subpath-test-configmap-c2tp no longer exists
STEP: Deleting pod pod-subpath-test-configmap-c2tp
Feb 17 17:13:27.358: INFO: Deleting pod "pod-subpath-test-configmap-c2tp" in namespace "subpath-9970"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 17:13:27.368: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-9970" for this suite.
Feb 17 17:13:33.439: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:13:33.828: INFO: namespace subpath-9970 deletion completed in 6.440812479s

• [SLOW TEST:29.007 seconds]
[sig-storage] Subpath
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with configmap pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 17:13:33.829: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-1912
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0644 on node default medium
Feb 17 17:13:34.122: INFO: Waiting up to 5m0s for pod "pod-97ea79ee-bb73-44b7-b43f-d639b4f325c0" in namespace "emptydir-1912" to be "success or failure"
Feb 17 17:13:34.135: INFO: Pod "pod-97ea79ee-bb73-44b7-b43f-d639b4f325c0": Phase="Pending", Reason="", readiness=false. Elapsed: 12.497674ms
Feb 17 17:13:36.149: INFO: Pod "pod-97ea79ee-bb73-44b7-b43f-d639b4f325c0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.026221942s
STEP: Saw pod success
Feb 17 17:13:36.149: INFO: Pod "pod-97ea79ee-bb73-44b7-b43f-d639b4f325c0" satisfied condition "success or failure"
Feb 17 17:13:36.159: INFO: Trying to get logs from node 10.242.0.98 pod pod-97ea79ee-bb73-44b7-b43f-d639b4f325c0 container test-container: <nil>
STEP: delete the pod
Feb 17 17:13:36.221: INFO: Waiting for pod pod-97ea79ee-bb73-44b7-b43f-d639b4f325c0 to disappear
Feb 17 17:13:36.231: INFO: Pod pod-97ea79ee-bb73-44b7-b43f-d639b4f325c0 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 17:13:36.231: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1912" for this suite.
Feb 17 17:13:42.309: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:13:42.881: INFO: namespace emptydir-1912 deletion completed in 6.626697735s

• [SLOW TEST:9.052 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 17:13:42.882: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename hostpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in hostpath-6914
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test hostPath mode
Feb 17 17:13:43.159: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "hostpath-6914" to be "success or failure"
Feb 17 17:13:43.173: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 14.105937ms
Feb 17 17:13:45.188: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0287586s
Feb 17 17:13:47.199: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.039924748s
STEP: Saw pod success
Feb 17 17:13:47.199: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Feb 17 17:13:47.210: INFO: Trying to get logs from node 10.242.0.59 pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Feb 17 17:13:47.273: INFO: Waiting for pod pod-host-path-test to disappear
Feb 17 17:13:47.284: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 17:13:47.284: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "hostpath-6914" for this suite.
Feb 17 17:13:53.354: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:13:53.758: INFO: namespace hostpath-6914 deletion completed in 6.45663882s

• [SLOW TEST:10.876 seconds]
[sig-storage] HostPath
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 17:13:53.758: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-481
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0644 on tmpfs
Feb 17 17:13:54.059: INFO: Waiting up to 5m0s for pod "pod-c2c0a897-e32b-4aa5-8dc8-5bcee1231b41" in namespace "emptydir-481" to be "success or failure"
Feb 17 17:13:54.071: INFO: Pod "pod-c2c0a897-e32b-4aa5-8dc8-5bcee1231b41": Phase="Pending", Reason="", readiness=false. Elapsed: 12.094967ms
Feb 17 17:13:56.088: INFO: Pod "pod-c2c0a897-e32b-4aa5-8dc8-5bcee1231b41": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.029477121s
STEP: Saw pod success
Feb 17 17:13:56.088: INFO: Pod "pod-c2c0a897-e32b-4aa5-8dc8-5bcee1231b41" satisfied condition "success or failure"
Feb 17 17:13:56.099: INFO: Trying to get logs from node 10.242.0.59 pod pod-c2c0a897-e32b-4aa5-8dc8-5bcee1231b41 container test-container: <nil>
STEP: delete the pod
Feb 17 17:13:56.174: INFO: Waiting for pod pod-c2c0a897-e32b-4aa5-8dc8-5bcee1231b41 to disappear
Feb 17 17:13:56.185: INFO: Pod pod-c2c0a897-e32b-4aa5-8dc8-5bcee1231b41 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 17:13:56.185: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-481" for this suite.
Feb 17 17:14:02.259: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:14:02.652: INFO: namespace emptydir-481 deletion completed in 6.445573311s

• [SLOW TEST:8.894 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 17:14:02.659: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-9075
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Feb 17 17:14:03.022: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Feb 17 17:14:03.046: INFO: Number of nodes with available pods: 0
Feb 17 17:14:03.047: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Feb 17 17:14:03.103: INFO: Number of nodes with available pods: 0
Feb 17 17:14:03.103: INFO: Node 10.242.0.59 is running more than one daemon pod
Feb 17 17:14:04.115: INFO: Number of nodes with available pods: 0
Feb 17 17:14:04.115: INFO: Node 10.242.0.59 is running more than one daemon pod
Feb 17 17:14:05.117: INFO: Number of nodes with available pods: 0
Feb 17 17:14:05.117: INFO: Node 10.242.0.59 is running more than one daemon pod
Feb 17 17:14:06.115: INFO: Number of nodes with available pods: 1
Feb 17 17:14:06.115: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Feb 17 17:14:06.172: INFO: Number of nodes with available pods: 1
Feb 17 17:14:06.172: INFO: Number of running nodes: 0, number of available pods: 1
Feb 17 17:14:07.184: INFO: Number of nodes with available pods: 0
Feb 17 17:14:07.185: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Feb 17 17:14:07.210: INFO: Number of nodes with available pods: 0
Feb 17 17:14:07.210: INFO: Node 10.242.0.59 is running more than one daemon pod
Feb 17 17:14:08.222: INFO: Number of nodes with available pods: 0
Feb 17 17:14:08.222: INFO: Node 10.242.0.59 is running more than one daemon pod
Feb 17 17:14:09.223: INFO: Number of nodes with available pods: 0
Feb 17 17:14:09.223: INFO: Node 10.242.0.59 is running more than one daemon pod
Feb 17 17:14:10.229: INFO: Number of nodes with available pods: 0
Feb 17 17:14:10.229: INFO: Node 10.242.0.59 is running more than one daemon pod
Feb 17 17:14:11.223: INFO: Number of nodes with available pods: 0
Feb 17 17:14:11.223: INFO: Node 10.242.0.59 is running more than one daemon pod
Feb 17 17:14:12.222: INFO: Number of nodes with available pods: 1
Feb 17 17:14:12.222: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-9075, will wait for the garbage collector to delete the pods
Feb 17 17:14:12.333: INFO: Deleting DaemonSet.extensions daemon-set took: 24.845016ms
Feb 17 17:14:12.533: INFO: Terminating DaemonSet.extensions daemon-set pods took: 200.247982ms
Feb 17 17:14:23.045: INFO: Number of nodes with available pods: 0
Feb 17 17:14:23.045: INFO: Number of running nodes: 0, number of available pods: 0
Feb 17 17:14:23.057: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-9075/daemonsets","resourceVersion":"32916"},"items":null}

Feb 17 17:14:23.068: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-9075/pods","resourceVersion":"32916"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 17:14:23.184: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-9075" for this suite.
Feb 17 17:14:31.262: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:14:31.663: INFO: namespace daemonsets-9075 deletion completed in 8.451224148s

• [SLOW TEST:29.004 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 17:14:31.666: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-5414
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1420
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb 17 17:14:31.955: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-079603707 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-5414'
Feb 17 17:14:32.142: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Feb 17 17:14:32.142: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1426
Feb 17 17:14:34.173: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-079603707 delete deployment e2e-test-nginx-deployment --namespace=kubectl-5414'
Feb 17 17:14:34.331: INFO: stderr: ""
Feb 17 17:14:34.331: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 17:14:34.331: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5414" for this suite.
Feb 17 17:14:58.402: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:14:58.815: INFO: namespace kubectl-5414 deletion completed in 24.461236894s

• [SLOW TEST:27.149 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run default
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 17:14:58.816: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2465
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-649ef988-2d76-4a74-950b-d693d02ea6ec
STEP: Creating a pod to test consume secrets
Feb 17 17:14:59.107: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-353e74e5-81f5-44bf-a77f-d1bfc10e8d8d" in namespace "projected-2465" to be "success or failure"
Feb 17 17:14:59.119: INFO: Pod "pod-projected-secrets-353e74e5-81f5-44bf-a77f-d1bfc10e8d8d": Phase="Pending", Reason="", readiness=false. Elapsed: 11.883806ms
Feb 17 17:15:01.130: INFO: Pod "pod-projected-secrets-353e74e5-81f5-44bf-a77f-d1bfc10e8d8d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.023673146s
STEP: Saw pod success
Feb 17 17:15:01.131: INFO: Pod "pod-projected-secrets-353e74e5-81f5-44bf-a77f-d1bfc10e8d8d" satisfied condition "success or failure"
Feb 17 17:15:01.151: INFO: Trying to get logs from node 10.242.0.98 pod pod-projected-secrets-353e74e5-81f5-44bf-a77f-d1bfc10e8d8d container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb 17 17:15:01.219: INFO: Waiting for pod pod-projected-secrets-353e74e5-81f5-44bf-a77f-d1bfc10e8d8d to disappear
Feb 17 17:15:01.229: INFO: Pod pod-projected-secrets-353e74e5-81f5-44bf-a77f-d1bfc10e8d8d no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 17:15:01.229: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2465" for this suite.
Feb 17 17:15:07.306: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:15:07.712: INFO: namespace projected-2465 deletion completed in 6.45980565s

• [SLOW TEST:8.896 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 17:15:07.714: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-3333
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0666 on tmpfs
Feb 17 17:15:07.994: INFO: Waiting up to 5m0s for pod "pod-5565d989-197a-44a4-ab89-8ee175b72151" in namespace "emptydir-3333" to be "success or failure"
Feb 17 17:15:08.005: INFO: Pod "pod-5565d989-197a-44a4-ab89-8ee175b72151": Phase="Pending", Reason="", readiness=false. Elapsed: 10.883764ms
Feb 17 17:15:10.018: INFO: Pod "pod-5565d989-197a-44a4-ab89-8ee175b72151": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.023626023s
STEP: Saw pod success
Feb 17 17:15:10.018: INFO: Pod "pod-5565d989-197a-44a4-ab89-8ee175b72151" satisfied condition "success or failure"
Feb 17 17:15:10.030: INFO: Trying to get logs from node 10.242.0.59 pod pod-5565d989-197a-44a4-ab89-8ee175b72151 container test-container: <nil>
STEP: delete the pod
Feb 17 17:15:10.097: INFO: Waiting for pod pod-5565d989-197a-44a4-ab89-8ee175b72151 to disappear
Feb 17 17:15:10.111: INFO: Pod pod-5565d989-197a-44a4-ab89-8ee175b72151 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 17:15:10.111: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3333" for this suite.
Feb 17 17:15:16.185: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:15:16.583: INFO: namespace emptydir-3333 deletion completed in 6.453464219s

• [SLOW TEST:8.869 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 17:15:16.585: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3902
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-cc29e592-0f6a-466f-989f-a3032775471c
STEP: Creating a pod to test consume configMaps
Feb 17 17:15:16.874: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-d8797fb0-8e15-4609-8566-2d1349eeaa7b" in namespace "projected-3902" to be "success or failure"
Feb 17 17:15:16.887: INFO: Pod "pod-projected-configmaps-d8797fb0-8e15-4609-8566-2d1349eeaa7b": Phase="Pending", Reason="", readiness=false. Elapsed: 12.957502ms
Feb 17 17:15:18.898: INFO: Pod "pod-projected-configmaps-d8797fb0-8e15-4609-8566-2d1349eeaa7b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.024056892s
STEP: Saw pod success
Feb 17 17:15:18.898: INFO: Pod "pod-projected-configmaps-d8797fb0-8e15-4609-8566-2d1349eeaa7b" satisfied condition "success or failure"
Feb 17 17:15:18.910: INFO: Trying to get logs from node 10.242.0.98 pod pod-projected-configmaps-d8797fb0-8e15-4609-8566-2d1349eeaa7b container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 17 17:15:18.990: INFO: Waiting for pod pod-projected-configmaps-d8797fb0-8e15-4609-8566-2d1349eeaa7b to disappear
Feb 17 17:15:19.002: INFO: Pod pod-projected-configmaps-d8797fb0-8e15-4609-8566-2d1349eeaa7b no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 17:15:19.002: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3902" for this suite.
Feb 17 17:15:25.071: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:15:25.493: INFO: namespace projected-3902 deletion completed in 6.47209179s

• [SLOW TEST:8.908 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 17:15:25.496: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-3474
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:63
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Feb 17 17:15:33.881: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Feb 17 17:15:33.895: INFO: Pod pod-with-prestop-http-hook still exists
Feb 17 17:15:35.895: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Feb 17 17:15:35.908: INFO: Pod pod-with-prestop-http-hook still exists
Feb 17 17:15:37.895: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Feb 17 17:15:37.907: INFO: Pod pod-with-prestop-http-hook still exists
Feb 17 17:15:39.895: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Feb 17 17:15:39.907: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 17:15:39.938: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-3474" for this suite.
Feb 17 17:16:04.012: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:16:04.413: INFO: namespace container-lifecycle-hook-3474 deletion completed in 24.454824053s

• [SLOW TEST:38.917 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when create a pod with lifecycle hook
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 17:16:04.413: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-2927
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: executing a command with run --rm and attach with stdin
Feb 17 17:16:04.676: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-079603707 --namespace=kubectl-2927 run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Feb 17 17:16:07.306: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Feb 17 17:16:07.306: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 17:16:09.333: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2927" for this suite.
Feb 17 17:16:15.400: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:16:15.816: INFO: namespace kubectl-2927 deletion completed in 6.465313229s

• [SLOW TEST:11.403 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run --rm job
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 17:16:15.818: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5559
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Feb 17 17:16:16.097: INFO: Waiting up to 5m0s for pod "downwardapi-volume-72f473cb-cf87-4209-88ea-6cd8dc794e79" in namespace "projected-5559" to be "success or failure"
Feb 17 17:16:16.109: INFO: Pod "downwardapi-volume-72f473cb-cf87-4209-88ea-6cd8dc794e79": Phase="Pending", Reason="", readiness=false. Elapsed: 11.843676ms
Feb 17 17:16:18.124: INFO: Pod "downwardapi-volume-72f473cb-cf87-4209-88ea-6cd8dc794e79": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.025965649s
STEP: Saw pod success
Feb 17 17:16:18.124: INFO: Pod "downwardapi-volume-72f473cb-cf87-4209-88ea-6cd8dc794e79" satisfied condition "success or failure"
Feb 17 17:16:18.137: INFO: Trying to get logs from node 10.242.0.98 pod downwardapi-volume-72f473cb-cf87-4209-88ea-6cd8dc794e79 container client-container: <nil>
STEP: delete the pod
Feb 17 17:16:18.227: INFO: Waiting for pod downwardapi-volume-72f473cb-cf87-4209-88ea-6cd8dc794e79 to disappear
Feb 17 17:16:18.240: INFO: Pod downwardapi-volume-72f473cb-cf87-4209-88ea-6cd8dc794e79 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 17:16:18.240: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5559" for this suite.
Feb 17 17:16:24.308: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:16:24.863: INFO: namespace projected-5559 deletion completed in 6.603761076s

• [SLOW TEST:9.045 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 17:16:24.864: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-249
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating secret secrets-249/secret-test-199aff71-1d8e-4ea9-900e-ac7c9ae932a6
STEP: Creating a pod to test consume secrets
Feb 17 17:16:25.357: INFO: Waiting up to 5m0s for pod "pod-configmaps-6188e660-5bf5-496f-8cf6-2666ed0e3004" in namespace "secrets-249" to be "success or failure"
Feb 17 17:16:25.367: INFO: Pod "pod-configmaps-6188e660-5bf5-496f-8cf6-2666ed0e3004": Phase="Pending", Reason="", readiness=false. Elapsed: 10.446129ms
Feb 17 17:16:27.379: INFO: Pod "pod-configmaps-6188e660-5bf5-496f-8cf6-2666ed0e3004": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.022471219s
STEP: Saw pod success
Feb 17 17:16:27.380: INFO: Pod "pod-configmaps-6188e660-5bf5-496f-8cf6-2666ed0e3004" satisfied condition "success or failure"
Feb 17 17:16:27.391: INFO: Trying to get logs from node 10.242.0.98 pod pod-configmaps-6188e660-5bf5-496f-8cf6-2666ed0e3004 container env-test: <nil>
STEP: delete the pod
Feb 17 17:16:27.466: INFO: Waiting for pod pod-configmaps-6188e660-5bf5-496f-8cf6-2666ed0e3004 to disappear
Feb 17 17:16:27.476: INFO: Pod pod-configmaps-6188e660-5bf5-496f-8cf6-2666ed0e3004 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 17:16:27.476: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-249" for this suite.
Feb 17 17:16:33.552: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:16:33.940: INFO: namespace secrets-249 deletion completed in 6.439170097s

• [SLOW TEST:9.076 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 17:16:33.942: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-4844
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Feb 17 17:16:34.229: INFO: Waiting up to 5m0s for pod "downward-api-c8cf53f0-b451-4ae5-8213-2c83a698f37e" in namespace "downward-api-4844" to be "success or failure"
Feb 17 17:16:34.244: INFO: Pod "downward-api-c8cf53f0-b451-4ae5-8213-2c83a698f37e": Phase="Pending", Reason="", readiness=false. Elapsed: 15.190692ms
Feb 17 17:16:36.256: INFO: Pod "downward-api-c8cf53f0-b451-4ae5-8213-2c83a698f37e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.026709266s
STEP: Saw pod success
Feb 17 17:16:36.256: INFO: Pod "downward-api-c8cf53f0-b451-4ae5-8213-2c83a698f37e" satisfied condition "success or failure"
Feb 17 17:16:36.268: INFO: Trying to get logs from node 10.242.0.98 pod downward-api-c8cf53f0-b451-4ae5-8213-2c83a698f37e container dapi-container: <nil>
STEP: delete the pod
Feb 17 17:16:36.335: INFO: Waiting for pod downward-api-c8cf53f0-b451-4ae5-8213-2c83a698f37e to disappear
Feb 17 17:16:36.346: INFO: Pod downward-api-c8cf53f0-b451-4ae5-8213-2c83a698f37e no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 17:16:36.346: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4844" for this suite.
Feb 17 17:16:42.422: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:16:42.826: INFO: namespace downward-api-4844 deletion completed in 6.456418111s

• [SLOW TEST:8.884 seconds]
[sig-node] Downward API
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 17:16:42.830: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-3073
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Feb 17 17:16:43.113: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Feb 17 17:16:48.125: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Feb 17 17:16:48.126: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
Feb 17 17:16:50.222: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment,GenerateName:,Namespace:deployment-3073,SelfLink:/apis/apps/v1/namespaces/deployment-3073/deployments/test-cleanup-deployment,UID:168fd656-0b23-4e60-8b81-a73ac34600e2,ResourceVersion:33627,Generation:1,CreationTimestamp:2020-02-17 17:16:48 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 1,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2020-02-17 17:16:48 +0000 UTC 2020-02-17 17:16:48 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2020-02-17 17:16:50 +0000 UTC 2020-02-17 17:16:48 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-cleanup-deployment-55bbcbc84c" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Feb 17 17:16:50.233: INFO: New ReplicaSet "test-cleanup-deployment-55bbcbc84c" of Deployment "test-cleanup-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-55bbcbc84c,GenerateName:,Namespace:deployment-3073,SelfLink:/apis/apps/v1/namespaces/deployment-3073/replicasets/test-cleanup-deployment-55bbcbc84c,UID:ac1a3796-00c0-4b88-bb47-d6ff1cd0bc1f,ResourceVersion:33616,Generation:1,CreationTimestamp:2020-02-17 17:16:48 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 55bbcbc84c,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment 168fd656-0b23-4e60-8b81-a73ac34600e2 0xc0037a91c7 0xc0037a91c8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: 55bbcbc84c,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 55bbcbc84c,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Feb 17 17:16:50.246: INFO: Pod "test-cleanup-deployment-55bbcbc84c-hrkcb" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-55bbcbc84c-hrkcb,GenerateName:test-cleanup-deployment-55bbcbc84c-,Namespace:deployment-3073,SelfLink:/api/v1/namespaces/deployment-3073/pods/test-cleanup-deployment-55bbcbc84c-hrkcb,UID:ca6077ce-febe-4101-a00f-8bad3852c024,ResourceVersion:33615,Generation:0,CreationTimestamp:2020-02-17 17:16:48 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 55bbcbc84c,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-deployment-55bbcbc84c ac1a3796-00c0-4b88-bb47-d6ff1cd0bc1f 0xc000d71047 0xc000d71048}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-jbfnr {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jbfnr,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-jbfnr true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.242.0.98,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000d710c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000d710e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-17 17:16:48 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2020-02-17 17:16:49 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2020-02-17 17:16:49 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-17 17:16:48 +0000 UTC  }],Message:,Reason:,HostIP:10.242.0.98,PodIP:172.30.197.158,StartTime:2020-02-17 17:16:48 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2020-02-17 17:16:49 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 containerd://baec9afb42e2338bce65f2d962cd06a188f45924544d23fb83c0d008ea32a2d2}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 17:16:50.246: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-3073" for this suite.
Feb 17 17:16:58.330: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:16:58.735: INFO: namespace deployment-3073 deletion completed in 8.456724881s

• [SLOW TEST:15.905 seconds]
[sig-apps] Deployment
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 17:16:58.746: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-4182
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-4182
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace statefulset-4182
STEP: Creating statefulset with conflicting port in namespace statefulset-4182
STEP: Waiting until pod test-pod will start running in namespace statefulset-4182
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-4182
Feb 17 17:17:03.107: INFO: Observed stateful pod in namespace: statefulset-4182, name: ss-0, uid: 1a29ae28-7413-4296-84f3-faff434701dc, status phase: Pending. Waiting for statefulset controller to delete.
Feb 17 17:17:03.180: INFO: Observed stateful pod in namespace: statefulset-4182, name: ss-0, uid: 1a29ae28-7413-4296-84f3-faff434701dc, status phase: Failed. Waiting for statefulset controller to delete.
Feb 17 17:17:03.195: INFO: Observed stateful pod in namespace: statefulset-4182, name: ss-0, uid: 1a29ae28-7413-4296-84f3-faff434701dc, status phase: Failed. Waiting for statefulset controller to delete.
Feb 17 17:17:03.207: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-4182
STEP: Removing pod with conflicting port in namespace statefulset-4182
STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-4182 and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Feb 17 17:17:07.288: INFO: Deleting all statefulset in ns statefulset-4182
Feb 17 17:17:07.303: INFO: Scaling statefulset ss to 0
Feb 17 17:17:17.356: INFO: Waiting for statefulset status.replicas updated to 0
Feb 17 17:17:17.372: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 17:17:17.425: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-4182" for this suite.
Feb 17 17:17:25.496: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:17:26.077: INFO: namespace statefulset-4182 deletion completed in 8.633127114s

• [SLOW TEST:27.332 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 17:17:26.078: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-8246
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
W0217 17:17:36.448314      16 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb 17 17:17:36.448: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 17:17:36.448: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-8246" for this suite.
Feb 17 17:17:44.511: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:17:44.936: INFO: namespace gc-8246 deletion completed in 8.473705702s

• [SLOW TEST:18.858 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 17:17:44.937: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-2864
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a test externalName service
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-2864.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-2864.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-2864.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-2864.svc.cluster.local; sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Feb 17 17:17:47.382: INFO: DNS probes using dns-test-c0869d8a-c363-459f-a283-a3416b159539 succeeded

STEP: deleting the pod
STEP: changing the externalName to bar.example.com
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-2864.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-2864.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-2864.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-2864.svc.cluster.local; sleep 1; done

STEP: creating a second pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Feb 17 17:17:51.543: INFO: File wheezy_udp@dns-test-service-3.dns-2864.svc.cluster.local from pod  dns-2864/dns-test-5ff2301e-8220-4347-98b5-1384db72d6c4 contains 'foo.example.com.
' instead of 'bar.example.com.'
Feb 17 17:17:51.572: INFO: File jessie_udp@dns-test-service-3.dns-2864.svc.cluster.local from pod  dns-2864/dns-test-5ff2301e-8220-4347-98b5-1384db72d6c4 contains 'foo.example.com.
' instead of 'bar.example.com.'
Feb 17 17:17:51.572: INFO: Lookups using dns-2864/dns-test-5ff2301e-8220-4347-98b5-1384db72d6c4 failed for: [wheezy_udp@dns-test-service-3.dns-2864.svc.cluster.local jessie_udp@dns-test-service-3.dns-2864.svc.cluster.local]

Feb 17 17:17:56.613: INFO: DNS probes using dns-test-5ff2301e-8220-4347-98b5-1384db72d6c4 succeeded

STEP: deleting the pod
STEP: changing the service to type=ClusterIP
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-2864.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-2864.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-2864.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-2864.svc.cluster.local; sleep 1; done

STEP: creating a third pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Feb 17 17:18:00.825: INFO: DNS probes using dns-test-22fa8b68-21cd-488d-a2e6-4edc8a8c4639 succeeded

STEP: deleting the pod
STEP: deleting the test externalName service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 17:18:00.917: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-2864" for this suite.
Feb 17 17:18:08.984: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:18:09.429: INFO: namespace dns-2864 deletion completed in 8.492454017s

• [SLOW TEST:24.492 seconds]
[sig-network] DNS
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 17:18:09.430: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-9332
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Feb 17 17:18:09.694: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 17:18:11.839: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-9332" for this suite.
Feb 17 17:18:51.912: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:18:52.337: INFO: namespace pods-9332 deletion completed in 40.477901379s

• [SLOW TEST:42.908 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 17:18:52.340: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-484
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: validating cluster-info
Feb 17 17:18:52.600: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-079603707 cluster-info'
Feb 17 17:18:52.738: INFO: stderr: ""
Feb 17 17:18:52.738: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://172.21.0.1:443\x1b[0m\n\x1b[0;32mCoreDNS\x1b[0m is running at \x1b[0;33mhttps://172.21.0.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\x1b[0;32mkubernetes-dashboard\x1b[0m is running at \x1b[0;33mhttps://172.21.0.1:443/api/v1/namespaces/kube-system/services/https:kubernetes-dashboard:/proxy\x1b[0m\n\x1b[0;32mMetrics-server\x1b[0m is running at \x1b[0;33mhttps://172.21.0.1:443/api/v1/namespaces/kube-system/services/https:metrics-server:/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 17:18:52.738: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-484" for this suite.
Feb 17 17:18:58.804: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:18:59.220: INFO: namespace kubectl-484 deletion completed in 6.463535664s

• [SLOW TEST:6.880 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl cluster-info
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 17:18:59.221: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-4836
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating the pod
Feb 17 17:19:02.118: INFO: Successfully updated pod "annotationupdate021fbd15-b517-4fa8-87dd-b1343deb0d08"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 17:19:04.183: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4836" for this suite.
Feb 17 17:19:28.252: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:19:28.670: INFO: namespace projected-4836 deletion completed in 24.468673686s

• [SLOW TEST:29.450 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 17:19:28.674: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-6106
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-upd-c21ff69c-6239-4acd-86ad-cd07d779059f
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 17:19:33.153: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6106" for this suite.
Feb 17 17:19:57.223: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:19:57.627: INFO: namespace configmap-6106 deletion completed in 24.45503626s

• [SLOW TEST:28.954 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 17:19:57.631: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-5200
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating pod
Feb 17 17:19:59.952: INFO: Pod pod-hostip-a9b4a60d-2597-40b8-8cf4-61ea9ac34252 has hostIP: 10.242.0.59
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 17:19:59.952: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-5200" for this suite.
Feb 17 17:20:24.020: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:20:24.412: INFO: namespace pods-5200 deletion completed in 24.442185542s

• [SLOW TEST:26.781 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 17:20:24.414: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1075
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Feb 17 17:20:24.708: INFO: Waiting up to 5m0s for pod "downwardapi-volume-18522f0f-0442-46a0-a2af-be4e0a8bd5da" in namespace "projected-1075" to be "success or failure"
Feb 17 17:20:24.725: INFO: Pod "downwardapi-volume-18522f0f-0442-46a0-a2af-be4e0a8bd5da": Phase="Pending", Reason="", readiness=false. Elapsed: 17.074844ms
Feb 17 17:20:26.737: INFO: Pod "downwardapi-volume-18522f0f-0442-46a0-a2af-be4e0a8bd5da": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.029422125s
STEP: Saw pod success
Feb 17 17:20:26.737: INFO: Pod "downwardapi-volume-18522f0f-0442-46a0-a2af-be4e0a8bd5da" satisfied condition "success or failure"
Feb 17 17:20:26.749: INFO: Trying to get logs from node 10.242.0.98 pod downwardapi-volume-18522f0f-0442-46a0-a2af-be4e0a8bd5da container client-container: <nil>
STEP: delete the pod
Feb 17 17:20:26.817: INFO: Waiting for pod downwardapi-volume-18522f0f-0442-46a0-a2af-be4e0a8bd5da to disappear
Feb 17 17:20:26.828: INFO: Pod downwardapi-volume-18522f0f-0442-46a0-a2af-be4e0a8bd5da no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 17:20:26.828: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1075" for this suite.
Feb 17 17:20:32.895: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:20:33.313: INFO: namespace projected-1075 deletion completed in 6.467115517s

• [SLOW TEST:8.900 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 17:20:33.315: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replicaset-4026
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Feb 17 17:20:33.568: INFO: Creating ReplicaSet my-hostname-basic-8c612bd3-d578-40b7-bb09-0b24551ab9d3
Feb 17 17:20:33.592: INFO: Pod name my-hostname-basic-8c612bd3-d578-40b7-bb09-0b24551ab9d3: Found 0 pods out of 1
Feb 17 17:20:38.607: INFO: Pod name my-hostname-basic-8c612bd3-d578-40b7-bb09-0b24551ab9d3: Found 1 pods out of 1
Feb 17 17:20:38.607: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-8c612bd3-d578-40b7-bb09-0b24551ab9d3" is running
Feb 17 17:20:38.619: INFO: Pod "my-hostname-basic-8c612bd3-d578-40b7-bb09-0b24551ab9d3-d8zj5" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-02-17 17:20:33 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-02-17 17:20:35 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-02-17 17:20:35 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-02-17 17:20:33 +0000 UTC Reason: Message:}])
Feb 17 17:20:38.619: INFO: Trying to dial the pod
Feb 17 17:20:43.675: INFO: Controller my-hostname-basic-8c612bd3-d578-40b7-bb09-0b24551ab9d3: Got expected result from replica 1 [my-hostname-basic-8c612bd3-d578-40b7-bb09-0b24551ab9d3-d8zj5]: "my-hostname-basic-8c612bd3-d578-40b7-bb09-0b24551ab9d3-d8zj5", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 17:20:43.675: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-4026" for this suite.
Feb 17 17:20:49.745: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:20:50.339: INFO: namespace replicaset-4026 deletion completed in 6.643669955s

• [SLOW TEST:17.024 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 17:20:50.340: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-3263
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating all guestbook components
Feb 17 17:20:50.596: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Feb 17 17:20:50.596: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-079603707 create -f - --namespace=kubectl-3263'
Feb 17 17:20:51.162: INFO: stderr: ""
Feb 17 17:20:51.162: INFO: stdout: "service/redis-slave created\n"
Feb 17 17:20:51.162: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Feb 17 17:20:51.162: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-079603707 create -f - --namespace=kubectl-3263'
Feb 17 17:20:51.458: INFO: stderr: ""
Feb 17 17:20:51.458: INFO: stdout: "service/redis-master created\n"
Feb 17 17:20:51.458: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Feb 17 17:20:51.458: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-079603707 create -f - --namespace=kubectl-3263'
Feb 17 17:20:51.733: INFO: stderr: ""
Feb 17 17:20:51.733: INFO: stdout: "service/frontend created\n"
Feb 17 17:20:51.733: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: guestbook
      tier: frontend
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Feb 17 17:20:51.734: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-079603707 create -f - --namespace=kubectl-3263'
Feb 17 17:20:52.012: INFO: stderr: ""
Feb 17 17:20:52.012: INFO: stdout: "deployment.apps/frontend created\n"
Feb 17 17:20:52.012: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  selector:
    matchLabels:
      app: redis
      role: master
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Feb 17 17:20:52.012: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-079603707 create -f - --namespace=kubectl-3263'
Feb 17 17:20:52.304: INFO: stderr: ""
Feb 17 17:20:52.304: INFO: stdout: "deployment.apps/redis-master created\n"
Feb 17 17:20:52.304: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  selector:
    matchLabels:
      app: redis
      role: slave
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave:v3
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Feb 17 17:20:52.304: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-079603707 create -f - --namespace=kubectl-3263'
Feb 17 17:20:52.691: INFO: stderr: ""
Feb 17 17:20:52.691: INFO: stdout: "deployment.apps/redis-slave created\n"
STEP: validating guestbook app
Feb 17 17:20:52.691: INFO: Waiting for all frontend pods to be Running.
Feb 17 17:21:12.744: INFO: Waiting for frontend to serve content.
Feb 17 17:21:17.795: INFO: Failed to get response from guestbook. err: <nil>, response: <br />
<b>Fatal error</b>:  Uncaught exception 'Predis\Connection\ConnectionException' with message 'Connection timed out [tcp://redis-slave:6379]' in /usr/local/lib/php/Predis/Connection/AbstractConnection.php:155
Stack trace:
#0 /usr/local/lib/php/Predis/Connection/StreamConnection.php(128): Predis\Connection\AbstractConnection-&gt;onConnectionError('Connection time...', 110)
#1 /usr/local/lib/php/Predis/Connection/StreamConnection.php(178): Predis\Connection\StreamConnection-&gt;createStreamSocket(Object(Predis\Connection\Parameters), 'tcp://redis-sla...', 4)
#2 /usr/local/lib/php/Predis/Connection/StreamConnection.php(100): Predis\Connection\StreamConnection-&gt;tcpStreamInitializer(Object(Predis\Connection\Parameters))
#3 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(81): Predis\Connection\StreamConnection-&gt;createResource()
#4 /usr/local/lib/php/Predis/Connection/StreamConnection.php(258): Predis\Connection\AbstractConnection-&gt;connect()
#5 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(180): Predis\Connection\Stre in <b>/usr/local/lib/php/Predis/Connection/AbstractConnection.php</b> on line <b>155</b><br />

Feb 17 17:21:22.842: INFO: Trying to add a new entry to the guestbook.
Feb 17 17:21:22.888: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Feb 17 17:21:22.923: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-079603707 delete --grace-period=0 --force -f - --namespace=kubectl-3263'
Feb 17 17:21:23.312: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 17 17:21:23.312: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Feb 17 17:21:23.312: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-079603707 delete --grace-period=0 --force -f - --namespace=kubectl-3263'
Feb 17 17:21:23.514: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 17 17:21:23.514: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Feb 17 17:21:23.515: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-079603707 delete --grace-period=0 --force -f - --namespace=kubectl-3263'
Feb 17 17:21:23.715: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 17 17:21:23.715: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Feb 17 17:21:23.715: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-079603707 delete --grace-period=0 --force -f - --namespace=kubectl-3263'
Feb 17 17:21:23.896: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 17 17:21:23.896: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Feb 17 17:21:23.897: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-079603707 delete --grace-period=0 --force -f - --namespace=kubectl-3263'
Feb 17 17:21:24.070: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 17 17:21:24.070: INFO: stdout: "deployment.apps \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Feb 17 17:21:24.070: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-079603707 delete --grace-period=0 --force -f - --namespace=kubectl-3263'
Feb 17 17:21:24.280: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 17 17:21:24.280: INFO: stdout: "deployment.apps \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 17:21:24.280: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3263" for this suite.
Feb 17 17:22:04.369: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:22:04.778: INFO: namespace kubectl-3263 deletion completed in 40.464452855s

• [SLOW TEST:74.438 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Guestbook application
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 17:22:04.780: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename svc-latency
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svc-latency-2956
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating replication controller svc-latency-rc in namespace svc-latency-2956
I0217 17:22:05.065667      16 runners.go:180] Created replication controller with name: svc-latency-rc, namespace: svc-latency-2956, replica count: 1
I0217 17:22:06.116355      16 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0217 17:22:07.116564      16 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Feb 17 17:22:07.249: INFO: Created: latency-svc-ptp2t
Feb 17 17:22:07.266: INFO: Got endpoints: latency-svc-ptp2t [49.488555ms]
Feb 17 17:22:07.298: INFO: Created: latency-svc-26hbk
Feb 17 17:22:07.307: INFO: Got endpoints: latency-svc-26hbk [40.511947ms]
Feb 17 17:22:07.325: INFO: Created: latency-svc-xxb4z
Feb 17 17:22:07.338: INFO: Got endpoints: latency-svc-xxb4z [72.195768ms]
Feb 17 17:22:07.346: INFO: Created: latency-svc-ll9kl
Feb 17 17:22:07.354: INFO: Got endpoints: latency-svc-ll9kl [87.723734ms]
Feb 17 17:22:07.362: INFO: Created: latency-svc-qgmst
Feb 17 17:22:07.376: INFO: Got endpoints: latency-svc-qgmst [109.628229ms]
Feb 17 17:22:07.380: INFO: Created: latency-svc-8rdtd
Feb 17 17:22:07.390: INFO: Got endpoints: latency-svc-8rdtd [124.187876ms]
Feb 17 17:22:07.395: INFO: Created: latency-svc-5zm64
Feb 17 17:22:07.412: INFO: Created: latency-svc-24wq6
Feb 17 17:22:07.413: INFO: Got endpoints: latency-svc-5zm64 [147.246935ms]
Feb 17 17:22:07.422: INFO: Got endpoints: latency-svc-24wq6 [155.594394ms]
Feb 17 17:22:07.427: INFO: Created: latency-svc-dfwfm
Feb 17 17:22:07.433: INFO: Got endpoints: latency-svc-dfwfm [166.682525ms]
Feb 17 17:22:07.441: INFO: Created: latency-svc-mx8d6
Feb 17 17:22:07.449: INFO: Got endpoints: latency-svc-mx8d6 [182.770193ms]
Feb 17 17:22:07.458: INFO: Created: latency-svc-4ks7n
Feb 17 17:22:07.467: INFO: Got endpoints: latency-svc-4ks7n [200.765928ms]
Feb 17 17:22:07.475: INFO: Created: latency-svc-zr6jk
Feb 17 17:22:07.483: INFO: Got endpoints: latency-svc-zr6jk [216.231416ms]
Feb 17 17:22:07.497: INFO: Created: latency-svc-xpmvq
Feb 17 17:22:07.506: INFO: Got endpoints: latency-svc-xpmvq [239.788854ms]
Feb 17 17:22:07.507: INFO: Created: latency-svc-764hr
Feb 17 17:22:07.521: INFO: Got endpoints: latency-svc-764hr [254.215326ms]
Feb 17 17:22:07.524: INFO: Created: latency-svc-rn6tc
Feb 17 17:22:07.533: INFO: Got endpoints: latency-svc-rn6tc [266.339265ms]
Feb 17 17:22:07.542: INFO: Created: latency-svc-w9qh2
Feb 17 17:22:07.548: INFO: Got endpoints: latency-svc-w9qh2 [281.779197ms]
Feb 17 17:22:07.557: INFO: Created: latency-svc-gs6xb
Feb 17 17:22:07.562: INFO: Got endpoints: latency-svc-gs6xb [254.952237ms]
Feb 17 17:22:07.572: INFO: Created: latency-svc-s6pvf
Feb 17 17:22:07.580: INFO: Got endpoints: latency-svc-s6pvf [241.425607ms]
Feb 17 17:22:07.586: INFO: Created: latency-svc-bscwq
Feb 17 17:22:07.596: INFO: Got endpoints: latency-svc-bscwq [241.977854ms]
Feb 17 17:22:07.602: INFO: Created: latency-svc-xh5sp
Feb 17 17:22:07.612: INFO: Got endpoints: latency-svc-xh5sp [236.068845ms]
Feb 17 17:22:07.621: INFO: Created: latency-svc-dzzh7
Feb 17 17:22:07.627: INFO: Got endpoints: latency-svc-dzzh7 [236.991958ms]
Feb 17 17:22:07.638: INFO: Created: latency-svc-6hxjh
Feb 17 17:22:07.645: INFO: Got endpoints: latency-svc-6hxjh [231.722055ms]
Feb 17 17:22:07.655: INFO: Created: latency-svc-dflk5
Feb 17 17:22:07.661: INFO: Got endpoints: latency-svc-dflk5 [238.584632ms]
Feb 17 17:22:07.677: INFO: Created: latency-svc-vlk5v
Feb 17 17:22:07.685: INFO: Got endpoints: latency-svc-vlk5v [251.990043ms]
Feb 17 17:22:07.686: INFO: Created: latency-svc-8n9tt
Feb 17 17:22:07.694: INFO: Got endpoints: latency-svc-8n9tt [244.582115ms]
Feb 17 17:22:07.700: INFO: Created: latency-svc-gnml9
Feb 17 17:22:07.708: INFO: Got endpoints: latency-svc-gnml9 [241.256661ms]
Feb 17 17:22:07.718: INFO: Created: latency-svc-bdknw
Feb 17 17:22:07.725: INFO: Got endpoints: latency-svc-bdknw [242.3886ms]
Feb 17 17:22:07.733: INFO: Created: latency-svc-dvkg7
Feb 17 17:22:07.742: INFO: Got endpoints: latency-svc-dvkg7 [235.890617ms]
Feb 17 17:22:07.747: INFO: Created: latency-svc-htnqp
Feb 17 17:22:07.756: INFO: Got endpoints: latency-svc-htnqp [235.297561ms]
Feb 17 17:22:07.764: INFO: Created: latency-svc-n8nhs
Feb 17 17:22:07.772: INFO: Got endpoints: latency-svc-n8nhs [239.474155ms]
Feb 17 17:22:07.780: INFO: Created: latency-svc-d78f8
Feb 17 17:22:07.791: INFO: Got endpoints: latency-svc-d78f8 [242.38326ms]
Feb 17 17:22:07.797: INFO: Created: latency-svc-xqxdq
Feb 17 17:22:07.806: INFO: Got endpoints: latency-svc-xqxdq [244.386439ms]
Feb 17 17:22:07.811: INFO: Created: latency-svc-8847b
Feb 17 17:22:07.820: INFO: Got endpoints: latency-svc-8847b [240.400464ms]
Feb 17 17:22:07.833: INFO: Created: latency-svc-ksmk4
Feb 17 17:22:07.840: INFO: Got endpoints: latency-svc-ksmk4 [243.893473ms]
Feb 17 17:22:07.897: INFO: Created: latency-svc-bbbjv
Feb 17 17:22:07.905: INFO: Got endpoints: latency-svc-bbbjv [293.214371ms]
Feb 17 17:22:07.915: INFO: Created: latency-svc-tklxr
Feb 17 17:22:07.925: INFO: Got endpoints: latency-svc-tklxr [297.385195ms]
Feb 17 17:22:07.931: INFO: Created: latency-svc-8m69j
Feb 17 17:22:07.937: INFO: Got endpoints: latency-svc-8m69j [291.895361ms]
Feb 17 17:22:07.944: INFO: Created: latency-svc-jd6d5
Feb 17 17:22:07.955: INFO: Got endpoints: latency-svc-jd6d5 [294.300718ms]
Feb 17 17:22:07.960: INFO: Created: latency-svc-x4nrl
Feb 17 17:22:07.972: INFO: Got endpoints: latency-svc-x4nrl [286.582191ms]
Feb 17 17:22:07.973: INFO: Created: latency-svc-6b424
Feb 17 17:22:07.985: INFO: Got endpoints: latency-svc-6b424 [291.152602ms]
Feb 17 17:22:07.995: INFO: Created: latency-svc-f2w5v
Feb 17 17:22:08.004: INFO: Got endpoints: latency-svc-f2w5v [295.809508ms]
Feb 17 17:22:08.013: INFO: Created: latency-svc-9chmv
Feb 17 17:22:08.023: INFO: Got endpoints: latency-svc-9chmv [298.109404ms]
Feb 17 17:22:08.028: INFO: Created: latency-svc-hkmq2
Feb 17 17:22:08.035: INFO: Got endpoints: latency-svc-hkmq2 [292.732047ms]
Feb 17 17:22:08.043: INFO: Created: latency-svc-vzhvv
Feb 17 17:22:08.052: INFO: Got endpoints: latency-svc-vzhvv [295.541817ms]
Feb 17 17:22:08.063: INFO: Created: latency-svc-snfvn
Feb 17 17:22:08.073: INFO: Got endpoints: latency-svc-snfvn [300.327794ms]
Feb 17 17:22:08.083: INFO: Created: latency-svc-hxm2j
Feb 17 17:22:08.087: INFO: Got endpoints: latency-svc-hxm2j [296.685728ms]
Feb 17 17:22:08.094: INFO: Created: latency-svc-nkx2g
Feb 17 17:22:08.102: INFO: Got endpoints: latency-svc-nkx2g [294.828603ms]
Feb 17 17:22:08.113: INFO: Created: latency-svc-rlwtf
Feb 17 17:22:08.120: INFO: Got endpoints: latency-svc-rlwtf [299.585953ms]
Feb 17 17:22:08.128: INFO: Created: latency-svc-5x7ck
Feb 17 17:22:08.150: INFO: Got endpoints: latency-svc-5x7ck [309.997136ms]
Feb 17 17:22:08.151: INFO: Created: latency-svc-cs4gb
Feb 17 17:22:08.151: INFO: Got endpoints: latency-svc-cs4gb [245.964379ms]
Feb 17 17:22:08.157: INFO: Created: latency-svc-zgnbl
Feb 17 17:22:08.165: INFO: Got endpoints: latency-svc-zgnbl [240.400441ms]
Feb 17 17:22:08.176: INFO: Created: latency-svc-njskf
Feb 17 17:22:08.185: INFO: Got endpoints: latency-svc-njskf [248.085872ms]
Feb 17 17:22:08.191: INFO: Created: latency-svc-h8dsv
Feb 17 17:22:08.200: INFO: Got endpoints: latency-svc-h8dsv [245.145938ms]
Feb 17 17:22:08.207: INFO: Created: latency-svc-zqqvb
Feb 17 17:22:08.215: INFO: Got endpoints: latency-svc-zqqvb [243.385393ms]
Feb 17 17:22:08.227: INFO: Created: latency-svc-tzg4k
Feb 17 17:22:08.236: INFO: Got endpoints: latency-svc-tzg4k [250.454543ms]
Feb 17 17:22:08.239: INFO: Created: latency-svc-6ffmh
Feb 17 17:22:08.249: INFO: Got endpoints: latency-svc-6ffmh [244.265691ms]
Feb 17 17:22:08.255: INFO: Created: latency-svc-lvxkq
Feb 17 17:22:08.263: INFO: Got endpoints: latency-svc-lvxkq [239.236332ms]
Feb 17 17:22:08.271: INFO: Created: latency-svc-6vjt5
Feb 17 17:22:08.279: INFO: Got endpoints: latency-svc-6vjt5 [244.336495ms]
Feb 17 17:22:08.285: INFO: Created: latency-svc-7wqbb
Feb 17 17:22:08.294: INFO: Got endpoints: latency-svc-7wqbb [242.308489ms]
Feb 17 17:22:08.304: INFO: Created: latency-svc-sxjt6
Feb 17 17:22:08.313: INFO: Got endpoints: latency-svc-sxjt6 [240.12489ms]
Feb 17 17:22:08.333: INFO: Created: latency-svc-k2dv6
Feb 17 17:22:08.334: INFO: Created: latency-svc-52lx8
Feb 17 17:22:08.343: INFO: Got endpoints: latency-svc-k2dv6 [256.0777ms]
Feb 17 17:22:08.345: INFO: Got endpoints: latency-svc-52lx8 [243.471227ms]
Feb 17 17:22:08.350: INFO: Created: latency-svc-7bzsl
Feb 17 17:22:08.357: INFO: Got endpoints: latency-svc-7bzsl [237.358068ms]
Feb 17 17:22:08.367: INFO: Created: latency-svc-hh8gl
Feb 17 17:22:08.375: INFO: Got endpoints: latency-svc-hh8gl [224.849579ms]
Feb 17 17:22:08.385: INFO: Created: latency-svc-xjn4z
Feb 17 17:22:08.393: INFO: Got endpoints: latency-svc-xjn4z [242.122316ms]
Feb 17 17:22:08.400: INFO: Created: latency-svc-5fk2z
Feb 17 17:22:08.413: INFO: Got endpoints: latency-svc-5fk2z [247.443434ms]
Feb 17 17:22:08.422: INFO: Created: latency-svc-7vckp
Feb 17 17:22:08.428: INFO: Got endpoints: latency-svc-7vckp [242.696522ms]
Feb 17 17:22:08.436: INFO: Created: latency-svc-2ndwb
Feb 17 17:22:08.446: INFO: Got endpoints: latency-svc-2ndwb [245.212476ms]
Feb 17 17:22:08.452: INFO: Created: latency-svc-47q6j
Feb 17 17:22:08.462: INFO: Got endpoints: latency-svc-47q6j [246.941186ms]
Feb 17 17:22:08.474: INFO: Created: latency-svc-nddrm
Feb 17 17:22:08.481: INFO: Got endpoints: latency-svc-nddrm [245.800104ms]
Feb 17 17:22:08.491: INFO: Created: latency-svc-xvbs6
Feb 17 17:22:08.498: INFO: Got endpoints: latency-svc-xvbs6 [249.705595ms]
Feb 17 17:22:08.508: INFO: Created: latency-svc-jn5wl
Feb 17 17:22:08.517: INFO: Got endpoints: latency-svc-jn5wl [254.26719ms]
Feb 17 17:22:08.523: INFO: Created: latency-svc-6znnq
Feb 17 17:22:08.533: INFO: Got endpoints: latency-svc-6znnq [253.544629ms]
Feb 17 17:22:08.538: INFO: Created: latency-svc-b25lr
Feb 17 17:22:08.547: INFO: Got endpoints: latency-svc-b25lr [253.367501ms]
Feb 17 17:22:08.555: INFO: Created: latency-svc-9m8c7
Feb 17 17:22:08.561: INFO: Got endpoints: latency-svc-9m8c7 [247.720482ms]
Feb 17 17:22:08.569: INFO: Created: latency-svc-6jsq5
Feb 17 17:22:08.588: INFO: Got endpoints: latency-svc-6jsq5 [244.575447ms]
Feb 17 17:22:08.593: INFO: Created: latency-svc-zgjtw
Feb 17 17:22:08.609: INFO: Got endpoints: latency-svc-zgjtw [263.945899ms]
Feb 17 17:22:08.617: INFO: Created: latency-svc-plrpb
Feb 17 17:22:08.626: INFO: Got endpoints: latency-svc-plrpb [268.77322ms]
Feb 17 17:22:08.633: INFO: Created: latency-svc-p8cdk
Feb 17 17:22:08.641: INFO: Got endpoints: latency-svc-p8cdk [265.933465ms]
Feb 17 17:22:08.649: INFO: Created: latency-svc-q9vwc
Feb 17 17:22:08.661: INFO: Got endpoints: latency-svc-q9vwc [267.303873ms]
Feb 17 17:22:08.667: INFO: Created: latency-svc-tt578
Feb 17 17:22:08.673: INFO: Got endpoints: latency-svc-tt578 [259.909626ms]
Feb 17 17:22:08.683: INFO: Created: latency-svc-lvgdx
Feb 17 17:22:08.695: INFO: Got endpoints: latency-svc-lvgdx [266.981113ms]
Feb 17 17:22:08.699: INFO: Created: latency-svc-4xgpc
Feb 17 17:22:08.707: INFO: Got endpoints: latency-svc-4xgpc [261.623636ms]
Feb 17 17:22:08.715: INFO: Created: latency-svc-bq8mq
Feb 17 17:22:08.723: INFO: Got endpoints: latency-svc-bq8mq [261.096073ms]
Feb 17 17:22:08.731: INFO: Created: latency-svc-mlnkv
Feb 17 17:22:08.739: INFO: Got endpoints: latency-svc-mlnkv [257.512166ms]
Feb 17 17:22:08.747: INFO: Created: latency-svc-8rkll
Feb 17 17:22:08.759: INFO: Got endpoints: latency-svc-8rkll [260.41234ms]
Feb 17 17:22:08.764: INFO: Created: latency-svc-d6fpj
Feb 17 17:22:08.773: INFO: Got endpoints: latency-svc-d6fpj [255.688877ms]
Feb 17 17:22:08.779: INFO: Created: latency-svc-zg5j8
Feb 17 17:22:08.794: INFO: Got endpoints: latency-svc-zg5j8 [261.595644ms]
Feb 17 17:22:08.796: INFO: Created: latency-svc-tj9dk
Feb 17 17:22:08.803: INFO: Got endpoints: latency-svc-tj9dk [255.022229ms]
Feb 17 17:22:08.811: INFO: Created: latency-svc-6cbrb
Feb 17 17:22:08.824: INFO: Got endpoints: latency-svc-6cbrb [262.453867ms]
Feb 17 17:22:08.824: INFO: Created: latency-svc-pndg5
Feb 17 17:22:08.832: INFO: Got endpoints: latency-svc-pndg5 [243.997315ms]
Feb 17 17:22:08.844: INFO: Created: latency-svc-2hpsd
Feb 17 17:22:08.851: INFO: Got endpoints: latency-svc-2hpsd [241.792126ms]
Feb 17 17:22:08.860: INFO: Created: latency-svc-xhmbn
Feb 17 17:22:08.868: INFO: Got endpoints: latency-svc-xhmbn [240.847042ms]
Feb 17 17:22:08.877: INFO: Created: latency-svc-hkgkk
Feb 17 17:22:08.883: INFO: Got endpoints: latency-svc-hkgkk [242.382487ms]
Feb 17 17:22:08.893: INFO: Created: latency-svc-bnrd9
Feb 17 17:22:08.900: INFO: Got endpoints: latency-svc-bnrd9 [238.483214ms]
Feb 17 17:22:08.908: INFO: Created: latency-svc-sf52x
Feb 17 17:22:08.919: INFO: Got endpoints: latency-svc-sf52x [245.734546ms]
Feb 17 17:22:08.924: INFO: Created: latency-svc-hw2v5
Feb 17 17:22:08.937: INFO: Got endpoints: latency-svc-hw2v5 [241.480247ms]
Feb 17 17:22:08.944: INFO: Created: latency-svc-g5w55
Feb 17 17:22:08.955: INFO: Got endpoints: latency-svc-g5w55 [246.921237ms]
Feb 17 17:22:08.960: INFO: Created: latency-svc-7lsgg
Feb 17 17:22:08.978: INFO: Created: latency-svc-q497v
Feb 17 17:22:08.984: INFO: Got endpoints: latency-svc-7lsgg [260.15369ms]
Feb 17 17:22:08.989: INFO: Got endpoints: latency-svc-q497v [250.212182ms]
Feb 17 17:22:08.995: INFO: Created: latency-svc-rdvh9
Feb 17 17:22:09.003: INFO: Got endpoints: latency-svc-rdvh9 [244.275097ms]
Feb 17 17:22:09.010: INFO: Created: latency-svc-62r9f
Feb 17 17:22:09.018: INFO: Got endpoints: latency-svc-62r9f [245.214008ms]
Feb 17 17:22:09.027: INFO: Created: latency-svc-cldmc
Feb 17 17:22:09.037: INFO: Got endpoints: latency-svc-cldmc [242.688573ms]
Feb 17 17:22:09.041: INFO: Created: latency-svc-snv8p
Feb 17 17:22:09.049: INFO: Got endpoints: latency-svc-snv8p [246.823431ms]
Feb 17 17:22:09.060: INFO: Created: latency-svc-nbvb7
Feb 17 17:22:09.065: INFO: Got endpoints: latency-svc-nbvb7 [240.957766ms]
Feb 17 17:22:09.074: INFO: Created: latency-svc-p785d
Feb 17 17:22:09.082: INFO: Got endpoints: latency-svc-p785d [250.288196ms]
Feb 17 17:22:09.089: INFO: Created: latency-svc-6ztn5
Feb 17 17:22:09.098: INFO: Got endpoints: latency-svc-6ztn5 [246.610201ms]
Feb 17 17:22:09.106: INFO: Created: latency-svc-mvc7t
Feb 17 17:22:09.116: INFO: Got endpoints: latency-svc-mvc7t [248.696009ms]
Feb 17 17:22:09.123: INFO: Created: latency-svc-7s4cq
Feb 17 17:22:09.131: INFO: Got endpoints: latency-svc-7s4cq [247.876104ms]
Feb 17 17:22:09.140: INFO: Created: latency-svc-glplt
Feb 17 17:22:09.149: INFO: Got endpoints: latency-svc-glplt [249.288907ms]
Feb 17 17:22:09.159: INFO: Created: latency-svc-q576j
Feb 17 17:22:09.167: INFO: Got endpoints: latency-svc-q576j [248.553323ms]
Feb 17 17:22:09.174: INFO: Created: latency-svc-rfpft
Feb 17 17:22:09.183: INFO: Got endpoints: latency-svc-rfpft [245.990239ms]
Feb 17 17:22:09.190: INFO: Created: latency-svc-j85z6
Feb 17 17:22:09.203: INFO: Got endpoints: latency-svc-j85z6 [248.532031ms]
Feb 17 17:22:09.207: INFO: Created: latency-svc-mdpcz
Feb 17 17:22:09.213: INFO: Got endpoints: latency-svc-mdpcz [229.339788ms]
Feb 17 17:22:09.220: INFO: Created: latency-svc-jgm6r
Feb 17 17:22:09.229: INFO: Got endpoints: latency-svc-jgm6r [239.826325ms]
Feb 17 17:22:09.235: INFO: Created: latency-svc-jkp2w
Feb 17 17:22:09.246: INFO: Got endpoints: latency-svc-jkp2w [242.576393ms]
Feb 17 17:22:09.253: INFO: Created: latency-svc-p2l9c
Feb 17 17:22:09.261: INFO: Got endpoints: latency-svc-p2l9c [243.253454ms]
Feb 17 17:22:09.268: INFO: Created: latency-svc-8drn9
Feb 17 17:22:09.276: INFO: Got endpoints: latency-svc-8drn9 [238.325114ms]
Feb 17 17:22:09.283: INFO: Created: latency-svc-ssmmx
Feb 17 17:22:09.293: INFO: Got endpoints: latency-svc-ssmmx [243.561234ms]
Feb 17 17:22:09.304: INFO: Created: latency-svc-wcznb
Feb 17 17:22:09.312: INFO: Got endpoints: latency-svc-wcznb [246.426809ms]
Feb 17 17:22:09.317: INFO: Created: latency-svc-dw4bb
Feb 17 17:22:09.329: INFO: Got endpoints: latency-svc-dw4bb [246.334762ms]
Feb 17 17:22:09.338: INFO: Created: latency-svc-rh845
Feb 17 17:22:09.346: INFO: Got endpoints: latency-svc-rh845 [248.372276ms]
Feb 17 17:22:09.353: INFO: Created: latency-svc-79slc
Feb 17 17:22:09.361: INFO: Got endpoints: latency-svc-79slc [244.73788ms]
Feb 17 17:22:09.370: INFO: Created: latency-svc-hc5pc
Feb 17 17:22:09.377: INFO: Got endpoints: latency-svc-hc5pc [246.043614ms]
Feb 17 17:22:09.387: INFO: Created: latency-svc-gsmbr
Feb 17 17:22:09.395: INFO: Got endpoints: latency-svc-gsmbr [245.911589ms]
Feb 17 17:22:09.401: INFO: Created: latency-svc-wpw25
Feb 17 17:22:09.409: INFO: Got endpoints: latency-svc-wpw25 [241.469227ms]
Feb 17 17:22:09.416: INFO: Created: latency-svc-dwps8
Feb 17 17:22:09.426: INFO: Got endpoints: latency-svc-dwps8 [242.523085ms]
Feb 17 17:22:09.433: INFO: Created: latency-svc-zbvgm
Feb 17 17:22:09.443: INFO: Got endpoints: latency-svc-zbvgm [239.451064ms]
Feb 17 17:22:09.448: INFO: Created: latency-svc-p6qcm
Feb 17 17:22:09.456: INFO: Got endpoints: latency-svc-p6qcm [243.011358ms]
Feb 17 17:22:09.465: INFO: Created: latency-svc-2c5jm
Feb 17 17:22:09.475: INFO: Got endpoints: latency-svc-2c5jm [245.653895ms]
Feb 17 17:22:09.486: INFO: Created: latency-svc-wjbfp
Feb 17 17:22:09.491: INFO: Got endpoints: latency-svc-wjbfp [245.483151ms]
Feb 17 17:22:09.501: INFO: Created: latency-svc-7nngz
Feb 17 17:22:09.508: INFO: Got endpoints: latency-svc-7nngz [246.354513ms]
Feb 17 17:22:09.518: INFO: Created: latency-svc-n9gm8
Feb 17 17:22:09.525: INFO: Got endpoints: latency-svc-n9gm8 [249.67658ms]
Feb 17 17:22:09.533: INFO: Created: latency-svc-zx78m
Feb 17 17:22:09.541: INFO: Got endpoints: latency-svc-zx78m [247.536413ms]
Feb 17 17:22:09.550: INFO: Created: latency-svc-gcxpn
Feb 17 17:22:09.560: INFO: Got endpoints: latency-svc-gcxpn [247.90566ms]
Feb 17 17:22:09.568: INFO: Created: latency-svc-jxrlp
Feb 17 17:22:09.574: INFO: Got endpoints: latency-svc-jxrlp [245.173115ms]
Feb 17 17:22:09.581: INFO: Created: latency-svc-cvmvp
Feb 17 17:22:09.590: INFO: Got endpoints: latency-svc-cvmvp [243.574906ms]
Feb 17 17:22:09.597: INFO: Created: latency-svc-4zsxh
Feb 17 17:22:09.607: INFO: Got endpoints: latency-svc-4zsxh [245.356011ms]
Feb 17 17:22:09.617: INFO: Created: latency-svc-ldnfg
Feb 17 17:22:09.621: INFO: Got endpoints: latency-svc-ldnfg [243.762813ms]
Feb 17 17:22:09.629: INFO: Created: latency-svc-jmw9d
Feb 17 17:22:09.640: INFO: Got endpoints: latency-svc-jmw9d [245.362223ms]
Feb 17 17:22:09.646: INFO: Created: latency-svc-dr6n8
Feb 17 17:22:09.655: INFO: Got endpoints: latency-svc-dr6n8 [245.882717ms]
Feb 17 17:22:09.665: INFO: Created: latency-svc-d8zmq
Feb 17 17:22:09.673: INFO: Got endpoints: latency-svc-d8zmq [246.784423ms]
Feb 17 17:22:09.689: INFO: Created: latency-svc-qtp9p
Feb 17 17:22:09.699: INFO: Created: latency-svc-mrpg2
Feb 17 17:22:09.702: INFO: Got endpoints: latency-svc-qtp9p [258.976089ms]
Feb 17 17:22:09.707: INFO: Got endpoints: latency-svc-mrpg2 [250.454697ms]
Feb 17 17:22:09.713: INFO: Created: latency-svc-km4ck
Feb 17 17:22:09.722: INFO: Got endpoints: latency-svc-km4ck [247.115914ms]
Feb 17 17:22:09.728: INFO: Created: latency-svc-j6wl7
Feb 17 17:22:09.739: INFO: Got endpoints: latency-svc-j6wl7 [247.409356ms]
Feb 17 17:22:09.744: INFO: Created: latency-svc-96sjl
Feb 17 17:22:09.754: INFO: Got endpoints: latency-svc-96sjl [245.703404ms]
Feb 17 17:22:09.761: INFO: Created: latency-svc-6kpqr
Feb 17 17:22:09.770: INFO: Got endpoints: latency-svc-6kpqr [244.607412ms]
Feb 17 17:22:09.777: INFO: Created: latency-svc-8sj54
Feb 17 17:22:09.785: INFO: Got endpoints: latency-svc-8sj54 [243.547367ms]
Feb 17 17:22:09.791: INFO: Created: latency-svc-pqzks
Feb 17 17:22:09.801: INFO: Got endpoints: latency-svc-pqzks [241.214576ms]
Feb 17 17:22:09.809: INFO: Created: latency-svc-k7d4q
Feb 17 17:22:09.815: INFO: Got endpoints: latency-svc-k7d4q [240.881616ms]
Feb 17 17:22:09.826: INFO: Created: latency-svc-wsp2b
Feb 17 17:22:09.839: INFO: Got endpoints: latency-svc-wsp2b [248.867181ms]
Feb 17 17:22:09.843: INFO: Created: latency-svc-qlbgj
Feb 17 17:22:09.857: INFO: Got endpoints: latency-svc-qlbgj [250.727865ms]
Feb 17 17:22:09.866: INFO: Created: latency-svc-p2lbr
Feb 17 17:22:09.873: INFO: Got endpoints: latency-svc-p2lbr [252.138485ms]
Feb 17 17:22:09.878: INFO: Created: latency-svc-kfsq8
Feb 17 17:22:09.885: INFO: Got endpoints: latency-svc-kfsq8 [244.382997ms]
Feb 17 17:22:09.895: INFO: Created: latency-svc-92hn9
Feb 17 17:22:09.904: INFO: Got endpoints: latency-svc-92hn9 [249.084088ms]
Feb 17 17:22:09.910: INFO: Created: latency-svc-vqb96
Feb 17 17:22:09.925: INFO: Got endpoints: latency-svc-vqb96 [252.260606ms]
Feb 17 17:22:09.927: INFO: Created: latency-svc-brwsg
Feb 17 17:22:09.934: INFO: Got endpoints: latency-svc-brwsg [232.497758ms]
Feb 17 17:22:09.945: INFO: Created: latency-svc-j278k
Feb 17 17:22:09.953: INFO: Got endpoints: latency-svc-j278k [246.096505ms]
Feb 17 17:22:09.958: INFO: Created: latency-svc-bb6qz
Feb 17 17:22:09.968: INFO: Got endpoints: latency-svc-bb6qz [245.909687ms]
Feb 17 17:22:09.976: INFO: Created: latency-svc-c9bdj
Feb 17 17:22:09.986: INFO: Got endpoints: latency-svc-c9bdj [246.721896ms]
Feb 17 17:22:09.994: INFO: Created: latency-svc-l4tj5
Feb 17 17:22:09.998: INFO: Got endpoints: latency-svc-l4tj5 [244.242221ms]
Feb 17 17:22:10.009: INFO: Created: latency-svc-x8wjk
Feb 17 17:22:10.017: INFO: Got endpoints: latency-svc-x8wjk [247.249982ms]
Feb 17 17:22:10.026: INFO: Created: latency-svc-l674d
Feb 17 17:22:10.039: INFO: Got endpoints: latency-svc-l674d [254.426861ms]
Feb 17 17:22:10.042: INFO: Created: latency-svc-rpvp9
Feb 17 17:22:10.054: INFO: Got endpoints: latency-svc-rpvp9 [252.288051ms]
Feb 17 17:22:10.060: INFO: Created: latency-svc-mk62f
Feb 17 17:22:10.074: INFO: Got endpoints: latency-svc-mk62f [258.282136ms]
Feb 17 17:22:10.074: INFO: Created: latency-svc-tqmmw
Feb 17 17:22:10.083: INFO: Got endpoints: latency-svc-tqmmw [244.326465ms]
Feb 17 17:22:10.089: INFO: Created: latency-svc-qzrmk
Feb 17 17:22:10.099: INFO: Got endpoints: latency-svc-qzrmk [241.509218ms]
Feb 17 17:22:10.108: INFO: Created: latency-svc-p6z9n
Feb 17 17:22:10.114: INFO: Got endpoints: latency-svc-p6z9n [240.655771ms]
Feb 17 17:22:10.124: INFO: Created: latency-svc-lzcnx
Feb 17 17:22:10.133: INFO: Got endpoints: latency-svc-lzcnx [247.700439ms]
Feb 17 17:22:10.140: INFO: Created: latency-svc-sxhkl
Feb 17 17:22:10.149: INFO: Got endpoints: latency-svc-sxhkl [245.524892ms]
Feb 17 17:22:10.157: INFO: Created: latency-svc-tr424
Feb 17 17:22:10.173: INFO: Got endpoints: latency-svc-tr424 [247.225703ms]
Feb 17 17:22:10.179: INFO: Created: latency-svc-5wnj6
Feb 17 17:22:10.186: INFO: Got endpoints: latency-svc-5wnj6 [252.025068ms]
Feb 17 17:22:10.196: INFO: Created: latency-svc-ghpvn
Feb 17 17:22:10.206: INFO: Got endpoints: latency-svc-ghpvn [252.732337ms]
Feb 17 17:22:10.221: INFO: Created: latency-svc-9gwh9
Feb 17 17:22:10.230: INFO: Got endpoints: latency-svc-9gwh9 [261.145145ms]
Feb 17 17:22:10.233: INFO: Created: latency-svc-6fwcn
Feb 17 17:22:10.246: INFO: Got endpoints: latency-svc-6fwcn [259.331082ms]
Feb 17 17:22:10.250: INFO: Created: latency-svc-ll86b
Feb 17 17:22:10.261: INFO: Got endpoints: latency-svc-ll86b [262.364346ms]
Feb 17 17:22:10.268: INFO: Created: latency-svc-q22fs
Feb 17 17:22:10.277: INFO: Got endpoints: latency-svc-q22fs [259.60901ms]
Feb 17 17:22:10.284: INFO: Created: latency-svc-c82jt
Feb 17 17:22:10.294: INFO: Got endpoints: latency-svc-c82jt [254.298567ms]
Feb 17 17:22:10.300: INFO: Created: latency-svc-hqrwj
Feb 17 17:22:10.308: INFO: Got endpoints: latency-svc-hqrwj [254.371579ms]
Feb 17 17:22:10.318: INFO: Created: latency-svc-mhhtj
Feb 17 17:22:10.330: INFO: Got endpoints: latency-svc-mhhtj [256.061866ms]
Feb 17 17:22:10.335: INFO: Created: latency-svc-vr4wp
Feb 17 17:22:10.345: INFO: Got endpoints: latency-svc-vr4wp [261.458835ms]
Feb 17 17:22:10.354: INFO: Created: latency-svc-vzlwq
Feb 17 17:22:10.361: INFO: Got endpoints: latency-svc-vzlwq [261.972674ms]
Feb 17 17:22:10.374: INFO: Created: latency-svc-rg2lv
Feb 17 17:22:10.383: INFO: Got endpoints: latency-svc-rg2lv [269.217179ms]
Feb 17 17:22:10.384: INFO: Created: latency-svc-pc9sk
Feb 17 17:22:10.394: INFO: Got endpoints: latency-svc-pc9sk [261.361076ms]
Feb 17 17:22:10.402: INFO: Created: latency-svc-82b5n
Feb 17 17:22:10.410: INFO: Got endpoints: latency-svc-82b5n [260.43618ms]
Feb 17 17:22:10.417: INFO: Created: latency-svc-pgtpm
Feb 17 17:22:10.424: INFO: Got endpoints: latency-svc-pgtpm [251.498419ms]
Feb 17 17:22:10.433: INFO: Created: latency-svc-vwdrg
Feb 17 17:22:10.442: INFO: Got endpoints: latency-svc-vwdrg [255.519132ms]
Feb 17 17:22:10.464: INFO: Created: latency-svc-m6jpx
Feb 17 17:22:10.469: INFO: Created: latency-svc-m6dtv
Feb 17 17:22:10.476: INFO: Got endpoints: latency-svc-m6dtv [245.850278ms]
Feb 17 17:22:10.477: INFO: Got endpoints: latency-svc-m6jpx [271.13634ms]
Feb 17 17:22:10.482: INFO: Created: latency-svc-f2gkl
Feb 17 17:22:10.489: INFO: Got endpoints: latency-svc-f2gkl [243.638017ms]
Feb 17 17:22:10.498: INFO: Created: latency-svc-4lz4n
Feb 17 17:22:10.507: INFO: Got endpoints: latency-svc-4lz4n [246.404199ms]
Feb 17 17:22:10.515: INFO: Created: latency-svc-f5j75
Feb 17 17:22:10.523: INFO: Got endpoints: latency-svc-f5j75 [245.798444ms]
Feb 17 17:22:10.531: INFO: Created: latency-svc-mt25d
Feb 17 17:22:10.542: INFO: Got endpoints: latency-svc-mt25d [248.306436ms]
Feb 17 17:22:10.549: INFO: Created: latency-svc-tz7dw
Feb 17 17:22:10.555: INFO: Got endpoints: latency-svc-tz7dw [246.404441ms]
Feb 17 17:22:10.566: INFO: Created: latency-svc-5plh8
Feb 17 17:22:10.577: INFO: Got endpoints: latency-svc-5plh8 [247.077223ms]
Feb 17 17:22:10.582: INFO: Created: latency-svc-mbztj
Feb 17 17:22:10.597: INFO: Got endpoints: latency-svc-mbztj [251.84394ms]
Feb 17 17:22:10.600: INFO: Created: latency-svc-588w4
Feb 17 17:22:10.609: INFO: Got endpoints: latency-svc-588w4 [247.631759ms]
Feb 17 17:22:10.619: INFO: Created: latency-svc-jct57
Feb 17 17:22:10.627: INFO: Got endpoints: latency-svc-jct57 [243.27265ms]
Feb 17 17:22:10.636: INFO: Created: latency-svc-mkj4k
Feb 17 17:22:10.647: INFO: Created: latency-svc-4wgqq
Feb 17 17:22:10.647: INFO: Got endpoints: latency-svc-mkj4k [253.113723ms]
Feb 17 17:22:10.659: INFO: Got endpoints: latency-svc-4wgqq [249.45962ms]
Feb 17 17:22:10.659: INFO: Latencies: [40.511947ms 72.195768ms 87.723734ms 109.628229ms 124.187876ms 147.246935ms 155.594394ms 166.682525ms 182.770193ms 200.765928ms 216.231416ms 224.849579ms 229.339788ms 231.722055ms 232.497758ms 235.297561ms 235.890617ms 236.068845ms 236.991958ms 237.358068ms 238.325114ms 238.483214ms 238.584632ms 239.236332ms 239.451064ms 239.474155ms 239.788854ms 239.826325ms 240.12489ms 240.400441ms 240.400464ms 240.655771ms 240.847042ms 240.881616ms 240.957766ms 241.214576ms 241.256661ms 241.425607ms 241.469227ms 241.480247ms 241.509218ms 241.792126ms 241.977854ms 242.122316ms 242.308489ms 242.382487ms 242.38326ms 242.3886ms 242.523085ms 242.576393ms 242.688573ms 242.696522ms 243.011358ms 243.253454ms 243.27265ms 243.385393ms 243.471227ms 243.547367ms 243.561234ms 243.574906ms 243.638017ms 243.762813ms 243.893473ms 243.997315ms 244.242221ms 244.265691ms 244.275097ms 244.326465ms 244.336495ms 244.382997ms 244.386439ms 244.575447ms 244.582115ms 244.607412ms 244.73788ms 245.145938ms 245.173115ms 245.212476ms 245.214008ms 245.356011ms 245.362223ms 245.483151ms 245.524892ms 245.653895ms 245.703404ms 245.734546ms 245.798444ms 245.800104ms 245.850278ms 245.882717ms 245.909687ms 245.911589ms 245.964379ms 245.990239ms 246.043614ms 246.096505ms 246.334762ms 246.354513ms 246.404199ms 246.404441ms 246.426809ms 246.610201ms 246.721896ms 246.784423ms 246.823431ms 246.921237ms 246.941186ms 247.077223ms 247.115914ms 247.225703ms 247.249982ms 247.409356ms 247.443434ms 247.536413ms 247.631759ms 247.700439ms 247.720482ms 247.876104ms 247.90566ms 248.085872ms 248.306436ms 248.372276ms 248.532031ms 248.553323ms 248.696009ms 248.867181ms 249.084088ms 249.288907ms 249.45962ms 249.67658ms 249.705595ms 250.212182ms 250.288196ms 250.454543ms 250.454697ms 250.727865ms 251.498419ms 251.84394ms 251.990043ms 252.025068ms 252.138485ms 252.260606ms 252.288051ms 252.732337ms 253.113723ms 253.367501ms 253.544629ms 254.215326ms 254.26719ms 254.298567ms 254.371579ms 254.426861ms 254.952237ms 255.022229ms 255.519132ms 255.688877ms 256.061866ms 256.0777ms 257.512166ms 258.282136ms 258.976089ms 259.331082ms 259.60901ms 259.909626ms 260.15369ms 260.41234ms 260.43618ms 261.096073ms 261.145145ms 261.361076ms 261.458835ms 261.595644ms 261.623636ms 261.972674ms 262.364346ms 262.453867ms 263.945899ms 265.933465ms 266.339265ms 266.981113ms 267.303873ms 268.77322ms 269.217179ms 271.13634ms 281.779197ms 286.582191ms 291.152602ms 291.895361ms 292.732047ms 293.214371ms 294.300718ms 294.828603ms 295.541817ms 295.809508ms 296.685728ms 297.385195ms 298.109404ms 299.585953ms 300.327794ms 309.997136ms]
Feb 17 17:22:10.660: INFO: 50 %ile: 246.426809ms
Feb 17 17:22:10.660: INFO: 90 %ile: 267.303873ms
Feb 17 17:22:10.660: INFO: 99 %ile: 300.327794ms
Feb 17 17:22:10.660: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 17:22:10.660: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svc-latency-2956" for this suite.
Feb 17 17:22:36.732: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:22:37.127: INFO: namespace svc-latency-2956 deletion completed in 26.446034247s

• [SLOW TEST:32.347 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should not be very high  [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 17:22:37.127: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-2361
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-4c9d2cfb-fc3a-4115-aaf3-ffd4b2e6163e
STEP: Creating a pod to test consume configMaps
Feb 17 17:22:37.417: INFO: Waiting up to 5m0s for pod "pod-configmaps-e696c1c2-a43d-4191-8aa6-328f514115c7" in namespace "configmap-2361" to be "success or failure"
Feb 17 17:22:37.428: INFO: Pod "pod-configmaps-e696c1c2-a43d-4191-8aa6-328f514115c7": Phase="Pending", Reason="", readiness=false. Elapsed: 11.029094ms
Feb 17 17:22:39.444: INFO: Pod "pod-configmaps-e696c1c2-a43d-4191-8aa6-328f514115c7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.027263534s
STEP: Saw pod success
Feb 17 17:22:39.444: INFO: Pod "pod-configmaps-e696c1c2-a43d-4191-8aa6-328f514115c7" satisfied condition "success or failure"
Feb 17 17:22:39.456: INFO: Trying to get logs from node 10.242.0.59 pod pod-configmaps-e696c1c2-a43d-4191-8aa6-328f514115c7 container configmap-volume-test: <nil>
STEP: delete the pod
Feb 17 17:22:39.523: INFO: Waiting for pod pod-configmaps-e696c1c2-a43d-4191-8aa6-328f514115c7 to disappear
Feb 17 17:22:39.533: INFO: Pod pod-configmaps-e696c1c2-a43d-4191-8aa6-328f514115c7 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 17:22:39.533: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2361" for this suite.
Feb 17 17:22:45.607: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:22:46.008: INFO: namespace configmap-2361 deletion completed in 6.451284913s

• [SLOW TEST:8.881 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 17:22:46.009: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-5451
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 17:22:50.317: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-5451" for this suite.
Feb 17 17:22:56.386: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:22:56.784: INFO: namespace kubelet-test-5451 deletion completed in 6.447967119s

• [SLOW TEST:10.775 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should have an terminated reason [NodeConformance] [Conformance]
    /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 17:22:56.786: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3515
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating the pod
Feb 17 17:22:59.684: INFO: Successfully updated pod "labelsupdate7ffbf42a-7c09-4813-ac1c-4fe26552c156"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 17:23:03.783: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3515" for this suite.
Feb 17 17:23:27.852: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:23:28.275: INFO: namespace projected-3515 deletion completed in 24.473095441s

• [SLOW TEST:31.489 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 17:23:28.276: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-1129
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1721
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb 17 17:23:28.543: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-079603707 run e2e-test-nginx-pod --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --labels=run=e2e-test-nginx-pod --namespace=kubectl-1129'
Feb 17 17:23:28.706: INFO: stderr: ""
Feb 17 17:23:28.706: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod is running
STEP: verifying the pod e2e-test-nginx-pod was created
Feb 17 17:23:33.756: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-079603707 get pod e2e-test-nginx-pod --namespace=kubectl-1129 -o json'
Feb 17 17:23:33.875: INFO: stderr: ""
Feb 17 17:23:33.875: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"annotations\": {\n            \"kubernetes.io/psp\": \"e2e-test-privileged-psp\"\n        },\n        \"creationTimestamp\": \"2020-02-17T17:23:28Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"kubectl-1129\",\n        \"resourceVersion\": \"36750\",\n        \"selfLink\": \"/api/v1/namespaces/kubectl-1129/pods/e2e-test-nginx-pod\",\n        \"uid\": \"a4f92374-630b-4383-8c61-737a7524b447\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-4gx5j\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"10.242.0.98\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 600\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 600\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-4gx5j\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-4gx5j\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-02-17T17:23:28Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-02-17T17:23:30Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-02-17T17:23:30Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-02-17T17:23:28Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"containerd://8c5aee2f9f8c1a30ccd5a4daafce26022c33eb437cb55a9bed4a4c253113818d\",\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imageID\": \"docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2020-02-17T17:23:30Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.242.0.98\",\n        \"phase\": \"Running\",\n        \"podIP\": \"172.30.197.171\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2020-02-17T17:23:28Z\"\n    }\n}\n"
STEP: replace the image in the pod
Feb 17 17:23:33.876: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-079603707 replace -f - --namespace=kubectl-1129'
Feb 17 17:23:34.284: INFO: stderr: ""
Feb 17 17:23:34.284: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
STEP: verifying the pod e2e-test-nginx-pod has the right image docker.io/library/busybox:1.29
[AfterEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1726
Feb 17 17:23:34.296: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-079603707 delete pods e2e-test-nginx-pod --namespace=kubectl-1129'
Feb 17 17:23:39.076: INFO: stderr: ""
Feb 17 17:23:39.076: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 17:23:39.076: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1129" for this suite.
Feb 17 17:23:45.147: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:23:45.561: INFO: namespace kubectl-1129 deletion completed in 6.466915511s

• [SLOW TEST:17.286 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl replace
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 17:23:45.561: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-4408
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-d2590f7c-e91c-49af-b955-3ef6eb78cc96
STEP: Creating a pod to test consume configMaps
Feb 17 17:23:45.852: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-d7ee5005-52e2-4574-9c00-424700d861cd" in namespace "projected-4408" to be "success or failure"
Feb 17 17:23:45.862: INFO: Pod "pod-projected-configmaps-d7ee5005-52e2-4574-9c00-424700d861cd": Phase="Pending", Reason="", readiness=false. Elapsed: 10.257254ms
Feb 17 17:23:47.873: INFO: Pod "pod-projected-configmaps-d7ee5005-52e2-4574-9c00-424700d861cd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021851152s
Feb 17 17:23:49.885: INFO: Pod "pod-projected-configmaps-d7ee5005-52e2-4574-9c00-424700d861cd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.033795952s
STEP: Saw pod success
Feb 17 17:23:49.885: INFO: Pod "pod-projected-configmaps-d7ee5005-52e2-4574-9c00-424700d861cd" satisfied condition "success or failure"
Feb 17 17:23:49.897: INFO: Trying to get logs from node 10.242.0.59 pod pod-projected-configmaps-d7ee5005-52e2-4574-9c00-424700d861cd container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 17 17:23:49.998: INFO: Waiting for pod pod-projected-configmaps-d7ee5005-52e2-4574-9c00-424700d861cd to disappear
Feb 17 17:23:50.008: INFO: Pod pod-projected-configmaps-d7ee5005-52e2-4574-9c00-424700d861cd no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 17:23:50.008: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4408" for this suite.
Feb 17 17:23:56.078: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:23:56.511: INFO: namespace projected-4408 deletion completed in 6.480580788s

• [SLOW TEST:10.950 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 17:23:56.511: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-7154
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
Feb 17 17:23:56.779: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 17:24:33.833: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-7154" for this suite.
Feb 17 17:24:39.918: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:24:40.318: INFO: namespace init-container-7154 deletion completed in 6.461057343s

• [SLOW TEST:43.806 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 17:24:40.318: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-wrapper-1627
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Feb 17 17:24:41.271: INFO: Pod name wrapped-volume-race-8ff5ec5e-2cca-449e-abdc-b023ebf6ca8d: Found 0 pods out of 5
Feb 17 17:24:46.289: INFO: Pod name wrapped-volume-race-8ff5ec5e-2cca-449e-abdc-b023ebf6ca8d: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-8ff5ec5e-2cca-449e-abdc-b023ebf6ca8d in namespace emptydir-wrapper-1627, will wait for the garbage collector to delete the pods
Feb 17 17:25:28.457: INFO: Deleting ReplicationController wrapped-volume-race-8ff5ec5e-2cca-449e-abdc-b023ebf6ca8d took: 30.779859ms
Feb 17 17:25:28.657: INFO: Terminating ReplicationController wrapped-volume-race-8ff5ec5e-2cca-449e-abdc-b023ebf6ca8d pods took: 200.264371ms
STEP: Creating RC which spawns configmap-volume pods
Feb 17 17:26:03.413: INFO: Pod name wrapped-volume-race-3a6177a3-0a85-4547-851b-f5dfcc7e8813: Found 0 pods out of 5
Feb 17 17:26:08.432: INFO: Pod name wrapped-volume-race-3a6177a3-0a85-4547-851b-f5dfcc7e8813: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-3a6177a3-0a85-4547-851b-f5dfcc7e8813 in namespace emptydir-wrapper-1627, will wait for the garbage collector to delete the pods
Feb 17 17:26:08.586: INFO: Deleting ReplicationController wrapped-volume-race-3a6177a3-0a85-4547-851b-f5dfcc7e8813 took: 33.330415ms
Feb 17 17:26:08.786: INFO: Terminating ReplicationController wrapped-volume-race-3a6177a3-0a85-4547-851b-f5dfcc7e8813 pods took: 200.406441ms
STEP: Creating RC which spawns configmap-volume pods
Feb 17 17:26:53.341: INFO: Pod name wrapped-volume-race-25191beb-24de-42d3-8bb5-3c19ac404e00: Found 0 pods out of 5
Feb 17 17:26:58.358: INFO: Pod name wrapped-volume-race-25191beb-24de-42d3-8bb5-3c19ac404e00: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-25191beb-24de-42d3-8bb5-3c19ac404e00 in namespace emptydir-wrapper-1627, will wait for the garbage collector to delete the pods
Feb 17 17:26:58.735: INFO: Deleting ReplicationController wrapped-volume-race-25191beb-24de-42d3-8bb5-3c19ac404e00 took: 35.717669ms
Feb 17 17:26:58.936: INFO: Terminating ReplicationController wrapped-volume-race-25191beb-24de-42d3-8bb5-3c19ac404e00 pods took: 200.466756ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 17:27:34.529: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-1627" for this suite.
Feb 17 17:27:44.601: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:27:45.025: INFO: namespace emptydir-wrapper-1627 deletion completed in 10.476965652s

• [SLOW TEST:184.707 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 17:27:45.026: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-4082
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test env composition
Feb 17 17:27:45.304: INFO: Waiting up to 5m0s for pod "var-expansion-35b84121-94d8-408e-81ad-8ff678423b9f" in namespace "var-expansion-4082" to be "success or failure"
Feb 17 17:27:45.316: INFO: Pod "var-expansion-35b84121-94d8-408e-81ad-8ff678423b9f": Phase="Pending", Reason="", readiness=false. Elapsed: 11.932233ms
Feb 17 17:27:47.327: INFO: Pod "var-expansion-35b84121-94d8-408e-81ad-8ff678423b9f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022771748s
Feb 17 17:27:49.343: INFO: Pod "var-expansion-35b84121-94d8-408e-81ad-8ff678423b9f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.038715543s
STEP: Saw pod success
Feb 17 17:27:49.343: INFO: Pod "var-expansion-35b84121-94d8-408e-81ad-8ff678423b9f" satisfied condition "success or failure"
Feb 17 17:27:49.355: INFO: Trying to get logs from node 10.242.0.59 pod var-expansion-35b84121-94d8-408e-81ad-8ff678423b9f container dapi-container: <nil>
STEP: delete the pod
Feb 17 17:27:49.429: INFO: Waiting for pod var-expansion-35b84121-94d8-408e-81ad-8ff678423b9f to disappear
Feb 17 17:27:49.440: INFO: Pod var-expansion-35b84121-94d8-408e-81ad-8ff678423b9f no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 17:27:49.440: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-4082" for this suite.
Feb 17 17:27:55.508: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:27:55.920: INFO: namespace var-expansion-4082 deletion completed in 6.459742533s

• [SLOW TEST:10.894 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 17:27:55.921: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-318
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Feb 17 17:27:56.213: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9106c49d-e594-4faa-856a-9693cb1d619e" in namespace "downward-api-318" to be "success or failure"
Feb 17 17:27:56.224: INFO: Pod "downwardapi-volume-9106c49d-e594-4faa-856a-9693cb1d619e": Phase="Pending", Reason="", readiness=false. Elapsed: 10.820011ms
Feb 17 17:27:58.235: INFO: Pod "downwardapi-volume-9106c49d-e594-4faa-856a-9693cb1d619e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021642527s
STEP: Saw pod success
Feb 17 17:27:58.235: INFO: Pod "downwardapi-volume-9106c49d-e594-4faa-856a-9693cb1d619e" satisfied condition "success or failure"
Feb 17 17:27:58.246: INFO: Trying to get logs from node 10.242.0.98 pod downwardapi-volume-9106c49d-e594-4faa-856a-9693cb1d619e container client-container: <nil>
STEP: delete the pod
Feb 17 17:27:58.312: INFO: Waiting for pod downwardapi-volume-9106c49d-e594-4faa-856a-9693cb1d619e to disappear
Feb 17 17:27:58.323: INFO: Pod downwardapi-volume-9106c49d-e594-4faa-856a-9693cb1d619e no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 17:27:58.323: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-318" for this suite.
Feb 17 17:28:04.391: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:28:04.786: INFO: namespace downward-api-318 deletion completed in 6.443252714s

• [SLOW TEST:8.865 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 17:28:04.787: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-4317
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-map-6f032b38-e93b-42ed-b010-38bbdd3dafe2
STEP: Creating a pod to test consume secrets
Feb 17 17:28:05.102: INFO: Waiting up to 5m0s for pod "pod-secrets-7100ceb2-18c8-4d9a-b69e-68b05f6861f0" in namespace "secrets-4317" to be "success or failure"
Feb 17 17:28:05.113: INFO: Pod "pod-secrets-7100ceb2-18c8-4d9a-b69e-68b05f6861f0": Phase="Pending", Reason="", readiness=false. Elapsed: 10.453529ms
Feb 17 17:28:07.125: INFO: Pod "pod-secrets-7100ceb2-18c8-4d9a-b69e-68b05f6861f0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.022538232s
STEP: Saw pod success
Feb 17 17:28:07.125: INFO: Pod "pod-secrets-7100ceb2-18c8-4d9a-b69e-68b05f6861f0" satisfied condition "success or failure"
Feb 17 17:28:07.139: INFO: Trying to get logs from node 10.242.0.59 pod pod-secrets-7100ceb2-18c8-4d9a-b69e-68b05f6861f0 container secret-volume-test: <nil>
STEP: delete the pod
Feb 17 17:28:07.206: INFO: Waiting for pod pod-secrets-7100ceb2-18c8-4d9a-b69e-68b05f6861f0 to disappear
Feb 17 17:28:07.218: INFO: Pod pod-secrets-7100ceb2-18c8-4d9a-b69e-68b05f6861f0 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 17:28:07.218: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-4317" for this suite.
Feb 17 17:28:13.296: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:28:13.688: INFO: namespace secrets-4317 deletion completed in 6.445070287s

• [SLOW TEST:8.901 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] version v1
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 17:28:13.689: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-7653
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Feb 17 17:28:14.221: INFO: (0) /api/v1/nodes/10.242.0.59/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 31.456468ms)
Feb 17 17:28:14.244: INFO: (1) /api/v1/nodes/10.242.0.59/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 22.48612ms)
Feb 17 17:28:14.268: INFO: (2) /api/v1/nodes/10.242.0.59/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 24.182093ms)
Feb 17 17:28:14.291: INFO: (3) /api/v1/nodes/10.242.0.59/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 22.669852ms)
Feb 17 17:28:14.314: INFO: (4) /api/v1/nodes/10.242.0.59/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 22.615505ms)
Feb 17 17:28:14.336: INFO: (5) /api/v1/nodes/10.242.0.59/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 22.331666ms)
Feb 17 17:28:14.365: INFO: (6) /api/v1/nodes/10.242.0.59/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 28.323488ms)
Feb 17 17:28:14.388: INFO: (7) /api/v1/nodes/10.242.0.59/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 23.20804ms)
Feb 17 17:28:14.414: INFO: (8) /api/v1/nodes/10.242.0.59/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 26.48069ms)
Feb 17 17:28:14.439: INFO: (9) /api/v1/nodes/10.242.0.59/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 24.144833ms)
Feb 17 17:28:14.461: INFO: (10) /api/v1/nodes/10.242.0.59/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 22.627595ms)
Feb 17 17:28:14.498: INFO: (11) /api/v1/nodes/10.242.0.59/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 36.156055ms)
Feb 17 17:28:14.520: INFO: (12) /api/v1/nodes/10.242.0.59/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 22.657806ms)
Feb 17 17:28:14.544: INFO: (13) /api/v1/nodes/10.242.0.59/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 23.921962ms)
Feb 17 17:28:14.567: INFO: (14) /api/v1/nodes/10.242.0.59/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 22.763803ms)
Feb 17 17:28:14.601: INFO: (15) /api/v1/nodes/10.242.0.59/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 34.116281ms)
Feb 17 17:28:14.629: INFO: (16) /api/v1/nodes/10.242.0.59/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 27.930994ms)
Feb 17 17:28:14.653: INFO: (17) /api/v1/nodes/10.242.0.59/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 23.336983ms)
Feb 17 17:28:14.675: INFO: (18) /api/v1/nodes/10.242.0.59/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 22.595675ms)
Feb 17 17:28:14.699: INFO: (19) /api/v1/nodes/10.242.0.59/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 23.308249ms)
[AfterEach] version v1
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 17:28:14.699: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-7653" for this suite.
Feb 17 17:28:20.769: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:28:21.164: INFO: namespace proxy-7653 deletion completed in 6.448377292s

• [SLOW TEST:7.476 seconds]
[sig-network] Proxy
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:58
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 17:28:21.166: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-2578
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Feb 17 17:28:21.418: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-079603707 version'
Feb 17 17:28:21.562: INFO: stderr: ""
Feb 17 17:28:21.562: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"15\", GitVersion:\"v1.15.10\", GitCommit:\"1bea6c00a7055edef03f1d4bb58b773fa8917f11\", GitTreeState:\"clean\", BuildDate:\"2020-02-11T20:13:57Z\", GoVersion:\"go1.12.12\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"15\", GitVersion:\"v1.15.10+IKS\", GitCommit:\"de009843b60976afddffbb5bc01eec7a67de556f\", GitTreeState:\"clean\", BuildDate:\"2020-02-13T06:08:47Z\", GoVersion:\"go1.12.12\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 17:28:21.562: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2578" for this suite.
Feb 17 17:28:27.635: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:28:28.091: INFO: namespace kubectl-2578 deletion completed in 6.509381581s

• [SLOW TEST:6.925 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl version
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 17:28:28.091: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-6894
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Feb 17 17:28:28.475: INFO: Number of nodes with available pods: 0
Feb 17 17:28:28.475: INFO: Node 10.242.0.59 is running more than one daemon pod
Feb 17 17:28:29.516: INFO: Number of nodes with available pods: 0
Feb 17 17:28:29.516: INFO: Node 10.242.0.59 is running more than one daemon pod
Feb 17 17:28:30.507: INFO: Number of nodes with available pods: 2
Feb 17 17:28:30.507: INFO: Node 10.242.0.59 is running more than one daemon pod
Feb 17 17:28:31.513: INFO: Number of nodes with available pods: 3
Feb 17 17:28:31.513: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Feb 17 17:28:31.578: INFO: Number of nodes with available pods: 2
Feb 17 17:28:31.578: INFO: Node 10.242.0.63 is running more than one daemon pod
Feb 17 17:28:32.608: INFO: Number of nodes with available pods: 2
Feb 17 17:28:32.608: INFO: Node 10.242.0.63 is running more than one daemon pod
Feb 17 17:28:33.729: INFO: Number of nodes with available pods: 3
Feb 17 17:28:33.729: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-6894, will wait for the garbage collector to delete the pods
Feb 17 17:28:33.840: INFO: Deleting DaemonSet.extensions daemon-set took: 27.168857ms
Feb 17 17:28:34.040: INFO: Terminating DaemonSet.extensions daemon-set pods took: 200.435224ms
Feb 17 17:28:47.352: INFO: Number of nodes with available pods: 0
Feb 17 17:28:47.352: INFO: Number of running nodes: 0, number of available pods: 0
Feb 17 17:28:47.362: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-6894/daemonsets","resourceVersion":"38163"},"items":null}

Feb 17 17:28:47.372: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-6894/pods","resourceVersion":"38163"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 17:28:47.433: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-6894" for this suite.
Feb 17 17:28:55.496: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:28:55.894: INFO: namespace daemonsets-6894 deletion completed in 8.446678049s

• [SLOW TEST:27.803 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 17:28:55.895: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-1828
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Feb 17 17:28:56.185: INFO: Waiting up to 5m0s for pod "downwardapi-volume-2c7f8211-65f1-4e0d-bb75-df0af41a16e6" in namespace "downward-api-1828" to be "success or failure"
Feb 17 17:28:56.198: INFO: Pod "downwardapi-volume-2c7f8211-65f1-4e0d-bb75-df0af41a16e6": Phase="Pending", Reason="", readiness=false. Elapsed: 13.386844ms
Feb 17 17:28:58.211: INFO: Pod "downwardapi-volume-2c7f8211-65f1-4e0d-bb75-df0af41a16e6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025613108s
Feb 17 17:29:00.222: INFO: Pod "downwardapi-volume-2c7f8211-65f1-4e0d-bb75-df0af41a16e6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.036579343s
STEP: Saw pod success
Feb 17 17:29:00.222: INFO: Pod "downwardapi-volume-2c7f8211-65f1-4e0d-bb75-df0af41a16e6" satisfied condition "success or failure"
Feb 17 17:29:00.233: INFO: Trying to get logs from node 10.242.0.98 pod downwardapi-volume-2c7f8211-65f1-4e0d-bb75-df0af41a16e6 container client-container: <nil>
STEP: delete the pod
Feb 17 17:29:00.312: INFO: Waiting for pod downwardapi-volume-2c7f8211-65f1-4e0d-bb75-df0af41a16e6 to disappear
Feb 17 17:29:00.324: INFO: Pod downwardapi-volume-2c7f8211-65f1-4e0d-bb75-df0af41a16e6 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 17:29:00.324: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1828" for this suite.
Feb 17 17:29:06.392: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:29:07.041: INFO: namespace downward-api-1828 deletion completed in 6.697432659s

• [SLOW TEST:11.146 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 17:29:07.042: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-9860
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Feb 17 17:29:07.304: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 17:29:08.431: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-9860" for this suite.
Feb 17 17:29:14.502: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:29:14.894: INFO: namespace custom-resource-definition-9860 deletion completed in 6.444666117s

• [SLOW TEST:7.853 seconds]
[sig-api-machinery] CustomResourceDefinition resources
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:35
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 17:29:14.895: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-7222
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod test-webserver-1afdfc22-fbb0-4ff3-a69c-853d506f3d9e in namespace container-probe-7222
Feb 17 17:29:17.197: INFO: Started pod test-webserver-1afdfc22-fbb0-4ff3-a69c-853d506f3d9e in namespace container-probe-7222
STEP: checking the pod's current state and verifying that restartCount is present
Feb 17 17:29:17.208: INFO: Initial restart count of pod test-webserver-1afdfc22-fbb0-4ff3-a69c-853d506f3d9e is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 17:33:18.799: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-7222" for this suite.
Feb 17 17:33:24.875: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:33:25.270: INFO: namespace container-probe-7222 deletion completed in 6.448885608s

• [SLOW TEST:250.376 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 17:33:25.271: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-1759
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
Feb 17 17:34:05.645: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W0217 17:34:05.645225      16 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 17:34:05.645: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-1759" for this suite.
Feb 17 17:34:13.715: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:34:14.120: INFO: namespace gc-1759 deletion completed in 8.457090739s

• [SLOW TEST:48.850 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 17:34:14.120: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-823
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1685
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb 17 17:34:14.387: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-079603707 run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-823'
Feb 17 17:34:14.706: INFO: stderr: ""
Feb 17 17:34:14.706: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1690
Feb 17 17:34:14.719: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-079603707 delete pods e2e-test-nginx-pod --namespace=kubectl-823'
Feb 17 17:34:28.909: INFO: stderr: ""
Feb 17 17:34:28.909: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 17:34:28.909: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-823" for this suite.
Feb 17 17:34:34.975: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:34:35.404: INFO: namespace kubectl-823 deletion completed in 6.476903744s

• [SLOW TEST:21.283 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run pod
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 17:34:35.404: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-507
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 17:34:35.703: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-507" for this suite.
Feb 17 17:34:41.770: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:34:42.166: INFO: namespace services-507 deletion completed in 6.444514041s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:92

• [SLOW TEST:6.762 seconds]
[sig-network] Services
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide secure master service  [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 17:34:42.166: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-1280
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the container
STEP: wait for the container to reach Failed
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Feb 17 17:34:44.489: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 17:34:44.545: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-1280" for this suite.
Feb 17 17:34:50.613: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:34:51.000: INFO: namespace container-runtime-1280 deletion completed in 6.436664511s

• [SLOW TEST:8.834 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  blackbox test
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
    on terminated container
    /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:129
      should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 17:34:51.001: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-8930
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Feb 17 17:34:51.285: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9a524387-0776-4171-a6dd-ac1b30348d04" in namespace "downward-api-8930" to be "success or failure"
Feb 17 17:34:51.300: INFO: Pod "downwardapi-volume-9a524387-0776-4171-a6dd-ac1b30348d04": Phase="Pending", Reason="", readiness=false. Elapsed: 15.142275ms
Feb 17 17:34:53.315: INFO: Pod "downwardapi-volume-9a524387-0776-4171-a6dd-ac1b30348d04": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.030239716s
STEP: Saw pod success
Feb 17 17:34:53.315: INFO: Pod "downwardapi-volume-9a524387-0776-4171-a6dd-ac1b30348d04" satisfied condition "success or failure"
Feb 17 17:34:53.332: INFO: Trying to get logs from node 10.242.0.98 pod downwardapi-volume-9a524387-0776-4171-a6dd-ac1b30348d04 container client-container: <nil>
STEP: delete the pod
Feb 17 17:34:53.418: INFO: Waiting for pod downwardapi-volume-9a524387-0776-4171-a6dd-ac1b30348d04 to disappear
Feb 17 17:34:53.429: INFO: Pod downwardapi-volume-9a524387-0776-4171-a6dd-ac1b30348d04 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 17:34:53.429: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8930" for this suite.
Feb 17 17:34:59.498: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:34:59.886: INFO: namespace downward-api-8930 deletion completed in 6.438446729s

• [SLOW TEST:8.885 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 17:34:59.887: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-8649
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0644 on tmpfs
Feb 17 17:35:00.165: INFO: Waiting up to 5m0s for pod "pod-0b3108b2-4862-42b4-94cf-7c114fc6e766" in namespace "emptydir-8649" to be "success or failure"
Feb 17 17:35:00.177: INFO: Pod "pod-0b3108b2-4862-42b4-94cf-7c114fc6e766": Phase="Pending", Reason="", readiness=false. Elapsed: 12.362874ms
Feb 17 17:35:02.190: INFO: Pod "pod-0b3108b2-4862-42b4-94cf-7c114fc6e766": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024642383s
Feb 17 17:35:04.201: INFO: Pod "pod-0b3108b2-4862-42b4-94cf-7c114fc6e766": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.035647524s
STEP: Saw pod success
Feb 17 17:35:04.201: INFO: Pod "pod-0b3108b2-4862-42b4-94cf-7c114fc6e766" satisfied condition "success or failure"
Feb 17 17:35:04.211: INFO: Trying to get logs from node 10.242.0.59 pod pod-0b3108b2-4862-42b4-94cf-7c114fc6e766 container test-container: <nil>
STEP: delete the pod
Feb 17 17:35:04.287: INFO: Waiting for pod pod-0b3108b2-4862-42b4-94cf-7c114fc6e766 to disappear
Feb 17 17:35:04.297: INFO: Pod pod-0b3108b2-4862-42b4-94cf-7c114fc6e766 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 17:35:04.297: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8649" for this suite.
Feb 17 17:35:10.366: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:35:10.770: INFO: namespace emptydir-8649 deletion completed in 6.454277293s

• [SLOW TEST:10.883 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 17:35:10.771: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-2673
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0777 on tmpfs
Feb 17 17:35:11.049: INFO: Waiting up to 5m0s for pod "pod-1b315223-f491-420d-8bb8-ae3880a6f513" in namespace "emptydir-2673" to be "success or failure"
Feb 17 17:35:11.065: INFO: Pod "pod-1b315223-f491-420d-8bb8-ae3880a6f513": Phase="Pending", Reason="", readiness=false. Elapsed: 15.090428ms
Feb 17 17:35:13.239: INFO: Pod "pod-1b315223-f491-420d-8bb8-ae3880a6f513": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.189706531s
STEP: Saw pod success
Feb 17 17:35:13.239: INFO: Pod "pod-1b315223-f491-420d-8bb8-ae3880a6f513" satisfied condition "success or failure"
Feb 17 17:35:13.255: INFO: Trying to get logs from node 10.242.0.98 pod pod-1b315223-f491-420d-8bb8-ae3880a6f513 container test-container: <nil>
STEP: delete the pod
Feb 17 17:35:13.343: INFO: Waiting for pod pod-1b315223-f491-420d-8bb8-ae3880a6f513 to disappear
Feb 17 17:35:13.354: INFO: Pod pod-1b315223-f491-420d-8bb8-ae3880a6f513 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 17:35:13.354: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2673" for this suite.
Feb 17 17:35:19.428: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:35:19.830: INFO: namespace emptydir-2673 deletion completed in 6.458144491s

• [SLOW TEST:9.060 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 17:35:19.832: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9011
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Feb 17 17:35:20.117: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b1254077-e201-4398-8138-525595d16478" in namespace "projected-9011" to be "success or failure"
Feb 17 17:35:20.130: INFO: Pod "downwardapi-volume-b1254077-e201-4398-8138-525595d16478": Phase="Pending", Reason="", readiness=false. Elapsed: 12.28111ms
Feb 17 17:35:22.140: INFO: Pod "downwardapi-volume-b1254077-e201-4398-8138-525595d16478": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.022827595s
STEP: Saw pod success
Feb 17 17:35:22.140: INFO: Pod "downwardapi-volume-b1254077-e201-4398-8138-525595d16478" satisfied condition "success or failure"
Feb 17 17:35:22.157: INFO: Trying to get logs from node 10.242.0.59 pod downwardapi-volume-b1254077-e201-4398-8138-525595d16478 container client-container: <nil>
STEP: delete the pod
Feb 17 17:35:22.226: INFO: Waiting for pod downwardapi-volume-b1254077-e201-4398-8138-525595d16478 to disappear
Feb 17 17:35:22.236: INFO: Pod downwardapi-volume-b1254077-e201-4398-8138-525595d16478 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 17:35:22.236: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9011" for this suite.
Feb 17 17:35:28.305: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:35:28.722: INFO: namespace projected-9011 deletion completed in 6.466932227s

• [SLOW TEST:8.891 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 17:35:28.723: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-6987
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
Feb 17 17:35:29.001: INFO: observed the pod list
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
Feb 17 17:35:36.137: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 17:35:36.148: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-6987" for this suite.
Feb 17 17:35:44.215: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:35:44.606: INFO: namespace pods-6987 deletion completed in 8.439522489s

• [SLOW TEST:15.882 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 17:35:44.607: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8154
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with configMap that has name projected-configmap-test-upd-4d143497-4bc8-4ae7-927a-fa16f674ce5f
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-4d143497-4bc8-4ae7-927a-fa16f674ce5f
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 17:35:49.065: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8154" for this suite.
Feb 17 17:36:13.136: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:36:13.577: INFO: namespace projected-8154 deletion completed in 24.492075851s

• [SLOW TEST:28.969 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 17:36:13.577: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1836
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Feb 17 17:36:13.867: INFO: Waiting up to 5m0s for pod "downwardapi-volume-939ca9b1-4e1d-4657-aa88-489dce4a1e06" in namespace "projected-1836" to be "success or failure"
Feb 17 17:36:13.878: INFO: Pod "downwardapi-volume-939ca9b1-4e1d-4657-aa88-489dce4a1e06": Phase="Pending", Reason="", readiness=false. Elapsed: 10.687197ms
Feb 17 17:36:15.900: INFO: Pod "downwardapi-volume-939ca9b1-4e1d-4657-aa88-489dce4a1e06": Phase="Pending", Reason="", readiness=false. Elapsed: 2.03269957s
Feb 17 17:36:17.912: INFO: Pod "downwardapi-volume-939ca9b1-4e1d-4657-aa88-489dce4a1e06": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.04513085s
STEP: Saw pod success
Feb 17 17:36:17.912: INFO: Pod "downwardapi-volume-939ca9b1-4e1d-4657-aa88-489dce4a1e06" satisfied condition "success or failure"
Feb 17 17:36:17.924: INFO: Trying to get logs from node 10.242.0.98 pod downwardapi-volume-939ca9b1-4e1d-4657-aa88-489dce4a1e06 container client-container: <nil>
STEP: delete the pod
Feb 17 17:36:17.996: INFO: Waiting for pod downwardapi-volume-939ca9b1-4e1d-4657-aa88-489dce4a1e06 to disappear
Feb 17 17:36:18.007: INFO: Pod downwardapi-volume-939ca9b1-4e1d-4657-aa88-489dce4a1e06 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 17:36:18.008: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1836" for this suite.
Feb 17 17:36:24.086: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:36:24.482: INFO: namespace projected-1836 deletion completed in 6.453700541s

• [SLOW TEST:10.905 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 17:36:24.483: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-3541
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Feb 17 17:36:24.850: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:watch-3541,SelfLink:/api/v1/namespaces/watch-3541/configmaps/e2e-watch-test-resource-version,UID:2989b700-3c21-4342-812e-26ead998bbf0,ResourceVersion:39651,Generation:0,CreationTimestamp:2020-02-17 17:36:24 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Feb 17 17:36:24.850: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:watch-3541,SelfLink:/api/v1/namespaces/watch-3541/configmaps/e2e-watch-test-resource-version,UID:2989b700-3c21-4342-812e-26ead998bbf0,ResourceVersion:39652,Generation:0,CreationTimestamp:2020-02-17 17:36:24 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 17:36:24.850: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-3541" for this suite.
Feb 17 17:36:30.917: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:36:31.336: INFO: namespace watch-3541 deletion completed in 6.468400838s

• [SLOW TEST:6.854 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 17:36:31.338: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-2838
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Feb 17 17:36:31.601: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 17:36:33.884: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-2838" for this suite.
Feb 17 17:37:21.957: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:37:22.370: INFO: namespace pods-2838 deletion completed in 48.465337948s

• [SLOW TEST:51.032 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 17:37:22.371: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-3230
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:63
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Feb 17 17:37:28.793: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb 17 17:37:28.804: INFO: Pod pod-with-poststart-http-hook still exists
Feb 17 17:37:30.804: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb 17 17:37:30.817: INFO: Pod pod-with-poststart-http-hook still exists
Feb 17 17:37:32.804: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb 17 17:37:32.816: INFO: Pod pod-with-poststart-http-hook still exists
Feb 17 17:37:34.805: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb 17 17:37:34.817: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 17:37:34.817: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-3230" for this suite.
Feb 17 17:37:58.883: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:37:59.284: INFO: namespace container-lifecycle-hook-3230 deletion completed in 24.448922012s

• [SLOW TEST:36.913 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when create a pod with lifecycle hook
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 17:37:59.284: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-4163
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-deea097e-de82-4acf-9d90-90a1111c7a70
STEP: Creating a pod to test consume secrets
Feb 17 17:37:59.576: INFO: Waiting up to 5m0s for pod "pod-secrets-36b1292c-dece-4b14-beac-c33d33babc97" in namespace "secrets-4163" to be "success or failure"
Feb 17 17:37:59.589: INFO: Pod "pod-secrets-36b1292c-dece-4b14-beac-c33d33babc97": Phase="Pending", Reason="", readiness=false. Elapsed: 12.626367ms
Feb 17 17:38:01.601: INFO: Pod "pod-secrets-36b1292c-dece-4b14-beac-c33d33babc97": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.024322577s
STEP: Saw pod success
Feb 17 17:38:01.601: INFO: Pod "pod-secrets-36b1292c-dece-4b14-beac-c33d33babc97" satisfied condition "success or failure"
Feb 17 17:38:01.613: INFO: Trying to get logs from node 10.242.0.98 pod pod-secrets-36b1292c-dece-4b14-beac-c33d33babc97 container secret-volume-test: <nil>
STEP: delete the pod
Feb 17 17:38:01.679: INFO: Waiting for pod pod-secrets-36b1292c-dece-4b14-beac-c33d33babc97 to disappear
Feb 17 17:38:01.691: INFO: Pod pod-secrets-36b1292c-dece-4b14-beac-c33d33babc97 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 17:38:01.691: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-4163" for this suite.
Feb 17 17:38:07.761: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:38:08.160: INFO: namespace secrets-4163 deletion completed in 6.450349396s

• [SLOW TEST:8.876 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 17:38:08.160: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-5840
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-5840
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace statefulset-5840
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-5840
Feb 17 17:38:08.463: INFO: Found 0 stateful pods, waiting for 1
Feb 17 17:38:18.475: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Feb 17 17:38:18.486: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-079603707 exec --namespace=statefulset-5840 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 17 17:38:18.915: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Feb 17 17:38:18.915: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 17 17:38:18.915: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 17 17:38:18.927: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Feb 17 17:38:28.940: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Feb 17 17:38:28.940: INFO: Waiting for statefulset status.replicas updated to 0
Feb 17 17:38:28.991: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999998062s
Feb 17 17:38:30.003: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.988785069s
Feb 17 17:38:31.015: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.976790525s
Feb 17 17:38:32.026: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.96547305s
Feb 17 17:38:33.053: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.954585641s
Feb 17 17:38:34.065: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.927020609s
Feb 17 17:38:35.077: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.914843294s
Feb 17 17:38:36.090: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.903211077s
Feb 17 17:38:37.101: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.890656997s
Feb 17 17:38:38.113: INFO: Verifying statefulset ss doesn't scale past 1 for another 879.714651ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-5840
Feb 17 17:38:39.126: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-079603707 exec --namespace=statefulset-5840 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 17 17:38:39.604: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Feb 17 17:38:39.604: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb 17 17:38:39.604: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb 17 17:38:39.615: INFO: Found 1 stateful pods, waiting for 3
Feb 17 17:38:49.627: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Feb 17 17:38:49.627: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Feb 17 17:38:49.627: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Feb 17 17:38:49.646: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-079603707 exec --namespace=statefulset-5840 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 17 17:38:50.092: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Feb 17 17:38:50.092: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 17 17:38:50.092: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 17 17:38:50.092: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-079603707 exec --namespace=statefulset-5840 ss-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 17 17:38:50.526: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Feb 17 17:38:50.526: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 17 17:38:50.526: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 17 17:38:50.526: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-079603707 exec --namespace=statefulset-5840 ss-2 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 17 17:38:51.013: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Feb 17 17:38:51.013: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 17 17:38:51.013: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 17 17:38:51.013: INFO: Waiting for statefulset status.replicas updated to 0
Feb 17 17:38:51.026: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 1
Feb 17 17:39:01.052: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Feb 17 17:39:01.052: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Feb 17 17:39:01.052: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Feb 17 17:39:01.093: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999998224s
Feb 17 17:39:02.106: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.986870878s
Feb 17 17:39:03.120: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.973953152s
Feb 17 17:39:04.133: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.960502437s
Feb 17 17:39:05.144: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.947723263s
Feb 17 17:39:06.157: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.936229869s
Feb 17 17:39:07.169: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.923302369s
Feb 17 17:39:08.182: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.911307238s
Feb 17 17:39:09.200: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.893179048s
Feb 17 17:39:10.212: INFO: Verifying statefulset ss doesn't scale past 3 for another 880.369246ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-5840
Feb 17 17:39:11.225: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-079603707 exec --namespace=statefulset-5840 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 17 17:39:11.656: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Feb 17 17:39:11.656: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb 17 17:39:11.656: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb 17 17:39:11.656: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-079603707 exec --namespace=statefulset-5840 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 17 17:39:12.098: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Feb 17 17:39:12.098: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb 17 17:39:12.098: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb 17 17:39:12.098: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-079603707 exec --namespace=statefulset-5840 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 17 17:39:12.519: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Feb 17 17:39:12.519: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb 17 17:39:12.519: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb 17 17:39:12.519: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Feb 17 17:39:42.601: INFO: Deleting all statefulset in ns statefulset-5840
Feb 17 17:39:42.614: INFO: Scaling statefulset ss to 0
Feb 17 17:39:42.655: INFO: Waiting for statefulset status.replicas updated to 0
Feb 17 17:39:42.668: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 17:39:42.736: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-5840" for this suite.
Feb 17 17:39:51.003: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:39:51.419: INFO: namespace statefulset-5840 deletion completed in 8.664368695s

• [SLOW TEST:103.259 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 17:39:51.419: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-3887
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:63
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Feb 17 17:39:57.850: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 17 17:39:57.862: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 17 17:39:59.863: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 17 17:39:59.875: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 17 17:40:01.863: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 17 17:40:01.876: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 17 17:40:03.863: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 17 17:40:03.875: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 17 17:40:05.863: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 17 17:40:05.874: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 17 17:40:07.863: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 17 17:40:07.874: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 17 17:40:09.863: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 17 17:40:09.875: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 17 17:40:11.863: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 17 17:40:11.874: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 17 17:40:13.863: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 17 17:40:13.874: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 17 17:40:15.863: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 17 17:40:15.874: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 17:40:15.874: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-3887" for this suite.
Feb 17 17:40:39.945: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:40:40.346: INFO: namespace container-lifecycle-hook-3887 deletion completed in 24.453358517s

• [SLOW TEST:48.928 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when create a pod with lifecycle hook
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 17:40:40.350: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-8552
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-8552.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-8552.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-8552.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-8552.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-8552.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-8552.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe /etc/hosts
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Feb 17 17:40:44.855: INFO: DNS probes using dns-8552/dns-test-37a8ccb9-2bf2-4764-b7df-28268bc28b2a succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 17:40:44.890: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-8552" for this suite.
Feb 17 17:40:52.959: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:40:53.377: INFO: namespace dns-8552 deletion completed in 8.468550756s

• [SLOW TEST:13.028 seconds]
[sig-network] DNS
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 17:40:53.378: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-1859
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1292
STEP: creating an rc
Feb 17 17:40:53.634: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-079603707 create -f - --namespace=kubectl-1859'
Feb 17 17:40:54.007: INFO: stderr: ""
Feb 17 17:40:54.007: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Waiting for Redis master to start.
Feb 17 17:40:55.018: INFO: Selector matched 1 pods for map[app:redis]
Feb 17 17:40:55.018: INFO: Found 0 / 1
Feb 17 17:40:56.019: INFO: Selector matched 1 pods for map[app:redis]
Feb 17 17:40:56.019: INFO: Found 1 / 1
Feb 17 17:40:56.019: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Feb 17 17:40:56.030: INFO: Selector matched 1 pods for map[app:redis]
Feb 17 17:40:56.030: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
STEP: checking for a matching strings
Feb 17 17:40:56.030: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-079603707 logs redis-master-mpvqp redis-master --namespace=kubectl-1859'
Feb 17 17:40:56.198: INFO: stderr: ""
Feb 17 17:40:56.198: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 17 Feb 17:40:55.342 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 17 Feb 17:40:55.342 # Server started, Redis version 3.2.12\n1:M 17 Feb 17:40:55.342 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 17 Feb 17:40:55.342 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log lines
Feb 17 17:40:56.199: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-079603707 logs redis-master-mpvqp redis-master --namespace=kubectl-1859 --tail=1'
Feb 17 17:40:56.350: INFO: stderr: ""
Feb 17 17:40:56.350: INFO: stdout: "1:M 17 Feb 17:40:55.342 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log bytes
Feb 17 17:40:56.350: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-079603707 logs redis-master-mpvqp redis-master --namespace=kubectl-1859 --limit-bytes=1'
Feb 17 17:40:56.522: INFO: stderr: ""
Feb 17 17:40:56.522: INFO: stdout: " "
STEP: exposing timestamps
Feb 17 17:40:56.522: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-079603707 logs redis-master-mpvqp redis-master --namespace=kubectl-1859 --tail=1 --timestamps'
Feb 17 17:40:56.702: INFO: stderr: ""
Feb 17 17:40:56.702: INFO: stdout: "2020-02-17T17:40:55.34316322Z 1:M 17 Feb 17:40:55.342 * The server is now ready to accept connections on port 6379\n"
STEP: restricting to a time range
Feb 17 17:40:59.202: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-079603707 logs redis-master-mpvqp redis-master --namespace=kubectl-1859 --since=1s'
Feb 17 17:40:59.362: INFO: stderr: ""
Feb 17 17:40:59.362: INFO: stdout: ""
Feb 17 17:40:59.362: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-079603707 logs redis-master-mpvqp redis-master --namespace=kubectl-1859 --since=24h'
Feb 17 17:40:59.663: INFO: stderr: ""
Feb 17 17:40:59.663: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 17 Feb 17:40:55.342 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 17 Feb 17:40:55.342 # Server started, Redis version 3.2.12\n1:M 17 Feb 17:40:55.342 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 17 Feb 17:40:55.342 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1298
STEP: using delete to clean up resources
Feb 17 17:40:59.664: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-079603707 delete --grace-period=0 --force -f - --namespace=kubectl-1859'
Feb 17 17:40:59.817: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 17 17:40:59.817: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
Feb 17 17:40:59.817: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-079603707 get rc,svc -l name=nginx --no-headers --namespace=kubectl-1859'
Feb 17 17:40:59.961: INFO: stderr: "No resources found.\n"
Feb 17 17:40:59.961: INFO: stdout: ""
Feb 17 17:40:59.961: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-079603707 get pods -l name=nginx --namespace=kubectl-1859 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Feb 17 17:41:00.118: INFO: stderr: ""
Feb 17 17:41:00.118: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 17:41:00.118: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1859" for this suite.
Feb 17 17:41:24.199: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:41:24.597: INFO: namespace kubectl-1859 deletion completed in 24.455857352s

• [SLOW TEST:31.219 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl logs
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 17:41:24.598: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-84
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-f075bb8f-c685-4f49-b609-36a770c835c0
STEP: Creating a pod to test consume configMaps
Feb 17 17:41:24.884: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-28eeada3-3d29-492e-b443-1a522f22c039" in namespace "projected-84" to be "success or failure"
Feb 17 17:41:24.895: INFO: Pod "pod-projected-configmaps-28eeada3-3d29-492e-b443-1a522f22c039": Phase="Pending", Reason="", readiness=false. Elapsed: 11.019863ms
Feb 17 17:41:26.907: INFO: Pod "pod-projected-configmaps-28eeada3-3d29-492e-b443-1a522f22c039": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02299474s
Feb 17 17:41:28.919: INFO: Pod "pod-projected-configmaps-28eeada3-3d29-492e-b443-1a522f22c039": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.034724231s
STEP: Saw pod success
Feb 17 17:41:28.919: INFO: Pod "pod-projected-configmaps-28eeada3-3d29-492e-b443-1a522f22c039" satisfied condition "success or failure"
Feb 17 17:41:28.930: INFO: Trying to get logs from node 10.242.0.59 pod pod-projected-configmaps-28eeada3-3d29-492e-b443-1a522f22c039 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 17 17:41:29.004: INFO: Waiting for pod pod-projected-configmaps-28eeada3-3d29-492e-b443-1a522f22c039 to disappear
Feb 17 17:41:29.015: INFO: Pod pod-projected-configmaps-28eeada3-3d29-492e-b443-1a522f22c039 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 17:41:29.015: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-84" for this suite.
Feb 17 17:41:35.085: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:41:35.490: INFO: namespace projected-84 deletion completed in 6.456590022s

• [SLOW TEST:10.893 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 17:41:35.491: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-367
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-projected-5jbq
STEP: Creating a pod to test atomic-volume-subpath
Feb 17 17:41:35.840: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-5jbq" in namespace "subpath-367" to be "success or failure"
Feb 17 17:41:35.851: INFO: Pod "pod-subpath-test-projected-5jbq": Phase="Pending", Reason="", readiness=false. Elapsed: 10.585132ms
Feb 17 17:41:37.863: INFO: Pod "pod-subpath-test-projected-5jbq": Phase="Running", Reason="", readiness=true. Elapsed: 2.022749032s
Feb 17 17:41:39.875: INFO: Pod "pod-subpath-test-projected-5jbq": Phase="Running", Reason="", readiness=true. Elapsed: 4.035365278s
Feb 17 17:41:41.888: INFO: Pod "pod-subpath-test-projected-5jbq": Phase="Running", Reason="", readiness=true. Elapsed: 6.048160659s
Feb 17 17:41:43.900: INFO: Pod "pod-subpath-test-projected-5jbq": Phase="Running", Reason="", readiness=true. Elapsed: 8.059605249s
Feb 17 17:41:45.913: INFO: Pod "pod-subpath-test-projected-5jbq": Phase="Running", Reason="", readiness=true. Elapsed: 10.07276665s
Feb 17 17:41:47.925: INFO: Pod "pod-subpath-test-projected-5jbq": Phase="Running", Reason="", readiness=true. Elapsed: 12.084566672s
Feb 17 17:41:49.937: INFO: Pod "pod-subpath-test-projected-5jbq": Phase="Running", Reason="", readiness=true. Elapsed: 14.096733159s
Feb 17 17:41:51.948: INFO: Pod "pod-subpath-test-projected-5jbq": Phase="Running", Reason="", readiness=true. Elapsed: 16.107787514s
Feb 17 17:41:53.959: INFO: Pod "pod-subpath-test-projected-5jbq": Phase="Running", Reason="", readiness=true. Elapsed: 18.119494221s
Feb 17 17:41:55.971: INFO: Pod "pod-subpath-test-projected-5jbq": Phase="Running", Reason="", readiness=true. Elapsed: 20.13124837s
Feb 17 17:41:57.983: INFO: Pod "pod-subpath-test-projected-5jbq": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.142951396s
STEP: Saw pod success
Feb 17 17:41:57.983: INFO: Pod "pod-subpath-test-projected-5jbq" satisfied condition "success or failure"
Feb 17 17:41:57.993: INFO: Trying to get logs from node 10.242.0.59 pod pod-subpath-test-projected-5jbq container test-container-subpath-projected-5jbq: <nil>
STEP: delete the pod
Feb 17 17:41:58.065: INFO: Waiting for pod pod-subpath-test-projected-5jbq to disappear
Feb 17 17:41:58.077: INFO: Pod pod-subpath-test-projected-5jbq no longer exists
STEP: Deleting pod pod-subpath-test-projected-5jbq
Feb 17 17:41:58.077: INFO: Deleting pod "pod-subpath-test-projected-5jbq" in namespace "subpath-367"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 17:41:58.089: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-367" for this suite.
Feb 17 17:42:04.155: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:42:04.543: INFO: namespace subpath-367 deletion completed in 6.436860259s

• [SLOW TEST:29.052 seconds]
[sig-storage] Subpath
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with projected pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Aggregator 
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 17:42:04.544: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename aggregator
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in aggregator-3329
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:76
Feb 17 17:42:04.805: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
[It] Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Registering the sample API server.
Feb 17 17:42:05.155: INFO: deployment "sample-apiserver-deployment" doesn't have the required revision set
Feb 17 17:42:07.282: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717558125, loc:(*time.Location)(0x7ed4a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717558125, loc:(*time.Location)(0x7ed4a20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717558125, loc:(*time.Location)(0x7ed4a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717558125, loc:(*time.Location)(0x7ed4a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 17 17:42:09.295: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717558125, loc:(*time.Location)(0x7ed4a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717558125, loc:(*time.Location)(0x7ed4a20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717558125, loc:(*time.Location)(0x7ed4a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717558125, loc:(*time.Location)(0x7ed4a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 17 17:42:11.297: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717558125, loc:(*time.Location)(0x7ed4a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717558125, loc:(*time.Location)(0x7ed4a20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717558125, loc:(*time.Location)(0x7ed4a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717558125, loc:(*time.Location)(0x7ed4a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 17 17:42:13.295: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717558125, loc:(*time.Location)(0x7ed4a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717558125, loc:(*time.Location)(0x7ed4a20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717558125, loc:(*time.Location)(0x7ed4a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717558125, loc:(*time.Location)(0x7ed4a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 17 17:42:15.296: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717558125, loc:(*time.Location)(0x7ed4a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717558125, loc:(*time.Location)(0x7ed4a20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717558125, loc:(*time.Location)(0x7ed4a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717558125, loc:(*time.Location)(0x7ed4a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 17 17:42:17.295: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717558125, loc:(*time.Location)(0x7ed4a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717558125, loc:(*time.Location)(0x7ed4a20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717558125, loc:(*time.Location)(0x7ed4a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717558125, loc:(*time.Location)(0x7ed4a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 17 17:42:19.295: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717558125, loc:(*time.Location)(0x7ed4a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717558125, loc:(*time.Location)(0x7ed4a20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717558125, loc:(*time.Location)(0x7ed4a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717558125, loc:(*time.Location)(0x7ed4a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 17 17:42:22.523: INFO: Waited 1.202625628s for the sample-apiserver to be ready to handle requests.
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:67
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 17:42:23.377: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "aggregator-3329" for this suite.
Feb 17 17:42:29.446: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:42:29.836: INFO: namespace aggregator-3329 deletion completed in 6.439140589s

• [SLOW TEST:25.292 seconds]
[sig-api-machinery] Aggregator
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 17:42:29.836: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-7431
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
Feb 17 17:42:30.766: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W0217 17:42:30.766351      16 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 17:42:30.766: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-7431" for this suite.
Feb 17 17:42:36.832: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:42:37.249: INFO: namespace gc-7431 deletion completed in 6.46630844s

• [SLOW TEST:7.413 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 17:42:37.249: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-5336
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Feb 17 17:42:40.101: INFO: Successfully updated pod "pod-update-activedeadlineseconds-e2d8d650-854c-4fe5-8cf4-3f5b625fb841"
Feb 17 17:42:40.101: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-e2d8d650-854c-4fe5-8cf4-3f5b625fb841" in namespace "pods-5336" to be "terminated due to deadline exceeded"
Feb 17 17:42:40.111: INFO: Pod "pod-update-activedeadlineseconds-e2d8d650-854c-4fe5-8cf4-3f5b625fb841": Phase="Running", Reason="", readiness=true. Elapsed: 10.492759ms
Feb 17 17:42:42.127: INFO: Pod "pod-update-activedeadlineseconds-e2d8d650-854c-4fe5-8cf4-3f5b625fb841": Phase="Running", Reason="", readiness=true. Elapsed: 2.026214612s
Feb 17 17:42:44.139: INFO: Pod "pod-update-activedeadlineseconds-e2d8d650-854c-4fe5-8cf4-3f5b625fb841": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 4.038202384s
Feb 17 17:42:44.139: INFO: Pod "pod-update-activedeadlineseconds-e2d8d650-854c-4fe5-8cf4-3f5b625fb841" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 17:42:44.139: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-5336" for this suite.
Feb 17 17:42:50.212: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:42:50.594: INFO: namespace pods-5336 deletion completed in 6.435592479s

• [SLOW TEST:13.344 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-apps] Job 
  should delete a job [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 17:42:50.594: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename job
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in job-2705
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete a job [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: delete a job
STEP: deleting Job.batch foo in namespace job-2705, will wait for the garbage collector to delete the pods
Feb 17 17:42:52.982: INFO: Deleting Job.batch foo took: 31.973257ms
Feb 17 17:42:53.182: INFO: Terminating Job.batch foo pods took: 200.297566ms
STEP: Ensuring job was deleted
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 17:43:33.095: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-2705" for this suite.
Feb 17 17:43:39.176: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:43:39.670: INFO: namespace job-2705 deletion completed in 6.54909358s

• [SLOW TEST:49.076 seconds]
[sig-apps] Job
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should delete a job [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 17:43:39.672: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-3999
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating the pod
Feb 17 17:43:42.565: INFO: Successfully updated pod "labelsupdate22db70f6-f401-4372-acf7-dcde74947257"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 17:43:44.632: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3999" for this suite.
Feb 17 17:44:08.706: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:44:09.106: INFO: namespace downward-api-3999 deletion completed in 24.456168282s

• [SLOW TEST:29.435 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 17:44:09.107: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-5432
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Feb 17 17:44:09.389: INFO: Pod name rollover-pod: Found 0 pods out of 1
Feb 17 17:44:14.401: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Feb 17 17:44:14.401: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Feb 17 17:44:16.412: INFO: Creating deployment "test-rollover-deployment"
Feb 17 17:44:16.444: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Feb 17 17:44:18.471: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Feb 17 17:44:18.500: INFO: Ensure that both replica sets have 1 created replica
Feb 17 17:44:18.521: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Feb 17 17:44:18.552: INFO: Updating deployment test-rollover-deployment
Feb 17 17:44:18.552: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Feb 17 17:44:20.582: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Feb 17 17:44:20.605: INFO: Make sure deployment "test-rollover-deployment" is complete
Feb 17 17:44:20.631: INFO: all replica sets need to contain the pod-template-hash label
Feb 17 17:44:20.631: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717558256, loc:(*time.Location)(0x7ed4a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717558256, loc:(*time.Location)(0x7ed4a20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717558260, loc:(*time.Location)(0x7ed4a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717558256, loc:(*time.Location)(0x7ed4a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 17 17:44:22.656: INFO: all replica sets need to contain the pod-template-hash label
Feb 17 17:44:22.656: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717558256, loc:(*time.Location)(0x7ed4a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717558256, loc:(*time.Location)(0x7ed4a20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717558260, loc:(*time.Location)(0x7ed4a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717558256, loc:(*time.Location)(0x7ed4a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 17 17:44:24.655: INFO: all replica sets need to contain the pod-template-hash label
Feb 17 17:44:24.655: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717558256, loc:(*time.Location)(0x7ed4a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717558256, loc:(*time.Location)(0x7ed4a20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717558260, loc:(*time.Location)(0x7ed4a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717558256, loc:(*time.Location)(0x7ed4a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 17 17:44:26.656: INFO: all replica sets need to contain the pod-template-hash label
Feb 17 17:44:26.656: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717558256, loc:(*time.Location)(0x7ed4a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717558256, loc:(*time.Location)(0x7ed4a20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717558260, loc:(*time.Location)(0x7ed4a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717558256, loc:(*time.Location)(0x7ed4a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 17 17:44:28.658: INFO: all replica sets need to contain the pod-template-hash label
Feb 17 17:44:28.658: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717558256, loc:(*time.Location)(0x7ed4a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717558256, loc:(*time.Location)(0x7ed4a20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717558260, loc:(*time.Location)(0x7ed4a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717558256, loc:(*time.Location)(0x7ed4a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 17 17:44:30.658: INFO: 
Feb 17 17:44:30.658: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:2, UnavailableReplicas:0, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717558256, loc:(*time.Location)(0x7ed4a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717558256, loc:(*time.Location)(0x7ed4a20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717558270, loc:(*time.Location)(0x7ed4a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717558256, loc:(*time.Location)(0x7ed4a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 17 17:44:32.655: INFO: 
Feb 17 17:44:32.656: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
Feb 17 17:44:32.691: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment,GenerateName:,Namespace:deployment-5432,SelfLink:/apis/apps/v1/namespaces/deployment-5432/deployments/test-rollover-deployment,UID:d62d1982-1e0e-435b-b37e-04e28be65be3,ResourceVersion:41426,Generation:2,CreationTimestamp:2020-02-17 17:44:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2020-02-17 17:44:16 +0000 UTC 2020-02-17 17:44:16 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2020-02-17 17:44:30 +0000 UTC 2020-02-17 17:44:16 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rollover-deployment-854595fc44" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Feb 17 17:44:32.701: INFO: New ReplicaSet "test-rollover-deployment-854595fc44" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-854595fc44,GenerateName:,Namespace:deployment-5432,SelfLink:/apis/apps/v1/namespaces/deployment-5432/replicasets/test-rollover-deployment-854595fc44,UID:78b1dbe2-4bbd-40ce-9fee-5c0871a33663,ResourceVersion:41416,Generation:2,CreationTimestamp:2020-02-17 17:44:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 854595fc44,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment d62d1982-1e0e-435b-b37e-04e28be65be3 0xc003ee83d7 0xc003ee83d8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 854595fc44,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 854595fc44,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Feb 17 17:44:32.701: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Feb 17 17:44:32.702: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-controller,GenerateName:,Namespace:deployment-5432,SelfLink:/apis/apps/v1/namespaces/deployment-5432/replicasets/test-rollover-controller,UID:c692c182-5a1e-4b7f-8a20-23c1b3f9697a,ResourceVersion:41425,Generation:2,CreationTimestamp:2020-02-17 17:44:09 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment d62d1982-1e0e-435b-b37e-04e28be65be3 0xc003ee8217 0xc003ee8218}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Feb 17 17:44:32.702: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-9b8b997cf,GenerateName:,Namespace:deployment-5432,SelfLink:/apis/apps/v1/namespaces/deployment-5432/replicasets/test-rollover-deployment-9b8b997cf,UID:b6f33df5-1443-4ea1-b718-63f7a010b2e2,ResourceVersion:41380,Generation:2,CreationTimestamp:2020-02-17 17:44:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 9b8b997cf,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment d62d1982-1e0e-435b-b37e-04e28be65be3 0xc003ee85c0 0xc003ee85c1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 9b8b997cf,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 9b8b997cf,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Feb 17 17:44:32.713: INFO: Pod "test-rollover-deployment-854595fc44-9kjp6" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-854595fc44-9kjp6,GenerateName:test-rollover-deployment-854595fc44-,Namespace:deployment-5432,SelfLink:/api/v1/namespaces/deployment-5432/pods/test-rollover-deployment-854595fc44-9kjp6,UID:a863a02a-56c4-4413-bf1e-c6d1d00a9f10,ResourceVersion:41396,Generation:0,CreationTimestamp:2020-02-17 17:44:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 854595fc44,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-rollover-deployment-854595fc44 78b1dbe2-4bbd-40ce-9fee-5c0871a33663 0xc0024c77c7 0xc0024c77c8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-dfwhq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-dfwhq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-dfwhq true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.242.0.59,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0024c7840} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0024c7860}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-17 17:44:18 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2020-02-17 17:44:20 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2020-02-17 17:44:20 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-17 17:44:18 +0000 UTC  }],Message:,Reason:,HostIP:10.242.0.59,PodIP:172.30.94.55,StartTime:2020-02-17 17:44:18 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2020-02-17 17:44:19 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 containerd://ecffd6fe2744f132d031726d5b8f5fa33080193421e38a5339f265e119c08f11}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 17:44:32.713: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-5432" for this suite.
Feb 17 17:44:40.784: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:44:41.174: INFO: namespace deployment-5432 deletion completed in 8.441915302s

• [SLOW TEST:32.067 seconds]
[sig-apps] Deployment
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support rollover [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 17:44:41.174: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-6865
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating Redis RC
Feb 17 17:44:41.451: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-079603707 create -f - --namespace=kubectl-6865'
Feb 17 17:44:41.985: INFO: stderr: ""
Feb 17 17:44:41.985: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Feb 17 17:44:42.997: INFO: Selector matched 1 pods for map[app:redis]
Feb 17 17:44:42.997: INFO: Found 0 / 1
Feb 17 17:44:43.997: INFO: Selector matched 1 pods for map[app:redis]
Feb 17 17:44:43.997: INFO: Found 1 / 1
Feb 17 17:44:43.997: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Feb 17 17:44:44.009: INFO: Selector matched 1 pods for map[app:redis]
Feb 17 17:44:44.009: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Feb 17 17:44:44.009: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-079603707 patch pod redis-master-5j4f6 --namespace=kubectl-6865 -p {"metadata":{"annotations":{"x":"y"}}}'
Feb 17 17:44:44.141: INFO: stderr: ""
Feb 17 17:44:44.141: INFO: stdout: "pod/redis-master-5j4f6 patched\n"
STEP: checking annotations
Feb 17 17:44:44.154: INFO: Selector matched 1 pods for map[app:redis]
Feb 17 17:44:44.154: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 17:44:44.154: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6865" for this suite.
Feb 17 17:45:08.220: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:45:08.618: INFO: namespace kubectl-6865 deletion completed in 24.446114528s

• [SLOW TEST:27.444 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl patch
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 17:45:08.620: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-94
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Feb 17 17:45:10.953: INFO: Expected: &{OK} to match Container's Termination Message: OK --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 17:45:11.003: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-94" for this suite.
Feb 17 17:45:17.082: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:45:17.494: INFO: namespace container-runtime-94 deletion completed in 6.469411769s

• [SLOW TEST:8.874 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  blackbox test
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
    on terminated container
    /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:129
      should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 17:45:17.494: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-8004
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:81
Feb 17 17:45:17.749: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Feb 17 17:45:17.784: INFO: Waiting for terminating namespaces to be deleted...
Feb 17 17:45:17.892: INFO: 
Logging pods the kubelet thinks is on node 10.242.0.59 before test
Feb 17 17:45:17.984: INFO: coredns-c6797c986-cc2j9 from kube-system started at 2020-02-17 14:55:56 +0000 UTC (1 container statuses recorded)
Feb 17 17:45:17.984: INFO: 	Container coredns ready: true, restart count 0
Feb 17 17:45:17.984: INFO: sonobuoy-systemd-logs-daemon-set-6f65da6b108e4900-wmp7s from sonobuoy started at 2020-02-17 16:14:12 +0000 UTC (2 container statuses recorded)
Feb 17 17:45:17.984: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Feb 17 17:45:17.984: INFO: 	Container systemd-logs ready: true, restart count 0
Feb 17 17:45:17.984: INFO: public-crbp5a1mjl0i8s7ceo0p0g-alb1-9c9db77cc-652w8 from kube-system started at 2020-02-17 14:46:17 +0000 UTC (4 container statuses recorded)
Feb 17 17:45:17.984: INFO: 	Container ingress-auth-1 ready: true, restart count 0
Feb 17 17:45:17.984: INFO: 	Container ingress-auth-2 ready: true, restart count 1
Feb 17 17:45:17.984: INFO: 	Container ingress-auth-3 ready: true, restart count 1
Feb 17 17:45:17.984: INFO: 	Container nginx-ingress ready: true, restart count 0
Feb 17 17:45:17.984: INFO: ibm-vpc-block-csi-node-t57kv from kube-system started at 2020-02-17 14:46:10 +0000 UTC (2 container statuses recorded)
Feb 17 17:45:17.984: INFO: 	Container csi-driver-registrar ready: true, restart count 0
Feb 17 17:45:17.984: INFO: 	Container iks-vpc-block-node-driver ready: true, restart count 0
Feb 17 17:45:17.984: INFO: calico-node-nt7xm from kube-system started at 2020-02-17 14:46:00 +0000 UTC (1 container statuses recorded)
Feb 17 17:45:17.984: INFO: 	Container calico-node ready: true, restart count 0
Feb 17 17:45:17.984: INFO: ibm-master-proxy-static-10.242.0.59 from kube-system started at 2020-02-17 14:44:03 +0000 UTC (2 container statuses recorded)
Feb 17 17:45:17.984: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Feb 17 17:45:17.984: INFO: 	Container pause ready: true, restart count 0
Feb 17 17:45:17.984: INFO: 
Logging pods the kubelet thinks is on node 10.242.0.63 before test
Feb 17 17:45:18.048: INFO: calico-kube-controllers-b449456b9-7xvhd from kube-system started at 2020-02-17 14:46:06 +0000 UTC (1 container statuses recorded)
Feb 17 17:45:18.048: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Feb 17 17:45:18.049: INFO: metrics-server-5dfbdfb747-ttl59 from kube-system started at 2020-02-17 14:46:28 +0000 UTC (2 container statuses recorded)
Feb 17 17:45:18.049: INFO: 	Container metrics-server ready: true, restart count 0
Feb 17 17:45:18.049: INFO: 	Container metrics-server-nanny ready: true, restart count 0
Feb 17 17:45:18.049: INFO: sonobuoy-systemd-logs-daemon-set-6f65da6b108e4900-mvgt7 from sonobuoy started at 2020-02-17 16:14:12 +0000 UTC (2 container statuses recorded)
Feb 17 17:45:18.049: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Feb 17 17:45:18.049: INFO: 	Container systemd-logs ready: true, restart count 0
Feb 17 17:45:18.049: INFO: public-crbp5a1mjl0i8s7ceo0p0g-alb1-9c9db77cc-hb966 from kube-system started at 2020-02-17 14:46:06 +0000 UTC (4 container statuses recorded)
Feb 17 17:45:18.049: INFO: 	Container ingress-auth-1 ready: true, restart count 1
Feb 17 17:45:18.049: INFO: 	Container ingress-auth-2 ready: true, restart count 1
Feb 17 17:45:18.049: INFO: 	Container ingress-auth-3 ready: true, restart count 1
Feb 17 17:45:18.049: INFO: 	Container nginx-ingress ready: true, restart count 0
Feb 17 17:45:18.049: INFO: ibm-vpc-block-csi-controller-0 from kube-system started at 2020-02-17 14:46:06 +0000 UTC (3 container statuses recorded)
Feb 17 17:45:18.049: INFO: 	Container csi-attacher ready: true, restart count 0
Feb 17 17:45:18.049: INFO: 	Container csi-provisioner ready: true, restart count 0
Feb 17 17:45:18.049: INFO: 	Container iks-vpc-block-driver ready: true, restart count 0
Feb 17 17:45:18.049: INFO: ibm-vpc-block-csi-node-44qtk from kube-system started at 2020-02-17 14:45:58 +0000 UTC (2 container statuses recorded)
Feb 17 17:45:18.049: INFO: 	Container csi-driver-registrar ready: true, restart count 0
Feb 17 17:45:18.049: INFO: 	Container iks-vpc-block-node-driver ready: true, restart count 0
Feb 17 17:45:18.049: INFO: coredns-autoscaler-65bc7cb8b5-246qr from kube-system started at 2020-02-17 14:46:06 +0000 UTC (1 container statuses recorded)
Feb 17 17:45:18.049: INFO: 	Container autoscaler ready: true, restart count 0
Feb 17 17:45:18.049: INFO: ibm-master-proxy-static-10.242.0.63 from kube-system started at 2020-02-17 14:43:57 +0000 UTC (2 container statuses recorded)
Feb 17 17:45:18.049: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Feb 17 17:45:18.049: INFO: 	Container pause ready: true, restart count 0
Feb 17 17:45:18.049: INFO: calico-node-2wvjj from kube-system started at 2020-02-17 14:45:48 +0000 UTC (1 container statuses recorded)
Feb 17 17:45:18.049: INFO: 	Container calico-node ready: true, restart count 0
Feb 17 17:45:18.049: INFO: vpn-bd4d5cff7-5tpm4 from kube-system started at 2020-02-17 14:55:34 +0000 UTC (1 container statuses recorded)
Feb 17 17:45:18.049: INFO: 	Container vpn ready: true, restart count 0
Feb 17 17:45:18.049: INFO: kubernetes-dashboard-656d9457bf-2qq9c from kube-system started at 2020-02-17 14:46:06 +0000 UTC (1 container statuses recorded)
Feb 17 17:45:18.049: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Feb 17 17:45:18.049: INFO: 
Logging pods the kubelet thinks is on node 10.242.0.98 before test
Feb 17 17:45:18.120: INFO: calico-node-ch65n from kube-system started at 2020-02-17 14:46:20 +0000 UTC (1 container statuses recorded)
Feb 17 17:45:18.120: INFO: 	Container calico-node ready: true, restart count 0
Feb 17 17:45:18.120: INFO: test-k8s-e2e-pvg-master-verification from default started at 2020-02-17 14:50:10 +0000 UTC (1 container statuses recorded)
Feb 17 17:45:18.120: INFO: 	Container test-k8s-e2e-pvg-master-verification ready: true, restart count 0
Feb 17 17:45:18.120: INFO: ibm-vpc-block-csi-node-lnnpn from kube-system started at 2020-02-17 14:46:30 +0000 UTC (2 container statuses recorded)
Feb 17 17:45:18.120: INFO: 	Container csi-driver-registrar ready: true, restart count 0
Feb 17 17:45:18.120: INFO: 	Container iks-vpc-block-node-driver ready: true, restart count 0
Feb 17 17:45:18.120: INFO: sonobuoy-e2e-job-8b0d4acd71ee4040 from sonobuoy started at 2020-02-17 16:14:12 +0000 UTC (2 container statuses recorded)
Feb 17 17:45:18.120: INFO: 	Container e2e ready: true, restart count 0
Feb 17 17:45:18.120: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb 17 17:45:18.120: INFO: coredns-c6797c986-rsp2r from kube-system started at 2020-02-17 14:55:56 +0000 UTC (1 container statuses recorded)
Feb 17 17:45:18.120: INFO: 	Container coredns ready: true, restart count 0
Feb 17 17:45:18.120: INFO: sonobuoy-systemd-logs-daemon-set-6f65da6b108e4900-fvg5d from sonobuoy started at 2020-02-17 16:14:12 +0000 UTC (2 container statuses recorded)
Feb 17 17:45:18.120: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Feb 17 17:45:18.120: INFO: 	Container systemd-logs ready: true, restart count 0
Feb 17 17:45:18.120: INFO: ibm-master-proxy-static-10.242.0.98 from kube-system started at 2020-02-17 14:44:09 +0000 UTC (2 container statuses recorded)
Feb 17 17:45:18.120: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Feb 17 17:45:18.120: INFO: 	Container pause ready: true, restart count 0
Feb 17 17:45:18.120: INFO: sonobuoy from sonobuoy started at 2020-02-17 16:14:06 +0000 UTC (1 container statuses recorded)
Feb 17 17:45:18.121: INFO: 	Container kube-sonobuoy ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: verifying the node has the label node 10.242.0.59
STEP: verifying the node has the label node 10.242.0.63
STEP: verifying the node has the label node 10.242.0.98
Feb 17 17:45:18.274: INFO: Pod test-k8s-e2e-pvg-master-verification requesting resource cpu=0m on Node 10.242.0.98
Feb 17 17:45:18.275: INFO: Pod calico-kube-controllers-b449456b9-7xvhd requesting resource cpu=10m on Node 10.242.0.63
Feb 17 17:45:18.275: INFO: Pod calico-node-2wvjj requesting resource cpu=250m on Node 10.242.0.63
Feb 17 17:45:18.275: INFO: Pod calico-node-ch65n requesting resource cpu=250m on Node 10.242.0.98
Feb 17 17:45:18.275: INFO: Pod calico-node-nt7xm requesting resource cpu=250m on Node 10.242.0.59
Feb 17 17:45:18.275: INFO: Pod coredns-autoscaler-65bc7cb8b5-246qr requesting resource cpu=20m on Node 10.242.0.63
Feb 17 17:45:18.275: INFO: Pod coredns-c6797c986-cc2j9 requesting resource cpu=100m on Node 10.242.0.59
Feb 17 17:45:18.275: INFO: Pod coredns-c6797c986-rsp2r requesting resource cpu=100m on Node 10.242.0.98
Feb 17 17:45:18.275: INFO: Pod ibm-master-proxy-static-10.242.0.59 requesting resource cpu=25m on Node 10.242.0.59
Feb 17 17:45:18.275: INFO: Pod ibm-master-proxy-static-10.242.0.63 requesting resource cpu=25m on Node 10.242.0.63
Feb 17 17:45:18.276: INFO: Pod ibm-master-proxy-static-10.242.0.98 requesting resource cpu=25m on Node 10.242.0.98
Feb 17 17:45:18.276: INFO: Pod ibm-vpc-block-csi-controller-0 requesting resource cpu=0m on Node 10.242.0.63
Feb 17 17:45:18.276: INFO: Pod ibm-vpc-block-csi-node-44qtk requesting resource cpu=0m on Node 10.242.0.63
Feb 17 17:45:18.276: INFO: Pod ibm-vpc-block-csi-node-lnnpn requesting resource cpu=0m on Node 10.242.0.98
Feb 17 17:45:18.276: INFO: Pod ibm-vpc-block-csi-node-t57kv requesting resource cpu=0m on Node 10.242.0.59
Feb 17 17:45:18.276: INFO: Pod kubernetes-dashboard-656d9457bf-2qq9c requesting resource cpu=50m on Node 10.242.0.63
Feb 17 17:45:18.276: INFO: Pod metrics-server-5dfbdfb747-ttl59 requesting resource cpu=113m on Node 10.242.0.63
Feb 17 17:45:18.276: INFO: Pod public-crbp5a1mjl0i8s7ceo0p0g-alb1-9c9db77cc-652w8 requesting resource cpu=10m on Node 10.242.0.59
Feb 17 17:45:18.276: INFO: Pod public-crbp5a1mjl0i8s7ceo0p0g-alb1-9c9db77cc-hb966 requesting resource cpu=10m on Node 10.242.0.63
Feb 17 17:45:18.276: INFO: Pod vpn-bd4d5cff7-5tpm4 requesting resource cpu=5m on Node 10.242.0.63
Feb 17 17:45:18.276: INFO: Pod sonobuoy requesting resource cpu=0m on Node 10.242.0.98
Feb 17 17:45:18.277: INFO: Pod sonobuoy-e2e-job-8b0d4acd71ee4040 requesting resource cpu=0m on Node 10.242.0.98
Feb 17 17:45:18.277: INFO: Pod sonobuoy-systemd-logs-daemon-set-6f65da6b108e4900-fvg5d requesting resource cpu=0m on Node 10.242.0.98
Feb 17 17:45:18.277: INFO: Pod sonobuoy-systemd-logs-daemon-set-6f65da6b108e4900-mvgt7 requesting resource cpu=0m on Node 10.242.0.63
Feb 17 17:45:18.277: INFO: Pod sonobuoy-systemd-logs-daemon-set-6f65da6b108e4900-wmp7s requesting resource cpu=0m on Node 10.242.0.59
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-0adaff41-ed26-4d0a-b1d0-9b1c4ab92a38.15f4419e8b6caf7c], Reason = [Scheduled], Message = [Successfully assigned sched-pred-8004/filler-pod-0adaff41-ed26-4d0a-b1d0-9b1c4ab92a38 to 10.242.0.59]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-0adaff41-ed26-4d0a-b1d0-9b1c4ab92a38.15f4419ec89f44d7], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-0adaff41-ed26-4d0a-b1d0-9b1c4ab92a38.15f4419ece4641b4], Reason = [Created], Message = [Created container filler-pod-0adaff41-ed26-4d0a-b1d0-9b1c4ab92a38]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-0adaff41-ed26-4d0a-b1d0-9b1c4ab92a38.15f4419ed731ea22], Reason = [Started], Message = [Started container filler-pod-0adaff41-ed26-4d0a-b1d0-9b1c4ab92a38]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-a1b66df6-f326-43df-8c9f-8f9dd49d3654.15f4419e8c9c3bdd], Reason = [Scheduled], Message = [Successfully assigned sched-pred-8004/filler-pod-a1b66df6-f326-43df-8c9f-8f9dd49d3654 to 10.242.0.63]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-a1b66df6-f326-43df-8c9f-8f9dd49d3654.15f4419ecf64a224], Reason = [Pulling], Message = [Pulling image "k8s.gcr.io/pause:3.1"]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-a1b66df6-f326-43df-8c9f-8f9dd49d3654.15f4419f04362903], Reason = [Pulled], Message = [Successfully pulled image "k8s.gcr.io/pause:3.1"]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-a1b66df6-f326-43df-8c9f-8f9dd49d3654.15f4419f09c435d3], Reason = [Created], Message = [Created container filler-pod-a1b66df6-f326-43df-8c9f-8f9dd49d3654]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-a1b66df6-f326-43df-8c9f-8f9dd49d3654.15f4419f13e54b69], Reason = [Started], Message = [Started container filler-pod-a1b66df6-f326-43df-8c9f-8f9dd49d3654]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-f692e7e8-23ea-4581-9211-e8d3bf4ef0e8.15f4419e8d4ad198], Reason = [Scheduled], Message = [Successfully assigned sched-pred-8004/filler-pod-f692e7e8-23ea-4581-9211-e8d3bf4ef0e8 to 10.242.0.98]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-f692e7e8-23ea-4581-9211-e8d3bf4ef0e8.15f4419ec944c3ea], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-f692e7e8-23ea-4581-9211-e8d3bf4ef0e8.15f4419ececd6110], Reason = [Created], Message = [Created container filler-pod-f692e7e8-23ea-4581-9211-e8d3bf4ef0e8]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-f692e7e8-23ea-4581-9211-e8d3bf4ef0e8.15f4419ed7629a8e], Reason = [Started], Message = [Started container filler-pod-f692e7e8-23ea-4581-9211-e8d3bf4ef0e8]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.15f4419f8067ff38], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 Insufficient cpu.]
STEP: removing the label node off the node 10.242.0.59
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node 10.242.0.63
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node 10.242.0.98
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 17:45:23.578: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-8004" for this suite.
Feb 17 17:45:31.645: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:45:32.046: INFO: namespace sched-pred-8004 deletion completed in 8.451837682s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:72

• [SLOW TEST:14.552 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 17:45:32.050: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replicaset-6927
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Feb 17 17:45:35.404: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 17:45:35.445: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-6927" for this suite.
Feb 17 17:45:59.511: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:45:59.913: INFO: namespace replicaset-6927 deletion completed in 24.44869036s

• [SLOW TEST:27.864 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 17:45:59.914: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-218
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
Feb 17 17:46:00.184: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 17:46:03.790: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-218" for this suite.
Feb 17 17:46:27.858: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:46:28.257: INFO: namespace init-container-218 deletion completed in 24.449529266s

• [SLOW TEST:28.344 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 17:46:28.258: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-9292
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name cm-test-opt-del-6cca0d0d-b8ee-4885-9471-339342df640e
STEP: Creating configMap with name cm-test-opt-upd-645360d5-d027-4d45-8821-9cdebac33a68
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-6cca0d0d-b8ee-4885-9471-339342df640e
STEP: Updating configmap cm-test-opt-upd-645360d5-d027-4d45-8821-9cdebac33a68
STEP: Creating configMap with name cm-test-opt-create-f9a98345-1915-46a9-8a98-45cc74992fab
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 17:47:52.283: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9292" for this suite.
Feb 17 17:48:16.350: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:48:16.747: INFO: namespace configmap-9292 deletion completed in 24.446600095s

• [SLOW TEST:108.489 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 17:48:16.749: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-1181
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secret-namespace-3276
STEP: Creating secret with name secret-test-35110a22-46bb-4ffb-96e0-36b4e9914119
STEP: Creating a pod to test consume secrets
Feb 17 17:48:17.296: INFO: Waiting up to 5m0s for pod "pod-secrets-429c2b3c-c0dc-4dab-a487-6a4f89564125" in namespace "secrets-1181" to be "success or failure"
Feb 17 17:48:17.309: INFO: Pod "pod-secrets-429c2b3c-c0dc-4dab-a487-6a4f89564125": Phase="Pending", Reason="", readiness=false. Elapsed: 12.523502ms
Feb 17 17:48:19.334: INFO: Pod "pod-secrets-429c2b3c-c0dc-4dab-a487-6a4f89564125": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.037470859s
STEP: Saw pod success
Feb 17 17:48:19.334: INFO: Pod "pod-secrets-429c2b3c-c0dc-4dab-a487-6a4f89564125" satisfied condition "success or failure"
Feb 17 17:48:19.345: INFO: Trying to get logs from node 10.242.0.59 pod pod-secrets-429c2b3c-c0dc-4dab-a487-6a4f89564125 container secret-volume-test: <nil>
STEP: delete the pod
Feb 17 17:48:19.416: INFO: Waiting for pod pod-secrets-429c2b3c-c0dc-4dab-a487-6a4f89564125 to disappear
Feb 17 17:48:19.427: INFO: Pod pod-secrets-429c2b3c-c0dc-4dab-a487-6a4f89564125 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 17:48:19.427: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-1181" for this suite.
Feb 17 17:48:25.498: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:48:25.885: INFO: namespace secrets-1181 deletion completed in 6.437091438s
STEP: Destroying namespace "secret-namespace-3276" for this suite.
Feb 17 17:48:31.938: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:48:32.347: INFO: namespace secret-namespace-3276 deletion completed in 6.461932447s

• [SLOW TEST:15.598 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 17:48:32.350: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-8433
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test use defaults
Feb 17 17:48:32.632: INFO: Waiting up to 5m0s for pod "client-containers-48485ac5-be4a-4e4f-a8ad-9f7fca2edf85" in namespace "containers-8433" to be "success or failure"
Feb 17 17:48:32.644: INFO: Pod "client-containers-48485ac5-be4a-4e4f-a8ad-9f7fca2edf85": Phase="Pending", Reason="", readiness=false. Elapsed: 12.053532ms
Feb 17 17:48:34.656: INFO: Pod "client-containers-48485ac5-be4a-4e4f-a8ad-9f7fca2edf85": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023407098s
Feb 17 17:48:36.667: INFO: Pod "client-containers-48485ac5-be4a-4e4f-a8ad-9f7fca2edf85": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.035084723s
STEP: Saw pod success
Feb 17 17:48:36.667: INFO: Pod "client-containers-48485ac5-be4a-4e4f-a8ad-9f7fca2edf85" satisfied condition "success or failure"
Feb 17 17:48:36.678: INFO: Trying to get logs from node 10.242.0.59 pod client-containers-48485ac5-be4a-4e4f-a8ad-9f7fca2edf85 container test-container: <nil>
STEP: delete the pod
Feb 17 17:48:36.744: INFO: Waiting for pod client-containers-48485ac5-be4a-4e4f-a8ad-9f7fca2edf85 to disappear
Feb 17 17:48:36.755: INFO: Pod client-containers-48485ac5-be4a-4e4f-a8ad-9f7fca2edf85 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 17:48:36.755: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-8433" for this suite.
Feb 17 17:48:42.826: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:48:43.233: INFO: namespace containers-8433 deletion completed in 6.452696602s

• [SLOW TEST:10.883 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 17:48:43.233: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-6244
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 17:48:43.542: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-6244" for this suite.
Feb 17 17:48:49.615: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:48:50.006: INFO: namespace kubelet-test-6244 deletion completed in 6.446487688s

• [SLOW TEST:6.773 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should be possible to delete [NodeConformance] [Conformance]
    /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 17:48:50.007: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-482
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod busybox-7b993ccc-f440-4692-9387-8ce19f042b9e in namespace container-probe-482
Feb 17 17:48:52.314: INFO: Started pod busybox-7b993ccc-f440-4692-9387-8ce19f042b9e in namespace container-probe-482
STEP: checking the pod's current state and verifying that restartCount is present
Feb 17 17:48:52.324: INFO: Initial restart count of pod busybox-7b993ccc-f440-4692-9387-8ce19f042b9e is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 17:52:53.887: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-482" for this suite.
Feb 17 17:52:59.990: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:53:00.384: INFO: namespace container-probe-482 deletion completed in 6.464567802s

• [SLOW TEST:250.378 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 17 17:53:00.387: INFO: >>> kubeConfig: /tmp/kubeconfig-079603707
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-1245
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-1245.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-1245.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-1245.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-1245.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-1245.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-1245.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-1245.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-1245.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-1245.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-1245.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-1245.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-1245.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-1245.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 252.65.21.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.21.65.252_udp@PTR;check="$$(dig +tcp +noall +answer +search 252.65.21.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.21.65.252_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-1245.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-1245.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-1245.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-1245.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-1245.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-1245.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-1245.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-1245.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-1245.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-1245.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-1245.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-1245.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-1245.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 252.65.21.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.21.65.252_udp@PTR;check="$$(dig +tcp +noall +answer +search 252.65.21.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.21.65.252_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Feb 17 17:53:02.790: INFO: Unable to read wheezy_udp@dns-test-service.dns-1245.svc.cluster.local from pod dns-1245/dns-test-1d45a713-5e43-4c79-97b9-69fb6c059a38: the server could not find the requested resource (get pods dns-test-1d45a713-5e43-4c79-97b9-69fb6c059a38)
Feb 17 17:53:02.809: INFO: Unable to read wheezy_tcp@dns-test-service.dns-1245.svc.cluster.local from pod dns-1245/dns-test-1d45a713-5e43-4c79-97b9-69fb6c059a38: the server could not find the requested resource (get pods dns-test-1d45a713-5e43-4c79-97b9-69fb6c059a38)
Feb 17 17:53:02.827: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-1245.svc.cluster.local from pod dns-1245/dns-test-1d45a713-5e43-4c79-97b9-69fb6c059a38: the server could not find the requested resource (get pods dns-test-1d45a713-5e43-4c79-97b9-69fb6c059a38)
Feb 17 17:53:02.847: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-1245.svc.cluster.local from pod dns-1245/dns-test-1d45a713-5e43-4c79-97b9-69fb6c059a38: the server could not find the requested resource (get pods dns-test-1d45a713-5e43-4c79-97b9-69fb6c059a38)
Feb 17 17:53:02.987: INFO: Unable to read jessie_udp@dns-test-service.dns-1245.svc.cluster.local from pod dns-1245/dns-test-1d45a713-5e43-4c79-97b9-69fb6c059a38: the server could not find the requested resource (get pods dns-test-1d45a713-5e43-4c79-97b9-69fb6c059a38)
Feb 17 17:53:03.006: INFO: Unable to read jessie_tcp@dns-test-service.dns-1245.svc.cluster.local from pod dns-1245/dns-test-1d45a713-5e43-4c79-97b9-69fb6c059a38: the server could not find the requested resource (get pods dns-test-1d45a713-5e43-4c79-97b9-69fb6c059a38)
Feb 17 17:53:03.042: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-1245.svc.cluster.local from pod dns-1245/dns-test-1d45a713-5e43-4c79-97b9-69fb6c059a38: the server could not find the requested resource (get pods dns-test-1d45a713-5e43-4c79-97b9-69fb6c059a38)
Feb 17 17:53:03.067: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-1245.svc.cluster.local from pod dns-1245/dns-test-1d45a713-5e43-4c79-97b9-69fb6c059a38: the server could not find the requested resource (get pods dns-test-1d45a713-5e43-4c79-97b9-69fb6c059a38)
Feb 17 17:53:03.200: INFO: Lookups using dns-1245/dns-test-1d45a713-5e43-4c79-97b9-69fb6c059a38 failed for: [wheezy_udp@dns-test-service.dns-1245.svc.cluster.local wheezy_tcp@dns-test-service.dns-1245.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-1245.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-1245.svc.cluster.local jessie_udp@dns-test-service.dns-1245.svc.cluster.local jessie_tcp@dns-test-service.dns-1245.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-1245.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-1245.svc.cluster.local]

Feb 17 17:53:08.222: INFO: Unable to read wheezy_udp@dns-test-service.dns-1245.svc.cluster.local from pod dns-1245/dns-test-1d45a713-5e43-4c79-97b9-69fb6c059a38: the server could not find the requested resource (get pods dns-test-1d45a713-5e43-4c79-97b9-69fb6c059a38)
Feb 17 17:53:08.246: INFO: Unable to read wheezy_tcp@dns-test-service.dns-1245.svc.cluster.local from pod dns-1245/dns-test-1d45a713-5e43-4c79-97b9-69fb6c059a38: the server could not find the requested resource (get pods dns-test-1d45a713-5e43-4c79-97b9-69fb6c059a38)
Feb 17 17:53:08.267: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-1245.svc.cluster.local from pod dns-1245/dns-test-1d45a713-5e43-4c79-97b9-69fb6c059a38: the server could not find the requested resource (get pods dns-test-1d45a713-5e43-4c79-97b9-69fb6c059a38)
Feb 17 17:53:08.289: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-1245.svc.cluster.local from pod dns-1245/dns-test-1d45a713-5e43-4c79-97b9-69fb6c059a38: the server could not find the requested resource (get pods dns-test-1d45a713-5e43-4c79-97b9-69fb6c059a38)
Feb 17 17:53:08.431: INFO: Unable to read jessie_udp@dns-test-service.dns-1245.svc.cluster.local from pod dns-1245/dns-test-1d45a713-5e43-4c79-97b9-69fb6c059a38: the server could not find the requested resource (get pods dns-test-1d45a713-5e43-4c79-97b9-69fb6c059a38)
Feb 17 17:53:08.451: INFO: Unable to read jessie_tcp@dns-test-service.dns-1245.svc.cluster.local from pod dns-1245/dns-test-1d45a713-5e43-4c79-97b9-69fb6c059a38: the server could not find the requested resource (get pods dns-test-1d45a713-5e43-4c79-97b9-69fb6c059a38)
Feb 17 17:53:08.610: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-1245.svc.cluster.local from pod dns-1245/dns-test-1d45a713-5e43-4c79-97b9-69fb6c059a38: the server could not find the requested resource (get pods dns-test-1d45a713-5e43-4c79-97b9-69fb6c059a38)
Feb 17 17:53:08.630: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-1245.svc.cluster.local from pod dns-1245/dns-test-1d45a713-5e43-4c79-97b9-69fb6c059a38: the server could not find the requested resource (get pods dns-test-1d45a713-5e43-4c79-97b9-69fb6c059a38)
Feb 17 17:53:08.752: INFO: Lookups using dns-1245/dns-test-1d45a713-5e43-4c79-97b9-69fb6c059a38 failed for: [wheezy_udp@dns-test-service.dns-1245.svc.cluster.local wheezy_tcp@dns-test-service.dns-1245.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-1245.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-1245.svc.cluster.local jessie_udp@dns-test-service.dns-1245.svc.cluster.local jessie_tcp@dns-test-service.dns-1245.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-1245.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-1245.svc.cluster.local]

Feb 17 17:53:13.219: INFO: Unable to read wheezy_udp@dns-test-service.dns-1245.svc.cluster.local from pod dns-1245/dns-test-1d45a713-5e43-4c79-97b9-69fb6c059a38: the server could not find the requested resource (get pods dns-test-1d45a713-5e43-4c79-97b9-69fb6c059a38)
Feb 17 17:53:13.239: INFO: Unable to read wheezy_tcp@dns-test-service.dns-1245.svc.cluster.local from pod dns-1245/dns-test-1d45a713-5e43-4c79-97b9-69fb6c059a38: the server could not find the requested resource (get pods dns-test-1d45a713-5e43-4c79-97b9-69fb6c059a38)
Feb 17 17:53:13.258: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-1245.svc.cluster.local from pod dns-1245/dns-test-1d45a713-5e43-4c79-97b9-69fb6c059a38: the server could not find the requested resource (get pods dns-test-1d45a713-5e43-4c79-97b9-69fb6c059a38)
Feb 17 17:53:13.278: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-1245.svc.cluster.local from pod dns-1245/dns-test-1d45a713-5e43-4c79-97b9-69fb6c059a38: the server could not find the requested resource (get pods dns-test-1d45a713-5e43-4c79-97b9-69fb6c059a38)
Feb 17 17:53:13.425: INFO: Unable to read jessie_udp@dns-test-service.dns-1245.svc.cluster.local from pod dns-1245/dns-test-1d45a713-5e43-4c79-97b9-69fb6c059a38: the server could not find the requested resource (get pods dns-test-1d45a713-5e43-4c79-97b9-69fb6c059a38)
Feb 17 17:53:13.449: INFO: Unable to read jessie_tcp@dns-test-service.dns-1245.svc.cluster.local from pod dns-1245/dns-test-1d45a713-5e43-4c79-97b9-69fb6c059a38: the server could not find the requested resource (get pods dns-test-1d45a713-5e43-4c79-97b9-69fb6c059a38)
Feb 17 17:53:13.473: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-1245.svc.cluster.local from pod dns-1245/dns-test-1d45a713-5e43-4c79-97b9-69fb6c059a38: the server could not find the requested resource (get pods dns-test-1d45a713-5e43-4c79-97b9-69fb6c059a38)
Feb 17 17:53:13.498: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-1245.svc.cluster.local from pod dns-1245/dns-test-1d45a713-5e43-4c79-97b9-69fb6c059a38: the server could not find the requested resource (get pods dns-test-1d45a713-5e43-4c79-97b9-69fb6c059a38)
Feb 17 17:53:13.633: INFO: Lookups using dns-1245/dns-test-1d45a713-5e43-4c79-97b9-69fb6c059a38 failed for: [wheezy_udp@dns-test-service.dns-1245.svc.cluster.local wheezy_tcp@dns-test-service.dns-1245.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-1245.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-1245.svc.cluster.local jessie_udp@dns-test-service.dns-1245.svc.cluster.local jessie_tcp@dns-test-service.dns-1245.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-1245.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-1245.svc.cluster.local]

Feb 17 17:53:18.222: INFO: Unable to read wheezy_udp@dns-test-service.dns-1245.svc.cluster.local from pod dns-1245/dns-test-1d45a713-5e43-4c79-97b9-69fb6c059a38: the server could not find the requested resource (get pods dns-test-1d45a713-5e43-4c79-97b9-69fb6c059a38)
Feb 17 17:53:18.242: INFO: Unable to read wheezy_tcp@dns-test-service.dns-1245.svc.cluster.local from pod dns-1245/dns-test-1d45a713-5e43-4c79-97b9-69fb6c059a38: the server could not find the requested resource (get pods dns-test-1d45a713-5e43-4c79-97b9-69fb6c059a38)
Feb 17 17:53:18.262: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-1245.svc.cluster.local from pod dns-1245/dns-test-1d45a713-5e43-4c79-97b9-69fb6c059a38: the server could not find the requested resource (get pods dns-test-1d45a713-5e43-4c79-97b9-69fb6c059a38)
Feb 17 17:53:18.285: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-1245.svc.cluster.local from pod dns-1245/dns-test-1d45a713-5e43-4c79-97b9-69fb6c059a38: the server could not find the requested resource (get pods dns-test-1d45a713-5e43-4c79-97b9-69fb6c059a38)
Feb 17 17:53:18.430: INFO: Unable to read jessie_udp@dns-test-service.dns-1245.svc.cluster.local from pod dns-1245/dns-test-1d45a713-5e43-4c79-97b9-69fb6c059a38: the server could not find the requested resource (get pods dns-test-1d45a713-5e43-4c79-97b9-69fb6c059a38)
Feb 17 17:53:18.450: INFO: Unable to read jessie_tcp@dns-test-service.dns-1245.svc.cluster.local from pod dns-1245/dns-test-1d45a713-5e43-4c79-97b9-69fb6c059a38: the server could not find the requested resource (get pods dns-test-1d45a713-5e43-4c79-97b9-69fb6c059a38)
Feb 17 17:53:18.473: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-1245.svc.cluster.local from pod dns-1245/dns-test-1d45a713-5e43-4c79-97b9-69fb6c059a38: the server could not find the requested resource (get pods dns-test-1d45a713-5e43-4c79-97b9-69fb6c059a38)
Feb 17 17:53:18.491: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-1245.svc.cluster.local from pod dns-1245/dns-test-1d45a713-5e43-4c79-97b9-69fb6c059a38: the server could not find the requested resource (get pods dns-test-1d45a713-5e43-4c79-97b9-69fb6c059a38)
Feb 17 17:53:18.712: INFO: Lookups using dns-1245/dns-test-1d45a713-5e43-4c79-97b9-69fb6c059a38 failed for: [wheezy_udp@dns-test-service.dns-1245.svc.cluster.local wheezy_tcp@dns-test-service.dns-1245.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-1245.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-1245.svc.cluster.local jessie_udp@dns-test-service.dns-1245.svc.cluster.local jessie_tcp@dns-test-service.dns-1245.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-1245.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-1245.svc.cluster.local]

Feb 17 17:53:23.221: INFO: Unable to read wheezy_udp@dns-test-service.dns-1245.svc.cluster.local from pod dns-1245/dns-test-1d45a713-5e43-4c79-97b9-69fb6c059a38: the server could not find the requested resource (get pods dns-test-1d45a713-5e43-4c79-97b9-69fb6c059a38)
Feb 17 17:53:23.240: INFO: Unable to read wheezy_tcp@dns-test-service.dns-1245.svc.cluster.local from pod dns-1245/dns-test-1d45a713-5e43-4c79-97b9-69fb6c059a38: the server could not find the requested resource (get pods dns-test-1d45a713-5e43-4c79-97b9-69fb6c059a38)
Feb 17 17:53:23.259: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-1245.svc.cluster.local from pod dns-1245/dns-test-1d45a713-5e43-4c79-97b9-69fb6c059a38: the server could not find the requested resource (get pods dns-test-1d45a713-5e43-4c79-97b9-69fb6c059a38)
Feb 17 17:53:23.278: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-1245.svc.cluster.local from pod dns-1245/dns-test-1d45a713-5e43-4c79-97b9-69fb6c059a38: the server could not find the requested resource (get pods dns-test-1d45a713-5e43-4c79-97b9-69fb6c059a38)
Feb 17 17:53:23.417: INFO: Unable to read jessie_udp@dns-test-service.dns-1245.svc.cluster.local from pod dns-1245/dns-test-1d45a713-5e43-4c79-97b9-69fb6c059a38: the server could not find the requested resource (get pods dns-test-1d45a713-5e43-4c79-97b9-69fb6c059a38)
Feb 17 17:53:23.436: INFO: Unable to read jessie_tcp@dns-test-service.dns-1245.svc.cluster.local from pod dns-1245/dns-test-1d45a713-5e43-4c79-97b9-69fb6c059a38: the server could not find the requested resource (get pods dns-test-1d45a713-5e43-4c79-97b9-69fb6c059a38)
Feb 17 17:53:23.455: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-1245.svc.cluster.local from pod dns-1245/dns-test-1d45a713-5e43-4c79-97b9-69fb6c059a38: the server could not find the requested resource (get pods dns-test-1d45a713-5e43-4c79-97b9-69fb6c059a38)
Feb 17 17:53:23.474: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-1245.svc.cluster.local from pod dns-1245/dns-test-1d45a713-5e43-4c79-97b9-69fb6c059a38: the server could not find the requested resource (get pods dns-test-1d45a713-5e43-4c79-97b9-69fb6c059a38)
Feb 17 17:53:23.595: INFO: Lookups using dns-1245/dns-test-1d45a713-5e43-4c79-97b9-69fb6c059a38 failed for: [wheezy_udp@dns-test-service.dns-1245.svc.cluster.local wheezy_tcp@dns-test-service.dns-1245.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-1245.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-1245.svc.cluster.local jessie_udp@dns-test-service.dns-1245.svc.cluster.local jessie_tcp@dns-test-service.dns-1245.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-1245.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-1245.svc.cluster.local]

Feb 17 17:53:28.221: INFO: Unable to read wheezy_udp@dns-test-service.dns-1245.svc.cluster.local from pod dns-1245/dns-test-1d45a713-5e43-4c79-97b9-69fb6c059a38: the server could not find the requested resource (get pods dns-test-1d45a713-5e43-4c79-97b9-69fb6c059a38)
Feb 17 17:53:28.243: INFO: Unable to read wheezy_tcp@dns-test-service.dns-1245.svc.cluster.local from pod dns-1245/dns-test-1d45a713-5e43-4c79-97b9-69fb6c059a38: the server could not find the requested resource (get pods dns-test-1d45a713-5e43-4c79-97b9-69fb6c059a38)
Feb 17 17:53:28.263: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-1245.svc.cluster.local from pod dns-1245/dns-test-1d45a713-5e43-4c79-97b9-69fb6c059a38: the server could not find the requested resource (get pods dns-test-1d45a713-5e43-4c79-97b9-69fb6c059a38)
Feb 17 17:53:28.283: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-1245.svc.cluster.local from pod dns-1245/dns-test-1d45a713-5e43-4c79-97b9-69fb6c059a38: the server could not find the requested resource (get pods dns-test-1d45a713-5e43-4c79-97b9-69fb6c059a38)
Feb 17 17:53:28.439: INFO: Unable to read jessie_udp@dns-test-service.dns-1245.svc.cluster.local from pod dns-1245/dns-test-1d45a713-5e43-4c79-97b9-69fb6c059a38: the server could not find the requested resource (get pods dns-test-1d45a713-5e43-4c79-97b9-69fb6c059a38)
Feb 17 17:53:28.460: INFO: Unable to read jessie_tcp@dns-test-service.dns-1245.svc.cluster.local from pod dns-1245/dns-test-1d45a713-5e43-4c79-97b9-69fb6c059a38: the server could not find the requested resource (get pods dns-test-1d45a713-5e43-4c79-97b9-69fb6c059a38)
Feb 17 17:53:28.481: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-1245.svc.cluster.local from pod dns-1245/dns-test-1d45a713-5e43-4c79-97b9-69fb6c059a38: the server could not find the requested resource (get pods dns-test-1d45a713-5e43-4c79-97b9-69fb6c059a38)
Feb 17 17:53:28.502: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-1245.svc.cluster.local from pod dns-1245/dns-test-1d45a713-5e43-4c79-97b9-69fb6c059a38: the server could not find the requested resource (get pods dns-test-1d45a713-5e43-4c79-97b9-69fb6c059a38)
Feb 17 17:53:28.621: INFO: Lookups using dns-1245/dns-test-1d45a713-5e43-4c79-97b9-69fb6c059a38 failed for: [wheezy_udp@dns-test-service.dns-1245.svc.cluster.local wheezy_tcp@dns-test-service.dns-1245.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-1245.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-1245.svc.cluster.local jessie_udp@dns-test-service.dns-1245.svc.cluster.local jessie_tcp@dns-test-service.dns-1245.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-1245.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-1245.svc.cluster.local]

Feb 17 17:53:33.592: INFO: DNS probes using dns-1245/dns-test-1d45a713-5e43-4c79-97b9-69fb6c059a38 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 17 17:53:33.767: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-1245" for this suite.
Feb 17 17:53:41.832: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:53:42.232: INFO: namespace dns-1245 deletion completed in 8.447895325s

• [SLOW TEST:41.845 seconds]
[sig-network] DNS
/workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.15.10-beta.0.23+57df7c4bc188bc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSFeb 17 17:53:42.232: INFO: Running AfterSuite actions on all nodes
Feb 17 17:53:42.232: INFO: Running AfterSuite actions on node 1
Feb 17 17:53:42.232: INFO: Skipping dumping logs from cluster

Ran 215 of 4412 Specs in 5935.576 seconds
SUCCESS! -- 215 Passed | 0 Failed | 0 Pending | 4197 Skipped
PASS

Ginkgo ran 1 suite in 1h38m57.181939073s
Test Suite Passed
