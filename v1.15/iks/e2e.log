I0827 18:30:15.699832      16 test_context.go:406] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-540514467
I0827 18:30:15.699943      16 e2e.go:241] Starting e2e run "1fb9f777-f96c-46fe-90f6-388f34acc7d5" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1566930614 - Will randomize all specs
Will run 215 of 4413 specs

Aug 27 18:30:15.974: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
Aug 27 18:30:15.978: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Aug 27 18:30:16.046: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Aug 27 18:30:16.131: INFO: 23 / 23 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Aug 27 18:30:16.131: INFO: expected 11 pod replicas in namespace 'kube-system', 11 are Running and Ready.
Aug 27 18:30:16.131: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Aug 27 18:30:16.155: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'calico-node' (0 seconds elapsed)
Aug 27 18:30:16.155: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'ibm-keepalived-watcher' (0 seconds elapsed)
Aug 27 18:30:16.155: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'ibm-kube-fluentd' (0 seconds elapsed)
Aug 27 18:30:16.155: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'ibm-master-proxy' (0 seconds elapsed)
Aug 27 18:30:16.155: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'node-local-dns' (0 seconds elapsed)
Aug 27 18:30:16.155: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'nvidia-driver-installer' (0 seconds elapsed)
Aug 27 18:30:16.155: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'nvidia-gpu-device-plugin' (0 seconds elapsed)
Aug 27 18:30:16.155: INFO: e2e test version: v1.15.3
Aug 27 18:30:16.160: INFO: kube-apiserver version: v1.15.3+IKS
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 18:30:16.161: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename init-container
Aug 27 18:30:16.255: INFO: Found PodSecurityPolicies; assuming PodSecurityPolicy is enabled.
Aug 27 18:30:16.310: INFO: Found ClusterRoles; assuming RBAC is enabled.
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-501
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
Aug 27 18:30:16.459: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 18:30:24.537: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-501" for this suite.
Aug 27 18:30:48.597: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 18:30:48.968: INFO: namespace init-container-501 deletion completed in 24.414728132s

• [SLOW TEST:32.807 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 18:30:48.968: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-5249
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
Aug 27 18:31:29.306: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
W0827 18:31:29.306147      16 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Aug 27 18:31:29.306: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-5249" for this suite.
Aug 27 18:31:37.369: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 18:31:37.764: INFO: namespace gc-5249 deletion completed in 8.443497386s

• [SLOW TEST:48.796 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 18:31:37.764: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-6513
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-map-bb0afc4b-bf0d-4290-8d6c-fa96a4d7eb4d
STEP: Creating a pod to test consume secrets
Aug 27 18:31:38.029: INFO: Waiting up to 5m0s for pod "pod-secrets-73385fa7-3aee-4ca7-b073-668fe115b26a" in namespace "secrets-6513" to be "success or failure"
Aug 27 18:31:38.040: INFO: Pod "pod-secrets-73385fa7-3aee-4ca7-b073-668fe115b26a": Phase="Pending", Reason="", readiness=false. Elapsed: 10.374248ms
Aug 27 18:31:40.051: INFO: Pod "pod-secrets-73385fa7-3aee-4ca7-b073-668fe115b26a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022151331s
Aug 27 18:31:42.064: INFO: Pod "pod-secrets-73385fa7-3aee-4ca7-b073-668fe115b26a": Phase="Pending", Reason="", readiness=false. Elapsed: 4.034735s
Aug 27 18:31:44.074: INFO: Pod "pod-secrets-73385fa7-3aee-4ca7-b073-668fe115b26a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.045108519s
STEP: Saw pod success
Aug 27 18:31:44.074: INFO: Pod "pod-secrets-73385fa7-3aee-4ca7-b073-668fe115b26a" satisfied condition "success or failure"
Aug 27 18:31:44.084: INFO: Trying to get logs from node 10.138.3.242 pod pod-secrets-73385fa7-3aee-4ca7-b073-668fe115b26a container secret-volume-test: <nil>
STEP: delete the pod
Aug 27 18:31:44.134: INFO: Waiting for pod pod-secrets-73385fa7-3aee-4ca7-b073-668fe115b26a to disappear
Aug 27 18:31:44.145: INFO: Pod pod-secrets-73385fa7-3aee-4ca7-b073-668fe115b26a no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 18:31:44.146: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6513" for this suite.
Aug 27 18:31:50.209: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 18:31:50.642: INFO: namespace secrets-6513 deletion completed in 6.479786935s

• [SLOW TEST:12.877 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 18:31:50.642: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename prestop
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in prestop-4165
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pre_stop.go:167
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating server pod server in namespace prestop-4165
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace prestop-4165
STEP: Deleting pre-stop pod
Aug 27 18:32:07.999: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 18:32:08.016: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "prestop-4165" for this suite.
Aug 27 18:32:48.078: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 18:32:48.465: INFO: namespace prestop-4165 deletion completed in 40.432568467s

• [SLOW TEST:57.823 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 18:32:48.466: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-6399
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-6399.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-6399.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-6399.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-6399.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-6399.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-6399.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-6399.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-6399.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-6399.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-6399.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-6399.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-6399.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-6399.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 129.82.21.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.21.82.129_udp@PTR;check="$$(dig +tcp +noall +answer +search 129.82.21.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.21.82.129_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-6399.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-6399.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-6399.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-6399.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-6399.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-6399.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-6399.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-6399.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-6399.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-6399.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-6399.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-6399.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-6399.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 129.82.21.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.21.82.129_udp@PTR;check="$$(dig +tcp +noall +answer +search 129.82.21.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.21.82.129_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Aug 27 18:33:10.801: INFO: Unable to read wheezy_udp@dns-test-service.dns-6399.svc.cluster.local from pod dns-6399/dns-test-49d8ac54-5834-4164-8bda-1c3884fe0609: the server could not find the requested resource (get pods dns-test-49d8ac54-5834-4164-8bda-1c3884fe0609)
Aug 27 18:33:10.818: INFO: Unable to read wheezy_tcp@dns-test-service.dns-6399.svc.cluster.local from pod dns-6399/dns-test-49d8ac54-5834-4164-8bda-1c3884fe0609: the server could not find the requested resource (get pods dns-test-49d8ac54-5834-4164-8bda-1c3884fe0609)
Aug 27 18:33:10.837: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-6399.svc.cluster.local from pod dns-6399/dns-test-49d8ac54-5834-4164-8bda-1c3884fe0609: the server could not find the requested resource (get pods dns-test-49d8ac54-5834-4164-8bda-1c3884fe0609)
Aug 27 18:33:10.852: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-6399.svc.cluster.local from pod dns-6399/dns-test-49d8ac54-5834-4164-8bda-1c3884fe0609: the server could not find the requested resource (get pods dns-test-49d8ac54-5834-4164-8bda-1c3884fe0609)
Aug 27 18:33:10.948: INFO: Unable to read jessie_udp@dns-test-service.dns-6399.svc.cluster.local from pod dns-6399/dns-test-49d8ac54-5834-4164-8bda-1c3884fe0609: the server could not find the requested resource (get pods dns-test-49d8ac54-5834-4164-8bda-1c3884fe0609)
Aug 27 18:33:10.962: INFO: Unable to read jessie_tcp@dns-test-service.dns-6399.svc.cluster.local from pod dns-6399/dns-test-49d8ac54-5834-4164-8bda-1c3884fe0609: the server could not find the requested resource (get pods dns-test-49d8ac54-5834-4164-8bda-1c3884fe0609)
Aug 27 18:33:10.976: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-6399.svc.cluster.local from pod dns-6399/dns-test-49d8ac54-5834-4164-8bda-1c3884fe0609: the server could not find the requested resource (get pods dns-test-49d8ac54-5834-4164-8bda-1c3884fe0609)
Aug 27 18:33:10.990: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-6399.svc.cluster.local from pod dns-6399/dns-test-49d8ac54-5834-4164-8bda-1c3884fe0609: the server could not find the requested resource (get pods dns-test-49d8ac54-5834-4164-8bda-1c3884fe0609)
Aug 27 18:33:11.095: INFO: Lookups using dns-6399/dns-test-49d8ac54-5834-4164-8bda-1c3884fe0609 failed for: [wheezy_udp@dns-test-service.dns-6399.svc.cluster.local wheezy_tcp@dns-test-service.dns-6399.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-6399.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-6399.svc.cluster.local jessie_udp@dns-test-service.dns-6399.svc.cluster.local jessie_tcp@dns-test-service.dns-6399.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-6399.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-6399.svc.cluster.local]

Aug 27 18:33:16.110: INFO: Unable to read wheezy_udp@dns-test-service.dns-6399.svc.cluster.local from pod dns-6399/dns-test-49d8ac54-5834-4164-8bda-1c3884fe0609: the server could not find the requested resource (get pods dns-test-49d8ac54-5834-4164-8bda-1c3884fe0609)
Aug 27 18:33:16.123: INFO: Unable to read wheezy_tcp@dns-test-service.dns-6399.svc.cluster.local from pod dns-6399/dns-test-49d8ac54-5834-4164-8bda-1c3884fe0609: the server could not find the requested resource (get pods dns-test-49d8ac54-5834-4164-8bda-1c3884fe0609)
Aug 27 18:33:16.137: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-6399.svc.cluster.local from pod dns-6399/dns-test-49d8ac54-5834-4164-8bda-1c3884fe0609: the server could not find the requested resource (get pods dns-test-49d8ac54-5834-4164-8bda-1c3884fe0609)
Aug 27 18:33:16.151: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-6399.svc.cluster.local from pod dns-6399/dns-test-49d8ac54-5834-4164-8bda-1c3884fe0609: the server could not find the requested resource (get pods dns-test-49d8ac54-5834-4164-8bda-1c3884fe0609)
Aug 27 18:33:16.277: INFO: Unable to read jessie_udp@dns-test-service.dns-6399.svc.cluster.local from pod dns-6399/dns-test-49d8ac54-5834-4164-8bda-1c3884fe0609: the server could not find the requested resource (get pods dns-test-49d8ac54-5834-4164-8bda-1c3884fe0609)
Aug 27 18:33:16.291: INFO: Unable to read jessie_tcp@dns-test-service.dns-6399.svc.cluster.local from pod dns-6399/dns-test-49d8ac54-5834-4164-8bda-1c3884fe0609: the server could not find the requested resource (get pods dns-test-49d8ac54-5834-4164-8bda-1c3884fe0609)
Aug 27 18:33:16.305: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-6399.svc.cluster.local from pod dns-6399/dns-test-49d8ac54-5834-4164-8bda-1c3884fe0609: the server could not find the requested resource (get pods dns-test-49d8ac54-5834-4164-8bda-1c3884fe0609)
Aug 27 18:33:16.327: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-6399.svc.cluster.local from pod dns-6399/dns-test-49d8ac54-5834-4164-8bda-1c3884fe0609: the server could not find the requested resource (get pods dns-test-49d8ac54-5834-4164-8bda-1c3884fe0609)
Aug 27 18:33:16.418: INFO: Lookups using dns-6399/dns-test-49d8ac54-5834-4164-8bda-1c3884fe0609 failed for: [wheezy_udp@dns-test-service.dns-6399.svc.cluster.local wheezy_tcp@dns-test-service.dns-6399.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-6399.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-6399.svc.cluster.local jessie_udp@dns-test-service.dns-6399.svc.cluster.local jessie_tcp@dns-test-service.dns-6399.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-6399.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-6399.svc.cluster.local]

Aug 27 18:33:21.169: INFO: Unable to read wheezy_udp@dns-test-service.dns-6399.svc.cluster.local from pod dns-6399/dns-test-49d8ac54-5834-4164-8bda-1c3884fe0609: the server could not find the requested resource (get pods dns-test-49d8ac54-5834-4164-8bda-1c3884fe0609)
Aug 27 18:33:21.192: INFO: Unable to read wheezy_tcp@dns-test-service.dns-6399.svc.cluster.local from pod dns-6399/dns-test-49d8ac54-5834-4164-8bda-1c3884fe0609: the server could not find the requested resource (get pods dns-test-49d8ac54-5834-4164-8bda-1c3884fe0609)
Aug 27 18:33:21.205: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-6399.svc.cluster.local from pod dns-6399/dns-test-49d8ac54-5834-4164-8bda-1c3884fe0609: the server could not find the requested resource (get pods dns-test-49d8ac54-5834-4164-8bda-1c3884fe0609)
Aug 27 18:33:21.218: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-6399.svc.cluster.local from pod dns-6399/dns-test-49d8ac54-5834-4164-8bda-1c3884fe0609: the server could not find the requested resource (get pods dns-test-49d8ac54-5834-4164-8bda-1c3884fe0609)
Aug 27 18:33:21.314: INFO: Unable to read jessie_udp@dns-test-service.dns-6399.svc.cluster.local from pod dns-6399/dns-test-49d8ac54-5834-4164-8bda-1c3884fe0609: the server could not find the requested resource (get pods dns-test-49d8ac54-5834-4164-8bda-1c3884fe0609)
Aug 27 18:33:21.328: INFO: Unable to read jessie_tcp@dns-test-service.dns-6399.svc.cluster.local from pod dns-6399/dns-test-49d8ac54-5834-4164-8bda-1c3884fe0609: the server could not find the requested resource (get pods dns-test-49d8ac54-5834-4164-8bda-1c3884fe0609)
Aug 27 18:33:21.342: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-6399.svc.cluster.local from pod dns-6399/dns-test-49d8ac54-5834-4164-8bda-1c3884fe0609: the server could not find the requested resource (get pods dns-test-49d8ac54-5834-4164-8bda-1c3884fe0609)
Aug 27 18:33:21.356: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-6399.svc.cluster.local from pod dns-6399/dns-test-49d8ac54-5834-4164-8bda-1c3884fe0609: the server could not find the requested resource (get pods dns-test-49d8ac54-5834-4164-8bda-1c3884fe0609)
Aug 27 18:33:21.446: INFO: Lookups using dns-6399/dns-test-49d8ac54-5834-4164-8bda-1c3884fe0609 failed for: [wheezy_udp@dns-test-service.dns-6399.svc.cluster.local wheezy_tcp@dns-test-service.dns-6399.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-6399.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-6399.svc.cluster.local jessie_udp@dns-test-service.dns-6399.svc.cluster.local jessie_tcp@dns-test-service.dns-6399.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-6399.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-6399.svc.cluster.local]

Aug 27 18:33:26.110: INFO: Unable to read wheezy_udp@dns-test-service.dns-6399.svc.cluster.local from pod dns-6399/dns-test-49d8ac54-5834-4164-8bda-1c3884fe0609: the server could not find the requested resource (get pods dns-test-49d8ac54-5834-4164-8bda-1c3884fe0609)
Aug 27 18:33:26.124: INFO: Unable to read wheezy_tcp@dns-test-service.dns-6399.svc.cluster.local from pod dns-6399/dns-test-49d8ac54-5834-4164-8bda-1c3884fe0609: the server could not find the requested resource (get pods dns-test-49d8ac54-5834-4164-8bda-1c3884fe0609)
Aug 27 18:33:26.138: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-6399.svc.cluster.local from pod dns-6399/dns-test-49d8ac54-5834-4164-8bda-1c3884fe0609: the server could not find the requested resource (get pods dns-test-49d8ac54-5834-4164-8bda-1c3884fe0609)
Aug 27 18:33:26.151: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-6399.svc.cluster.local from pod dns-6399/dns-test-49d8ac54-5834-4164-8bda-1c3884fe0609: the server could not find the requested resource (get pods dns-test-49d8ac54-5834-4164-8bda-1c3884fe0609)
Aug 27 18:33:26.269: INFO: Unable to read jessie_udp@dns-test-service.dns-6399.svc.cluster.local from pod dns-6399/dns-test-49d8ac54-5834-4164-8bda-1c3884fe0609: the server could not find the requested resource (get pods dns-test-49d8ac54-5834-4164-8bda-1c3884fe0609)
Aug 27 18:33:26.282: INFO: Unable to read jessie_tcp@dns-test-service.dns-6399.svc.cluster.local from pod dns-6399/dns-test-49d8ac54-5834-4164-8bda-1c3884fe0609: the server could not find the requested resource (get pods dns-test-49d8ac54-5834-4164-8bda-1c3884fe0609)
Aug 27 18:33:26.297: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-6399.svc.cluster.local from pod dns-6399/dns-test-49d8ac54-5834-4164-8bda-1c3884fe0609: the server could not find the requested resource (get pods dns-test-49d8ac54-5834-4164-8bda-1c3884fe0609)
Aug 27 18:33:26.312: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-6399.svc.cluster.local from pod dns-6399/dns-test-49d8ac54-5834-4164-8bda-1c3884fe0609: the server could not find the requested resource (get pods dns-test-49d8ac54-5834-4164-8bda-1c3884fe0609)
Aug 27 18:33:26.411: INFO: Lookups using dns-6399/dns-test-49d8ac54-5834-4164-8bda-1c3884fe0609 failed for: [wheezy_udp@dns-test-service.dns-6399.svc.cluster.local wheezy_tcp@dns-test-service.dns-6399.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-6399.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-6399.svc.cluster.local jessie_udp@dns-test-service.dns-6399.svc.cluster.local jessie_tcp@dns-test-service.dns-6399.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-6399.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-6399.svc.cluster.local]

Aug 27 18:33:31.110: INFO: Unable to read wheezy_udp@dns-test-service.dns-6399.svc.cluster.local from pod dns-6399/dns-test-49d8ac54-5834-4164-8bda-1c3884fe0609: the server could not find the requested resource (get pods dns-test-49d8ac54-5834-4164-8bda-1c3884fe0609)
Aug 27 18:33:31.263: INFO: Unable to read jessie_tcp@dns-test-service.dns-6399.svc.cluster.local from pod dns-6399/dns-test-49d8ac54-5834-4164-8bda-1c3884fe0609: the server could not find the requested resource (get pods dns-test-49d8ac54-5834-4164-8bda-1c3884fe0609)
Aug 27 18:33:31.372: INFO: Lookups using dns-6399/dns-test-49d8ac54-5834-4164-8bda-1c3884fe0609 failed for: [wheezy_udp@dns-test-service.dns-6399.svc.cluster.local jessie_tcp@dns-test-service.dns-6399.svc.cluster.local]

Aug 27 18:33:36.373: INFO: DNS probes using dns-6399/dns-test-49d8ac54-5834-4164-8bda-1c3884fe0609 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 18:33:36.494: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-6399" for this suite.
Aug 27 18:33:42.559: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 18:33:42.937: INFO: namespace dns-6399 deletion completed in 6.427046903s

• [SLOW TEST:54.471 seconds]
[sig-network] DNS
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 18:33:42.938: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-8428
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:63
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Aug 27 18:33:51.265: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Aug 27 18:33:51.275: INFO: Pod pod-with-prestop-http-hook still exists
Aug 27 18:33:53.276: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Aug 27 18:33:53.286: INFO: Pod pod-with-prestop-http-hook still exists
Aug 27 18:33:55.276: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Aug 27 18:33:55.286: INFO: Pod pod-with-prestop-http-hook still exists
Aug 27 18:33:57.276: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Aug 27 18:33:57.287: INFO: Pod pod-with-prestop-http-hook still exists
Aug 27 18:33:59.276: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Aug 27 18:33:59.286: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 18:33:59.326: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-8428" for this suite.
Aug 27 18:34:23.398: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 18:34:23.783: INFO: namespace container-lifecycle-hook-8428 deletion completed in 24.441747714s

• [SLOW TEST:40.845 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when create a pod with lifecycle hook
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 18:34:23.785: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9632
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Aug 27 18:34:24.031: INFO: Waiting up to 5m0s for pod "downwardapi-volume-da11c007-10e4-4fc0-8443-5a67841795f5" in namespace "projected-9632" to be "success or failure"
Aug 27 18:34:24.043: INFO: Pod "downwardapi-volume-da11c007-10e4-4fc0-8443-5a67841795f5": Phase="Pending", Reason="", readiness=false. Elapsed: 11.435532ms
Aug 27 18:34:26.053: INFO: Pod "downwardapi-volume-da11c007-10e4-4fc0-8443-5a67841795f5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021842014s
Aug 27 18:34:28.065: INFO: Pod "downwardapi-volume-da11c007-10e4-4fc0-8443-5a67841795f5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.033856706s
STEP: Saw pod success
Aug 27 18:34:28.065: INFO: Pod "downwardapi-volume-da11c007-10e4-4fc0-8443-5a67841795f5" satisfied condition "success or failure"
Aug 27 18:34:28.074: INFO: Trying to get logs from node 10.138.3.242 pod downwardapi-volume-da11c007-10e4-4fc0-8443-5a67841795f5 container client-container: <nil>
STEP: delete the pod
Aug 27 18:34:28.119: INFO: Waiting for pod downwardapi-volume-da11c007-10e4-4fc0-8443-5a67841795f5 to disappear
Aug 27 18:34:28.128: INFO: Pod downwardapi-volume-da11c007-10e4-4fc0-8443-5a67841795f5 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 18:34:28.128: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9632" for this suite.
Aug 27 18:34:34.188: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 18:34:34.560: INFO: namespace projected-9632 deletion completed in 6.417223011s

• [SLOW TEST:10.776 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 18:34:34.561: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-2152
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0666 on tmpfs
Aug 27 18:34:34.813: INFO: Waiting up to 5m0s for pod "pod-14ccd529-4ead-4dc6-85e2-ad6df90d0eff" in namespace "emptydir-2152" to be "success or failure"
Aug 27 18:34:34.824: INFO: Pod "pod-14ccd529-4ead-4dc6-85e2-ad6df90d0eff": Phase="Pending", Reason="", readiness=false. Elapsed: 10.387315ms
Aug 27 18:34:36.835: INFO: Pod "pod-14ccd529-4ead-4dc6-85e2-ad6df90d0eff": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021427308s
Aug 27 18:34:38.846: INFO: Pod "pod-14ccd529-4ead-4dc6-85e2-ad6df90d0eff": Phase="Pending", Reason="", readiness=false. Elapsed: 4.032088596s
Aug 27 18:34:40.877: INFO: Pod "pod-14ccd529-4ead-4dc6-85e2-ad6df90d0eff": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.063174066s
STEP: Saw pod success
Aug 27 18:34:40.877: INFO: Pod "pod-14ccd529-4ead-4dc6-85e2-ad6df90d0eff" satisfied condition "success or failure"
Aug 27 18:34:40.887: INFO: Trying to get logs from node 10.138.3.233 pod pod-14ccd529-4ead-4dc6-85e2-ad6df90d0eff container test-container: <nil>
STEP: delete the pod
Aug 27 18:34:40.938: INFO: Waiting for pod pod-14ccd529-4ead-4dc6-85e2-ad6df90d0eff to disappear
Aug 27 18:34:40.950: INFO: Pod pod-14ccd529-4ead-4dc6-85e2-ad6df90d0eff no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 18:34:40.950: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2152" for this suite.
Aug 27 18:34:47.009: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 18:34:47.391: INFO: namespace emptydir-2152 deletion completed in 6.426519813s

• [SLOW TEST:12.830 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 18:34:47.393: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8038
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name s-test-opt-del-3dea48af-4dc3-40ac-a38f-4d37f4f4633b
STEP: Creating secret with name s-test-opt-upd-23669f89-e537-41d3-9065-9adde165e8ae
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-3dea48af-4dc3-40ac-a38f-4d37f4f4633b
STEP: Updating secret s-test-opt-upd-23669f89-e537-41d3-9065-9adde165e8ae
STEP: Creating secret with name s-test-opt-create-a6dd4716-bcb3-4597-a6ed-5a237620fbca
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 18:34:53.893: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8038" for this suite.
Aug 27 18:35:17.951: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 18:35:18.382: INFO: namespace projected-8038 deletion completed in 24.474304007s

• [SLOW TEST:30.990 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 18:35:18.384: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-5500
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
Aug 27 18:35:28.708: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
W0827 18:35:28.708247      16 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Aug 27 18:35:28.708: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-5500" for this suite.
Aug 27 18:35:34.768: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 18:35:35.133: INFO: namespace gc-5500 deletion completed in 6.41112636s

• [SLOW TEST:16.750 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 18:35:35.135: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-7824
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1293
STEP: creating an rc
Aug 27 18:35:35.359: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-540514467 create -f - --namespace=kubectl-7824'
Aug 27 18:35:35.750: INFO: stderr: ""
Aug 27 18:35:35.750: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Waiting for Redis master to start.
Aug 27 18:35:36.761: INFO: Selector matched 1 pods for map[app:redis]
Aug 27 18:35:36.761: INFO: Found 0 / 1
Aug 27 18:35:37.761: INFO: Selector matched 1 pods for map[app:redis]
Aug 27 18:35:37.761: INFO: Found 0 / 1
Aug 27 18:35:38.761: INFO: Selector matched 1 pods for map[app:redis]
Aug 27 18:35:38.761: INFO: Found 0 / 1
Aug 27 18:35:39.761: INFO: Selector matched 1 pods for map[app:redis]
Aug 27 18:35:39.761: INFO: Found 0 / 1
Aug 27 18:35:40.761: INFO: Selector matched 1 pods for map[app:redis]
Aug 27 18:35:40.761: INFO: Found 0 / 1
Aug 27 18:35:41.761: INFO: Selector matched 1 pods for map[app:redis]
Aug 27 18:35:41.761: INFO: Found 1 / 1
Aug 27 18:35:41.761: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Aug 27 18:35:41.771: INFO: Selector matched 1 pods for map[app:redis]
Aug 27 18:35:41.771: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
STEP: checking for a matching strings
Aug 27 18:35:41.771: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-540514467 logs redis-master-wgvl6 redis-master --namespace=kubectl-7824'
Aug 27 18:35:41.916: INFO: stderr: ""
Aug 27 18:35:41.916: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 27 Aug 18:35:40.324 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 27 Aug 18:35:40.324 # Server started, Redis version 3.2.12\n1:M 27 Aug 18:35:40.324 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 27 Aug 18:35:40.324 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log lines
Aug 27 18:35:41.916: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-540514467 log redis-master-wgvl6 redis-master --namespace=kubectl-7824 --tail=1'
Aug 27 18:35:42.066: INFO: stderr: ""
Aug 27 18:35:42.066: INFO: stdout: "1:M 27 Aug 18:35:40.324 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log bytes
Aug 27 18:35:42.066: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-540514467 log redis-master-wgvl6 redis-master --namespace=kubectl-7824 --limit-bytes=1'
Aug 27 18:35:42.222: INFO: stderr: ""
Aug 27 18:35:42.222: INFO: stdout: " "
STEP: exposing timestamps
Aug 27 18:35:42.222: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-540514467 log redis-master-wgvl6 redis-master --namespace=kubectl-7824 --tail=1 --timestamps'
Aug 27 18:35:42.354: INFO: stderr: ""
Aug 27 18:35:42.354: INFO: stdout: "2019-08-27T18:35:40.325324367Z 1:M 27 Aug 18:35:40.324 * The server is now ready to accept connections on port 6379\n"
STEP: restricting to a time range
Aug 27 18:35:44.854: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-540514467 log redis-master-wgvl6 redis-master --namespace=kubectl-7824 --since=1s'
Aug 27 18:35:45.008: INFO: stderr: ""
Aug 27 18:35:45.008: INFO: stdout: ""
Aug 27 18:35:45.008: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-540514467 log redis-master-wgvl6 redis-master --namespace=kubectl-7824 --since=24h'
Aug 27 18:35:45.163: INFO: stderr: ""
Aug 27 18:35:45.163: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 27 Aug 18:35:40.324 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 27 Aug 18:35:40.324 # Server started, Redis version 3.2.12\n1:M 27 Aug 18:35:40.324 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 27 Aug 18:35:40.324 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1299
STEP: using delete to clean up resources
Aug 27 18:35:45.163: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-540514467 delete --grace-period=0 --force -f - --namespace=kubectl-7824'
Aug 27 18:35:45.446: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 27 18:35:45.446: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
Aug 27 18:35:45.446: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-540514467 get rc,svc -l name=nginx --no-headers --namespace=kubectl-7824'
Aug 27 18:35:45.582: INFO: stderr: "No resources found.\n"
Aug 27 18:35:45.582: INFO: stdout: ""
Aug 27 18:35:45.582: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-540514467 get pods -l name=nginx --namespace=kubectl-7824 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Aug 27 18:35:45.707: INFO: stderr: ""
Aug 27 18:35:45.707: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 18:35:45.707: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7824" for this suite.
Aug 27 18:36:09.770: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 18:36:10.146: INFO: namespace kubectl-7824 deletion completed in 24.42262684s

• [SLOW TEST:35.012 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl logs
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 18:36:10.149: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-6378
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:63
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Aug 27 18:36:20.506: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 27 18:36:20.517: INFO: Pod pod-with-prestop-exec-hook still exists
Aug 27 18:36:22.517: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 27 18:36:22.528: INFO: Pod pod-with-prestop-exec-hook still exists
Aug 27 18:36:24.517: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 27 18:36:24.528: INFO: Pod pod-with-prestop-exec-hook still exists
Aug 27 18:36:26.517: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 27 18:36:26.529: INFO: Pod pod-with-prestop-exec-hook still exists
Aug 27 18:36:28.517: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 27 18:36:28.528: INFO: Pod pod-with-prestop-exec-hook still exists
Aug 27 18:36:30.517: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 27 18:36:30.528: INFO: Pod pod-with-prestop-exec-hook still exists
Aug 27 18:36:32.517: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 27 18:36:32.528: INFO: Pod pod-with-prestop-exec-hook still exists
Aug 27 18:36:34.517: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 27 18:36:34.528: INFO: Pod pod-with-prestop-exec-hook still exists
Aug 27 18:36:36.517: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 27 18:36:36.528: INFO: Pod pod-with-prestop-exec-hook still exists
Aug 27 18:36:38.517: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 27 18:36:38.528: INFO: Pod pod-with-prestop-exec-hook still exists
Aug 27 18:36:40.517: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 27 18:36:40.528: INFO: Pod pod-with-prestop-exec-hook still exists
Aug 27 18:36:42.517: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 27 18:36:42.528: INFO: Pod pod-with-prestop-exec-hook still exists
Aug 27 18:36:44.517: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 27 18:36:44.528: INFO: Pod pod-with-prestop-exec-hook still exists
Aug 27 18:36:46.517: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 27 18:36:46.528: INFO: Pod pod-with-prestop-exec-hook still exists
Aug 27 18:36:48.517: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 27 18:36:48.527: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 18:36:48.561: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-6378" for this suite.
Aug 27 18:37:10.623: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 18:37:11.051: INFO: namespace container-lifecycle-hook-6378 deletion completed in 22.474187764s

• [SLOW TEST:60.902 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when create a pod with lifecycle hook
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 18:37:11.051: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-7844
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0777 on node default medium
Aug 27 18:37:11.291: INFO: Waiting up to 5m0s for pod "pod-583617e8-b99d-416e-b23a-d1c6168390aa" in namespace "emptydir-7844" to be "success or failure"
Aug 27 18:37:11.302: INFO: Pod "pod-583617e8-b99d-416e-b23a-d1c6168390aa": Phase="Pending", Reason="", readiness=false. Elapsed: 11.060875ms
Aug 27 18:37:13.313: INFO: Pod "pod-583617e8-b99d-416e-b23a-d1c6168390aa": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021662249s
Aug 27 18:37:15.324: INFO: Pod "pod-583617e8-b99d-416e-b23a-d1c6168390aa": Phase="Pending", Reason="", readiness=false. Elapsed: 4.032691999s
Aug 27 18:37:17.334: INFO: Pod "pod-583617e8-b99d-416e-b23a-d1c6168390aa": Phase="Pending", Reason="", readiness=false. Elapsed: 6.043263313s
Aug 27 18:37:19.345: INFO: Pod "pod-583617e8-b99d-416e-b23a-d1c6168390aa": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.053673625s
STEP: Saw pod success
Aug 27 18:37:19.345: INFO: Pod "pod-583617e8-b99d-416e-b23a-d1c6168390aa" satisfied condition "success or failure"
Aug 27 18:37:19.355: INFO: Trying to get logs from node 10.138.3.242 pod pod-583617e8-b99d-416e-b23a-d1c6168390aa container test-container: <nil>
STEP: delete the pod
Aug 27 18:37:19.399: INFO: Waiting for pod pod-583617e8-b99d-416e-b23a-d1c6168390aa to disappear
Aug 27 18:37:19.410: INFO: Pod pod-583617e8-b99d-416e-b23a-d1c6168390aa no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 18:37:19.410: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7844" for this suite.
Aug 27 18:37:25.469: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 18:37:25.853: INFO: namespace emptydir-7844 deletion completed in 6.428709281s

• [SLOW TEST:14.802 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 18:37:25.856: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-3347
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-3347.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-3347.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-3347.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-3347.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-3347.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-3347.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe /etc/hosts
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Aug 27 18:37:30.268: INFO: DNS probes using dns-3347/dns-test-c62711a1-cb65-40ab-8f5b-21b73bde12f8 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 18:37:30.305: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-3347" for this suite.
Aug 27 18:37:36.366: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 18:37:36.850: INFO: namespace dns-3347 deletion completed in 6.529734528s

• [SLOW TEST:10.995 seconds]
[sig-network] DNS
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 18:37:36.852: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename svc-latency
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svc-latency-2924
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating replication controller svc-latency-rc in namespace svc-latency-2924
I0827 18:37:37.089336      16 runners.go:180] Created replication controller with name: svc-latency-rc, namespace: svc-latency-2924, replica count: 1
I0827 18:37:38.139829      16 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0827 18:37:39.140053      16 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Aug 27 18:37:39.265: INFO: Created: latency-svc-7gj87
Aug 27 18:37:39.272: INFO: Got endpoints: latency-svc-7gj87 [31.69023ms]
Aug 27 18:37:39.297: INFO: Created: latency-svc-6m2pd
Aug 27 18:37:39.302: INFO: Got endpoints: latency-svc-6m2pd [30.391516ms]
Aug 27 18:37:39.307: INFO: Created: latency-svc-cp6jm
Aug 27 18:37:39.312: INFO: Got endpoints: latency-svc-cp6jm [39.647894ms]
Aug 27 18:37:39.317: INFO: Created: latency-svc-cgpb7
Aug 27 18:37:39.323: INFO: Got endpoints: latency-svc-cgpb7 [50.406126ms]
Aug 27 18:37:39.327: INFO: Created: latency-svc-f2qkt
Aug 27 18:37:39.331: INFO: Got endpoints: latency-svc-f2qkt [58.885711ms]
Aug 27 18:37:39.337: INFO: Created: latency-svc-d4wl7
Aug 27 18:37:39.341: INFO: Got endpoints: latency-svc-d4wl7 [69.242066ms]
Aug 27 18:37:39.346: INFO: Created: latency-svc-2sbxh
Aug 27 18:37:39.351: INFO: Got endpoints: latency-svc-2sbxh [78.986105ms]
Aug 27 18:37:39.357: INFO: Created: latency-svc-nlt2w
Aug 27 18:37:39.362: INFO: Got endpoints: latency-svc-nlt2w [89.906004ms]
Aug 27 18:37:39.367: INFO: Created: latency-svc-v75zl
Aug 27 18:37:39.372: INFO: Got endpoints: latency-svc-v75zl [99.50566ms]
Aug 27 18:37:39.377: INFO: Created: latency-svc-g4882
Aug 27 18:37:39.382: INFO: Got endpoints: latency-svc-g4882 [109.449478ms]
Aug 27 18:37:39.388: INFO: Created: latency-svc-czbx2
Aug 27 18:37:39.392: INFO: Got endpoints: latency-svc-czbx2 [120.128955ms]
Aug 27 18:37:39.398: INFO: Created: latency-svc-s4jmm
Aug 27 18:37:39.403: INFO: Got endpoints: latency-svc-s4jmm [130.506316ms]
Aug 27 18:37:39.408: INFO: Created: latency-svc-9jrl7
Aug 27 18:37:39.413: INFO: Got endpoints: latency-svc-9jrl7 [140.208914ms]
Aug 27 18:37:39.419: INFO: Created: latency-svc-xlhnt
Aug 27 18:37:39.424: INFO: Got endpoints: latency-svc-xlhnt [151.64377ms]
Aug 27 18:37:39.430: INFO: Created: latency-svc-9pzkh
Aug 27 18:37:39.435: INFO: Got endpoints: latency-svc-9pzkh [162.548328ms]
Aug 27 18:37:39.439: INFO: Created: latency-svc-dn2z2
Aug 27 18:37:39.444: INFO: Got endpoints: latency-svc-dn2z2 [171.566955ms]
Aug 27 18:37:39.448: INFO: Created: latency-svc-7f72f
Aug 27 18:37:39.453: INFO: Got endpoints: latency-svc-7f72f [151.05658ms]
Aug 27 18:37:39.458: INFO: Created: latency-svc-hhwz6
Aug 27 18:37:39.463: INFO: Got endpoints: latency-svc-hhwz6 [151.152108ms]
Aug 27 18:37:39.469: INFO: Created: latency-svc-v54pg
Aug 27 18:37:39.476: INFO: Got endpoints: latency-svc-v54pg [152.91097ms]
Aug 27 18:37:39.479: INFO: Created: latency-svc-6sdkd
Aug 27 18:37:39.484: INFO: Got endpoints: latency-svc-6sdkd [153.019963ms]
Aug 27 18:37:39.491: INFO: Created: latency-svc-zgvwv
Aug 27 18:37:39.495: INFO: Got endpoints: latency-svc-zgvwv [153.158432ms]
Aug 27 18:37:39.498: INFO: Created: latency-svc-pfnzl
Aug 27 18:37:39.503: INFO: Got endpoints: latency-svc-pfnzl [152.058468ms]
Aug 27 18:37:39.509: INFO: Created: latency-svc-8k2m7
Aug 27 18:37:39.513: INFO: Got endpoints: latency-svc-8k2m7 [151.096074ms]
Aug 27 18:37:39.519: INFO: Created: latency-svc-pfxl2
Aug 27 18:37:39.524: INFO: Got endpoints: latency-svc-pfxl2 [151.82455ms]
Aug 27 18:37:39.529: INFO: Created: latency-svc-zqfjx
Aug 27 18:37:39.534: INFO: Got endpoints: latency-svc-zqfjx [151.846905ms]
Aug 27 18:37:39.538: INFO: Created: latency-svc-km2h6
Aug 27 18:37:39.544: INFO: Got endpoints: latency-svc-km2h6 [151.48383ms]
Aug 27 18:37:39.550: INFO: Created: latency-svc-2v6gt
Aug 27 18:37:39.553: INFO: Got endpoints: latency-svc-2v6gt [150.596533ms]
Aug 27 18:37:39.559: INFO: Created: latency-svc-ht4jw
Aug 27 18:37:39.564: INFO: Got endpoints: latency-svc-ht4jw [151.107357ms]
Aug 27 18:37:39.570: INFO: Created: latency-svc-m4hmk
Aug 27 18:37:39.575: INFO: Got endpoints: latency-svc-m4hmk [151.165282ms]
Aug 27 18:37:39.578: INFO: Created: latency-svc-jsbbt
Aug 27 18:37:39.583: INFO: Got endpoints: latency-svc-jsbbt [148.607684ms]
Aug 27 18:37:39.590: INFO: Created: latency-svc-xxdb5
Aug 27 18:37:39.594: INFO: Got endpoints: latency-svc-xxdb5 [150.023844ms]
Aug 27 18:37:39.599: INFO: Created: latency-svc-bvrfn
Aug 27 18:37:39.604: INFO: Got endpoints: latency-svc-bvrfn [150.655272ms]
Aug 27 18:37:39.609: INFO: Created: latency-svc-p5m6x
Aug 27 18:37:39.613: INFO: Got endpoints: latency-svc-p5m6x [150.212791ms]
Aug 27 18:37:39.618: INFO: Created: latency-svc-6fc4z
Aug 27 18:37:39.623: INFO: Got endpoints: latency-svc-6fc4z [147.385532ms]
Aug 27 18:37:39.628: INFO: Created: latency-svc-xzrbf
Aug 27 18:37:39.634: INFO: Got endpoints: latency-svc-xzrbf [149.695425ms]
Aug 27 18:37:39.642: INFO: Created: latency-svc-czgck
Aug 27 18:37:39.647: INFO: Got endpoints: latency-svc-czgck [151.765367ms]
Aug 27 18:37:39.652: INFO: Created: latency-svc-8f8z2
Aug 27 18:37:39.657: INFO: Got endpoints: latency-svc-8f8z2 [153.359169ms]
Aug 27 18:37:39.662: INFO: Created: latency-svc-vr2hg
Aug 27 18:37:39.668: INFO: Got endpoints: latency-svc-vr2hg [154.023392ms]
Aug 27 18:37:39.673: INFO: Created: latency-svc-znqtf
Aug 27 18:37:39.677: INFO: Got endpoints: latency-svc-znqtf [153.620924ms]
Aug 27 18:37:39.682: INFO: Created: latency-svc-2z4r8
Aug 27 18:37:39.687: INFO: Got endpoints: latency-svc-2z4r8 [152.844807ms]
Aug 27 18:37:39.692: INFO: Created: latency-svc-7hw6n
Aug 27 18:37:39.697: INFO: Got endpoints: latency-svc-7hw6n [153.17437ms]
Aug 27 18:37:39.702: INFO: Created: latency-svc-vdpwx
Aug 27 18:37:39.707: INFO: Got endpoints: latency-svc-vdpwx [153.363827ms]
Aug 27 18:37:39.712: INFO: Created: latency-svc-6x7nf
Aug 27 18:37:39.717: INFO: Got endpoints: latency-svc-6x7nf [152.858772ms]
Aug 27 18:37:39.722: INFO: Created: latency-svc-pq86r
Aug 27 18:37:39.727: INFO: Got endpoints: latency-svc-pq86r [151.345073ms]
Aug 27 18:37:39.733: INFO: Created: latency-svc-dzbcz
Aug 27 18:37:39.738: INFO: Got endpoints: latency-svc-dzbcz [155.070946ms]
Aug 27 18:37:39.743: INFO: Created: latency-svc-qrd4p
Aug 27 18:37:39.749: INFO: Got endpoints: latency-svc-qrd4p [154.718787ms]
Aug 27 18:37:39.753: INFO: Created: latency-svc-hvbkn
Aug 27 18:37:39.758: INFO: Got endpoints: latency-svc-hvbkn [154.050008ms]
Aug 27 18:37:39.764: INFO: Created: latency-svc-fn6p4
Aug 27 18:37:39.769: INFO: Got endpoints: latency-svc-fn6p4 [155.787787ms]
Aug 27 18:37:39.775: INFO: Created: latency-svc-kzvwq
Aug 27 18:37:39.780: INFO: Got endpoints: latency-svc-kzvwq [156.969063ms]
Aug 27 18:37:39.785: INFO: Created: latency-svc-j78z2
Aug 27 18:37:39.790: INFO: Got endpoints: latency-svc-j78z2 [155.977487ms]
Aug 27 18:37:39.795: INFO: Created: latency-svc-qkt8v
Aug 27 18:37:39.801: INFO: Got endpoints: latency-svc-qkt8v [153.963163ms]
Aug 27 18:37:39.864: INFO: Created: latency-svc-q82zl
Aug 27 18:37:39.865: INFO: Got endpoints: latency-svc-q82zl [197.315241ms]
Aug 27 18:37:39.864: INFO: Created: latency-svc-jmmnt
Aug 27 18:37:39.865: INFO: Got endpoints: latency-svc-jmmnt [208.204297ms]
Aug 27 18:37:39.864: INFO: Created: latency-svc-8b4kd
Aug 27 18:37:39.864: INFO: Created: latency-svc-9xr7z
Aug 27 18:37:39.865: INFO: Got endpoints: latency-svc-9xr7z [188.096473ms]
Aug 27 18:37:39.865: INFO: Got endpoints: latency-svc-8b4kd [178.710015ms]
Aug 27 18:37:39.866: INFO: Created: latency-svc-jlxqw
Aug 27 18:37:39.866: INFO: Got endpoints: latency-svc-jlxqw [159.161394ms]
Aug 27 18:37:39.866: INFO: Created: latency-svc-4lfw8
Aug 27 18:37:39.866: INFO: Got endpoints: latency-svc-4lfw8 [168.614807ms]
Aug 27 18:37:39.868: INFO: Created: latency-svc-2b7s2
Aug 27 18:37:39.872: INFO: Got endpoints: latency-svc-2b7s2 [154.964356ms]
Aug 27 18:37:39.878: INFO: Created: latency-svc-n7lg6
Aug 27 18:37:39.883: INFO: Got endpoints: latency-svc-n7lg6 [156.187498ms]
Aug 27 18:37:39.888: INFO: Created: latency-svc-ktfqm
Aug 27 18:37:39.893: INFO: Got endpoints: latency-svc-ktfqm [154.80078ms]
Aug 27 18:37:39.899: INFO: Created: latency-svc-v66q9
Aug 27 18:37:39.904: INFO: Got endpoints: latency-svc-v66q9 [155.253117ms]
Aug 27 18:37:39.909: INFO: Created: latency-svc-hjxrr
Aug 27 18:37:39.915: INFO: Got endpoints: latency-svc-hjxrr [156.591594ms]
Aug 27 18:37:39.919: INFO: Created: latency-svc-prsnt
Aug 27 18:37:39.946: INFO: Created: latency-svc-tf2sm
Aug 27 18:37:39.946: INFO: Got endpoints: latency-svc-tf2sm [155.965101ms]
Aug 27 18:37:39.946: INFO: Created: latency-svc-dnv4l
Aug 27 18:37:39.946: INFO: Got endpoints: latency-svc-dnv4l [166.040002ms]
Aug 27 18:37:39.946: INFO: Got endpoints: latency-svc-prsnt [176.79887ms]
Aug 27 18:37:39.950: INFO: Created: latency-svc-bszd7
Aug 27 18:37:39.955: INFO: Got endpoints: latency-svc-bszd7 [154.019356ms]
Aug 27 18:37:39.960: INFO: Created: latency-svc-bdp6z
Aug 27 18:37:39.965: INFO: Got endpoints: latency-svc-bdp6z [100.259525ms]
Aug 27 18:37:39.970: INFO: Created: latency-svc-7bqtl
Aug 27 18:37:39.977: INFO: Got endpoints: latency-svc-7bqtl [111.624847ms]
Aug 27 18:37:39.982: INFO: Created: latency-svc-n9fhq
Aug 27 18:37:39.988: INFO: Got endpoints: latency-svc-n9fhq [121.986429ms]
Aug 27 18:37:39.992: INFO: Created: latency-svc-pwpch
Aug 27 18:37:39.998: INFO: Got endpoints: latency-svc-pwpch [132.318606ms]
Aug 27 18:37:40.003: INFO: Created: latency-svc-pb4c2
Aug 27 18:37:40.008: INFO: Got endpoints: latency-svc-pb4c2 [142.305351ms]
Aug 27 18:37:40.014: INFO: Created: latency-svc-sjrhq
Aug 27 18:37:40.019: INFO: Got endpoints: latency-svc-sjrhq [153.446795ms]
Aug 27 18:37:40.024: INFO: Created: latency-svc-f2ztp
Aug 27 18:37:40.029: INFO: Got endpoints: latency-svc-f2ztp [157.407295ms]
Aug 27 18:37:40.036: INFO: Created: latency-svc-xx4tp
Aug 27 18:37:40.041: INFO: Got endpoints: latency-svc-xx4tp [157.576445ms]
Aug 27 18:37:40.046: INFO: Created: latency-svc-v8swq
Aug 27 18:37:40.051: INFO: Got endpoints: latency-svc-v8swq [157.840337ms]
Aug 27 18:37:40.055: INFO: Created: latency-svc-hcfz8
Aug 27 18:37:40.060: INFO: Got endpoints: latency-svc-hcfz8 [156.222587ms]
Aug 27 18:37:40.066: INFO: Created: latency-svc-lqxn5
Aug 27 18:37:40.071: INFO: Got endpoints: latency-svc-lqxn5 [156.160127ms]
Aug 27 18:37:40.076: INFO: Created: latency-svc-mtpvk
Aug 27 18:37:40.081: INFO: Got endpoints: latency-svc-mtpvk [135.347402ms]
Aug 27 18:37:40.088: INFO: Created: latency-svc-s8mqh
Aug 27 18:37:40.093: INFO: Got endpoints: latency-svc-s8mqh [147.062031ms]
Aug 27 18:37:40.097: INFO: Created: latency-svc-zrgql
Aug 27 18:37:40.127: INFO: Created: latency-svc-mcnc6
Aug 27 18:37:40.127: INFO: Got endpoints: latency-svc-mcnc6 [161.33886ms]
Aug 27 18:37:40.127: INFO: Created: latency-svc-xj9rb
Aug 27 18:37:40.127: INFO: Got endpoints: latency-svc-zrgql [180.015885ms]
Aug 27 18:37:40.127: INFO: Got endpoints: latency-svc-xj9rb [172.348831ms]
Aug 27 18:37:40.127: INFO: Created: latency-svc-pzmkl
Aug 27 18:37:40.132: INFO: Got endpoints: latency-svc-pzmkl [155.326867ms]
Aug 27 18:37:40.139: INFO: Created: latency-svc-8wq5n
Aug 27 18:37:40.156: INFO: Created: latency-svc-7rxvj
Aug 27 18:37:40.157: INFO: Got endpoints: latency-svc-7rxvj [158.488234ms]
Aug 27 18:37:40.157: INFO: Got endpoints: latency-svc-8wq5n [169.120267ms]
Aug 27 18:37:40.159: INFO: Created: latency-svc-499hw
Aug 27 18:37:40.165: INFO: Got endpoints: latency-svc-499hw [156.479741ms]
Aug 27 18:37:40.169: INFO: Created: latency-svc-sdw88
Aug 27 18:37:40.175: INFO: Got endpoints: latency-svc-sdw88 [155.143418ms]
Aug 27 18:37:40.180: INFO: Created: latency-svc-gfmvh
Aug 27 18:37:40.186: INFO: Got endpoints: latency-svc-gfmvh [29.119698ms]
Aug 27 18:37:40.189: INFO: Created: latency-svc-4lvlc
Aug 27 18:37:40.194: INFO: Got endpoints: latency-svc-4lvlc [37.158697ms]
Aug 27 18:37:40.201: INFO: Created: latency-svc-nzqp2
Aug 27 18:37:40.207: INFO: Got endpoints: latency-svc-nzqp2 [166.226523ms]
Aug 27 18:37:40.212: INFO: Created: latency-svc-8m5hl
Aug 27 18:37:40.216: INFO: Got endpoints: latency-svc-8m5hl [164.981814ms]
Aug 27 18:37:40.222: INFO: Created: latency-svc-5hvbf
Aug 27 18:37:40.226: INFO: Got endpoints: latency-svc-5hvbf [165.94141ms]
Aug 27 18:37:40.231: INFO: Created: latency-svc-8hc8m
Aug 27 18:37:40.236: INFO: Got endpoints: latency-svc-8hc8m [165.382786ms]
Aug 27 18:37:40.241: INFO: Created: latency-svc-mffqm
Aug 27 18:37:40.247: INFO: Got endpoints: latency-svc-mffqm [165.442975ms]
Aug 27 18:37:40.256: INFO: Created: latency-svc-zmnvz
Aug 27 18:37:40.261: INFO: Got endpoints: latency-svc-zmnvz [167.393123ms]
Aug 27 18:37:40.265: INFO: Created: latency-svc-9xpgw
Aug 27 18:37:40.270: INFO: Got endpoints: latency-svc-9xpgw [142.813759ms]
Aug 27 18:37:40.275: INFO: Created: latency-svc-m82hx
Aug 27 18:37:40.282: INFO: Got endpoints: latency-svc-m82hx [154.457065ms]
Aug 27 18:37:40.285: INFO: Created: latency-svc-pmkz6
Aug 27 18:37:40.295: INFO: Created: latency-svc-cm2xk
Aug 27 18:37:40.295: INFO: Got endpoints: latency-svc-pmkz6 [167.871691ms]
Aug 27 18:37:40.302: INFO: Got endpoints: latency-svc-cm2xk [170.446556ms]
Aug 27 18:37:40.305: INFO: Created: latency-svc-zcxl9
Aug 27 18:37:40.310: INFO: Got endpoints: latency-svc-zcxl9 [281.27378ms]
Aug 27 18:37:40.315: INFO: Created: latency-svc-svbdw
Aug 27 18:37:40.320: INFO: Got endpoints: latency-svc-svbdw [155.248673ms]
Aug 27 18:37:40.325: INFO: Created: latency-svc-kdbx7
Aug 27 18:37:40.330: INFO: Got endpoints: latency-svc-kdbx7 [155.860487ms]
Aug 27 18:37:40.336: INFO: Created: latency-svc-fwdl9
Aug 27 18:37:40.341: INFO: Got endpoints: latency-svc-fwdl9 [155.249354ms]
Aug 27 18:37:40.346: INFO: Created: latency-svc-fwccm
Aug 27 18:37:40.352: INFO: Got endpoints: latency-svc-fwccm [157.707037ms]
Aug 27 18:37:40.358: INFO: Created: latency-svc-jjq8q
Aug 27 18:37:40.364: INFO: Got endpoints: latency-svc-jjq8q [157.210637ms]
Aug 27 18:37:40.369: INFO: Created: latency-svc-pldnv
Aug 27 18:37:40.374: INFO: Got endpoints: latency-svc-pldnv [157.807708ms]
Aug 27 18:37:40.379: INFO: Created: latency-svc-b7bfj
Aug 27 18:37:40.384: INFO: Got endpoints: latency-svc-b7bfj [157.863087ms]
Aug 27 18:37:40.390: INFO: Created: latency-svc-6rjt6
Aug 27 18:37:40.398: INFO: Got endpoints: latency-svc-6rjt6 [161.3698ms]
Aug 27 18:37:40.401: INFO: Created: latency-svc-mmrv8
Aug 27 18:37:40.407: INFO: Got endpoints: latency-svc-mmrv8 [159.605754ms]
Aug 27 18:37:40.410: INFO: Created: latency-svc-2h6j7
Aug 27 18:37:40.419: INFO: Got endpoints: latency-svc-2h6j7 [158.492941ms]
Aug 27 18:37:40.422: INFO: Created: latency-svc-sjq5j
Aug 27 18:37:40.425: INFO: Got endpoints: latency-svc-sjq5j [155.635971ms]
Aug 27 18:37:40.431: INFO: Created: latency-svc-ljq8p
Aug 27 18:37:40.436: INFO: Got endpoints: latency-svc-ljq8p [154.581544ms]
Aug 27 18:37:40.441: INFO: Created: latency-svc-7wtng
Aug 27 18:37:40.447: INFO: Got endpoints: latency-svc-7wtng [151.881929ms]
Aug 27 18:37:40.452: INFO: Created: latency-svc-xpsxh
Aug 27 18:37:40.457: INFO: Got endpoints: latency-svc-xpsxh [154.540651ms]
Aug 27 18:37:40.461: INFO: Created: latency-svc-49vw7
Aug 27 18:37:40.467: INFO: Got endpoints: latency-svc-49vw7 [156.206429ms]
Aug 27 18:37:40.474: INFO: Created: latency-svc-vrlkz
Aug 27 18:37:40.479: INFO: Got endpoints: latency-svc-vrlkz [158.816258ms]
Aug 27 18:37:40.486: INFO: Created: latency-svc-7mpsj
Aug 27 18:37:40.491: INFO: Got endpoints: latency-svc-7mpsj [160.350453ms]
Aug 27 18:37:40.495: INFO: Created: latency-svc-s8vmf
Aug 27 18:37:40.500: INFO: Got endpoints: latency-svc-s8vmf [158.973437ms]
Aug 27 18:37:40.505: INFO: Created: latency-svc-tfh9f
Aug 27 18:37:40.510: INFO: Got endpoints: latency-svc-tfh9f [157.888787ms]
Aug 27 18:37:40.515: INFO: Created: latency-svc-5q8bx
Aug 27 18:37:40.520: INFO: Got endpoints: latency-svc-5q8bx [155.851538ms]
Aug 27 18:37:40.524: INFO: Created: latency-svc-2vlq9
Aug 27 18:37:40.529: INFO: Got endpoints: latency-svc-2vlq9 [154.8307ms]
Aug 27 18:37:40.535: INFO: Created: latency-svc-r9c2t
Aug 27 18:37:40.540: INFO: Got endpoints: latency-svc-r9c2t [155.684559ms]
Aug 27 18:37:40.546: INFO: Created: latency-svc-5t49r
Aug 27 18:37:40.550: INFO: Got endpoints: latency-svc-5t49r [152.667535ms]
Aug 27 18:37:40.557: INFO: Created: latency-svc-fww62
Aug 27 18:37:40.562: INFO: Got endpoints: latency-svc-fww62 [155.174472ms]
Aug 27 18:37:40.567: INFO: Created: latency-svc-2qkr4
Aug 27 18:37:40.572: INFO: Got endpoints: latency-svc-2qkr4 [152.259283ms]
Aug 27 18:37:40.578: INFO: Created: latency-svc-6qg6b
Aug 27 18:37:40.582: INFO: Got endpoints: latency-svc-6qg6b [156.982294ms]
Aug 27 18:37:40.588: INFO: Created: latency-svc-2ffg7
Aug 27 18:37:40.593: INFO: Got endpoints: latency-svc-2ffg7 [156.95461ms]
Aug 27 18:37:40.598: INFO: Created: latency-svc-lxnns
Aug 27 18:37:40.603: INFO: Got endpoints: latency-svc-lxnns [156.278566ms]
Aug 27 18:37:40.609: INFO: Created: latency-svc-d9v8w
Aug 27 18:37:40.614: INFO: Got endpoints: latency-svc-d9v8w [156.598021ms]
Aug 27 18:37:40.619: INFO: Created: latency-svc-5qbj5
Aug 27 18:37:40.637: INFO: Created: latency-svc-fdhmb
Aug 27 18:37:40.637: INFO: Got endpoints: latency-svc-fdhmb [158.32799ms]
Aug 27 18:37:40.637: INFO: Got endpoints: latency-svc-5qbj5 [170.631798ms]
Aug 27 18:37:40.641: INFO: Created: latency-svc-dfhn6
Aug 27 18:37:40.646: INFO: Got endpoints: latency-svc-dfhn6 [154.6927ms]
Aug 27 18:37:40.651: INFO: Created: latency-svc-wbnrf
Aug 27 18:37:40.656: INFO: Got endpoints: latency-svc-wbnrf [155.999687ms]
Aug 27 18:37:40.662: INFO: Created: latency-svc-pb6wj
Aug 27 18:37:40.668: INFO: Got endpoints: latency-svc-pb6wj [158.487273ms]
Aug 27 18:37:40.671: INFO: Created: latency-svc-7qfp6
Aug 27 18:37:40.676: INFO: Got endpoints: latency-svc-7qfp6 [155.919217ms]
Aug 27 18:37:40.683: INFO: Created: latency-svc-wnw86
Aug 27 18:37:40.688: INFO: Got endpoints: latency-svc-wnw86 [158.528354ms]
Aug 27 18:37:40.693: INFO: Created: latency-svc-nld5x
Aug 27 18:37:40.698: INFO: Got endpoints: latency-svc-nld5x [158.086944ms]
Aug 27 18:37:40.703: INFO: Created: latency-svc-x5fvz
Aug 27 18:37:40.708: INFO: Got endpoints: latency-svc-x5fvz [157.408847ms]
Aug 27 18:37:40.713: INFO: Created: latency-svc-5tlnq
Aug 27 18:37:40.718: INFO: Got endpoints: latency-svc-5tlnq [156.257889ms]
Aug 27 18:37:40.723: INFO: Created: latency-svc-jg687
Aug 27 18:37:40.728: INFO: Got endpoints: latency-svc-jg687 [156.552334ms]
Aug 27 18:37:40.734: INFO: Created: latency-svc-k59d9
Aug 27 18:37:40.739: INFO: Got endpoints: latency-svc-k59d9 [156.822352ms]
Aug 27 18:37:40.744: INFO: Created: latency-svc-g7f96
Aug 27 18:37:40.749: INFO: Got endpoints: latency-svc-g7f96 [155.85771ms]
Aug 27 18:37:40.754: INFO: Created: latency-svc-f9qkf
Aug 27 18:37:40.760: INFO: Got endpoints: latency-svc-f9qkf [156.371945ms]
Aug 27 18:37:40.765: INFO: Created: latency-svc-4pnmh
Aug 27 18:37:40.770: INFO: Got endpoints: latency-svc-4pnmh [155.906559ms]
Aug 27 18:37:40.775: INFO: Created: latency-svc-5fwmc
Aug 27 18:37:40.780: INFO: Got endpoints: latency-svc-5fwmc [142.706069ms]
Aug 27 18:37:40.786: INFO: Created: latency-svc-xzc4k
Aug 27 18:37:40.792: INFO: Got endpoints: latency-svc-xzc4k [154.682088ms]
Aug 27 18:37:40.795: INFO: Created: latency-svc-8hrnq
Aug 27 18:37:40.800: INFO: Got endpoints: latency-svc-8hrnq [154.159423ms]
Aug 27 18:37:40.806: INFO: Created: latency-svc-c4qf9
Aug 27 18:37:40.826: INFO: Got endpoints: latency-svc-c4qf9 [170.233594ms]
Aug 27 18:37:40.827: INFO: Created: latency-svc-s4526
Aug 27 18:37:40.827: INFO: Got endpoints: latency-svc-s4526 [158.447437ms]
Aug 27 18:37:40.827: INFO: Created: latency-svc-2tvgr
Aug 27 18:37:40.832: INFO: Got endpoints: latency-svc-2tvgr [156.017529ms]
Aug 27 18:37:40.838: INFO: Created: latency-svc-mxszc
Aug 27 18:37:40.846: INFO: Got endpoints: latency-svc-mxszc [158.29853ms]
Aug 27 18:37:40.848: INFO: Created: latency-svc-md24g
Aug 27 18:37:40.853: INFO: Got endpoints: latency-svc-md24g [155.143036ms]
Aug 27 18:37:40.859: INFO: Created: latency-svc-npq42
Aug 27 18:37:40.864: INFO: Got endpoints: latency-svc-npq42 [156.106283ms]
Aug 27 18:37:40.869: INFO: Created: latency-svc-7pdqp
Aug 27 18:37:40.874: INFO: Got endpoints: latency-svc-7pdqp [155.389336ms]
Aug 27 18:37:40.882: INFO: Created: latency-svc-vfkm6
Aug 27 18:37:40.887: INFO: Got endpoints: latency-svc-vfkm6 [158.217029ms]
Aug 27 18:37:40.892: INFO: Created: latency-svc-vgfcp
Aug 27 18:37:40.897: INFO: Got endpoints: latency-svc-vgfcp [157.305356ms]
Aug 27 18:37:40.903: INFO: Created: latency-svc-99x8p
Aug 27 18:37:40.907: INFO: Got endpoints: latency-svc-99x8p [157.596595ms]
Aug 27 18:37:40.914: INFO: Created: latency-svc-ktvq9
Aug 27 18:37:40.919: INFO: Got endpoints: latency-svc-ktvq9 [159.371943ms]
Aug 27 18:37:40.923: INFO: Created: latency-svc-tnll9
Aug 27 18:37:40.928: INFO: Got endpoints: latency-svc-tnll9 [157.899827ms]
Aug 27 18:37:40.933: INFO: Created: latency-svc-l4dwx
Aug 27 18:37:40.939: INFO: Got endpoints: latency-svc-l4dwx [158.748724ms]
Aug 27 18:37:40.943: INFO: Created: latency-svc-wfgt4
Aug 27 18:37:40.948: INFO: Got endpoints: latency-svc-wfgt4 [155.48337ms]
Aug 27 18:37:40.954: INFO: Created: latency-svc-g67gj
Aug 27 18:37:40.959: INFO: Got endpoints: latency-svc-g67gj [159.277924ms]
Aug 27 18:37:40.964: INFO: Created: latency-svc-q94nh
Aug 27 18:37:40.969: INFO: Got endpoints: latency-svc-q94nh [142.749715ms]
Aug 27 18:37:40.974: INFO: Created: latency-svc-h7gw2
Aug 27 18:37:40.980: INFO: Got endpoints: latency-svc-h7gw2 [153.286208ms]
Aug 27 18:37:40.985: INFO: Created: latency-svc-j2l7v
Aug 27 18:37:40.990: INFO: Got endpoints: latency-svc-j2l7v [157.507101ms]
Aug 27 18:37:41.004: INFO: Created: latency-svc-5v87c
Aug 27 18:37:41.004: INFO: Got endpoints: latency-svc-5v87c [157.977394ms]
Aug 27 18:37:41.006: INFO: Created: latency-svc-2kpnf
Aug 27 18:37:41.011: INFO: Got endpoints: latency-svc-2kpnf [158.16151ms]
Aug 27 18:37:41.017: INFO: Created: latency-svc-tpq2r
Aug 27 18:37:41.022: INFO: Got endpoints: latency-svc-tpq2r [157.899377ms]
Aug 27 18:37:41.028: INFO: Created: latency-svc-n2xqx
Aug 27 18:37:41.033: INFO: Got endpoints: latency-svc-n2xqx [159.309063ms]
Aug 27 18:37:41.038: INFO: Created: latency-svc-8gb6q
Aug 27 18:37:41.050: INFO: Got endpoints: latency-svc-8gb6q [163.19317ms]
Aug 27 18:37:41.050: INFO: Created: latency-svc-nfscx
Aug 27 18:37:41.053: INFO: Got endpoints: latency-svc-nfscx [156.550519ms]
Aug 27 18:37:41.059: INFO: Created: latency-svc-tk88f
Aug 27 18:37:41.064: INFO: Got endpoints: latency-svc-tk88f [156.969901ms]
Aug 27 18:37:41.068: INFO: Created: latency-svc-rdz4t
Aug 27 18:37:41.073: INFO: Got endpoints: latency-svc-rdz4t [154.049562ms]
Aug 27 18:37:41.078: INFO: Created: latency-svc-zs589
Aug 27 18:37:41.083: INFO: Got endpoints: latency-svc-zs589 [155.744193ms]
Aug 27 18:37:41.088: INFO: Created: latency-svc-cm8wj
Aug 27 18:37:41.093: INFO: Got endpoints: latency-svc-cm8wj [154.403237ms]
Aug 27 18:37:41.099: INFO: Created: latency-svc-7nnzs
Aug 27 18:37:41.105: INFO: Got endpoints: latency-svc-7nnzs [157.187823ms]
Aug 27 18:37:41.111: INFO: Created: latency-svc-zdtx5
Aug 27 18:37:41.116: INFO: Got endpoints: latency-svc-zdtx5 [156.528072ms]
Aug 27 18:37:41.120: INFO: Created: latency-svc-26wft
Aug 27 18:37:41.124: INFO: Got endpoints: latency-svc-26wft [154.428392ms]
Aug 27 18:37:41.130: INFO: Created: latency-svc-rv82k
Aug 27 18:37:41.136: INFO: Got endpoints: latency-svc-rv82k [155.689265ms]
Aug 27 18:37:41.217: INFO: Created: latency-svc-2fd7x
Aug 27 18:37:41.217: INFO: Created: latency-svc-brlx6
Aug 27 18:37:41.217: INFO: Created: latency-svc-c4cg7
Aug 27 18:37:41.218: INFO: Got endpoints: latency-svc-2fd7x [213.319879ms]
Aug 27 18:37:41.218: INFO: Got endpoints: latency-svc-brlx6 [227.748973ms]
Aug 27 18:37:41.218: INFO: Created: latency-svc-6ndl4
Aug 27 18:37:41.218: INFO: Created: latency-svc-l8vb6
Aug 27 18:37:41.218: INFO: Got endpoints: latency-svc-c4cg7 [206.460342ms]
Aug 27 18:37:41.218: INFO: Created: latency-svc-lw7sv
Aug 27 18:37:41.218: INFO: Got endpoints: latency-svc-lw7sv [185.469213ms]
Aug 27 18:37:41.218: INFO: Got endpoints: latency-svc-6ndl4 [165.151732ms]
Aug 27 18:37:41.219: INFO: Got endpoints: latency-svc-l8vb6 [168.620156ms]
Aug 27 18:37:41.219: INFO: Created: latency-svc-zl847
Aug 27 18:37:41.219: INFO: Got endpoints: latency-svc-zl847 [196.640792ms]
Aug 27 18:37:41.220: INFO: Created: latency-svc-gmxd5
Aug 27 18:37:41.222: INFO: Got endpoints: latency-svc-gmxd5 [158.250909ms]
Aug 27 18:37:41.227: INFO: Created: latency-svc-8f4b4
Aug 27 18:37:41.232: INFO: Got endpoints: latency-svc-8f4b4 [158.57333ms]
Aug 27 18:37:41.238: INFO: Created: latency-svc-slr7j
Aug 27 18:37:41.243: INFO: Got endpoints: latency-svc-slr7j [159.320527ms]
Aug 27 18:37:41.248: INFO: Created: latency-svc-jmnsh
Aug 27 18:37:41.252: INFO: Got endpoints: latency-svc-jmnsh [158.660601ms]
Aug 27 18:37:41.260: INFO: Created: latency-svc-cg5gn
Aug 27 18:37:41.265: INFO: Got endpoints: latency-svc-cg5gn [159.857501ms]
Aug 27 18:37:41.269: INFO: Created: latency-svc-xp8l8
Aug 27 18:37:41.274: INFO: Got endpoints: latency-svc-xp8l8 [157.719523ms]
Aug 27 18:37:41.279: INFO: Created: latency-svc-ncr66
Aug 27 18:37:41.283: INFO: Got endpoints: latency-svc-ncr66 [159.509761ms]
Aug 27 18:37:41.290: INFO: Created: latency-svc-8gbfb
Aug 27 18:37:41.295: INFO: Got endpoints: latency-svc-8gbfb [158.784384ms]
Aug 27 18:37:41.300: INFO: Created: latency-svc-rtgwk
Aug 27 18:37:41.305: INFO: Got endpoints: latency-svc-rtgwk [87.481892ms]
Aug 27 18:37:41.310: INFO: Created: latency-svc-q8zkc
Aug 27 18:37:41.315: INFO: Got endpoints: latency-svc-q8zkc [96.237221ms]
Aug 27 18:37:41.321: INFO: Created: latency-svc-54xf9
Aug 27 18:37:41.336: INFO: Created: latency-svc-clrh5
Aug 27 18:37:41.336: INFO: Got endpoints: latency-svc-clrh5 [117.555061ms]
Aug 27 18:37:41.336: INFO: Got endpoints: latency-svc-54xf9 [118.276491ms]
Aug 27 18:37:41.341: INFO: Created: latency-svc-snmlr
Aug 27 18:37:41.347: INFO: Got endpoints: latency-svc-snmlr [128.12481ms]
Aug 27 18:37:41.352: INFO: Created: latency-svc-gt56c
Aug 27 18:37:41.357: INFO: Got endpoints: latency-svc-gt56c [138.46049ms]
Aug 27 18:37:41.362: INFO: Created: latency-svc-twqf9
Aug 27 18:37:41.366: INFO: Got endpoints: latency-svc-twqf9 [148.012456ms]
Aug 27 18:37:41.366: INFO: Latencies: [29.119698ms 30.391516ms 37.158697ms 39.647894ms 50.406126ms 58.885711ms 69.242066ms 78.986105ms 87.481892ms 89.906004ms 96.237221ms 99.50566ms 100.259525ms 109.449478ms 111.624847ms 117.555061ms 118.276491ms 120.128955ms 121.986429ms 128.12481ms 130.506316ms 132.318606ms 135.347402ms 138.46049ms 140.208914ms 142.305351ms 142.706069ms 142.749715ms 142.813759ms 147.062031ms 147.385532ms 148.012456ms 148.607684ms 149.695425ms 150.023844ms 150.212791ms 150.596533ms 150.655272ms 151.05658ms 151.096074ms 151.107357ms 151.152108ms 151.165282ms 151.345073ms 151.48383ms 151.64377ms 151.765367ms 151.82455ms 151.846905ms 151.881929ms 152.058468ms 152.259283ms 152.667535ms 152.844807ms 152.858772ms 152.91097ms 153.019963ms 153.158432ms 153.17437ms 153.286208ms 153.359169ms 153.363827ms 153.446795ms 153.620924ms 153.963163ms 154.019356ms 154.023392ms 154.049562ms 154.050008ms 154.159423ms 154.403237ms 154.428392ms 154.457065ms 154.540651ms 154.581544ms 154.682088ms 154.6927ms 154.718787ms 154.80078ms 154.8307ms 154.964356ms 155.070946ms 155.143036ms 155.143418ms 155.174472ms 155.248673ms 155.249354ms 155.253117ms 155.326867ms 155.389336ms 155.48337ms 155.635971ms 155.684559ms 155.689265ms 155.744193ms 155.787787ms 155.851538ms 155.85771ms 155.860487ms 155.906559ms 155.919217ms 155.965101ms 155.977487ms 155.999687ms 156.017529ms 156.106283ms 156.160127ms 156.187498ms 156.206429ms 156.222587ms 156.257889ms 156.278566ms 156.371945ms 156.479741ms 156.528072ms 156.550519ms 156.552334ms 156.591594ms 156.598021ms 156.822352ms 156.95461ms 156.969063ms 156.969901ms 156.982294ms 157.187823ms 157.210637ms 157.305356ms 157.407295ms 157.408847ms 157.507101ms 157.576445ms 157.596595ms 157.707037ms 157.719523ms 157.807708ms 157.840337ms 157.863087ms 157.888787ms 157.899377ms 157.899827ms 157.977394ms 158.086944ms 158.16151ms 158.217029ms 158.250909ms 158.29853ms 158.32799ms 158.447437ms 158.487273ms 158.488234ms 158.492941ms 158.528354ms 158.57333ms 158.660601ms 158.748724ms 158.784384ms 158.816258ms 158.973437ms 159.161394ms 159.277924ms 159.309063ms 159.320527ms 159.371943ms 159.509761ms 159.605754ms 159.857501ms 160.350453ms 161.33886ms 161.3698ms 162.548328ms 163.19317ms 164.981814ms 165.151732ms 165.382786ms 165.442975ms 165.94141ms 166.040002ms 166.226523ms 167.393123ms 167.871691ms 168.614807ms 168.620156ms 169.120267ms 170.233594ms 170.446556ms 170.631798ms 171.566955ms 172.348831ms 176.79887ms 178.710015ms 180.015885ms 185.469213ms 188.096473ms 196.640792ms 197.315241ms 206.460342ms 208.204297ms 213.319879ms 227.748973ms 281.27378ms]
Aug 27 18:37:41.367: INFO: 50 %ile: 155.919217ms
Aug 27 18:37:41.367: INFO: 90 %ile: 168.614807ms
Aug 27 18:37:41.367: INFO: 99 %ile: 227.748973ms
Aug 27 18:37:41.367: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 18:37:41.367: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svc-latency-2924" for this suite.
Aug 27 18:38:07.422: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 18:38:07.808: INFO: namespace svc-latency-2924 deletion completed in 26.428802011s

• [SLOW TEST:30.956 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should not be very high  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 18:38:07.808: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-6452
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: validating cluster-info
Aug 27 18:38:08.023: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-540514467 cluster-info'
Aug 27 18:38:08.168: INFO: stderr: ""
Aug 27 18:38:08.168: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://172.21.0.1:443\x1b[0m\n\x1b[0;32mCoreDNS\x1b[0m is running at \x1b[0;33mhttps://172.21.0.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\x1b[0;32mkubernetes-dashboard\x1b[0m is running at \x1b[0;33mhttps://172.21.0.1:443/api/v1/namespaces/kube-system/services/https:kubernetes-dashboard:/proxy\x1b[0m\n\x1b[0;32mMetrics-server\x1b[0m is running at \x1b[0;33mhttps://172.21.0.1:443/api/v1/namespaces/kube-system/services/https:metrics-server:/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 18:38:08.168: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6452" for this suite.
Aug 27 18:38:14.225: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 18:38:14.575: INFO: namespace kubectl-6452 deletion completed in 6.392355493s

• [SLOW TEST:6.767 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl cluster-info
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 18:38:14.575: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6690
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-0e942156-5e78-458c-a8be-0dda410036ec
STEP: Creating a pod to test consume configMaps
Aug 27 18:38:14.839: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-0a13e453-4c2f-429d-8ed6-b6f731e98639" in namespace "projected-6690" to be "success or failure"
Aug 27 18:38:14.848: INFO: Pod "pod-projected-configmaps-0a13e453-4c2f-429d-8ed6-b6f731e98639": Phase="Pending", Reason="", readiness=false. Elapsed: 9.488938ms
Aug 27 18:38:16.859: INFO: Pod "pod-projected-configmaps-0a13e453-4c2f-429d-8ed6-b6f731e98639": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020250167s
Aug 27 18:38:19.081: INFO: Pod "pod-projected-configmaps-0a13e453-4c2f-429d-8ed6-b6f731e98639": Phase="Pending", Reason="", readiness=false. Elapsed: 4.241876707s
Aug 27 18:38:21.090: INFO: Pod "pod-projected-configmaps-0a13e453-4c2f-429d-8ed6-b6f731e98639": Phase="Pending", Reason="", readiness=false. Elapsed: 6.251605228s
Aug 27 18:38:23.101: INFO: Pod "pod-projected-configmaps-0a13e453-4c2f-429d-8ed6-b6f731e98639": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.262593209s
STEP: Saw pod success
Aug 27 18:38:23.101: INFO: Pod "pod-projected-configmaps-0a13e453-4c2f-429d-8ed6-b6f731e98639" satisfied condition "success or failure"
Aug 27 18:38:23.111: INFO: Trying to get logs from node 10.138.3.233 pod pod-projected-configmaps-0a13e453-4c2f-429d-8ed6-b6f731e98639 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Aug 27 18:38:23.156: INFO: Waiting for pod pod-projected-configmaps-0a13e453-4c2f-429d-8ed6-b6f731e98639 to disappear
Aug 27 18:38:23.166: INFO: Pod pod-projected-configmaps-0a13e453-4c2f-429d-8ed6-b6f731e98639 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 18:38:23.166: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6690" for this suite.
Aug 27 18:38:29.236: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 18:38:29.625: INFO: namespace projected-6690 deletion completed in 6.43558663s

• [SLOW TEST:15.050 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 18:38:29.627: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-3476
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test use defaults
Aug 27 18:38:29.866: INFO: Waiting up to 5m0s for pod "client-containers-42b8e9c2-e199-4f34-a722-98f7bf95c373" in namespace "containers-3476" to be "success or failure"
Aug 27 18:38:29.876: INFO: Pod "client-containers-42b8e9c2-e199-4f34-a722-98f7bf95c373": Phase="Pending", Reason="", readiness=false. Elapsed: 9.733424ms
Aug 27 18:38:31.886: INFO: Pod "client-containers-42b8e9c2-e199-4f34-a722-98f7bf95c373": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020056441s
Aug 27 18:38:33.896: INFO: Pod "client-containers-42b8e9c2-e199-4f34-a722-98f7bf95c373": Phase="Pending", Reason="", readiness=false. Elapsed: 4.030306704s
Aug 27 18:38:35.913: INFO: Pod "client-containers-42b8e9c2-e199-4f34-a722-98f7bf95c373": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.046599271s
STEP: Saw pod success
Aug 27 18:38:35.913: INFO: Pod "client-containers-42b8e9c2-e199-4f34-a722-98f7bf95c373" satisfied condition "success or failure"
Aug 27 18:38:35.922: INFO: Trying to get logs from node 10.138.3.242 pod client-containers-42b8e9c2-e199-4f34-a722-98f7bf95c373 container test-container: <nil>
STEP: delete the pod
Aug 27 18:38:35.966: INFO: Waiting for pod client-containers-42b8e9c2-e199-4f34-a722-98f7bf95c373 to disappear
Aug 27 18:38:35.977: INFO: Pod client-containers-42b8e9c2-e199-4f34-a722-98f7bf95c373 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 18:38:35.977: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-3476" for this suite.
Aug 27 18:38:42.038: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 18:38:42.400: INFO: namespace containers-3476 deletion completed in 6.406717151s

• [SLOW TEST:12.773 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 18:38:42.404: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-8271
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name s-test-opt-del-79b188b2-8add-4500-8b08-0091b7dec56d
STEP: Creating secret with name s-test-opt-upd-dd56fdd2-5492-4c96-b523-d06aab8deaf1
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-79b188b2-8add-4500-8b08-0091b7dec56d
STEP: Updating secret s-test-opt-upd-dd56fdd2-5492-4c96-b523-d06aab8deaf1
STEP: Creating secret with name s-test-opt-create-ad1fa8df-d018-40dd-bdb3-02eef54c975c
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 18:39:57.696: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8271" for this suite.
Aug 27 18:40:21.759: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 18:40:22.121: INFO: namespace secrets-8271 deletion completed in 24.406919317s

• [SLOW TEST:99.717 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 18:40:22.123: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svcaccounts-1806
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: getting the auto-created API token
Aug 27 18:40:22.904: INFO: created pod pod-service-account-defaultsa
Aug 27 18:40:22.904: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Aug 27 18:40:22.915: INFO: created pod pod-service-account-mountsa
Aug 27 18:40:22.915: INFO: pod pod-service-account-mountsa service account token volume mount: true
Aug 27 18:40:22.926: INFO: created pod pod-service-account-nomountsa
Aug 27 18:40:22.926: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Aug 27 18:40:22.937: INFO: created pod pod-service-account-defaultsa-mountspec
Aug 27 18:40:22.937: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Aug 27 18:40:22.948: INFO: created pod pod-service-account-mountsa-mountspec
Aug 27 18:40:22.948: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Aug 27 18:40:22.959: INFO: created pod pod-service-account-nomountsa-mountspec
Aug 27 18:40:22.959: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Aug 27 18:40:22.970: INFO: created pod pod-service-account-defaultsa-nomountspec
Aug 27 18:40:22.970: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Aug 27 18:40:22.981: INFO: created pod pod-service-account-mountsa-nomountspec
Aug 27 18:40:22.981: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Aug 27 18:40:22.991: INFO: created pod pod-service-account-nomountsa-nomountspec
Aug 27 18:40:22.991: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 18:40:22.992: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-1806" for this suite.
Aug 27 18:40:29.060: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 18:40:29.437: INFO: namespace svcaccounts-1806 deletion completed in 6.428787158s

• [SLOW TEST:7.314 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:23
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 18:40:29.440: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5811
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name cm-test-opt-del-2992b7ee-4012-4947-9ca9-8b984a60ed91
STEP: Creating configMap with name cm-test-opt-upd-47f19557-640b-4562-b7e2-0cb433953d20
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-2992b7ee-4012-4947-9ca9-8b984a60ed91
STEP: Updating configmap cm-test-opt-upd-47f19557-640b-4562-b7e2-0cb433953d20
STEP: Creating configMap with name cm-test-opt-create-2859f3db-d9af-4be5-b976-233141ab678f
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 18:41:36.621: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5811" for this suite.
Aug 27 18:42:00.683: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 18:42:01.036: INFO: namespace projected-5811 deletion completed in 24.397897207s

• [SLOW TEST:91.596 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 18:42:01.036: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8689
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating the pod
Aug 27 18:42:03.867: INFO: Successfully updated pod "annotationupdate1b7ca7e9-8238-4d78-a26a-946b0156ac6a"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 18:42:05.909: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8689" for this suite.
Aug 27 18:42:29.972: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 18:42:30.368: INFO: namespace projected-8689 deletion completed in 24.439335846s

• [SLOW TEST:29.333 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 18:42:30.369: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-74
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Performing setup for networking test in namespace pod-network-test-74
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Aug 27 18:42:30.594: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Aug 27 18:42:56.846: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.37.198:8080/dial?request=hostName&protocol=http&host=172.30.145.63&port=8080&tries=1'] Namespace:pod-network-test-74 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 27 18:42:56.847: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
Aug 27 18:42:57.211: INFO: Waiting for endpoints: map[]
Aug 27 18:42:57.221: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.37.198:8080/dial?request=hostName&protocol=http&host=172.30.37.200&port=8080&tries=1'] Namespace:pod-network-test-74 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 27 18:42:57.221: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
Aug 27 18:42:57.517: INFO: Waiting for endpoints: map[]
Aug 27 18:42:57.532: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.37.198:8080/dial?request=hostName&protocol=http&host=172.30.115.59&port=8080&tries=1'] Namespace:pod-network-test-74 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 27 18:42:57.532: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
Aug 27 18:42:57.836: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 18:42:57.836: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-74" for this suite.
Aug 27 18:43:21.896: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 18:43:22.261: INFO: namespace pod-network-test-74 deletion completed in 24.408841052s

• [SLOW TEST:51.892 seconds]
[sig-network] Networking
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 18:43:22.262: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-757
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Aug 27 18:43:22.486: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-540514467 version'
Aug 27 18:43:22.595: INFO: stderr: ""
Aug 27 18:43:22.595: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"15\", GitVersion:\"v1.15.3\", GitCommit:\"2d3c76f9091b6bec110a5e63777c332469e0cba2\", GitTreeState:\"clean\", BuildDate:\"2019-08-19T11:13:54Z\", GoVersion:\"go1.12.9\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"15\", GitVersion:\"v1.15.3+IKS\", GitCommit:\"66a72e7aa8fd2dbf64af493f50f943d7f7067916\", GitTreeState:\"clean\", BuildDate:\"2019-08-23T08:07:38Z\", GoVersion:\"go1.12.9\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 18:43:22.595: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-757" for this suite.
Aug 27 18:43:28.652: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 18:43:29.017: INFO: namespace kubectl-757 deletion completed in 6.409605363s

• [SLOW TEST:6.755 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl version
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 18:43:29.017: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-2205
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Aug 27 18:43:29.264: INFO: Waiting up to 5m0s for pod "downward-api-34064aa4-8a37-4424-a581-c980e1da73ee" in namespace "downward-api-2205" to be "success or failure"
Aug 27 18:43:29.276: INFO: Pod "downward-api-34064aa4-8a37-4424-a581-c980e1da73ee": Phase="Pending", Reason="", readiness=false. Elapsed: 11.267517ms
Aug 27 18:43:31.291: INFO: Pod "downward-api-34064aa4-8a37-4424-a581-c980e1da73ee": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.026776159s
STEP: Saw pod success
Aug 27 18:43:31.291: INFO: Pod "downward-api-34064aa4-8a37-4424-a581-c980e1da73ee" satisfied condition "success or failure"
Aug 27 18:43:31.301: INFO: Trying to get logs from node 10.138.3.233 pod downward-api-34064aa4-8a37-4424-a581-c980e1da73ee container dapi-container: <nil>
STEP: delete the pod
Aug 27 18:43:31.346: INFO: Waiting for pod downward-api-34064aa4-8a37-4424-a581-c980e1da73ee to disappear
Aug 27 18:43:31.365: INFO: Pod downward-api-34064aa4-8a37-4424-a581-c980e1da73ee no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 18:43:31.365: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2205" for this suite.
Aug 27 18:43:37.421: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 18:43:37.804: INFO: namespace downward-api-2205 deletion completed in 6.424697318s

• [SLOW TEST:8.787 seconds]
[sig-node] Downward API
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 18:43:37.812: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-2548
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating secret secrets-2548/secret-test-08b6bc99-c51b-4ae5-a1aa-81414935c1a8
STEP: Creating a pod to test consume secrets
Aug 27 18:43:38.069: INFO: Waiting up to 5m0s for pod "pod-configmaps-b8e7b4f9-91a6-4d8e-96c0-04ec0322b94a" in namespace "secrets-2548" to be "success or failure"
Aug 27 18:43:38.079: INFO: Pod "pod-configmaps-b8e7b4f9-91a6-4d8e-96c0-04ec0322b94a": Phase="Pending", Reason="", readiness=false. Elapsed: 10.043407ms
Aug 27 18:43:40.090: INFO: Pod "pod-configmaps-b8e7b4f9-91a6-4d8e-96c0-04ec0322b94a": Phase="Running", Reason="", readiness=true. Elapsed: 2.020436925s
Aug 27 18:43:42.101: INFO: Pod "pod-configmaps-b8e7b4f9-91a6-4d8e-96c0-04ec0322b94a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.031805113s
STEP: Saw pod success
Aug 27 18:43:42.101: INFO: Pod "pod-configmaps-b8e7b4f9-91a6-4d8e-96c0-04ec0322b94a" satisfied condition "success or failure"
Aug 27 18:43:42.111: INFO: Trying to get logs from node 10.138.3.242 pod pod-configmaps-b8e7b4f9-91a6-4d8e-96c0-04ec0322b94a container env-test: <nil>
STEP: delete the pod
Aug 27 18:43:42.158: INFO: Waiting for pod pod-configmaps-b8e7b4f9-91a6-4d8e-96c0-04ec0322b94a to disappear
Aug 27 18:43:42.275: INFO: Pod pod-configmaps-b8e7b4f9-91a6-4d8e-96c0-04ec0322b94a no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 18:43:42.275: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-2548" for this suite.
Aug 27 18:43:48.343: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 18:43:48.714: INFO: namespace secrets-2548 deletion completed in 6.415959998s

• [SLOW TEST:10.901 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 18:43:48.714: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-3220
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test override all
Aug 27 18:43:48.947: INFO: Waiting up to 5m0s for pod "client-containers-0db7b5d1-aa03-46b1-82db-a0f1213c0f80" in namespace "containers-3220" to be "success or failure"
Aug 27 18:43:48.959: INFO: Pod "client-containers-0db7b5d1-aa03-46b1-82db-a0f1213c0f80": Phase="Pending", Reason="", readiness=false. Elapsed: 11.33348ms
Aug 27 18:43:50.969: INFO: Pod "client-containers-0db7b5d1-aa03-46b1-82db-a0f1213c0f80": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021720711s
Aug 27 18:43:52.979: INFO: Pod "client-containers-0db7b5d1-aa03-46b1-82db-a0f1213c0f80": Phase="Pending", Reason="", readiness=false. Elapsed: 4.031945017s
Aug 27 18:43:54.990: INFO: Pod "client-containers-0db7b5d1-aa03-46b1-82db-a0f1213c0f80": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.042361588s
STEP: Saw pod success
Aug 27 18:43:54.990: INFO: Pod "client-containers-0db7b5d1-aa03-46b1-82db-a0f1213c0f80" satisfied condition "success or failure"
Aug 27 18:43:55.000: INFO: Trying to get logs from node 10.138.3.233 pod client-containers-0db7b5d1-aa03-46b1-82db-a0f1213c0f80 container test-container: <nil>
STEP: delete the pod
Aug 27 18:43:55.047: INFO: Waiting for pod client-containers-0db7b5d1-aa03-46b1-82db-a0f1213c0f80 to disappear
Aug 27 18:43:55.056: INFO: Pod client-containers-0db7b5d1-aa03-46b1-82db-a0f1213c0f80 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 18:43:55.056: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-3220" for this suite.
Aug 27 18:44:01.117: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 18:44:01.490: INFO: namespace containers-3220 deletion completed in 6.417388698s

• [SLOW TEST:12.776 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 18:44:01.490: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-516
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-map-8cc82779-953b-462d-ba05-c1dda7fbeaf9
STEP: Creating a pod to test consume configMaps
Aug 27 18:44:01.911: INFO: Waiting up to 5m0s for pod "pod-configmaps-f91bb5fd-0214-4f04-8b77-2c8ae37ee556" in namespace "configmap-516" to be "success or failure"
Aug 27 18:44:01.921: INFO: Pod "pod-configmaps-f91bb5fd-0214-4f04-8b77-2c8ae37ee556": Phase="Pending", Reason="", readiness=false. Elapsed: 9.50569ms
Aug 27 18:44:03.931: INFO: Pod "pod-configmaps-f91bb5fd-0214-4f04-8b77-2c8ae37ee556": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.019614372s
STEP: Saw pod success
Aug 27 18:44:03.931: INFO: Pod "pod-configmaps-f91bb5fd-0214-4f04-8b77-2c8ae37ee556" satisfied condition "success or failure"
Aug 27 18:44:03.941: INFO: Trying to get logs from node 10.138.3.242 pod pod-configmaps-f91bb5fd-0214-4f04-8b77-2c8ae37ee556 container configmap-volume-test: <nil>
STEP: delete the pod
Aug 27 18:44:03.985: INFO: Waiting for pod pod-configmaps-f91bb5fd-0214-4f04-8b77-2c8ae37ee556 to disappear
Aug 27 18:44:03.995: INFO: Pod pod-configmaps-f91bb5fd-0214-4f04-8b77-2c8ae37ee556 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 18:44:03.995: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-516" for this suite.
Aug 27 18:44:10.054: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 18:44:10.423: INFO: namespace configmap-516 deletion completed in 6.41444343s

• [SLOW TEST:8.933 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 18:44:10.425: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-2482
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Aug 27 18:44:10.726: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Aug 27 18:44:10.747: INFO: Number of nodes with available pods: 0
Aug 27 18:44:10.747: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Aug 27 18:44:10.793: INFO: Number of nodes with available pods: 0
Aug 27 18:44:10.793: INFO: Node 10.138.3.199 is running more than one daemon pod
Aug 27 18:44:11.804: INFO: Number of nodes with available pods: 0
Aug 27 18:44:11.804: INFO: Node 10.138.3.199 is running more than one daemon pod
Aug 27 18:44:12.804: INFO: Number of nodes with available pods: 1
Aug 27 18:44:12.804: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Aug 27 18:44:12.851: INFO: Number of nodes with available pods: 1
Aug 27 18:44:12.851: INFO: Number of running nodes: 0, number of available pods: 1
Aug 27 18:44:13.861: INFO: Number of nodes with available pods: 0
Aug 27 18:44:13.861: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Aug 27 18:44:13.886: INFO: Number of nodes with available pods: 0
Aug 27 18:44:13.886: INFO: Node 10.138.3.199 is running more than one daemon pod
Aug 27 18:44:14.896: INFO: Number of nodes with available pods: 0
Aug 27 18:44:14.896: INFO: Node 10.138.3.199 is running more than one daemon pod
Aug 27 18:44:15.896: INFO: Number of nodes with available pods: 0
Aug 27 18:44:15.896: INFO: Node 10.138.3.199 is running more than one daemon pod
Aug 27 18:44:16.896: INFO: Number of nodes with available pods: 0
Aug 27 18:44:16.896: INFO: Node 10.138.3.199 is running more than one daemon pod
Aug 27 18:44:17.896: INFO: Number of nodes with available pods: 0
Aug 27 18:44:17.896: INFO: Node 10.138.3.199 is running more than one daemon pod
Aug 27 18:44:18.896: INFO: Number of nodes with available pods: 1
Aug 27 18:44:18.896: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-2482, will wait for the garbage collector to delete the pods
Aug 27 18:44:19.010: INFO: Deleting DaemonSet.extensions daemon-set took: 32.851553ms
Aug 27 18:44:19.110: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.352113ms
Aug 27 18:44:22.821: INFO: Number of nodes with available pods: 0
Aug 27 18:44:22.821: INFO: Number of running nodes: 0, number of available pods: 0
Aug 27 18:44:22.833: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-2482/daemonsets","resourceVersion":"25096"},"items":null}

Aug 27 18:44:22.843: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-2482/pods","resourceVersion":"25096"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 18:44:22.911: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-2482" for this suite.
Aug 27 18:44:28.970: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 18:44:29.368: INFO: namespace daemonsets-2482 deletion completed in 6.440652391s

• [SLOW TEST:18.943 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 18:44:29.372: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-5740
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1457
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Aug 27 18:44:29.598: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-540514467 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=kubectl-5740'
Aug 27 18:44:29.737: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Aug 27 18:44:29.737: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: verifying the pod controlled by rc e2e-test-nginx-rc was created
STEP: confirm that you can get logs from an rc
Aug 27 18:44:29.772: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-75s79]
Aug 27 18:44:29.772: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-75s79" in namespace "kubectl-5740" to be "running and ready"
Aug 27 18:44:29.781: INFO: Pod "e2e-test-nginx-rc-75s79": Phase="Pending", Reason="", readiness=false. Elapsed: 9.134842ms
Aug 27 18:44:31.791: INFO: Pod "e2e-test-nginx-rc-75s79": Phase="Running", Reason="", readiness=true. Elapsed: 2.019811163s
Aug 27 18:44:31.792: INFO: Pod "e2e-test-nginx-rc-75s79" satisfied condition "running and ready"
Aug 27 18:44:31.792: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-75s79]
Aug 27 18:44:31.792: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-540514467 logs rc/e2e-test-nginx-rc --namespace=kubectl-5740'
Aug 27 18:44:31.949: INFO: stderr: ""
Aug 27 18:44:31.949: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1462
Aug 27 18:44:31.949: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-540514467 delete rc e2e-test-nginx-rc --namespace=kubectl-5740'
Aug 27 18:44:32.114: INFO: stderr: ""
Aug 27 18:44:32.114: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 18:44:32.114: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5740" for this suite.
Aug 27 18:44:56.177: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 18:44:56.585: INFO: namespace kubectl-5740 deletion completed in 24.451586941s

• [SLOW TEST:27.212 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run rc
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 18:44:56.585: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-4427
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name projected-secret-test-fdb66bc5-d451-4269-8f26-d627f293c4b6
STEP: Creating a pod to test consume secrets
Aug 27 18:44:56.832: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-17ac9c75-b124-47d4-808c-18765653901c" in namespace "projected-4427" to be "success or failure"
Aug 27 18:44:56.841: INFO: Pod "pod-projected-secrets-17ac9c75-b124-47d4-808c-18765653901c": Phase="Pending", Reason="", readiness=false. Elapsed: 9.328947ms
Aug 27 18:44:58.853: INFO: Pod "pod-projected-secrets-17ac9c75-b124-47d4-808c-18765653901c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020667578s
STEP: Saw pod success
Aug 27 18:44:58.853: INFO: Pod "pod-projected-secrets-17ac9c75-b124-47d4-808c-18765653901c" satisfied condition "success or failure"
Aug 27 18:44:58.862: INFO: Trying to get logs from node 10.138.3.242 pod pod-projected-secrets-17ac9c75-b124-47d4-808c-18765653901c container secret-volume-test: <nil>
STEP: delete the pod
Aug 27 18:44:58.906: INFO: Waiting for pod pod-projected-secrets-17ac9c75-b124-47d4-808c-18765653901c to disappear
Aug 27 18:44:58.916: INFO: Pod pod-projected-secrets-17ac9c75-b124-47d4-808c-18765653901c no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 18:44:58.916: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4427" for this suite.
Aug 27 18:45:04.979: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 18:45:05.365: INFO: namespace projected-4427 deletion completed in 6.434417336s

• [SLOW TEST:8.780 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 18:45:05.366: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-3259
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test substitution in container's args
Aug 27 18:45:05.612: INFO: Waiting up to 5m0s for pod "var-expansion-8546038a-0d85-421a-803b-5b4d2842160d" in namespace "var-expansion-3259" to be "success or failure"
Aug 27 18:45:05.623: INFO: Pod "var-expansion-8546038a-0d85-421a-803b-5b4d2842160d": Phase="Pending", Reason="", readiness=false. Elapsed: 11.430759ms
Aug 27 18:45:07.634: INFO: Pod "var-expansion-8546038a-0d85-421a-803b-5b4d2842160d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021938792s
STEP: Saw pod success
Aug 27 18:45:07.634: INFO: Pod "var-expansion-8546038a-0d85-421a-803b-5b4d2842160d" satisfied condition "success or failure"
Aug 27 18:45:07.643: INFO: Trying to get logs from node 10.138.3.233 pod var-expansion-8546038a-0d85-421a-803b-5b4d2842160d container dapi-container: <nil>
STEP: delete the pod
Aug 27 18:45:07.693: INFO: Waiting for pod var-expansion-8546038a-0d85-421a-803b-5b4d2842160d to disappear
Aug 27 18:45:07.705: INFO: Pod var-expansion-8546038a-0d85-421a-803b-5b4d2842160d no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 18:45:07.705: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-3259" for this suite.
Aug 27 18:45:13.764: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 18:45:14.124: INFO: namespace var-expansion-3259 deletion completed in 6.404113482s

• [SLOW TEST:8.758 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 18:45:14.125: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-5697
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating the pod
Aug 27 18:45:18.941: INFO: Successfully updated pod "labelsupdate65af5b74-560e-4273-a6b2-1f1fdc183468"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 18:45:20.986: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5697" for this suite.
Aug 27 18:45:45.044: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 18:45:45.456: INFO: namespace downward-api-5697 deletion completed in 24.455271925s

• [SLOW TEST:31.332 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 18:45:45.458: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-7432
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: executing a command with run --rm and attach with stdin
Aug 27 18:45:45.754: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-540514467 --namespace=kubectl-7432 run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Aug 27 18:45:47.660: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Aug 27 18:45:47.660: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 18:45:49.689: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7432" for this suite.
Aug 27 18:45:59.753: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 18:46:00.217: INFO: namespace kubectl-7432 deletion completed in 10.512662618s

• [SLOW TEST:14.759 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run --rm job
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 18:46:00.217: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-4436
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Aug 27 18:46:00.456: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 18:46:04.812: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-4436" for this suite.
Aug 27 18:46:44.875: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 18:46:45.254: INFO: namespace pods-4436 deletion completed in 40.427128765s

• [SLOW TEST:45.037 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 18:46:45.259: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-9157
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Aug 27 18:46:45.563: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-9157,SelfLink:/api/v1/namespaces/watch-9157/configmaps/e2e-watch-test-label-changed,UID:197d0a83-81e4-468e-a516-1d90d55b4fdf,ResourceVersion:25598,Generation:0,CreationTimestamp:2019-08-27 18:46:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Aug 27 18:46:45.563: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-9157,SelfLink:/api/v1/namespaces/watch-9157/configmaps/e2e-watch-test-label-changed,UID:197d0a83-81e4-468e-a516-1d90d55b4fdf,ResourceVersion:25599,Generation:0,CreationTimestamp:2019-08-27 18:46:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Aug 27 18:46:45.563: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-9157,SelfLink:/api/v1/namespaces/watch-9157/configmaps/e2e-watch-test-label-changed,UID:197d0a83-81e4-468e-a516-1d90d55b4fdf,ResourceVersion:25600,Generation:0,CreationTimestamp:2019-08-27 18:46:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Aug 27 18:46:55.644: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-9157,SelfLink:/api/v1/namespaces/watch-9157/configmaps/e2e-watch-test-label-changed,UID:197d0a83-81e4-468e-a516-1d90d55b4fdf,ResourceVersion:25620,Generation:0,CreationTimestamp:2019-08-27 18:46:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Aug 27 18:46:55.644: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-9157,SelfLink:/api/v1/namespaces/watch-9157/configmaps/e2e-watch-test-label-changed,UID:197d0a83-81e4-468e-a516-1d90d55b4fdf,ResourceVersion:25621,Generation:0,CreationTimestamp:2019-08-27 18:46:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Aug 27 18:46:55.644: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-9157,SelfLink:/api/v1/namespaces/watch-9157/configmaps/e2e-watch-test-label-changed,UID:197d0a83-81e4-468e-a516-1d90d55b4fdf,ResourceVersion:25622,Generation:0,CreationTimestamp:2019-08-27 18:46:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 18:46:55.644: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-9157" for this suite.
Aug 27 18:47:01.707: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 18:47:02.171: INFO: namespace watch-9157 deletion completed in 6.512003642s

• [SLOW TEST:16.913 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 18:47:02.173: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-7003
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:273
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a replication controller
Aug 27 18:47:02.394: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-540514467 create -f - --namespace=kubectl-7003'
Aug 27 18:47:02.728: INFO: stderr: ""
Aug 27 18:47:02.728: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Aug 27 18:47:02.728: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-540514467 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7003'
Aug 27 18:47:02.856: INFO: stderr: ""
Aug 27 18:47:02.856: INFO: stdout: "update-demo-nautilus-2v8gb update-demo-nautilus-7nwg2 "
Aug 27 18:47:02.856: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-540514467 get pods update-demo-nautilus-2v8gb -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7003'
Aug 27 18:47:02.993: INFO: stderr: ""
Aug 27 18:47:02.993: INFO: stdout: ""
Aug 27 18:47:02.993: INFO: update-demo-nautilus-2v8gb is created but not running
Aug 27 18:47:07.993: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-540514467 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7003'
Aug 27 18:47:08.125: INFO: stderr: ""
Aug 27 18:47:08.125: INFO: stdout: "update-demo-nautilus-2v8gb update-demo-nautilus-7nwg2 "
Aug 27 18:47:08.125: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-540514467 get pods update-demo-nautilus-2v8gb -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7003'
Aug 27 18:47:08.256: INFO: stderr: ""
Aug 27 18:47:08.256: INFO: stdout: ""
Aug 27 18:47:08.256: INFO: update-demo-nautilus-2v8gb is created but not running
Aug 27 18:47:13.257: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-540514467 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7003'
Aug 27 18:47:13.387: INFO: stderr: ""
Aug 27 18:47:13.387: INFO: stdout: "update-demo-nautilus-2v8gb update-demo-nautilus-7nwg2 "
Aug 27 18:47:13.387: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-540514467 get pods update-demo-nautilus-2v8gb -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7003'
Aug 27 18:47:13.536: INFO: stderr: ""
Aug 27 18:47:13.536: INFO: stdout: "true"
Aug 27 18:47:13.536: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-540514467 get pods update-demo-nautilus-2v8gb -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7003'
Aug 27 18:47:13.669: INFO: stderr: ""
Aug 27 18:47:13.669: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Aug 27 18:47:13.669: INFO: validating pod update-demo-nautilus-2v8gb
Aug 27 18:47:13.687: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug 27 18:47:13.687: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug 27 18:47:13.687: INFO: update-demo-nautilus-2v8gb is verified up and running
Aug 27 18:47:13.687: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-540514467 get pods update-demo-nautilus-7nwg2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7003'
Aug 27 18:47:13.802: INFO: stderr: ""
Aug 27 18:47:13.802: INFO: stdout: "true"
Aug 27 18:47:13.802: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-540514467 get pods update-demo-nautilus-7nwg2 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7003'
Aug 27 18:47:13.931: INFO: stderr: ""
Aug 27 18:47:13.931: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Aug 27 18:47:13.931: INFO: validating pod update-demo-nautilus-7nwg2
Aug 27 18:47:13.953: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug 27 18:47:13.953: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug 27 18:47:13.953: INFO: update-demo-nautilus-7nwg2 is verified up and running
STEP: scaling down the replication controller
Aug 27 18:47:13.955: INFO: scanned /root for discovery docs: <nil>
Aug 27 18:47:13.956: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-540514467 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=kubectl-7003'
Aug 27 18:47:15.141: INFO: stderr: ""
Aug 27 18:47:15.141: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Aug 27 18:47:15.142: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-540514467 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7003'
Aug 27 18:47:15.280: INFO: stderr: ""
Aug 27 18:47:15.280: INFO: stdout: "update-demo-nautilus-2v8gb update-demo-nautilus-7nwg2 "
STEP: Replicas for name=update-demo: expected=1 actual=2
Aug 27 18:47:20.280: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-540514467 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7003'
Aug 27 18:47:20.411: INFO: stderr: ""
Aug 27 18:47:20.411: INFO: stdout: "update-demo-nautilus-7nwg2 "
Aug 27 18:47:20.411: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-540514467 get pods update-demo-nautilus-7nwg2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7003'
Aug 27 18:47:20.535: INFO: stderr: ""
Aug 27 18:47:20.535: INFO: stdout: "true"
Aug 27 18:47:20.535: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-540514467 get pods update-demo-nautilus-7nwg2 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7003'
Aug 27 18:47:20.765: INFO: stderr: ""
Aug 27 18:47:20.765: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Aug 27 18:47:20.765: INFO: validating pod update-demo-nautilus-7nwg2
Aug 27 18:47:20.782: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug 27 18:47:20.782: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug 27 18:47:20.782: INFO: update-demo-nautilus-7nwg2 is verified up and running
STEP: scaling up the replication controller
Aug 27 18:47:20.784: INFO: scanned /root for discovery docs: <nil>
Aug 27 18:47:20.784: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-540514467 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=kubectl-7003'
Aug 27 18:47:21.957: INFO: stderr: ""
Aug 27 18:47:21.957: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Aug 27 18:47:21.957: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-540514467 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7003'
Aug 27 18:47:22.094: INFO: stderr: ""
Aug 27 18:47:22.094: INFO: stdout: "update-demo-nautilus-7nwg2 update-demo-nautilus-pw8c4 "
Aug 27 18:47:22.094: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-540514467 get pods update-demo-nautilus-7nwg2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7003'
Aug 27 18:47:22.214: INFO: stderr: ""
Aug 27 18:47:22.215: INFO: stdout: "true"
Aug 27 18:47:22.215: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-540514467 get pods update-demo-nautilus-7nwg2 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7003'
Aug 27 18:47:22.329: INFO: stderr: ""
Aug 27 18:47:22.329: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Aug 27 18:47:22.329: INFO: validating pod update-demo-nautilus-7nwg2
Aug 27 18:47:22.343: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug 27 18:47:22.343: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug 27 18:47:22.343: INFO: update-demo-nautilus-7nwg2 is verified up and running
Aug 27 18:47:22.344: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-540514467 get pods update-demo-nautilus-pw8c4 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7003'
Aug 27 18:47:22.488: INFO: stderr: ""
Aug 27 18:47:22.488: INFO: stdout: ""
Aug 27 18:47:22.488: INFO: update-demo-nautilus-pw8c4 is created but not running
Aug 27 18:47:27.489: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-540514467 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7003'
Aug 27 18:47:27.616: INFO: stderr: ""
Aug 27 18:47:27.616: INFO: stdout: "update-demo-nautilus-7nwg2 update-demo-nautilus-pw8c4 "
Aug 27 18:47:27.616: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-540514467 get pods update-demo-nautilus-7nwg2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7003'
Aug 27 18:47:27.734: INFO: stderr: ""
Aug 27 18:47:27.734: INFO: stdout: "true"
Aug 27 18:47:27.734: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-540514467 get pods update-demo-nautilus-7nwg2 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7003'
Aug 27 18:47:27.853: INFO: stderr: ""
Aug 27 18:47:27.853: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Aug 27 18:47:27.853: INFO: validating pod update-demo-nautilus-7nwg2
Aug 27 18:47:27.868: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug 27 18:47:27.868: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug 27 18:47:27.868: INFO: update-demo-nautilus-7nwg2 is verified up and running
Aug 27 18:47:27.868: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-540514467 get pods update-demo-nautilus-pw8c4 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7003'
Aug 27 18:47:28.000: INFO: stderr: ""
Aug 27 18:47:28.000: INFO: stdout: "true"
Aug 27 18:47:28.000: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-540514467 get pods update-demo-nautilus-pw8c4 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7003'
Aug 27 18:47:28.119: INFO: stderr: ""
Aug 27 18:47:28.119: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Aug 27 18:47:28.119: INFO: validating pod update-demo-nautilus-pw8c4
Aug 27 18:47:28.137: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug 27 18:47:28.137: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug 27 18:47:28.137: INFO: update-demo-nautilus-pw8c4 is verified up and running
STEP: using delete to clean up resources
Aug 27 18:47:28.137: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-540514467 delete --grace-period=0 --force -f - --namespace=kubectl-7003'
Aug 27 18:47:28.288: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 27 18:47:28.288: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Aug 27 18:47:28.288: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-540514467 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-7003'
Aug 27 18:47:28.420: INFO: stderr: "No resources found.\n"
Aug 27 18:47:28.420: INFO: stdout: ""
Aug 27 18:47:28.420: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-540514467 get pods -l name=update-demo --namespace=kubectl-7003 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Aug 27 18:47:28.545: INFO: stderr: ""
Aug 27 18:47:28.545: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 18:47:28.545: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7003" for this suite.
Aug 27 18:47:52.608: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 18:47:52.972: INFO: namespace kubectl-7003 deletion completed in 24.408904076s

• [SLOW TEST:50.800 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 18:47:52.973: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-2054
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: validating api versions
Aug 27 18:47:53.192: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-540514467 api-versions'
Aug 27 18:47:53.327: INFO: stderr: ""
Aug 27 18:47:53.327: INFO: stdout: "admissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\napps/v1beta1\napps/v1beta2\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\nbatch/v2alpha1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1\ncoordination.k8s.io/v1beta1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nmetrics.k8s.io/v1beta1\nnetworking.k8s.io/v1\nnetworking.k8s.io/v1beta1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 18:47:53.327: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2054" for this suite.
Aug 27 18:47:59.384: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 18:47:59.759: INFO: namespace kubectl-2054 deletion completed in 6.42028811s

• [SLOW TEST:6.787 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl api-versions
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 18:47:59.761: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-8113
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0666 on node default medium
Aug 27 18:47:59.995: INFO: Waiting up to 5m0s for pod "pod-3206dc85-d345-463b-8bdd-a27fef5ec0bf" in namespace "emptydir-8113" to be "success or failure"
Aug 27 18:48:00.006: INFO: Pod "pod-3206dc85-d345-463b-8bdd-a27fef5ec0bf": Phase="Pending", Reason="", readiness=false. Elapsed: 10.407587ms
Aug 27 18:48:02.017: INFO: Pod "pod-3206dc85-d345-463b-8bdd-a27fef5ec0bf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021304282s
STEP: Saw pod success
Aug 27 18:48:02.017: INFO: Pod "pod-3206dc85-d345-463b-8bdd-a27fef5ec0bf" satisfied condition "success or failure"
Aug 27 18:48:02.026: INFO: Trying to get logs from node 10.138.3.242 pod pod-3206dc85-d345-463b-8bdd-a27fef5ec0bf container test-container: <nil>
STEP: delete the pod
Aug 27 18:48:02.075: INFO: Waiting for pod pod-3206dc85-d345-463b-8bdd-a27fef5ec0bf to disappear
Aug 27 18:48:02.093: INFO: Pod pod-3206dc85-d345-463b-8bdd-a27fef5ec0bf no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 18:48:02.093: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8113" for this suite.
Aug 27 18:48:08.154: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 18:48:08.552: INFO: namespace emptydir-8113 deletion completed in 6.443394064s

• [SLOW TEST:8.791 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 18:48:08.553: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-4913
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-4913.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-4913.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Aug 27 18:48:12.942: INFO: DNS probes using dns-4913/dns-test-2102249c-ba50-49b5-8908-339de1ef0ba9 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 18:48:12.969: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-4913" for this suite.
Aug 27 18:48:19.029: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 18:48:19.424: INFO: namespace dns-4913 deletion completed in 6.439216359s

• [SLOW TEST:10.870 seconds]
[sig-network] DNS
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 18:48:19.424: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9620
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Aug 27 18:48:19.674: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d7a908b7-baba-4bad-95f7-847d352f093c" in namespace "projected-9620" to be "success or failure"
Aug 27 18:48:19.685: INFO: Pod "downwardapi-volume-d7a908b7-baba-4bad-95f7-847d352f093c": Phase="Pending", Reason="", readiness=false. Elapsed: 11.44571ms
Aug 27 18:48:21.696: INFO: Pod "downwardapi-volume-d7a908b7-baba-4bad-95f7-847d352f093c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022128701s
Aug 27 18:48:23.712: INFO: Pod "downwardapi-volume-d7a908b7-baba-4bad-95f7-847d352f093c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.038784841s
STEP: Saw pod success
Aug 27 18:48:23.712: INFO: Pod "downwardapi-volume-d7a908b7-baba-4bad-95f7-847d352f093c" satisfied condition "success or failure"
Aug 27 18:48:23.722: INFO: Trying to get logs from node 10.138.3.242 pod downwardapi-volume-d7a908b7-baba-4bad-95f7-847d352f093c container client-container: <nil>
STEP: delete the pod
Aug 27 18:48:23.766: INFO: Waiting for pod downwardapi-volume-d7a908b7-baba-4bad-95f7-847d352f093c to disappear
Aug 27 18:48:23.775: INFO: Pod downwardapi-volume-d7a908b7-baba-4bad-95f7-847d352f093c no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 18:48:23.775: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9620" for this suite.
Aug 27 18:48:29.835: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 18:48:30.283: INFO: namespace projected-9620 deletion completed in 6.492707814s

• [SLOW TEST:10.859 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 18:48:30.283: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-181
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Aug 27 18:48:30.531: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-181,SelfLink:/api/v1/namespaces/watch-181/configmaps/e2e-watch-test-configmap-a,UID:30a4851f-f0cd-49a2-a3ef-26c600b67966,ResourceVersion:26046,Generation:0,CreationTimestamp:2019-08-27 18:48:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Aug 27 18:48:30.531: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-181,SelfLink:/api/v1/namespaces/watch-181/configmaps/e2e-watch-test-configmap-a,UID:30a4851f-f0cd-49a2-a3ef-26c600b67966,ResourceVersion:26046,Generation:0,CreationTimestamp:2019-08-27 18:48:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Aug 27 18:48:40.552: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-181,SelfLink:/api/v1/namespaces/watch-181/configmaps/e2e-watch-test-configmap-a,UID:30a4851f-f0cd-49a2-a3ef-26c600b67966,ResourceVersion:26063,Generation:0,CreationTimestamp:2019-08-27 18:48:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Aug 27 18:48:40.552: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-181,SelfLink:/api/v1/namespaces/watch-181/configmaps/e2e-watch-test-configmap-a,UID:30a4851f-f0cd-49a2-a3ef-26c600b67966,ResourceVersion:26063,Generation:0,CreationTimestamp:2019-08-27 18:48:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Aug 27 18:48:50.592: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-181,SelfLink:/api/v1/namespaces/watch-181/configmaps/e2e-watch-test-configmap-a,UID:30a4851f-f0cd-49a2-a3ef-26c600b67966,ResourceVersion:26082,Generation:0,CreationTimestamp:2019-08-27 18:48:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Aug 27 18:48:50.592: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-181,SelfLink:/api/v1/namespaces/watch-181/configmaps/e2e-watch-test-configmap-a,UID:30a4851f-f0cd-49a2-a3ef-26c600b67966,ResourceVersion:26082,Generation:0,CreationTimestamp:2019-08-27 18:48:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Aug 27 18:49:00.614: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-181,SelfLink:/api/v1/namespaces/watch-181/configmaps/e2e-watch-test-configmap-a,UID:30a4851f-f0cd-49a2-a3ef-26c600b67966,ResourceVersion:26101,Generation:0,CreationTimestamp:2019-08-27 18:48:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Aug 27 18:49:00.614: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-181,SelfLink:/api/v1/namespaces/watch-181/configmaps/e2e-watch-test-configmap-a,UID:30a4851f-f0cd-49a2-a3ef-26c600b67966,ResourceVersion:26101,Generation:0,CreationTimestamp:2019-08-27 18:48:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Aug 27 18:49:10.633: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-181,SelfLink:/api/v1/namespaces/watch-181/configmaps/e2e-watch-test-configmap-b,UID:0ad09f27-947d-42ee-945a-b316d3f6902d,ResourceVersion:26119,Generation:0,CreationTimestamp:2019-08-27 18:49:10 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Aug 27 18:49:10.633: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-181,SelfLink:/api/v1/namespaces/watch-181/configmaps/e2e-watch-test-configmap-b,UID:0ad09f27-947d-42ee-945a-b316d3f6902d,ResourceVersion:26119,Generation:0,CreationTimestamp:2019-08-27 18:49:10 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Aug 27 18:49:20.653: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-181,SelfLink:/api/v1/namespaces/watch-181/configmaps/e2e-watch-test-configmap-b,UID:0ad09f27-947d-42ee-945a-b316d3f6902d,ResourceVersion:26136,Generation:0,CreationTimestamp:2019-08-27 18:49:10 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Aug 27 18:49:20.653: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-181,SelfLink:/api/v1/namespaces/watch-181/configmaps/e2e-watch-test-configmap-b,UID:0ad09f27-947d-42ee-945a-b316d3f6902d,ResourceVersion:26136,Generation:0,CreationTimestamp:2019-08-27 18:49:10 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 18:49:30.654: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-181" for this suite.
Aug 27 18:49:36.713: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 18:49:37.096: INFO: namespace watch-181 deletion completed in 6.426753027s

• [SLOW TEST:66.813 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-api-machinery] Secrets 
  should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 18:49:37.096: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-7215
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name secret-emptykey-test-3fc97ff7-d8d5-49fd-8bef-4430450bc640
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 18:49:37.325: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7215" for this suite.
Aug 27 18:49:43.383: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 18:49:43.747: INFO: namespace secrets-7215 deletion completed in 6.409957533s

• [SLOW TEST:6.651 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 18:49:43.748: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svcaccounts-2619
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: getting the auto-created API token
STEP: reading a file in the container
Aug 27 18:49:46.569: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-2619 pod-service-account-a4788cd9-31e0-4ebd-a013-5859efa0aa53 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
STEP: reading a file in the container
Aug 27 18:49:46.995: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-2619 pod-service-account-a4788cd9-31e0-4ebd-a013-5859efa0aa53 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
STEP: reading a file in the container
Aug 27 18:49:47.471: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-2619 pod-service-account-a4788cd9-31e0-4ebd-a013-5859efa0aa53 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 18:49:47.963: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-2619" for this suite.
Aug 27 18:49:54.021: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 18:49:54.382: INFO: namespace svcaccounts-2619 deletion completed in 6.404166712s

• [SLOW TEST:10.634 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:23
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 18:49:54.382: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-8632
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Aug 27 18:49:54.615: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6e61a9a7-9519-4f23-9a4f-7e00f63f52c5" in namespace "downward-api-8632" to be "success or failure"
Aug 27 18:49:54.624: INFO: Pod "downwardapi-volume-6e61a9a7-9519-4f23-9a4f-7e00f63f52c5": Phase="Pending", Reason="", readiness=false. Elapsed: 9.241856ms
Aug 27 18:49:56.635: INFO: Pod "downwardapi-volume-6e61a9a7-9519-4f23-9a4f-7e00f63f52c5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020024583s
STEP: Saw pod success
Aug 27 18:49:56.635: INFO: Pod "downwardapi-volume-6e61a9a7-9519-4f23-9a4f-7e00f63f52c5" satisfied condition "success or failure"
Aug 27 18:49:56.646: INFO: Trying to get logs from node 10.138.3.242 pod downwardapi-volume-6e61a9a7-9519-4f23-9a4f-7e00f63f52c5 container client-container: <nil>
STEP: delete the pod
Aug 27 18:49:56.693: INFO: Waiting for pod downwardapi-volume-6e61a9a7-9519-4f23-9a4f-7e00f63f52c5 to disappear
Aug 27 18:49:56.703: INFO: Pod downwardapi-volume-6e61a9a7-9519-4f23-9a4f-7e00f63f52c5 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 18:49:56.703: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8632" for this suite.
Aug 27 18:50:02.762: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 18:50:03.122: INFO: namespace downward-api-8632 deletion completed in 6.405078472s

• [SLOW TEST:8.741 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 18:50:03.123: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-3422
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Aug 27 18:50:03.479: INFO: Number of nodes with available pods: 0
Aug 27 18:50:03.479: INFO: Node 10.138.3.199 is running more than one daemon pod
Aug 27 18:50:04.517: INFO: Number of nodes with available pods: 0
Aug 27 18:50:04.517: INFO: Node 10.138.3.199 is running more than one daemon pod
Aug 27 18:50:05.513: INFO: Number of nodes with available pods: 3
Aug 27 18:50:05.513: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Stop a daemon pod, check that the daemon pod is revived.
Aug 27 18:50:05.578: INFO: Number of nodes with available pods: 2
Aug 27 18:50:05.578: INFO: Node 10.138.3.233 is running more than one daemon pod
Aug 27 18:50:06.603: INFO: Number of nodes with available pods: 2
Aug 27 18:50:06.603: INFO: Node 10.138.3.233 is running more than one daemon pod
Aug 27 18:50:07.604: INFO: Number of nodes with available pods: 2
Aug 27 18:50:07.604: INFO: Node 10.138.3.233 is running more than one daemon pod
Aug 27 18:50:08.605: INFO: Number of nodes with available pods: 2
Aug 27 18:50:08.605: INFO: Node 10.138.3.233 is running more than one daemon pod
Aug 27 18:50:09.603: INFO: Number of nodes with available pods: 2
Aug 27 18:50:09.604: INFO: Node 10.138.3.233 is running more than one daemon pod
Aug 27 18:50:10.603: INFO: Number of nodes with available pods: 2
Aug 27 18:50:10.604: INFO: Node 10.138.3.233 is running more than one daemon pod
Aug 27 18:50:11.616: INFO: Number of nodes with available pods: 2
Aug 27 18:50:11.616: INFO: Node 10.138.3.233 is running more than one daemon pod
Aug 27 18:50:12.603: INFO: Number of nodes with available pods: 2
Aug 27 18:50:12.603: INFO: Node 10.138.3.233 is running more than one daemon pod
Aug 27 18:50:13.603: INFO: Number of nodes with available pods: 2
Aug 27 18:50:13.603: INFO: Node 10.138.3.233 is running more than one daemon pod
Aug 27 18:50:14.603: INFO: Number of nodes with available pods: 2
Aug 27 18:50:14.603: INFO: Node 10.138.3.233 is running more than one daemon pod
Aug 27 18:50:15.604: INFO: Number of nodes with available pods: 2
Aug 27 18:50:15.604: INFO: Node 10.138.3.233 is running more than one daemon pod
Aug 27 18:50:16.603: INFO: Number of nodes with available pods: 2
Aug 27 18:50:16.603: INFO: Node 10.138.3.233 is running more than one daemon pod
Aug 27 18:50:17.603: INFO: Number of nodes with available pods: 2
Aug 27 18:50:17.603: INFO: Node 10.138.3.233 is running more than one daemon pod
Aug 27 18:50:18.607: INFO: Number of nodes with available pods: 2
Aug 27 18:50:18.607: INFO: Node 10.138.3.233 is running more than one daemon pod
Aug 27 18:50:19.605: INFO: Number of nodes with available pods: 2
Aug 27 18:50:19.605: INFO: Node 10.138.3.233 is running more than one daemon pod
Aug 27 18:50:20.603: INFO: Number of nodes with available pods: 3
Aug 27 18:50:20.603: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-3422, will wait for the garbage collector to delete the pods
Aug 27 18:50:20.696: INFO: Deleting DaemonSet.extensions daemon-set took: 21.011007ms
Aug 27 18:50:20.797: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.29892ms
Aug 27 18:50:33.806: INFO: Number of nodes with available pods: 0
Aug 27 18:50:33.806: INFO: Number of running nodes: 0, number of available pods: 0
Aug 27 18:50:33.816: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-3422/daemonsets","resourceVersion":"26460"},"items":null}

Aug 27 18:50:33.826: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-3422/pods","resourceVersion":"26460"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 18:50:33.870: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-3422" for this suite.
Aug 27 18:50:39.928: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 18:50:40.557: INFO: namespace daemonsets-3422 deletion completed in 6.672251452s

• [SLOW TEST:37.434 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 18:50:40.559: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-1601
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:179
[It] should be submitted and removed  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 18:50:40.801: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-1601" for this suite.
Aug 27 18:51:04.859: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 18:51:05.225: INFO: namespace pods-1601 deletion completed in 24.408536214s

• [SLOW TEST:24.666 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should be submitted and removed  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 18:51:05.225: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-8105
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test substitution in container's command
Aug 27 18:51:05.472: INFO: Waiting up to 5m0s for pod "var-expansion-25c38fcf-cd8e-477f-9839-dc24c6bb099c" in namespace "var-expansion-8105" to be "success or failure"
Aug 27 18:51:05.482: INFO: Pod "var-expansion-25c38fcf-cd8e-477f-9839-dc24c6bb099c": Phase="Pending", Reason="", readiness=false. Elapsed: 9.958368ms
Aug 27 18:51:07.492: INFO: Pod "var-expansion-25c38fcf-cd8e-477f-9839-dc24c6bb099c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020365975s
STEP: Saw pod success
Aug 27 18:51:07.492: INFO: Pod "var-expansion-25c38fcf-cd8e-477f-9839-dc24c6bb099c" satisfied condition "success or failure"
Aug 27 18:51:07.502: INFO: Trying to get logs from node 10.138.3.242 pod var-expansion-25c38fcf-cd8e-477f-9839-dc24c6bb099c container dapi-container: <nil>
STEP: delete the pod
Aug 27 18:51:07.546: INFO: Waiting for pod var-expansion-25c38fcf-cd8e-477f-9839-dc24c6bb099c to disappear
Aug 27 18:51:07.555: INFO: Pod var-expansion-25c38fcf-cd8e-477f-9839-dc24c6bb099c no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 18:51:07.555: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-8105" for this suite.
Aug 27 18:51:13.644: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 18:51:13.996: INFO: namespace var-expansion-8105 deletion completed in 6.423295613s

• [SLOW TEST:8.771 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 18:51:13.997: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-7222
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Performing setup for networking test in namespace pod-network-test-7222
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Aug 27 18:51:14.222: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Aug 27 18:51:38.446: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://172.30.115.14:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-7222 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 27 18:51:38.446: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
Aug 27 18:51:38.783: INFO: Found all expected endpoints: [netserver-0]
Aug 27 18:51:38.794: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://172.30.37.212:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-7222 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 27 18:51:38.794: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
Aug 27 18:51:39.129: INFO: Found all expected endpoints: [netserver-1]
Aug 27 18:51:39.139: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://172.30.145.7:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-7222 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 27 18:51:39.139: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
Aug 27 18:51:39.536: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 18:51:39.536: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-7222" for this suite.
Aug 27 18:52:03.597: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 18:52:04.019: INFO: namespace pod-network-test-7222 deletion completed in 24.467386951s

• [SLOW TEST:50.023 seconds]
[sig-network] Networking
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 18:52:04.021: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-1614
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secret-namespace-4916
STEP: Creating secret with name secret-test-f1f84b86-82db-46a4-8e1c-975b03e15967
STEP: Creating a pod to test consume secrets
Aug 27 18:52:04.501: INFO: Waiting up to 5m0s for pod "pod-secrets-0ea7dc4a-68b9-425f-bc90-7b3464d3c8da" in namespace "secrets-1614" to be "success or failure"
Aug 27 18:52:04.511: INFO: Pod "pod-secrets-0ea7dc4a-68b9-425f-bc90-7b3464d3c8da": Phase="Pending", Reason="", readiness=false. Elapsed: 10.526931ms
Aug 27 18:52:06.522: INFO: Pod "pod-secrets-0ea7dc4a-68b9-425f-bc90-7b3464d3c8da": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021534287s
STEP: Saw pod success
Aug 27 18:52:06.523: INFO: Pod "pod-secrets-0ea7dc4a-68b9-425f-bc90-7b3464d3c8da" satisfied condition "success or failure"
Aug 27 18:52:06.532: INFO: Trying to get logs from node 10.138.3.233 pod pod-secrets-0ea7dc4a-68b9-425f-bc90-7b3464d3c8da container secret-volume-test: <nil>
STEP: delete the pod
Aug 27 18:52:06.583: INFO: Waiting for pod pod-secrets-0ea7dc4a-68b9-425f-bc90-7b3464d3c8da to disappear
Aug 27 18:52:06.593: INFO: Pod pod-secrets-0ea7dc4a-68b9-425f-bc90-7b3464d3c8da no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 18:52:06.593: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-1614" for this suite.
Aug 27 18:52:12.661: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 18:52:13.018: INFO: namespace secrets-1614 deletion completed in 6.409815907s
STEP: Destroying namespace "secret-namespace-4916" for this suite.
Aug 27 18:52:19.063: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 18:52:19.438: INFO: namespace secret-namespace-4916 deletion completed in 6.420247676s

• [SLOW TEST:15.417 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 18:52:19.439: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7152
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-dd34fec2-a601-4a7e-a91d-5a7c5b59e3f3
STEP: Creating a pod to test consume secrets
Aug 27 18:52:19.687: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-80365d93-9b04-4b43-9cb4-2f0447164bce" in namespace "projected-7152" to be "success or failure"
Aug 27 18:52:19.698: INFO: Pod "pod-projected-secrets-80365d93-9b04-4b43-9cb4-2f0447164bce": Phase="Pending", Reason="", readiness=false. Elapsed: 10.504404ms
Aug 27 18:52:21.708: INFO: Pod "pod-projected-secrets-80365d93-9b04-4b43-9cb4-2f0447164bce": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.02072215s
STEP: Saw pod success
Aug 27 18:52:21.708: INFO: Pod "pod-projected-secrets-80365d93-9b04-4b43-9cb4-2f0447164bce" satisfied condition "success or failure"
Aug 27 18:52:21.718: INFO: Trying to get logs from node 10.138.3.242 pod pod-projected-secrets-80365d93-9b04-4b43-9cb4-2f0447164bce container projected-secret-volume-test: <nil>
STEP: delete the pod
Aug 27 18:52:21.769: INFO: Waiting for pod pod-projected-secrets-80365d93-9b04-4b43-9cb4-2f0447164bce to disappear
Aug 27 18:52:21.779: INFO: Pod pod-projected-secrets-80365d93-9b04-4b43-9cb4-2f0447164bce no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 18:52:21.779: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7152" for this suite.
Aug 27 18:52:27.837: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 18:52:28.190: INFO: namespace projected-7152 deletion completed in 6.396108311s

• [SLOW TEST:8.751 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 18:52:28.193: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-137
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Aug 27 18:52:31.005: INFO: Successfully updated pod "pod-update-207a44e9-4235-448a-9add-0887f578ffcf"
STEP: verifying the updated pod is in kubernetes
Aug 27 18:52:31.026: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 18:52:31.026: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-137" for this suite.
Aug 27 18:52:55.085: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 18:52:55.489: INFO: namespace pods-137 deletion completed in 24.447980787s

• [SLOW TEST:27.297 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] version v1
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 18:52:55.490: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-2916
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Aug 27 18:52:55.740: INFO: (0) /api/v1/nodes/10.138.3.199/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 20.638995ms)
Aug 27 18:52:55.767: INFO: (1) /api/v1/nodes/10.138.3.199/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 26.905199ms)
Aug 27 18:52:55.782: INFO: (2) /api/v1/nodes/10.138.3.199/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 15.321753ms)
Aug 27 18:52:55.797: INFO: (3) /api/v1/nodes/10.138.3.199/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 14.782991ms)
Aug 27 18:52:55.812: INFO: (4) /api/v1/nodes/10.138.3.199/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 14.857199ms)
Aug 27 18:52:55.827: INFO: (5) /api/v1/nodes/10.138.3.199/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 14.800616ms)
Aug 27 18:52:55.844: INFO: (6) /api/v1/nodes/10.138.3.199/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 16.555551ms)
Aug 27 18:52:55.858: INFO: (7) /api/v1/nodes/10.138.3.199/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 14.850554ms)
Aug 27 18:52:55.875: INFO: (8) /api/v1/nodes/10.138.3.199/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 16.941369ms)
Aug 27 18:52:55.890: INFO: (9) /api/v1/nodes/10.138.3.199/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 14.695773ms)
Aug 27 18:52:55.905: INFO: (10) /api/v1/nodes/10.138.3.199/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 14.870484ms)
Aug 27 18:52:55.922: INFO: (11) /api/v1/nodes/10.138.3.199/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 17.071068ms)
Aug 27 18:52:55.951: INFO: (12) /api/v1/nodes/10.138.3.199/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 20.206016ms)
Aug 27 18:52:55.977: INFO: (13) /api/v1/nodes/10.138.3.199/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 26.297816ms)
Aug 27 18:52:55.993: INFO: (14) /api/v1/nodes/10.138.3.199/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 15.441322ms)
Aug 27 18:52:56.009: INFO: (15) /api/v1/nodes/10.138.3.199/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 15.718885ms)
Aug 27 18:52:56.024: INFO: (16) /api/v1/nodes/10.138.3.199/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 15.10487ms)
Aug 27 18:52:56.039: INFO: (17) /api/v1/nodes/10.138.3.199/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 15.349982ms)
Aug 27 18:52:56.054: INFO: (18) /api/v1/nodes/10.138.3.199/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 14.51038ms)
Aug 27 18:52:56.092: INFO: (19) /api/v1/nodes/10.138.3.199/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 37.602825ms)
[AfterEach] version v1
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 18:52:56.092: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-2916" for this suite.
Aug 27 18:53:02.148: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 18:53:02.526: INFO: namespace proxy-2916 deletion completed in 6.42171803s

• [SLOW TEST:7.036 seconds]
[sig-network] Proxy
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:58
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 18:53:02.526: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename hostpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in hostpath-9096
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test hostPath mode
Aug 27 18:53:02.761: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "hostpath-9096" to be "success or failure"
Aug 27 18:53:02.775: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 13.727656ms
Aug 27 18:53:04.786: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.02415829s
STEP: Saw pod success
Aug 27 18:53:04.786: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Aug 27 18:53:04.819: INFO: Trying to get logs from node 10.138.3.242 pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Aug 27 18:53:04.870: INFO: Waiting for pod pod-host-path-test to disappear
Aug 27 18:53:04.879: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 18:53:04.879: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "hostpath-9096" for this suite.
Aug 27 18:53:10.940: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 18:53:11.319: INFO: namespace hostpath-9096 deletion completed in 6.425287374s

• [SLOW TEST:8.793 seconds]
[sig-storage] HostPath
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 18:53:11.319: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-4609
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name cm-test-opt-del-38fd9ad9-cc10-4af8-af63-0c2a9ce4a50f
STEP: Creating configMap with name cm-test-opt-upd-03e04fcc-c6b7-4200-8c05-723531a93585
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-38fd9ad9-cc10-4af8-af63-0c2a9ce4a50f
STEP: Updating configmap cm-test-opt-upd-03e04fcc-c6b7-4200-8c05-723531a93585
STEP: Creating configMap with name cm-test-opt-create-8210a036-031b-4372-a0c8-c33de45c0a4b
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 18:54:42.769: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4609" for this suite.
Aug 27 18:55:06.832: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 18:55:07.236: INFO: namespace configmap-4609 deletion completed in 24.448598038s

• [SLOW TEST:115.917 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 18:55:07.236: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-kubelet-etc-hosts-289
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Aug 27 18:55:15.566: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-289 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 27 18:55:15.566: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
Aug 27 18:55:15.899: INFO: Exec stderr: ""
Aug 27 18:55:15.899: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-289 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 27 18:55:15.899: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
Aug 27 18:55:16.196: INFO: Exec stderr: ""
Aug 27 18:55:16.196: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-289 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 27 18:55:16.196: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
Aug 27 18:55:16.552: INFO: Exec stderr: ""
Aug 27 18:55:16.552: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-289 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 27 18:55:16.552: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
Aug 27 18:55:16.874: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Aug 27 18:55:16.874: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-289 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 27 18:55:16.874: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
Aug 27 18:55:17.239: INFO: Exec stderr: ""
Aug 27 18:55:17.239: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-289 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 27 18:55:17.239: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
Aug 27 18:55:17.574: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Aug 27 18:55:17.574: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-289 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 27 18:55:17.574: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
Aug 27 18:55:17.874: INFO: Exec stderr: ""
Aug 27 18:55:17.874: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-289 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 27 18:55:17.874: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
Aug 27 18:55:18.173: INFO: Exec stderr: ""
Aug 27 18:55:18.173: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-289 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 27 18:55:18.173: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
Aug 27 18:55:18.502: INFO: Exec stderr: ""
Aug 27 18:55:18.502: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-289 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 27 18:55:18.502: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
Aug 27 18:55:18.788: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 18:55:18.789: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-kubelet-etc-hosts-289" for this suite.
Aug 27 18:56:04.851: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 18:56:05.256: INFO: namespace e2e-kubelet-etc-hosts-289 deletion completed in 46.450730577s

• [SLOW TEST:58.020 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 18:56:05.258: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-3296
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0644 on node default medium
Aug 27 18:56:05.495: INFO: Waiting up to 5m0s for pod "pod-d7fcdeb0-3715-4347-b313-4519aa24a663" in namespace "emptydir-3296" to be "success or failure"
Aug 27 18:56:05.505: INFO: Pod "pod-d7fcdeb0-3715-4347-b313-4519aa24a663": Phase="Pending", Reason="", readiness=false. Elapsed: 9.762472ms
Aug 27 18:56:07.516: INFO: Pod "pod-d7fcdeb0-3715-4347-b313-4519aa24a663": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020492143s
STEP: Saw pod success
Aug 27 18:56:07.516: INFO: Pod "pod-d7fcdeb0-3715-4347-b313-4519aa24a663" satisfied condition "success or failure"
Aug 27 18:56:07.526: INFO: Trying to get logs from node 10.138.3.242 pod pod-d7fcdeb0-3715-4347-b313-4519aa24a663 container test-container: <nil>
STEP: delete the pod
Aug 27 18:56:07.570: INFO: Waiting for pod pod-d7fcdeb0-3715-4347-b313-4519aa24a663 to disappear
Aug 27 18:56:07.582: INFO: Pod pod-d7fcdeb0-3715-4347-b313-4519aa24a663 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 18:56:07.582: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3296" for this suite.
Aug 27 18:56:13.641: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 18:56:14.005: INFO: namespace emptydir-3296 deletion completed in 6.407293878s

• [SLOW TEST:8.747 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 18:56:14.006: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-3247
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Aug 27 18:56:14.251: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-3247,SelfLink:/api/v1/namespaces/watch-3247/configmaps/e2e-watch-test-watch-closed,UID:3fee9cf4-a1c8-4d38-b83b-58b32e519ba4,ResourceVersion:27586,Generation:0,CreationTimestamp:2019-08-27 18:56:14 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Aug 27 18:56:14.251: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-3247,SelfLink:/api/v1/namespaces/watch-3247/configmaps/e2e-watch-test-watch-closed,UID:3fee9cf4-a1c8-4d38-b83b-58b32e519ba4,ResourceVersion:27587,Generation:0,CreationTimestamp:2019-08-27 18:56:14 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Aug 27 18:56:14.294: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-3247,SelfLink:/api/v1/namespaces/watch-3247/configmaps/e2e-watch-test-watch-closed,UID:3fee9cf4-a1c8-4d38-b83b-58b32e519ba4,ResourceVersion:27588,Generation:0,CreationTimestamp:2019-08-27 18:56:14 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Aug 27 18:56:14.294: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-3247,SelfLink:/api/v1/namespaces/watch-3247/configmaps/e2e-watch-test-watch-closed,UID:3fee9cf4-a1c8-4d38-b83b-58b32e519ba4,ResourceVersion:27589,Generation:0,CreationTimestamp:2019-08-27 18:56:14 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 18:56:14.295: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-3247" for this suite.
Aug 27 18:56:20.350: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 18:56:20.734: INFO: namespace watch-3247 deletion completed in 6.42844998s

• [SLOW TEST:6.728 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 18:56:20.734: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5167
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-map-e9b0cd79-41fe-4383-9c06-28264860adb4
STEP: Creating a pod to test consume configMaps
Aug 27 18:56:20.977: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-58b4dba0-4207-4333-bb23-543904593864" in namespace "projected-5167" to be "success or failure"
Aug 27 18:56:20.989: INFO: Pod "pod-projected-configmaps-58b4dba0-4207-4333-bb23-543904593864": Phase="Pending", Reason="", readiness=false. Elapsed: 11.823602ms
Aug 27 18:56:22.999: INFO: Pod "pod-projected-configmaps-58b4dba0-4207-4333-bb23-543904593864": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.022499936s
STEP: Saw pod success
Aug 27 18:56:22.999: INFO: Pod "pod-projected-configmaps-58b4dba0-4207-4333-bb23-543904593864" satisfied condition "success or failure"
Aug 27 18:56:23.009: INFO: Trying to get logs from node 10.138.3.233 pod pod-projected-configmaps-58b4dba0-4207-4333-bb23-543904593864 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Aug 27 18:56:23.056: INFO: Waiting for pod pod-projected-configmaps-58b4dba0-4207-4333-bb23-543904593864 to disappear
Aug 27 18:56:23.067: INFO: Pod pod-projected-configmaps-58b4dba0-4207-4333-bb23-543904593864 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 18:56:23.067: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5167" for this suite.
Aug 27 18:56:29.126: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 18:56:29.478: INFO: namespace projected-5167 deletion completed in 6.396421138s

• [SLOW TEST:8.744 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 18:56:29.479: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-7258
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Aug 27 18:56:29.717: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-540514467 create -f - --namespace=kubectl-7258'
Aug 27 18:56:30.117: INFO: stderr: ""
Aug 27 18:56:30.117: INFO: stdout: "replicationcontroller/redis-master created\n"
Aug 27 18:56:30.117: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-540514467 create -f - --namespace=kubectl-7258'
Aug 27 18:56:30.478: INFO: stderr: ""
Aug 27 18:56:30.478: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Aug 27 18:56:31.488: INFO: Selector matched 1 pods for map[app:redis]
Aug 27 18:56:31.489: INFO: Found 0 / 1
Aug 27 18:56:32.489: INFO: Selector matched 1 pods for map[app:redis]
Aug 27 18:56:32.489: INFO: Found 0 / 1
Aug 27 18:56:33.489: INFO: Selector matched 1 pods for map[app:redis]
Aug 27 18:56:33.489: INFO: Found 0 / 1
Aug 27 18:56:34.489: INFO: Selector matched 1 pods for map[app:redis]
Aug 27 18:56:34.489: INFO: Found 0 / 1
Aug 27 18:56:35.489: INFO: Selector matched 1 pods for map[app:redis]
Aug 27 18:56:35.489: INFO: Found 0 / 1
Aug 27 18:56:36.489: INFO: Selector matched 1 pods for map[app:redis]
Aug 27 18:56:36.489: INFO: Found 1 / 1
Aug 27 18:56:36.489: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Aug 27 18:56:36.499: INFO: Selector matched 1 pods for map[app:redis]
Aug 27 18:56:36.499: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Aug 27 18:56:36.499: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-540514467 describe pod redis-master-8tgnt --namespace=kubectl-7258'
Aug 27 18:56:36.650: INFO: stderr: ""
Aug 27 18:56:36.650: INFO: stdout: "Name:           redis-master-8tgnt\nNamespace:      kubectl-7258\nPriority:       0\nNode:           10.138.3.242/10.138.3.242\nStart Time:     Tue, 27 Aug 2019 18:56:30 +0000\nLabels:         app=redis\n                role=master\nAnnotations:    kubernetes.io/psp: e2e-test-privileged-psp\nStatus:         Running\nIP:             172.30.115.12\nControlled By:  ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   containerd://3f83054f6cbe09e7543a02a6335f5fcca2c94cc1e20572d35aa819a4b9121dad\n    Image:          gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Image ID:       gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Tue, 27 Aug 2019 18:56:35 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-gbp9x (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-gbp9x:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-gbp9x\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 600s\n                 node.kubernetes.io/unreachable:NoExecute for 600s\nEvents:\n  Type    Reason     Age   From                   Message\n  ----    ------     ----  ----                   -------\n  Normal  Scheduled  6s    default-scheduler      Successfully assigned kubectl-7258/redis-master-8tgnt to 10.138.3.242\n  Normal  Pulling    5s    kubelet, 10.138.3.242  Pulling image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\"\n  Normal  Pulled     1s    kubelet, 10.138.3.242  Successfully pulled image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\"\n  Normal  Created    1s    kubelet, 10.138.3.242  Created container redis-master\n  Normal  Started    1s    kubelet, 10.138.3.242  Started container redis-master\n"
Aug 27 18:56:36.650: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-540514467 describe rc redis-master --namespace=kubectl-7258'
Aug 27 18:56:36.824: INFO: stderr: ""
Aug 27 18:56:36.824: INFO: stdout: "Name:         redis-master\nNamespace:    kubectl-7258\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  6s    replication-controller  Created pod: redis-master-8tgnt\n"
Aug 27 18:56:36.824: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-540514467 describe service redis-master --namespace=kubectl-7258'
Aug 27 18:56:36.994: INFO: stderr: ""
Aug 27 18:56:36.994: INFO: stdout: "Name:              redis-master\nNamespace:         kubectl-7258\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                172.21.49.250\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         172.30.115.12:6379\nSession Affinity:  None\nEvents:            <none>\n"
Aug 27 18:56:37.011: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-540514467 describe node 10.138.3.199'
Aug 27 18:56:37.209: INFO: stderr: ""
Aug 27 18:56:37.209: INFO: stdout: "Name:               10.138.3.199\nRoles:              <none>\nLabels:             arch=amd64\n                    beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/instance-type=b3c.4x16.encrypted\n                    beta.kubernetes.io/os=linux\n                    failure-domain.beta.kubernetes.io/region=au-syd\n                    failure-domain.beta.kubernetes.io/zone=syd01\n                    ibm-cloud.kubernetes.io/encrypted-docker-data=true\n                    ibm-cloud.kubernetes.io/external-ip=168.1.37.98\n                    ibm-cloud.kubernetes.io/ha-worker=true\n                    ibm-cloud.kubernetes.io/iaas-provider=softlayer\n                    ibm-cloud.kubernetes.io/internal-ip=10.138.3.199\n                    ibm-cloud.kubernetes.io/machine-type=b3c.4x16.encrypted\n                    ibm-cloud.kubernetes.io/os=UBUNTU_18_64\n                    ibm-cloud.kubernetes.io/region=au-syd\n                    ibm-cloud.kubernetes.io/sgx-enabled=false\n                    ibm-cloud.kubernetes.io/worker-id=kube-blilkl7s0qcmd68ptvug-kubee2epvgf-default-000001e6\n                    ibm-cloud.kubernetes.io/worker-pool-id=blilkl7s0qcmd68ptvug-44e405d\n                    ibm-cloud.kubernetes.io/worker-pool-name=default\n                    ibm-cloud.kubernetes.io/worker-version=1.15.2_1514\n                    ibm-cloud.kubernetes.io/zone=syd01\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=10.138.3.199\n                    kubernetes.io/os=linux\n                    privateVLAN=2086933\n                    publicVLAN=2086931\nAnnotations:        node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Tue, 27 Aug 2019 16:48:40 +0000\nTaints:             <none>\nUnschedulable:      false\nConditions:\n  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----             ------  -----------------                 ------------------                ------                       -------\n  MemoryPressure   False   Tue, 27 Aug 2019 18:55:47 +0000   Tue, 27 Aug 2019 16:48:40 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure     False   Tue, 27 Aug 2019 18:55:47 +0000   Tue, 27 Aug 2019 16:48:40 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure      False   Tue, 27 Aug 2019 18:55:47 +0000   Tue, 27 Aug 2019 16:48:40 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready            True    Tue, 27 Aug 2019 18:55:47 +0000   Tue, 27 Aug 2019 16:48:50 +0000   KubeletReady                 kubelet is posting ready status. AppArmor enabled\nAddresses:\n  InternalIP:  10.138.3.199\n  ExternalIP:  168.1.37.98\n  Hostname:    10.138.3.199\nCapacity:\n cpu:                4\n ephemeral-storage:  102685624Ki\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             16419940Ki\n pods:               110\nAllocatable:\n cpu:                3910m\n ephemeral-storage:  99892574949\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             13627492Ki\n pods:               110\nSystem Info:\n Machine ID:                 f0c4485fc964428d92e46c87ec7b9fdc\n System UUID:                D159BF5B-AF00-6FDA-712A-7161DF50E93B\n Boot ID:                    4aeaa377-c5f5-4ad1-838b-b82e2c1cd296\n Kernel Version:             4.15.0-58-generic\n OS Image:                   Ubuntu 18.04.3 LTS\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  containerd://1.2.7\n Kubelet Version:            v1.15.2+IKS\n Kube-Proxy Version:         v1.15.2+IKS\nProviderID:                  ibm://cc7530878c499d74ad77f31c918c626e///blilkl7s0qcmd68ptvug/kube-blilkl7s0qcmd68ptvug-kubee2epvgf-default-000001e6\nNon-terminated Pods:         (13 in total)\n  Namespace                  Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                  ----                                                       ------------  ----------  ---------------  -------------  ---\n  heptio-sonobuoy            sonobuoy-e2e-job-7e16f540f6e644a9                          0 (0%)        0 (0%)      0 (0%)           0 (0%)         27m\n  heptio-sonobuoy            sonobuoy-systemd-logs-daemon-set-6de4f4bc9f654bc5-2n49n    0 (0%)        0 (0%)      0 (0%)           0 (0%)         27m\n  kube-system                calico-kube-controllers-8b68f5487-frr4d                    10m (0%)      0 (0%)      25Mi (0%)        3Gi (23%)      134m\n  kube-system                calico-node-qtfmd                                          250m (6%)     0 (0%)      80Mi (0%)        0 (0%)         127m\n  kube-system                coredns-64f45bf67-82p5d                                    100m (2%)     0 (0%)      70Mi (0%)        400Mi (3%)     99m\n  kube-system                coredns-autoscaler-74cb66766b-v4jw4                        20m (0%)      0 (0%)      10Mi (0%)        0 (0%)         133m\n  kube-system                ibm-file-plugin-8598c89fd6-zkw7p                           50m (1%)      200m (5%)   100Mi (0%)       0 (0%)         132m\n  kube-system                ibm-keepalived-watcher-q4lz6                               5m (0%)       0 (0%)      10Mi (0%)        0 (0%)         127m\n  kube-system                ibm-kube-fluentd-sndbh                                     25m (0%)      300m (7%)   150Mi (1%)       1600M (11%)    127m\n  kube-system                ibm-master-proxy-static-10.138.3.199                       25m (0%)      300m (7%)   32M (0%)         512M (3%)      127m\n  kube-system                ibm-storage-watcher-79884b9494-zg264                       50m (1%)      200m (5%)   100Mi (0%)       0 (0%)         132m\n  kube-system                kubernetes-dashboard-596f947ff4-qhm8x                      50m (1%)      0 (0%)      100Mi (0%)       0 (0%)         131m\n  kube-system                public-crblilkl7s0qcmd68ptvug-alb1-96757c898-jhng9         0 (0%)        0 (0%)      0 (0%)           0 (0%)         119m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests       Limits\n  --------           --------       ------\n  cpu                585m (14%)     1 (25%)\n  memory             691730Ki (5%)  5617828Ki (41%)\n  ephemeral-storage  0 (0%)         0 (0%)\nEvents:              <none>\n"
Aug 27 18:56:37.209: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-540514467 describe namespace kubectl-7258'
Aug 27 18:56:37.359: INFO: stderr: ""
Aug 27 18:56:37.359: INFO: stdout: "Name:         kubectl-7258\nLabels:       e2e-framework=kubectl\n              e2e-run=1fb9f777-f96c-46fe-90f6-388f34acc7d5\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 18:56:37.359: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7258" for this suite.
Aug 27 18:57:01.433: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 18:57:01.815: INFO: namespace kubectl-7258 deletion completed in 24.426248011s

• [SLOW TEST:32.336 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl describe
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] version v1
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 18:57:01.817: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-3543
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Aug 27 18:57:02.079: INFO: (0) /api/v1/nodes/10.138.3.199:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 15.367837ms)
Aug 27 18:57:02.095: INFO: (1) /api/v1/nodes/10.138.3.199:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 16.338206ms)
Aug 27 18:57:02.111: INFO: (2) /api/v1/nodes/10.138.3.199:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 16.279867ms)
Aug 27 18:57:02.127: INFO: (3) /api/v1/nodes/10.138.3.199:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 15.68784ms)
Aug 27 18:57:02.149: INFO: (4) /api/v1/nodes/10.138.3.199:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 21.640754ms)
Aug 27 18:57:02.164: INFO: (5) /api/v1/nodes/10.138.3.199:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 15.121639ms)
Aug 27 18:57:02.179: INFO: (6) /api/v1/nodes/10.138.3.199:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 14.660534ms)
Aug 27 18:57:02.195: INFO: (7) /api/v1/nodes/10.138.3.199:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 16.403068ms)
Aug 27 18:57:02.212: INFO: (8) /api/v1/nodes/10.138.3.199:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 16.607321ms)
Aug 27 18:57:02.230: INFO: (9) /api/v1/nodes/10.138.3.199:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 17.968178ms)
Aug 27 18:57:02.246: INFO: (10) /api/v1/nodes/10.138.3.199:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 16.128691ms)
Aug 27 18:57:02.276: INFO: (11) /api/v1/nodes/10.138.3.199:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 29.423147ms)
Aug 27 18:57:02.293: INFO: (12) /api/v1/nodes/10.138.3.199:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 16.784627ms)
Aug 27 18:57:02.309: INFO: (13) /api/v1/nodes/10.138.3.199:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 16.153216ms)
Aug 27 18:57:02.325: INFO: (14) /api/v1/nodes/10.138.3.199:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 15.735495ms)
Aug 27 18:57:02.340: INFO: (15) /api/v1/nodes/10.138.3.199:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 15.561697ms)
Aug 27 18:57:02.357: INFO: (16) /api/v1/nodes/10.138.3.199:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 16.229124ms)
Aug 27 18:57:02.373: INFO: (17) /api/v1/nodes/10.138.3.199:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 16.749468ms)
Aug 27 18:57:02.389: INFO: (18) /api/v1/nodes/10.138.3.199:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 15.600908ms)
Aug 27 18:57:02.404: INFO: (19) /api/v1/nodes/10.138.3.199:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 15.159041ms)
[AfterEach] version v1
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 18:57:02.405: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-3543" for this suite.
Aug 27 18:57:08.463: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 18:57:08.808: INFO: namespace proxy-3543 deletion completed in 6.389564587s

• [SLOW TEST:6.991 seconds]
[sig-network] Proxy
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:58
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 18:57:08.808: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-1308
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0777 on tmpfs
Aug 27 18:57:09.039: INFO: Waiting up to 5m0s for pod "pod-c8fdae72-98d7-4b90-a99e-1a58b8101b5c" in namespace "emptydir-1308" to be "success or failure"
Aug 27 18:57:09.051: INFO: Pod "pod-c8fdae72-98d7-4b90-a99e-1a58b8101b5c": Phase="Pending", Reason="", readiness=false. Elapsed: 11.271706ms
Aug 27 18:57:11.061: INFO: Pod "pod-c8fdae72-98d7-4b90-a99e-1a58b8101b5c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021418984s
STEP: Saw pod success
Aug 27 18:57:11.061: INFO: Pod "pod-c8fdae72-98d7-4b90-a99e-1a58b8101b5c" satisfied condition "success or failure"
Aug 27 18:57:11.070: INFO: Trying to get logs from node 10.138.3.233 pod pod-c8fdae72-98d7-4b90-a99e-1a58b8101b5c container test-container: <nil>
STEP: delete the pod
Aug 27 18:57:11.119: INFO: Waiting for pod pod-c8fdae72-98d7-4b90-a99e-1a58b8101b5c to disappear
Aug 27 18:57:11.128: INFO: Pod pod-c8fdae72-98d7-4b90-a99e-1a58b8101b5c no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 18:57:11.128: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1308" for this suite.
Aug 27 18:57:17.186: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 18:57:17.625: INFO: namespace emptydir-1308 deletion completed in 6.481433592s

• [SLOW TEST:8.818 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 18:57:17.626: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5034
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Aug 27 18:57:17.866: INFO: Waiting up to 5m0s for pod "downwardapi-volume-81479acb-479e-49f6-8eac-528979f8db0c" in namespace "projected-5034" to be "success or failure"
Aug 27 18:57:17.876: INFO: Pod "downwardapi-volume-81479acb-479e-49f6-8eac-528979f8db0c": Phase="Pending", Reason="", readiness=false. Elapsed: 10.480946ms
Aug 27 18:57:19.887: INFO: Pod "downwardapi-volume-81479acb-479e-49f6-8eac-528979f8db0c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021411997s
Aug 27 18:57:21.899: INFO: Pod "downwardapi-volume-81479acb-479e-49f6-8eac-528979f8db0c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.033495148s
STEP: Saw pod success
Aug 27 18:57:21.899: INFO: Pod "downwardapi-volume-81479acb-479e-49f6-8eac-528979f8db0c" satisfied condition "success or failure"
Aug 27 18:57:21.909: INFO: Trying to get logs from node 10.138.3.242 pod downwardapi-volume-81479acb-479e-49f6-8eac-528979f8db0c container client-container: <nil>
STEP: delete the pod
Aug 27 18:57:21.954: INFO: Waiting for pod downwardapi-volume-81479acb-479e-49f6-8eac-528979f8db0c to disappear
Aug 27 18:57:21.965: INFO: Pod downwardapi-volume-81479acb-479e-49f6-8eac-528979f8db0c no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 18:57:21.965: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5034" for this suite.
Aug 27 18:57:28.024: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 18:57:28.374: INFO: namespace projected-5034 deletion completed in 6.39428779s

• [SLOW TEST:10.748 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 18:57:28.377: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-4117
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Aug 27 18:57:28.614: INFO: Waiting up to 5m0s for pod "downwardapi-volume-830c1df3-b196-4e32-b5da-29890a0a3d62" in namespace "projected-4117" to be "success or failure"
Aug 27 18:57:28.627: INFO: Pod "downwardapi-volume-830c1df3-b196-4e32-b5da-29890a0a3d62": Phase="Pending", Reason="", readiness=false. Elapsed: 13.326932ms
Aug 27 18:57:30.638: INFO: Pod "downwardapi-volume-830c1df3-b196-4e32-b5da-29890a0a3d62": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023543732s
Aug 27 18:57:32.648: INFO: Pod "downwardapi-volume-830c1df3-b196-4e32-b5da-29890a0a3d62": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.033929937s
STEP: Saw pod success
Aug 27 18:57:32.648: INFO: Pod "downwardapi-volume-830c1df3-b196-4e32-b5da-29890a0a3d62" satisfied condition "success or failure"
Aug 27 18:57:32.658: INFO: Trying to get logs from node 10.138.3.233 pod downwardapi-volume-830c1df3-b196-4e32-b5da-29890a0a3d62 container client-container: <nil>
STEP: delete the pod
Aug 27 18:57:32.703: INFO: Waiting for pod downwardapi-volume-830c1df3-b196-4e32-b5da-29890a0a3d62 to disappear
Aug 27 18:57:32.714: INFO: Pod downwardapi-volume-830c1df3-b196-4e32-b5da-29890a0a3d62 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 18:57:32.714: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4117" for this suite.
Aug 27 18:57:38.773: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 18:57:39.131: INFO: namespace projected-4117 deletion completed in 6.402546401s

• [SLOW TEST:10.754 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 18:57:39.132: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-8865
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Aug 27 18:57:39.372: INFO: Waiting up to 5m0s for pod "downwardapi-volume-32b129a7-257a-4eee-8276-641ddd70c3bd" in namespace "downward-api-8865" to be "success or failure"
Aug 27 18:57:39.381: INFO: Pod "downwardapi-volume-32b129a7-257a-4eee-8276-641ddd70c3bd": Phase="Pending", Reason="", readiness=false. Elapsed: 9.703016ms
Aug 27 18:57:41.392: INFO: Pod "downwardapi-volume-32b129a7-257a-4eee-8276-641ddd70c3bd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.019825344s
STEP: Saw pod success
Aug 27 18:57:41.392: INFO: Pod "downwardapi-volume-32b129a7-257a-4eee-8276-641ddd70c3bd" satisfied condition "success or failure"
Aug 27 18:57:41.402: INFO: Trying to get logs from node 10.138.3.242 pod downwardapi-volume-32b129a7-257a-4eee-8276-641ddd70c3bd container client-container: <nil>
STEP: delete the pod
Aug 27 18:57:41.447: INFO: Waiting for pod downwardapi-volume-32b129a7-257a-4eee-8276-641ddd70c3bd to disappear
Aug 27 18:57:41.456: INFO: Pod downwardapi-volume-32b129a7-257a-4eee-8276-641ddd70c3bd no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 18:57:41.457: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8865" for this suite.
Aug 27 18:57:47.518: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 18:57:47.867: INFO: namespace downward-api-8865 deletion completed in 6.395963726s

• [SLOW TEST:8.736 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 18:57:47.869: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-4010
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:81
Aug 27 18:57:48.087: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Aug 27 18:57:48.110: INFO: Waiting for terminating namespaces to be deleted...
Aug 27 18:57:48.122: INFO: 
Logging pods the kubelet thinks is on node 10.138.3.199 before test
Aug 27 18:57:48.204: INFO: sonobuoy-systemd-logs-daemon-set-6de4f4bc9f654bc5-2n49n from heptio-sonobuoy started at 2019-08-27 18:29:36 +0000 UTC (2 container statuses recorded)
Aug 27 18:57:48.204: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug 27 18:57:48.204: INFO: 	Container systemd-logs ready: true, restart count 0
Aug 27 18:57:48.204: INFO: kubernetes-dashboard-596f947ff4-qhm8x from kube-system started at 2019-08-27 16:48:54 +0000 UTC (1 container statuses recorded)
Aug 27 18:57:48.204: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Aug 27 18:57:48.204: INFO: ibm-storage-watcher-79884b9494-zg264 from kube-system started at 2019-08-27 16:48:54 +0000 UTC (1 container statuses recorded)
Aug 27 18:57:48.204: INFO: 	Container ibm-storage-watcher-container ready: true, restart count 0
Aug 27 18:57:48.204: INFO: ibm-kube-fluentd-sndbh from kube-system started at 2019-08-27 16:49:31 +0000 UTC (1 container statuses recorded)
Aug 27 18:57:48.204: INFO: 	Container fluentd ready: true, restart count 0
Aug 27 18:57:48.204: INFO: ibm-keepalived-watcher-q4lz6 from kube-system started at 2019-08-27 16:48:40 +0000 UTC (1 container statuses recorded)
Aug 27 18:57:48.204: INFO: 	Container keepalived-watcher ready: true, restart count 0
Aug 27 18:57:48.204: INFO: public-crblilkl7s0qcmd68ptvug-alb1-96757c898-jhng9 from kube-system started at 2019-08-27 16:57:11 +0000 UTC (4 container statuses recorded)
Aug 27 18:57:48.204: INFO: 	Container ingress-auth-1 ready: true, restart count 0
Aug 27 18:57:48.204: INFO: 	Container ingress-auth-2 ready: true, restart count 0
Aug 27 18:57:48.204: INFO: 	Container ingress-auth-3 ready: true, restart count 0
Aug 27 18:57:48.204: INFO: 	Container nginx-ingress ready: true, restart count 0
Aug 27 18:57:48.204: INFO: coredns-64f45bf67-82p5d from kube-system started at 2019-08-27 17:16:42 +0000 UTC (1 container statuses recorded)
Aug 27 18:57:48.204: INFO: 	Container coredns ready: true, restart count 0
Aug 27 18:57:48.204: INFO: coredns-autoscaler-74cb66766b-v4jw4 from kube-system started at 2019-08-27 16:48:54 +0000 UTC (1 container statuses recorded)
Aug 27 18:57:48.204: INFO: 	Container autoscaler ready: true, restart count 0
Aug 27 18:57:48.204: INFO: calico-kube-controllers-8b68f5487-frr4d from kube-system started at 2019-08-27 16:48:54 +0000 UTC (1 container statuses recorded)
Aug 27 18:57:48.204: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Aug 27 18:57:48.204: INFO: sonobuoy-e2e-job-7e16f540f6e644a9 from heptio-sonobuoy started at 2019-08-27 18:29:36 +0000 UTC (2 container statuses recorded)
Aug 27 18:57:48.205: INFO: 	Container e2e ready: true, restart count 0
Aug 27 18:57:48.205: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug 27 18:57:48.205: INFO: calico-node-qtfmd from kube-system started at 2019-08-27 16:48:40 +0000 UTC (1 container statuses recorded)
Aug 27 18:57:48.205: INFO: 	Container calico-node ready: true, restart count 0
Aug 27 18:57:48.205: INFO: ibm-file-plugin-8598c89fd6-zkw7p from kube-system started at 2019-08-27 16:48:54 +0000 UTC (1 container statuses recorded)
Aug 27 18:57:48.205: INFO: 	Container ibm-file-plugin-container ready: true, restart count 0
Aug 27 18:57:48.205: INFO: ibm-master-proxy-static-10.138.3.199 from kube-system started at 2019-08-27 16:48:38 +0000 UTC (2 container statuses recorded)
Aug 27 18:57:48.205: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Aug 27 18:57:48.205: INFO: 	Container pause ready: true, restart count 0
Aug 27 18:57:48.205: INFO: 
Logging pods the kubelet thinks is on node 10.138.3.233 before test
Aug 27 18:57:48.233: INFO: ibm-kube-fluentd-7vnnc from kube-system started at 2019-08-27 16:49:31 +0000 UTC (1 container statuses recorded)
Aug 27 18:57:48.233: INFO: 	Container fluentd ready: true, restart count 0
Aug 27 18:57:48.233: INFO: ibm-cloud-provider-ip-168-1-33-254-684b4b48d5-6htlx from ibm-system started at 2019-08-27 16:54:12 +0000 UTC (1 container statuses recorded)
Aug 27 18:57:48.233: INFO: 	Container ibm-cloud-provider-ip-168-1-33-254 ready: true, restart count 0
Aug 27 18:57:48.233: INFO: ibm-master-proxy-static-10.138.3.233 from kube-system started at 2019-08-27 16:48:48 +0000 UTC (2 container statuses recorded)
Aug 27 18:57:48.233: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Aug 27 18:57:48.233: INFO: 	Container pause ready: true, restart count 0
Aug 27 18:57:48.233: INFO: metrics-server-74c65558d9-bjxkf from kube-system started at 2019-08-27 16:49:27 +0000 UTC (2 container statuses recorded)
Aug 27 18:57:48.233: INFO: 	Container metrics-server ready: true, restart count 0
Aug 27 18:57:48.233: INFO: 	Container metrics-server-nanny ready: true, restart count 0
Aug 27 18:57:48.233: INFO: public-crblilkl7s0qcmd68ptvug-alb1-96757c898-ttk5v from kube-system started at 2019-08-27 16:57:11 +0000 UTC (4 container statuses recorded)
Aug 27 18:57:48.233: INFO: 	Container ingress-auth-1 ready: true, restart count 0
Aug 27 18:57:48.233: INFO: 	Container ingress-auth-2 ready: true, restart count 0
Aug 27 18:57:48.233: INFO: 	Container ingress-auth-3 ready: true, restart count 0
Aug 27 18:57:48.233: INFO: 	Container nginx-ingress ready: true, restart count 0
Aug 27 18:57:48.233: INFO: sonobuoy-systemd-logs-daemon-set-6de4f4bc9f654bc5-5t68b from heptio-sonobuoy started at 2019-08-27 18:29:36 +0000 UTC (2 container statuses recorded)
Aug 27 18:57:48.233: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug 27 18:57:48.233: INFO: 	Container systemd-logs ready: true, restart count 0
Aug 27 18:57:48.233: INFO: ibm-keepalived-watcher-rqmrm from kube-system started at 2019-08-27 16:48:49 +0000 UTC (1 container statuses recorded)
Aug 27 18:57:48.233: INFO: 	Container keepalived-watcher ready: true, restart count 0
Aug 27 18:57:48.233: INFO: calico-node-hhq6f from kube-system started at 2019-08-27 16:48:49 +0000 UTC (1 container statuses recorded)
Aug 27 18:57:48.233: INFO: 	Container calico-node ready: true, restart count 0
Aug 27 18:57:48.233: INFO: 
Logging pods the kubelet thinks is on node 10.138.3.242 before test
Aug 27 18:57:48.262: INFO: ibm-master-proxy-static-10.138.3.242 from kube-system started at 2019-08-27 16:49:34 +0000 UTC (2 container statuses recorded)
Aug 27 18:57:48.262: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Aug 27 18:57:48.262: INFO: 	Container pause ready: true, restart count 0
Aug 27 18:57:48.262: INFO: ibm-kube-fluentd-9wfd4 from kube-system started at 2019-08-27 16:49:35 +0000 UTC (1 container statuses recorded)
Aug 27 18:57:48.262: INFO: 	Container fluentd ready: true, restart count 0
Aug 27 18:57:48.262: INFO: test-k8s-e2e-pvg-master-verification from default started at 2019-08-27 16:51:12 +0000 UTC (1 container statuses recorded)
Aug 27 18:57:48.262: INFO: 	Container test-k8s-e2e-pvg-master-verification ready: true, restart count 0
Aug 27 18:57:48.262: INFO: coredns-64f45bf67-b57dh from kube-system started at 2019-08-27 17:16:42 +0000 UTC (1 container statuses recorded)
Aug 27 18:57:48.262: INFO: 	Container coredns ready: true, restart count 0
Aug 27 18:57:48.262: INFO: ibm-keepalived-watcher-jsshh from kube-system started at 2019-08-27 16:49:35 +0000 UTC (1 container statuses recorded)
Aug 27 18:57:48.262: INFO: 	Container keepalived-watcher ready: true, restart count 0
Aug 27 18:57:48.262: INFO: calico-node-b9wft from kube-system started at 2019-08-27 16:49:35 +0000 UTC (1 container statuses recorded)
Aug 27 18:57:48.262: INFO: 	Container calico-node ready: true, restart count 0
Aug 27 18:57:48.262: INFO: ibm-cloud-provider-ip-168-1-33-254-684b4b48d5-f6mrh from ibm-system started at 2019-08-27 16:54:12 +0000 UTC (1 container statuses recorded)
Aug 27 18:57:48.262: INFO: 	Container ibm-cloud-provider-ip-168-1-33-254 ready: true, restart count 0
Aug 27 18:57:48.263: INFO: sonobuoy from heptio-sonobuoy started at 2019-08-27 18:29:26 +0000 UTC (1 container statuses recorded)
Aug 27 18:57:48.263: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Aug 27 18:57:48.263: INFO: vpn-75d8697c68-t4p4j from kube-system started at 2019-08-27 17:16:10 +0000 UTC (1 container statuses recorded)
Aug 27 18:57:48.263: INFO: 	Container vpn ready: true, restart count 0
Aug 27 18:57:48.263: INFO: sonobuoy-systemd-logs-daemon-set-6de4f4bc9f654bc5-jt7wr from heptio-sonobuoy started at 2019-08-27 18:29:36 +0000 UTC (2 container statuses recorded)
Aug 27 18:57:48.263: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug 27 18:57:48.263: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-dd52b89f-a264-420a-aee3-1fde736b480a 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-dd52b89f-a264-420a-aee3-1fde736b480a off the node 10.138.3.233
STEP: verifying the node doesn't have the label kubernetes.io/e2e-dd52b89f-a264-420a-aee3-1fde736b480a
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 18:57:52.467: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-4010" for this suite.
Aug 27 18:58:08.535: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 18:58:08.898: INFO: namespace sched-pred-4010 deletion completed in 16.411925199s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:72

• [SLOW TEST:21.029 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 18:58:08.900: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-4389
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-86d56b0a-0c8e-45a5-9860-cbfb8dbc67c9
STEP: Creating a pod to test consume secrets
Aug 27 18:58:09.146: INFO: Waiting up to 5m0s for pod "pod-secrets-f7b4afaa-5860-48f9-8502-9f279886fd64" in namespace "secrets-4389" to be "success or failure"
Aug 27 18:58:09.156: INFO: Pod "pod-secrets-f7b4afaa-5860-48f9-8502-9f279886fd64": Phase="Pending", Reason="", readiness=false. Elapsed: 10.628423ms
Aug 27 18:58:11.167: INFO: Pod "pod-secrets-f7b4afaa-5860-48f9-8502-9f279886fd64": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021242878s
Aug 27 18:58:13.177: INFO: Pod "pod-secrets-f7b4afaa-5860-48f9-8502-9f279886fd64": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.031647817s
STEP: Saw pod success
Aug 27 18:58:13.178: INFO: Pod "pod-secrets-f7b4afaa-5860-48f9-8502-9f279886fd64" satisfied condition "success or failure"
Aug 27 18:58:13.187: INFO: Trying to get logs from node 10.138.3.242 pod pod-secrets-f7b4afaa-5860-48f9-8502-9f279886fd64 container secret-volume-test: <nil>
STEP: delete the pod
Aug 27 18:58:13.241: INFO: Waiting for pod pod-secrets-f7b4afaa-5860-48f9-8502-9f279886fd64 to disappear
Aug 27 18:58:13.251: INFO: Pod pod-secrets-f7b4afaa-5860-48f9-8502-9f279886fd64 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 18:58:13.251: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-4389" for this suite.
Aug 27 18:58:19.310: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 18:58:19.691: INFO: namespace secrets-4389 deletion completed in 6.425095925s

• [SLOW TEST:10.791 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 18:58:19.692: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-5252
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-projected-rc6h
STEP: Creating a pod to test atomic-volume-subpath
Aug 27 18:58:19.968: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-rc6h" in namespace "subpath-5252" to be "success or failure"
Aug 27 18:58:19.979: INFO: Pod "pod-subpath-test-projected-rc6h": Phase="Pending", Reason="", readiness=false. Elapsed: 10.575804ms
Aug 27 18:58:21.989: INFO: Pod "pod-subpath-test-projected-rc6h": Phase="Running", Reason="", readiness=true. Elapsed: 2.020641233s
Aug 27 18:58:24.000: INFO: Pod "pod-subpath-test-projected-rc6h": Phase="Running", Reason="", readiness=true. Elapsed: 4.031578557s
Aug 27 18:58:26.010: INFO: Pod "pod-subpath-test-projected-rc6h": Phase="Running", Reason="", readiness=true. Elapsed: 6.041831715s
Aug 27 18:58:28.021: INFO: Pod "pod-subpath-test-projected-rc6h": Phase="Running", Reason="", readiness=true. Elapsed: 8.052547197s
Aug 27 18:58:30.031: INFO: Pod "pod-subpath-test-projected-rc6h": Phase="Running", Reason="", readiness=true. Elapsed: 10.063279062s
Aug 27 18:58:32.042: INFO: Pod "pod-subpath-test-projected-rc6h": Phase="Running", Reason="", readiness=true. Elapsed: 12.074168538s
Aug 27 18:58:34.053: INFO: Pod "pod-subpath-test-projected-rc6h": Phase="Running", Reason="", readiness=true. Elapsed: 14.085075371s
Aug 27 18:58:36.064: INFO: Pod "pod-subpath-test-projected-rc6h": Phase="Running", Reason="", readiness=true. Elapsed: 16.095720451s
Aug 27 18:58:38.074: INFO: Pod "pod-subpath-test-projected-rc6h": Phase="Running", Reason="", readiness=true. Elapsed: 18.106066083s
Aug 27 18:58:40.085: INFO: Pod "pod-subpath-test-projected-rc6h": Phase="Running", Reason="", readiness=true. Elapsed: 20.116527771s
Aug 27 18:58:42.096: INFO: Pod "pod-subpath-test-projected-rc6h": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.127517016s
STEP: Saw pod success
Aug 27 18:58:42.096: INFO: Pod "pod-subpath-test-projected-rc6h" satisfied condition "success or failure"
Aug 27 18:58:42.105: INFO: Trying to get logs from node 10.138.3.233 pod pod-subpath-test-projected-rc6h container test-container-subpath-projected-rc6h: <nil>
STEP: delete the pod
Aug 27 18:58:42.161: INFO: Waiting for pod pod-subpath-test-projected-rc6h to disappear
Aug 27 18:58:42.170: INFO: Pod pod-subpath-test-projected-rc6h no longer exists
STEP: Deleting pod pod-subpath-test-projected-rc6h
Aug 27 18:58:42.170: INFO: Deleting pod "pod-subpath-test-projected-rc6h" in namespace "subpath-5252"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 18:58:42.180: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-5252" for this suite.
Aug 27 18:58:48.240: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 18:58:48.620: INFO: namespace subpath-5252 deletion completed in 6.425093001s

• [SLOW TEST:28.928 seconds]
[sig-storage] Subpath
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with projected pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 18:58:48.620: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6231
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Aug 27 18:58:48.859: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c53263ac-cf2f-4156-b2b4-0e036e326b2a" in namespace "projected-6231" to be "success or failure"
Aug 27 18:58:49.081: INFO: Pod "downwardapi-volume-c53263ac-cf2f-4156-b2b4-0e036e326b2a": Phase="Pending", Reason="", readiness=false. Elapsed: 222.008119ms
Aug 27 18:58:51.092: INFO: Pod "downwardapi-volume-c53263ac-cf2f-4156-b2b4-0e036e326b2a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.232847012s
STEP: Saw pod success
Aug 27 18:58:51.092: INFO: Pod "downwardapi-volume-c53263ac-cf2f-4156-b2b4-0e036e326b2a" satisfied condition "success or failure"
Aug 27 18:58:51.102: INFO: Trying to get logs from node 10.138.3.233 pod downwardapi-volume-c53263ac-cf2f-4156-b2b4-0e036e326b2a container client-container: <nil>
STEP: delete the pod
Aug 27 18:58:51.157: INFO: Waiting for pod downwardapi-volume-c53263ac-cf2f-4156-b2b4-0e036e326b2a to disappear
Aug 27 18:58:51.167: INFO: Pod downwardapi-volume-c53263ac-cf2f-4156-b2b4-0e036e326b2a no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 18:58:51.167: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6231" for this suite.
Aug 27 18:58:57.229: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 18:58:57.588: INFO: namespace projected-6231 deletion completed in 6.405779321s

• [SLOW TEST:8.968 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 18:58:57.591: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-8329
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
Aug 27 18:58:57.818: INFO: observed the pod list
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 18:59:13.762: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-8329" for this suite.
Aug 27 18:59:19.842: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 18:59:20.260: INFO: namespace pods-8329 deletion completed in 6.463463532s

• [SLOW TEST:22.670 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 18:59:20.264: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-5189
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
Aug 27 18:59:20.486: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 18:59:24.420: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-5189" for this suite.
Aug 27 18:59:30.484: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 18:59:30.853: INFO: namespace init-container-5189 deletion completed in 6.417055336s

• [SLOW TEST:10.590 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 18:59:30.854: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-117
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
Aug 27 19:00:01.185: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
W0827 19:00:01.185182      16 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Aug 27 19:00:01.185: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-117" for this suite.
Aug 27 19:00:07.242: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 19:00:07.635: INFO: namespace gc-117 deletion completed in 6.437574154s

• [SLOW TEST:36.782 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 19:00:07.636: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-7313
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 19:00:34.481: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-7313" for this suite.
Aug 27 19:00:40.542: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 19:00:40.965: INFO: namespace container-runtime-7313 deletion completed in 6.467366512s

• [SLOW TEST:33.329 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  blackbox test
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
    when starting a container that exits
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 19:00:40.968: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-5128
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod busybox-e241319b-6038-41e5-8023-8c2b86085b9e in namespace container-probe-5128
Aug 27 19:00:45.234: INFO: Started pod busybox-e241319b-6038-41e5-8023-8c2b86085b9e in namespace container-probe-5128
STEP: checking the pod's current state and verifying that restartCount is present
Aug 27 19:00:45.244: INFO: Initial restart count of pod busybox-e241319b-6038-41e5-8023-8c2b86085b9e is 0
Aug 27 19:01:33.512: INFO: Restart count of pod container-probe-5128/busybox-e241319b-6038-41e5-8023-8c2b86085b9e is now 1 (48.267682872s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 19:01:33.541: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-5128" for this suite.
Aug 27 19:01:39.604: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 19:01:39.970: INFO: namespace container-probe-5128 deletion completed in 6.413585815s

• [SLOW TEST:59.003 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 19:01:39.971: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-7921
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Aug 27 19:01:40.290: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Aug 27 19:01:40.324: INFO: Number of nodes with available pods: 0
Aug 27 19:01:40.324: INFO: Node 10.138.3.199 is running more than one daemon pod
Aug 27 19:01:41.350: INFO: Number of nodes with available pods: 0
Aug 27 19:01:41.350: INFO: Node 10.138.3.199 is running more than one daemon pod
Aug 27 19:01:42.356: INFO: Number of nodes with available pods: 1
Aug 27 19:01:42.356: INFO: Node 10.138.3.233 is running more than one daemon pod
Aug 27 19:01:43.355: INFO: Number of nodes with available pods: 3
Aug 27 19:01:43.355: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Aug 27 19:01:43.436: INFO: Wrong image for pod: daemon-set-5jrrq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 27 19:01:43.436: INFO: Wrong image for pod: daemon-set-87sdv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 27 19:01:43.436: INFO: Wrong image for pod: daemon-set-w2c6c. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 27 19:01:44.470: INFO: Wrong image for pod: daemon-set-5jrrq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 27 19:01:44.470: INFO: Wrong image for pod: daemon-set-87sdv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 27 19:01:44.470: INFO: Wrong image for pod: daemon-set-w2c6c. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 27 19:01:45.458: INFO: Wrong image for pod: daemon-set-5jrrq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 27 19:01:45.458: INFO: Wrong image for pod: daemon-set-87sdv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 27 19:01:45.458: INFO: Wrong image for pod: daemon-set-w2c6c. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 27 19:01:46.460: INFO: Wrong image for pod: daemon-set-5jrrq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 27 19:01:46.460: INFO: Wrong image for pod: daemon-set-87sdv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 27 19:01:46.460: INFO: Wrong image for pod: daemon-set-w2c6c. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 27 19:01:46.460: INFO: Pod daemon-set-w2c6c is not available
Aug 27 19:01:47.458: INFO: Wrong image for pod: daemon-set-5jrrq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 27 19:01:47.459: INFO: Wrong image for pod: daemon-set-87sdv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 27 19:01:47.459: INFO: Wrong image for pod: daemon-set-w2c6c. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 27 19:01:47.459: INFO: Pod daemon-set-w2c6c is not available
Aug 27 19:01:48.459: INFO: Wrong image for pod: daemon-set-5jrrq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 27 19:01:48.459: INFO: Wrong image for pod: daemon-set-87sdv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 27 19:01:48.459: INFO: Wrong image for pod: daemon-set-w2c6c. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 27 19:01:48.459: INFO: Pod daemon-set-w2c6c is not available
Aug 27 19:01:49.459: INFO: Wrong image for pod: daemon-set-5jrrq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 27 19:01:49.459: INFO: Wrong image for pod: daemon-set-87sdv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 27 19:01:49.459: INFO: Wrong image for pod: daemon-set-w2c6c. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 27 19:01:49.459: INFO: Pod daemon-set-w2c6c is not available
Aug 27 19:01:50.459: INFO: Wrong image for pod: daemon-set-5jrrq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 27 19:01:50.459: INFO: Wrong image for pod: daemon-set-87sdv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 27 19:01:50.459: INFO: Wrong image for pod: daemon-set-w2c6c. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 27 19:01:50.459: INFO: Pod daemon-set-w2c6c is not available
Aug 27 19:01:51.458: INFO: Wrong image for pod: daemon-set-5jrrq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 27 19:01:51.458: INFO: Wrong image for pod: daemon-set-87sdv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 27 19:01:51.458: INFO: Wrong image for pod: daemon-set-w2c6c. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 27 19:01:51.458: INFO: Pod daemon-set-w2c6c is not available
Aug 27 19:01:52.458: INFO: Wrong image for pod: daemon-set-5jrrq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 27 19:01:52.458: INFO: Wrong image for pod: daemon-set-87sdv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 27 19:01:52.458: INFO: Wrong image for pod: daemon-set-w2c6c. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 27 19:01:52.458: INFO: Pod daemon-set-w2c6c is not available
Aug 27 19:01:53.459: INFO: Wrong image for pod: daemon-set-5jrrq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 27 19:01:53.459: INFO: Wrong image for pod: daemon-set-87sdv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 27 19:01:53.459: INFO: Wrong image for pod: daemon-set-w2c6c. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 27 19:01:53.459: INFO: Pod daemon-set-w2c6c is not available
Aug 27 19:01:54.458: INFO: Wrong image for pod: daemon-set-5jrrq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 27 19:01:54.458: INFO: Wrong image for pod: daemon-set-87sdv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 27 19:01:54.458: INFO: Pod daemon-set-9qf2c is not available
Aug 27 19:01:55.458: INFO: Wrong image for pod: daemon-set-5jrrq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 27 19:01:55.458: INFO: Wrong image for pod: daemon-set-87sdv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 27 19:01:55.458: INFO: Pod daemon-set-9qf2c is not available
Aug 27 19:01:56.463: INFO: Wrong image for pod: daemon-set-5jrrq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 27 19:01:56.463: INFO: Wrong image for pod: daemon-set-87sdv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 27 19:01:57.458: INFO: Wrong image for pod: daemon-set-5jrrq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 27 19:01:57.459: INFO: Wrong image for pod: daemon-set-87sdv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 27 19:01:57.459: INFO: Pod daemon-set-87sdv is not available
Aug 27 19:01:58.458: INFO: Wrong image for pod: daemon-set-5jrrq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 27 19:01:58.458: INFO: Wrong image for pod: daemon-set-87sdv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 27 19:01:58.458: INFO: Pod daemon-set-87sdv is not available
Aug 27 19:01:59.458: INFO: Wrong image for pod: daemon-set-5jrrq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 27 19:01:59.458: INFO: Wrong image for pod: daemon-set-87sdv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 27 19:01:59.458: INFO: Pod daemon-set-87sdv is not available
Aug 27 19:02:00.458: INFO: Wrong image for pod: daemon-set-5jrrq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 27 19:02:00.458: INFO: Wrong image for pod: daemon-set-87sdv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 27 19:02:00.458: INFO: Pod daemon-set-87sdv is not available
Aug 27 19:02:01.460: INFO: Wrong image for pod: daemon-set-5jrrq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 27 19:02:01.460: INFO: Wrong image for pod: daemon-set-87sdv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 27 19:02:01.461: INFO: Pod daemon-set-87sdv is not available
Aug 27 19:02:02.458: INFO: Wrong image for pod: daemon-set-5jrrq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 27 19:02:02.458: INFO: Wrong image for pod: daemon-set-87sdv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 27 19:02:02.458: INFO: Pod daemon-set-87sdv is not available
Aug 27 19:02:03.459: INFO: Wrong image for pod: daemon-set-5jrrq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 27 19:02:03.459: INFO: Wrong image for pod: daemon-set-87sdv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 27 19:02:03.459: INFO: Pod daemon-set-87sdv is not available
Aug 27 19:02:04.459: INFO: Wrong image for pod: daemon-set-5jrrq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 27 19:02:04.459: INFO: Wrong image for pod: daemon-set-87sdv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 27 19:02:04.459: INFO: Pod daemon-set-87sdv is not available
Aug 27 19:02:05.460: INFO: Wrong image for pod: daemon-set-5jrrq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 27 19:02:05.460: INFO: Wrong image for pod: daemon-set-87sdv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 27 19:02:05.460: INFO: Pod daemon-set-87sdv is not available
Aug 27 19:02:06.458: INFO: Wrong image for pod: daemon-set-5jrrq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 27 19:02:06.458: INFO: Wrong image for pod: daemon-set-87sdv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 27 19:02:06.458: INFO: Pod daemon-set-87sdv is not available
Aug 27 19:02:07.458: INFO: Wrong image for pod: daemon-set-5jrrq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 27 19:02:07.459: INFO: Wrong image for pod: daemon-set-87sdv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 27 19:02:07.459: INFO: Pod daemon-set-87sdv is not available
Aug 27 19:02:08.458: INFO: Wrong image for pod: daemon-set-5jrrq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 27 19:02:08.458: INFO: Wrong image for pod: daemon-set-87sdv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 27 19:02:08.458: INFO: Pod daemon-set-87sdv is not available
Aug 27 19:02:09.457: INFO: Wrong image for pod: daemon-set-5jrrq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 27 19:02:09.458: INFO: Pod daemon-set-g698j is not available
Aug 27 19:02:10.459: INFO: Wrong image for pod: daemon-set-5jrrq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 27 19:02:10.459: INFO: Pod daemon-set-g698j is not available
Aug 27 19:02:11.458: INFO: Wrong image for pod: daemon-set-5jrrq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 27 19:02:11.458: INFO: Pod daemon-set-g698j is not available
Aug 27 19:02:12.458: INFO: Wrong image for pod: daemon-set-5jrrq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 27 19:02:12.458: INFO: Pod daemon-set-g698j is not available
Aug 27 19:02:13.473: INFO: Wrong image for pod: daemon-set-5jrrq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 27 19:02:13.473: INFO: Pod daemon-set-g698j is not available
Aug 27 19:02:14.458: INFO: Wrong image for pod: daemon-set-5jrrq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 27 19:02:15.458: INFO: Wrong image for pod: daemon-set-5jrrq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 27 19:02:15.458: INFO: Pod daemon-set-5jrrq is not available
Aug 27 19:02:16.457: INFO: Wrong image for pod: daemon-set-5jrrq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 27 19:02:16.458: INFO: Pod daemon-set-5jrrq is not available
Aug 27 19:02:17.458: INFO: Pod daemon-set-xl7v5 is not available
STEP: Check that daemon pods are still running on every node of the cluster.
Aug 27 19:02:17.494: INFO: Number of nodes with available pods: 2
Aug 27 19:02:17.494: INFO: Node 10.138.3.233 is running more than one daemon pod
Aug 27 19:02:18.523: INFO: Number of nodes with available pods: 3
Aug 27 19:02:18.523: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-7921, will wait for the garbage collector to delete the pods
Aug 27 19:02:18.661: INFO: Deleting DaemonSet.extensions daemon-set took: 22.511728ms
Aug 27 19:02:18.761: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.279843ms
Aug 27 19:02:23.771: INFO: Number of nodes with available pods: 0
Aug 27 19:02:23.771: INFO: Number of running nodes: 0, number of available pods: 0
Aug 27 19:02:23.781: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-7921/daemonsets","resourceVersion":"29087"},"items":null}

Aug 27 19:02:23.790: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-7921/pods","resourceVersion":"29087"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 19:02:23.838: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-7921" for this suite.
Aug 27 19:02:31.897: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 19:02:32.272: INFO: namespace daemonsets-7921 deletion completed in 8.418986346s

• [SLOW TEST:52.301 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 19:02:32.272: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-7037
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating Redis RC
Aug 27 19:02:32.490: INFO: namespace kubectl-7037
Aug 27 19:02:32.490: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-540514467 create -f - --namespace=kubectl-7037'
Aug 27 19:02:32.750: INFO: stderr: ""
Aug 27 19:02:32.750: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Aug 27 19:02:33.761: INFO: Selector matched 1 pods for map[app:redis]
Aug 27 19:02:33.761: INFO: Found 0 / 1
Aug 27 19:02:34.762: INFO: Selector matched 1 pods for map[app:redis]
Aug 27 19:02:34.762: INFO: Found 1 / 1
Aug 27 19:02:34.762: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Aug 27 19:02:34.771: INFO: Selector matched 1 pods for map[app:redis]
Aug 27 19:02:34.771: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Aug 27 19:02:34.771: INFO: wait on redis-master startup in kubectl-7037 
Aug 27 19:02:34.771: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-540514467 logs redis-master-gdqc2 redis-master --namespace=kubectl-7037'
Aug 27 19:02:34.931: INFO: stderr: ""
Aug 27 19:02:34.931: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 27 Aug 19:02:34.206 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 27 Aug 19:02:34.206 # Server started, Redis version 3.2.12\n1:M 27 Aug 19:02:34.206 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 27 Aug 19:02:34.206 * The server is now ready to accept connections on port 6379\n"
STEP: exposing RC
Aug 27 19:02:34.931: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-540514467 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=kubectl-7037'
Aug 27 19:02:35.095: INFO: stderr: ""
Aug 27 19:02:35.095: INFO: stdout: "service/rm2 exposed\n"
Aug 27 19:02:35.106: INFO: Service rm2 in namespace kubectl-7037 found.
STEP: exposing service
Aug 27 19:02:37.129: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-540514467 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=kubectl-7037'
Aug 27 19:02:37.285: INFO: stderr: ""
Aug 27 19:02:37.285: INFO: stdout: "service/rm3 exposed\n"
Aug 27 19:02:37.297: INFO: Service rm3 in namespace kubectl-7037 found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 19:02:39.320: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7037" for this suite.
Aug 27 19:03:03.380: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 19:03:03.770: INFO: namespace kubectl-7037 deletion completed in 24.435219659s

• [SLOW TEST:31.499 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl expose
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create services for rc  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 19:03:03.771: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-4607
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-28b1a413-001e-4372-9b64-4d3bbd77740c
STEP: Creating a pod to test consume secrets
Aug 27 19:03:04.024: INFO: Waiting up to 5m0s for pod "pod-secrets-3fde93db-0e1b-4549-be3f-5ef0298975a8" in namespace "secrets-4607" to be "success or failure"
Aug 27 19:03:04.035: INFO: Pod "pod-secrets-3fde93db-0e1b-4549-be3f-5ef0298975a8": Phase="Pending", Reason="", readiness=false. Elapsed: 10.636415ms
Aug 27 19:03:06.045: INFO: Pod "pod-secrets-3fde93db-0e1b-4549-be3f-5ef0298975a8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021019235s
STEP: Saw pod success
Aug 27 19:03:06.045: INFO: Pod "pod-secrets-3fde93db-0e1b-4549-be3f-5ef0298975a8" satisfied condition "success or failure"
Aug 27 19:03:06.055: INFO: Trying to get logs from node 10.138.3.242 pod pod-secrets-3fde93db-0e1b-4549-be3f-5ef0298975a8 container secret-volume-test: <nil>
STEP: delete the pod
Aug 27 19:03:06.099: INFO: Waiting for pod pod-secrets-3fde93db-0e1b-4549-be3f-5ef0298975a8 to disappear
Aug 27 19:03:06.110: INFO: Pod pod-secrets-3fde93db-0e1b-4549-be3f-5ef0298975a8 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 19:03:06.110: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-4607" for this suite.
Aug 27 19:03:12.169: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 19:03:12.530: INFO: namespace secrets-4607 deletion completed in 6.403954317s

• [SLOW TEST:8.758 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 19:03:12.530: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-7194
STEP: Waiting for a default service account to be provisioned in namespace
[It] pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating Pod
STEP: Waiting for the pod running
STEP: Geting the pod
STEP: Reading file content from the nginx-container
Aug 27 19:03:14.822: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-540514467 exec pod-sharedvolume-c68a0e19-6b34-4273-b024-3105eff789e6 -c busybox-main-container --namespace=emptydir-7194 -- cat /usr/share/volumeshare/shareddata.txt'
Aug 27 19:03:15.270: INFO: stderr: ""
Aug 27 19:03:15.270: INFO: stdout: "Hello from the busy-box sub-container\n"
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 19:03:15.270: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7194" for this suite.
Aug 27 19:03:21.332: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 19:03:21.713: INFO: namespace emptydir-7194 deletion completed in 6.426757801s

• [SLOW TEST:9.183 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 19:03:21.715: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-4882
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating pod
Aug 27 19:03:23.992: INFO: Pod pod-hostip-fc92487a-8c06-4b47-8b09-c90ecb6ea8d2 has hostIP: 10.138.3.242
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 19:03:23.992: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-4882" for this suite.
Aug 27 19:03:48.052: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 19:03:48.461: INFO: namespace pods-4882 deletion completed in 24.453270402s

• [SLOW TEST:26.747 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 19:03:48.465: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-1133
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Aug 27 19:03:50.758: INFO: Expected: &{OK} to match Container's Termination Message: OK --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 19:03:50.792: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-1133" for this suite.
Aug 27 19:03:56.859: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 19:03:57.238: INFO: namespace container-runtime-1133 deletion completed in 6.424238336s

• [SLOW TEST:8.773 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  blackbox test
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
    on terminated container
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:129
      should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 19:03:57.239: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename events
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in events-4969
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Aug 27 19:04:03.519: INFO: &Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-fcb4120b-203d-4e65-8e1e-9cda39299db7,GenerateName:,Namespace:events-4969,SelfLink:/api/v1/namespaces/events-4969/pods/send-events-fcb4120b-203d-4e65-8e1e-9cda39299db7,UID:8034175f-73d0-47a1-a5a6-7ced79a1dc97,ResourceVersion:29539,Generation:0,CreationTimestamp:2019-08-27 19:03:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 461014545,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-26j9r {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-26j9r,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-26j9r true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.138.3.242,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0038f2310} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0038f2330}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:03:57 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:04:02 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:04:02 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:03:57 +0000 UTC  }],Message:,Reason:,HostIP:10.138.3.242,PodIP:172.30.115.30,StartTime:2019-08-27 19:03:57 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2019-08-27 19:04:02 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 gcr.io/kubernetes-e2e-test-images/serve-hostname@sha256:bab70473a6d8ef65a22625dc9a1b0f0452e811530fdbe77e4408523460177ff1 containerd://465279063dcbe9ec2bc9b36eebc1a8ce9751a41048a18c78548b9c6c76ce0455}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}

STEP: checking for scheduler event about the pod
Aug 27 19:04:05.533: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Aug 27 19:04:07.546: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 19:04:07.562: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-4969" for this suite.
Aug 27 19:04:47.622: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 19:04:48.059: INFO: namespace events-4969 deletion completed in 40.481991624s

• [SLOW TEST:50.820 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 19:04:48.062: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-5451
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Aug 27 19:04:48.302: INFO: Waiting up to 5m0s for pod "downward-api-c8388afb-3c61-4516-96e6-d894cef42939" in namespace "downward-api-5451" to be "success or failure"
Aug 27 19:04:48.312: INFO: Pod "downward-api-c8388afb-3c61-4516-96e6-d894cef42939": Phase="Pending", Reason="", readiness=false. Elapsed: 10.026377ms
Aug 27 19:04:50.326: INFO: Pod "downward-api-c8388afb-3c61-4516-96e6-d894cef42939": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023518208s
Aug 27 19:04:52.337: INFO: Pod "downward-api-c8388afb-3c61-4516-96e6-d894cef42939": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.034889111s
STEP: Saw pod success
Aug 27 19:04:52.337: INFO: Pod "downward-api-c8388afb-3c61-4516-96e6-d894cef42939" satisfied condition "success or failure"
Aug 27 19:04:52.347: INFO: Trying to get logs from node 10.138.3.233 pod downward-api-c8388afb-3c61-4516-96e6-d894cef42939 container dapi-container: <nil>
STEP: delete the pod
Aug 27 19:04:52.394: INFO: Waiting for pod downward-api-c8388afb-3c61-4516-96e6-d894cef42939 to disappear
Aug 27 19:04:52.403: INFO: Pod downward-api-c8388afb-3c61-4516-96e6-d894cef42939 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 19:04:52.403: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5451" for this suite.
Aug 27 19:04:58.463: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 19:04:58.841: INFO: namespace downward-api-5451 deletion completed in 6.422477532s

• [SLOW TEST:10.780 seconds]
[sig-node] Downward API
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 19:04:58.843: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in namespaces-2175
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-36
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-3141
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 19:05:24.682: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-2175" for this suite.
Aug 27 19:05:30.743: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 19:05:31.101: INFO: namespace namespaces-2175 deletion completed in 6.403741329s
STEP: Destroying namespace "nsdeletetest-36" for this suite.
Aug 27 19:05:31.113: INFO: Namespace nsdeletetest-36 was already deleted
STEP: Destroying namespace "nsdeletetest-3141" for this suite.
Aug 27 19:05:37.156: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 19:05:37.510: INFO: namespace nsdeletetest-3141 deletion completed in 6.396468757s

• [SLOW TEST:38.667 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 19:05:37.515: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-822
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-822
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace statefulset-822
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-822
Aug 27 19:05:37.778: INFO: Found 0 stateful pods, waiting for 1
Aug 27 19:05:47.789: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Aug 27 19:05:47.799: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-540514467 exec --namespace=statefulset-822 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Aug 27 19:05:48.289: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Aug 27 19:05:48.289: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Aug 27 19:05:48.289: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Aug 27 19:05:48.300: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Aug 27 19:05:58.311: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Aug 27 19:05:58.311: INFO: Waiting for statefulset status.replicas updated to 0
Aug 27 19:05:58.351: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999998014s
Aug 27 19:05:59.362: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.990042937s
Aug 27 19:06:00.380: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.979491511s
Aug 27 19:06:01.391: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.961508276s
Aug 27 19:06:02.403: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.950436919s
Aug 27 19:06:03.413: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.938468675s
Aug 27 19:06:04.424: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.928072192s
Aug 27 19:06:05.435: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.917141655s
Aug 27 19:06:06.449: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.906331964s
Aug 27 19:06:07.459: INFO: Verifying statefulset ss doesn't scale past 1 for another 892.731149ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-822
Aug 27 19:06:08.471: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-540514467 exec --namespace=statefulset-822 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 27 19:06:08.907: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Aug 27 19:06:08.907: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Aug 27 19:06:08.907: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Aug 27 19:06:08.918: INFO: Found 1 stateful pods, waiting for 3
Aug 27 19:06:18.939: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Aug 27 19:06:18.939: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Aug 27 19:06:18.939: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Aug 27 19:06:18.955: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-540514467 exec --namespace=statefulset-822 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Aug 27 19:06:19.440: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Aug 27 19:06:19.440: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Aug 27 19:06:19.440: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Aug 27 19:06:19.440: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-540514467 exec --namespace=statefulset-822 ss-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Aug 27 19:06:19.903: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Aug 27 19:06:19.903: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Aug 27 19:06:19.903: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Aug 27 19:06:19.903: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-540514467 exec --namespace=statefulset-822 ss-2 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Aug 27 19:06:20.362: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Aug 27 19:06:20.362: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Aug 27 19:06:20.362: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Aug 27 19:06:20.362: INFO: Waiting for statefulset status.replicas updated to 0
Aug 27 19:06:20.372: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 1
Aug 27 19:06:30.394: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Aug 27 19:06:30.394: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Aug 27 19:06:30.394: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Aug 27 19:06:30.425: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999998036s
Aug 27 19:06:31.437: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.989639134s
Aug 27 19:06:32.448: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.978049791s
Aug 27 19:06:33.459: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.966803795s
Aug 27 19:06:34.471: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.955578782s
Aug 27 19:06:35.488: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.944052569s
Aug 27 19:06:36.499: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.926756814s
Aug 27 19:06:37.511: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.915581474s
Aug 27 19:06:38.522: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.903832065s
Aug 27 19:06:39.532: INFO: Verifying statefulset ss doesn't scale past 3 for another 893.057391ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-822
Aug 27 19:06:40.543: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-540514467 exec --namespace=statefulset-822 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 27 19:06:41.191: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Aug 27 19:06:41.191: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Aug 27 19:06:41.191: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Aug 27 19:06:41.191: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-540514467 exec --namespace=statefulset-822 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 27 19:06:41.647: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Aug 27 19:06:41.647: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Aug 27 19:06:41.647: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Aug 27 19:06:41.647: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-540514467 exec --namespace=statefulset-822 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 27 19:06:42.153: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Aug 27 19:06:42.153: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Aug 27 19:06:42.153: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Aug 27 19:06:42.153: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Aug 27 19:07:02.200: INFO: Deleting all statefulset in ns statefulset-822
Aug 27 19:07:02.210: INFO: Scaling statefulset ss to 0
Aug 27 19:07:02.240: INFO: Waiting for statefulset status.replicas updated to 0
Aug 27 19:07:02.249: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 19:07:02.292: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-822" for this suite.
Aug 27 19:07:08.354: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 19:07:08.741: INFO: namespace statefulset-822 deletion completed in 6.433486149s

• [SLOW TEST:91.226 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 19:07:08.746: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-wrapper-7895
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 19:07:15.104: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-7895" for this suite.
Aug 27 19:07:21.163: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 19:07:21.551: INFO: namespace emptydir-wrapper-7895 deletion completed in 6.43233525s

• [SLOW TEST:12.805 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not conflict [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 19:07:21.551: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-9355
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-5dee5ddc-5da3-45d7-a81e-edd07e22ce0f
STEP: Creating a pod to test consume configMaps
Aug 27 19:07:21.802: INFO: Waiting up to 5m0s for pod "pod-configmaps-23c40db1-d366-46d3-a4f9-221254f803bb" in namespace "configmap-9355" to be "success or failure"
Aug 27 19:07:21.811: INFO: Pod "pod-configmaps-23c40db1-d366-46d3-a4f9-221254f803bb": Phase="Pending", Reason="", readiness=false. Elapsed: 9.690794ms
Aug 27 19:07:23.822: INFO: Pod "pod-configmaps-23c40db1-d366-46d3-a4f9-221254f803bb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020158111s
Aug 27 19:07:25.833: INFO: Pod "pod-configmaps-23c40db1-d366-46d3-a4f9-221254f803bb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.031258566s
STEP: Saw pod success
Aug 27 19:07:25.833: INFO: Pod "pod-configmaps-23c40db1-d366-46d3-a4f9-221254f803bb" satisfied condition "success or failure"
Aug 27 19:07:25.843: INFO: Trying to get logs from node 10.138.3.233 pod pod-configmaps-23c40db1-d366-46d3-a4f9-221254f803bb container configmap-volume-test: <nil>
STEP: delete the pod
Aug 27 19:07:25.905: INFO: Waiting for pod pod-configmaps-23c40db1-d366-46d3-a4f9-221254f803bb to disappear
Aug 27 19:07:25.914: INFO: Pod pod-configmaps-23c40db1-d366-46d3-a4f9-221254f803bb no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 19:07:25.915: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9355" for this suite.
Aug 27 19:07:31.974: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 19:07:32.343: INFO: namespace configmap-9355 deletion completed in 6.411756097s

• [SLOW TEST:10.792 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 19:07:32.344: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in namespaces-2321
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-8598
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-5832
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 19:07:39.054: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-2321" for this suite.
Aug 27 19:07:45.115: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 19:07:45.516: INFO: namespace namespaces-2321 deletion completed in 6.443856289s
STEP: Destroying namespace "nsdeletetest-8598" for this suite.
Aug 27 19:07:45.534: INFO: Namespace nsdeletetest-8598 was already deleted
STEP: Destroying namespace "nsdeletetest-5832" for this suite.
Aug 27 19:07:51.581: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 19:07:51.968: INFO: namespace nsdeletetest-5832 deletion completed in 6.43342149s

• [SLOW TEST:19.624 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 19:07:51.968: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-1105
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating service endpoint-test2 in namespace services-1105
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-1105 to expose endpoints map[]
Aug 27 19:07:52.215: INFO: successfully validated that service endpoint-test2 in namespace services-1105 exposes endpoints map[] (9.559872ms elapsed)
STEP: Creating pod pod1 in namespace services-1105
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-1105 to expose endpoints map[pod1:[80]]
Aug 27 19:07:54.298: INFO: successfully validated that service endpoint-test2 in namespace services-1105 exposes endpoints map[pod1:[80]] (2.063988325s elapsed)
STEP: Creating pod pod2 in namespace services-1105
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-1105 to expose endpoints map[pod1:[80] pod2:[80]]
Aug 27 19:07:57.446: INFO: successfully validated that service endpoint-test2 in namespace services-1105 exposes endpoints map[pod1:[80] pod2:[80]] (3.133931648s elapsed)
STEP: Deleting pod pod1 in namespace services-1105
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-1105 to expose endpoints map[pod2:[80]]
Aug 27 19:07:57.480: INFO: successfully validated that service endpoint-test2 in namespace services-1105 exposes endpoints map[pod2:[80]] (19.947122ms elapsed)
STEP: Deleting pod pod2 in namespace services-1105
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-1105 to expose endpoints map[]
Aug 27 19:07:57.504: INFO: successfully validated that service endpoint-test2 in namespace services-1105 exposes endpoints map[] (9.822677ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 19:07:57.556: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-1105" for this suite.
Aug 27 19:08:03.622: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 19:08:03.999: INFO: namespace services-1105 deletion completed in 6.427213631s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:92

• [SLOW TEST:12.032 seconds]
[sig-network] Services
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 19:08:04.000: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-3984
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap configmap-3984/configmap-test-f676d2d9-c20f-452e-a1af-cc9b158255f5
STEP: Creating a pod to test consume configMaps
Aug 27 19:08:04.248: INFO: Waiting up to 5m0s for pod "pod-configmaps-b903baa6-59bf-43d1-8c5b-742b0ec002d4" in namespace "configmap-3984" to be "success or failure"
Aug 27 19:08:04.259: INFO: Pod "pod-configmaps-b903baa6-59bf-43d1-8c5b-742b0ec002d4": Phase="Pending", Reason="", readiness=false. Elapsed: 11.210064ms
Aug 27 19:08:06.269: INFO: Pod "pod-configmaps-b903baa6-59bf-43d1-8c5b-742b0ec002d4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021674938s
Aug 27 19:08:08.281: INFO: Pod "pod-configmaps-b903baa6-59bf-43d1-8c5b-742b0ec002d4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.033284458s
STEP: Saw pod success
Aug 27 19:08:08.281: INFO: Pod "pod-configmaps-b903baa6-59bf-43d1-8c5b-742b0ec002d4" satisfied condition "success or failure"
Aug 27 19:08:08.307: INFO: Trying to get logs from node 10.138.3.242 pod pod-configmaps-b903baa6-59bf-43d1-8c5b-742b0ec002d4 container env-test: <nil>
STEP: delete the pod
Aug 27 19:08:08.365: INFO: Waiting for pod pod-configmaps-b903baa6-59bf-43d1-8c5b-742b0ec002d4 to disappear
Aug 27 19:08:08.374: INFO: Pod pod-configmaps-b903baa6-59bf-43d1-8c5b-742b0ec002d4 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 19:08:08.374: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3984" for this suite.
Aug 27 19:08:14.432: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 19:08:14.822: INFO: namespace configmap-3984 deletion completed in 6.433354358s

• [SLOW TEST:10.822 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 19:08:14.824: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-6012
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir volume type on tmpfs
Aug 27 19:08:15.061: INFO: Waiting up to 5m0s for pod "pod-57d642bd-efa3-483d-a16c-f926677cc44b" in namespace "emptydir-6012" to be "success or failure"
Aug 27 19:08:15.072: INFO: Pod "pod-57d642bd-efa3-483d-a16c-f926677cc44b": Phase="Pending", Reason="", readiness=false. Elapsed: 10.087022ms
Aug 27 19:08:17.082: INFO: Pod "pod-57d642bd-efa3-483d-a16c-f926677cc44b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020381406s
Aug 27 19:08:19.094: INFO: Pod "pod-57d642bd-efa3-483d-a16c-f926677cc44b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.032191412s
STEP: Saw pod success
Aug 27 19:08:19.094: INFO: Pod "pod-57d642bd-efa3-483d-a16c-f926677cc44b" satisfied condition "success or failure"
Aug 27 19:08:19.103: INFO: Trying to get logs from node 10.138.3.233 pod pod-57d642bd-efa3-483d-a16c-f926677cc44b container test-container: <nil>
STEP: delete the pod
Aug 27 19:08:19.154: INFO: Waiting for pod pod-57d642bd-efa3-483d-a16c-f926677cc44b to disappear
Aug 27 19:08:19.166: INFO: Pod pod-57d642bd-efa3-483d-a16c-f926677cc44b no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 19:08:19.166: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6012" for this suite.
Aug 27 19:08:25.226: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 19:08:25.615: INFO: namespace emptydir-6012 deletion completed in 6.433297515s

• [SLOW TEST:10.792 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 19:08:25.617: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6219
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-map-b4080295-cf49-482d-9b65-a072c1c5c892
STEP: Creating a pod to test consume configMaps
Aug 27 19:08:25.868: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-b7210f10-2ff3-4727-ad14-e86775fbca65" in namespace "projected-6219" to be "success or failure"
Aug 27 19:08:25.890: INFO: Pod "pod-projected-configmaps-b7210f10-2ff3-4727-ad14-e86775fbca65": Phase="Pending", Reason="", readiness=false. Elapsed: 21.534315ms
Aug 27 19:08:27.902: INFO: Pod "pod-projected-configmaps-b7210f10-2ff3-4727-ad14-e86775fbca65": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.033343584s
STEP: Saw pod success
Aug 27 19:08:27.902: INFO: Pod "pod-projected-configmaps-b7210f10-2ff3-4727-ad14-e86775fbca65" satisfied condition "success or failure"
Aug 27 19:08:27.911: INFO: Trying to get logs from node 10.138.3.242 pod pod-projected-configmaps-b7210f10-2ff3-4727-ad14-e86775fbca65 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Aug 27 19:08:27.955: INFO: Waiting for pod pod-projected-configmaps-b7210f10-2ff3-4727-ad14-e86775fbca65 to disappear
Aug 27 19:08:27.965: INFO: Pod pod-projected-configmaps-b7210f10-2ff3-4727-ad14-e86775fbca65 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 19:08:27.965: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6219" for this suite.
Aug 27 19:08:34.026: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 19:08:34.383: INFO: namespace projected-6219 deletion completed in 6.402234029s

• [SLOW TEST:8.767 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 19:08:34.392: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-3812
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0777 on node default medium
Aug 27 19:08:34.637: INFO: Waiting up to 5m0s for pod "pod-0acfb503-b268-4323-84ce-b385212c98f6" in namespace "emptydir-3812" to be "success or failure"
Aug 27 19:08:34.649: INFO: Pod "pod-0acfb503-b268-4323-84ce-b385212c98f6": Phase="Pending", Reason="", readiness=false. Elapsed: 11.702134ms
Aug 27 19:08:36.660: INFO: Pod "pod-0acfb503-b268-4323-84ce-b385212c98f6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.022677291s
STEP: Saw pod success
Aug 27 19:08:36.660: INFO: Pod "pod-0acfb503-b268-4323-84ce-b385212c98f6" satisfied condition "success or failure"
Aug 27 19:08:36.670: INFO: Trying to get logs from node 10.138.3.233 pod pod-0acfb503-b268-4323-84ce-b385212c98f6 container test-container: <nil>
STEP: delete the pod
Aug 27 19:08:36.717: INFO: Waiting for pod pod-0acfb503-b268-4323-84ce-b385212c98f6 to disappear
Aug 27 19:08:36.729: INFO: Pod pod-0acfb503-b268-4323-84ce-b385212c98f6 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 19:08:36.729: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3812" for this suite.
Aug 27 19:08:42.788: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 19:08:43.271: INFO: namespace emptydir-3812 deletion completed in 6.526395123s

• [SLOW TEST:8.880 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 19:08:43.271: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replicaset-247
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Aug 27 19:08:43.491: INFO: Creating ReplicaSet my-hostname-basic-74925961-4a48-4e95-9442-d6afb6f8bd88
Aug 27 19:08:43.515: INFO: Pod name my-hostname-basic-74925961-4a48-4e95-9442-d6afb6f8bd88: Found 0 pods out of 1
Aug 27 19:08:48.528: INFO: Pod name my-hostname-basic-74925961-4a48-4e95-9442-d6afb6f8bd88: Found 1 pods out of 1
Aug 27 19:08:48.529: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-74925961-4a48-4e95-9442-d6afb6f8bd88" is running
Aug 27 19:08:50.549: INFO: Pod "my-hostname-basic-74925961-4a48-4e95-9442-d6afb6f8bd88-kth5z" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-08-27 19:08:43 +0000 UTC Reason: Message:} {Type:Ready Status:False LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-08-27 19:08:43 +0000 UTC Reason:ContainersNotReady Message:containers with unready status: [my-hostname-basic-74925961-4a48-4e95-9442-d6afb6f8bd88]} {Type:ContainersReady Status:False LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-08-27 19:08:43 +0000 UTC Reason:ContainersNotReady Message:containers with unready status: [my-hostname-basic-74925961-4a48-4e95-9442-d6afb6f8bd88]} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-08-27 19:08:43 +0000 UTC Reason: Message:}])
Aug 27 19:08:50.549: INFO: Trying to dial the pod
Aug 27 19:08:55.587: INFO: Controller my-hostname-basic-74925961-4a48-4e95-9442-d6afb6f8bd88: Got expected result from replica 1 [my-hostname-basic-74925961-4a48-4e95-9442-d6afb6f8bd88-kth5z]: "my-hostname-basic-74925961-4a48-4e95-9442-d6afb6f8bd88-kth5z", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 19:08:55.587: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-247" for this suite.
Aug 27 19:09:01.650: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 19:09:02.042: INFO: namespace replicaset-247 deletion completed in 6.437715615s

• [SLOW TEST:18.771 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 19:09:02.042: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-3633
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1722
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Aug 27 19:09:02.262: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-540514467 run e2e-test-nginx-pod --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --labels=run=e2e-test-nginx-pod --namespace=kubectl-3633'
Aug 27 19:09:02.411: INFO: stderr: ""
Aug 27 19:09:02.411: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod is running
STEP: verifying the pod e2e-test-nginx-pod was created
Aug 27 19:09:07.462: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-540514467 get pod e2e-test-nginx-pod --namespace=kubectl-3633 -o json'
Aug 27 19:09:07.580: INFO: stderr: ""
Aug 27 19:09:07.580: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"annotations\": {\n            \"kubernetes.io/psp\": \"e2e-test-privileged-psp\"\n        },\n        \"creationTimestamp\": \"2019-08-27T19:09:02Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"kubectl-3633\",\n        \"resourceVersion\": \"30789\",\n        \"selfLink\": \"/api/v1/namespaces/kubectl-3633/pods/e2e-test-nginx-pod\",\n        \"uid\": \"7fc4da24-3b4e-4cd3-8739-6822f6018ce1\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-gngbb\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"10.138.3.242\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 600\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 600\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-gngbb\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-gngbb\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-08-27T19:09:02Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-08-27T19:09:04Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-08-27T19:09:04Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-08-27T19:09:02Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"containerd://d92ec610b4884e3ccb1419c2b5ee6eff954396c9071609bbd1aaab49e9ef2a44\",\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imageID\": \"docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2019-08-27T19:09:03Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.138.3.242\",\n        \"phase\": \"Running\",\n        \"podIP\": \"172.30.115.34\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2019-08-27T19:09:02Z\"\n    }\n}\n"
STEP: replace the image in the pod
Aug 27 19:09:07.580: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-540514467 replace -f - --namespace=kubectl-3633'
Aug 27 19:09:07.838: INFO: stderr: ""
Aug 27 19:09:07.838: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
STEP: verifying the pod e2e-test-nginx-pod has the right image docker.io/library/busybox:1.29
[AfterEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1727
Aug 27 19:09:07.848: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-540514467 delete pods e2e-test-nginx-pod --namespace=kubectl-3633'
Aug 27 19:09:13.755: INFO: stderr: ""
Aug 27 19:09:13.755: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 19:09:13.755: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3633" for this suite.
Aug 27 19:09:19.820: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 19:09:20.275: INFO: namespace kubectl-3633 deletion completed in 6.500626641s

• [SLOW TEST:18.233 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl replace
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 19:09:20.275: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-4898
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 19:09:24.543: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-4898" for this suite.
Aug 27 19:09:30.607: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 19:09:31.007: INFO: namespace kubelet-test-4898 deletion completed in 6.447073091s

• [SLOW TEST:10.732 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should have an terminated reason [NodeConformance] [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 19:09:31.008: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-3213
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-downwardapi-9c7p
STEP: Creating a pod to test atomic-volume-subpath
Aug 27 19:09:31.286: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-9c7p" in namespace "subpath-3213" to be "success or failure"
Aug 27 19:09:31.299: INFO: Pod "pod-subpath-test-downwardapi-9c7p": Phase="Pending", Reason="", readiness=false. Elapsed: 13.216966ms
Aug 27 19:09:33.311: INFO: Pod "pod-subpath-test-downwardapi-9c7p": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025577671s
Aug 27 19:09:35.322: INFO: Pod "pod-subpath-test-downwardapi-9c7p": Phase="Running", Reason="", readiness=true. Elapsed: 4.036612492s
Aug 27 19:09:37.334: INFO: Pod "pod-subpath-test-downwardapi-9c7p": Phase="Running", Reason="", readiness=true. Elapsed: 6.047910846s
Aug 27 19:09:39.344: INFO: Pod "pod-subpath-test-downwardapi-9c7p": Phase="Running", Reason="", readiness=true. Elapsed: 8.057987578s
Aug 27 19:09:41.354: INFO: Pod "pod-subpath-test-downwardapi-9c7p": Phase="Running", Reason="", readiness=true. Elapsed: 10.068768022s
Aug 27 19:09:43.365: INFO: Pod "pod-subpath-test-downwardapi-9c7p": Phase="Running", Reason="", readiness=true. Elapsed: 12.079151027s
Aug 27 19:09:45.375: INFO: Pod "pod-subpath-test-downwardapi-9c7p": Phase="Running", Reason="", readiness=true. Elapsed: 14.089792421s
Aug 27 19:09:47.387: INFO: Pod "pod-subpath-test-downwardapi-9c7p": Phase="Running", Reason="", readiness=true. Elapsed: 16.101227781s
Aug 27 19:09:49.398: INFO: Pod "pod-subpath-test-downwardapi-9c7p": Phase="Running", Reason="", readiness=true. Elapsed: 18.112058791s
Aug 27 19:09:51.409: INFO: Pod "pod-subpath-test-downwardapi-9c7p": Phase="Running", Reason="", readiness=true. Elapsed: 20.123159583s
Aug 27 19:09:53.419: INFO: Pod "pod-subpath-test-downwardapi-9c7p": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.133448121s
STEP: Saw pod success
Aug 27 19:09:53.419: INFO: Pod "pod-subpath-test-downwardapi-9c7p" satisfied condition "success or failure"
Aug 27 19:09:53.429: INFO: Trying to get logs from node 10.138.3.233 pod pod-subpath-test-downwardapi-9c7p container test-container-subpath-downwardapi-9c7p: <nil>
STEP: delete the pod
Aug 27 19:09:53.479: INFO: Waiting for pod pod-subpath-test-downwardapi-9c7p to disappear
Aug 27 19:09:53.491: INFO: Pod pod-subpath-test-downwardapi-9c7p no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-9c7p
Aug 27 19:09:53.491: INFO: Deleting pod "pod-subpath-test-downwardapi-9c7p" in namespace "subpath-3213"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 19:09:53.501: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-3213" for this suite.
Aug 27 19:09:59.561: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 19:09:59.921: INFO: namespace subpath-3213 deletion completed in 6.404613635s

• [SLOW TEST:28.913 seconds]
[sig-storage] Subpath
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with downward pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 19:09:59.922: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6906
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-map-7d2ca5a3-05fe-4726-945f-81ef808d4fda
STEP: Creating a pod to test consume secrets
Aug 27 19:10:00.200: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-b3ab1954-f12b-44e0-beb9-a588936d3dca" in namespace "projected-6906" to be "success or failure"
Aug 27 19:10:00.210: INFO: Pod "pod-projected-secrets-b3ab1954-f12b-44e0-beb9-a588936d3dca": Phase="Pending", Reason="", readiness=false. Elapsed: 10.684936ms
Aug 27 19:10:02.223: INFO: Pod "pod-projected-secrets-b3ab1954-f12b-44e0-beb9-a588936d3dca": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023444931s
Aug 27 19:10:04.234: INFO: Pod "pod-projected-secrets-b3ab1954-f12b-44e0-beb9-a588936d3dca": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.034292008s
STEP: Saw pod success
Aug 27 19:10:04.234: INFO: Pod "pod-projected-secrets-b3ab1954-f12b-44e0-beb9-a588936d3dca" satisfied condition "success or failure"
Aug 27 19:10:04.244: INFO: Trying to get logs from node 10.138.3.242 pod pod-projected-secrets-b3ab1954-f12b-44e0-beb9-a588936d3dca container projected-secret-volume-test: <nil>
STEP: delete the pod
Aug 27 19:10:04.291: INFO: Waiting for pod pod-projected-secrets-b3ab1954-f12b-44e0-beb9-a588936d3dca to disappear
Aug 27 19:10:04.301: INFO: Pod pod-projected-secrets-b3ab1954-f12b-44e0-beb9-a588936d3dca no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 19:10:04.301: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6906" for this suite.
Aug 27 19:10:10.364: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 19:10:10.759: INFO: namespace projected-6906 deletion completed in 6.438190894s

• [SLOW TEST:10.837 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 19:10:10.759: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-5562
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-configmap-zqcb
STEP: Creating a pod to test atomic-volume-subpath
Aug 27 19:10:11.020: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-zqcb" in namespace "subpath-5562" to be "success or failure"
Aug 27 19:10:11.030: INFO: Pod "pod-subpath-test-configmap-zqcb": Phase="Pending", Reason="", readiness=false. Elapsed: 9.92768ms
Aug 27 19:10:13.040: INFO: Pod "pod-subpath-test-configmap-zqcb": Phase="Running", Reason="", readiness=true. Elapsed: 2.020507426s
Aug 27 19:10:15.052: INFO: Pod "pod-subpath-test-configmap-zqcb": Phase="Running", Reason="", readiness=true. Elapsed: 4.031961343s
Aug 27 19:10:17.062: INFO: Pod "pod-subpath-test-configmap-zqcb": Phase="Running", Reason="", readiness=true. Elapsed: 6.042305514s
Aug 27 19:10:19.073: INFO: Pod "pod-subpath-test-configmap-zqcb": Phase="Running", Reason="", readiness=true. Elapsed: 8.052779273s
Aug 27 19:10:21.097: INFO: Pod "pod-subpath-test-configmap-zqcb": Phase="Running", Reason="", readiness=true. Elapsed: 10.077479649s
Aug 27 19:10:23.108: INFO: Pod "pod-subpath-test-configmap-zqcb": Phase="Running", Reason="", readiness=true. Elapsed: 12.088353887s
Aug 27 19:10:25.120: INFO: Pod "pod-subpath-test-configmap-zqcb": Phase="Running", Reason="", readiness=true. Elapsed: 14.100457159s
Aug 27 19:10:27.131: INFO: Pod "pod-subpath-test-configmap-zqcb": Phase="Running", Reason="", readiness=true. Elapsed: 16.111344254s
Aug 27 19:10:29.141: INFO: Pod "pod-subpath-test-configmap-zqcb": Phase="Running", Reason="", readiness=true. Elapsed: 18.121717354s
Aug 27 19:10:31.153: INFO: Pod "pod-subpath-test-configmap-zqcb": Phase="Running", Reason="", readiness=true. Elapsed: 20.132875107s
Aug 27 19:10:33.164: INFO: Pod "pod-subpath-test-configmap-zqcb": Phase="Running", Reason="", readiness=true. Elapsed: 22.14413655s
Aug 27 19:10:35.177: INFO: Pod "pod-subpath-test-configmap-zqcb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.157591086s
STEP: Saw pod success
Aug 27 19:10:35.178: INFO: Pod "pod-subpath-test-configmap-zqcb" satisfied condition "success or failure"
Aug 27 19:10:35.189: INFO: Trying to get logs from node 10.138.3.233 pod pod-subpath-test-configmap-zqcb container test-container-subpath-configmap-zqcb: <nil>
STEP: delete the pod
Aug 27 19:10:35.247: INFO: Waiting for pod pod-subpath-test-configmap-zqcb to disappear
Aug 27 19:10:35.257: INFO: Pod pod-subpath-test-configmap-zqcb no longer exists
STEP: Deleting pod pod-subpath-test-configmap-zqcb
Aug 27 19:10:35.257: INFO: Deleting pod "pod-subpath-test-configmap-zqcb" in namespace "subpath-5562"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 19:10:35.267: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-5562" for this suite.
Aug 27 19:10:41.330: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 19:10:41.729: INFO: namespace subpath-5562 deletion completed in 6.44662873s

• [SLOW TEST:30.970 seconds]
[sig-storage] Subpath
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with configmap pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 19:10:41.729: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-3469
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Aug 27 19:10:42.012: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"3eb24b01-b21e-4307-8f4d-07f797fb8c20", Controller:(*bool)(0xc002e46b5a), BlockOwnerDeletion:(*bool)(0xc002e46b5b)}}
Aug 27 19:10:42.023: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"6d4b2666-08f3-4556-a864-0485ba51254f", Controller:(*bool)(0xc00385c696), BlockOwnerDeletion:(*bool)(0xc00385c697)}}
Aug 27 19:10:42.035: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"37eb9df0-8eae-4aad-84e7-b3fb740c5955", Controller:(*bool)(0xc0016a2f86), BlockOwnerDeletion:(*bool)(0xc0016a2f87)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 19:10:47.068: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-3469" for this suite.
Aug 27 19:10:53.128: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 19:10:53.585: INFO: namespace gc-3469 deletion completed in 6.501126878s

• [SLOW TEST:11.856 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 19:10:53.586: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-5723
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0644 on node default medium
Aug 27 19:10:53.845: INFO: Waiting up to 5m0s for pod "pod-a3fdcebc-14ab-4d10-9b3d-a8b3d1986710" in namespace "emptydir-5723" to be "success or failure"
Aug 27 19:10:53.856: INFO: Pod "pod-a3fdcebc-14ab-4d10-9b3d-a8b3d1986710": Phase="Pending", Reason="", readiness=false. Elapsed: 11.203414ms
Aug 27 19:10:55.866: INFO: Pod "pod-a3fdcebc-14ab-4d10-9b3d-a8b3d1986710": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021222927s
STEP: Saw pod success
Aug 27 19:10:55.866: INFO: Pod "pod-a3fdcebc-14ab-4d10-9b3d-a8b3d1986710" satisfied condition "success or failure"
Aug 27 19:10:55.877: INFO: Trying to get logs from node 10.138.3.242 pod pod-a3fdcebc-14ab-4d10-9b3d-a8b3d1986710 container test-container: <nil>
STEP: delete the pod
Aug 27 19:10:55.925: INFO: Waiting for pod pod-a3fdcebc-14ab-4d10-9b3d-a8b3d1986710 to disappear
Aug 27 19:10:55.936: INFO: Pod pod-a3fdcebc-14ab-4d10-9b3d-a8b3d1986710 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 19:10:55.936: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5723" for this suite.
Aug 27 19:11:01.999: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 19:11:02.372: INFO: namespace emptydir-5723 deletion completed in 6.421112374s

• [SLOW TEST:8.787 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 19:11:02.373: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-8250
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:63
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Aug 27 19:11:08.717: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Aug 27 19:11:08.728: INFO: Pod pod-with-poststart-http-hook still exists
Aug 27 19:11:10.728: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Aug 27 19:11:10.739: INFO: Pod pod-with-poststart-http-hook still exists
Aug 27 19:11:12.728: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Aug 27 19:11:12.739: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 19:11:12.739: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-8250" for this suite.
Aug 27 19:11:36.797: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 19:11:37.160: INFO: namespace container-lifecycle-hook-8250 deletion completed in 24.406835574s

• [SLOW TEST:34.788 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when create a pod with lifecycle hook
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 19:11:37.161: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-2938
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1613
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Aug 27 19:11:37.380: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-540514467 run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-2938'
Aug 27 19:11:37.509: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Aug 27 19:11:37.509: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
STEP: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1618
Aug 27 19:11:37.525: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-540514467 delete jobs e2e-test-nginx-job --namespace=kubectl-2938'
Aug 27 19:11:37.665: INFO: stderr: ""
Aug 27 19:11:37.665: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 19:11:37.665: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2938" for this suite.
Aug 27 19:11:59.722: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 19:12:00.115: INFO: namespace kubectl-2938 deletion completed in 22.436193581s

• [SLOW TEST:22.954 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run job
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 19:12:00.115: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-1401
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-secret-55rf
STEP: Creating a pod to test atomic-volume-subpath
Aug 27 19:12:00.399: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-55rf" in namespace "subpath-1401" to be "success or failure"
Aug 27 19:12:00.410: INFO: Pod "pod-subpath-test-secret-55rf": Phase="Pending", Reason="", readiness=false. Elapsed: 11.205984ms
Aug 27 19:12:02.428: INFO: Pod "pod-subpath-test-secret-55rf": Phase="Pending", Reason="", readiness=false. Elapsed: 2.028551174s
Aug 27 19:12:04.438: INFO: Pod "pod-subpath-test-secret-55rf": Phase="Running", Reason="", readiness=true. Elapsed: 4.038932417s
Aug 27 19:12:06.450: INFO: Pod "pod-subpath-test-secret-55rf": Phase="Running", Reason="", readiness=true. Elapsed: 6.051186141s
Aug 27 19:12:08.462: INFO: Pod "pod-subpath-test-secret-55rf": Phase="Running", Reason="", readiness=true. Elapsed: 8.06315203s
Aug 27 19:12:10.473: INFO: Pod "pod-subpath-test-secret-55rf": Phase="Running", Reason="", readiness=true. Elapsed: 10.073614242s
Aug 27 19:12:12.484: INFO: Pod "pod-subpath-test-secret-55rf": Phase="Running", Reason="", readiness=true. Elapsed: 12.084783714s
Aug 27 19:12:14.495: INFO: Pod "pod-subpath-test-secret-55rf": Phase="Running", Reason="", readiness=true. Elapsed: 14.095400852s
Aug 27 19:12:16.505: INFO: Pod "pod-subpath-test-secret-55rf": Phase="Running", Reason="", readiness=true. Elapsed: 16.105604997s
Aug 27 19:12:18.515: INFO: Pod "pod-subpath-test-secret-55rf": Phase="Running", Reason="", readiness=true. Elapsed: 18.116296252s
Aug 27 19:12:20.527: INFO: Pod "pod-subpath-test-secret-55rf": Phase="Running", Reason="", readiness=true. Elapsed: 20.128006134s
Aug 27 19:12:22.537: INFO: Pod "pod-subpath-test-secret-55rf": Phase="Running", Reason="", readiness=true. Elapsed: 22.138307581s
Aug 27 19:12:24.548: INFO: Pod "pod-subpath-test-secret-55rf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.149322557s
STEP: Saw pod success
Aug 27 19:12:24.549: INFO: Pod "pod-subpath-test-secret-55rf" satisfied condition "success or failure"
Aug 27 19:12:24.559: INFO: Trying to get logs from node 10.138.3.233 pod pod-subpath-test-secret-55rf container test-container-subpath-secret-55rf: <nil>
STEP: delete the pod
Aug 27 19:12:24.604: INFO: Waiting for pod pod-subpath-test-secret-55rf to disappear
Aug 27 19:12:24.616: INFO: Pod pod-subpath-test-secret-55rf no longer exists
STEP: Deleting pod pod-subpath-test-secret-55rf
Aug 27 19:12:24.616: INFO: Deleting pod "pod-subpath-test-secret-55rf" in namespace "subpath-1401"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 19:12:24.636: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-1401" for this suite.
Aug 27 19:12:30.695: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 19:12:31.112: INFO: namespace subpath-1401 deletion completed in 6.46050955s

• [SLOW TEST:30.997 seconds]
[sig-storage] Subpath
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with secret pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 19:12:31.114: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-3975
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 19:12:33.398: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-3975" for this suite.
Aug 27 19:13:15.458: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 19:13:15.862: INFO: namespace kubelet-test-3975 deletion completed in 42.449458917s

• [SLOW TEST:44.748 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when scheduling a read only busybox container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:187
    should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 19:13:15.862: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-7474
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1558
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Aug 27 19:13:16.085: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-540514467 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --generator=deployment/apps.v1 --namespace=kubectl-7474'
Aug 27 19:13:16.241: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Aug 27 19:13:16.241: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the deployment e2e-test-nginx-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1563
Aug 27 19:13:18.263: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-540514467 delete deployment e2e-test-nginx-deployment --namespace=kubectl-7474'
Aug 27 19:13:18.419: INFO: stderr: ""
Aug 27 19:13:18.419: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 19:13:18.419: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7474" for this suite.
Aug 27 19:13:42.481: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 19:13:42.864: INFO: namespace kubectl-7474 deletion completed in 24.42885328s

• [SLOW TEST:27.002 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 19:13:42.864: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-7276
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Aug 27 19:13:43.100: INFO: Waiting up to 5m0s for pod "downwardapi-volume-1c4ac745-061c-4d93-ae5b-7d9919c486e7" in namespace "downward-api-7276" to be "success or failure"
Aug 27 19:13:43.115: INFO: Pod "downwardapi-volume-1c4ac745-061c-4d93-ae5b-7d9919c486e7": Phase="Pending", Reason="", readiness=false. Elapsed: 15.093617ms
Aug 27 19:13:45.126: INFO: Pod "downwardapi-volume-1c4ac745-061c-4d93-ae5b-7d9919c486e7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026213583s
Aug 27 19:13:47.137: INFO: Pod "downwardapi-volume-1c4ac745-061c-4d93-ae5b-7d9919c486e7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.037145608s
STEP: Saw pod success
Aug 27 19:13:47.137: INFO: Pod "downwardapi-volume-1c4ac745-061c-4d93-ae5b-7d9919c486e7" satisfied condition "success or failure"
Aug 27 19:13:47.147: INFO: Trying to get logs from node 10.138.3.242 pod downwardapi-volume-1c4ac745-061c-4d93-ae5b-7d9919c486e7 container client-container: <nil>
STEP: delete the pod
Aug 27 19:13:47.198: INFO: Waiting for pod downwardapi-volume-1c4ac745-061c-4d93-ae5b-7d9919c486e7 to disappear
Aug 27 19:13:47.208: INFO: Pod downwardapi-volume-1c4ac745-061c-4d93-ae5b-7d9919c486e7 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 19:13:47.208: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7276" for this suite.
Aug 27 19:13:53.268: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 19:13:53.647: INFO: namespace downward-api-7276 deletion completed in 6.424250077s

• [SLOW TEST:10.783 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 19:13:53.647: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-7759
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Aug 27 19:13:53.882: INFO: Pod name pod-release: Found 0 pods out of 1
Aug 27 19:13:58.900: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 19:13:58.936: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-7759" for this suite.
Aug 27 19:14:04.994: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 19:14:05.368: INFO: namespace replication-controller-7759 deletion completed in 6.417346903s

• [SLOW TEST:11.721 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 19:14:05.368: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-6048
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-12908b59-cad8-45e4-b588-ec7ab8198215
STEP: Creating a pod to test consume configMaps
Aug 27 19:14:05.619: INFO: Waiting up to 5m0s for pod "pod-configmaps-2e07bb09-3680-4c8f-b292-b3868faad8b6" in namespace "configmap-6048" to be "success or failure"
Aug 27 19:14:05.633: INFO: Pod "pod-configmaps-2e07bb09-3680-4c8f-b292-b3868faad8b6": Phase="Pending", Reason="", readiness=false. Elapsed: 13.570153ms
Aug 27 19:14:07.646: INFO: Pod "pod-configmaps-2e07bb09-3680-4c8f-b292-b3868faad8b6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026904051s
Aug 27 19:14:09.657: INFO: Pod "pod-configmaps-2e07bb09-3680-4c8f-b292-b3868faad8b6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.037543477s
STEP: Saw pod success
Aug 27 19:14:09.657: INFO: Pod "pod-configmaps-2e07bb09-3680-4c8f-b292-b3868faad8b6" satisfied condition "success or failure"
Aug 27 19:14:09.666: INFO: Trying to get logs from node 10.138.3.233 pod pod-configmaps-2e07bb09-3680-4c8f-b292-b3868faad8b6 container configmap-volume-test: <nil>
STEP: delete the pod
Aug 27 19:14:09.718: INFO: Waiting for pod pod-configmaps-2e07bb09-3680-4c8f-b292-b3868faad8b6 to disappear
Aug 27 19:14:09.727: INFO: Pod pod-configmaps-2e07bb09-3680-4c8f-b292-b3868faad8b6 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 19:14:09.727: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6048" for this suite.
Aug 27 19:14:15.789: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 19:14:16.189: INFO: namespace configmap-6048 deletion completed in 6.44593426s

• [SLOW TEST:10.821 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 19:14:16.190: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7801
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-projected-all-test-volume-12e98a7c-109a-4821-accf-740736b0351e
STEP: Creating secret with name secret-projected-all-test-volume-16491667-715d-45db-aa86-1038efcfd66c
STEP: Creating a pod to test Check all projections for projected volume plugin
Aug 27 19:14:16.449: INFO: Waiting up to 5m0s for pod "projected-volume-a3bf0bad-59ef-410d-9695-27798b9dde91" in namespace "projected-7801" to be "success or failure"
Aug 27 19:14:16.460: INFO: Pod "projected-volume-a3bf0bad-59ef-410d-9695-27798b9dde91": Phase="Pending", Reason="", readiness=false. Elapsed: 11.213422ms
Aug 27 19:14:18.471: INFO: Pod "projected-volume-a3bf0bad-59ef-410d-9695-27798b9dde91": Phase="Running", Reason="", readiness=true. Elapsed: 2.02216226s
Aug 27 19:14:20.482: INFO: Pod "projected-volume-a3bf0bad-59ef-410d-9695-27798b9dde91": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.032871476s
STEP: Saw pod success
Aug 27 19:14:20.482: INFO: Pod "projected-volume-a3bf0bad-59ef-410d-9695-27798b9dde91" satisfied condition "success or failure"
Aug 27 19:14:20.492: INFO: Trying to get logs from node 10.138.3.233 pod projected-volume-a3bf0bad-59ef-410d-9695-27798b9dde91 container projected-all-volume-test: <nil>
STEP: delete the pod
Aug 27 19:14:20.537: INFO: Waiting for pod projected-volume-a3bf0bad-59ef-410d-9695-27798b9dde91 to disappear
Aug 27 19:14:20.548: INFO: Pod projected-volume-a3bf0bad-59ef-410d-9695-27798b9dde91 no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 19:14:20.548: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7801" for this suite.
Aug 27 19:14:26.607: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 19:14:27.029: INFO: namespace projected-7801 deletion completed in 6.466883205s

• [SLOW TEST:10.839 seconds]
[sig-storage] Projected combined
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_combined.go:31
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 19:14:27.029: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-wrapper-8333
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Aug 27 19:14:27.826: INFO: Pod name wrapped-volume-race-19f78b92-9bc2-4cfc-b19a-a2fc640131ee: Found 0 pods out of 5
Aug 27 19:14:32.845: INFO: Pod name wrapped-volume-race-19f78b92-9bc2-4cfc-b19a-a2fc640131ee: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-19f78b92-9bc2-4cfc-b19a-a2fc640131ee in namespace emptydir-wrapper-8333, will wait for the garbage collector to delete the pods
Aug 27 19:14:39.018: INFO: Deleting ReplicationController wrapped-volume-race-19f78b92-9bc2-4cfc-b19a-a2fc640131ee took: 22.153487ms
Aug 27 19:14:39.119: INFO: Terminating ReplicationController wrapped-volume-race-19f78b92-9bc2-4cfc-b19a-a2fc640131ee pods took: 101.134286ms
STEP: Creating RC which spawns configmap-volume pods
Aug 27 19:15:18.867: INFO: Pod name wrapped-volume-race-468606f8-248c-48e4-81fc-368a2a701371: Found 0 pods out of 5
Aug 27 19:15:23.894: INFO: Pod name wrapped-volume-race-468606f8-248c-48e4-81fc-368a2a701371: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-468606f8-248c-48e4-81fc-368a2a701371 in namespace emptydir-wrapper-8333, will wait for the garbage collector to delete the pods
Aug 27 19:15:24.029: INFO: Deleting ReplicationController wrapped-volume-race-468606f8-248c-48e4-81fc-368a2a701371 took: 23.250429ms
Aug 27 19:15:24.129: INFO: Terminating ReplicationController wrapped-volume-race-468606f8-248c-48e4-81fc-368a2a701371 pods took: 100.280089ms
STEP: Creating RC which spawns configmap-volume pods
Aug 27 19:16:08.884: INFO: Pod name wrapped-volume-race-fce795ad-5910-4418-8152-4ff2b9086b9f: Found 0 pods out of 5
Aug 27 19:16:13.903: INFO: Pod name wrapped-volume-race-fce795ad-5910-4418-8152-4ff2b9086b9f: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-fce795ad-5910-4418-8152-4ff2b9086b9f in namespace emptydir-wrapper-8333, will wait for the garbage collector to delete the pods
Aug 27 19:16:14.037: INFO: Deleting ReplicationController wrapped-volume-race-fce795ad-5910-4418-8152-4ff2b9086b9f took: 22.238683ms
Aug 27 19:16:14.137: INFO: Terminating ReplicationController wrapped-volume-race-fce795ad-5910-4418-8152-4ff2b9086b9f pods took: 100.289211ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 19:16:59.781: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-8333" for this suite.
Aug 27 19:17:07.841: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 19:17:08.214: INFO: namespace emptydir-wrapper-8333 deletion completed in 8.417599527s

• [SLOW TEST:161.185 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 19:17:08.214: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-4941
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test env composition
Aug 27 19:17:08.482: INFO: Waiting up to 5m0s for pod "var-expansion-d977904e-0e8b-4299-97d1-f41779319d78" in namespace "var-expansion-4941" to be "success or failure"
Aug 27 19:17:08.494: INFO: Pod "var-expansion-d977904e-0e8b-4299-97d1-f41779319d78": Phase="Pending", Reason="", readiness=false. Elapsed: 11.238337ms
Aug 27 19:17:10.504: INFO: Pod "var-expansion-d977904e-0e8b-4299-97d1-f41779319d78": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021676015s
STEP: Saw pod success
Aug 27 19:17:10.504: INFO: Pod "var-expansion-d977904e-0e8b-4299-97d1-f41779319d78" satisfied condition "success or failure"
Aug 27 19:17:10.515: INFO: Trying to get logs from node 10.138.3.233 pod var-expansion-d977904e-0e8b-4299-97d1-f41779319d78 container dapi-container: <nil>
STEP: delete the pod
Aug 27 19:17:10.567: INFO: Waiting for pod var-expansion-d977904e-0e8b-4299-97d1-f41779319d78 to disappear
Aug 27 19:17:10.578: INFO: Pod var-expansion-d977904e-0e8b-4299-97d1-f41779319d78 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 19:17:10.578: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-4941" for this suite.
Aug 27 19:17:16.637: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 19:17:16.988: INFO: namespace var-expansion-4941 deletion completed in 6.394759114s

• [SLOW TEST:8.774 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 19:17:16.988: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3860
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-46420832-6d9a-4dc1-aa6f-655a83729e5f
STEP: Creating a pod to test consume configMaps
Aug 27 19:17:17.237: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-f39f5889-0a62-4d38-a849-700bfc99928f" in namespace "projected-3860" to be "success or failure"
Aug 27 19:17:17.249: INFO: Pod "pod-projected-configmaps-f39f5889-0a62-4d38-a849-700bfc99928f": Phase="Pending", Reason="", readiness=false. Elapsed: 12.110641ms
Aug 27 19:17:19.260: INFO: Pod "pod-projected-configmaps-f39f5889-0a62-4d38-a849-700bfc99928f": Phase="Running", Reason="", readiness=true. Elapsed: 2.022554576s
Aug 27 19:17:21.270: INFO: Pod "pod-projected-configmaps-f39f5889-0a62-4d38-a849-700bfc99928f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.03331303s
STEP: Saw pod success
Aug 27 19:17:21.271: INFO: Pod "pod-projected-configmaps-f39f5889-0a62-4d38-a849-700bfc99928f" satisfied condition "success or failure"
Aug 27 19:17:21.282: INFO: Trying to get logs from node 10.138.3.242 pod pod-projected-configmaps-f39f5889-0a62-4d38-a849-700bfc99928f container projected-configmap-volume-test: <nil>
STEP: delete the pod
Aug 27 19:17:21.326: INFO: Waiting for pod pod-projected-configmaps-f39f5889-0a62-4d38-a849-700bfc99928f to disappear
Aug 27 19:17:21.337: INFO: Pod pod-projected-configmaps-f39f5889-0a62-4d38-a849-700bfc99928f no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 19:17:21.338: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3860" for this suite.
Aug 27 19:17:27.404: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 19:17:27.832: INFO: namespace projected-3860 deletion completed in 6.476101639s

• [SLOW TEST:10.843 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 19:17:27.832: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-9479
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Aug 27 19:17:28.088: INFO: Waiting up to 5m0s for pod "downward-api-8a144e5b-bff1-4dbe-b9a7-6e70632f825d" in namespace "downward-api-9479" to be "success or failure"
Aug 27 19:17:28.098: INFO: Pod "downward-api-8a144e5b-bff1-4dbe-b9a7-6e70632f825d": Phase="Pending", Reason="", readiness=false. Elapsed: 10.609594ms
Aug 27 19:17:30.109: INFO: Pod "downward-api-8a144e5b-bff1-4dbe-b9a7-6e70632f825d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021235572s
STEP: Saw pod success
Aug 27 19:17:30.109: INFO: Pod "downward-api-8a144e5b-bff1-4dbe-b9a7-6e70632f825d" satisfied condition "success or failure"
Aug 27 19:17:30.119: INFO: Trying to get logs from node 10.138.3.242 pod downward-api-8a144e5b-bff1-4dbe-b9a7-6e70632f825d container dapi-container: <nil>
STEP: delete the pod
Aug 27 19:17:30.166: INFO: Waiting for pod downward-api-8a144e5b-bff1-4dbe-b9a7-6e70632f825d to disappear
Aug 27 19:17:30.177: INFO: Pod downward-api-8a144e5b-bff1-4dbe-b9a7-6e70632f825d no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 19:17:30.178: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9479" for this suite.
Aug 27 19:17:36.249: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 19:17:36.632: INFO: namespace downward-api-9479 deletion completed in 6.434502883s

• [SLOW TEST:8.801 seconds]
[sig-node] Downward API
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 19:17:36.634: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-7530
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Aug 27 19:17:39.439: INFO: Successfully updated pod "pod-update-activedeadlineseconds-8ac2be03-ad93-4561-8b46-249a5594768b"
Aug 27 19:17:39.439: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-8ac2be03-ad93-4561-8b46-249a5594768b" in namespace "pods-7530" to be "terminated due to deadline exceeded"
Aug 27 19:17:39.450: INFO: Pod "pod-update-activedeadlineseconds-8ac2be03-ad93-4561-8b46-249a5594768b": Phase="Running", Reason="", readiness=true. Elapsed: 10.741192ms
Aug 27 19:17:41.460: INFO: Pod "pod-update-activedeadlineseconds-8ac2be03-ad93-4561-8b46-249a5594768b": Phase="Running", Reason="", readiness=true. Elapsed: 2.021220776s
Aug 27 19:17:43.477: INFO: Pod "pod-update-activedeadlineseconds-8ac2be03-ad93-4561-8b46-249a5594768b": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 4.038214357s
Aug 27 19:17:43.478: INFO: Pod "pod-update-activedeadlineseconds-8ac2be03-ad93-4561-8b46-249a5594768b" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 19:17:43.478: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-7530" for this suite.
Aug 27 19:17:49.538: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 19:17:49.947: INFO: namespace pods-7530 deletion completed in 6.454249228s

• [SLOW TEST:13.313 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 19:17:49.949: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-4037
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-map-ba931a9e-894d-481a-889c-ef525dfa1d95
STEP: Creating a pod to test consume secrets
Aug 27 19:17:50.196: INFO: Waiting up to 5m0s for pod "pod-secrets-e410d9fd-7012-4765-a4b5-1a291612ae4a" in namespace "secrets-4037" to be "success or failure"
Aug 27 19:17:50.207: INFO: Pod "pod-secrets-e410d9fd-7012-4765-a4b5-1a291612ae4a": Phase="Pending", Reason="", readiness=false. Elapsed: 10.577312ms
Aug 27 19:17:52.218: INFO: Pod "pod-secrets-e410d9fd-7012-4765-a4b5-1a291612ae4a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020981129s
Aug 27 19:17:54.229: INFO: Pod "pod-secrets-e410d9fd-7012-4765-a4b5-1a291612ae4a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.032056284s
STEP: Saw pod success
Aug 27 19:17:54.229: INFO: Pod "pod-secrets-e410d9fd-7012-4765-a4b5-1a291612ae4a" satisfied condition "success or failure"
Aug 27 19:17:54.239: INFO: Trying to get logs from node 10.138.3.233 pod pod-secrets-e410d9fd-7012-4765-a4b5-1a291612ae4a container secret-volume-test: <nil>
STEP: delete the pod
Aug 27 19:17:54.285: INFO: Waiting for pod pod-secrets-e410d9fd-7012-4765-a4b5-1a291612ae4a to disappear
Aug 27 19:17:54.295: INFO: Pod pod-secrets-e410d9fd-7012-4765-a4b5-1a291612ae4a no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 19:17:54.295: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-4037" for this suite.
Aug 27 19:18:00.355: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 19:18:00.759: INFO: namespace secrets-4037 deletion completed in 6.448521003s

• [SLOW TEST:10.811 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 19:18:00.761: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-2891
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 19:19:01.009: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-2891" for this suite.
Aug 27 19:19:25.069: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 19:19:25.505: INFO: namespace container-probe-2891 deletion completed in 24.480630796s

• [SLOW TEST:84.744 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 19:19:25.505: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-4344
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-upd-50c536f2-486d-43d1-b1cb-6a1cd19efaca
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-50c536f2-486d-43d1-b1cb-6a1cd19efaca
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 19:19:29.870: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4344" for this suite.
Aug 27 19:19:53.929: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 19:19:54.343: INFO: namespace configmap-4344 deletion completed in 24.458186511s

• [SLOW TEST:28.838 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 19:19:54.344: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-9824
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0777 on tmpfs
Aug 27 19:19:54.581: INFO: Waiting up to 5m0s for pod "pod-cb57678c-c1e1-46c8-b1d5-e1708a7133f2" in namespace "emptydir-9824" to be "success or failure"
Aug 27 19:19:54.591: INFO: Pod "pod-cb57678c-c1e1-46c8-b1d5-e1708a7133f2": Phase="Pending", Reason="", readiness=false. Elapsed: 10.276849ms
Aug 27 19:19:56.602: INFO: Pod "pod-cb57678c-c1e1-46c8-b1d5-e1708a7133f2": Phase="Running", Reason="", readiness=true. Elapsed: 2.020721742s
Aug 27 19:19:58.612: INFO: Pod "pod-cb57678c-c1e1-46c8-b1d5-e1708a7133f2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.031238017s
STEP: Saw pod success
Aug 27 19:19:58.612: INFO: Pod "pod-cb57678c-c1e1-46c8-b1d5-e1708a7133f2" satisfied condition "success or failure"
Aug 27 19:19:58.622: INFO: Trying to get logs from node 10.138.3.242 pod pod-cb57678c-c1e1-46c8-b1d5-e1708a7133f2 container test-container: <nil>
STEP: delete the pod
Aug 27 19:19:58.673: INFO: Waiting for pod pod-cb57678c-c1e1-46c8-b1d5-e1708a7133f2 to disappear
Aug 27 19:19:58.684: INFO: Pod pod-cb57678c-c1e1-46c8-b1d5-e1708a7133f2 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 19:19:58.684: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9824" for this suite.
Aug 27 19:20:04.757: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 19:20:05.198: INFO: namespace emptydir-9824 deletion completed in 6.498077161s

• [SLOW TEST:10.855 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] version v1
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 19:20:05.199: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-5436
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-7bs7n in namespace proxy-5436
I0827 19:20:05.466625      16 runners.go:180] Created replication controller with name: proxy-service-7bs7n, namespace: proxy-5436, replica count: 1
I0827 19:20:06.517030      16 runners.go:180] proxy-service-7bs7n Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0827 19:20:07.517260      16 runners.go:180] proxy-service-7bs7n Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0827 19:20:08.517539      16 runners.go:180] proxy-service-7bs7n Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0827 19:20:09.517795      16 runners.go:180] proxy-service-7bs7n Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0827 19:20:10.518038      16 runners.go:180] proxy-service-7bs7n Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0827 19:20:11.518317      16 runners.go:180] proxy-service-7bs7n Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0827 19:20:12.518564      16 runners.go:180] proxy-service-7bs7n Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0827 19:20:13.518744      16 runners.go:180] proxy-service-7bs7n Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0827 19:20:14.518991      16 runners.go:180] proxy-service-7bs7n Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0827 19:20:15.519206      16 runners.go:180] proxy-service-7bs7n Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0827 19:20:16.519449      16 runners.go:180] proxy-service-7bs7n Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0827 19:20:17.519707      16 runners.go:180] proxy-service-7bs7n Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0827 19:20:18.519973      16 runners.go:180] proxy-service-7bs7n Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Aug 27 19:20:18.530: INFO: setup took 13.100359544s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Aug 27 19:20:18.547: INFO: (0) /api/v1/namespaces/proxy-5436/pods/proxy-service-7bs7n-bf8g2:162/proxy/: bar (200; 16.804691ms)
Aug 27 19:20:18.549: INFO: (0) /api/v1/namespaces/proxy-5436/pods/http:proxy-service-7bs7n-bf8g2:162/proxy/: bar (200; 18.878283ms)
Aug 27 19:20:18.549: INFO: (0) /api/v1/namespaces/proxy-5436/pods/proxy-service-7bs7n-bf8g2:160/proxy/: foo (200; 18.742816ms)
Aug 27 19:20:18.555: INFO: (0) /api/v1/namespaces/proxy-5436/pods/proxy-service-7bs7n-bf8g2:1080/proxy/: <a href="/api/v1/namespaces/proxy-5436/pods/proxy-service-7bs7n-bf8g2:1080/proxy/rewriteme">test<... (200; 24.432334ms)
Aug 27 19:20:18.555: INFO: (0) /api/v1/namespaces/proxy-5436/pods/http:proxy-service-7bs7n-bf8g2:1080/proxy/: <a href="/api/v1/namespaces/proxy-5436/pods/http:proxy-service-7bs7n-bf8g2:1080/proxy/rewriteme">... (200; 24.406164ms)
Aug 27 19:20:18.556: INFO: (0) /api/v1/namespaces/proxy-5436/services/http:proxy-service-7bs7n:portname2/proxy/: bar (200; 25.287495ms)
Aug 27 19:20:18.556: INFO: (0) /api/v1/namespaces/proxy-5436/pods/http:proxy-service-7bs7n-bf8g2:160/proxy/: foo (200; 25.272469ms)
Aug 27 19:20:18.556: INFO: (0) /api/v1/namespaces/proxy-5436/services/proxy-service-7bs7n:portname2/proxy/: bar (200; 25.427617ms)
Aug 27 19:20:18.556: INFO: (0) /api/v1/namespaces/proxy-5436/services/proxy-service-7bs7n:portname1/proxy/: foo (200; 25.313179ms)
Aug 27 19:20:18.556: INFO: (0) /api/v1/namespaces/proxy-5436/services/http:proxy-service-7bs7n:portname1/proxy/: foo (200; 25.626064ms)
Aug 27 19:20:18.556: INFO: (0) /api/v1/namespaces/proxy-5436/pods/proxy-service-7bs7n-bf8g2/proxy/: <a href="/api/v1/namespaces/proxy-5436/pods/proxy-service-7bs7n-bf8g2/proxy/rewriteme">test</a> (200; 25.633593ms)
Aug 27 19:20:18.561: INFO: (0) /api/v1/namespaces/proxy-5436/pods/https:proxy-service-7bs7n-bf8g2:443/proxy/: <a href="/api/v1/namespaces/proxy-5436/pods/https:proxy-service-7bs7n-bf8g2:443/proxy/tlsrewritem... (200; 30.619543ms)
Aug 27 19:20:18.562: INFO: (0) /api/v1/namespaces/proxy-5436/pods/https:proxy-service-7bs7n-bf8g2:462/proxy/: tls qux (200; 31.556326ms)
Aug 27 19:20:18.562: INFO: (0) /api/v1/namespaces/proxy-5436/pods/https:proxy-service-7bs7n-bf8g2:460/proxy/: tls baz (200; 31.622681ms)
Aug 27 19:20:18.567: INFO: (0) /api/v1/namespaces/proxy-5436/services/https:proxy-service-7bs7n:tlsportname2/proxy/: tls qux (200; 36.484985ms)
Aug 27 19:20:18.568: INFO: (0) /api/v1/namespaces/proxy-5436/services/https:proxy-service-7bs7n:tlsportname1/proxy/: tls baz (200; 37.412492ms)
Aug 27 19:20:18.581: INFO: (1) /api/v1/namespaces/proxy-5436/pods/proxy-service-7bs7n-bf8g2/proxy/: <a href="/api/v1/namespaces/proxy-5436/pods/proxy-service-7bs7n-bf8g2/proxy/rewriteme">test</a> (200; 12.941498ms)
Aug 27 19:20:18.583: INFO: (1) /api/v1/namespaces/proxy-5436/pods/proxy-service-7bs7n-bf8g2:160/proxy/: foo (200; 15.179931ms)
Aug 27 19:20:18.583: INFO: (1) /api/v1/namespaces/proxy-5436/pods/http:proxy-service-7bs7n-bf8g2:162/proxy/: bar (200; 15.338266ms)
Aug 27 19:20:18.583: INFO: (1) /api/v1/namespaces/proxy-5436/pods/http:proxy-service-7bs7n-bf8g2:1080/proxy/: <a href="/api/v1/namespaces/proxy-5436/pods/http:proxy-service-7bs7n-bf8g2:1080/proxy/rewriteme">... (200; 14.917243ms)
Aug 27 19:20:18.583: INFO: (1) /api/v1/namespaces/proxy-5436/pods/proxy-service-7bs7n-bf8g2:162/proxy/: bar (200; 15.239821ms)
Aug 27 19:20:18.583: INFO: (1) /api/v1/namespaces/proxy-5436/pods/https:proxy-service-7bs7n-bf8g2:462/proxy/: tls qux (200; 14.950587ms)
Aug 27 19:20:18.583: INFO: (1) /api/v1/namespaces/proxy-5436/pods/https:proxy-service-7bs7n-bf8g2:460/proxy/: tls baz (200; 15.269929ms)
Aug 27 19:20:18.583: INFO: (1) /api/v1/namespaces/proxy-5436/pods/http:proxy-service-7bs7n-bf8g2:160/proxy/: foo (200; 15.165553ms)
Aug 27 19:20:18.584: INFO: (1) /api/v1/namespaces/proxy-5436/pods/proxy-service-7bs7n-bf8g2:1080/proxy/: <a href="/api/v1/namespaces/proxy-5436/pods/proxy-service-7bs7n-bf8g2:1080/proxy/rewriteme">test<... (200; 15.700862ms)
Aug 27 19:20:18.584: INFO: (1) /api/v1/namespaces/proxy-5436/pods/https:proxy-service-7bs7n-bf8g2:443/proxy/: <a href="/api/v1/namespaces/proxy-5436/pods/https:proxy-service-7bs7n-bf8g2:443/proxy/tlsrewritem... (200; 14.856219ms)
Aug 27 19:20:18.587: INFO: (1) /api/v1/namespaces/proxy-5436/services/http:proxy-service-7bs7n:portname2/proxy/: bar (200; 18.424088ms)
Aug 27 19:20:18.588: INFO: (1) /api/v1/namespaces/proxy-5436/services/http:proxy-service-7bs7n:portname1/proxy/: foo (200; 20.176492ms)
Aug 27 19:20:18.588: INFO: (1) /api/v1/namespaces/proxy-5436/services/proxy-service-7bs7n:portname2/proxy/: bar (200; 20.190464ms)
Aug 27 19:20:18.588: INFO: (1) /api/v1/namespaces/proxy-5436/services/https:proxy-service-7bs7n:tlsportname2/proxy/: tls qux (200; 20.40995ms)
Aug 27 19:20:18.588: INFO: (1) /api/v1/namespaces/proxy-5436/services/proxy-service-7bs7n:portname1/proxy/: foo (200; 20.27479ms)
Aug 27 19:20:18.588: INFO: (1) /api/v1/namespaces/proxy-5436/services/https:proxy-service-7bs7n:tlsportname1/proxy/: tls baz (200; 20.554445ms)
Aug 27 19:20:18.602: INFO: (2) /api/v1/namespaces/proxy-5436/pods/http:proxy-service-7bs7n-bf8g2:160/proxy/: foo (200; 13.148152ms)
Aug 27 19:20:18.606: INFO: (2) /api/v1/namespaces/proxy-5436/pods/http:proxy-service-7bs7n-bf8g2:1080/proxy/: <a href="/api/v1/namespaces/proxy-5436/pods/http:proxy-service-7bs7n-bf8g2:1080/proxy/rewriteme">... (200; 17.163412ms)
Aug 27 19:20:18.606: INFO: (2) /api/v1/namespaces/proxy-5436/pods/proxy-service-7bs7n-bf8g2:162/proxy/: bar (200; 17.427622ms)
Aug 27 19:20:18.606: INFO: (2) /api/v1/namespaces/proxy-5436/pods/proxy-service-7bs7n-bf8g2:160/proxy/: foo (200; 17.21252ms)
Aug 27 19:20:18.606: INFO: (2) /api/v1/namespaces/proxy-5436/pods/http:proxy-service-7bs7n-bf8g2:162/proxy/: bar (200; 16.953719ms)
Aug 27 19:20:18.606: INFO: (2) /api/v1/namespaces/proxy-5436/pods/https:proxy-service-7bs7n-bf8g2:460/proxy/: tls baz (200; 16.936394ms)
Aug 27 19:20:18.606: INFO: (2) /api/v1/namespaces/proxy-5436/pods/https:proxy-service-7bs7n-bf8g2:462/proxy/: tls qux (200; 17.172967ms)
Aug 27 19:20:18.606: INFO: (2) /api/v1/namespaces/proxy-5436/pods/https:proxy-service-7bs7n-bf8g2:443/proxy/: <a href="/api/v1/namespaces/proxy-5436/pods/https:proxy-service-7bs7n-bf8g2:443/proxy/tlsrewritem... (200; 17.450206ms)
Aug 27 19:20:18.607: INFO: (2) /api/v1/namespaces/proxy-5436/pods/proxy-service-7bs7n-bf8g2/proxy/: <a href="/api/v1/namespaces/proxy-5436/pods/proxy-service-7bs7n-bf8g2/proxy/rewriteme">test</a> (200; 17.815587ms)
Aug 27 19:20:18.607: INFO: (2) /api/v1/namespaces/proxy-5436/pods/proxy-service-7bs7n-bf8g2:1080/proxy/: <a href="/api/v1/namespaces/proxy-5436/pods/proxy-service-7bs7n-bf8g2:1080/proxy/rewriteme">test<... (200; 17.868317ms)
Aug 27 19:20:18.609: INFO: (2) /api/v1/namespaces/proxy-5436/services/http:proxy-service-7bs7n:portname1/proxy/: foo (200; 20.252027ms)
Aug 27 19:20:18.612: INFO: (2) /api/v1/namespaces/proxy-5436/services/proxy-service-7bs7n:portname1/proxy/: foo (200; 23.150956ms)
Aug 27 19:20:18.612: INFO: (2) /api/v1/namespaces/proxy-5436/services/https:proxy-service-7bs7n:tlsportname2/proxy/: tls qux (200; 23.09558ms)
Aug 27 19:20:18.612: INFO: (2) /api/v1/namespaces/proxy-5436/services/https:proxy-service-7bs7n:tlsportname1/proxy/: tls baz (200; 23.330732ms)
Aug 27 19:20:18.612: INFO: (2) /api/v1/namespaces/proxy-5436/services/proxy-service-7bs7n:portname2/proxy/: bar (200; 23.280043ms)
Aug 27 19:20:18.612: INFO: (2) /api/v1/namespaces/proxy-5436/services/http:proxy-service-7bs7n:portname2/proxy/: bar (200; 23.590177ms)
Aug 27 19:20:18.626: INFO: (3) /api/v1/namespaces/proxy-5436/pods/http:proxy-service-7bs7n-bf8g2:162/proxy/: bar (200; 12.740205ms)
Aug 27 19:20:18.628: INFO: (3) /api/v1/namespaces/proxy-5436/pods/https:proxy-service-7bs7n-bf8g2:443/proxy/: <a href="/api/v1/namespaces/proxy-5436/pods/https:proxy-service-7bs7n-bf8g2:443/proxy/tlsrewritem... (200; 14.724266ms)
Aug 27 19:20:18.629: INFO: (3) /api/v1/namespaces/proxy-5436/pods/http:proxy-service-7bs7n-bf8g2:160/proxy/: foo (200; 15.080044ms)
Aug 27 19:20:18.629: INFO: (3) /api/v1/namespaces/proxy-5436/pods/https:proxy-service-7bs7n-bf8g2:462/proxy/: tls qux (200; 15.038847ms)
Aug 27 19:20:18.629: INFO: (3) /api/v1/namespaces/proxy-5436/pods/http:proxy-service-7bs7n-bf8g2:1080/proxy/: <a href="/api/v1/namespaces/proxy-5436/pods/http:proxy-service-7bs7n-bf8g2:1080/proxy/rewriteme">... (200; 16.158059ms)
Aug 27 19:20:18.629: INFO: (3) /api/v1/namespaces/proxy-5436/pods/proxy-service-7bs7n-bf8g2/proxy/: <a href="/api/v1/namespaces/proxy-5436/pods/proxy-service-7bs7n-bf8g2/proxy/rewriteme">test</a> (200; 16.289121ms)
Aug 27 19:20:18.629: INFO: (3) /api/v1/namespaces/proxy-5436/pods/proxy-service-7bs7n-bf8g2:160/proxy/: foo (200; 16.077424ms)
Aug 27 19:20:18.629: INFO: (3) /api/v1/namespaces/proxy-5436/pods/proxy-service-7bs7n-bf8g2:162/proxy/: bar (200; 15.996467ms)
Aug 27 19:20:18.630: INFO: (3) /api/v1/namespaces/proxy-5436/pods/https:proxy-service-7bs7n-bf8g2:460/proxy/: tls baz (200; 15.783558ms)
Aug 27 19:20:18.630: INFO: (3) /api/v1/namespaces/proxy-5436/pods/proxy-service-7bs7n-bf8g2:1080/proxy/: <a href="/api/v1/namespaces/proxy-5436/pods/proxy-service-7bs7n-bf8g2:1080/proxy/rewriteme">test<... (200; 15.829404ms)
Aug 27 19:20:18.632: INFO: (3) /api/v1/namespaces/proxy-5436/services/https:proxy-service-7bs7n:tlsportname2/proxy/: tls qux (200; 18.988775ms)
Aug 27 19:20:18.635: INFO: (3) /api/v1/namespaces/proxy-5436/services/https:proxy-service-7bs7n:tlsportname1/proxy/: tls baz (200; 21.341981ms)
Aug 27 19:20:18.635: INFO: (3) /api/v1/namespaces/proxy-5436/services/proxy-service-7bs7n:portname2/proxy/: bar (200; 20.464217ms)
Aug 27 19:20:18.635: INFO: (3) /api/v1/namespaces/proxy-5436/services/http:proxy-service-7bs7n:portname2/proxy/: bar (200; 20.935562ms)
Aug 27 19:20:18.635: INFO: (3) /api/v1/namespaces/proxy-5436/services/http:proxy-service-7bs7n:portname1/proxy/: foo (200; 20.869882ms)
Aug 27 19:20:18.635: INFO: (3) /api/v1/namespaces/proxy-5436/services/proxy-service-7bs7n:portname1/proxy/: foo (200; 21.199421ms)
Aug 27 19:20:18.648: INFO: (4) /api/v1/namespaces/proxy-5436/pods/https:proxy-service-7bs7n-bf8g2:462/proxy/: tls qux (200; 12.932813ms)
Aug 27 19:20:18.651: INFO: (4) /api/v1/namespaces/proxy-5436/pods/http:proxy-service-7bs7n-bf8g2:160/proxy/: foo (200; 15.036151ms)
Aug 27 19:20:18.651: INFO: (4) /api/v1/namespaces/proxy-5436/pods/http:proxy-service-7bs7n-bf8g2:162/proxy/: bar (200; 14.707675ms)
Aug 27 19:20:18.651: INFO: (4) /api/v1/namespaces/proxy-5436/pods/proxy-service-7bs7n-bf8g2/proxy/: <a href="/api/v1/namespaces/proxy-5436/pods/proxy-service-7bs7n-bf8g2/proxy/rewriteme">test</a> (200; 15.40992ms)
Aug 27 19:20:18.651: INFO: (4) /api/v1/namespaces/proxy-5436/pods/https:proxy-service-7bs7n-bf8g2:443/proxy/: <a href="/api/v1/namespaces/proxy-5436/pods/https:proxy-service-7bs7n-bf8g2:443/proxy/tlsrewritem... (200; 15.134736ms)
Aug 27 19:20:18.653: INFO: (4) /api/v1/namespaces/proxy-5436/pods/proxy-service-7bs7n-bf8g2:1080/proxy/: <a href="/api/v1/namespaces/proxy-5436/pods/proxy-service-7bs7n-bf8g2:1080/proxy/rewriteme">test<... (200; 17.259099ms)
Aug 27 19:20:18.653: INFO: (4) /api/v1/namespaces/proxy-5436/pods/http:proxy-service-7bs7n-bf8g2:1080/proxy/: <a href="/api/v1/namespaces/proxy-5436/pods/http:proxy-service-7bs7n-bf8g2:1080/proxy/rewriteme">... (200; 17.712909ms)
Aug 27 19:20:18.653: INFO: (4) /api/v1/namespaces/proxy-5436/pods/proxy-service-7bs7n-bf8g2:160/proxy/: foo (200; 17.360023ms)
Aug 27 19:20:18.653: INFO: (4) /api/v1/namespaces/proxy-5436/pods/proxy-service-7bs7n-bf8g2:162/proxy/: bar (200; 17.676238ms)
Aug 27 19:20:18.654: INFO: (4) /api/v1/namespaces/proxy-5436/pods/https:proxy-service-7bs7n-bf8g2:460/proxy/: tls baz (200; 17.496995ms)
Aug 27 19:20:18.661: INFO: (4) /api/v1/namespaces/proxy-5436/services/proxy-service-7bs7n:portname2/proxy/: bar (200; 24.93604ms)
Aug 27 19:20:18.661: INFO: (4) /api/v1/namespaces/proxy-5436/services/http:proxy-service-7bs7n:portname2/proxy/: bar (200; 24.693869ms)
Aug 27 19:20:18.661: INFO: (4) /api/v1/namespaces/proxy-5436/services/http:proxy-service-7bs7n:portname1/proxy/: foo (200; 24.925954ms)
Aug 27 19:20:18.661: INFO: (4) /api/v1/namespaces/proxy-5436/services/proxy-service-7bs7n:portname1/proxy/: foo (200; 24.984894ms)
Aug 27 19:20:18.661: INFO: (4) /api/v1/namespaces/proxy-5436/services/https:proxy-service-7bs7n:tlsportname2/proxy/: tls qux (200; 25.319237ms)
Aug 27 19:20:18.661: INFO: (4) /api/v1/namespaces/proxy-5436/services/https:proxy-service-7bs7n:tlsportname1/proxy/: tls baz (200; 25.369986ms)
Aug 27 19:20:18.677: INFO: (5) /api/v1/namespaces/proxy-5436/pods/https:proxy-service-7bs7n-bf8g2:460/proxy/: tls baz (200; 16.01477ms)
Aug 27 19:20:18.677: INFO: (5) /api/v1/namespaces/proxy-5436/pods/http:proxy-service-7bs7n-bf8g2:1080/proxy/: <a href="/api/v1/namespaces/proxy-5436/pods/http:proxy-service-7bs7n-bf8g2:1080/proxy/rewriteme">... (200; 15.825645ms)
Aug 27 19:20:18.677: INFO: (5) /api/v1/namespaces/proxy-5436/pods/proxy-service-7bs7n-bf8g2:162/proxy/: bar (200; 15.767101ms)
Aug 27 19:20:18.677: INFO: (5) /api/v1/namespaces/proxy-5436/pods/http:proxy-service-7bs7n-bf8g2:162/proxy/: bar (200; 16.003643ms)
Aug 27 19:20:18.677: INFO: (5) /api/v1/namespaces/proxy-5436/pods/proxy-service-7bs7n-bf8g2:1080/proxy/: <a href="/api/v1/namespaces/proxy-5436/pods/proxy-service-7bs7n-bf8g2:1080/proxy/rewriteme">test<... (200; 16.143563ms)
Aug 27 19:20:18.679: INFO: (5) /api/v1/namespaces/proxy-5436/pods/https:proxy-service-7bs7n-bf8g2:443/proxy/: <a href="/api/v1/namespaces/proxy-5436/pods/https:proxy-service-7bs7n-bf8g2:443/proxy/tlsrewritem... (200; 17.457135ms)
Aug 27 19:20:18.679: INFO: (5) /api/v1/namespaces/proxy-5436/pods/https:proxy-service-7bs7n-bf8g2:462/proxy/: tls qux (200; 17.364899ms)
Aug 27 19:20:18.679: INFO: (5) /api/v1/namespaces/proxy-5436/pods/http:proxy-service-7bs7n-bf8g2:160/proxy/: foo (200; 17.567187ms)
Aug 27 19:20:18.679: INFO: (5) /api/v1/namespaces/proxy-5436/pods/proxy-service-7bs7n-bf8g2:160/proxy/: foo (200; 17.432386ms)
Aug 27 19:20:18.679: INFO: (5) /api/v1/namespaces/proxy-5436/pods/proxy-service-7bs7n-bf8g2/proxy/: <a href="/api/v1/namespaces/proxy-5436/pods/proxy-service-7bs7n-bf8g2/proxy/rewriteme">test</a> (200; 17.63438ms)
Aug 27 19:20:18.680: INFO: (5) /api/v1/namespaces/proxy-5436/services/proxy-service-7bs7n:portname2/proxy/: bar (200; 18.935168ms)
Aug 27 19:20:18.680: INFO: (5) /api/v1/namespaces/proxy-5436/services/http:proxy-service-7bs7n:portname2/proxy/: bar (200; 19.254021ms)
Aug 27 19:20:18.682: INFO: (5) /api/v1/namespaces/proxy-5436/services/https:proxy-service-7bs7n:tlsportname1/proxy/: tls baz (200; 20.694835ms)
Aug 27 19:20:18.682: INFO: (5) /api/v1/namespaces/proxy-5436/services/https:proxy-service-7bs7n:tlsportname2/proxy/: tls qux (200; 21.483628ms)
Aug 27 19:20:18.682: INFO: (5) /api/v1/namespaces/proxy-5436/services/http:proxy-service-7bs7n:portname1/proxy/: foo (200; 21.389875ms)
Aug 27 19:20:18.682: INFO: (5) /api/v1/namespaces/proxy-5436/services/proxy-service-7bs7n:portname1/proxy/: foo (200; 21.126892ms)
Aug 27 19:20:18.695: INFO: (6) /api/v1/namespaces/proxy-5436/pods/http:proxy-service-7bs7n-bf8g2:160/proxy/: foo (200; 11.907021ms)
Aug 27 19:20:18.699: INFO: (6) /api/v1/namespaces/proxy-5436/pods/proxy-service-7bs7n-bf8g2/proxy/: <a href="/api/v1/namespaces/proxy-5436/pods/proxy-service-7bs7n-bf8g2/proxy/rewriteme">test</a> (200; 16.062059ms)
Aug 27 19:20:18.699: INFO: (6) /api/v1/namespaces/proxy-5436/pods/proxy-service-7bs7n-bf8g2:162/proxy/: bar (200; 16.338044ms)
Aug 27 19:20:18.699: INFO: (6) /api/v1/namespaces/proxy-5436/pods/https:proxy-service-7bs7n-bf8g2:462/proxy/: tls qux (200; 16.004217ms)
Aug 27 19:20:18.699: INFO: (6) /api/v1/namespaces/proxy-5436/pods/http:proxy-service-7bs7n-bf8g2:162/proxy/: bar (200; 15.7954ms)
Aug 27 19:20:18.699: INFO: (6) /api/v1/namespaces/proxy-5436/pods/https:proxy-service-7bs7n-bf8g2:460/proxy/: tls baz (200; 15.821567ms)
Aug 27 19:20:18.699: INFO: (6) /api/v1/namespaces/proxy-5436/pods/http:proxy-service-7bs7n-bf8g2:1080/proxy/: <a href="/api/v1/namespaces/proxy-5436/pods/http:proxy-service-7bs7n-bf8g2:1080/proxy/rewriteme">... (200; 16.136461ms)
Aug 27 19:20:18.699: INFO: (6) /api/v1/namespaces/proxy-5436/pods/proxy-service-7bs7n-bf8g2:160/proxy/: foo (200; 15.965219ms)
Aug 27 19:20:18.699: INFO: (6) /api/v1/namespaces/proxy-5436/pods/https:proxy-service-7bs7n-bf8g2:443/proxy/: <a href="/api/v1/namespaces/proxy-5436/pods/https:proxy-service-7bs7n-bf8g2:443/proxy/tlsrewritem... (200; 15.810618ms)
Aug 27 19:20:18.700: INFO: (6) /api/v1/namespaces/proxy-5436/pods/proxy-service-7bs7n-bf8g2:1080/proxy/: <a href="/api/v1/namespaces/proxy-5436/pods/proxy-service-7bs7n-bf8g2:1080/proxy/rewriteme">test<... (200; 16.093749ms)
Aug 27 19:20:18.701: INFO: (6) /api/v1/namespaces/proxy-5436/services/http:proxy-service-7bs7n:portname1/proxy/: foo (200; 17.376157ms)
Aug 27 19:20:18.702: INFO: (6) /api/v1/namespaces/proxy-5436/services/proxy-service-7bs7n:portname1/proxy/: foo (200; 19.487005ms)
Aug 27 19:20:18.703: INFO: (6) /api/v1/namespaces/proxy-5436/services/https:proxy-service-7bs7n:tlsportname2/proxy/: tls qux (200; 19.761719ms)
Aug 27 19:20:18.703: INFO: (6) /api/v1/namespaces/proxy-5436/services/proxy-service-7bs7n:portname2/proxy/: bar (200; 19.956144ms)
Aug 27 19:20:18.703: INFO: (6) /api/v1/namespaces/proxy-5436/services/http:proxy-service-7bs7n:portname2/proxy/: bar (200; 20.533376ms)
Aug 27 19:20:18.703: INFO: (6) /api/v1/namespaces/proxy-5436/services/https:proxy-service-7bs7n:tlsportname1/proxy/: tls baz (200; 20.274042ms)
Aug 27 19:20:18.717: INFO: (7) /api/v1/namespaces/proxy-5436/pods/https:proxy-service-7bs7n-bf8g2:443/proxy/: <a href="/api/v1/namespaces/proxy-5436/pods/https:proxy-service-7bs7n-bf8g2:443/proxy/tlsrewritem... (200; 13.321946ms)
Aug 27 19:20:18.719: INFO: (7) /api/v1/namespaces/proxy-5436/pods/https:proxy-service-7bs7n-bf8g2:460/proxy/: tls baz (200; 15.584257ms)
Aug 27 19:20:18.719: INFO: (7) /api/v1/namespaces/proxy-5436/pods/http:proxy-service-7bs7n-bf8g2:160/proxy/: foo (200; 15.792478ms)
Aug 27 19:20:18.719: INFO: (7) /api/v1/namespaces/proxy-5436/pods/http:proxy-service-7bs7n-bf8g2:162/proxy/: bar (200; 15.572875ms)
Aug 27 19:20:18.719: INFO: (7) /api/v1/namespaces/proxy-5436/pods/proxy-service-7bs7n-bf8g2:1080/proxy/: <a href="/api/v1/namespaces/proxy-5436/pods/proxy-service-7bs7n-bf8g2:1080/proxy/rewriteme">test<... (200; 15.717108ms)
Aug 27 19:20:18.719: INFO: (7) /api/v1/namespaces/proxy-5436/pods/proxy-service-7bs7n-bf8g2:160/proxy/: foo (200; 15.444938ms)
Aug 27 19:20:18.719: INFO: (7) /api/v1/namespaces/proxy-5436/pods/proxy-service-7bs7n-bf8g2:162/proxy/: bar (200; 15.449963ms)
Aug 27 19:20:18.719: INFO: (7) /api/v1/namespaces/proxy-5436/pods/proxy-service-7bs7n-bf8g2/proxy/: <a href="/api/v1/namespaces/proxy-5436/pods/proxy-service-7bs7n-bf8g2/proxy/rewriteme">test</a> (200; 15.882374ms)
Aug 27 19:20:18.720: INFO: (7) /api/v1/namespaces/proxy-5436/pods/https:proxy-service-7bs7n-bf8g2:462/proxy/: tls qux (200; 15.642822ms)
Aug 27 19:20:18.720: INFO: (7) /api/v1/namespaces/proxy-5436/pods/http:proxy-service-7bs7n-bf8g2:1080/proxy/: <a href="/api/v1/namespaces/proxy-5436/pods/http:proxy-service-7bs7n-bf8g2:1080/proxy/rewriteme">... (200; 16.174854ms)
Aug 27 19:20:18.723: INFO: (7) /api/v1/namespaces/proxy-5436/services/http:proxy-service-7bs7n:portname1/proxy/: foo (200; 18.72848ms)
Aug 27 19:20:18.724: INFO: (7) /api/v1/namespaces/proxy-5436/services/proxy-service-7bs7n:portname1/proxy/: foo (200; 20.511781ms)
Aug 27 19:20:18.724: INFO: (7) /api/v1/namespaces/proxy-5436/services/proxy-service-7bs7n:portname2/proxy/: bar (200; 20.330949ms)
Aug 27 19:20:18.725: INFO: (7) /api/v1/namespaces/proxy-5436/services/https:proxy-service-7bs7n:tlsportname1/proxy/: tls baz (200; 20.7535ms)
Aug 27 19:20:18.725: INFO: (7) /api/v1/namespaces/proxy-5436/services/http:proxy-service-7bs7n:portname2/proxy/: bar (200; 20.846426ms)
Aug 27 19:20:18.725: INFO: (7) /api/v1/namespaces/proxy-5436/services/https:proxy-service-7bs7n:tlsportname2/proxy/: tls qux (200; 21.348459ms)
Aug 27 19:20:18.739: INFO: (8) /api/v1/namespaces/proxy-5436/pods/http:proxy-service-7bs7n-bf8g2:162/proxy/: bar (200; 13.517455ms)
Aug 27 19:20:18.740: INFO: (8) /api/v1/namespaces/proxy-5436/pods/proxy-service-7bs7n-bf8g2:160/proxy/: foo (200; 14.523959ms)
Aug 27 19:20:18.740: INFO: (8) /api/v1/namespaces/proxy-5436/pods/http:proxy-service-7bs7n-bf8g2:160/proxy/: foo (200; 15.292455ms)
Aug 27 19:20:18.740: INFO: (8) /api/v1/namespaces/proxy-5436/pods/http:proxy-service-7bs7n-bf8g2:1080/proxy/: <a href="/api/v1/namespaces/proxy-5436/pods/http:proxy-service-7bs7n-bf8g2:1080/proxy/rewriteme">... (200; 14.70042ms)
Aug 27 19:20:18.743: INFO: (8) /api/v1/namespaces/proxy-5436/pods/https:proxy-service-7bs7n-bf8g2:443/proxy/: <a href="/api/v1/namespaces/proxy-5436/pods/https:proxy-service-7bs7n-bf8g2:443/proxy/tlsrewritem... (200; 17.225764ms)
Aug 27 19:20:18.743: INFO: (8) /api/v1/namespaces/proxy-5436/pods/https:proxy-service-7bs7n-bf8g2:462/proxy/: tls qux (200; 17.195983ms)
Aug 27 19:20:18.743: INFO: (8) /api/v1/namespaces/proxy-5436/pods/https:proxy-service-7bs7n-bf8g2:460/proxy/: tls baz (200; 16.931221ms)
Aug 27 19:20:18.743: INFO: (8) /api/v1/namespaces/proxy-5436/pods/proxy-service-7bs7n-bf8g2:1080/proxy/: <a href="/api/v1/namespaces/proxy-5436/pods/proxy-service-7bs7n-bf8g2:1080/proxy/rewriteme">test<... (200; 17.012418ms)
Aug 27 19:20:18.743: INFO: (8) /api/v1/namespaces/proxy-5436/pods/proxy-service-7bs7n-bf8g2:162/proxy/: bar (200; 17.359322ms)
Aug 27 19:20:18.743: INFO: (8) /api/v1/namespaces/proxy-5436/pods/proxy-service-7bs7n-bf8g2/proxy/: <a href="/api/v1/namespaces/proxy-5436/pods/proxy-service-7bs7n-bf8g2/proxy/rewriteme">test</a> (200; 17.414831ms)
Aug 27 19:20:18.744: INFO: (8) /api/v1/namespaces/proxy-5436/services/https:proxy-service-7bs7n:tlsportname1/proxy/: tls baz (200; 18.134644ms)
Aug 27 19:20:18.746: INFO: (8) /api/v1/namespaces/proxy-5436/services/proxy-service-7bs7n:portname1/proxy/: foo (200; 20.505492ms)
Aug 27 19:20:18.748: INFO: (8) /api/v1/namespaces/proxy-5436/services/http:proxy-service-7bs7n:portname2/proxy/: bar (200; 22.971599ms)
Aug 27 19:20:18.748: INFO: (8) /api/v1/namespaces/proxy-5436/services/proxy-service-7bs7n:portname2/proxy/: bar (200; 22.394768ms)
Aug 27 19:20:18.748: INFO: (8) /api/v1/namespaces/proxy-5436/services/https:proxy-service-7bs7n:tlsportname2/proxy/: tls qux (200; 22.572773ms)
Aug 27 19:20:18.749: INFO: (8) /api/v1/namespaces/proxy-5436/services/http:proxy-service-7bs7n:portname1/proxy/: foo (200; 23.00808ms)
Aug 27 19:20:18.761: INFO: (9) /api/v1/namespaces/proxy-5436/pods/proxy-service-7bs7n-bf8g2:162/proxy/: bar (200; 12.473085ms)
Aug 27 19:20:18.765: INFO: (9) /api/v1/namespaces/proxy-5436/pods/proxy-service-7bs7n-bf8g2/proxy/: <a href="/api/v1/namespaces/proxy-5436/pods/proxy-service-7bs7n-bf8g2/proxy/rewriteme">test</a> (200; 16.24952ms)
Aug 27 19:20:18.765: INFO: (9) /api/v1/namespaces/proxy-5436/pods/proxy-service-7bs7n-bf8g2:160/proxy/: foo (200; 16.443122ms)
Aug 27 19:20:18.765: INFO: (9) /api/v1/namespaces/proxy-5436/pods/http:proxy-service-7bs7n-bf8g2:162/proxy/: bar (200; 16.661418ms)
Aug 27 19:20:18.766: INFO: (9) /api/v1/namespaces/proxy-5436/pods/http:proxy-service-7bs7n-bf8g2:160/proxy/: foo (200; 16.398199ms)
Aug 27 19:20:18.766: INFO: (9) /api/v1/namespaces/proxy-5436/pods/http:proxy-service-7bs7n-bf8g2:1080/proxy/: <a href="/api/v1/namespaces/proxy-5436/pods/http:proxy-service-7bs7n-bf8g2:1080/proxy/rewriteme">... (200; 16.966594ms)
Aug 27 19:20:18.766: INFO: (9) /api/v1/namespaces/proxy-5436/pods/https:proxy-service-7bs7n-bf8g2:460/proxy/: tls baz (200; 17.228073ms)
Aug 27 19:20:18.766: INFO: (9) /api/v1/namespaces/proxy-5436/pods/https:proxy-service-7bs7n-bf8g2:462/proxy/: tls qux (200; 17.269761ms)
Aug 27 19:20:18.766: INFO: (9) /api/v1/namespaces/proxy-5436/pods/https:proxy-service-7bs7n-bf8g2:443/proxy/: <a href="/api/v1/namespaces/proxy-5436/pods/https:proxy-service-7bs7n-bf8g2:443/proxy/tlsrewritem... (200; 17.41949ms)
Aug 27 19:20:18.766: INFO: (9) /api/v1/namespaces/proxy-5436/pods/proxy-service-7bs7n-bf8g2:1080/proxy/: <a href="/api/v1/namespaces/proxy-5436/pods/proxy-service-7bs7n-bf8g2:1080/proxy/rewriteme">test<... (200; 17.442791ms)
Aug 27 19:20:18.770: INFO: (9) /api/v1/namespaces/proxy-5436/services/proxy-service-7bs7n:portname2/proxy/: bar (200; 20.591767ms)
Aug 27 19:20:18.773: INFO: (9) /api/v1/namespaces/proxy-5436/services/http:proxy-service-7bs7n:portname2/proxy/: bar (200; 23.93909ms)
Aug 27 19:20:18.773: INFO: (9) /api/v1/namespaces/proxy-5436/services/http:proxy-service-7bs7n:portname1/proxy/: foo (200; 24.159051ms)
Aug 27 19:20:18.773: INFO: (9) /api/v1/namespaces/proxy-5436/services/proxy-service-7bs7n:portname1/proxy/: foo (200; 23.835391ms)
Aug 27 19:20:18.773: INFO: (9) /api/v1/namespaces/proxy-5436/services/https:proxy-service-7bs7n:tlsportname1/proxy/: tls baz (200; 23.902028ms)
Aug 27 19:20:18.773: INFO: (9) /api/v1/namespaces/proxy-5436/services/https:proxy-service-7bs7n:tlsportname2/proxy/: tls qux (200; 24.067829ms)
Aug 27 19:20:18.788: INFO: (10) /api/v1/namespaces/proxy-5436/pods/proxy-service-7bs7n-bf8g2:162/proxy/: bar (200; 15.142936ms)
Aug 27 19:20:18.789: INFO: (10) /api/v1/namespaces/proxy-5436/pods/http:proxy-service-7bs7n-bf8g2:1080/proxy/: <a href="/api/v1/namespaces/proxy-5436/pods/http:proxy-service-7bs7n-bf8g2:1080/proxy/rewriteme">... (200; 15.764574ms)
Aug 27 19:20:18.789: INFO: (10) /api/v1/namespaces/proxy-5436/pods/proxy-service-7bs7n-bf8g2:1080/proxy/: <a href="/api/v1/namespaces/proxy-5436/pods/proxy-service-7bs7n-bf8g2:1080/proxy/rewriteme">test<... (200; 15.929105ms)
Aug 27 19:20:18.790: INFO: (10) /api/v1/namespaces/proxy-5436/pods/proxy-service-7bs7n-bf8g2/proxy/: <a href="/api/v1/namespaces/proxy-5436/pods/proxy-service-7bs7n-bf8g2/proxy/rewriteme">test</a> (200; 16.101647ms)
Aug 27 19:20:18.790: INFO: (10) /api/v1/namespaces/proxy-5436/pods/http:proxy-service-7bs7n-bf8g2:160/proxy/: foo (200; 16.361275ms)
Aug 27 19:20:18.790: INFO: (10) /api/v1/namespaces/proxy-5436/pods/http:proxy-service-7bs7n-bf8g2:162/proxy/: bar (200; 16.749521ms)
Aug 27 19:20:18.790: INFO: (10) /api/v1/namespaces/proxy-5436/pods/https:proxy-service-7bs7n-bf8g2:443/proxy/: <a href="/api/v1/namespaces/proxy-5436/pods/https:proxy-service-7bs7n-bf8g2:443/proxy/tlsrewritem... (200; 17.087303ms)
Aug 27 19:20:18.790: INFO: (10) /api/v1/namespaces/proxy-5436/pods/https:proxy-service-7bs7n-bf8g2:462/proxy/: tls qux (200; 16.933227ms)
Aug 27 19:20:18.790: INFO: (10) /api/v1/namespaces/proxy-5436/pods/https:proxy-service-7bs7n-bf8g2:460/proxy/: tls baz (200; 17.061242ms)
Aug 27 19:20:18.790: INFO: (10) /api/v1/namespaces/proxy-5436/pods/proxy-service-7bs7n-bf8g2:160/proxy/: foo (200; 16.820994ms)
Aug 27 19:20:18.793: INFO: (10) /api/v1/namespaces/proxy-5436/services/https:proxy-service-7bs7n:tlsportname1/proxy/: tls baz (200; 19.624144ms)
Aug 27 19:20:18.795: INFO: (10) /api/v1/namespaces/proxy-5436/services/proxy-service-7bs7n:portname2/proxy/: bar (200; 21.401252ms)
Aug 27 19:20:18.795: INFO: (10) /api/v1/namespaces/proxy-5436/services/http:proxy-service-7bs7n:portname2/proxy/: bar (200; 21.512097ms)
Aug 27 19:20:18.795: INFO: (10) /api/v1/namespaces/proxy-5436/services/https:proxy-service-7bs7n:tlsportname2/proxy/: tls qux (200; 21.497262ms)
Aug 27 19:20:18.796: INFO: (10) /api/v1/namespaces/proxy-5436/services/http:proxy-service-7bs7n:portname1/proxy/: foo (200; 22.328132ms)
Aug 27 19:20:18.796: INFO: (10) /api/v1/namespaces/proxy-5436/services/proxy-service-7bs7n:portname1/proxy/: foo (200; 22.081135ms)
Aug 27 19:20:18.809: INFO: (11) /api/v1/namespaces/proxy-5436/pods/proxy-service-7bs7n-bf8g2:162/proxy/: bar (200; 13.195347ms)
Aug 27 19:20:18.812: INFO: (11) /api/v1/namespaces/proxy-5436/pods/proxy-service-7bs7n-bf8g2:1080/proxy/: <a href="/api/v1/namespaces/proxy-5436/pods/proxy-service-7bs7n-bf8g2:1080/proxy/rewriteme">test<... (200; 15.843863ms)
Aug 27 19:20:18.812: INFO: (11) /api/v1/namespaces/proxy-5436/pods/http:proxy-service-7bs7n-bf8g2:1080/proxy/: <a href="/api/v1/namespaces/proxy-5436/pods/http:proxy-service-7bs7n-bf8g2:1080/proxy/rewriteme">... (200; 16.19416ms)
Aug 27 19:20:18.813: INFO: (11) /api/v1/namespaces/proxy-5436/pods/https:proxy-service-7bs7n-bf8g2:460/proxy/: tls baz (200; 16.229721ms)
Aug 27 19:20:18.813: INFO: (11) /api/v1/namespaces/proxy-5436/pods/https:proxy-service-7bs7n-bf8g2:462/proxy/: tls qux (200; 16.713743ms)
Aug 27 19:20:18.813: INFO: (11) /api/v1/namespaces/proxy-5436/pods/http:proxy-service-7bs7n-bf8g2:160/proxy/: foo (200; 16.696702ms)
Aug 27 19:20:18.813: INFO: (11) /api/v1/namespaces/proxy-5436/pods/proxy-service-7bs7n-bf8g2:160/proxy/: foo (200; 16.489707ms)
Aug 27 19:20:18.813: INFO: (11) /api/v1/namespaces/proxy-5436/pods/https:proxy-service-7bs7n-bf8g2:443/proxy/: <a href="/api/v1/namespaces/proxy-5436/pods/https:proxy-service-7bs7n-bf8g2:443/proxy/tlsrewritem... (200; 16.833861ms)
Aug 27 19:20:18.813: INFO: (11) /api/v1/namespaces/proxy-5436/pods/http:proxy-service-7bs7n-bf8g2:162/proxy/: bar (200; 16.585315ms)
Aug 27 19:20:18.813: INFO: (11) /api/v1/namespaces/proxy-5436/pods/proxy-service-7bs7n-bf8g2/proxy/: <a href="/api/v1/namespaces/proxy-5436/pods/proxy-service-7bs7n-bf8g2/proxy/rewriteme">test</a> (200; 17.043218ms)
Aug 27 19:20:18.816: INFO: (11) /api/v1/namespaces/proxy-5436/services/http:proxy-service-7bs7n:portname1/proxy/: foo (200; 19.748682ms)
Aug 27 19:20:18.818: INFO: (11) /api/v1/namespaces/proxy-5436/services/http:proxy-service-7bs7n:portname2/proxy/: bar (200; 21.789411ms)
Aug 27 19:20:18.818: INFO: (11) /api/v1/namespaces/proxy-5436/services/proxy-service-7bs7n:portname2/proxy/: bar (200; 22.195099ms)
Aug 27 19:20:18.818: INFO: (11) /api/v1/namespaces/proxy-5436/services/https:proxy-service-7bs7n:tlsportname1/proxy/: tls baz (200; 22.167766ms)
Aug 27 19:20:18.818: INFO: (11) /api/v1/namespaces/proxy-5436/services/proxy-service-7bs7n:portname1/proxy/: foo (200; 22.13368ms)
Aug 27 19:20:18.818: INFO: (11) /api/v1/namespaces/proxy-5436/services/https:proxy-service-7bs7n:tlsportname2/proxy/: tls qux (200; 22.25368ms)
Aug 27 19:20:18.835: INFO: (12) /api/v1/namespaces/proxy-5436/pods/http:proxy-service-7bs7n-bf8g2:1080/proxy/: <a href="/api/v1/namespaces/proxy-5436/pods/http:proxy-service-7bs7n-bf8g2:1080/proxy/rewriteme">... (200; 15.900737ms)
Aug 27 19:20:18.835: INFO: (12) /api/v1/namespaces/proxy-5436/pods/proxy-service-7bs7n-bf8g2/proxy/: <a href="/api/v1/namespaces/proxy-5436/pods/proxy-service-7bs7n-bf8g2/proxy/rewriteme">test</a> (200; 16.047493ms)
Aug 27 19:20:18.835: INFO: (12) /api/v1/namespaces/proxy-5436/pods/proxy-service-7bs7n-bf8g2:1080/proxy/: <a href="/api/v1/namespaces/proxy-5436/pods/proxy-service-7bs7n-bf8g2:1080/proxy/rewriteme">test<... (200; 15.992986ms)
Aug 27 19:20:18.835: INFO: (12) /api/v1/namespaces/proxy-5436/pods/http:proxy-service-7bs7n-bf8g2:160/proxy/: foo (200; 16.203999ms)
Aug 27 19:20:18.835: INFO: (12) /api/v1/namespaces/proxy-5436/pods/https:proxy-service-7bs7n-bf8g2:462/proxy/: tls qux (200; 16.165684ms)
Aug 27 19:20:18.836: INFO: (12) /api/v1/namespaces/proxy-5436/pods/proxy-service-7bs7n-bf8g2:162/proxy/: bar (200; 16.744467ms)
Aug 27 19:20:18.836: INFO: (12) /api/v1/namespaces/proxy-5436/pods/proxy-service-7bs7n-bf8g2:160/proxy/: foo (200; 17.305944ms)
Aug 27 19:20:18.836: INFO: (12) /api/v1/namespaces/proxy-5436/pods/http:proxy-service-7bs7n-bf8g2:162/proxy/: bar (200; 17.365084ms)
Aug 27 19:20:18.836: INFO: (12) /api/v1/namespaces/proxy-5436/pods/https:proxy-service-7bs7n-bf8g2:443/proxy/: <a href="/api/v1/namespaces/proxy-5436/pods/https:proxy-service-7bs7n-bf8g2:443/proxy/tlsrewritem... (200; 17.172264ms)
Aug 27 19:20:18.836: INFO: (12) /api/v1/namespaces/proxy-5436/services/https:proxy-service-7bs7n:tlsportname2/proxy/: tls qux (200; 17.484703ms)
Aug 27 19:20:18.836: INFO: (12) /api/v1/namespaces/proxy-5436/pods/https:proxy-service-7bs7n-bf8g2:460/proxy/: tls baz (200; 17.535093ms)
Aug 27 19:20:18.838: INFO: (12) /api/v1/namespaces/proxy-5436/services/http:proxy-service-7bs7n:portname1/proxy/: foo (200; 19.757554ms)
Aug 27 19:20:18.840: INFO: (12) /api/v1/namespaces/proxy-5436/services/proxy-service-7bs7n:portname2/proxy/: bar (200; 21.51411ms)
Aug 27 19:20:18.840: INFO: (12) /api/v1/namespaces/proxy-5436/services/https:proxy-service-7bs7n:tlsportname1/proxy/: tls baz (200; 21.340597ms)
Aug 27 19:20:18.840: INFO: (12) /api/v1/namespaces/proxy-5436/services/proxy-service-7bs7n:portname1/proxy/: foo (200; 21.648987ms)
Aug 27 19:20:18.840: INFO: (12) /api/v1/namespaces/proxy-5436/services/http:proxy-service-7bs7n:portname2/proxy/: bar (200; 21.56814ms)
Aug 27 19:20:18.853: INFO: (13) /api/v1/namespaces/proxy-5436/pods/https:proxy-service-7bs7n-bf8g2:443/proxy/: <a href="/api/v1/namespaces/proxy-5436/pods/https:proxy-service-7bs7n-bf8g2:443/proxy/tlsrewritem... (200; 12.660948ms)
Aug 27 19:20:18.856: INFO: (13) /api/v1/namespaces/proxy-5436/pods/http:proxy-service-7bs7n-bf8g2:160/proxy/: foo (200; 15.192682ms)
Aug 27 19:20:18.856: INFO: (13) /api/v1/namespaces/proxy-5436/pods/http:proxy-service-7bs7n-bf8g2:162/proxy/: bar (200; 15.597699ms)
Aug 27 19:20:18.856: INFO: (13) /api/v1/namespaces/proxy-5436/pods/proxy-service-7bs7n-bf8g2:162/proxy/: bar (200; 15.55204ms)
Aug 27 19:20:18.856: INFO: (13) /api/v1/namespaces/proxy-5436/pods/proxy-service-7bs7n-bf8g2:1080/proxy/: <a href="/api/v1/namespaces/proxy-5436/pods/proxy-service-7bs7n-bf8g2:1080/proxy/rewriteme">test<... (200; 15.232914ms)
Aug 27 19:20:18.856: INFO: (13) /api/v1/namespaces/proxy-5436/pods/proxy-service-7bs7n-bf8g2/proxy/: <a href="/api/v1/namespaces/proxy-5436/pods/proxy-service-7bs7n-bf8g2/proxy/rewriteme">test</a> (200; 15.362755ms)
Aug 27 19:20:18.856: INFO: (13) /api/v1/namespaces/proxy-5436/pods/https:proxy-service-7bs7n-bf8g2:460/proxy/: tls baz (200; 15.597103ms)
Aug 27 19:20:18.856: INFO: (13) /api/v1/namespaces/proxy-5436/pods/proxy-service-7bs7n-bf8g2:160/proxy/: foo (200; 15.628946ms)
Aug 27 19:20:18.856: INFO: (13) /api/v1/namespaces/proxy-5436/pods/https:proxy-service-7bs7n-bf8g2:462/proxy/: tls qux (200; 15.796567ms)
Aug 27 19:20:18.856: INFO: (13) /api/v1/namespaces/proxy-5436/pods/http:proxy-service-7bs7n-bf8g2:1080/proxy/: <a href="/api/v1/namespaces/proxy-5436/pods/http:proxy-service-7bs7n-bf8g2:1080/proxy/rewriteme">... (200; 15.709966ms)
Aug 27 19:20:18.860: INFO: (13) /api/v1/namespaces/proxy-5436/services/proxy-service-7bs7n:portname2/proxy/: bar (200; 18.893875ms)
Aug 27 19:20:18.862: INFO: (13) /api/v1/namespaces/proxy-5436/services/proxy-service-7bs7n:portname1/proxy/: foo (200; 21.415774ms)
Aug 27 19:20:18.862: INFO: (13) /api/v1/namespaces/proxy-5436/services/https:proxy-service-7bs7n:tlsportname2/proxy/: tls qux (200; 21.40479ms)
Aug 27 19:20:18.862: INFO: (13) /api/v1/namespaces/proxy-5436/services/http:proxy-service-7bs7n:portname2/proxy/: bar (200; 21.381357ms)
Aug 27 19:20:18.862: INFO: (13) /api/v1/namespaces/proxy-5436/services/http:proxy-service-7bs7n:portname1/proxy/: foo (200; 21.716022ms)
Aug 27 19:20:18.862: INFO: (13) /api/v1/namespaces/proxy-5436/services/https:proxy-service-7bs7n:tlsportname1/proxy/: tls baz (200; 21.609019ms)
Aug 27 19:20:18.878: INFO: (14) /api/v1/namespaces/proxy-5436/pods/http:proxy-service-7bs7n-bf8g2:162/proxy/: bar (200; 15.251927ms)
Aug 27 19:20:18.878: INFO: (14) /api/v1/namespaces/proxy-5436/pods/https:proxy-service-7bs7n-bf8g2:462/proxy/: tls qux (200; 14.737645ms)
Aug 27 19:20:18.878: INFO: (14) /api/v1/namespaces/proxy-5436/pods/https:proxy-service-7bs7n-bf8g2:460/proxy/: tls baz (200; 15.127171ms)
Aug 27 19:20:18.878: INFO: (14) /api/v1/namespaces/proxy-5436/pods/http:proxy-service-7bs7n-bf8g2:160/proxy/: foo (200; 15.069404ms)
Aug 27 19:20:18.878: INFO: (14) /api/v1/namespaces/proxy-5436/pods/proxy-service-7bs7n-bf8g2:160/proxy/: foo (200; 15.314576ms)
Aug 27 19:20:18.878: INFO: (14) /api/v1/namespaces/proxy-5436/pods/proxy-service-7bs7n-bf8g2:1080/proxy/: <a href="/api/v1/namespaces/proxy-5436/pods/proxy-service-7bs7n-bf8g2:1080/proxy/rewriteme">test<... (200; 15.207986ms)
Aug 27 19:20:18.878: INFO: (14) /api/v1/namespaces/proxy-5436/pods/https:proxy-service-7bs7n-bf8g2:443/proxy/: <a href="/api/v1/namespaces/proxy-5436/pods/https:proxy-service-7bs7n-bf8g2:443/proxy/tlsrewritem... (200; 15.662743ms)
Aug 27 19:20:18.878: INFO: (14) /api/v1/namespaces/proxy-5436/pods/proxy-service-7bs7n-bf8g2:162/proxy/: bar (200; 15.957778ms)
Aug 27 19:20:18.878: INFO: (14) /api/v1/namespaces/proxy-5436/pods/http:proxy-service-7bs7n-bf8g2:1080/proxy/: <a href="/api/v1/namespaces/proxy-5436/pods/http:proxy-service-7bs7n-bf8g2:1080/proxy/rewriteme">... (200; 15.880576ms)
Aug 27 19:20:18.878: INFO: (14) /api/v1/namespaces/proxy-5436/pods/proxy-service-7bs7n-bf8g2/proxy/: <a href="/api/v1/namespaces/proxy-5436/pods/proxy-service-7bs7n-bf8g2/proxy/rewriteme">test</a> (200; 15.939084ms)
Aug 27 19:20:18.879: INFO: (14) /api/v1/namespaces/proxy-5436/services/https:proxy-service-7bs7n:tlsportname2/proxy/: tls qux (200; 16.730651ms)
Aug 27 19:20:18.882: INFO: (14) /api/v1/namespaces/proxy-5436/services/proxy-service-7bs7n:portname1/proxy/: foo (200; 19.08222ms)
Aug 27 19:20:18.884: INFO: (14) /api/v1/namespaces/proxy-5436/services/proxy-service-7bs7n:portname2/proxy/: bar (200; 21.287088ms)
Aug 27 19:20:18.884: INFO: (14) /api/v1/namespaces/proxy-5436/services/http:proxy-service-7bs7n:portname2/proxy/: bar (200; 21.45012ms)
Aug 27 19:20:18.884: INFO: (14) /api/v1/namespaces/proxy-5436/services/https:proxy-service-7bs7n:tlsportname1/proxy/: tls baz (200; 21.403664ms)
Aug 27 19:20:18.884: INFO: (14) /api/v1/namespaces/proxy-5436/services/http:proxy-service-7bs7n:portname1/proxy/: foo (200; 21.417172ms)
Aug 27 19:20:18.898: INFO: (15) /api/v1/namespaces/proxy-5436/pods/https:proxy-service-7bs7n-bf8g2:462/proxy/: tls qux (200; 13.270296ms)
Aug 27 19:20:18.900: INFO: (15) /api/v1/namespaces/proxy-5436/pods/proxy-service-7bs7n-bf8g2:1080/proxy/: <a href="/api/v1/namespaces/proxy-5436/pods/proxy-service-7bs7n-bf8g2:1080/proxy/rewriteme">test<... (200; 14.805505ms)
Aug 27 19:20:18.901: INFO: (15) /api/v1/namespaces/proxy-5436/pods/https:proxy-service-7bs7n-bf8g2:443/proxy/: <a href="/api/v1/namespaces/proxy-5436/pods/https:proxy-service-7bs7n-bf8g2:443/proxy/tlsrewritem... (200; 16.08266ms)
Aug 27 19:20:18.901: INFO: (15) /api/v1/namespaces/proxy-5436/pods/proxy-service-7bs7n-bf8g2:160/proxy/: foo (200; 16.379059ms)
Aug 27 19:20:18.901: INFO: (15) /api/v1/namespaces/proxy-5436/pods/http:proxy-service-7bs7n-bf8g2:160/proxy/: foo (200; 16.27245ms)
Aug 27 19:20:18.901: INFO: (15) /api/v1/namespaces/proxy-5436/pods/http:proxy-service-7bs7n-bf8g2:1080/proxy/: <a href="/api/v1/namespaces/proxy-5436/pods/http:proxy-service-7bs7n-bf8g2:1080/proxy/rewriteme">... (200; 16.58151ms)
Aug 27 19:20:18.901: INFO: (15) /api/v1/namespaces/proxy-5436/pods/proxy-service-7bs7n-bf8g2/proxy/: <a href="/api/v1/namespaces/proxy-5436/pods/proxy-service-7bs7n-bf8g2/proxy/rewriteme">test</a> (200; 16.895001ms)
Aug 27 19:20:18.901: INFO: (15) /api/v1/namespaces/proxy-5436/pods/http:proxy-service-7bs7n-bf8g2:162/proxy/: bar (200; 16.252808ms)
Aug 27 19:20:18.901: INFO: (15) /api/v1/namespaces/proxy-5436/pods/https:proxy-service-7bs7n-bf8g2:460/proxy/: tls baz (200; 16.288543ms)
Aug 27 19:20:18.901: INFO: (15) /api/v1/namespaces/proxy-5436/pods/proxy-service-7bs7n-bf8g2:162/proxy/: bar (200; 16.564006ms)
Aug 27 19:20:18.904: INFO: (15) /api/v1/namespaces/proxy-5436/services/http:proxy-service-7bs7n:portname1/proxy/: foo (200; 19.36687ms)
Aug 27 19:20:18.906: INFO: (15) /api/v1/namespaces/proxy-5436/services/https:proxy-service-7bs7n:tlsportname2/proxy/: tls qux (200; 20.9959ms)
Aug 27 19:20:18.906: INFO: (15) /api/v1/namespaces/proxy-5436/services/https:proxy-service-7bs7n:tlsportname1/proxy/: tls baz (200; 21.0813ms)
Aug 27 19:20:18.906: INFO: (15) /api/v1/namespaces/proxy-5436/services/proxy-service-7bs7n:portname2/proxy/: bar (200; 21.337187ms)
Aug 27 19:20:18.906: INFO: (15) /api/v1/namespaces/proxy-5436/services/http:proxy-service-7bs7n:portname2/proxy/: bar (200; 21.29557ms)
Aug 27 19:20:18.906: INFO: (15) /api/v1/namespaces/proxy-5436/services/proxy-service-7bs7n:portname1/proxy/: foo (200; 21.477231ms)
Aug 27 19:20:18.927: INFO: (16) /api/v1/namespaces/proxy-5436/pods/https:proxy-service-7bs7n-bf8g2:462/proxy/: tls qux (200; 20.287367ms)
Aug 27 19:20:18.928: INFO: (16) /api/v1/namespaces/proxy-5436/pods/proxy-service-7bs7n-bf8g2:160/proxy/: foo (200; 21.574912ms)
Aug 27 19:20:18.928: INFO: (16) /api/v1/namespaces/proxy-5436/services/https:proxy-service-7bs7n:tlsportname1/proxy/: tls baz (200; 21.79464ms)
Aug 27 19:20:18.928: INFO: (16) /api/v1/namespaces/proxy-5436/pods/https:proxy-service-7bs7n-bf8g2:460/proxy/: tls baz (200; 21.477244ms)
Aug 27 19:20:18.928: INFO: (16) /api/v1/namespaces/proxy-5436/services/https:proxy-service-7bs7n:tlsportname2/proxy/: tls qux (200; 21.547849ms)
Aug 27 19:20:18.928: INFO: (16) /api/v1/namespaces/proxy-5436/pods/http:proxy-service-7bs7n-bf8g2:1080/proxy/: <a href="/api/v1/namespaces/proxy-5436/pods/http:proxy-service-7bs7n-bf8g2:1080/proxy/rewriteme">... (200; 21.781346ms)
Aug 27 19:20:18.928: INFO: (16) /api/v1/namespaces/proxy-5436/pods/proxy-service-7bs7n-bf8g2:162/proxy/: bar (200; 21.657435ms)
Aug 27 19:20:18.928: INFO: (16) /api/v1/namespaces/proxy-5436/pods/http:proxy-service-7bs7n-bf8g2:162/proxy/: bar (200; 21.61903ms)
Aug 27 19:20:18.928: INFO: (16) /api/v1/namespaces/proxy-5436/pods/https:proxy-service-7bs7n-bf8g2:443/proxy/: <a href="/api/v1/namespaces/proxy-5436/pods/https:proxy-service-7bs7n-bf8g2:443/proxy/tlsrewritem... (200; 21.457038ms)
Aug 27 19:20:18.928: INFO: (16) /api/v1/namespaces/proxy-5436/pods/proxy-service-7bs7n-bf8g2:1080/proxy/: <a href="/api/v1/namespaces/proxy-5436/pods/proxy-service-7bs7n-bf8g2:1080/proxy/rewriteme">test<... (200; 21.626352ms)
Aug 27 19:20:18.928: INFO: (16) /api/v1/namespaces/proxy-5436/pods/http:proxy-service-7bs7n-bf8g2:160/proxy/: foo (200; 21.601445ms)
Aug 27 19:20:18.928: INFO: (16) /api/v1/namespaces/proxy-5436/pods/proxy-service-7bs7n-bf8g2/proxy/: <a href="/api/v1/namespaces/proxy-5436/pods/proxy-service-7bs7n-bf8g2/proxy/rewriteme">test</a> (200; 21.819769ms)
Aug 27 19:20:18.930: INFO: (16) /api/v1/namespaces/proxy-5436/services/proxy-service-7bs7n:portname1/proxy/: foo (200; 23.810277ms)
Aug 27 19:20:18.931: INFO: (16) /api/v1/namespaces/proxy-5436/services/proxy-service-7bs7n:portname2/proxy/: bar (200; 24.700648ms)
Aug 27 19:20:18.931: INFO: (16) /api/v1/namespaces/proxy-5436/services/http:proxy-service-7bs7n:portname2/proxy/: bar (200; 24.287604ms)
Aug 27 19:20:18.931: INFO: (16) /api/v1/namespaces/proxy-5436/services/http:proxy-service-7bs7n:portname1/proxy/: foo (200; 24.631097ms)
Aug 27 19:20:18.944: INFO: (17) /api/v1/namespaces/proxy-5436/pods/proxy-service-7bs7n-bf8g2/proxy/: <a href="/api/v1/namespaces/proxy-5436/pods/proxy-service-7bs7n-bf8g2/proxy/rewriteme">test</a> (200; 13.028597ms)
Aug 27 19:20:18.944: INFO: (17) /api/v1/namespaces/proxy-5436/pods/http:proxy-service-7bs7n-bf8g2:1080/proxy/: <a href="/api/v1/namespaces/proxy-5436/pods/http:proxy-service-7bs7n-bf8g2:1080/proxy/rewriteme">... (200; 12.938508ms)
Aug 27 19:20:18.946: INFO: (17) /api/v1/namespaces/proxy-5436/pods/http:proxy-service-7bs7n-bf8g2:160/proxy/: foo (200; 14.942204ms)
Aug 27 19:20:18.947: INFO: (17) /api/v1/namespaces/proxy-5436/pods/http:proxy-service-7bs7n-bf8g2:162/proxy/: bar (200; 15.843495ms)
Aug 27 19:20:18.947: INFO: (17) /api/v1/namespaces/proxy-5436/pods/https:proxy-service-7bs7n-bf8g2:462/proxy/: tls qux (200; 15.375223ms)
Aug 27 19:20:18.947: INFO: (17) /api/v1/namespaces/proxy-5436/pods/https:proxy-service-7bs7n-bf8g2:460/proxy/: tls baz (200; 15.58556ms)
Aug 27 19:20:18.947: INFO: (17) /api/v1/namespaces/proxy-5436/pods/proxy-service-7bs7n-bf8g2:160/proxy/: foo (200; 15.852352ms)
Aug 27 19:20:18.947: INFO: (17) /api/v1/namespaces/proxy-5436/pods/proxy-service-7bs7n-bf8g2:162/proxy/: bar (200; 15.863066ms)
Aug 27 19:20:18.948: INFO: (17) /api/v1/namespaces/proxy-5436/pods/https:proxy-service-7bs7n-bf8g2:443/proxy/: <a href="/api/v1/namespaces/proxy-5436/pods/https:proxy-service-7bs7n-bf8g2:443/proxy/tlsrewritem... (200; 16.25269ms)
Aug 27 19:20:18.948: INFO: (17) /api/v1/namespaces/proxy-5436/pods/proxy-service-7bs7n-bf8g2:1080/proxy/: <a href="/api/v1/namespaces/proxy-5436/pods/proxy-service-7bs7n-bf8g2:1080/proxy/rewriteme">test<... (200; 15.742393ms)
Aug 27 19:20:18.950: INFO: (17) /api/v1/namespaces/proxy-5436/services/http:proxy-service-7bs7n:portname1/proxy/: foo (200; 18.818118ms)
Aug 27 19:20:18.952: INFO: (17) /api/v1/namespaces/proxy-5436/services/proxy-service-7bs7n:portname1/proxy/: foo (200; 20.089719ms)
Aug 27 19:20:18.952: INFO: (17) /api/v1/namespaces/proxy-5436/services/proxy-service-7bs7n:portname2/proxy/: bar (200; 20.315099ms)
Aug 27 19:20:18.952: INFO: (17) /api/v1/namespaces/proxy-5436/services/https:proxy-service-7bs7n:tlsportname2/proxy/: tls qux (200; 20.42914ms)
Aug 27 19:20:18.953: INFO: (17) /api/v1/namespaces/proxy-5436/services/https:proxy-service-7bs7n:tlsportname1/proxy/: tls baz (200; 21.893603ms)
Aug 27 19:20:18.953: INFO: (17) /api/v1/namespaces/proxy-5436/services/http:proxy-service-7bs7n:portname2/proxy/: bar (200; 21.932904ms)
Aug 27 19:20:18.967: INFO: (18) /api/v1/namespaces/proxy-5436/pods/http:proxy-service-7bs7n-bf8g2:162/proxy/: bar (200; 13.566617ms)
Aug 27 19:20:18.969: INFO: (18) /api/v1/namespaces/proxy-5436/pods/proxy-service-7bs7n-bf8g2:162/proxy/: bar (200; 15.616484ms)
Aug 27 19:20:18.969: INFO: (18) /api/v1/namespaces/proxy-5436/pods/http:proxy-service-7bs7n-bf8g2:1080/proxy/: <a href="/api/v1/namespaces/proxy-5436/pods/http:proxy-service-7bs7n-bf8g2:1080/proxy/rewriteme">... (200; 15.581764ms)
Aug 27 19:20:18.969: INFO: (18) /api/v1/namespaces/proxy-5436/pods/proxy-service-7bs7n-bf8g2/proxy/: <a href="/api/v1/namespaces/proxy-5436/pods/proxy-service-7bs7n-bf8g2/proxy/rewriteme">test</a> (200; 15.631384ms)
Aug 27 19:20:18.970: INFO: (18) /api/v1/namespaces/proxy-5436/pods/proxy-service-7bs7n-bf8g2:1080/proxy/: <a href="/api/v1/namespaces/proxy-5436/pods/proxy-service-7bs7n-bf8g2:1080/proxy/rewriteme">test<... (200; 15.963068ms)
Aug 27 19:20:18.970: INFO: (18) /api/v1/namespaces/proxy-5436/pods/proxy-service-7bs7n-bf8g2:160/proxy/: foo (200; 16.431032ms)
Aug 27 19:20:18.970: INFO: (18) /api/v1/namespaces/proxy-5436/pods/https:proxy-service-7bs7n-bf8g2:460/proxy/: tls baz (200; 16.884277ms)
Aug 27 19:20:18.970: INFO: (18) /api/v1/namespaces/proxy-5436/pods/http:proxy-service-7bs7n-bf8g2:160/proxy/: foo (200; 16.734366ms)
Aug 27 19:20:18.971: INFO: (18) /api/v1/namespaces/proxy-5436/pods/https:proxy-service-7bs7n-bf8g2:462/proxy/: tls qux (200; 16.789161ms)
Aug 27 19:20:18.970: INFO: (18) /api/v1/namespaces/proxy-5436/pods/https:proxy-service-7bs7n-bf8g2:443/proxy/: <a href="/api/v1/namespaces/proxy-5436/pods/https:proxy-service-7bs7n-bf8g2:443/proxy/tlsrewritem... (200; 16.540711ms)
Aug 27 19:20:18.974: INFO: (18) /api/v1/namespaces/proxy-5436/services/https:proxy-service-7bs7n:tlsportname2/proxy/: tls qux (200; 20.513635ms)
Aug 27 19:20:18.975: INFO: (18) /api/v1/namespaces/proxy-5436/services/http:proxy-service-7bs7n:portname2/proxy/: bar (200; 21.63896ms)
Aug 27 19:20:18.976: INFO: (18) /api/v1/namespaces/proxy-5436/services/proxy-service-7bs7n:portname1/proxy/: foo (200; 22.021148ms)
Aug 27 19:20:18.976: INFO: (18) /api/v1/namespaces/proxy-5436/services/proxy-service-7bs7n:portname2/proxy/: bar (200; 22.018881ms)
Aug 27 19:20:18.976: INFO: (18) /api/v1/namespaces/proxy-5436/services/https:proxy-service-7bs7n:tlsportname1/proxy/: tls baz (200; 21.77628ms)
Aug 27 19:20:18.976: INFO: (18) /api/v1/namespaces/proxy-5436/services/http:proxy-service-7bs7n:portname1/proxy/: foo (200; 22.071582ms)
Aug 27 19:20:18.988: INFO: (19) /api/v1/namespaces/proxy-5436/pods/proxy-service-7bs7n-bf8g2/proxy/: <a href="/api/v1/namespaces/proxy-5436/pods/proxy-service-7bs7n-bf8g2/proxy/rewriteme">test</a> (200; 12.451885ms)
Aug 27 19:20:18.991: INFO: (19) /api/v1/namespaces/proxy-5436/pods/http:proxy-service-7bs7n-bf8g2:160/proxy/: foo (200; 14.979003ms)
Aug 27 19:20:18.991: INFO: (19) /api/v1/namespaces/proxy-5436/pods/https:proxy-service-7bs7n-bf8g2:460/proxy/: tls baz (200; 14.978723ms)
Aug 27 19:20:18.991: INFO: (19) /api/v1/namespaces/proxy-5436/pods/proxy-service-7bs7n-bf8g2:1080/proxy/: <a href="/api/v1/namespaces/proxy-5436/pods/proxy-service-7bs7n-bf8g2:1080/proxy/rewriteme">test<... (200; 14.930454ms)
Aug 27 19:20:18.991: INFO: (19) /api/v1/namespaces/proxy-5436/pods/https:proxy-service-7bs7n-bf8g2:443/proxy/: <a href="/api/v1/namespaces/proxy-5436/pods/https:proxy-service-7bs7n-bf8g2:443/proxy/tlsrewritem... (200; 15.317486ms)
Aug 27 19:20:18.991: INFO: (19) /api/v1/namespaces/proxy-5436/pods/proxy-service-7bs7n-bf8g2:162/proxy/: bar (200; 15.387817ms)
Aug 27 19:20:18.992: INFO: (19) /api/v1/namespaces/proxy-5436/pods/http:proxy-service-7bs7n-bf8g2:162/proxy/: bar (200; 15.691087ms)
Aug 27 19:20:18.992: INFO: (19) /api/v1/namespaces/proxy-5436/pods/https:proxy-service-7bs7n-bf8g2:462/proxy/: tls qux (200; 15.828477ms)
Aug 27 19:20:18.992: INFO: (19) /api/v1/namespaces/proxy-5436/pods/proxy-service-7bs7n-bf8g2:160/proxy/: foo (200; 15.917831ms)
Aug 27 19:20:18.992: INFO: (19) /api/v1/namespaces/proxy-5436/pods/http:proxy-service-7bs7n-bf8g2:1080/proxy/: <a href="/api/v1/namespaces/proxy-5436/pods/http:proxy-service-7bs7n-bf8g2:1080/proxy/rewriteme">... (200; 16.109995ms)
Aug 27 19:20:18.995: INFO: (19) /api/v1/namespaces/proxy-5436/services/https:proxy-service-7bs7n:tlsportname2/proxy/: tls qux (200; 19.027184ms)
Aug 27 19:20:18.997: INFO: (19) /api/v1/namespaces/proxy-5436/services/proxy-service-7bs7n:portname2/proxy/: bar (200; 20.840877ms)
Aug 27 19:20:18.997: INFO: (19) /api/v1/namespaces/proxy-5436/services/http:proxy-service-7bs7n:portname1/proxy/: foo (200; 20.789922ms)
Aug 27 19:20:18.997: INFO: (19) /api/v1/namespaces/proxy-5436/services/http:proxy-service-7bs7n:portname2/proxy/: bar (200; 20.594567ms)
Aug 27 19:20:18.997: INFO: (19) /api/v1/namespaces/proxy-5436/services/proxy-service-7bs7n:portname1/proxy/: foo (200; 21.31338ms)
Aug 27 19:20:18.998: INFO: (19) /api/v1/namespaces/proxy-5436/services/https:proxy-service-7bs7n:tlsportname1/proxy/: tls baz (200; 21.570377ms)
STEP: deleting ReplicationController proxy-service-7bs7n in namespace proxy-5436, will wait for the garbage collector to delete the pods
Aug 27 19:20:19.081: INFO: Deleting ReplicationController proxy-service-7bs7n took: 22.619894ms
Aug 27 19:20:19.181: INFO: Terminating ReplicationController proxy-service-7bs7n pods took: 100.224777ms
[AfterEach] version v1
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 19:20:23.782: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-5436" for this suite.
Aug 27 19:20:29.839: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 19:20:30.217: INFO: namespace proxy-5436 deletion completed in 6.420489749s

• [SLOW TEST:25.018 seconds]
[sig-network] Proxy
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:58
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 19:20:30.218: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-4896
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-4896
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a new StatefulSet
Aug 27 19:20:30.489: INFO: Found 0 stateful pods, waiting for 3
Aug 27 19:20:40.501: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Aug 27 19:20:40.501: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Aug 27 19:20:40.501: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Aug 27 19:20:40.531: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-540514467 exec --namespace=statefulset-4896 ss2-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Aug 27 19:20:41.090: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Aug 27 19:20:41.090: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Aug 27 19:20:41.090: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Aug 27 19:20:41.143: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Aug 27 19:20:51.196: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-540514467 exec --namespace=statefulset-4896 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 27 19:20:51.649: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Aug 27 19:20:51.649: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Aug 27 19:20:51.649: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Aug 27 19:21:11.710: INFO: Waiting for StatefulSet statefulset-4896/ss2 to complete update
Aug 27 19:21:11.710: INFO: Waiting for Pod statefulset-4896/ss2-0 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
STEP: Rolling back to a previous revision
Aug 27 19:21:21.731: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-540514467 exec --namespace=statefulset-4896 ss2-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Aug 27 19:21:22.137: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Aug 27 19:21:22.137: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Aug 27 19:21:22.137: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Aug 27 19:21:32.232: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Aug 27 19:21:42.284: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-540514467 exec --namespace=statefulset-4896 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 27 19:21:42.766: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Aug 27 19:21:42.766: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Aug 27 19:21:42.766: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Aug 27 19:22:02.824: INFO: Waiting for StatefulSet statefulset-4896/ss2 to complete update
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Aug 27 19:22:12.845: INFO: Deleting all statefulset in ns statefulset-4896
Aug 27 19:22:12.855: INFO: Scaling statefulset ss2 to 0
Aug 27 19:22:32.896: INFO: Waiting for statefulset status.replicas updated to 0
Aug 27 19:22:32.906: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 19:22:32.948: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-4896" for this suite.
Aug 27 19:22:41.118: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 19:22:41.481: INFO: namespace statefulset-4896 deletion completed in 8.518244616s

• [SLOW TEST:131.263 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 19:22:41.481: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2915
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating the pod
Aug 27 19:22:46.505: INFO: Successfully updated pod "labelsupdate3a6f00d8-3ed6-4d9e-8dd9-81087cd825c1"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 19:22:48.548: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2915" for this suite.
Aug 27 19:23:12.608: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 19:23:12.978: INFO: namespace projected-2915 deletion completed in 24.415375534s

• [SLOW TEST:31.497 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 19:23:12.979: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-2057
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1421
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Aug 27 19:23:13.214: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-540514467 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-2057'
Aug 27 19:23:13.365: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Aug 27 19:23:13.365: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1427
Aug 27 19:23:15.386: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-540514467 delete deployment e2e-test-nginx-deployment --namespace=kubectl-2057'
Aug 27 19:23:15.549: INFO: stderr: ""
Aug 27 19:23:15.549: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 19:23:15.549: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2057" for this suite.
Aug 27 19:23:39.609: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 19:23:40.022: INFO: namespace kubectl-2057 deletion completed in 24.457839528s

• [SLOW TEST:27.043 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run default
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 19:23:40.026: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-7566
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0827 19:23:50.466027      16 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Aug 27 19:23:50.466: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 19:23:50.466: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-7566" for this suite.
Aug 27 19:23:58.528: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 19:23:58.962: INFO: namespace gc-7566 deletion completed in 8.481196403s

• [SLOW TEST:18.937 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 19:23:58.962: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-3089
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating Redis RC
Aug 27 19:23:59.182: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-540514467 create -f - --namespace=kubectl-3089'
Aug 27 19:23:59.495: INFO: stderr: ""
Aug 27 19:23:59.495: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Aug 27 19:24:00.506: INFO: Selector matched 1 pods for map[app:redis]
Aug 27 19:24:00.506: INFO: Found 0 / 1
Aug 27 19:24:01.506: INFO: Selector matched 1 pods for map[app:redis]
Aug 27 19:24:01.506: INFO: Found 1 / 1
Aug 27 19:24:01.506: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Aug 27 19:24:01.516: INFO: Selector matched 1 pods for map[app:redis]
Aug 27 19:24:01.516: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Aug 27 19:24:01.516: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-540514467 patch pod redis-master-z6ltp --namespace=kubectl-3089 -p {"metadata":{"annotations":{"x":"y"}}}'
Aug 27 19:24:01.651: INFO: stderr: ""
Aug 27 19:24:01.651: INFO: stdout: "pod/redis-master-z6ltp patched\n"
STEP: checking annotations
Aug 27 19:24:01.662: INFO: Selector matched 1 pods for map[app:redis]
Aug 27 19:24:01.662: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 19:24:01.662: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3089" for this suite.
Aug 27 19:24:25.733: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 19:24:26.132: INFO: namespace kubectl-3089 deletion completed in 24.444676929s

• [SLOW TEST:27.170 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl patch
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 19:24:26.135: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-4217
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Aug 27 19:24:26.386: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d22bcc61-2b99-4cc1-a813-c0f203c8929c" in namespace "projected-4217" to be "success or failure"
Aug 27 19:24:26.397: INFO: Pod "downwardapi-volume-d22bcc61-2b99-4cc1-a813-c0f203c8929c": Phase="Pending", Reason="", readiness=false. Elapsed: 10.349574ms
Aug 27 19:24:28.407: INFO: Pod "downwardapi-volume-d22bcc61-2b99-4cc1-a813-c0f203c8929c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021081981s
Aug 27 19:24:30.418: INFO: Pod "downwardapi-volume-d22bcc61-2b99-4cc1-a813-c0f203c8929c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.0317966s
STEP: Saw pod success
Aug 27 19:24:30.418: INFO: Pod "downwardapi-volume-d22bcc61-2b99-4cc1-a813-c0f203c8929c" satisfied condition "success or failure"
Aug 27 19:24:30.428: INFO: Trying to get logs from node 10.138.3.242 pod downwardapi-volume-d22bcc61-2b99-4cc1-a813-c0f203c8929c container client-container: <nil>
STEP: delete the pod
Aug 27 19:24:30.475: INFO: Waiting for pod downwardapi-volume-d22bcc61-2b99-4cc1-a813-c0f203c8929c to disappear
Aug 27 19:24:30.486: INFO: Pod downwardapi-volume-d22bcc61-2b99-4cc1-a813-c0f203c8929c no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 19:24:30.486: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4217" for this suite.
Aug 27 19:24:36.553: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 19:24:36.938: INFO: namespace projected-4217 deletion completed in 6.430609661s

• [SLOW TEST:10.803 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 19:24:36.941: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-2904
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-309d55e7-6caa-47f2-ac77-123fdd23d926
STEP: Creating a pod to test consume configMaps
Aug 27 19:24:37.192: INFO: Waiting up to 5m0s for pod "pod-configmaps-a5cfa351-1b38-495c-8c11-69bb6f62a0f6" in namespace "configmap-2904" to be "success or failure"
Aug 27 19:24:37.203: INFO: Pod "pod-configmaps-a5cfa351-1b38-495c-8c11-69bb6f62a0f6": Phase="Pending", Reason="", readiness=false. Elapsed: 10.730122ms
Aug 27 19:24:39.213: INFO: Pod "pod-configmaps-a5cfa351-1b38-495c-8c11-69bb6f62a0f6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021285543s
STEP: Saw pod success
Aug 27 19:24:39.213: INFO: Pod "pod-configmaps-a5cfa351-1b38-495c-8c11-69bb6f62a0f6" satisfied condition "success or failure"
Aug 27 19:24:39.222: INFO: Trying to get logs from node 10.138.3.233 pod pod-configmaps-a5cfa351-1b38-495c-8c11-69bb6f62a0f6 container configmap-volume-test: <nil>
STEP: delete the pod
Aug 27 19:24:39.278: INFO: Waiting for pod pod-configmaps-a5cfa351-1b38-495c-8c11-69bb6f62a0f6 to disappear
Aug 27 19:24:39.287: INFO: Pod pod-configmaps-a5cfa351-1b38-495c-8c11-69bb6f62a0f6 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 19:24:39.287: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2904" for this suite.
Aug 27 19:24:45.362: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 19:24:45.816: INFO: namespace configmap-2904 deletion completed in 6.498535854s

• [SLOW TEST:8.876 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 19:24:45.816: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-2769
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the container
STEP: wait for the container to reach Failed
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Aug 27 19:24:49.107: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 19:24:49.153: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-2769" for this suite.
Aug 27 19:24:55.215: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 19:24:55.694: INFO: namespace container-runtime-2769 deletion completed in 6.524719947s

• [SLOW TEST:9.878 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  blackbox test
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
    on terminated container
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:129
      should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 19:24:55.696: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-1964
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-1964
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace statefulset-1964
STEP: Creating statefulset with conflicting port in namespace statefulset-1964
STEP: Waiting until pod test-pod will start running in namespace statefulset-1964
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-1964
Aug 27 19:25:00.005: INFO: Observed stateful pod in namespace: statefulset-1964, name: ss-0, uid: 897221b3-4e2b-47a1-8b9f-4d23bd065744, status phase: Pending. Waiting for statefulset controller to delete.
Aug 27 19:25:00.083: INFO: Observed stateful pod in namespace: statefulset-1964, name: ss-0, uid: 897221b3-4e2b-47a1-8b9f-4d23bd065744, status phase: Failed. Waiting for statefulset controller to delete.
Aug 27 19:25:00.095: INFO: Observed stateful pod in namespace: statefulset-1964, name: ss-0, uid: 897221b3-4e2b-47a1-8b9f-4d23bd065744, status phase: Failed. Waiting for statefulset controller to delete.
Aug 27 19:25:00.099: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-1964
STEP: Removing pod with conflicting port in namespace statefulset-1964
STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-1964 and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Aug 27 19:25:06.167: INFO: Deleting all statefulset in ns statefulset-1964
Aug 27 19:25:06.177: INFO: Scaling statefulset ss to 0
Aug 27 19:25:26.218: INFO: Waiting for statefulset status.replicas updated to 0
Aug 27 19:25:26.227: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 19:25:26.278: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-1964" for this suite.
Aug 27 19:25:34.347: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 19:25:34.740: INFO: namespace statefulset-1964 deletion completed in 8.436776049s

• [SLOW TEST:39.044 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 19:25:34.741: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-8340
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1686
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Aug 27 19:25:34.962: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-540514467 run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-8340'
Aug 27 19:25:35.109: INFO: stderr: ""
Aug 27 19:25:35.109: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1691
Aug 27 19:25:35.120: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-540514467 delete pods e2e-test-nginx-pod --namespace=kubectl-8340'
Aug 27 19:25:38.093: INFO: stderr: ""
Aug 27 19:25:38.093: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 19:25:38.093: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8340" for this suite.
Aug 27 19:25:44.153: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 19:25:44.500: INFO: namespace kubectl-8340 deletion completed in 6.390641663s

• [SLOW TEST:9.759 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run pod
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 19:25:44.502: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-8819
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-d010f447-e429-43a4-9613-3b4806ff84f9
STEP: Creating a pod to test consume secrets
Aug 27 19:25:44.752: INFO: Waiting up to 5m0s for pod "pod-secrets-8206fa5f-2312-47c6-bd2f-f22cc1b1b259" in namespace "secrets-8819" to be "success or failure"
Aug 27 19:25:44.763: INFO: Pod "pod-secrets-8206fa5f-2312-47c6-bd2f-f22cc1b1b259": Phase="Pending", Reason="", readiness=false. Elapsed: 11.409247ms
Aug 27 19:25:46.774: INFO: Pod "pod-secrets-8206fa5f-2312-47c6-bd2f-f22cc1b1b259": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.022046681s
STEP: Saw pod success
Aug 27 19:25:46.774: INFO: Pod "pod-secrets-8206fa5f-2312-47c6-bd2f-f22cc1b1b259" satisfied condition "success or failure"
Aug 27 19:25:46.784: INFO: Trying to get logs from node 10.138.3.242 pod pod-secrets-8206fa5f-2312-47c6-bd2f-f22cc1b1b259 container secret-volume-test: <nil>
STEP: delete the pod
Aug 27 19:25:46.838: INFO: Waiting for pod pod-secrets-8206fa5f-2312-47c6-bd2f-f22cc1b1b259 to disappear
Aug 27 19:25:46.848: INFO: Pod pod-secrets-8206fa5f-2312-47c6-bd2f-f22cc1b1b259 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 19:25:46.848: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8819" for this suite.
Aug 27 19:25:52.908: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 19:25:53.310: INFO: namespace secrets-8819 deletion completed in 6.447337296s

• [SLOW TEST:8.808 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 19:25:53.311: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-5025
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-configmap-xwpt
STEP: Creating a pod to test atomic-volume-subpath
Aug 27 19:25:53.575: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-xwpt" in namespace "subpath-5025" to be "success or failure"
Aug 27 19:25:53.585: INFO: Pod "pod-subpath-test-configmap-xwpt": Phase="Pending", Reason="", readiness=false. Elapsed: 10.111534ms
Aug 27 19:25:55.596: INFO: Pod "pod-subpath-test-configmap-xwpt": Phase="Running", Reason="", readiness=true. Elapsed: 2.02072287s
Aug 27 19:25:57.606: INFO: Pod "pod-subpath-test-configmap-xwpt": Phase="Running", Reason="", readiness=true. Elapsed: 4.031151852s
Aug 27 19:25:59.617: INFO: Pod "pod-subpath-test-configmap-xwpt": Phase="Running", Reason="", readiness=true. Elapsed: 6.042225703s
Aug 27 19:26:01.628: INFO: Pod "pod-subpath-test-configmap-xwpt": Phase="Running", Reason="", readiness=true. Elapsed: 8.052921393s
Aug 27 19:26:03.639: INFO: Pod "pod-subpath-test-configmap-xwpt": Phase="Running", Reason="", readiness=true. Elapsed: 10.063557942s
Aug 27 19:26:05.650: INFO: Pod "pod-subpath-test-configmap-xwpt": Phase="Running", Reason="", readiness=true. Elapsed: 12.074356752s
Aug 27 19:26:07.660: INFO: Pod "pod-subpath-test-configmap-xwpt": Phase="Running", Reason="", readiness=true. Elapsed: 14.085127908s
Aug 27 19:26:09.672: INFO: Pod "pod-subpath-test-configmap-xwpt": Phase="Running", Reason="", readiness=true. Elapsed: 16.096481343s
Aug 27 19:26:11.683: INFO: Pod "pod-subpath-test-configmap-xwpt": Phase="Running", Reason="", readiness=true. Elapsed: 18.107942437s
Aug 27 19:26:13.694: INFO: Pod "pod-subpath-test-configmap-xwpt": Phase="Running", Reason="", readiness=true. Elapsed: 20.119089566s
Aug 27 19:26:15.705: INFO: Pod "pod-subpath-test-configmap-xwpt": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.129714447s
STEP: Saw pod success
Aug 27 19:26:15.705: INFO: Pod "pod-subpath-test-configmap-xwpt" satisfied condition "success or failure"
Aug 27 19:26:15.716: INFO: Trying to get logs from node 10.138.3.233 pod pod-subpath-test-configmap-xwpt container test-container-subpath-configmap-xwpt: <nil>
STEP: delete the pod
Aug 27 19:26:15.768: INFO: Waiting for pod pod-subpath-test-configmap-xwpt to disappear
Aug 27 19:26:15.778: INFO: Pod pod-subpath-test-configmap-xwpt no longer exists
STEP: Deleting pod pod-subpath-test-configmap-xwpt
Aug 27 19:26:15.778: INFO: Deleting pod "pod-subpath-test-configmap-xwpt" in namespace "subpath-5025"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 19:26:15.787: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-5025" for this suite.
Aug 27 19:26:21.850: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 19:26:22.264: INFO: namespace subpath-5025 deletion completed in 6.460997559s

• [SLOW TEST:28.954 seconds]
[sig-storage] Subpath
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 19:26:22.271: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-6399
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:81
Aug 27 19:26:22.491: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Aug 27 19:26:22.517: INFO: Waiting for terminating namespaces to be deleted...
Aug 27 19:26:22.529: INFO: 
Logging pods the kubelet thinks is on node 10.138.3.199 before test
Aug 27 19:26:22.573: INFO: calico-node-qtfmd from kube-system started at 2019-08-27 16:48:40 +0000 UTC (1 container statuses recorded)
Aug 27 19:26:22.573: INFO: 	Container calico-node ready: true, restart count 0
Aug 27 19:26:22.573: INFO: public-crblilkl7s0qcmd68ptvug-alb1-96757c898-jhng9 from kube-system started at 2019-08-27 16:57:11 +0000 UTC (4 container statuses recorded)
Aug 27 19:26:22.573: INFO: 	Container ingress-auth-1 ready: true, restart count 0
Aug 27 19:26:22.573: INFO: 	Container ingress-auth-2 ready: true, restart count 0
Aug 27 19:26:22.573: INFO: 	Container ingress-auth-3 ready: true, restart count 0
Aug 27 19:26:22.573: INFO: 	Container nginx-ingress ready: true, restart count 0
Aug 27 19:26:22.573: INFO: coredns-64f45bf67-82p5d from kube-system started at 2019-08-27 17:16:42 +0000 UTC (1 container statuses recorded)
Aug 27 19:26:22.573: INFO: 	Container coredns ready: true, restart count 0
Aug 27 19:26:22.573: INFO: coredns-autoscaler-74cb66766b-v4jw4 from kube-system started at 2019-08-27 16:48:54 +0000 UTC (1 container statuses recorded)
Aug 27 19:26:22.573: INFO: 	Container autoscaler ready: true, restart count 0
Aug 27 19:26:22.573: INFO: calico-kube-controllers-8b68f5487-frr4d from kube-system started at 2019-08-27 16:48:54 +0000 UTC (1 container statuses recorded)
Aug 27 19:26:22.573: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Aug 27 19:26:22.573: INFO: sonobuoy-e2e-job-7e16f540f6e644a9 from heptio-sonobuoy started at 2019-08-27 18:29:36 +0000 UTC (2 container statuses recorded)
Aug 27 19:26:22.573: INFO: 	Container e2e ready: true, restart count 0
Aug 27 19:26:22.573: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug 27 19:26:22.573: INFO: ibm-master-proxy-static-10.138.3.199 from kube-system started at 2019-08-27 16:48:38 +0000 UTC (2 container statuses recorded)
Aug 27 19:26:22.573: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Aug 27 19:26:22.573: INFO: 	Container pause ready: true, restart count 0
Aug 27 19:26:22.573: INFO: ibm-file-plugin-8598c89fd6-zkw7p from kube-system started at 2019-08-27 16:48:54 +0000 UTC (1 container statuses recorded)
Aug 27 19:26:22.573: INFO: 	Container ibm-file-plugin-container ready: true, restart count 0
Aug 27 19:26:22.573: INFO: sonobuoy-systemd-logs-daemon-set-6de4f4bc9f654bc5-2n49n from heptio-sonobuoy started at 2019-08-27 18:29:36 +0000 UTC (2 container statuses recorded)
Aug 27 19:26:22.573: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug 27 19:26:22.573: INFO: 	Container systemd-logs ready: true, restart count 0
Aug 27 19:26:22.573: INFO: ibm-keepalived-watcher-q4lz6 from kube-system started at 2019-08-27 16:48:40 +0000 UTC (1 container statuses recorded)
Aug 27 19:26:22.573: INFO: 	Container keepalived-watcher ready: true, restart count 0
Aug 27 19:26:22.573: INFO: kubernetes-dashboard-596f947ff4-qhm8x from kube-system started at 2019-08-27 16:48:54 +0000 UTC (1 container statuses recorded)
Aug 27 19:26:22.573: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Aug 27 19:26:22.573: INFO: ibm-storage-watcher-79884b9494-zg264 from kube-system started at 2019-08-27 16:48:54 +0000 UTC (1 container statuses recorded)
Aug 27 19:26:22.573: INFO: 	Container ibm-storage-watcher-container ready: true, restart count 0
Aug 27 19:26:22.573: INFO: ibm-kube-fluentd-sndbh from kube-system started at 2019-08-27 16:49:31 +0000 UTC (1 container statuses recorded)
Aug 27 19:26:22.573: INFO: 	Container fluentd ready: true, restart count 0
Aug 27 19:26:22.573: INFO: 
Logging pods the kubelet thinks is on node 10.138.3.233 before test
Aug 27 19:26:22.603: INFO: metrics-server-74c65558d9-bjxkf from kube-system started at 2019-08-27 16:49:27 +0000 UTC (2 container statuses recorded)
Aug 27 19:26:22.603: INFO: 	Container metrics-server ready: true, restart count 0
Aug 27 19:26:22.603: INFO: 	Container metrics-server-nanny ready: true, restart count 0
Aug 27 19:26:22.603: INFO: public-crblilkl7s0qcmd68ptvug-alb1-96757c898-ttk5v from kube-system started at 2019-08-27 16:57:11 +0000 UTC (4 container statuses recorded)
Aug 27 19:26:22.603: INFO: 	Container ingress-auth-1 ready: true, restart count 0
Aug 27 19:26:22.603: INFO: 	Container ingress-auth-2 ready: true, restart count 0
Aug 27 19:26:22.603: INFO: 	Container ingress-auth-3 ready: true, restart count 0
Aug 27 19:26:22.603: INFO: 	Container nginx-ingress ready: true, restart count 0
Aug 27 19:26:22.603: INFO: sonobuoy-systemd-logs-daemon-set-6de4f4bc9f654bc5-5t68b from heptio-sonobuoy started at 2019-08-27 18:29:36 +0000 UTC (2 container statuses recorded)
Aug 27 19:26:22.603: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug 27 19:26:22.603: INFO: 	Container systemd-logs ready: true, restart count 0
Aug 27 19:26:22.603: INFO: ibm-keepalived-watcher-rqmrm from kube-system started at 2019-08-27 16:48:49 +0000 UTC (1 container statuses recorded)
Aug 27 19:26:22.603: INFO: 	Container keepalived-watcher ready: true, restart count 0
Aug 27 19:26:22.603: INFO: calico-node-hhq6f from kube-system started at 2019-08-27 16:48:49 +0000 UTC (1 container statuses recorded)
Aug 27 19:26:22.603: INFO: 	Container calico-node ready: true, restart count 0
Aug 27 19:26:22.603: INFO: ibm-kube-fluentd-7vnnc from kube-system started at 2019-08-27 16:49:31 +0000 UTC (1 container statuses recorded)
Aug 27 19:26:22.603: INFO: 	Container fluentd ready: true, restart count 0
Aug 27 19:26:22.603: INFO: ibm-cloud-provider-ip-168-1-33-254-684b4b48d5-6htlx from ibm-system started at 2019-08-27 16:54:12 +0000 UTC (1 container statuses recorded)
Aug 27 19:26:22.603: INFO: 	Container ibm-cloud-provider-ip-168-1-33-254 ready: true, restart count 0
Aug 27 19:26:22.603: INFO: ibm-master-proxy-static-10.138.3.233 from kube-system started at 2019-08-27 16:48:48 +0000 UTC (2 container statuses recorded)
Aug 27 19:26:22.603: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Aug 27 19:26:22.603: INFO: 	Container pause ready: true, restart count 0
Aug 27 19:26:22.603: INFO: 
Logging pods the kubelet thinks is on node 10.138.3.242 before test
Aug 27 19:26:22.632: INFO: sonobuoy-systemd-logs-daemon-set-6de4f4bc9f654bc5-jt7wr from heptio-sonobuoy started at 2019-08-27 18:29:36 +0000 UTC (2 container statuses recorded)
Aug 27 19:26:22.632: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug 27 19:26:22.632: INFO: 	Container systemd-logs ready: true, restart count 0
Aug 27 19:26:22.632: INFO: vpn-75d8697c68-t4p4j from kube-system started at 2019-08-27 17:16:10 +0000 UTC (1 container statuses recorded)
Aug 27 19:26:22.632: INFO: 	Container vpn ready: true, restart count 0
Aug 27 19:26:22.632: INFO: ibm-kube-fluentd-9wfd4 from kube-system started at 2019-08-27 16:49:35 +0000 UTC (1 container statuses recorded)
Aug 27 19:26:22.632: INFO: 	Container fluentd ready: true, restart count 0
Aug 27 19:26:22.632: INFO: ibm-master-proxy-static-10.138.3.242 from kube-system started at 2019-08-27 16:49:34 +0000 UTC (2 container statuses recorded)
Aug 27 19:26:22.632: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Aug 27 19:26:22.632: INFO: 	Container pause ready: true, restart count 0
Aug 27 19:26:22.632: INFO: coredns-64f45bf67-b57dh from kube-system started at 2019-08-27 17:16:42 +0000 UTC (1 container statuses recorded)
Aug 27 19:26:22.633: INFO: 	Container coredns ready: true, restart count 0
Aug 27 19:26:22.633: INFO: test-k8s-e2e-pvg-master-verification from default started at 2019-08-27 16:51:12 +0000 UTC (1 container statuses recorded)
Aug 27 19:26:22.633: INFO: 	Container test-k8s-e2e-pvg-master-verification ready: true, restart count 0
Aug 27 19:26:22.633: INFO: calico-node-b9wft from kube-system started at 2019-08-27 16:49:35 +0000 UTC (1 container statuses recorded)
Aug 27 19:26:22.633: INFO: 	Container calico-node ready: true, restart count 0
Aug 27 19:26:22.633: INFO: ibm-cloud-provider-ip-168-1-33-254-684b4b48d5-f6mrh from ibm-system started at 2019-08-27 16:54:12 +0000 UTC (1 container statuses recorded)
Aug 27 19:26:22.633: INFO: 	Container ibm-cloud-provider-ip-168-1-33-254 ready: true, restart count 0
Aug 27 19:26:22.633: INFO: sonobuoy from heptio-sonobuoy started at 2019-08-27 18:29:26 +0000 UTC (1 container statuses recorded)
Aug 27 19:26:22.633: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Aug 27 19:26:22.634: INFO: ibm-keepalived-watcher-jsshh from kube-system started at 2019-08-27 16:49:35 +0000 UTC (1 container statuses recorded)
Aug 27 19:26:22.634: INFO: 	Container keepalived-watcher ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.15bede27be4820d9], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 19:26:23.705: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-6399" for this suite.
Aug 27 19:26:29.767: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 19:26:30.182: INFO: namespace sched-pred-6399 deletion completed in 6.459856209s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:72

• [SLOW TEST:7.911 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 19:26:30.184: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-3562
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Aug 27 19:26:30.425: INFO: Waiting up to 5m0s for pod "downward-api-5d6f615c-067d-463d-b235-5fc1e96c08f5" in namespace "downward-api-3562" to be "success or failure"
Aug 27 19:26:30.436: INFO: Pod "downward-api-5d6f615c-067d-463d-b235-5fc1e96c08f5": Phase="Pending", Reason="", readiness=false. Elapsed: 11.63913ms
Aug 27 19:26:32.447: INFO: Pod "downward-api-5d6f615c-067d-463d-b235-5fc1e96c08f5": Phase="Running", Reason="", readiness=true. Elapsed: 2.022689071s
Aug 27 19:26:34.459: INFO: Pod "downward-api-5d6f615c-067d-463d-b235-5fc1e96c08f5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.034090396s
STEP: Saw pod success
Aug 27 19:26:34.459: INFO: Pod "downward-api-5d6f615c-067d-463d-b235-5fc1e96c08f5" satisfied condition "success or failure"
Aug 27 19:26:34.468: INFO: Trying to get logs from node 10.138.3.242 pod downward-api-5d6f615c-067d-463d-b235-5fc1e96c08f5 container dapi-container: <nil>
STEP: delete the pod
Aug 27 19:26:34.515: INFO: Waiting for pod downward-api-5d6f615c-067d-463d-b235-5fc1e96c08f5 to disappear
Aug 27 19:26:34.525: INFO: Pod downward-api-5d6f615c-067d-463d-b235-5fc1e96c08f5 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 19:26:34.525: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3562" for this suite.
Aug 27 19:26:40.583: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 19:26:40.983: INFO: namespace downward-api-3562 deletion completed in 6.443554263s

• [SLOW TEST:10.800 seconds]
[sig-node] Downward API
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 19:26:40.984: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-9907
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Aug 27 19:26:41.219: INFO: Waiting up to 5m0s for pod "downward-api-4252e162-3d2c-43ed-bb06-9f4699be41a9" in namespace "downward-api-9907" to be "success or failure"
Aug 27 19:26:41.230: INFO: Pod "downward-api-4252e162-3d2c-43ed-bb06-9f4699be41a9": Phase="Pending", Reason="", readiness=false. Elapsed: 11.154608ms
Aug 27 19:26:43.242: INFO: Pod "downward-api-4252e162-3d2c-43ed-bb06-9f4699be41a9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023297114s
Aug 27 19:26:45.253: INFO: Pod "downward-api-4252e162-3d2c-43ed-bb06-9f4699be41a9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.033844822s
STEP: Saw pod success
Aug 27 19:26:45.253: INFO: Pod "downward-api-4252e162-3d2c-43ed-bb06-9f4699be41a9" satisfied condition "success or failure"
Aug 27 19:26:45.263: INFO: Trying to get logs from node 10.138.3.233 pod downward-api-4252e162-3d2c-43ed-bb06-9f4699be41a9 container dapi-container: <nil>
STEP: delete the pod
Aug 27 19:26:45.310: INFO: Waiting for pod downward-api-4252e162-3d2c-43ed-bb06-9f4699be41a9 to disappear
Aug 27 19:26:45.320: INFO: Pod downward-api-4252e162-3d2c-43ed-bb06-9f4699be41a9 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 19:26:45.320: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9907" for this suite.
Aug 27 19:26:51.382: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 19:26:51.758: INFO: namespace downward-api-9907 deletion completed in 6.420585707s

• [SLOW TEST:10.774 seconds]
[sig-node] Downward API
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 19:26:51.759: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-5579
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-e90753f7-d070-43da-894a-f71b6e4065a9
STEP: Creating a pod to test consume secrets
Aug 27 19:26:52.003: INFO: Waiting up to 5m0s for pod "pod-secrets-0294295c-528c-4a80-a990-30b5355ae42e" in namespace "secrets-5579" to be "success or failure"
Aug 27 19:26:52.014: INFO: Pod "pod-secrets-0294295c-528c-4a80-a990-30b5355ae42e": Phase="Pending", Reason="", readiness=false. Elapsed: 10.797549ms
Aug 27 19:26:54.024: INFO: Pod "pod-secrets-0294295c-528c-4a80-a990-30b5355ae42e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021126534s
STEP: Saw pod success
Aug 27 19:26:54.024: INFO: Pod "pod-secrets-0294295c-528c-4a80-a990-30b5355ae42e" satisfied condition "success or failure"
Aug 27 19:26:54.034: INFO: Trying to get logs from node 10.138.3.242 pod pod-secrets-0294295c-528c-4a80-a990-30b5355ae42e container secret-volume-test: <nil>
STEP: delete the pod
Aug 27 19:26:54.080: INFO: Waiting for pod pod-secrets-0294295c-528c-4a80-a990-30b5355ae42e to disappear
Aug 27 19:26:54.091: INFO: Pod pod-secrets-0294295c-528c-4a80-a990-30b5355ae42e no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 19:26:54.091: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5579" for this suite.
Aug 27 19:27:00.149: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 19:27:00.534: INFO: namespace secrets-5579 deletion completed in 6.427787657s

• [SLOW TEST:8.775 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 19:27:00.535: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-1961
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Aug 27 19:27:00.774: INFO: Waiting up to 5m0s for pod "downwardapi-volume-3100986a-d7b0-43b1-bc4b-f9bebee06947" in namespace "downward-api-1961" to be "success or failure"
Aug 27 19:27:00.783: INFO: Pod "downwardapi-volume-3100986a-d7b0-43b1-bc4b-f9bebee06947": Phase="Pending", Reason="", readiness=false. Elapsed: 9.290561ms
Aug 27 19:27:02.793: INFO: Pod "downwardapi-volume-3100986a-d7b0-43b1-bc4b-f9bebee06947": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019451037s
Aug 27 19:27:04.804: INFO: Pod "downwardapi-volume-3100986a-d7b0-43b1-bc4b-f9bebee06947": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.03065094s
STEP: Saw pod success
Aug 27 19:27:04.804: INFO: Pod "downwardapi-volume-3100986a-d7b0-43b1-bc4b-f9bebee06947" satisfied condition "success or failure"
Aug 27 19:27:04.814: INFO: Trying to get logs from node 10.138.3.242 pod downwardapi-volume-3100986a-d7b0-43b1-bc4b-f9bebee06947 container client-container: <nil>
STEP: delete the pod
Aug 27 19:27:04.867: INFO: Waiting for pod downwardapi-volume-3100986a-d7b0-43b1-bc4b-f9bebee06947 to disappear
Aug 27 19:27:04.876: INFO: Pod downwardapi-volume-3100986a-d7b0-43b1-bc4b-f9bebee06947 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 19:27:04.877: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1961" for this suite.
Aug 27 19:27:10.935: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 19:27:11.362: INFO: namespace downward-api-1961 deletion completed in 6.470895996s

• [SLOW TEST:10.827 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 19:27:11.362: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-5479
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Aug 27 19:27:11.611: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Aug 27 19:27:16.622: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Aug 27 19:27:16.622: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
Aug 27 19:27:18.706: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment,GenerateName:,Namespace:deployment-5479,SelfLink:/apis/apps/v1/namespaces/deployment-5479/deployments/test-cleanup-deployment,UID:29e2e573-1003-497e-8c77-cce173577131,ResourceVersion:35751,Generation:1,CreationTimestamp:2019-08-27 19:27:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 1,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-08-27 19:27:16 +0000 UTC 2019-08-27 19:27:16 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-08-27 19:27:18 +0000 UTC 2019-08-27 19:27:16 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-cleanup-deployment-55bbcbc84c" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Aug 27 19:27:18.719: INFO: New ReplicaSet "test-cleanup-deployment-55bbcbc84c" of Deployment "test-cleanup-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-55bbcbc84c,GenerateName:,Namespace:deployment-5479,SelfLink:/apis/apps/v1/namespaces/deployment-5479/replicasets/test-cleanup-deployment-55bbcbc84c,UID:f268e8e4-8c86-4a01-9be5-3c47abe05e57,ResourceVersion:35740,Generation:1,CreationTimestamp:2019-08-27 19:27:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 55bbcbc84c,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment 29e2e573-1003-497e-8c77-cce173577131 0xc001d5b047 0xc001d5b048}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: 55bbcbc84c,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 55bbcbc84c,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Aug 27 19:27:18.730: INFO: Pod "test-cleanup-deployment-55bbcbc84c-n5bws" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-55bbcbc84c-n5bws,GenerateName:test-cleanup-deployment-55bbcbc84c-,Namespace:deployment-5479,SelfLink:/api/v1/namespaces/deployment-5479/pods/test-cleanup-deployment-55bbcbc84c-n5bws,UID:7784c41d-0303-4166-af68-ba8da7ff1b72,ResourceVersion:35739,Generation:0,CreationTimestamp:2019-08-27 19:27:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 55bbcbc84c,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-deployment-55bbcbc84c f268e8e4-8c86-4a01-9be5-3c47abe05e57 0xc001d5b667 0xc001d5b668}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-r828l {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-r828l,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-r828l true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.138.3.233,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001d5b6e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001d5b700}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:27:16 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:27:18 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:27:18 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:27:16 +0000 UTC  }],Message:,Reason:,HostIP:10.138.3.233,PodIP:172.30.37.201,StartTime:2019-08-27 19:27:16 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-08-27 19:27:18 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 containerd://8e70f1075ef934e1554af404e480fed061122cc420d07bc3e40aa2e2248a3aef}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 19:27:18.730: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-5479" for this suite.
Aug 27 19:27:24.790: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 19:27:25.180: INFO: namespace deployment-5479 deletion completed in 6.433850813s

• [SLOW TEST:13.817 seconds]
[sig-apps] Deployment
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 19:27:25.180: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-8129
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir volume type on node default medium
Aug 27 19:27:25.414: INFO: Waiting up to 5m0s for pod "pod-23b96220-a56a-4907-8a2a-049dd56954ad" in namespace "emptydir-8129" to be "success or failure"
Aug 27 19:27:25.424: INFO: Pod "pod-23b96220-a56a-4907-8a2a-049dd56954ad": Phase="Pending", Reason="", readiness=false. Elapsed: 9.796102ms
Aug 27 19:27:27.435: INFO: Pod "pod-23b96220-a56a-4907-8a2a-049dd56954ad": Phase="Running", Reason="", readiness=true. Elapsed: 2.020116534s
Aug 27 19:27:29.445: INFO: Pod "pod-23b96220-a56a-4907-8a2a-049dd56954ad": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.030705921s
STEP: Saw pod success
Aug 27 19:27:29.445: INFO: Pod "pod-23b96220-a56a-4907-8a2a-049dd56954ad" satisfied condition "success or failure"
Aug 27 19:27:29.455: INFO: Trying to get logs from node 10.138.3.242 pod pod-23b96220-a56a-4907-8a2a-049dd56954ad container test-container: <nil>
STEP: delete the pod
Aug 27 19:27:29.505: INFO: Waiting for pod pod-23b96220-a56a-4907-8a2a-049dd56954ad to disappear
Aug 27 19:27:29.515: INFO: Pod pod-23b96220-a56a-4907-8a2a-049dd56954ad no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 19:27:29.515: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8129" for this suite.
Aug 27 19:27:35.576: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 19:27:35.982: INFO: namespace emptydir-8129 deletion completed in 6.451557145s

• [SLOW TEST:10.802 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 19:27:35.983: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-6849
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-map-c911d7ec-61f2-470d-b37a-065d9e8e4e95
STEP: Creating a pod to test consume configMaps
Aug 27 19:27:36.241: INFO: Waiting up to 5m0s for pod "pod-configmaps-304d14df-693d-49b9-b7a7-b4a12b03e55d" in namespace "configmap-6849" to be "success or failure"
Aug 27 19:27:36.252: INFO: Pod "pod-configmaps-304d14df-693d-49b9-b7a7-b4a12b03e55d": Phase="Pending", Reason="", readiness=false. Elapsed: 11.093135ms
Aug 27 19:27:38.263: INFO: Pod "pod-configmaps-304d14df-693d-49b9-b7a7-b4a12b03e55d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021920011s
Aug 27 19:27:40.273: INFO: Pod "pod-configmaps-304d14df-693d-49b9-b7a7-b4a12b03e55d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.032538498s
STEP: Saw pod success
Aug 27 19:27:40.273: INFO: Pod "pod-configmaps-304d14df-693d-49b9-b7a7-b4a12b03e55d" satisfied condition "success or failure"
Aug 27 19:27:40.283: INFO: Trying to get logs from node 10.138.3.233 pod pod-configmaps-304d14df-693d-49b9-b7a7-b4a12b03e55d container configmap-volume-test: <nil>
STEP: delete the pod
Aug 27 19:27:40.331: INFO: Waiting for pod pod-configmaps-304d14df-693d-49b9-b7a7-b4a12b03e55d to disappear
Aug 27 19:27:40.340: INFO: Pod pod-configmaps-304d14df-693d-49b9-b7a7-b4a12b03e55d no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 19:27:40.341: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6849" for this suite.
Aug 27 19:27:46.402: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 19:27:46.812: INFO: namespace configmap-6849 deletion completed in 6.455989848s

• [SLOW TEST:10.830 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 19:27:46.813: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5593
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-map-4cd84e0c-5a36-4278-ad9c-3cdcab362e7d
STEP: Creating a pod to test consume configMaps
Aug 27 19:27:47.063: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-4fb536aa-7505-4a59-a2ea-bf7e94345089" in namespace "projected-5593" to be "success or failure"
Aug 27 19:27:47.073: INFO: Pod "pod-projected-configmaps-4fb536aa-7505-4a59-a2ea-bf7e94345089": Phase="Pending", Reason="", readiness=false. Elapsed: 9.838498ms
Aug 27 19:27:49.083: INFO: Pod "pod-projected-configmaps-4fb536aa-7505-4a59-a2ea-bf7e94345089": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020403226s
STEP: Saw pod success
Aug 27 19:27:49.084: INFO: Pod "pod-projected-configmaps-4fb536aa-7505-4a59-a2ea-bf7e94345089" satisfied condition "success or failure"
Aug 27 19:27:49.094: INFO: Trying to get logs from node 10.138.3.242 pod pod-projected-configmaps-4fb536aa-7505-4a59-a2ea-bf7e94345089 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Aug 27 19:27:49.139: INFO: Waiting for pod pod-projected-configmaps-4fb536aa-7505-4a59-a2ea-bf7e94345089 to disappear
Aug 27 19:27:49.149: INFO: Pod pod-projected-configmaps-4fb536aa-7505-4a59-a2ea-bf7e94345089 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 19:27:49.149: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5593" for this suite.
Aug 27 19:27:55.208: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 19:27:55.567: INFO: namespace projected-5593 deletion completed in 6.402654787s

• [SLOW TEST:8.753 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 19:27:55.568: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-9909
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:81
Aug 27 19:27:55.783: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Aug 27 19:27:55.814: INFO: Waiting for terminating namespaces to be deleted...
Aug 27 19:27:55.827: INFO: 
Logging pods the kubelet thinks is on node 10.138.3.199 before test
Aug 27 19:27:55.858: INFO: sonobuoy-systemd-logs-daemon-set-6de4f4bc9f654bc5-2n49n from heptio-sonobuoy started at 2019-08-27 18:29:36 +0000 UTC (2 container statuses recorded)
Aug 27 19:27:55.858: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug 27 19:27:55.858: INFO: 	Container systemd-logs ready: true, restart count 0
Aug 27 19:27:55.858: INFO: ibm-kube-fluentd-sndbh from kube-system started at 2019-08-27 16:49:31 +0000 UTC (1 container statuses recorded)
Aug 27 19:27:55.858: INFO: 	Container fluentd ready: true, restart count 0
Aug 27 19:27:55.858: INFO: ibm-keepalived-watcher-q4lz6 from kube-system started at 2019-08-27 16:48:40 +0000 UTC (1 container statuses recorded)
Aug 27 19:27:55.858: INFO: 	Container keepalived-watcher ready: true, restart count 0
Aug 27 19:27:55.858: INFO: kubernetes-dashboard-596f947ff4-qhm8x from kube-system started at 2019-08-27 16:48:54 +0000 UTC (1 container statuses recorded)
Aug 27 19:27:55.858: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Aug 27 19:27:55.858: INFO: ibm-storage-watcher-79884b9494-zg264 from kube-system started at 2019-08-27 16:48:54 +0000 UTC (1 container statuses recorded)
Aug 27 19:27:55.858: INFO: 	Container ibm-storage-watcher-container ready: true, restart count 0
Aug 27 19:27:55.858: INFO: coredns-autoscaler-74cb66766b-v4jw4 from kube-system started at 2019-08-27 16:48:54 +0000 UTC (1 container statuses recorded)
Aug 27 19:27:55.858: INFO: 	Container autoscaler ready: true, restart count 0
Aug 27 19:27:55.858: INFO: calico-kube-controllers-8b68f5487-frr4d from kube-system started at 2019-08-27 16:48:54 +0000 UTC (1 container statuses recorded)
Aug 27 19:27:55.858: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Aug 27 19:27:55.858: INFO: sonobuoy-e2e-job-7e16f540f6e644a9 from heptio-sonobuoy started at 2019-08-27 18:29:36 +0000 UTC (2 container statuses recorded)
Aug 27 19:27:55.858: INFO: 	Container e2e ready: true, restart count 0
Aug 27 19:27:55.858: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug 27 19:27:55.858: INFO: calico-node-qtfmd from kube-system started at 2019-08-27 16:48:40 +0000 UTC (1 container statuses recorded)
Aug 27 19:27:55.858: INFO: 	Container calico-node ready: true, restart count 0
Aug 27 19:27:55.858: INFO: public-crblilkl7s0qcmd68ptvug-alb1-96757c898-jhng9 from kube-system started at 2019-08-27 16:57:11 +0000 UTC (4 container statuses recorded)
Aug 27 19:27:55.858: INFO: 	Container ingress-auth-1 ready: true, restart count 0
Aug 27 19:27:55.858: INFO: 	Container ingress-auth-2 ready: true, restart count 0
Aug 27 19:27:55.858: INFO: 	Container ingress-auth-3 ready: true, restart count 0
Aug 27 19:27:55.858: INFO: 	Container nginx-ingress ready: true, restart count 0
Aug 27 19:27:55.858: INFO: coredns-64f45bf67-82p5d from kube-system started at 2019-08-27 17:16:42 +0000 UTC (1 container statuses recorded)
Aug 27 19:27:55.858: INFO: 	Container coredns ready: true, restart count 0
Aug 27 19:27:55.858: INFO: ibm-master-proxy-static-10.138.3.199 from kube-system started at 2019-08-27 16:48:38 +0000 UTC (2 container statuses recorded)
Aug 27 19:27:55.858: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Aug 27 19:27:55.858: INFO: 	Container pause ready: true, restart count 0
Aug 27 19:27:55.858: INFO: ibm-file-plugin-8598c89fd6-zkw7p from kube-system started at 2019-08-27 16:48:54 +0000 UTC (1 container statuses recorded)
Aug 27 19:27:55.858: INFO: 	Container ibm-file-plugin-container ready: true, restart count 0
Aug 27 19:27:55.858: INFO: 
Logging pods the kubelet thinks is on node 10.138.3.233 before test
Aug 27 19:27:55.905: INFO: ibm-kube-fluentd-7vnnc from kube-system started at 2019-08-27 16:49:31 +0000 UTC (1 container statuses recorded)
Aug 27 19:27:55.905: INFO: 	Container fluentd ready: true, restart count 0
Aug 27 19:27:55.905: INFO: ibm-cloud-provider-ip-168-1-33-254-684b4b48d5-6htlx from ibm-system started at 2019-08-27 16:54:12 +0000 UTC (1 container statuses recorded)
Aug 27 19:27:55.905: INFO: 	Container ibm-cloud-provider-ip-168-1-33-254 ready: true, restart count 0
Aug 27 19:27:55.905: INFO: ibm-master-proxy-static-10.138.3.233 from kube-system started at 2019-08-27 16:48:48 +0000 UTC (2 container statuses recorded)
Aug 27 19:27:55.905: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Aug 27 19:27:55.905: INFO: 	Container pause ready: true, restart count 0
Aug 27 19:27:55.905: INFO: calico-node-hhq6f from kube-system started at 2019-08-27 16:48:49 +0000 UTC (1 container statuses recorded)
Aug 27 19:27:55.905: INFO: 	Container calico-node ready: true, restart count 0
Aug 27 19:27:55.905: INFO: metrics-server-74c65558d9-bjxkf from kube-system started at 2019-08-27 16:49:27 +0000 UTC (2 container statuses recorded)
Aug 27 19:27:55.905: INFO: 	Container metrics-server ready: true, restart count 0
Aug 27 19:27:55.905: INFO: 	Container metrics-server-nanny ready: true, restart count 0
Aug 27 19:27:55.905: INFO: public-crblilkl7s0qcmd68ptvug-alb1-96757c898-ttk5v from kube-system started at 2019-08-27 16:57:11 +0000 UTC (4 container statuses recorded)
Aug 27 19:27:55.905: INFO: 	Container ingress-auth-1 ready: true, restart count 0
Aug 27 19:27:55.905: INFO: 	Container ingress-auth-2 ready: true, restart count 0
Aug 27 19:27:55.905: INFO: 	Container ingress-auth-3 ready: true, restart count 0
Aug 27 19:27:55.905: INFO: 	Container nginx-ingress ready: true, restart count 0
Aug 27 19:27:55.905: INFO: sonobuoy-systemd-logs-daemon-set-6de4f4bc9f654bc5-5t68b from heptio-sonobuoy started at 2019-08-27 18:29:36 +0000 UTC (2 container statuses recorded)
Aug 27 19:27:55.905: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug 27 19:27:55.905: INFO: 	Container systemd-logs ready: true, restart count 0
Aug 27 19:27:55.905: INFO: ibm-keepalived-watcher-rqmrm from kube-system started at 2019-08-27 16:48:49 +0000 UTC (1 container statuses recorded)
Aug 27 19:27:55.905: INFO: 	Container keepalived-watcher ready: true, restart count 0
Aug 27 19:27:55.905: INFO: 
Logging pods the kubelet thinks is on node 10.138.3.242 before test
Aug 27 19:27:55.938: INFO: ibm-master-proxy-static-10.138.3.242 from kube-system started at 2019-08-27 16:49:34 +0000 UTC (2 container statuses recorded)
Aug 27 19:27:55.938: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Aug 27 19:27:55.938: INFO: 	Container pause ready: true, restart count 0
Aug 27 19:27:55.938: INFO: ibm-kube-fluentd-9wfd4 from kube-system started at 2019-08-27 16:49:35 +0000 UTC (1 container statuses recorded)
Aug 27 19:27:55.938: INFO: 	Container fluentd ready: true, restart count 0
Aug 27 19:27:55.938: INFO: test-k8s-e2e-pvg-master-verification from default started at 2019-08-27 16:51:12 +0000 UTC (1 container statuses recorded)
Aug 27 19:27:55.938: INFO: 	Container test-k8s-e2e-pvg-master-verification ready: true, restart count 0
Aug 27 19:27:55.938: INFO: coredns-64f45bf67-b57dh from kube-system started at 2019-08-27 17:16:42 +0000 UTC (1 container statuses recorded)
Aug 27 19:27:55.938: INFO: 	Container coredns ready: true, restart count 0
Aug 27 19:27:55.938: INFO: ibm-keepalived-watcher-jsshh from kube-system started at 2019-08-27 16:49:35 +0000 UTC (1 container statuses recorded)
Aug 27 19:27:55.938: INFO: 	Container keepalived-watcher ready: true, restart count 0
Aug 27 19:27:55.938: INFO: calico-node-b9wft from kube-system started at 2019-08-27 16:49:35 +0000 UTC (1 container statuses recorded)
Aug 27 19:27:55.938: INFO: 	Container calico-node ready: true, restart count 0
Aug 27 19:27:55.938: INFO: ibm-cloud-provider-ip-168-1-33-254-684b4b48d5-f6mrh from ibm-system started at 2019-08-27 16:54:12 +0000 UTC (1 container statuses recorded)
Aug 27 19:27:55.938: INFO: 	Container ibm-cloud-provider-ip-168-1-33-254 ready: true, restart count 0
Aug 27 19:27:55.938: INFO: sonobuoy from heptio-sonobuoy started at 2019-08-27 18:29:26 +0000 UTC (1 container statuses recorded)
Aug 27 19:27:55.938: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Aug 27 19:27:55.938: INFO: vpn-75d8697c68-t4p4j from kube-system started at 2019-08-27 17:16:10 +0000 UTC (1 container statuses recorded)
Aug 27 19:27:55.938: INFO: 	Container vpn ready: true, restart count 0
Aug 27 19:27:55.938: INFO: sonobuoy-systemd-logs-daemon-set-6de4f4bc9f654bc5-jt7wr from heptio-sonobuoy started at 2019-08-27 18:29:36 +0000 UTC (2 container statuses recorded)
Aug 27 19:27:55.938: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug 27 19:27:55.938: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: verifying the node has the label node 10.138.3.199
STEP: verifying the node has the label node 10.138.3.233
STEP: verifying the node has the label node 10.138.3.242
Aug 27 19:27:56.084: INFO: Pod test-k8s-e2e-pvg-master-verification requesting resource cpu=0m on Node 10.138.3.242
Aug 27 19:27:56.084: INFO: Pod sonobuoy requesting resource cpu=0m on Node 10.138.3.242
Aug 27 19:27:56.084: INFO: Pod sonobuoy-e2e-job-7e16f540f6e644a9 requesting resource cpu=0m on Node 10.138.3.199
Aug 27 19:27:56.084: INFO: Pod sonobuoy-systemd-logs-daemon-set-6de4f4bc9f654bc5-2n49n requesting resource cpu=0m on Node 10.138.3.199
Aug 27 19:27:56.084: INFO: Pod sonobuoy-systemd-logs-daemon-set-6de4f4bc9f654bc5-5t68b requesting resource cpu=0m on Node 10.138.3.233
Aug 27 19:27:56.084: INFO: Pod sonobuoy-systemd-logs-daemon-set-6de4f4bc9f654bc5-jt7wr requesting resource cpu=0m on Node 10.138.3.242
Aug 27 19:27:56.084: INFO: Pod ibm-cloud-provider-ip-168-1-33-254-684b4b48d5-6htlx requesting resource cpu=5m on Node 10.138.3.233
Aug 27 19:27:56.084: INFO: Pod ibm-cloud-provider-ip-168-1-33-254-684b4b48d5-f6mrh requesting resource cpu=5m on Node 10.138.3.242
Aug 27 19:27:56.084: INFO: Pod calico-kube-controllers-8b68f5487-frr4d requesting resource cpu=10m on Node 10.138.3.199
Aug 27 19:27:56.084: INFO: Pod calico-node-b9wft requesting resource cpu=250m on Node 10.138.3.242
Aug 27 19:27:56.084: INFO: Pod calico-node-hhq6f requesting resource cpu=250m on Node 10.138.3.233
Aug 27 19:27:56.084: INFO: Pod calico-node-qtfmd requesting resource cpu=250m on Node 10.138.3.199
Aug 27 19:27:56.084: INFO: Pod coredns-64f45bf67-82p5d requesting resource cpu=100m on Node 10.138.3.199
Aug 27 19:27:56.084: INFO: Pod coredns-64f45bf67-b57dh requesting resource cpu=100m on Node 10.138.3.242
Aug 27 19:27:56.084: INFO: Pod coredns-autoscaler-74cb66766b-v4jw4 requesting resource cpu=20m on Node 10.138.3.199
Aug 27 19:27:56.084: INFO: Pod ibm-file-plugin-8598c89fd6-zkw7p requesting resource cpu=50m on Node 10.138.3.199
Aug 27 19:27:56.084: INFO: Pod ibm-keepalived-watcher-jsshh requesting resource cpu=5m on Node 10.138.3.242
Aug 27 19:27:56.084: INFO: Pod ibm-keepalived-watcher-q4lz6 requesting resource cpu=5m on Node 10.138.3.199
Aug 27 19:27:56.084: INFO: Pod ibm-keepalived-watcher-rqmrm requesting resource cpu=5m on Node 10.138.3.233
Aug 27 19:27:56.084: INFO: Pod ibm-kube-fluentd-7vnnc requesting resource cpu=25m on Node 10.138.3.233
Aug 27 19:27:56.084: INFO: Pod ibm-kube-fluentd-9wfd4 requesting resource cpu=25m on Node 10.138.3.242
Aug 27 19:27:56.084: INFO: Pod ibm-kube-fluentd-sndbh requesting resource cpu=25m on Node 10.138.3.199
Aug 27 19:27:56.085: INFO: Pod ibm-master-proxy-static-10.138.3.199 requesting resource cpu=25m on Node 10.138.3.199
Aug 27 19:27:56.085: INFO: Pod ibm-master-proxy-static-10.138.3.233 requesting resource cpu=25m on Node 10.138.3.233
Aug 27 19:27:56.085: INFO: Pod ibm-master-proxy-static-10.138.3.242 requesting resource cpu=25m on Node 10.138.3.242
Aug 27 19:27:56.085: INFO: Pod ibm-storage-watcher-79884b9494-zg264 requesting resource cpu=50m on Node 10.138.3.199
Aug 27 19:27:56.085: INFO: Pod kubernetes-dashboard-596f947ff4-qhm8x requesting resource cpu=50m on Node 10.138.3.199
Aug 27 19:27:56.085: INFO: Pod metrics-server-74c65558d9-bjxkf requesting resource cpu=53m on Node 10.138.3.233
Aug 27 19:27:56.085: INFO: Pod public-crblilkl7s0qcmd68ptvug-alb1-96757c898-jhng9 requesting resource cpu=0m on Node 10.138.3.199
Aug 27 19:27:56.085: INFO: Pod public-crblilkl7s0qcmd68ptvug-alb1-96757c898-ttk5v requesting resource cpu=0m on Node 10.138.3.233
Aug 27 19:27:56.085: INFO: Pod vpn-75d8697c68-t4p4j requesting resource cpu=5m on Node 10.138.3.242
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-0fd5fd81-bba8-4bbb-9406-abfdc6d7346e.15bede3d7e4a5fdf], Reason = [Scheduled], Message = [Successfully assigned sched-pred-9909/filler-pod-0fd5fd81-bba8-4bbb-9406-abfdc6d7346e to 10.138.3.199]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-0fd5fd81-bba8-4bbb-9406-abfdc6d7346e.15bede3dc1014a09], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-0fd5fd81-bba8-4bbb-9406-abfdc6d7346e.15bede3dc597a8cf], Reason = [Created], Message = [Created container filler-pod-0fd5fd81-bba8-4bbb-9406-abfdc6d7346e]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-0fd5fd81-bba8-4bbb-9406-abfdc6d7346e.15bede3dd454a6a1], Reason = [Started], Message = [Started container filler-pod-0fd5fd81-bba8-4bbb-9406-abfdc6d7346e]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-31da90e6-96f3-4267-8a75-4f528ec456f1.15bede3d7efdb7fe], Reason = [Scheduled], Message = [Successfully assigned sched-pred-9909/filler-pod-31da90e6-96f3-4267-8a75-4f528ec456f1 to 10.138.3.233]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-31da90e6-96f3-4267-8a75-4f528ec456f1.15bede3dc1eb483c], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-31da90e6-96f3-4267-8a75-4f528ec456f1.15bede3dc64d76be], Reason = [Created], Message = [Created container filler-pod-31da90e6-96f3-4267-8a75-4f528ec456f1]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-31da90e6-96f3-4267-8a75-4f528ec456f1.15bede3dd20b8f95], Reason = [Started], Message = [Started container filler-pod-31da90e6-96f3-4267-8a75-4f528ec456f1]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-457e02c6-a927-4355-8896-f9ef00039a5a.15bede3d7fb26384], Reason = [Scheduled], Message = [Successfully assigned sched-pred-9909/filler-pod-457e02c6-a927-4355-8896-f9ef00039a5a to 10.138.3.242]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-457e02c6-a927-4355-8896-f9ef00039a5a.15bede3dbe75b94c], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-457e02c6-a927-4355-8896-f9ef00039a5a.15bede3dc2db5c71], Reason = [Created], Message = [Created container filler-pod-457e02c6-a927-4355-8896-f9ef00039a5a]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-457e02c6-a927-4355-8896-f9ef00039a5a.15bede3dcef986a4], Reason = [Started], Message = [Started container filler-pod-457e02c6-a927-4355-8896-f9ef00039a5a]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.15bede3dfaa83177], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 Insufficient cpu.]
STEP: removing the label node off the node 10.138.3.199
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node 10.138.3.233
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node 10.138.3.242
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 19:27:59.335: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-9909" for this suite.
Aug 27 19:28:05.392: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 19:28:05.786: INFO: namespace sched-pred-9909 deletion completed in 6.437926603s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:72

• [SLOW TEST:10.219 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 19:28:05.787: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2342
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with configMap that has name projected-configmap-test-upd-8e640c08-224d-48c7-8652-558853be04e0
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-8e640c08-224d-48c7-8652-558853be04e0
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 19:28:10.146: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2342" for this suite.
Aug 27 19:28:34.203: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 19:28:34.589: INFO: namespace projected-2342 deletion completed in 24.428844604s

• [SLOW TEST:28.802 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 19:28:34.591: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-9665
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap that has name configmap-test-emptyKey-20e4417b-e9ec-4de9-8f00-fe96118ec54e
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 19:28:34.817: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9665" for this suite.
Aug 27 19:28:40.878: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 19:28:41.231: INFO: namespace configmap-9665 deletion completed in 6.401939496s

• [SLOW TEST:6.641 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 19:28:41.232: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-8791
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: starting the proxy server
Aug 27 19:28:41.455: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-540514467 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 19:28:41.579: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8791" for this suite.
Aug 27 19:28:47.637: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 19:28:48.052: INFO: namespace kubectl-8791 deletion completed in 6.459711079s

• [SLOW TEST:6.820 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Proxy server
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 19:28:48.052: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-3670
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-bf603a5c-fc8e-4325-bf39-b1b2a8c8b986
STEP: Creating a pod to test consume configMaps
Aug 27 19:28:48.305: INFO: Waiting up to 5m0s for pod "pod-configmaps-d1030f2a-39f4-4352-803e-4d8b50b9a98b" in namespace "configmap-3670" to be "success or failure"
Aug 27 19:28:48.315: INFO: Pod "pod-configmaps-d1030f2a-39f4-4352-803e-4d8b50b9a98b": Phase="Pending", Reason="", readiness=false. Elapsed: 9.542318ms
Aug 27 19:28:50.325: INFO: Pod "pod-configmaps-d1030f2a-39f4-4352-803e-4d8b50b9a98b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020409148s
STEP: Saw pod success
Aug 27 19:28:50.326: INFO: Pod "pod-configmaps-d1030f2a-39f4-4352-803e-4d8b50b9a98b" satisfied condition "success or failure"
Aug 27 19:28:50.336: INFO: Trying to get logs from node 10.138.3.242 pod pod-configmaps-d1030f2a-39f4-4352-803e-4d8b50b9a98b container configmap-volume-test: <nil>
STEP: delete the pod
Aug 27 19:28:50.380: INFO: Waiting for pod pod-configmaps-d1030f2a-39f4-4352-803e-4d8b50b9a98b to disappear
Aug 27 19:28:50.390: INFO: Pod pod-configmaps-d1030f2a-39f4-4352-803e-4d8b50b9a98b no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 19:28:50.390: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3670" for this suite.
Aug 27 19:28:56.449: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 19:28:56.840: INFO: namespace configmap-3670 deletion completed in 6.435554503s

• [SLOW TEST:8.788 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 19:28:56.841: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-3699
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Aug 27 19:28:57.166: INFO: Create a RollingUpdate DaemonSet
Aug 27 19:28:57.179: INFO: Check that daemon pods launch on every node of the cluster
Aug 27 19:28:57.202: INFO: Number of nodes with available pods: 0
Aug 27 19:28:57.202: INFO: Node 10.138.3.199 is running more than one daemon pod
Aug 27 19:28:58.229: INFO: Number of nodes with available pods: 0
Aug 27 19:28:58.229: INFO: Node 10.138.3.199 is running more than one daemon pod
Aug 27 19:28:59.230: INFO: Number of nodes with available pods: 3
Aug 27 19:28:59.230: INFO: Number of running nodes: 3, number of available pods: 3
Aug 27 19:28:59.230: INFO: Update the DaemonSet to trigger a rollout
Aug 27 19:28:59.252: INFO: Updating DaemonSet daemon-set
Aug 27 19:29:03.300: INFO: Roll back the DaemonSet before rollout is complete
Aug 27 19:29:03.322: INFO: Updating DaemonSet daemon-set
Aug 27 19:29:03.322: INFO: Make sure DaemonSet rollback is complete
Aug 27 19:29:03.339: INFO: Wrong image for pod: daemon-set-l6j9t. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Aug 27 19:29:03.339: INFO: Pod daemon-set-l6j9t is not available
Aug 27 19:29:04.362: INFO: Wrong image for pod: daemon-set-l6j9t. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Aug 27 19:29:04.362: INFO: Pod daemon-set-l6j9t is not available
Aug 27 19:29:05.364: INFO: Pod daemon-set-rr68s is not available
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-3699, will wait for the garbage collector to delete the pods
Aug 27 19:29:05.482: INFO: Deleting DaemonSet.extensions daemon-set took: 20.332868ms
Aug 27 19:29:05.582: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.301022ms
Aug 27 19:29:18.692: INFO: Number of nodes with available pods: 0
Aug 27 19:29:18.692: INFO: Number of running nodes: 0, number of available pods: 0
Aug 27 19:29:18.703: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-3699/daemonsets","resourceVersion":"36411"},"items":null}

Aug 27 19:29:18.713: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-3699/pods","resourceVersion":"36411"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 19:29:18.763: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-3699" for this suite.
Aug 27 19:29:26.837: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 19:29:27.226: INFO: namespace daemonsets-3699 deletion completed in 8.450786595s

• [SLOW TEST:30.385 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 19:29:27.227: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-7319
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Aug 27 19:29:27.449: INFO: Creating deployment "test-recreate-deployment"
Aug 27 19:29:27.461: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Aug 27 19:29:27.489: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
Aug 27 19:29:29.512: INFO: Waiting deployment "test-recreate-deployment" to complete
Aug 27 19:29:29.522: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63702530967, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63702530967, loc:(*time.Location)(0x7ec7a20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63702530967, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63702530967, loc:(*time.Location)(0x7ec7a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-6df85df6b9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 27 19:29:31.532: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Aug 27 19:29:31.553: INFO: Updating deployment test-recreate-deployment
Aug 27 19:29:31.553: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
Aug 27 19:29:31.650: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment,GenerateName:,Namespace:deployment-7319,SelfLink:/apis/apps/v1/namespaces/deployment-7319/deployments/test-recreate-deployment,UID:1a2f4680-092c-4a9e-8885-aee184bcd0b6,ResourceVersion:36521,Generation:2,CreationTimestamp:2019-08-27 19:29:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[{Available False 2019-08-27 19:29:31 +0000 UTC 2019-08-27 19:29:31 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-08-27 19:29:31 +0000 UTC 2019-08-27 19:29:27 +0000 UTC ReplicaSetUpdated ReplicaSet "test-recreate-deployment-5c8c9cc69d" is progressing.}],ReadyReplicas:0,CollisionCount:nil,},}

Aug 27 19:29:31.663: INFO: New ReplicaSet "test-recreate-deployment-5c8c9cc69d" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-5c8c9cc69d,GenerateName:,Namespace:deployment-7319,SelfLink:/apis/apps/v1/namespaces/deployment-7319/replicasets/test-recreate-deployment-5c8c9cc69d,UID:d152616d-e381-45f2-a234-9a51a57e7b28,ResourceVersion:36518,Generation:1,CreationTimestamp:2019-08-27 19:29:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5c8c9cc69d,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 1a2f4680-092c-4a9e-8885-aee184bcd0b6 0xc001e53fe7 0xc001e53fe8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 5c8c9cc69d,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5c8c9cc69d,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Aug 27 19:29:31.663: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Aug 27 19:29:31.663: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-6df85df6b9,GenerateName:,Namespace:deployment-7319,SelfLink:/apis/apps/v1/namespaces/deployment-7319/replicasets/test-recreate-deployment-6df85df6b9,UID:584d99fa-72d2-4822-8598-90abe96b2ea1,ResourceVersion:36510,Generation:2,CreationTimestamp:2019-08-27 19:29:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 6df85df6b9,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 1a2f4680-092c-4a9e-8885-aee184bcd0b6 0xc00385c0b7 0xc00385c0b8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 6df85df6b9,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 6df85df6b9,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Aug 27 19:29:31.674: INFO: Pod "test-recreate-deployment-5c8c9cc69d-sgnsh" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-5c8c9cc69d-sgnsh,GenerateName:test-recreate-deployment-5c8c9cc69d-,Namespace:deployment-7319,SelfLink:/api/v1/namespaces/deployment-7319/pods/test-recreate-deployment-5c8c9cc69d-sgnsh,UID:cce33772-06c8-4c01-a93f-298fc6f39c0a,ResourceVersion:36522,Generation:0,CreationTimestamp:2019-08-27 19:29:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5c8c9cc69d,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-recreate-deployment-5c8c9cc69d d152616d-e381-45f2-a234-9a51a57e7b28 0xc00385c9a7 0xc00385c9a8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-9r78l {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9r78l,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-9r78l true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.138.3.242,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00385ca30} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00385ca50}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:29:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:29:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:29:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:29:31 +0000 UTC  }],Message:,Reason:,HostIP:10.138.3.242,PodIP:,StartTime:2019-08-27 19:29:31 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 19:29:31.674: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-7319" for this suite.
Aug 27 19:29:37.733: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 19:29:38.130: INFO: namespace deployment-7319 deletion completed in 6.440110336s

• [SLOW TEST:10.903 seconds]
[sig-apps] Deployment
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 19:29:38.133: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-9633
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-13f10e9a-69c3-42a7-aa98-63a974607c5e
STEP: Creating a pod to test consume secrets
Aug 27 19:29:38.385: INFO: Waiting up to 5m0s for pod "pod-secrets-f84ce9ed-efa0-47e1-9791-d6e1fb0aba7a" in namespace "secrets-9633" to be "success or failure"
Aug 27 19:29:38.396: INFO: Pod "pod-secrets-f84ce9ed-efa0-47e1-9791-d6e1fb0aba7a": Phase="Pending", Reason="", readiness=false. Elapsed: 10.439298ms
Aug 27 19:29:40.407: INFO: Pod "pod-secrets-f84ce9ed-efa0-47e1-9791-d6e1fb0aba7a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021157188s
Aug 27 19:29:42.417: INFO: Pod "pod-secrets-f84ce9ed-efa0-47e1-9791-d6e1fb0aba7a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.031873946s
STEP: Saw pod success
Aug 27 19:29:42.417: INFO: Pod "pod-secrets-f84ce9ed-efa0-47e1-9791-d6e1fb0aba7a" satisfied condition "success or failure"
Aug 27 19:29:42.427: INFO: Trying to get logs from node 10.138.3.233 pod pod-secrets-f84ce9ed-efa0-47e1-9791-d6e1fb0aba7a container secret-env-test: <nil>
STEP: delete the pod
Aug 27 19:29:42.477: INFO: Waiting for pod pod-secrets-f84ce9ed-efa0-47e1-9791-d6e1fb0aba7a to disappear
Aug 27 19:29:42.488: INFO: Pod pod-secrets-f84ce9ed-efa0-47e1-9791-d6e1fb0aba7a no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 19:29:42.488: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9633" for this suite.
Aug 27 19:29:48.553: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 19:29:49.176: INFO: namespace secrets-9633 deletion completed in 6.667219915s

• [SLOW TEST:11.043 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 19:29:49.179: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-6899
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Aug 27 19:29:51.457: INFO: Expected: &{} to match Container's Termination Message:  --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 19:29:51.495: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-6899" for this suite.
Aug 27 19:29:57.553: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 19:29:57.927: INFO: namespace container-runtime-6899 deletion completed in 6.416980126s

• [SLOW TEST:8.748 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  blackbox test
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
    on terminated container
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:129
      should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 19:29:57.928: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-9620
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl label
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1211
STEP: creating the pod
Aug 27 19:29:58.147: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-540514467 create -f - --namespace=kubectl-9620'
Aug 27 19:29:58.476: INFO: stderr: ""
Aug 27 19:29:58.476: INFO: stdout: "pod/pause created\n"
Aug 27 19:29:58.476: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Aug 27 19:29:58.476: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-9620" to be "running and ready"
Aug 27 19:29:58.487: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 10.502471ms
Aug 27 19:30:00.498: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021597319s
Aug 27 19:30:02.508: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 4.031505338s
Aug 27 19:30:02.508: INFO: Pod "pause" satisfied condition "running and ready"
Aug 27 19:30:02.508: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: adding the label testing-label with value testing-label-value to a pod
Aug 27 19:30:02.508: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-540514467 label pods pause testing-label=testing-label-value --namespace=kubectl-9620'
Aug 27 19:30:02.642: INFO: stderr: ""
Aug 27 19:30:02.642: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Aug 27 19:30:02.642: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-540514467 get pod pause -L testing-label --namespace=kubectl-9620'
Aug 27 19:30:02.776: INFO: stderr: ""
Aug 27 19:30:02.776: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          4s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Aug 27 19:30:02.776: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-540514467 label pods pause testing-label- --namespace=kubectl-9620'
Aug 27 19:30:02.920: INFO: stderr: ""
Aug 27 19:30:02.920: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Aug 27 19:30:02.920: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-540514467 get pod pause -L testing-label --namespace=kubectl-9620'
Aug 27 19:30:03.041: INFO: stderr: ""
Aug 27 19:30:03.041: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          5s    \n"
[AfterEach] [k8s.io] Kubectl label
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1218
STEP: using delete to clean up resources
Aug 27 19:30:03.041: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-540514467 delete --grace-period=0 --force -f - --namespace=kubectl-9620'
Aug 27 19:30:03.188: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 27 19:30:03.188: INFO: stdout: "pod \"pause\" force deleted\n"
Aug 27 19:30:03.188: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-540514467 get rc,svc -l name=pause --no-headers --namespace=kubectl-9620'
Aug 27 19:30:03.331: INFO: stderr: "No resources found.\n"
Aug 27 19:30:03.331: INFO: stdout: ""
Aug 27 19:30:03.332: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-540514467 get pods -l name=pause --namespace=kubectl-9620 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Aug 27 19:30:03.505: INFO: stderr: ""
Aug 27 19:30:03.505: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 19:30:03.505: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9620" for this suite.
Aug 27 19:30:09.569: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 19:30:09.974: INFO: namespace kubectl-9620 deletion completed in 6.451461107s

• [SLOW TEST:12.046 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl label
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 19:30:09.974: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-7116
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-map-27479dbd-71b9-4515-90af-42180191d959
STEP: Creating a pod to test consume configMaps
Aug 27 19:30:10.236: INFO: Waiting up to 5m0s for pod "pod-configmaps-ebc4354e-543a-4679-bb72-607e7342cb9e" in namespace "configmap-7116" to be "success or failure"
Aug 27 19:30:10.246: INFO: Pod "pod-configmaps-ebc4354e-543a-4679-bb72-607e7342cb9e": Phase="Pending", Reason="", readiness=false. Elapsed: 10.738654ms
Aug 27 19:30:12.257: INFO: Pod "pod-configmaps-ebc4354e-543a-4679-bb72-607e7342cb9e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021035264s
Aug 27 19:30:14.267: INFO: Pod "pod-configmaps-ebc4354e-543a-4679-bb72-607e7342cb9e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.031648548s
STEP: Saw pod success
Aug 27 19:30:14.267: INFO: Pod "pod-configmaps-ebc4354e-543a-4679-bb72-607e7342cb9e" satisfied condition "success or failure"
Aug 27 19:30:14.277: INFO: Trying to get logs from node 10.138.3.242 pod pod-configmaps-ebc4354e-543a-4679-bb72-607e7342cb9e container configmap-volume-test: <nil>
STEP: delete the pod
Aug 27 19:30:14.322: INFO: Waiting for pod pod-configmaps-ebc4354e-543a-4679-bb72-607e7342cb9e to disappear
Aug 27 19:30:14.332: INFO: Pod pod-configmaps-ebc4354e-543a-4679-bb72-607e7342cb9e no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 19:30:14.332: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7116" for this suite.
Aug 27 19:30:20.392: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 19:30:20.757: INFO: namespace configmap-7116 deletion completed in 6.407559918s

• [SLOW TEST:10.782 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 19:30:20.757: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-9646
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 pods, got 2 pods
STEP: expected 0 rs, got 1 rs
STEP: Gathering metrics
Aug 27 19:30:21.602: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 19:30:21.602: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
W0827 19:30:21.602825      16 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
STEP: Destroying namespace "gc-9646" for this suite.
Aug 27 19:30:27.659: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 19:30:28.023: INFO: namespace gc-9646 deletion completed in 6.406996932s

• [SLOW TEST:7.266 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 19:30:28.023: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-3324
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Aug 27 19:30:28.291: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ed0104d8-cc19-456e-b9f3-a6c1b09691b1" in namespace "downward-api-3324" to be "success or failure"
Aug 27 19:30:28.301: INFO: Pod "downwardapi-volume-ed0104d8-cc19-456e-b9f3-a6c1b09691b1": Phase="Pending", Reason="", readiness=false. Elapsed: 9.846792ms
Aug 27 19:30:30.311: INFO: Pod "downwardapi-volume-ed0104d8-cc19-456e-b9f3-a6c1b09691b1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020298025s
STEP: Saw pod success
Aug 27 19:30:30.311: INFO: Pod "downwardapi-volume-ed0104d8-cc19-456e-b9f3-a6c1b09691b1" satisfied condition "success or failure"
Aug 27 19:30:30.321: INFO: Trying to get logs from node 10.138.3.233 pod downwardapi-volume-ed0104d8-cc19-456e-b9f3-a6c1b09691b1 container client-container: <nil>
STEP: delete the pod
Aug 27 19:30:30.371: INFO: Waiting for pod downwardapi-volume-ed0104d8-cc19-456e-b9f3-a6c1b09691b1 to disappear
Aug 27 19:30:30.383: INFO: Pod downwardapi-volume-ed0104d8-cc19-456e-b9f3-a6c1b09691b1 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 19:30:30.383: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3324" for this suite.
Aug 27 19:30:36.444: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 19:30:36.842: INFO: namespace downward-api-3324 deletion completed in 6.442247764s

• [SLOW TEST:8.819 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 19:30:36.844: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-2945
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating service multi-endpoint-test in namespace services-2945
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-2945 to expose endpoints map[]
Aug 27 19:30:37.096: INFO: successfully validated that service multi-endpoint-test in namespace services-2945 exposes endpoints map[] (9.541407ms elapsed)
STEP: Creating pod pod1 in namespace services-2945
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-2945 to expose endpoints map[pod1:[100]]
Aug 27 19:30:39.173: INFO: successfully validated that service multi-endpoint-test in namespace services-2945 exposes endpoints map[pod1:[100]] (2.058772568s elapsed)
STEP: Creating pod pod2 in namespace services-2945
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-2945 to expose endpoints map[pod1:[100] pod2:[101]]
Aug 27 19:30:42.311: INFO: successfully validated that service multi-endpoint-test in namespace services-2945 exposes endpoints map[pod1:[100] pod2:[101]] (3.125746278s elapsed)
STEP: Deleting pod pod1 in namespace services-2945
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-2945 to expose endpoints map[pod2:[101]]
Aug 27 19:30:42.346: INFO: successfully validated that service multi-endpoint-test in namespace services-2945 exposes endpoints map[pod2:[101]] (20.70688ms elapsed)
STEP: Deleting pod pod2 in namespace services-2945
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-2945 to expose endpoints map[]
Aug 27 19:30:42.374: INFO: successfully validated that service multi-endpoint-test in namespace services-2945 exposes endpoints map[] (13.170718ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 19:30:42.424: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-2945" for this suite.
Aug 27 19:31:06.486: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 19:31:06.921: INFO: namespace services-2945 deletion completed in 24.481817954s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:92

• [SLOW TEST:30.078 seconds]
[sig-network] Services
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 19:31:06.923: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-7240
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 19:31:12.233: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-7240" for this suite.
Aug 27 19:31:36.295: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 19:31:36.692: INFO: namespace replication-controller-7240 deletion completed in 24.441466347s

• [SLOW TEST:29.769 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 19:31:36.692: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2980
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Aug 27 19:31:36.927: INFO: Waiting up to 5m0s for pod "downwardapi-volume-7905ec86-7306-4d59-aa52-bca7b2730c4c" in namespace "projected-2980" to be "success or failure"
Aug 27 19:31:36.938: INFO: Pod "downwardapi-volume-7905ec86-7306-4d59-aa52-bca7b2730c4c": Phase="Pending", Reason="", readiness=false. Elapsed: 11.354641ms
Aug 27 19:31:38.949: INFO: Pod "downwardapi-volume-7905ec86-7306-4d59-aa52-bca7b2730c4c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021841556s
Aug 27 19:31:40.960: INFO: Pod "downwardapi-volume-7905ec86-7306-4d59-aa52-bca7b2730c4c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.032803382s
STEP: Saw pod success
Aug 27 19:31:40.960: INFO: Pod "downwardapi-volume-7905ec86-7306-4d59-aa52-bca7b2730c4c" satisfied condition "success or failure"
Aug 27 19:31:40.970: INFO: Trying to get logs from node 10.138.3.233 pod downwardapi-volume-7905ec86-7306-4d59-aa52-bca7b2730c4c container client-container: <nil>
STEP: delete the pod
Aug 27 19:31:41.015: INFO: Waiting for pod downwardapi-volume-7905ec86-7306-4d59-aa52-bca7b2730c4c to disappear
Aug 27 19:31:41.025: INFO: Pod downwardapi-volume-7905ec86-7306-4d59-aa52-bca7b2730c4c no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 19:31:41.025: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2980" for this suite.
Aug 27 19:31:47.086: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 19:31:47.496: INFO: namespace projected-2980 deletion completed in 6.453439766s

• [SLOW TEST:10.803 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 19:31:47.496: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5215
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Aug 27 19:31:47.732: INFO: Waiting up to 5m0s for pod "downwardapi-volume-30c8158b-2b44-4790-bb8b-34563debc25f" in namespace "projected-5215" to be "success or failure"
Aug 27 19:31:47.742: INFO: Pod "downwardapi-volume-30c8158b-2b44-4790-bb8b-34563debc25f": Phase="Pending", Reason="", readiness=false. Elapsed: 9.974517ms
Aug 27 19:31:49.752: INFO: Pod "downwardapi-volume-30c8158b-2b44-4790-bb8b-34563debc25f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020556217s
STEP: Saw pod success
Aug 27 19:31:49.752: INFO: Pod "downwardapi-volume-30c8158b-2b44-4790-bb8b-34563debc25f" satisfied condition "success or failure"
Aug 27 19:31:49.762: INFO: Trying to get logs from node 10.138.3.242 pod downwardapi-volume-30c8158b-2b44-4790-bb8b-34563debc25f container client-container: <nil>
STEP: delete the pod
Aug 27 19:31:49.817: INFO: Waiting for pod downwardapi-volume-30c8158b-2b44-4790-bb8b-34563debc25f to disappear
Aug 27 19:31:49.827: INFO: Pod downwardapi-volume-30c8158b-2b44-4790-bb8b-34563debc25f no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 19:31:49.827: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5215" for this suite.
Aug 27 19:31:55.890: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 19:31:56.247: INFO: namespace projected-5215 deletion completed in 6.403591454s

• [SLOW TEST:8.751 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 19:31:56.247: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3980
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-map-fa61be5b-2ffb-4b57-acee-906adafdb03a
STEP: Creating a pod to test consume secrets
Aug 27 19:31:56.524: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-207db2d6-e2ca-4091-8ba0-cae899d25084" in namespace "projected-3980" to be "success or failure"
Aug 27 19:31:56.535: INFO: Pod "pod-projected-secrets-207db2d6-e2ca-4091-8ba0-cae899d25084": Phase="Pending", Reason="", readiness=false. Elapsed: 10.840972ms
Aug 27 19:31:58.545: INFO: Pod "pod-projected-secrets-207db2d6-e2ca-4091-8ba0-cae899d25084": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021076799s
STEP: Saw pod success
Aug 27 19:31:58.546: INFO: Pod "pod-projected-secrets-207db2d6-e2ca-4091-8ba0-cae899d25084" satisfied condition "success or failure"
Aug 27 19:31:58.555: INFO: Trying to get logs from node 10.138.3.233 pod pod-projected-secrets-207db2d6-e2ca-4091-8ba0-cae899d25084 container projected-secret-volume-test: <nil>
STEP: delete the pod
Aug 27 19:31:58.601: INFO: Waiting for pod pod-projected-secrets-207db2d6-e2ca-4091-8ba0-cae899d25084 to disappear
Aug 27 19:31:58.612: INFO: Pod pod-projected-secrets-207db2d6-e2ca-4091-8ba0-cae899d25084 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 19:31:58.612: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3980" for this suite.
Aug 27 19:32:04.673: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 19:32:05.121: INFO: namespace projected-3980 deletion completed in 6.491582479s

• [SLOW TEST:8.874 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 19:32:05.122: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-2587
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-2587
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating stateful set ss in namespace statefulset-2587
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-2587
Aug 27 19:32:05.392: INFO: Found 0 stateful pods, waiting for 1
Aug 27 19:32:15.404: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Aug 27 19:32:15.414: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-540514467 exec --namespace=statefulset-2587 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Aug 27 19:32:15.957: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Aug 27 19:32:15.957: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Aug 27 19:32:15.957: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Aug 27 19:32:15.967: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Aug 27 19:32:25.982: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Aug 27 19:32:25.982: INFO: Waiting for statefulset status.replicas updated to 0
Aug 27 19:32:26.021: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
Aug 27 19:32:26.022: INFO: ss-0  10.138.3.242  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:32:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:32:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:32:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:32:05 +0000 UTC  }]
Aug 27 19:32:26.022: INFO: ss-1                Pending         []
Aug 27 19:32:26.022: INFO: 
Aug 27 19:32:26.022: INFO: StatefulSet ss has not reached scale 3, at 2
Aug 27 19:32:27.034: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.990059947s
Aug 27 19:32:28.046: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.97775271s
Aug 27 19:32:29.058: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.96516435s
Aug 27 19:32:30.070: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.953271103s
Aug 27 19:32:31.081: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.941822691s
Aug 27 19:32:32.093: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.930173323s
Aug 27 19:32:33.104: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.918823725s
Aug 27 19:32:34.115: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.907486205s
Aug 27 19:32:35.127: INFO: Verifying statefulset ss doesn't scale past 3 for another 896.160794ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-2587
Aug 27 19:32:36.139: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-540514467 exec --namespace=statefulset-2587 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 27 19:32:36.616: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Aug 27 19:32:36.616: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Aug 27 19:32:36.616: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Aug 27 19:32:36.616: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-540514467 exec --namespace=statefulset-2587 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 27 19:32:37.040: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Aug 27 19:32:37.040: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Aug 27 19:32:37.040: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Aug 27 19:32:37.040: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-540514467 exec --namespace=statefulset-2587 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 27 19:32:37.470: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Aug 27 19:32:37.470: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Aug 27 19:32:37.470: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Aug 27 19:32:37.480: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Aug 27 19:32:37.480: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Aug 27 19:32:37.480: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Aug 27 19:32:37.491: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-540514467 exec --namespace=statefulset-2587 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Aug 27 19:32:37.961: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Aug 27 19:32:37.961: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Aug 27 19:32:37.961: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Aug 27 19:32:37.961: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-540514467 exec --namespace=statefulset-2587 ss-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Aug 27 19:32:38.428: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Aug 27 19:32:38.428: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Aug 27 19:32:38.428: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Aug 27 19:32:38.428: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-540514467 exec --namespace=statefulset-2587 ss-2 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Aug 27 19:32:38.869: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Aug 27 19:32:38.869: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Aug 27 19:32:38.869: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Aug 27 19:32:38.869: INFO: Waiting for statefulset status.replicas updated to 0
Aug 27 19:32:38.879: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Aug 27 19:32:48.900: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Aug 27 19:32:48.900: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Aug 27 19:32:48.900: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Aug 27 19:32:48.930: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
Aug 27 19:32:48.930: INFO: ss-0  10.138.3.242  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:32:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:32:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:32:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:32:05 +0000 UTC  }]
Aug 27 19:32:48.930: INFO: ss-1  10.138.3.233  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:32:26 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:32:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:32:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:32:25 +0000 UTC  }]
Aug 27 19:32:48.930: INFO: ss-2  10.138.3.199  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:32:26 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:32:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:32:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:32:25 +0000 UTC  }]
Aug 27 19:32:48.930: INFO: 
Aug 27 19:32:48.930: INFO: StatefulSet ss has not reached scale 0, at 3
Aug 27 19:32:49.941: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
Aug 27 19:32:49.941: INFO: ss-0  10.138.3.242  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:32:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:32:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:32:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:32:05 +0000 UTC  }]
Aug 27 19:32:49.942: INFO: ss-1  10.138.3.233  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:32:26 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:32:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:32:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:32:25 +0000 UTC  }]
Aug 27 19:32:49.942: INFO: ss-2  10.138.3.199  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:32:26 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:32:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:32:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:32:25 +0000 UTC  }]
Aug 27 19:32:49.942: INFO: 
Aug 27 19:32:49.942: INFO: StatefulSet ss has not reached scale 0, at 3
Aug 27 19:32:50.953: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
Aug 27 19:32:50.953: INFO: ss-0  10.138.3.242  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:32:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:32:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:32:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:32:05 +0000 UTC  }]
Aug 27 19:32:50.953: INFO: ss-1  10.138.3.233  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:32:26 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:32:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:32:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:32:25 +0000 UTC  }]
Aug 27 19:32:50.953: INFO: ss-2  10.138.3.199  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:32:26 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:32:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:32:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:32:25 +0000 UTC  }]
Aug 27 19:32:50.953: INFO: 
Aug 27 19:32:50.953: INFO: StatefulSet ss has not reached scale 0, at 3
Aug 27 19:32:51.964: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
Aug 27 19:32:51.964: INFO: ss-0  10.138.3.242  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:32:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:32:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:32:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:32:05 +0000 UTC  }]
Aug 27 19:32:51.964: INFO: ss-1  10.138.3.233  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:32:26 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:32:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:32:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:32:25 +0000 UTC  }]
Aug 27 19:32:51.964: INFO: 
Aug 27 19:32:51.964: INFO: StatefulSet ss has not reached scale 0, at 2
Aug 27 19:32:52.975: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
Aug 27 19:32:52.975: INFO: ss-0  10.138.3.242  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:32:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:32:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:32:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:32:05 +0000 UTC  }]
Aug 27 19:32:52.975: INFO: ss-1  10.138.3.233  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:32:26 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:32:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:32:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:32:25 +0000 UTC  }]
Aug 27 19:32:52.975: INFO: 
Aug 27 19:32:52.975: INFO: StatefulSet ss has not reached scale 0, at 2
Aug 27 19:32:53.985: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
Aug 27 19:32:53.986: INFO: ss-1  10.138.3.233  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:32:26 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:32:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:32:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:32:25 +0000 UTC  }]
Aug 27 19:32:53.986: INFO: 
Aug 27 19:32:53.986: INFO: StatefulSet ss has not reached scale 0, at 1
Aug 27 19:32:54.996: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
Aug 27 19:32:54.996: INFO: ss-1  10.138.3.233  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:32:26 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:32:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:32:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:32:25 +0000 UTC  }]
Aug 27 19:32:54.996: INFO: 
Aug 27 19:32:54.996: INFO: StatefulSet ss has not reached scale 0, at 1
Aug 27 19:32:56.007: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
Aug 27 19:32:56.007: INFO: ss-1  10.138.3.233  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:32:26 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:32:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:32:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:32:25 +0000 UTC  }]
Aug 27 19:32:56.007: INFO: 
Aug 27 19:32:56.007: INFO: StatefulSet ss has not reached scale 0, at 1
Aug 27 19:32:57.019: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
Aug 27 19:32:57.019: INFO: ss-1  10.138.3.233  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:32:26 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:32:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:32:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:32:25 +0000 UTC  }]
Aug 27 19:32:57.019: INFO: 
Aug 27 19:32:57.020: INFO: StatefulSet ss has not reached scale 0, at 1
Aug 27 19:32:58.031: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
Aug 27 19:32:58.031: INFO: ss-1  10.138.3.233  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:32:26 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:32:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:32:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:32:25 +0000 UTC  }]
Aug 27 19:32:58.031: INFO: 
Aug 27 19:32:58.031: INFO: StatefulSet ss has not reached scale 0, at 1
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-2587
Aug 27 19:32:59.042: INFO: Scaling statefulset ss to 0
Aug 27 19:32:59.071: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Aug 27 19:32:59.080: INFO: Deleting all statefulset in ns statefulset-2587
Aug 27 19:32:59.090: INFO: Scaling statefulset ss to 0
Aug 27 19:32:59.119: INFO: Waiting for statefulset status.replicas updated to 0
Aug 27 19:32:59.128: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 19:32:59.172: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-2587" for this suite.
Aug 27 19:33:07.235: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 19:33:07.598: INFO: namespace statefulset-2587 deletion completed in 8.410865101s

• [SLOW TEST:62.477 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 19:33:07.598: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-7958
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Aug 27 19:33:07.840: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b9b74980-c6f6-4ea8-a38e-db15f7a53229" in namespace "downward-api-7958" to be "success or failure"
Aug 27 19:33:07.852: INFO: Pod "downwardapi-volume-b9b74980-c6f6-4ea8-a38e-db15f7a53229": Phase="Pending", Reason="", readiness=false. Elapsed: 11.304058ms
Aug 27 19:33:09.869: INFO: Pod "downwardapi-volume-b9b74980-c6f6-4ea8-a38e-db15f7a53229": Phase="Running", Reason="", readiness=true. Elapsed: 2.028489625s
Aug 27 19:33:11.879: INFO: Pod "downwardapi-volume-b9b74980-c6f6-4ea8-a38e-db15f7a53229": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.03894064s
STEP: Saw pod success
Aug 27 19:33:11.879: INFO: Pod "downwardapi-volume-b9b74980-c6f6-4ea8-a38e-db15f7a53229" satisfied condition "success or failure"
Aug 27 19:33:11.889: INFO: Trying to get logs from node 10.138.3.233 pod downwardapi-volume-b9b74980-c6f6-4ea8-a38e-db15f7a53229 container client-container: <nil>
STEP: delete the pod
Aug 27 19:33:11.934: INFO: Waiting for pod downwardapi-volume-b9b74980-c6f6-4ea8-a38e-db15f7a53229 to disappear
Aug 27 19:33:11.943: INFO: Pod downwardapi-volume-b9b74980-c6f6-4ea8-a38e-db15f7a53229 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 19:33:11.943: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7958" for this suite.
Aug 27 19:33:18.003: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 19:33:18.380: INFO: namespace downward-api-7958 deletion completed in 6.419790097s

• [SLOW TEST:10.781 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 19:33:18.381: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-7669
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Aug 27 19:33:18.598: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Aug 27 19:33:18.623: INFO: Pod name sample-pod: Found 0 pods out of 1
Aug 27 19:33:23.634: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Aug 27 19:33:23.634: INFO: Creating deployment "test-rolling-update-deployment"
Aug 27 19:33:23.645: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Aug 27 19:33:23.666: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Aug 27 19:33:25.689: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Aug 27 19:33:25.699: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
Aug 27 19:33:25.742: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment,GenerateName:,Namespace:deployment-7669,SelfLink:/apis/apps/v1/namespaces/deployment-7669/deployments/test-rolling-update-deployment,UID:044d4ea0-aeab-4963-a51b-7a058415f6c0,ResourceVersion:37720,Generation:1,CreationTimestamp:2019-08-27 19:33:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-08-27 19:33:23 +0000 UTC 2019-08-27 19:33:23 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-08-27 19:33:25 +0000 UTC 2019-08-27 19:33:23 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rolling-update-deployment-79f6b9d75c" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Aug 27 19:33:25.754: INFO: New ReplicaSet "test-rolling-update-deployment-79f6b9d75c" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-79f6b9d75c,GenerateName:,Namespace:deployment-7669,SelfLink:/apis/apps/v1/namespaces/deployment-7669/replicasets/test-rolling-update-deployment-79f6b9d75c,UID:e09d6e92-f289-43c2-8979-d685a1313764,ResourceVersion:37709,Generation:1,CreationTimestamp:2019-08-27 19:33:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 79f6b9d75c,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 044d4ea0-aeab-4963-a51b-7a058415f6c0 0xc0021c3a67 0xc0021c3a68}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 79f6b9d75c,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 79f6b9d75c,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Aug 27 19:33:25.754: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Aug 27 19:33:25.754: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-controller,GenerateName:,Namespace:deployment-7669,SelfLink:/apis/apps/v1/namespaces/deployment-7669/replicasets/test-rolling-update-controller,UID:7640da7f-57b8-46e7-afa9-d010f9df72af,ResourceVersion:37718,Generation:2,CreationTimestamp:2019-08-27 19:33:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305832,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 044d4ea0-aeab-4963-a51b-7a058415f6c0 0xc0021c3987 0xc0021c3988}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Aug 27 19:33:25.764: INFO: Pod "test-rolling-update-deployment-79f6b9d75c-mknmz" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-79f6b9d75c-mknmz,GenerateName:test-rolling-update-deployment-79f6b9d75c-,Namespace:deployment-7669,SelfLink:/api/v1/namespaces/deployment-7669/pods/test-rolling-update-deployment-79f6b9d75c-mknmz,UID:beaf7c95-cbcb-47c3-8ca2-aa8d15078689,ResourceVersion:37708,Generation:0,CreationTimestamp:2019-08-27 19:33:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 79f6b9d75c,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-rolling-update-deployment-79f6b9d75c e09d6e92-f289-43c2-8979-d685a1313764 0xc002630357 0xc002630358}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-bf7z2 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-bf7z2,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-bf7z2 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.138.3.233,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0026303d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0026303f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:33:23 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:33:25 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:33:25 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:33:23 +0000 UTC  }],Message:,Reason:,HostIP:10.138.3.233,PodIP:172.30.37.216,StartTime:2019-08-27 19:33:23 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-08-27 19:33:25 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 containerd://8a454a14700b24f702b8b543184eb2cd7e1fd65ec38e9dd207c9d6071f7f88b9}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 19:33:25.764: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-7669" for this suite.
Aug 27 19:33:31.829: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 19:33:32.252: INFO: namespace deployment-7669 deletion completed in 6.472942157s

• [SLOW TEST:13.872 seconds]
[sig-apps] Deployment
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 19:33:32.253: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-7399
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap configmap-7399/configmap-test-a80ff0e5-a71c-4cfa-8921-40e8e5088d74
STEP: Creating a pod to test consume configMaps
Aug 27 19:33:32.496: INFO: Waiting up to 5m0s for pod "pod-configmaps-f43abc34-112d-4e3e-b5c5-3619cbf75d39" in namespace "configmap-7399" to be "success or failure"
Aug 27 19:33:32.505: INFO: Pod "pod-configmaps-f43abc34-112d-4e3e-b5c5-3619cbf75d39": Phase="Pending", Reason="", readiness=false. Elapsed: 8.89259ms
Aug 27 19:33:34.516: INFO: Pod "pod-configmaps-f43abc34-112d-4e3e-b5c5-3619cbf75d39": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019267442s
Aug 27 19:33:36.527: INFO: Pod "pod-configmaps-f43abc34-112d-4e3e-b5c5-3619cbf75d39": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.029997879s
STEP: Saw pod success
Aug 27 19:33:36.527: INFO: Pod "pod-configmaps-f43abc34-112d-4e3e-b5c5-3619cbf75d39" satisfied condition "success or failure"
Aug 27 19:33:36.537: INFO: Trying to get logs from node 10.138.3.242 pod pod-configmaps-f43abc34-112d-4e3e-b5c5-3619cbf75d39 container env-test: <nil>
STEP: delete the pod
Aug 27 19:33:36.586: INFO: Waiting for pod pod-configmaps-f43abc34-112d-4e3e-b5c5-3619cbf75d39 to disappear
Aug 27 19:33:36.595: INFO: Pod pod-configmaps-f43abc34-112d-4e3e-b5c5-3619cbf75d39 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 19:33:36.595: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7399" for this suite.
Aug 27 19:33:42.658: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 19:33:43.028: INFO: namespace configmap-7399 deletion completed in 6.416403888s

• [SLOW TEST:10.775 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 19:33:43.030: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-4095
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a test externalName service
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-4095.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-4095.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-4095.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-4095.svc.cluster.local; sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Aug 27 19:33:45.341: INFO: DNS probes using dns-test-b2494eb4-3c1a-4c02-ac17-6214663f37c4 succeeded

STEP: deleting the pod
STEP: changing the externalName to bar.example.com
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-4095.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-4095.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-4095.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-4095.svc.cluster.local; sleep 1; done

STEP: creating a second pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Aug 27 19:34:03.491: INFO: File wheezy_udp@dns-test-service-3.dns-4095.svc.cluster.local from pod  dns-4095/dns-test-2db20ad2-d474-410f-88c9-f16b8a33ba24 contains 'foo.example.com.
' instead of 'bar.example.com.'
Aug 27 19:34:03.504: INFO: File jessie_udp@dns-test-service-3.dns-4095.svc.cluster.local from pod  dns-4095/dns-test-2db20ad2-d474-410f-88c9-f16b8a33ba24 contains 'foo.example.com.
' instead of 'bar.example.com.'
Aug 27 19:34:03.504: INFO: Lookups using dns-4095/dns-test-2db20ad2-d474-410f-88c9-f16b8a33ba24 failed for: [wheezy_udp@dns-test-service-3.dns-4095.svc.cluster.local jessie_udp@dns-test-service-3.dns-4095.svc.cluster.local]

Aug 27 19:34:08.518: INFO: File wheezy_udp@dns-test-service-3.dns-4095.svc.cluster.local from pod  dns-4095/dns-test-2db20ad2-d474-410f-88c9-f16b8a33ba24 contains 'foo.example.com.
' instead of 'bar.example.com.'
Aug 27 19:34:08.531: INFO: File jessie_udp@dns-test-service-3.dns-4095.svc.cluster.local from pod  dns-4095/dns-test-2db20ad2-d474-410f-88c9-f16b8a33ba24 contains 'foo.example.com.
' instead of 'bar.example.com.'
Aug 27 19:34:08.531: INFO: Lookups using dns-4095/dns-test-2db20ad2-d474-410f-88c9-f16b8a33ba24 failed for: [wheezy_udp@dns-test-service-3.dns-4095.svc.cluster.local jessie_udp@dns-test-service-3.dns-4095.svc.cluster.local]

Aug 27 19:34:13.518: INFO: File wheezy_udp@dns-test-service-3.dns-4095.svc.cluster.local from pod  dns-4095/dns-test-2db20ad2-d474-410f-88c9-f16b8a33ba24 contains 'foo.example.com.
' instead of 'bar.example.com.'
Aug 27 19:34:13.531: INFO: File jessie_udp@dns-test-service-3.dns-4095.svc.cluster.local from pod  dns-4095/dns-test-2db20ad2-d474-410f-88c9-f16b8a33ba24 contains 'foo.example.com.
' instead of 'bar.example.com.'
Aug 27 19:34:13.531: INFO: Lookups using dns-4095/dns-test-2db20ad2-d474-410f-88c9-f16b8a33ba24 failed for: [wheezy_udp@dns-test-service-3.dns-4095.svc.cluster.local jessie_udp@dns-test-service-3.dns-4095.svc.cluster.local]

Aug 27 19:34:18.531: INFO: DNS probes using dns-test-2db20ad2-d474-410f-88c9-f16b8a33ba24 succeeded

STEP: deleting the pod
STEP: changing the service to type=ClusterIP
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-4095.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-4095.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-4095.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-4095.svc.cluster.local; sleep 1; done

STEP: creating a third pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Aug 27 19:34:22.711: INFO: DNS probes using dns-test-567c7a8a-8f5a-42b6-9cec-ebfcfaef2743 succeeded

STEP: deleting the pod
STEP: deleting the test externalName service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 19:34:22.777: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-4095" for this suite.
Aug 27 19:34:30.836: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 19:34:31.236: INFO: namespace dns-4095 deletion completed in 8.442160644s

• [SLOW TEST:48.206 seconds]
[sig-network] DNS
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 19:34:31.236: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-8662
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
Aug 27 19:34:31.455: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 19:34:35.903: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-8662" for this suite.
Aug 27 19:34:41.965: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 19:34:42.341: INFO: namespace init-container-8662 deletion completed in 6.4226929s

• [SLOW TEST:11.106 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 19:34:42.342: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-2679
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Aug 27 19:34:42.586: INFO: Waiting up to 5m0s for pod "downwardapi-volume-54b8aa3c-b2fc-46ef-8be2-cd006b386e7a" in namespace "downward-api-2679" to be "success or failure"
Aug 27 19:34:42.595: INFO: Pod "downwardapi-volume-54b8aa3c-b2fc-46ef-8be2-cd006b386e7a": Phase="Pending", Reason="", readiness=false. Elapsed: 9.499655ms
Aug 27 19:34:44.606: INFO: Pod "downwardapi-volume-54b8aa3c-b2fc-46ef-8be2-cd006b386e7a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020204852s
STEP: Saw pod success
Aug 27 19:34:44.606: INFO: Pod "downwardapi-volume-54b8aa3c-b2fc-46ef-8be2-cd006b386e7a" satisfied condition "success or failure"
Aug 27 19:34:44.616: INFO: Trying to get logs from node 10.138.3.233 pod downwardapi-volume-54b8aa3c-b2fc-46ef-8be2-cd006b386e7a container client-container: <nil>
STEP: delete the pod
Aug 27 19:34:44.675: INFO: Waiting for pod downwardapi-volume-54b8aa3c-b2fc-46ef-8be2-cd006b386e7a to disappear
Aug 27 19:34:44.684: INFO: Pod downwardapi-volume-54b8aa3c-b2fc-46ef-8be2-cd006b386e7a no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 19:34:44.684: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2679" for this suite.
Aug 27 19:34:50.746: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 19:34:51.100: INFO: namespace downward-api-2679 deletion completed in 6.397195865s

• [SLOW TEST:8.758 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 19:34:51.101: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-6569
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating all guestbook components
Aug 27 19:34:51.321: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Aug 27 19:34:51.321: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-540514467 create -f - --namespace=kubectl-6569'
Aug 27 19:34:51.590: INFO: stderr: ""
Aug 27 19:34:51.590: INFO: stdout: "service/redis-slave created\n"
Aug 27 19:34:51.590: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Aug 27 19:34:51.590: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-540514467 create -f - --namespace=kubectl-6569'
Aug 27 19:34:51.844: INFO: stderr: ""
Aug 27 19:34:51.844: INFO: stdout: "service/redis-master created\n"
Aug 27 19:34:51.844: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Aug 27 19:34:51.844: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-540514467 create -f - --namespace=kubectl-6569'
Aug 27 19:34:52.186: INFO: stderr: ""
Aug 27 19:34:52.187: INFO: stdout: "service/frontend created\n"
Aug 27 19:34:52.187: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: guestbook
      tier: frontend
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Aug 27 19:34:52.187: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-540514467 create -f - --namespace=kubectl-6569'
Aug 27 19:34:52.496: INFO: stderr: ""
Aug 27 19:34:52.496: INFO: stdout: "deployment.apps/frontend created\n"
Aug 27 19:34:52.496: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  selector:
    matchLabels:
      app: redis
      role: master
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Aug 27 19:34:52.496: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-540514467 create -f - --namespace=kubectl-6569'
Aug 27 19:34:52.737: INFO: stderr: ""
Aug 27 19:34:52.737: INFO: stdout: "deployment.apps/redis-master created\n"
Aug 27 19:34:52.737: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  selector:
    matchLabels:
      app: redis
      role: slave
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave:v3
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Aug 27 19:34:52.737: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-540514467 create -f - --namespace=kubectl-6569'
Aug 27 19:34:53.074: INFO: stderr: ""
Aug 27 19:34:53.074: INFO: stdout: "deployment.apps/redis-slave created\n"
STEP: validating guestbook app
Aug 27 19:34:53.074: INFO: Waiting for all frontend pods to be Running.
Aug 27 19:35:13.127: INFO: Waiting for frontend to serve content.
Aug 27 19:35:18.164: INFO: Failed to get response from guestbook. err: <nil>, response: <br />
<b>Fatal error</b>:  Uncaught exception 'Predis\Connection\ConnectionException' with message 'Connection timed out [tcp://redis-slave:6379]' in /usr/local/lib/php/Predis/Connection/AbstractConnection.php:155
Stack trace:
#0 /usr/local/lib/php/Predis/Connection/StreamConnection.php(128): Predis\Connection\AbstractConnection-&gt;onConnectionError('Connection time...', 110)
#1 /usr/local/lib/php/Predis/Connection/StreamConnection.php(178): Predis\Connection\StreamConnection-&gt;createStreamSocket(Object(Predis\Connection\Parameters), 'tcp://redis-sla...', 4)
#2 /usr/local/lib/php/Predis/Connection/StreamConnection.php(100): Predis\Connection\StreamConnection-&gt;tcpStreamInitializer(Object(Predis\Connection\Parameters))
#3 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(81): Predis\Connection\StreamConnection-&gt;createResource()
#4 /usr/local/lib/php/Predis/Connection/StreamConnection.php(258): Predis\Connection\AbstractConnection-&gt;connect()
#5 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(180): Predis\Connection\Stre in <b>/usr/local/lib/php/Predis/Connection/AbstractConnection.php</b> on line <b>155</b><br />

Aug 27 19:35:23.196: INFO: Trying to add a new entry to the guestbook.
Aug 27 19:35:23.229: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Aug 27 19:35:23.255: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-540514467 delete --grace-period=0 --force -f - --namespace=kubectl-6569'
Aug 27 19:35:23.441: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 27 19:35:23.441: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Aug 27 19:35:23.441: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-540514467 delete --grace-period=0 --force -f - --namespace=kubectl-6569'
Aug 27 19:35:23.623: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 27 19:35:23.623: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Aug 27 19:35:23.623: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-540514467 delete --grace-period=0 --force -f - --namespace=kubectl-6569'
Aug 27 19:35:23.798: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 27 19:35:23.798: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Aug 27 19:35:23.799: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-540514467 delete --grace-period=0 --force -f - --namespace=kubectl-6569'
Aug 27 19:35:23.942: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 27 19:35:23.942: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Aug 27 19:35:23.942: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-540514467 delete --grace-period=0 --force -f - --namespace=kubectl-6569'
Aug 27 19:35:24.095: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 27 19:35:24.095: INFO: stdout: "deployment.apps \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Aug 27 19:35:24.095: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-540514467 delete --grace-period=0 --force -f - --namespace=kubectl-6569'
Aug 27 19:35:24.243: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 27 19:35:24.243: INFO: stdout: "deployment.apps \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 19:35:24.244: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6569" for this suite.
Aug 27 19:36:04.304: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 19:36:04.679: INFO: namespace kubectl-6569 deletion completed in 40.41964767s

• [SLOW TEST:73.579 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Guestbook application
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 19:36:04.679: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-7888
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:63
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Aug 27 19:36:11.026: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 27 19:36:11.037: INFO: Pod pod-with-poststart-exec-hook still exists
Aug 27 19:36:13.039: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 27 19:36:13.051: INFO: Pod pod-with-poststart-exec-hook still exists
Aug 27 19:36:15.037: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 27 19:36:15.047: INFO: Pod pod-with-poststart-exec-hook still exists
Aug 27 19:36:17.037: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 27 19:36:17.047: INFO: Pod pod-with-poststart-exec-hook still exists
Aug 27 19:36:19.037: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 27 19:36:19.048: INFO: Pod pod-with-poststart-exec-hook still exists
Aug 27 19:36:21.037: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 27 19:36:21.048: INFO: Pod pod-with-poststart-exec-hook still exists
Aug 27 19:36:23.037: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 27 19:36:23.048: INFO: Pod pod-with-poststart-exec-hook still exists
Aug 27 19:36:25.037: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 27 19:36:25.048: INFO: Pod pod-with-poststart-exec-hook still exists
Aug 27 19:36:27.037: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 27 19:36:27.048: INFO: Pod pod-with-poststart-exec-hook still exists
Aug 27 19:36:29.037: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 27 19:36:29.048: INFO: Pod pod-with-poststart-exec-hook still exists
Aug 27 19:36:31.037: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 27 19:36:31.048: INFO: Pod pod-with-poststart-exec-hook still exists
Aug 27 19:36:33.037: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 27 19:36:33.047: INFO: Pod pod-with-poststart-exec-hook still exists
Aug 27 19:36:35.037: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 27 19:36:35.048: INFO: Pod pod-with-poststart-exec-hook still exists
Aug 27 19:36:37.037: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 27 19:36:37.048: INFO: Pod pod-with-poststart-exec-hook still exists
Aug 27 19:36:39.037: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 27 19:36:39.047: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 19:36:39.048: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-7888" for this suite.
Aug 27 19:37:03.244: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 19:37:03.617: INFO: namespace container-lifecycle-hook-7888 deletion completed in 24.553588656s

• [SLOW TEST:58.938 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when create a pod with lifecycle hook
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Aggregator 
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 19:37:03.618: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename aggregator
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in aggregator-4091
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:76
Aug 27 19:37:03.837: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
[It] Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Registering the sample API server.
Aug 27 19:37:04.961: INFO: deployment "sample-apiserver-deployment" doesn't have the required revision set
Aug 27 19:37:07.072: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63702531424, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63702531424, loc:(*time.Location)(0x7ec7a20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63702531424, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63702531424, loc:(*time.Location)(0x7ec7a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 27 19:37:09.082: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63702531424, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63702531424, loc:(*time.Location)(0x7ec7a20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63702531424, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63702531424, loc:(*time.Location)(0x7ec7a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 27 19:37:11.083: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63702531424, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63702531424, loc:(*time.Location)(0x7ec7a20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63702531424, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63702531424, loc:(*time.Location)(0x7ec7a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 27 19:37:13.083: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63702531424, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63702531424, loc:(*time.Location)(0x7ec7a20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63702531424, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63702531424, loc:(*time.Location)(0x7ec7a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 27 19:37:15.083: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63702531424, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63702531424, loc:(*time.Location)(0x7ec7a20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63702531424, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63702531424, loc:(*time.Location)(0x7ec7a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 27 19:37:17.082: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63702531424, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63702531424, loc:(*time.Location)(0x7ec7a20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63702531424, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63702531424, loc:(*time.Location)(0x7ec7a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 27 19:37:19.083: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63702531424, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63702531424, loc:(*time.Location)(0x7ec7a20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63702531424, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63702531424, loc:(*time.Location)(0x7ec7a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 27 19:37:21.085: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63702531424, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63702531424, loc:(*time.Location)(0x7ec7a20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63702531424, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63702531424, loc:(*time.Location)(0x7ec7a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 27 19:37:23.083: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63702531424, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63702531424, loc:(*time.Location)(0x7ec7a20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63702531424, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63702531424, loc:(*time.Location)(0x7ec7a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 27 19:37:25.083: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63702531443, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63702531424, loc:(*time.Location)(0x7ec7a20)}}, Reason:"NewReplicaSetAvailable", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" has successfully progressed."}, v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63702531444, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63702531444, loc:(*time.Location)(0x7ec7a20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}}, CollisionCount:(*int32)(nil)}
Aug 27 19:37:32.366: INFO: Waited 5.267077103s for the sample-apiserver to be ready to handle requests.
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:67
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 19:37:32.916: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "aggregator-4091" for this suite.
Aug 27 19:37:41.038: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 19:37:41.389: INFO: namespace aggregator-4091 deletion completed in 8.457294908s

• [SLOW TEST:37.771 seconds]
[sig-api-machinery] Aggregator
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 19:37:41.390: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-9075
STEP: Waiting for a default service account to be provisioned in namespace
[It] should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Aug 27 19:37:41.609: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
STEP: Creating rc "condition-test" that asks for more than the allowed pod quota
STEP: Checking rc "condition-test" has the desired failure condition set
STEP: Scaling down rc "condition-test" to satisfy pod quota
Aug 27 19:37:42.703: INFO: Updating replication controller "condition-test"
STEP: Checking rc "condition-test" has no failure condition set
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 19:37:42.713: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-9075" for this suite.
Aug 27 19:37:48.783: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 19:37:49.176: INFO: namespace replication-controller-9075 deletion completed in 6.446833999s

• [SLOW TEST:7.786 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 19:37:49.181: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-2903
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod liveness-9053410c-75ad-4879-9b9b-8370ceb76678 in namespace container-probe-2903
Aug 27 19:37:57.438: INFO: Started pod liveness-9053410c-75ad-4879-9b9b-8370ceb76678 in namespace container-probe-2903
STEP: checking the pod's current state and verifying that restartCount is present
Aug 27 19:37:57.447: INFO: Initial restart count of pod liveness-9053410c-75ad-4879-9b9b-8370ceb76678 is 0
Aug 27 19:38:13.545: INFO: Restart count of pod container-probe-2903/liveness-9053410c-75ad-4879-9b9b-8370ceb76678 is now 1 (16.09813939s elapsed)
Aug 27 19:38:33.673: INFO: Restart count of pod container-probe-2903/liveness-9053410c-75ad-4879-9b9b-8370ceb76678 is now 2 (36.226151516s elapsed)
Aug 27 19:38:53.785: INFO: Restart count of pod container-probe-2903/liveness-9053410c-75ad-4879-9b9b-8370ceb76678 is now 3 (56.337425319s elapsed)
Aug 27 19:39:13.893: INFO: Restart count of pod container-probe-2903/liveness-9053410c-75ad-4879-9b9b-8370ceb76678 is now 4 (1m16.446161708s elapsed)
Aug 27 19:40:28.309: INFO: Restart count of pod container-probe-2903/liveness-9053410c-75ad-4879-9b9b-8370ceb76678 is now 5 (2m30.862167205s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 19:40:28.335: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-2903" for this suite.
Aug 27 19:40:34.407: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 19:40:34.794: INFO: namespace container-probe-2903 deletion completed in 6.432816008s

• [SLOW TEST:165.613 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 19:40:34.794: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-9510
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Aug 27 19:40:35.041: INFO: Pod name rollover-pod: Found 0 pods out of 1
Aug 27 19:40:40.052: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Aug 27 19:40:40.052: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Aug 27 19:40:42.065: INFO: Creating deployment "test-rollover-deployment"
Aug 27 19:40:42.086: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Aug 27 19:40:44.106: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Aug 27 19:40:44.127: INFO: Ensure that both replica sets have 1 created replica
Aug 27 19:40:44.150: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Aug 27 19:40:44.171: INFO: Updating deployment test-rollover-deployment
Aug 27 19:40:44.171: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Aug 27 19:40:46.191: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Aug 27 19:40:46.214: INFO: Make sure deployment "test-rollover-deployment" is complete
Aug 27 19:40:46.236: INFO: all replica sets need to contain the pod-template-hash label
Aug 27 19:40:46.236: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63702531642, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63702531642, loc:(*time.Location)(0x7ec7a20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63702531645, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63702531642, loc:(*time.Location)(0x7ec7a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 27 19:40:48.262: INFO: all replica sets need to contain the pod-template-hash label
Aug 27 19:40:48.262: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63702531642, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63702531642, loc:(*time.Location)(0x7ec7a20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63702531645, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63702531642, loc:(*time.Location)(0x7ec7a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 27 19:40:50.260: INFO: all replica sets need to contain the pod-template-hash label
Aug 27 19:40:50.260: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63702531642, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63702531642, loc:(*time.Location)(0x7ec7a20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63702531645, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63702531642, loc:(*time.Location)(0x7ec7a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 27 19:40:52.260: INFO: all replica sets need to contain the pod-template-hash label
Aug 27 19:40:52.260: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63702531642, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63702531642, loc:(*time.Location)(0x7ec7a20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63702531645, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63702531642, loc:(*time.Location)(0x7ec7a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 27 19:40:54.259: INFO: all replica sets need to contain the pod-template-hash label
Aug 27 19:40:54.259: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63702531642, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63702531642, loc:(*time.Location)(0x7ec7a20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63702531645, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63702531642, loc:(*time.Location)(0x7ec7a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 27 19:40:56.261: INFO: 
Aug 27 19:40:56.261: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
Aug 27 19:40:56.296: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment,GenerateName:,Namespace:deployment-9510,SelfLink:/apis/apps/v1/namespaces/deployment-9510/deployments/test-rollover-deployment,UID:d9abeae9-ed80-43f3-a94b-4360fe200c08,ResourceVersion:39427,Generation:2,CreationTimestamp:2019-08-27 19:40:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-08-27 19:40:42 +0000 UTC 2019-08-27 19:40:42 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-08-27 19:40:55 +0000 UTC 2019-08-27 19:40:42 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rollover-deployment-854595fc44" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Aug 27 19:40:56.309: INFO: New ReplicaSet "test-rollover-deployment-854595fc44" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-854595fc44,GenerateName:,Namespace:deployment-9510,SelfLink:/apis/apps/v1/namespaces/deployment-9510/replicasets/test-rollover-deployment-854595fc44,UID:03ec748c-c818-44a5-9c7e-82f29a4948ed,ResourceVersion:39416,Generation:2,CreationTimestamp:2019-08-27 19:40:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 854595fc44,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment d9abeae9-ed80-43f3-a94b-4360fe200c08 0xc001e52a67 0xc001e52a68}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 854595fc44,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 854595fc44,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Aug 27 19:40:56.309: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Aug 27 19:40:56.309: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-controller,GenerateName:,Namespace:deployment-9510,SelfLink:/apis/apps/v1/namespaces/deployment-9510/replicasets/test-rollover-controller,UID:f3b42078-1725-424a-89ca-a48cc557edca,ResourceVersion:39425,Generation:2,CreationTimestamp:2019-08-27 19:40:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment d9abeae9-ed80-43f3-a94b-4360fe200c08 0xc001e52997 0xc001e52998}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Aug 27 19:40:56.315: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-9b8b997cf,GenerateName:,Namespace:deployment-9510,SelfLink:/apis/apps/v1/namespaces/deployment-9510/replicasets/test-rollover-deployment-9b8b997cf,UID:d30bfe7f-57f5-4ed3-b22c-9af60cfcdd18,ResourceVersion:39375,Generation:2,CreationTimestamp:2019-08-27 19:40:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 9b8b997cf,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment d9abeae9-ed80-43f3-a94b-4360fe200c08 0xc001e52bf0 0xc001e52bf1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 9b8b997cf,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 9b8b997cf,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Aug 27 19:40:56.325: INFO: Pod "test-rollover-deployment-854595fc44-l5lk9" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-854595fc44-l5lk9,GenerateName:test-rollover-deployment-854595fc44-,Namespace:deployment-9510,SelfLink:/api/v1/namespaces/deployment-9510/pods/test-rollover-deployment-854595fc44-l5lk9,UID:fc5b158e-f1b2-4d73-a9e9-d7148eb42f06,ResourceVersion:39396,Generation:0,CreationTimestamp:2019-08-27 19:40:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 854595fc44,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-rollover-deployment-854595fc44 03ec748c-c818-44a5-9c7e-82f29a4948ed 0xc001e53ae7 0xc001e53ae8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-2xpmn {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-2xpmn,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-2xpmn true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.138.3.242,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001e53b60} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001e53b80}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:40:44 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:40:45 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:40:45 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:40:44 +0000 UTC  }],Message:,Reason:,HostIP:10.138.3.242,PodIP:172.30.115.30,StartTime:2019-08-27 19:40:44 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-08-27 19:40:45 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 containerd://a2db89ecf30a456d37abfa40874756201f1f211a8edcf22cfbba872236292125}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 19:40:56.325: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-9510" for this suite.
Aug 27 19:41:04.385: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 19:41:04.768: INFO: namespace deployment-9510 deletion completed in 8.426854008s

• [SLOW TEST:29.974 seconds]
[sig-apps] Deployment
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support rollover [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 19:41:04.769: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-5453
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0644 on tmpfs
Aug 27 19:41:05.007: INFO: Waiting up to 5m0s for pod "pod-a085b0d7-02ee-4da5-9cd7-afad4d805cbf" in namespace "emptydir-5453" to be "success or failure"
Aug 27 19:41:05.016: INFO: Pod "pod-a085b0d7-02ee-4da5-9cd7-afad4d805cbf": Phase="Pending", Reason="", readiness=false. Elapsed: 9.19365ms
Aug 27 19:41:07.027: INFO: Pod "pod-a085b0d7-02ee-4da5-9cd7-afad4d805cbf": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019475889s
Aug 27 19:41:09.037: INFO: Pod "pod-a085b0d7-02ee-4da5-9cd7-afad4d805cbf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.029873565s
STEP: Saw pod success
Aug 27 19:41:09.037: INFO: Pod "pod-a085b0d7-02ee-4da5-9cd7-afad4d805cbf" satisfied condition "success or failure"
Aug 27 19:41:09.047: INFO: Trying to get logs from node 10.138.3.233 pod pod-a085b0d7-02ee-4da5-9cd7-afad4d805cbf container test-container: <nil>
STEP: delete the pod
Aug 27 19:41:09.104: INFO: Waiting for pod pod-a085b0d7-02ee-4da5-9cd7-afad4d805cbf to disappear
Aug 27 19:41:09.115: INFO: Pod pod-a085b0d7-02ee-4da5-9cd7-afad4d805cbf no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 19:41:09.115: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5453" for this suite.
Aug 27 19:41:15.174: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 19:41:15.567: INFO: namespace emptydir-5453 deletion completed in 6.436738519s

• [SLOW TEST:10.799 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 19:41:15.568: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-9715
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0666 on node default medium
Aug 27 19:41:15.811: INFO: Waiting up to 5m0s for pod "pod-f7f3789d-592c-4b39-af58-1c91ae91a388" in namespace "emptydir-9715" to be "success or failure"
Aug 27 19:41:15.822: INFO: Pod "pod-f7f3789d-592c-4b39-af58-1c91ae91a388": Phase="Pending", Reason="", readiness=false. Elapsed: 10.742895ms
Aug 27 19:41:17.832: INFO: Pod "pod-f7f3789d-592c-4b39-af58-1c91ae91a388": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020850718s
STEP: Saw pod success
Aug 27 19:41:17.832: INFO: Pod "pod-f7f3789d-592c-4b39-af58-1c91ae91a388" satisfied condition "success or failure"
Aug 27 19:41:17.842: INFO: Trying to get logs from node 10.138.3.242 pod pod-f7f3789d-592c-4b39-af58-1c91ae91a388 container test-container: <nil>
STEP: delete the pod
Aug 27 19:41:17.896: INFO: Waiting for pod pod-f7f3789d-592c-4b39-af58-1c91ae91a388 to disappear
Aug 27 19:41:17.907: INFO: Pod pod-f7f3789d-592c-4b39-af58-1c91ae91a388 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 19:41:17.908: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9715" for this suite.
Aug 27 19:41:23.968: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 19:41:24.324: INFO: namespace emptydir-9715 deletion completed in 6.401095241s

• [SLOW TEST:8.756 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 19:41:24.326: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2567
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-48e16d7d-ec8a-45f1-b087-f1dd8a5329bb
STEP: Creating a pod to test consume configMaps
Aug 27 19:41:24.580: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-6ce6692d-7c8d-49bf-a827-4ccf7b52c632" in namespace "projected-2567" to be "success or failure"
Aug 27 19:41:24.590: INFO: Pod "pod-projected-configmaps-6ce6692d-7c8d-49bf-a827-4ccf7b52c632": Phase="Pending", Reason="", readiness=false. Elapsed: 10.018579ms
Aug 27 19:41:26.603: INFO: Pod "pod-projected-configmaps-6ce6692d-7c8d-49bf-a827-4ccf7b52c632": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.022883247s
STEP: Saw pod success
Aug 27 19:41:26.603: INFO: Pod "pod-projected-configmaps-6ce6692d-7c8d-49bf-a827-4ccf7b52c632" satisfied condition "success or failure"
Aug 27 19:41:26.613: INFO: Trying to get logs from node 10.138.3.233 pod pod-projected-configmaps-6ce6692d-7c8d-49bf-a827-4ccf7b52c632 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Aug 27 19:41:26.663: INFO: Waiting for pod pod-projected-configmaps-6ce6692d-7c8d-49bf-a827-4ccf7b52c632 to disappear
Aug 27 19:41:26.672: INFO: Pod pod-projected-configmaps-6ce6692d-7c8d-49bf-a827-4ccf7b52c632 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 19:41:26.673: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2567" for this suite.
Aug 27 19:41:32.733: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 19:41:33.100: INFO: namespace projected-2567 deletion completed in 6.411098244s

• [SLOW TEST:8.775 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 19:41:33.101: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-2510
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating the pod
Aug 27 19:41:35.953: INFO: Successfully updated pod "annotationupdatec6b18e51-3f3d-4352-a449-ed423d2f6fb0"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 19:41:40.019: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2510" for this suite.
Aug 27 19:42:04.083: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 19:42:04.474: INFO: namespace downward-api-2510 deletion completed in 24.43841838s

• [SLOW TEST:31.373 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 19:42:04.475: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-9061
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Performing setup for networking test in namespace pod-network-test-9061
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Aug 27 19:42:04.693: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Aug 27 19:42:26.928: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 172.30.37.227 8081 | grep -v '^\s*$'] Namespace:pod-network-test-9061 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 27 19:42:26.928: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
Aug 27 19:42:28.247: INFO: Found all expected endpoints: [netserver-0]
Aug 27 19:42:28.258: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 172.30.115.33 8081 | grep -v '^\s*$'] Namespace:pod-network-test-9061 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 27 19:42:28.258: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
Aug 27 19:42:29.558: INFO: Found all expected endpoints: [netserver-1]
Aug 27 19:42:29.568: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 172.30.145.43 8081 | grep -v '^\s*$'] Namespace:pod-network-test-9061 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 27 19:42:29.568: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
Aug 27 19:42:30.906: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 19:42:30.907: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-9061" for this suite.
Aug 27 19:42:54.967: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 19:42:55.400: INFO: namespace pod-network-test-9061 deletion completed in 24.477083247s

• [SLOW TEST:50.925 seconds]
[sig-network] Networking
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 19:42:55.400: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-6622
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0644 on tmpfs
Aug 27 19:42:55.637: INFO: Waiting up to 5m0s for pod "pod-acd384bd-da64-449c-90a4-133e47e30236" in namespace "emptydir-6622" to be "success or failure"
Aug 27 19:42:55.648: INFO: Pod "pod-acd384bd-da64-449c-90a4-133e47e30236": Phase="Pending", Reason="", readiness=false. Elapsed: 11.100455ms
Aug 27 19:42:57.659: INFO: Pod "pod-acd384bd-da64-449c-90a4-133e47e30236": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0217631s
STEP: Saw pod success
Aug 27 19:42:57.659: INFO: Pod "pod-acd384bd-da64-449c-90a4-133e47e30236" satisfied condition "success or failure"
Aug 27 19:42:57.669: INFO: Trying to get logs from node 10.138.3.233 pod pod-acd384bd-da64-449c-90a4-133e47e30236 container test-container: <nil>
STEP: delete the pod
Aug 27 19:42:57.715: INFO: Waiting for pod pod-acd384bd-da64-449c-90a4-133e47e30236 to disappear
Aug 27 19:42:57.725: INFO: Pod pod-acd384bd-da64-449c-90a4-133e47e30236 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 19:42:57.726: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6622" for this suite.
Aug 27 19:43:03.787: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 19:43:04.148: INFO: namespace emptydir-6622 deletion completed in 6.406639694s

• [SLOW TEST:8.748 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 19:43:04.151: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-779
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod liveness-8e374c61-abfd-4919-b7c8-05a683d6fc26 in namespace container-probe-779
Aug 27 19:43:10.407: INFO: Started pod liveness-8e374c61-abfd-4919-b7c8-05a683d6fc26 in namespace container-probe-779
STEP: checking the pod's current state and verifying that restartCount is present
Aug 27 19:43:10.417: INFO: Initial restart count of pod liveness-8e374c61-abfd-4919-b7c8-05a683d6fc26 is 0
Aug 27 19:43:28.526: INFO: Restart count of pod container-probe-779/liveness-8e374c61-abfd-4919-b7c8-05a683d6fc26 is now 1 (18.108396248s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 19:43:28.553: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-779" for this suite.
Aug 27 19:43:34.611: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 19:43:35.008: INFO: namespace container-probe-779 deletion completed in 6.440469363s

• [SLOW TEST:30.857 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 19:43:35.009: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-9229
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test override arguments
Aug 27 19:43:35.255: INFO: Waiting up to 5m0s for pod "client-containers-448a3014-7867-4f85-95ec-498e89b34720" in namespace "containers-9229" to be "success or failure"
Aug 27 19:43:35.265: INFO: Pod "client-containers-448a3014-7867-4f85-95ec-498e89b34720": Phase="Pending", Reason="", readiness=false. Elapsed: 10.017292ms
Aug 27 19:43:37.278: INFO: Pod "client-containers-448a3014-7867-4f85-95ec-498e89b34720": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023159757s
Aug 27 19:43:39.289: INFO: Pod "client-containers-448a3014-7867-4f85-95ec-498e89b34720": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.034159996s
STEP: Saw pod success
Aug 27 19:43:39.289: INFO: Pod "client-containers-448a3014-7867-4f85-95ec-498e89b34720" satisfied condition "success or failure"
Aug 27 19:43:39.299: INFO: Trying to get logs from node 10.138.3.233 pod client-containers-448a3014-7867-4f85-95ec-498e89b34720 container test-container: <nil>
STEP: delete the pod
Aug 27 19:43:39.346: INFO: Waiting for pod client-containers-448a3014-7867-4f85-95ec-498e89b34720 to disappear
Aug 27 19:43:39.356: INFO: Pod client-containers-448a3014-7867-4f85-95ec-498e89b34720 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 19:43:39.356: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-9229" for this suite.
Aug 27 19:43:45.437: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 19:43:46.147: INFO: namespace containers-9229 deletion completed in 6.753907381s

• [SLOW TEST:11.138 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 19:43:46.147: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-3698
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 19:43:48.432: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-3698" for this suite.
Aug 27 19:44:38.496: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 19:44:38.908: INFO: namespace kubelet-test-3698 deletion completed in 50.460136533s

• [SLOW TEST:52.761 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when scheduling a busybox Pod with hostAliases
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:136
    should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 19:44:38.909: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-1730
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
Aug 27 19:44:45.219: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
W0827 19:44:45.218998      16 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Aug 27 19:44:45.219: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-1730" for this suite.
Aug 27 19:44:53.283: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 19:44:53.686: INFO: namespace gc-1730 deletion completed in 8.451458569s

• [SLOW TEST:14.777 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 19:44:53.688: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-4922
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Aug 27 19:44:53.902: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 19:44:56.018: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-4922" for this suite.
Aug 27 19:45:40.078: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 19:45:40.465: INFO: namespace pods-4922 deletion completed in 44.431931961s

• [SLOW TEST:46.778 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 19:45:40.470: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-1996
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Aug 27 19:45:40.685: INFO: Creating deployment "nginx-deployment"
Aug 27 19:45:40.696: INFO: Waiting for observed generation 1
Aug 27 19:45:42.716: INFO: Waiting for all required pods to come up
Aug 27 19:45:42.731: INFO: Pod name nginx: Found 10 pods out of 10
STEP: ensuring each pod is running
Aug 27 19:45:44.756: INFO: Waiting for deployment "nginx-deployment" to complete
Aug 27 19:45:44.777: INFO: Updating deployment "nginx-deployment" with a non-existent image
Aug 27 19:45:44.798: INFO: Updating deployment nginx-deployment
Aug 27 19:45:44.798: INFO: Waiting for observed generation 2
Aug 27 19:45:46.818: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Aug 27 19:45:46.834: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Aug 27 19:45:46.846: INFO: Waiting for the first rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Aug 27 19:45:46.881: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Aug 27 19:45:46.881: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Aug 27 19:45:46.893: INFO: Waiting for the second rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Aug 27 19:45:46.916: INFO: Verifying that deployment "nginx-deployment" has minimum required number of available replicas
Aug 27 19:45:46.916: INFO: Scaling up the deployment "nginx-deployment" from 10 to 30
Aug 27 19:45:46.938: INFO: Updating deployment nginx-deployment
Aug 27 19:45:46.938: INFO: Waiting for the replicasets of deployment "nginx-deployment" to have desired number of replicas
Aug 27 19:45:46.962: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Aug 27 19:45:49.005: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
Aug 27 19:45:49.028: INFO: Deployment "nginx-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment,GenerateName:,Namespace:deployment-1996,SelfLink:/apis/apps/v1/namespaces/deployment-1996/deployments/nginx-deployment,UID:6ec58a66-b6fe-4370-bc02-1a4f0e7af113,ResourceVersion:41115,Generation:3,CreationTimestamp:2019-08-27 19:45:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*30,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:33,UpdatedReplicas:13,AvailableReplicas:9,UnavailableReplicas:24,Conditions:[{Available False 2019-08-27 19:45:46 +0000 UTC 2019-08-27 19:45:46 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-08-27 19:45:48 +0000 UTC 2019-08-27 19:45:40 +0000 UTC ReplicaSetUpdated ReplicaSet "nginx-deployment-55fb7cb77f" is progressing.}],ReadyReplicas:9,CollisionCount:nil,},}

Aug 27 19:45:49.042: INFO: New ReplicaSet "nginx-deployment-55fb7cb77f" of Deployment "nginx-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f,GenerateName:,Namespace:deployment-1996,SelfLink:/apis/apps/v1/namespaces/deployment-1996/replicasets/nginx-deployment-55fb7cb77f,UID:1ee77715-5a41-481e-8077-6bda27c51893,ResourceVersion:40965,Generation:3,CreationTimestamp:2019-08-27 19:45:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 6ec58a66-b6fe-4370-bc02-1a4f0e7af113 0xc002db3bf7 0xc002db3bf8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*13,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:13,FullyLabeledReplicas:13,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Aug 27 19:45:49.042: INFO: All old ReplicaSets of Deployment "nginx-deployment":
Aug 27 19:45:49.042: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498,GenerateName:,Namespace:deployment-1996,SelfLink:/apis/apps/v1/namespaces/deployment-1996/replicasets/nginx-deployment-7b8c6f4498,UID:76c6c91c-bea9-49c2-9f67-3d3e80503e73,ResourceVersion:41113,Generation:3,CreationTimestamp:2019-08-27 19:45:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 6ec58a66-b6fe-4370-bc02-1a4f0e7af113 0xc002db3cc7 0xc002db3cc8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*20,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:20,FullyLabeledReplicas:20,ObservedGeneration:3,ReadyReplicas:9,AvailableReplicas:9,Conditions:[],},}
Aug 27 19:45:49.069: INFO: Pod "nginx-deployment-55fb7cb77f-2j2jt" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-2j2jt,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-1996,SelfLink:/api/v1/namespaces/deployment-1996/pods/nginx-deployment-55fb7cb77f-2j2jt,UID:820c269c-3f0a-42bf-88b3-32299cb5fa97,ResourceVersion:41011,Generation:0,CreationTimestamp:2019-08-27 19:45:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 1ee77715-5a41-481e-8077-6bda27c51893 0xc0021e9107 0xc0021e9108}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-5sd4z {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5sd4z,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-5sd4z true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.138.3.242,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0021e9180} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0021e91a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:45:47 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:45:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:45:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:45:46 +0000 UTC  }],Message:,Reason:,HostIP:10.138.3.242,PodIP:,StartTime:2019-08-27 19:45:47 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 27 19:45:49.069: INFO: Pod "nginx-deployment-55fb7cb77f-4cc42" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-4cc42,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-1996,SelfLink:/api/v1/namespaces/deployment-1996/pods/nginx-deployment-55fb7cb77f-4cc42,UID:6c116148-1595-4823-b5c9-5f4f68a9c4b7,ResourceVersion:40976,Generation:0,CreationTimestamp:2019-08-27 19:45:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 1ee77715-5a41-481e-8077-6bda27c51893 0xc0021e9280 0xc0021e9281}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-5sd4z {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5sd4z,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-5sd4z true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.138.3.233,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0021e9300} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0021e9320}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:45:46 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:45:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:45:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:45:46 +0000 UTC  }],Message:,Reason:,HostIP:10.138.3.233,PodIP:,StartTime:2019-08-27 19:45:46 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 27 19:45:49.069: INFO: Pod "nginx-deployment-55fb7cb77f-7rkcw" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-7rkcw,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-1996,SelfLink:/api/v1/namespaces/deployment-1996/pods/nginx-deployment-55fb7cb77f-7rkcw,UID:fa1acad8-d1b6-46da-a84d-7ac8a174e1e5,ResourceVersion:40854,Generation:0,CreationTimestamp:2019-08-27 19:45:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 1ee77715-5a41-481e-8077-6bda27c51893 0xc0021e93f0 0xc0021e93f1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-5sd4z {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5sd4z,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-5sd4z true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.138.3.199,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0021e9470} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0021e9490}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:45:44 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:45:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:45:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:45:44 +0000 UTC  }],Message:,Reason:,HostIP:10.138.3.199,PodIP:,StartTime:2019-08-27 19:45:44 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 27 19:45:49.070: INFO: Pod "nginx-deployment-55fb7cb77f-cl2q8" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-cl2q8,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-1996,SelfLink:/api/v1/namespaces/deployment-1996/pods/nginx-deployment-55fb7cb77f-cl2q8,UID:b6578ae7-effe-4dee-86b5-3bea057ec105,ResourceVersion:40877,Generation:0,CreationTimestamp:2019-08-27 19:45:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 1ee77715-5a41-481e-8077-6bda27c51893 0xc0021e9570 0xc0021e9571}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-5sd4z {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5sd4z,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-5sd4z true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.138.3.242,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0021e95f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0021e9610}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:45:44 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:45:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:45:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:45:44 +0000 UTC  }],Message:,Reason:,HostIP:10.138.3.242,PodIP:,StartTime:2019-08-27 19:45:44 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 27 19:45:49.070: INFO: Pod "nginx-deployment-55fb7cb77f-jlmnb" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-jlmnb,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-1996,SelfLink:/api/v1/namespaces/deployment-1996/pods/nginx-deployment-55fb7cb77f-jlmnb,UID:522ae5cb-799d-42d2-afbb-31b6a1a72c5f,ResourceVersion:41015,Generation:0,CreationTimestamp:2019-08-27 19:45:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 1ee77715-5a41-481e-8077-6bda27c51893 0xc0021e96e0 0xc0021e96e1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-5sd4z {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5sd4z,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-5sd4z true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.138.3.242,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0021e9760} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0021e9780}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:45:47 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:45:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:45:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:45:46 +0000 UTC  }],Message:,Reason:,HostIP:10.138.3.242,PodIP:,StartTime:2019-08-27 19:45:47 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 27 19:45:49.070: INFO: Pod "nginx-deployment-55fb7cb77f-k8kx8" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-k8kx8,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-1996,SelfLink:/api/v1/namespaces/deployment-1996/pods/nginx-deployment-55fb7cb77f-k8kx8,UID:9d01ae25-a179-4955-b127-d2e63e82f103,ResourceVersion:41114,Generation:0,CreationTimestamp:2019-08-27 19:45:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 1ee77715-5a41-481e-8077-6bda27c51893 0xc0021e9850 0xc0021e9851}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-5sd4z {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5sd4z,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-5sd4z true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.138.3.233,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0021e98d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0021e98f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:45:44 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:45:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:45:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:45:44 +0000 UTC  }],Message:,Reason:,HostIP:10.138.3.233,PodIP:172.30.37.240,StartTime:2019-08-27 19:45:44 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to resolve image "docker.io/library/nginx:404": no available registry endpoint: docker.io/library/nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 27 19:45:49.070: INFO: Pod "nginx-deployment-55fb7cb77f-kg4q8" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-kg4q8,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-1996,SelfLink:/api/v1/namespaces/deployment-1996/pods/nginx-deployment-55fb7cb77f-kg4q8,UID:62e08658-8a72-4267-b11b-1340a9536c6e,ResourceVersion:40986,Generation:0,CreationTimestamp:2019-08-27 19:45:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 1ee77715-5a41-481e-8077-6bda27c51893 0xc0021e99e0 0xc0021e99e1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-5sd4z {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5sd4z,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-5sd4z true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.138.3.233,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0021e9a60} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0021e9a80}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:45:46 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:45:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:45:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:45:46 +0000 UTC  }],Message:,Reason:,HostIP:10.138.3.233,PodIP:,StartTime:2019-08-27 19:45:46 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 27 19:45:49.070: INFO: Pod "nginx-deployment-55fb7cb77f-lc5fw" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-lc5fw,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-1996,SelfLink:/api/v1/namespaces/deployment-1996/pods/nginx-deployment-55fb7cb77f-lc5fw,UID:97830a5a-ea14-4ac2-990c-2b86b83e129a,ResourceVersion:40992,Generation:0,CreationTimestamp:2019-08-27 19:45:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 1ee77715-5a41-481e-8077-6bda27c51893 0xc0021e9b50 0xc0021e9b51}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-5sd4z {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5sd4z,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-5sd4z true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.138.3.199,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0021e9bd0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0021e9bf0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:45:47 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:45:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:45:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:45:46 +0000 UTC  }],Message:,Reason:,HostIP:10.138.3.199,PodIP:,StartTime:2019-08-27 19:45:47 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 27 19:45:49.071: INFO: Pod "nginx-deployment-55fb7cb77f-pzgzs" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-pzgzs,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-1996,SelfLink:/api/v1/namespaces/deployment-1996/pods/nginx-deployment-55fb7cb77f-pzgzs,UID:ca727e50-00bd-4cb1-87f7-72df81c7976a,ResourceVersion:40997,Generation:0,CreationTimestamp:2019-08-27 19:45:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 1ee77715-5a41-481e-8077-6bda27c51893 0xc0021e9cd0 0xc0021e9cd1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-5sd4z {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5sd4z,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-5sd4z true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.138.3.233,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0021e9d50} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0021e9d70}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:45:47 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:45:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:45:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:45:46 +0000 UTC  }],Message:,Reason:,HostIP:10.138.3.233,PodIP:,StartTime:2019-08-27 19:45:47 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 27 19:45:49.071: INFO: Pod "nginx-deployment-55fb7cb77f-q2vvv" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-q2vvv,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-1996,SelfLink:/api/v1/namespaces/deployment-1996/pods/nginx-deployment-55fb7cb77f-q2vvv,UID:fec79fde-8ebd-4c4f-9495-3c71a1fa0ed1,ResourceVersion:40991,Generation:0,CreationTimestamp:2019-08-27 19:45:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 1ee77715-5a41-481e-8077-6bda27c51893 0xc0021e9e50 0xc0021e9e51}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-5sd4z {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5sd4z,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-5sd4z true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.138.3.233,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0021e9ed0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0021e9ef0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:45:47 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:45:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:45:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:45:46 +0000 UTC  }],Message:,Reason:,HostIP:10.138.3.233,PodIP:,StartTime:2019-08-27 19:45:47 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 27 19:45:49.071: INFO: Pod "nginx-deployment-55fb7cb77f-q8f4f" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-q8f4f,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-1996,SelfLink:/api/v1/namespaces/deployment-1996/pods/nginx-deployment-55fb7cb77f-q8f4f,UID:1b5dbe02-285f-4375-be37-8f9a99a75803,ResourceVersion:40878,Generation:0,CreationTimestamp:2019-08-27 19:45:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 1ee77715-5a41-481e-8077-6bda27c51893 0xc0021e9fc0 0xc0021e9fc1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-5sd4z {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5sd4z,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-5sd4z true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.138.3.242,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0021c2040} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0021c2060}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:45:44 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:45:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:45:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:45:44 +0000 UTC  }],Message:,Reason:,HostIP:10.138.3.242,PodIP:,StartTime:2019-08-27 19:45:44 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 27 19:45:49.071: INFO: Pod "nginx-deployment-55fb7cb77f-qrh2r" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-qrh2r,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-1996,SelfLink:/api/v1/namespaces/deployment-1996/pods/nginx-deployment-55fb7cb77f-qrh2r,UID:81beffea-435b-4334-a6dc-cb0f1bdbf305,ResourceVersion:40853,Generation:0,CreationTimestamp:2019-08-27 19:45:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 1ee77715-5a41-481e-8077-6bda27c51893 0xc0021c2130 0xc0021c2131}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-5sd4z {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5sd4z,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-5sd4z true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.138.3.242,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0021c21c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0021c21e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:45:44 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:45:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:45:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:45:44 +0000 UTC  }],Message:,Reason:,HostIP:10.138.3.242,PodIP:,StartTime:2019-08-27 19:45:44 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 27 19:45:49.071: INFO: Pod "nginx-deployment-55fb7cb77f-zv7ng" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-zv7ng,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-1996,SelfLink:/api/v1/namespaces/deployment-1996/pods/nginx-deployment-55fb7cb77f-zv7ng,UID:0b0ad003-2388-4e1c-a238-67b01211f3f9,ResourceVersion:40978,Generation:0,CreationTimestamp:2019-08-27 19:45:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 1ee77715-5a41-481e-8077-6bda27c51893 0xc0021c22c0 0xc0021c22c1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-5sd4z {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5sd4z,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-5sd4z true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.138.3.199,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0021c2340} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0021c2360}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:45:46 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:45:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:45:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:45:46 +0000 UTC  }],Message:,Reason:,HostIP:10.138.3.199,PodIP:,StartTime:2019-08-27 19:45:46 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 27 19:45:49.072: INFO: Pod "nginx-deployment-7b8c6f4498-45lj2" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-45lj2,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-1996,SelfLink:/api/v1/namespaces/deployment-1996/pods/nginx-deployment-7b8c6f4498-45lj2,UID:c4599eb7-d4da-4135-aba7-58ada94947d8,ResourceVersion:40802,Generation:0,CreationTimestamp:2019-08-27 19:45:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 76c6c91c-bea9-49c2-9f67-3d3e80503e73 0xc0021c2430 0xc0021c2431}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-5sd4z {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5sd4z,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-5sd4z true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.138.3.233,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0021c24a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0021c24c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:45:40 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:45:42 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:45:42 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:45:40 +0000 UTC  }],Message:,Reason:,HostIP:10.138.3.233,PodIP:172.30.37.238,StartTime:2019-08-27 19:45:40 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-08-27 19:45:42 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 containerd://1c9a52f1952ef300552f8a48c847c9bb2738bf8424f892ea17d30533aa74b7ab}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 27 19:45:49.072: INFO: Pod "nginx-deployment-7b8c6f4498-6dzrs" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-6dzrs,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-1996,SelfLink:/api/v1/namespaces/deployment-1996/pods/nginx-deployment-7b8c6f4498-6dzrs,UID:78b95f6a-e37b-4719-bff1-8efb4d867eef,ResourceVersion:40972,Generation:0,CreationTimestamp:2019-08-27 19:45:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 76c6c91c-bea9-49c2-9f67-3d3e80503e73 0xc0021c25c7 0xc0021c25c8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-5sd4z {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5sd4z,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-5sd4z true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.138.3.199,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0021c2640} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0021c2660}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:45:46 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:45:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:45:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:45:46 +0000 UTC  }],Message:,Reason:,HostIP:10.138.3.199,PodIP:,StartTime:2019-08-27 19:45:46 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 27 19:45:49.072: INFO: Pod "nginx-deployment-7b8c6f4498-6sm4f" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-6sm4f,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-1996,SelfLink:/api/v1/namespaces/deployment-1996/pods/nginx-deployment-7b8c6f4498-6sm4f,UID:6b625c14-e0d0-46e8-9910-56fabe950c6e,ResourceVersion:40809,Generation:0,CreationTimestamp:2019-08-27 19:45:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 76c6c91c-bea9-49c2-9f67-3d3e80503e73 0xc0021c2727 0xc0021c2728}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-5sd4z {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5sd4z,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-5sd4z true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.138.3.199,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0021c27a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0021c27c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:45:40 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:45:43 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:45:43 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:45:40 +0000 UTC  }],Message:,Reason:,HostIP:10.138.3.199,PodIP:172.30.145.47,StartTime:2019-08-27 19:45:40 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-08-27 19:45:42 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 containerd://a9d0be953aff5817da2da4b5976ec79c3c18a153fb293f08a3f9768120ae5286}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 27 19:45:49.072: INFO: Pod "nginx-deployment-7b8c6f4498-94qwc" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-94qwc,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-1996,SelfLink:/api/v1/namespaces/deployment-1996/pods/nginx-deployment-7b8c6f4498-94qwc,UID:c41306e2-399f-459c-9614-8cdf97495766,ResourceVersion:40783,Generation:0,CreationTimestamp:2019-08-27 19:45:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 76c6c91c-bea9-49c2-9f67-3d3e80503e73 0xc0021c2897 0xc0021c2898}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-5sd4z {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5sd4z,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-5sd4z true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.138.3.242,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0021c2910} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0021c2930}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:45:40 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:45:42 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:45:42 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:45:40 +0000 UTC  }],Message:,Reason:,HostIP:10.138.3.242,PodIP:172.30.115.41,StartTime:2019-08-27 19:45:40 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-08-27 19:45:42 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 containerd://aa478e08dd0625b2180f5d6b312a502501cec21222c86ca4d8f31a22ca79bdcb}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 27 19:45:49.072: INFO: Pod "nginx-deployment-7b8c6f4498-9rxcf" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-9rxcf,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-1996,SelfLink:/api/v1/namespaces/deployment-1996/pods/nginx-deployment-7b8c6f4498-9rxcf,UID:a79e0a28-2cc8-40bd-9ef1-8532013ef67d,ResourceVersion:40981,Generation:0,CreationTimestamp:2019-08-27 19:45:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 76c6c91c-bea9-49c2-9f67-3d3e80503e73 0xc0021c2a07 0xc0021c2a08}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-5sd4z {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5sd4z,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-5sd4z true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.138.3.233,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0021c2a90} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0021c2ab0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:45:46 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:45:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:45:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:45:46 +0000 UTC  }],Message:,Reason:,HostIP:10.138.3.233,PodIP:,StartTime:2019-08-27 19:45:46 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 27 19:45:49.073: INFO: Pod "nginx-deployment-7b8c6f4498-dnpgw" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-dnpgw,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-1996,SelfLink:/api/v1/namespaces/deployment-1996/pods/nginx-deployment-7b8c6f4498-dnpgw,UID:b3bc78d3-8868-453a-a361-10f5e4d77738,ResourceVersion:41006,Generation:0,CreationTimestamp:2019-08-27 19:45:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 76c6c91c-bea9-49c2-9f67-3d3e80503e73 0xc0021c2b77 0xc0021c2b78}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-5sd4z {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5sd4z,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-5sd4z true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.138.3.242,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0021c2bf0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0021c2c10}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:45:47 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:45:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:45:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:45:46 +0000 UTC  }],Message:,Reason:,HostIP:10.138.3.242,PodIP:,StartTime:2019-08-27 19:45:47 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 27 19:45:49.073: INFO: Pod "nginx-deployment-7b8c6f4498-g9ddv" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-g9ddv,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-1996,SelfLink:/api/v1/namespaces/deployment-1996/pods/nginx-deployment-7b8c6f4498-g9ddv,UID:ab1a5b00-8f7f-4d0f-9828-8a86ad2cf78a,ResourceVersion:40797,Generation:0,CreationTimestamp:2019-08-27 19:45:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 76c6c91c-bea9-49c2-9f67-3d3e80503e73 0xc0021c2cd7 0xc0021c2cd8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-5sd4z {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5sd4z,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-5sd4z true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.138.3.233,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0021c2d50} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0021c2d70}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:45:40 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:45:42 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:45:42 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:45:40 +0000 UTC  }],Message:,Reason:,HostIP:10.138.3.233,PodIP:172.30.37.237,StartTime:2019-08-27 19:45:40 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-08-27 19:45:42 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 containerd://58a11a7c7dd59c255c41694f0dc00c3c63f28119e6b55eddf9ba821e6e76df69}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 27 19:45:49.073: INFO: Pod "nginx-deployment-7b8c6f4498-hp2kt" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-hp2kt,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-1996,SelfLink:/api/v1/namespaces/deployment-1996/pods/nginx-deployment-7b8c6f4498-hp2kt,UID:834275d5-d576-4c16-b3f4-ed391b80b71e,ResourceVersion:40982,Generation:0,CreationTimestamp:2019-08-27 19:45:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 76c6c91c-bea9-49c2-9f67-3d3e80503e73 0xc0021c2e47 0xc0021c2e48}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-5sd4z {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5sd4z,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-5sd4z true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.138.3.199,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0021c2ec0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0021c2ef0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:45:46 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:45:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:45:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:45:46 +0000 UTC  }],Message:,Reason:,HostIP:10.138.3.199,PodIP:,StartTime:2019-08-27 19:45:46 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 27 19:45:49.073: INFO: Pod "nginx-deployment-7b8c6f4498-hwq4d" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-hwq4d,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-1996,SelfLink:/api/v1/namespaces/deployment-1996/pods/nginx-deployment-7b8c6f4498-hwq4d,UID:5f08142b-117c-4d02-bd2d-05b86304111d,ResourceVersion:40811,Generation:0,CreationTimestamp:2019-08-27 19:45:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 76c6c91c-bea9-49c2-9f67-3d3e80503e73 0xc0021c2fb7 0xc0021c2fb8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-5sd4z {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5sd4z,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-5sd4z true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.138.3.199,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0021c3030} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0021c3050}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:45:40 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:45:43 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:45:43 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:45:40 +0000 UTC  }],Message:,Reason:,HostIP:10.138.3.199,PodIP:172.30.145.46,StartTime:2019-08-27 19:45:40 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-08-27 19:45:42 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 containerd://98d1ab7f732ac840da2c06b7f63ee941eee2ee897e7490a4d2a1f1a022e143b1}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 27 19:45:49.073: INFO: Pod "nginx-deployment-7b8c6f4498-hxrxx" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-hxrxx,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-1996,SelfLink:/api/v1/namespaces/deployment-1996/pods/nginx-deployment-7b8c6f4498-hxrxx,UID:12c59d95-00b4-432e-a324-a3ca0d7fd2d4,ResourceVersion:40800,Generation:0,CreationTimestamp:2019-08-27 19:45:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 76c6c91c-bea9-49c2-9f67-3d3e80503e73 0xc0021c3127 0xc0021c3128}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-5sd4z {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5sd4z,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-5sd4z true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.138.3.233,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0021c31a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0021c31c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:45:40 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:45:42 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:45:42 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:45:40 +0000 UTC  }],Message:,Reason:,HostIP:10.138.3.233,PodIP:172.30.37.239,StartTime:2019-08-27 19:45:40 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-08-27 19:45:42 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 containerd://41ffe9e21f22efa5451856a4d8d232f73bd143747f9cb3d5d3d7ee1e08507aff}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 27 19:45:49.074: INFO: Pod "nginx-deployment-7b8c6f4498-jqz69" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-jqz69,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-1996,SelfLink:/api/v1/namespaces/deployment-1996/pods/nginx-deployment-7b8c6f4498-jqz69,UID:a8ff97d9-23ee-43d9-84ea-28fbe9f4aa64,ResourceVersion:40805,Generation:0,CreationTimestamp:2019-08-27 19:45:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 76c6c91c-bea9-49c2-9f67-3d3e80503e73 0xc0021c3297 0xc0021c3298}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-5sd4z {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5sd4z,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-5sd4z true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.138.3.233,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0021c3310} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0021c3330}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:45:40 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:45:42 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:45:42 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:45:40 +0000 UTC  }],Message:,Reason:,HostIP:10.138.3.233,PodIP:172.30.37.234,StartTime:2019-08-27 19:45:40 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-08-27 19:45:42 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 containerd://3778f8e2ce8d8e92a7ce77b6a0e03e2c0a71bd57ad78f1e1850da7239181b788}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 27 19:45:49.074: INFO: Pod "nginx-deployment-7b8c6f4498-kf7c9" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-kf7c9,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-1996,SelfLink:/api/v1/namespaces/deployment-1996/pods/nginx-deployment-7b8c6f4498-kf7c9,UID:d549107a-33be-4194-9694-b8089de79544,ResourceVersion:40975,Generation:0,CreationTimestamp:2019-08-27 19:45:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 76c6c91c-bea9-49c2-9f67-3d3e80503e73 0xc0021c3407 0xc0021c3408}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-5sd4z {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5sd4z,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-5sd4z true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.138.3.242,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0021c3480} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0021c34a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:45:46 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:45:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:45:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:45:46 +0000 UTC  }],Message:,Reason:,HostIP:10.138.3.242,PodIP:,StartTime:2019-08-27 19:45:46 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 27 19:45:49.074: INFO: Pod "nginx-deployment-7b8c6f4498-l8rvb" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-l8rvb,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-1996,SelfLink:/api/v1/namespaces/deployment-1996/pods/nginx-deployment-7b8c6f4498-l8rvb,UID:ea167b73-5fa9-4694-80c7-b45eb8fcd028,ResourceVersion:41001,Generation:0,CreationTimestamp:2019-08-27 19:45:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 76c6c91c-bea9-49c2-9f67-3d3e80503e73 0xc0021c3567 0xc0021c3568}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-5sd4z {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5sd4z,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-5sd4z true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.138.3.242,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0021c35e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0021c3600}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:45:46 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:45:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:45:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:45:46 +0000 UTC  }],Message:,Reason:,HostIP:10.138.3.242,PodIP:,StartTime:2019-08-27 19:45:46 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 27 19:45:49.074: INFO: Pod "nginx-deployment-7b8c6f4498-p5sx9" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-p5sx9,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-1996,SelfLink:/api/v1/namespaces/deployment-1996/pods/nginx-deployment-7b8c6f4498-p5sx9,UID:43c2ec26-e170-49b9-8210-aa025cefbe90,ResourceVersion:40993,Generation:0,CreationTimestamp:2019-08-27 19:45:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 76c6c91c-bea9-49c2-9f67-3d3e80503e73 0xc0021c36c7 0xc0021c36c8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-5sd4z {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5sd4z,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-5sd4z true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.138.3.242,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0021c3740} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0021c3760}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:45:46 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:45:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:45:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:45:46 +0000 UTC  }],Message:,Reason:,HostIP:10.138.3.242,PodIP:,StartTime:2019-08-27 19:45:46 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 27 19:45:49.074: INFO: Pod "nginx-deployment-7b8c6f4498-prrvx" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-prrvx,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-1996,SelfLink:/api/v1/namespaces/deployment-1996/pods/nginx-deployment-7b8c6f4498-prrvx,UID:2545eac1-ec49-4664-9e24-fc2b4ad61a8b,ResourceVersion:40957,Generation:0,CreationTimestamp:2019-08-27 19:45:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 76c6c91c-bea9-49c2-9f67-3d3e80503e73 0xc0021c3827 0xc0021c3828}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-5sd4z {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5sd4z,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-5sd4z true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.138.3.199,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0021c38a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0021c38c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:45:46 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:45:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:45:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:45:46 +0000 UTC  }],Message:,Reason:,HostIP:10.138.3.199,PodIP:,StartTime:2019-08-27 19:45:46 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 27 19:45:49.075: INFO: Pod "nginx-deployment-7b8c6f4498-qhntc" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-qhntc,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-1996,SelfLink:/api/v1/namespaces/deployment-1996/pods/nginx-deployment-7b8c6f4498-qhntc,UID:4a3d5bc2-5e53-4666-962a-27349e6c4a7b,ResourceVersion:40987,Generation:0,CreationTimestamp:2019-08-27 19:45:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 76c6c91c-bea9-49c2-9f67-3d3e80503e73 0xc0021c3987 0xc0021c3988}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-5sd4z {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5sd4z,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-5sd4z true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.138.3.199,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0021c3a10} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0021c3a30}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:45:47 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:45:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:45:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:45:46 +0000 UTC  }],Message:,Reason:,HostIP:10.138.3.199,PodIP:,StartTime:2019-08-27 19:45:47 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 27 19:45:49.075: INFO: Pod "nginx-deployment-7b8c6f4498-t87wj" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-t87wj,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-1996,SelfLink:/api/v1/namespaces/deployment-1996/pods/nginx-deployment-7b8c6f4498-t87wj,UID:628c61a6-030d-4116-a127-96dc8f6447a7,ResourceVersion:40964,Generation:0,CreationTimestamp:2019-08-27 19:45:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 76c6c91c-bea9-49c2-9f67-3d3e80503e73 0xc0021c3af7 0xc0021c3af8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-5sd4z {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5sd4z,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-5sd4z true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.138.3.242,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0021c3b70} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0021c3b90}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:45:46 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:45:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:45:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:45:46 +0000 UTC  }],Message:,Reason:,HostIP:10.138.3.242,PodIP:,StartTime:2019-08-27 19:45:46 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 27 19:45:49.075: INFO: Pod "nginx-deployment-7b8c6f4498-thp4t" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-thp4t,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-1996,SelfLink:/api/v1/namespaces/deployment-1996/pods/nginx-deployment-7b8c6f4498-thp4t,UID:08ad12b9-908c-40b6-8860-d4fabb4ba4e6,ResourceVersion:40984,Generation:0,CreationTimestamp:2019-08-27 19:45:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 76c6c91c-bea9-49c2-9f67-3d3e80503e73 0xc0021c3c57 0xc0021c3c58}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-5sd4z {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5sd4z,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-5sd4z true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.138.3.242,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0021c3cd0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0021c3cf0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:45:46 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:45:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:45:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:45:46 +0000 UTC  }],Message:,Reason:,HostIP:10.138.3.242,PodIP:,StartTime:2019-08-27 19:45:46 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 27 19:45:49.075: INFO: Pod "nginx-deployment-7b8c6f4498-vwlg5" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-vwlg5,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-1996,SelfLink:/api/v1/namespaces/deployment-1996/pods/nginx-deployment-7b8c6f4498-vwlg5,UID:d77d1f5e-4282-431c-b2a8-b0f6714f7355,ResourceVersion:41111,Generation:0,CreationTimestamp:2019-08-27 19:45:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 76c6c91c-bea9-49c2-9f67-3d3e80503e73 0xc0021c3db7 0xc0021c3db8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-5sd4z {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5sd4z,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-5sd4z true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.138.3.233,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0021c3e30} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0021c3e50}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:45:46 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:45:48 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:45:48 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:45:46 +0000 UTC  }],Message:,Reason:,HostIP:10.138.3.233,PodIP:172.30.37.244,StartTime:2019-08-27 19:45:46 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-08-27 19:45:48 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 containerd://8c09f9dca6f5f959a23e696588cb5ca36319d37d358b2581b75c99530371919f}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 27 19:45:49.075: INFO: Pod "nginx-deployment-7b8c6f4498-zkkwx" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-zkkwx,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-1996,SelfLink:/api/v1/namespaces/deployment-1996/pods/nginx-deployment-7b8c6f4498-zkkwx,UID:73ca9235-eba4-4fb3-90de-98f02129dc68,ResourceVersion:40819,Generation:0,CreationTimestamp:2019-08-27 19:45:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 76c6c91c-bea9-49c2-9f67-3d3e80503e73 0xc0021c3f37 0xc0021c3f38}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-5sd4z {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5sd4z,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-5sd4z true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.138.3.242,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0021c3fb0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0021c3fd0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:45:40 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:45:43 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:45:43 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-27 19:45:40 +0000 UTC  }],Message:,Reason:,HostIP:10.138.3.242,PodIP:172.30.115.44,StartTime:2019-08-27 19:45:40 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-08-27 19:45:42 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 containerd://06b4cecbca5877067fd03ff14c51d699a12fcedd6404db8a40ea5259e3c6d15c}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 19:45:49.076: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-1996" for this suite.
Aug 27 19:45:59.136: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 19:45:59.526: INFO: namespace deployment-1996 deletion completed in 10.437931436s

• [SLOW TEST:19.057 seconds]
[sig-apps] Deployment
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 19:45:59.532: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-7950
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Aug 27 19:45:59.768: INFO: Waiting up to 5m0s for pod "downwardapi-volume-07fab18c-3260-4f2e-8644-198b96fc0aa5" in namespace "downward-api-7950" to be "success or failure"
Aug 27 19:45:59.778: INFO: Pod "downwardapi-volume-07fab18c-3260-4f2e-8644-198b96fc0aa5": Phase="Pending", Reason="", readiness=false. Elapsed: 9.238357ms
Aug 27 19:46:01.788: INFO: Pod "downwardapi-volume-07fab18c-3260-4f2e-8644-198b96fc0aa5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01981232s
Aug 27 19:46:03.800: INFO: Pod "downwardapi-volume-07fab18c-3260-4f2e-8644-198b96fc0aa5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.031383454s
STEP: Saw pod success
Aug 27 19:46:03.800: INFO: Pod "downwardapi-volume-07fab18c-3260-4f2e-8644-198b96fc0aa5" satisfied condition "success or failure"
Aug 27 19:46:03.811: INFO: Trying to get logs from node 10.138.3.233 pod downwardapi-volume-07fab18c-3260-4f2e-8644-198b96fc0aa5 container client-container: <nil>
STEP: delete the pod
Aug 27 19:46:03.856: INFO: Waiting for pod downwardapi-volume-07fab18c-3260-4f2e-8644-198b96fc0aa5 to disappear
Aug 27 19:46:03.865: INFO: Pod downwardapi-volume-07fab18c-3260-4f2e-8644-198b96fc0aa5 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 19:46:03.865: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7950" for this suite.
Aug 27 19:46:09.923: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 19:46:10.297: INFO: namespace downward-api-7950 deletion completed in 6.417205741s

• [SLOW TEST:10.766 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 19:46:10.298: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-8602
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod busybox-e47aaa7f-4580-4b10-8577-ef689a0aa6bb in namespace container-probe-8602
Aug 27 19:46:14.563: INFO: Started pod busybox-e47aaa7f-4580-4b10-8577-ef689a0aa6bb in namespace container-probe-8602
STEP: checking the pod's current state and verifying that restartCount is present
Aug 27 19:46:14.573: INFO: Initial restart count of pod busybox-e47aaa7f-4580-4b10-8577-ef689a0aa6bb is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 19:50:15.918: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-8602" for this suite.
Aug 27 19:50:21.979: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 19:50:22.354: INFO: namespace container-probe-8602 deletion completed in 6.419799097s

• [SLOW TEST:252.056 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Delete Grace Period 
  should be submitted and removed [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 19:50:22.355: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-2579
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Delete Grace Period
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:47
[It] should be submitted and removed [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: setting up selector
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
Aug 27 19:50:24.644: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-540514467 proxy -p 0'
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
Aug 27 19:50:29.806: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 19:50:29.816: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-2579" for this suite.
Aug 27 19:50:35.883: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 19:50:36.285: INFO: namespace pods-2579 deletion completed in 6.457126992s

• [SLOW TEST:13.930 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  [k8s.io] Delete Grace Period
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should be submitted and removed [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 19:50:36.286: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-9174
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1517
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Aug 27 19:50:36.505: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-540514467 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=kubectl-9174'
Aug 27 19:50:36.754: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Aug 27 19:50:36.754: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
Aug 27 19:50:36.771: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 1 spec.replicas 1 status.replicas 0
STEP: rolling-update to same image controller
Aug 27 19:50:36.782: INFO: scanned /root for discovery docs: <nil>
Aug 27 19:50:36.782: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-540514467 rolling-update e2e-test-nginx-rc --update-period=1s --image=docker.io/library/nginx:1.14-alpine --image-pull-policy=IfNotPresent --namespace=kubectl-9174'
Aug 27 19:50:52.751: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Aug 27 19:50:52.751: INFO: stdout: "Created e2e-test-nginx-rc-f2a3f3b66589a3403532e3102c97de66\nScaling up e2e-test-nginx-rc-f2a3f3b66589a3403532e3102c97de66 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-f2a3f3b66589a3403532e3102c97de66 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-f2a3f3b66589a3403532e3102c97de66 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
Aug 27 19:50:52.751: INFO: stdout: "Created e2e-test-nginx-rc-f2a3f3b66589a3403532e3102c97de66\nScaling up e2e-test-nginx-rc-f2a3f3b66589a3403532e3102c97de66 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-f2a3f3b66589a3403532e3102c97de66 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-f2a3f3b66589a3403532e3102c97de66 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
Aug 27 19:50:52.751: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-540514467 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=kubectl-9174'
Aug 27 19:50:52.878: INFO: stderr: ""
Aug 27 19:50:52.878: INFO: stdout: "e2e-test-nginx-rc-f2a3f3b66589a3403532e3102c97de66-sshlw "
Aug 27 19:50:52.878: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-540514467 get pods e2e-test-nginx-rc-f2a3f3b66589a3403532e3102c97de66-sshlw -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9174'
Aug 27 19:50:53.002: INFO: stderr: ""
Aug 27 19:50:53.002: INFO: stdout: "true"
Aug 27 19:50:53.002: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-540514467 get pods e2e-test-nginx-rc-f2a3f3b66589a3403532e3102c97de66-sshlw -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9174'
Aug 27 19:50:53.127: INFO: stderr: ""
Aug 27 19:50:53.127: INFO: stdout: "docker.io/library/nginx:1.14-alpine"
Aug 27 19:50:53.127: INFO: e2e-test-nginx-rc-f2a3f3b66589a3403532e3102c97de66-sshlw is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1523
Aug 27 19:50:53.127: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-540514467 delete rc e2e-test-nginx-rc --namespace=kubectl-9174'
Aug 27 19:50:53.267: INFO: stderr: ""
Aug 27 19:50:53.267: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 19:50:53.267: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9174" for this suite.
Aug 27 19:50:59.328: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 19:50:59.752: INFO: namespace kubectl-9174 deletion completed in 6.467848393s

• [SLOW TEST:23.466 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-apps] Job 
  should delete a job [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 19:50:59.752: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename job
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in job-2785
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete a job [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: delete a job
STEP: deleting Job.batch foo in namespace job-2785, will wait for the garbage collector to delete the pods
Aug 27 19:51:04.083: INFO: Deleting Job.batch foo took: 21.066228ms
Aug 27 19:51:04.183: INFO: Terminating Job.batch foo pods took: 100.238134ms
STEP: Ensuring job was deleted
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 19:51:36.697: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-2785" for this suite.
Aug 27 19:51:42.756: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 19:51:43.116: INFO: namespace job-2785 deletion completed in 6.403342292s

• [SLOW TEST:43.364 seconds]
[sig-apps] Job
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should delete a job [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 19:51:43.117: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-9698
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Aug 27 19:51:45.400: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 19:51:45.437: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-9698" for this suite.
Aug 27 19:51:51.499: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 19:51:51.853: INFO: namespace container-runtime-9698 deletion completed in 6.401113958s

• [SLOW TEST:8.736 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  blackbox test
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
    on terminated container
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:129
      should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
      /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 19:51:51.854: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-2008
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Aug 27 19:52:14.119: INFO: Container started at 2019-08-27 19:51:53 +0000 UTC, pod became ready at 2019-08-27 19:52:12 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 19:52:14.119: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-2008" for this suite.
Aug 27 19:52:38.182: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 19:52:38.585: INFO: namespace container-probe-2008 deletion completed in 24.449598591s

• [SLOW TEST:46.731 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 19:52:38.591: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-3358
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test override command
Aug 27 19:52:38.830: INFO: Waiting up to 5m0s for pod "client-containers-14b30dd9-7710-4d7f-bf70-9f721047cafa" in namespace "containers-3358" to be "success or failure"
Aug 27 19:52:38.839: INFO: Pod "client-containers-14b30dd9-7710-4d7f-bf70-9f721047cafa": Phase="Pending", Reason="", readiness=false. Elapsed: 9.50063ms
Aug 27 19:52:40.906: INFO: Pod "client-containers-14b30dd9-7710-4d7f-bf70-9f721047cafa": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.076071781s
STEP: Saw pod success
Aug 27 19:52:40.906: INFO: Pod "client-containers-14b30dd9-7710-4d7f-bf70-9f721047cafa" satisfied condition "success or failure"
Aug 27 19:52:40.916: INFO: Trying to get logs from node 10.138.3.242 pod client-containers-14b30dd9-7710-4d7f-bf70-9f721047cafa container test-container: <nil>
STEP: delete the pod
Aug 27 19:52:40.971: INFO: Waiting for pod client-containers-14b30dd9-7710-4d7f-bf70-9f721047cafa to disappear
Aug 27 19:52:40.982: INFO: Pod client-containers-14b30dd9-7710-4d7f-bf70-9f721047cafa no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 19:52:40.982: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-3358" for this suite.
Aug 27 19:52:47.044: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 19:52:47.437: INFO: namespace containers-3358 deletion completed in 6.438970171s

• [SLOW TEST:8.847 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 19:52:47.438: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-2801
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:273
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the initial replication controller
Aug 27 19:52:47.659: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-540514467 create -f - --namespace=kubectl-2801'
Aug 27 19:52:47.962: INFO: stderr: ""
Aug 27 19:52:47.962: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Aug 27 19:52:47.962: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-540514467 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-2801'
Aug 27 19:52:48.089: INFO: stderr: ""
Aug 27 19:52:48.089: INFO: stdout: "update-demo-nautilus-5nmlb update-demo-nautilus-x82gw "
Aug 27 19:52:48.089: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-540514467 get pods update-demo-nautilus-5nmlb -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2801'
Aug 27 19:52:48.216: INFO: stderr: ""
Aug 27 19:52:48.216: INFO: stdout: ""
Aug 27 19:52:48.216: INFO: update-demo-nautilus-5nmlb is created but not running
Aug 27 19:52:53.217: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-540514467 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-2801'
Aug 27 19:52:53.357: INFO: stderr: ""
Aug 27 19:52:53.357: INFO: stdout: "update-demo-nautilus-5nmlb update-demo-nautilus-x82gw "
Aug 27 19:52:53.357: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-540514467 get pods update-demo-nautilus-5nmlb -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2801'
Aug 27 19:52:53.512: INFO: stderr: ""
Aug 27 19:52:53.512: INFO: stdout: "true"
Aug 27 19:52:53.512: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-540514467 get pods update-demo-nautilus-5nmlb -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-2801'
Aug 27 19:52:53.630: INFO: stderr: ""
Aug 27 19:52:53.630: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Aug 27 19:52:53.630: INFO: validating pod update-demo-nautilus-5nmlb
Aug 27 19:52:53.649: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug 27 19:52:53.649: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug 27 19:52:53.649: INFO: update-demo-nautilus-5nmlb is verified up and running
Aug 27 19:52:53.649: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-540514467 get pods update-demo-nautilus-x82gw -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2801'
Aug 27 19:52:53.782: INFO: stderr: ""
Aug 27 19:52:53.782: INFO: stdout: "true"
Aug 27 19:52:53.782: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-540514467 get pods update-demo-nautilus-x82gw -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-2801'
Aug 27 19:52:53.896: INFO: stderr: ""
Aug 27 19:52:53.896: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Aug 27 19:52:53.896: INFO: validating pod update-demo-nautilus-x82gw
Aug 27 19:52:53.913: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug 27 19:52:53.913: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug 27 19:52:53.913: INFO: update-demo-nautilus-x82gw is verified up and running
STEP: rolling-update to new replication controller
Aug 27 19:52:53.915: INFO: scanned /root for discovery docs: <nil>
Aug 27 19:52:53.915: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-540514467 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=kubectl-2801'
Aug 27 19:53:18.853: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Aug 27 19:53:18.853: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Aug 27 19:53:18.853: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-540514467 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-2801'
Aug 27 19:53:18.999: INFO: stderr: ""
Aug 27 19:53:18.999: INFO: stdout: "update-demo-kitten-c8c2k update-demo-kitten-nj56v "
Aug 27 19:53:18.999: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-540514467 get pods update-demo-kitten-c8c2k -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2801'
Aug 27 19:53:19.119: INFO: stderr: ""
Aug 27 19:53:19.119: INFO: stdout: "true"
Aug 27 19:53:19.119: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-540514467 get pods update-demo-kitten-c8c2k -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-2801'
Aug 27 19:53:19.254: INFO: stderr: ""
Aug 27 19:53:19.254: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Aug 27 19:53:19.254: INFO: validating pod update-demo-kitten-c8c2k
Aug 27 19:53:19.272: INFO: got data: {
  "image": "kitten.jpg"
}

Aug 27 19:53:19.272: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Aug 27 19:53:19.272: INFO: update-demo-kitten-c8c2k is verified up and running
Aug 27 19:53:19.273: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-540514467 get pods update-demo-kitten-nj56v -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2801'
Aug 27 19:53:19.405: INFO: stderr: ""
Aug 27 19:53:19.405: INFO: stdout: "true"
Aug 27 19:53:19.406: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-540514467 get pods update-demo-kitten-nj56v -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-2801'
Aug 27 19:53:19.553: INFO: stderr: ""
Aug 27 19:53:19.553: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Aug 27 19:53:19.553: INFO: validating pod update-demo-kitten-nj56v
Aug 27 19:53:19.573: INFO: got data: {
  "image": "kitten.jpg"
}

Aug 27 19:53:19.573: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Aug 27 19:53:19.573: INFO: update-demo-kitten-nj56v is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 19:53:19.573: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2801" for this suite.
Aug 27 19:53:43.636: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 19:53:44.036: INFO: namespace kubectl-2801 deletion completed in 24.443983125s

• [SLOW TEST:56.598 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 19:53:44.041: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-3604
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Aug 27 19:53:44.365: INFO: Number of nodes with available pods: 0
Aug 27 19:53:44.365: INFO: Node 10.138.3.199 is running more than one daemon pod
Aug 27 19:53:45.390: INFO: Number of nodes with available pods: 0
Aug 27 19:53:45.390: INFO: Node 10.138.3.199 is running more than one daemon pod
Aug 27 19:53:46.390: INFO: Number of nodes with available pods: 2
Aug 27 19:53:46.390: INFO: Node 10.138.3.242 is running more than one daemon pod
Aug 27 19:53:47.391: INFO: Number of nodes with available pods: 3
Aug 27 19:53:47.391: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Aug 27 19:53:47.445: INFO: Number of nodes with available pods: 2
Aug 27 19:53:47.445: INFO: Node 10.138.3.233 is running more than one daemon pod
Aug 27 19:53:48.472: INFO: Number of nodes with available pods: 2
Aug 27 19:53:48.472: INFO: Node 10.138.3.233 is running more than one daemon pod
Aug 27 19:53:49.472: INFO: Number of nodes with available pods: 2
Aug 27 19:53:49.472: INFO: Node 10.138.3.233 is running more than one daemon pod
Aug 27 19:53:50.474: INFO: Number of nodes with available pods: 3
Aug 27 19:53:50.474: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-3604, will wait for the garbage collector to delete the pods
Aug 27 19:53:50.579: INFO: Deleting DaemonSet.extensions daemon-set took: 21.225784ms
Aug 27 19:53:50.679: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.240473ms
Aug 27 19:54:03.789: INFO: Number of nodes with available pods: 0
Aug 27 19:54:03.790: INFO: Number of running nodes: 0, number of available pods: 0
Aug 27 19:54:03.800: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-3604/daemonsets","resourceVersion":"42957"},"items":null}

Aug 27 19:54:03.811: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-3604/pods","resourceVersion":"42957"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 19:54:03.875: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-3604" for this suite.
Aug 27 19:54:12.036: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 19:54:12.408: INFO: namespace daemonsets-3604 deletion completed in 8.422377599s

• [SLOW TEST:28.368 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 19:54:12.412: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-3511
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 19:54:12.659: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-3511" for this suite.
Aug 27 19:54:36.714: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 19:54:37.124: INFO: namespace kubelet-test-3511 deletion completed in 24.454445481s

• [SLOW TEST:24.713 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should be possible to delete [NodeConformance] [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 19:54:37.125: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-9327
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod test-webserver-ac236c09-b979-4428-a0c7-2d419940ec17 in namespace container-probe-9327
Aug 27 19:54:41.378: INFO: Started pod test-webserver-ac236c09-b979-4428-a0c7-2d419940ec17 in namespace container-probe-9327
STEP: checking the pod's current state and verifying that restartCount is present
Aug 27 19:54:41.388: INFO: Initial restart count of pod test-webserver-ac236c09-b979-4428-a0c7-2d419940ec17 is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 19:58:42.761: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-9327" for this suite.
Aug 27 19:58:48.818: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 19:58:49.182: INFO: namespace container-probe-9327 deletion completed in 6.406331317s

• [SLOW TEST:252.057 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 19:58:49.184: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-8247
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Performing setup for networking test in namespace pod-network-test-8247
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Aug 27 19:58:49.401: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Aug 27 19:59:09.620: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.37.196:8080/dial?request=hostName&protocol=udp&host=172.30.145.55&port=8081&tries=1'] Namespace:pod-network-test-8247 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 27 19:59:09.620: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
Aug 27 19:59:09.958: INFO: Waiting for endpoints: map[]
Aug 27 19:59:09.978: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.37.196:8080/dial?request=hostName&protocol=udp&host=172.30.37.255&port=8081&tries=1'] Namespace:pod-network-test-8247 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 27 19:59:09.978: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
Aug 27 19:59:10.342: INFO: Waiting for endpoints: map[]
Aug 27 19:59:10.353: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.37.196:8080/dial?request=hostName&protocol=udp&host=172.30.115.3&port=8081&tries=1'] Namespace:pod-network-test-8247 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 27 19:59:10.353: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
Aug 27 19:59:10.695: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 19:59:10.696: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-8247" for this suite.
Aug 27 19:59:34.755: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 19:59:35.120: INFO: namespace pod-network-test-8247 deletion completed in 24.408158423s

• [SLOW TEST:45.936 seconds]
[sig-network] Networking
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 19:59:35.123: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-4761
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-4761
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a new StatefulSet
Aug 27 19:59:35.388: INFO: Found 0 stateful pods, waiting for 3
Aug 27 19:59:45.399: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Aug 27 19:59:45.399: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Aug 27 19:59:45.399: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Aug 27 19:59:45.463: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Aug 27 19:59:55.534: INFO: Updating stateful set ss2
Aug 27 19:59:55.557: INFO: Waiting for Pod statefulset-4761/ss2-2 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Aug 27 20:00:05.594: INFO: Waiting for Pod statefulset-4761/ss2-2 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
STEP: Restoring Pods to the correct revision when they are deleted
Aug 27 20:00:15.645: INFO: Found 2 stateful pods, waiting for 3
Aug 27 20:00:25.657: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Aug 27 20:00:25.657: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Aug 27 20:00:25.657: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Aug 27 20:00:25.708: INFO: Updating stateful set ss2
Aug 27 20:00:25.730: INFO: Waiting for Pod statefulset-4761/ss2-1 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Aug 27 20:00:35.785: INFO: Updating stateful set ss2
Aug 27 20:00:35.809: INFO: Waiting for StatefulSet statefulset-4761/ss2 to complete update
Aug 27 20:00:35.809: INFO: Waiting for Pod statefulset-4761/ss2-0 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Aug 27 20:00:45.831: INFO: Waiting for StatefulSet statefulset-4761/ss2 to complete update
Aug 27 20:00:45.831: INFO: Waiting for Pod statefulset-4761/ss2-0 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Aug 27 20:00:55.830: INFO: Deleting all statefulset in ns statefulset-4761
Aug 27 20:00:55.842: INFO: Scaling statefulset ss2 to 0
Aug 27 20:01:25.887: INFO: Waiting for statefulset status.replicas updated to 0
Aug 27 20:01:25.897: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 20:01:25.941: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-4761" for this suite.
Aug 27 20:01:34.010: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 20:01:34.442: INFO: namespace statefulset-4761 deletion completed in 8.47790595s

• [SLOW TEST:119.319 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 20:01:34.444: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-5356
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Aug 27 20:01:34.752: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:watch-5356,SelfLink:/api/v1/namespaces/watch-5356/configmaps/e2e-watch-test-resource-version,UID:fcc13099-c222-43f3-92a2-10cbe2736627,ResourceVersion:44229,Generation:0,CreationTimestamp:2019-08-27 20:01:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Aug 27 20:01:34.753: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:watch-5356,SelfLink:/api/v1/namespaces/watch-5356/configmaps/e2e-watch-test-resource-version,UID:fcc13099-c222-43f3-92a2-10cbe2736627,ResourceVersion:44230,Generation:0,CreationTimestamp:2019-08-27 20:01:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 20:01:34.753: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-5356" for this suite.
Aug 27 20:01:40.811: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 20:01:41.187: INFO: namespace watch-5356 deletion completed in 6.420992404s

• [SLOW TEST:6.743 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 20:01:41.189: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7602
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Aug 27 20:01:41.428: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e96352e4-5e47-4184-a7f7-0664c1525557" in namespace "projected-7602" to be "success or failure"
Aug 27 20:01:41.439: INFO: Pod "downwardapi-volume-e96352e4-5e47-4184-a7f7-0664c1525557": Phase="Pending", Reason="", readiness=false. Elapsed: 10.846729ms
Aug 27 20:01:43.451: INFO: Pod "downwardapi-volume-e96352e4-5e47-4184-a7f7-0664c1525557": Phase="Running", Reason="", readiness=true. Elapsed: 2.022805628s
Aug 27 20:01:45.461: INFO: Pod "downwardapi-volume-e96352e4-5e47-4184-a7f7-0664c1525557": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.033278344s
STEP: Saw pod success
Aug 27 20:01:45.461: INFO: Pod "downwardapi-volume-e96352e4-5e47-4184-a7f7-0664c1525557" satisfied condition "success or failure"
Aug 27 20:01:45.471: INFO: Trying to get logs from node 10.138.3.233 pod downwardapi-volume-e96352e4-5e47-4184-a7f7-0664c1525557 container client-container: <nil>
STEP: delete the pod
Aug 27 20:01:45.523: INFO: Waiting for pod downwardapi-volume-e96352e4-5e47-4184-a7f7-0664c1525557 to disappear
Aug 27 20:01:45.534: INFO: Pod downwardapi-volume-e96352e4-5e47-4184-a7f7-0664c1525557 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 20:01:45.534: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7602" for this suite.
Aug 27 20:01:51.593: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 20:01:51.969: INFO: namespace projected-7602 deletion completed in 6.419705151s

• [SLOW TEST:10.781 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 20:01:51.970: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9611
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-a631cf4d-d4ee-4247-a0c4-717b9b37e95e
STEP: Creating a pod to test consume secrets
Aug 27 20:01:52.220: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-f12968f3-a2ae-4acf-bdcc-a0611d6a5d9b" in namespace "projected-9611" to be "success or failure"
Aug 27 20:01:52.231: INFO: Pod "pod-projected-secrets-f12968f3-a2ae-4acf-bdcc-a0611d6a5d9b": Phase="Pending", Reason="", readiness=false. Elapsed: 10.449728ms
Aug 27 20:01:54.242: INFO: Pod "pod-projected-secrets-f12968f3-a2ae-4acf-bdcc-a0611d6a5d9b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021388788s
Aug 27 20:01:56.252: INFO: Pod "pod-projected-secrets-f12968f3-a2ae-4acf-bdcc-a0611d6a5d9b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.032074828s
STEP: Saw pod success
Aug 27 20:01:56.253: INFO: Pod "pod-projected-secrets-f12968f3-a2ae-4acf-bdcc-a0611d6a5d9b" satisfied condition "success or failure"
Aug 27 20:01:56.262: INFO: Trying to get logs from node 10.138.3.242 pod pod-projected-secrets-f12968f3-a2ae-4acf-bdcc-a0611d6a5d9b container projected-secret-volume-test: <nil>
STEP: delete the pod
Aug 27 20:01:56.330: INFO: Waiting for pod pod-projected-secrets-f12968f3-a2ae-4acf-bdcc-a0611d6a5d9b to disappear
Aug 27 20:01:56.340: INFO: Pod pod-projected-secrets-f12968f3-a2ae-4acf-bdcc-a0611d6a5d9b no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 20:01:56.340: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9611" for this suite.
Aug 27 20:02:02.410: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 20:02:02.799: INFO: namespace projected-9611 deletion completed in 6.433891673s

• [SLOW TEST:10.829 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 20:02:02.800: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-6702
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
Aug 27 20:02:03.014: INFO: PodSpec: initContainers in spec.initContainers
Aug 27 20:02:53.987: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-83981f94-e90b-4e59-aea9-f4ee655eed29", GenerateName:"", Namespace:"init-container-6702", SelfLink:"/api/v1/namespaces/init-container-6702/pods/pod-init-83981f94-e90b-4e59-aea9-f4ee655eed29", UID:"8f9bb1a6-a9fe-4b1c-8b23-77ca8cb8046e", ResourceVersion:"44479", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63702532922, loc:(*time.Location)(0x7ec7a20)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"14089052"}, Annotations:map[string]string{"kubernetes.io/psp":"e2e-test-privileged-psp"}, OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-qz7f9", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc000226180), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-qz7f9", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-qz7f9", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-qz7f9", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc0013d8088), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"10.138.3.233", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc001d4a000), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0013d8110)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0013d8130)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc0013d8138), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc0013d813c), PreemptionPolicy:(*v1.PreemptionPolicy)(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63702532923, loc:(*time.Location)(0x7ec7a20)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63702532923, loc:(*time.Location)(0x7ec7a20)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63702532923, loc:(*time.Location)(0x7ec7a20)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63702532922, loc:(*time.Location)(0x7ec7a20)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.138.3.233", PodIP:"172.30.37.201", StartTime:(*v1.Time)(0xc0026120c0), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(0xc002612120), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc000dde4d0)}, Ready:false, RestartCount:3, Image:"docker.io/library/busybox:1.29", ImageID:"docker.io/library/busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"containerd://90a1dd72059f9eb27a9ffbf5e38edb97448000906dfe984753b307df3b2791ec"}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc002612160), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:""}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0026120e0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:""}}, QOSClass:"Guaranteed"}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 20:02:53.988: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-6702" for this suite.
Aug 27 20:03:18.046: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 20:03:18.411: INFO: namespace init-container-6702 deletion completed in 24.408176469s

• [SLOW TEST:75.611 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 20:03:18.412: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-5252
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Starting the proxy
Aug 27 20:03:18.650: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-540514467 proxy --unix-socket=/tmp/kubectl-proxy-unix342145082/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 20:03:18.722: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5252" for this suite.
Aug 27 20:03:24.780: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 20:03:25.151: INFO: namespace kubectl-5252 deletion completed in 6.416366931s

• [SLOW TEST:6.739 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Proxy server
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 20:03:25.151: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8251
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-5f1ed879-5eae-4c60-a03e-0b1fd0effbbe
STEP: Creating a pod to test consume configMaps
Aug 27 20:03:25.402: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-26ca1fd4-9895-4303-a7ce-1c6fb8d99679" in namespace "projected-8251" to be "success or failure"
Aug 27 20:03:25.427: INFO: Pod "pod-projected-configmaps-26ca1fd4-9895-4303-a7ce-1c6fb8d99679": Phase="Pending", Reason="", readiness=false. Elapsed: 25.313772ms
Aug 27 20:03:27.438: INFO: Pod "pod-projected-configmaps-26ca1fd4-9895-4303-a7ce-1c6fb8d99679": Phase="Pending", Reason="", readiness=false. Elapsed: 2.036020522s
Aug 27 20:03:29.448: INFO: Pod "pod-projected-configmaps-26ca1fd4-9895-4303-a7ce-1c6fb8d99679": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.046542198s
STEP: Saw pod success
Aug 27 20:03:29.448: INFO: Pod "pod-projected-configmaps-26ca1fd4-9895-4303-a7ce-1c6fb8d99679" satisfied condition "success or failure"
Aug 27 20:03:29.458: INFO: Trying to get logs from node 10.138.3.242 pod pod-projected-configmaps-26ca1fd4-9895-4303-a7ce-1c6fb8d99679 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Aug 27 20:03:29.505: INFO: Waiting for pod pod-projected-configmaps-26ca1fd4-9895-4303-a7ce-1c6fb8d99679 to disappear
Aug 27 20:03:29.514: INFO: Pod pod-projected-configmaps-26ca1fd4-9895-4303-a7ce-1c6fb8d99679 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 20:03:29.514: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8251" for this suite.
Aug 27 20:03:35.576: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 20:03:35.963: INFO: namespace projected-8251 deletion completed in 6.433275203s

• [SLOW TEST:10.812 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 20:03:35.964: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-9811
STEP: Waiting for a default service account to be provisioned in namespace
[It] should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: starting a background goroutine to produce watch events
STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 20:03:41.636: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-9811" for this suite.
Aug 27 20:03:47.800: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 20:03:48.199: INFO: namespace watch-9811 deletion completed in 6.510379722s

• [SLOW TEST:12.235 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 20:03:48.201: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-1352
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0666 on tmpfs
Aug 27 20:03:48.437: INFO: Waiting up to 5m0s for pod "pod-4043acd3-3f0d-461c-b0c8-f99fea31df2b" in namespace "emptydir-1352" to be "success or failure"
Aug 27 20:03:48.448: INFO: Pod "pod-4043acd3-3f0d-461c-b0c8-f99fea31df2b": Phase="Pending", Reason="", readiness=false. Elapsed: 10.310329ms
Aug 27 20:03:50.458: INFO: Pod "pod-4043acd3-3f0d-461c-b0c8-f99fea31df2b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020095676s
STEP: Saw pod success
Aug 27 20:03:50.458: INFO: Pod "pod-4043acd3-3f0d-461c-b0c8-f99fea31df2b" satisfied condition "success or failure"
Aug 27 20:03:50.467: INFO: Trying to get logs from node 10.138.3.233 pod pod-4043acd3-3f0d-461c-b0c8-f99fea31df2b container test-container: <nil>
STEP: delete the pod
Aug 27 20:03:50.512: INFO: Waiting for pod pod-4043acd3-3f0d-461c-b0c8-f99fea31df2b to disappear
Aug 27 20:03:50.522: INFO: Pod pod-4043acd3-3f0d-461c-b0c8-f99fea31df2b no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 20:03:50.522: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1352" for this suite.
Aug 27 20:03:56.586: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 20:03:56.967: INFO: namespace emptydir-1352 deletion completed in 6.430139174s

• [SLOW TEST:8.766 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 20:03:56.968: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-9946
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Aug 27 20:03:59.282: INFO: Waiting up to 5m0s for pod "client-envvars-14df14c4-42b0-4c19-9f5e-562d39dc23e6" in namespace "pods-9946" to be "success or failure"
Aug 27 20:03:59.293: INFO: Pod "client-envvars-14df14c4-42b0-4c19-9f5e-562d39dc23e6": Phase="Pending", Reason="", readiness=false. Elapsed: 10.999452ms
Aug 27 20:04:01.305: INFO: Pod "client-envvars-14df14c4-42b0-4c19-9f5e-562d39dc23e6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.022986447s
STEP: Saw pod success
Aug 27 20:04:01.305: INFO: Pod "client-envvars-14df14c4-42b0-4c19-9f5e-562d39dc23e6" satisfied condition "success or failure"
Aug 27 20:04:01.316: INFO: Trying to get logs from node 10.138.3.233 pod client-envvars-14df14c4-42b0-4c19-9f5e-562d39dc23e6 container env3cont: <nil>
STEP: delete the pod
Aug 27 20:04:01.361: INFO: Waiting for pod client-envvars-14df14c4-42b0-4c19-9f5e-562d39dc23e6 to disappear
Aug 27 20:04:01.371: INFO: Pod client-envvars-14df14c4-42b0-4c19-9f5e-562d39dc23e6 no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 20:04:01.371: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-9946" for this suite.
Aug 27 20:04:45.432: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 20:04:45.864: INFO: namespace pods-9946 deletion completed in 44.478762271s

• [SLOW TEST:48.897 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 20:04:45.865: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-9248
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-upd-059eb8ca-728f-4085-838e-2e14739abfa7
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 20:04:48.216: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9248" for this suite.
Aug 27 20:05:12.279: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 20:05:12.666: INFO: namespace configmap-9248 deletion completed in 24.434153528s

• [SLOW TEST:26.801 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 20:05:12.668: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-2254
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 20:05:12.906: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-2254" for this suite.
Aug 27 20:05:18.964: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 20:05:19.316: INFO: namespace services-2254 deletion completed in 6.39550076s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:92

• [SLOW TEST:6.648 seconds]
[sig-network] Services
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide secure master service  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 20:05:19.316: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-6837
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Aug 27 20:05:19.554: INFO: Waiting up to 5m0s for pod "downwardapi-volume-1d21a165-5132-4c37-8678-e7e1f4f353a3" in namespace "downward-api-6837" to be "success or failure"
Aug 27 20:05:19.567: INFO: Pod "downwardapi-volume-1d21a165-5132-4c37-8678-e7e1f4f353a3": Phase="Pending", Reason="", readiness=false. Elapsed: 13.515947ms
Aug 27 20:05:21.578: INFO: Pod "downwardapi-volume-1d21a165-5132-4c37-8678-e7e1f4f353a3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.024252272s
STEP: Saw pod success
Aug 27 20:05:21.578: INFO: Pod "downwardapi-volume-1d21a165-5132-4c37-8678-e7e1f4f353a3" satisfied condition "success or failure"
Aug 27 20:05:21.588: INFO: Trying to get logs from node 10.138.3.233 pod downwardapi-volume-1d21a165-5132-4c37-8678-e7e1f4f353a3 container client-container: <nil>
STEP: delete the pod
Aug 27 20:05:21.640: INFO: Waiting for pod downwardapi-volume-1d21a165-5132-4c37-8678-e7e1f4f353a3 to disappear
Aug 27 20:05:21.650: INFO: Pod downwardapi-volume-1d21a165-5132-4c37-8678-e7e1f4f353a3 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 20:05:21.650: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6837" for this suite.
Aug 27 20:05:27.708: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 20:05:28.087: INFO: namespace downward-api-6837 deletion completed in 6.42230001s

• [SLOW TEST:8.771 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 20:05:28.088: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-28
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 20:05:30.376: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-28" for this suite.
Aug 27 20:06:10.442: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 20:06:10.840: INFO: namespace kubelet-test-28 deletion completed in 40.447221286s

• [SLOW TEST:42.752 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when scheduling a busybox command in a pod
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:40
    should print the output to logs [NodeConformance] [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 20:06:10.840: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-6496
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Aug 27 20:06:11.063: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 20:06:12.187: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-6496" for this suite.
Aug 27 20:06:18.251: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 20:06:18.606: INFO: namespace custom-resource-definition-6496 deletion completed in 6.404035331s

• [SLOW TEST:7.766 seconds]
[sig-api-machinery] CustomResourceDefinition resources
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:35
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 20:06:18.607: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-1374
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating replication controller my-hostname-basic-f6a62044-f100-4c44-b3ce-e2a400dabb48
Aug 27 20:06:18.871: INFO: Pod name my-hostname-basic-f6a62044-f100-4c44-b3ce-e2a400dabb48: Found 0 pods out of 1
Aug 27 20:06:23.883: INFO: Pod name my-hostname-basic-f6a62044-f100-4c44-b3ce-e2a400dabb48: Found 1 pods out of 1
Aug 27 20:06:23.883: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-f6a62044-f100-4c44-b3ce-e2a400dabb48" are running
Aug 27 20:06:23.892: INFO: Pod "my-hostname-basic-f6a62044-f100-4c44-b3ce-e2a400dabb48-d2kgm" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-08-27 20:06:18 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-08-27 20:06:20 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-08-27 20:06:20 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-08-27 20:06:18 +0000 UTC Reason: Message:}])
Aug 27 20:06:23.893: INFO: Trying to dial the pod
Aug 27 20:06:28.932: INFO: Controller my-hostname-basic-f6a62044-f100-4c44-b3ce-e2a400dabb48: Got expected result from replica 1 [my-hostname-basic-f6a62044-f100-4c44-b3ce-e2a400dabb48-d2kgm]: "my-hostname-basic-f6a62044-f100-4c44-b3ce-e2a400dabb48-d2kgm", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 20:06:28.932: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-1374" for this suite.
Aug 27 20:06:34.996: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 20:06:35.365: INFO: namespace replication-controller-1374 deletion completed in 6.416885612s

• [SLOW TEST:16.758 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 20:06:35.365: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-3909
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:273
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a replication controller
Aug 27 20:06:35.584: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-540514467 create -f - --namespace=kubectl-3909'
Aug 27 20:06:36.054: INFO: stderr: ""
Aug 27 20:06:36.054: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Aug 27 20:06:36.054: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-540514467 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-3909'
Aug 27 20:06:36.203: INFO: stderr: ""
Aug 27 20:06:36.203: INFO: stdout: "update-demo-nautilus-cjkhr update-demo-nautilus-xzpwj "
Aug 27 20:06:36.203: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-540514467 get pods update-demo-nautilus-cjkhr -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3909'
Aug 27 20:06:36.331: INFO: stderr: ""
Aug 27 20:06:36.331: INFO: stdout: ""
Aug 27 20:06:36.331: INFO: update-demo-nautilus-cjkhr is created but not running
Aug 27 20:06:41.332: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-540514467 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-3909'
Aug 27 20:06:41.463: INFO: stderr: ""
Aug 27 20:06:41.463: INFO: stdout: "update-demo-nautilus-cjkhr update-demo-nautilus-xzpwj "
Aug 27 20:06:41.463: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-540514467 get pods update-demo-nautilus-cjkhr -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3909'
Aug 27 20:06:41.580: INFO: stderr: ""
Aug 27 20:06:41.581: INFO: stdout: "true"
Aug 27 20:06:41.581: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-540514467 get pods update-demo-nautilus-cjkhr -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-3909'
Aug 27 20:06:41.711: INFO: stderr: ""
Aug 27 20:06:41.711: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Aug 27 20:06:41.711: INFO: validating pod update-demo-nautilus-cjkhr
Aug 27 20:06:41.728: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug 27 20:06:41.728: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug 27 20:06:41.728: INFO: update-demo-nautilus-cjkhr is verified up and running
Aug 27 20:06:41.728: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-540514467 get pods update-demo-nautilus-xzpwj -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3909'
Aug 27 20:06:41.860: INFO: stderr: ""
Aug 27 20:06:41.860: INFO: stdout: "true"
Aug 27 20:06:41.860: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-540514467 get pods update-demo-nautilus-xzpwj -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-3909'
Aug 27 20:06:41.996: INFO: stderr: ""
Aug 27 20:06:41.996: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Aug 27 20:06:41.996: INFO: validating pod update-demo-nautilus-xzpwj
Aug 27 20:06:42.014: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug 27 20:06:42.014: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug 27 20:06:42.014: INFO: update-demo-nautilus-xzpwj is verified up and running
STEP: using delete to clean up resources
Aug 27 20:06:42.014: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-540514467 delete --grace-period=0 --force -f - --namespace=kubectl-3909'
Aug 27 20:06:42.153: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 27 20:06:42.153: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Aug 27 20:06:42.153: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-540514467 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-3909'
Aug 27 20:06:42.281: INFO: stderr: "No resources found.\n"
Aug 27 20:06:42.281: INFO: stdout: ""
Aug 27 20:06:42.281: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-540514467 get pods -l name=update-demo --namespace=kubectl-3909 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Aug 27 20:06:42.400: INFO: stderr: ""
Aug 27 20:06:42.400: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 20:06:42.400: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3909" for this suite.
Aug 27 20:06:50.460: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 20:06:50.842: INFO: namespace kubectl-3909 deletion completed in 8.426634227s

• [SLOW TEST:15.477 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 20:06:50.844: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replicaset-1772
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Aug 27 20:06:54.293: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 20:06:54.327: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-1772" for this suite.
Aug 27 20:07:10.389: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 20:07:10.827: INFO: namespace replicaset-1772 deletion completed in 16.481235886s

• [SLOW TEST:19.984 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 27 20:07:10.828: INFO: >>> kubeConfig: /tmp/kubeconfig-540514467
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5770
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-3eb660e2-b001-4261-84a7-2da130fd0c75
STEP: Creating a pod to test consume secrets
Aug 27 20:07:11.074: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-97a7c674-73d4-4665-9e50-c25c2c1945b5" in namespace "projected-5770" to be "success or failure"
Aug 27 20:07:11.085: INFO: Pod "pod-projected-secrets-97a7c674-73d4-4665-9e50-c25c2c1945b5": Phase="Pending", Reason="", readiness=false. Elapsed: 11.045466ms
Aug 27 20:07:13.096: INFO: Pod "pod-projected-secrets-97a7c674-73d4-4665-9e50-c25c2c1945b5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021812233s
Aug 27 20:07:15.107: INFO: Pod "pod-projected-secrets-97a7c674-73d4-4665-9e50-c25c2c1945b5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.032403313s
STEP: Saw pod success
Aug 27 20:07:15.107: INFO: Pod "pod-projected-secrets-97a7c674-73d4-4665-9e50-c25c2c1945b5" satisfied condition "success or failure"
Aug 27 20:07:15.117: INFO: Trying to get logs from node 10.138.3.242 pod pod-projected-secrets-97a7c674-73d4-4665-9e50-c25c2c1945b5 container projected-secret-volume-test: <nil>
STEP: delete the pod
Aug 27 20:07:15.169: INFO: Waiting for pod pod-projected-secrets-97a7c674-73d4-4665-9e50-c25c2c1945b5 to disappear
Aug 27 20:07:15.188: INFO: Pod pod-projected-secrets-97a7c674-73d4-4665-9e50-c25c2c1945b5 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 27 20:07:15.188: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5770" for this suite.
Aug 27 20:07:21.249: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 27 20:07:21.664: INFO: namespace projected-5770 deletion completed in 6.460355403s

• [SLOW TEST:10.837 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSAug 27 20:07:21.666: INFO: Running AfterSuite actions on all nodes
Aug 27 20:07:21.666: INFO: Running AfterSuite actions on node 1
Aug 27 20:07:21.666: INFO: Skipping dumping logs from cluster

Ran 215 of 4413 Specs in 5825.698 seconds
SUCCESS! -- 215 Passed | 0 Failed | 0 Pending | 4198 Skipped
PASS

Ginkgo ran 1 suite in 1h37m7.471845795s
Test Suite Passed
